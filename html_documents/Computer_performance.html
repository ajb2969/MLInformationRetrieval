<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="364">Computer performance</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>Computer performance</h1>
<hr/>

<p><strong>Computer performance</strong> is characterized by the amount of useful work accomplished by a computer system or computer network compared to the time and resources used. Depending on the context, high computer performance may involve one or more of the following:</p>
<ul>
<li>Short <a href="Response_time_(technology)" title="wikilink">response time</a> for a given piece of work</li>
<li>High <a class="uri" href="throughput" title="wikilink">throughput</a> (rate of processing work)</li>
<li>Low utilization of <a href="computing_resource" title="wikilink">computing resource</a>(s)</li>
<li><a href="High_availability" title="wikilink">High availability</a> of the computing system or application</li>
<li>Fast (or highly compact) <a href="data_compression" title="wikilink">data compression</a> and decompression</li>
<li>High <a href="Bandwidth_(computing)" title="wikilink">bandwidth</a></li>
<li>Short <a href="data_transmission" title="wikilink">data transmission</a> time</li>
</ul>
<h2 id="technical-and-non-technical-definitions">Technical and non-technical definitions</h2>

<p>The performance of any computer system can be evaluated in measurable, technical terms, using one or more of the metrics listed above. This way the performance can be</p>
<ul>
<li>Compared relative to other systems or the same system before/after changes</li>
<li>In absolute terms, e.g. for fulfilling a contractual obligation</li>
</ul>

<p>Whilst the above definition relates to a scientific, technical approach, the following definition given by <a href="Arnold_Allen" title="wikilink">Arnold Allen</a> would be useful for a non-technical audience:</p>
<blockquote>

<p>''The word <em>performance</em> in computer performance means the same thing that performance means in other contexts, that is, it means "How well is the computer doing the work it is supposed to do?"''<a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a></p>
</blockquote>
<h3 id="as-an-aspect-of-software-quality">As an aspect of software quality</h3>

<p><a href="Computer_software" title="wikilink">Computer software</a> performance, particularly <a href="software_application" title="wikilink">software application</a> response time, is an aspect of <a href="software_quality" title="wikilink">software quality</a> that is important in <a href="human–computer_interaction" title="wikilink">human–computer interactions</a>.</p>
<h2 id="performance-engineering">Performance engineering</h2>

<p>Performance engineering within systems engineering, encompasses the set of roles, skills, activities, practices, tools, and deliverables applied at every phase of the systems development life cycle which ensures that a solution will be designed, implemented, and operationally supported to meet the performance requirements defined for the solution.</p>

<p>Performance engineering continuously deals with trade-offs between types of performance. Occasionally a <a href="CPU_design" title="wikilink">CPU designer</a> can find a way to make a CPU with better overall performance by improving one of the aspects of performance, presented below, without sacrificing the CPU's performance in other areas. For example, building the CPU out of better, faster transistors.</p>

<p>However, sometimes pushing one type of performance to an extreme leads to a CPU with worse overall performance, because other important aspects were sacrificed to get one impressive-looking number, for example, the chip's <a href="clock_rate" title="wikilink">clock rate</a> (see the <a href="megahertz_myth" title="wikilink">megahertz myth</a>).</p>
<h3 id="application-performance-engineering">Application performance engineering</h3>

<p>Application Performance Engineering (APE) is a specific methodology within <a href="performance_engineering" title="wikilink">performance engineering</a> designed to meet the challenges associated with application performance in increasingly distributed mobile, cloud and terrestrial IT environments. It includes the roles, skills, activities, practices, tools and deliverables applied at every phase of the application lifecycle that ensure an application will be designed, implemented and operationally supported to meet non-functional performance requirements.</p>
<h2 id="aspects-of-performance">Aspects of performance</h2>

<p>Computer performance <a href="Software_metric" title="wikilink">metrics</a> (things to measure) include <a class="uri" href="availability" title="wikilink">availability</a>, <a href="Response_time_(technology)" title="wikilink">response time</a>, <a href="channel_capacity" title="wikilink">channel capacity</a>, <a href="Latency_(engineering)" title="wikilink">latency</a>, <a href="completion_time" title="wikilink">completion time</a>, <a href="service_time" title="wikilink">service time</a>, <a href="Bandwidth_(computing)" title="wikilink">bandwidth</a>, <a class="uri" href="throughput" title="wikilink">throughput</a>, <a href="relative_efficiency" title="wikilink">relative efficiency</a>, <a class="uri" href="scalability" title="wikilink">scalability</a>, <a href="performance_per_watt" title="wikilink">performance per watt</a>, <a href="Data_compression" title="wikilink">compression ratio</a>, <a href="instruction_path_length" title="wikilink">instruction path length</a> and <a href="speed_up" title="wikilink">speed up</a>. <a class="uri" href="CPU" title="wikilink">CPU</a> benchmarks are available.<a class="footnoteRef" href="#fn2" id="fnref2"><sup>2</sup></a></p>
<h3 id="availability">Availability</h3>

<p>Availability of a system is typically measured as a factor of its reliability - as reliability increases, so does availability (that is, less <a class="uri" href="downtime" title="wikilink">downtime</a>). Availability of a system may also be increased by the strategy of focusing on increasing testability and maintainability and not on reliability. Improving maintainability is generally easier than reliability. Maintainability estimates (Repair rates) are also generally more accurate. However, because the uncertainties in the reliability estimates are in most cases very large, it is likely to dominate the availability (prediction uncertainty) problem, even while maintainability levels are very high.</p>
<h3 id="response-time">Response time</h3>

<p>Response time is the total amount of time it takes to respond to a request for service. In computing, that service can be any unit of work from a simple disk IO to loading a complex <a href="web_page" title="wikilink">web page</a>. The response time is the sum of three numbers:<a class="footnoteRef" href="#fn3" id="fnref3"><sup>3</sup></a></p>
<ul>
<li>Service time - How long it takes to do the work requested.</li>
<li>Wait time - How long the request has to wait for requests queued ahead of it before it gets to run.</li>
<li>Transmission time – How long it takes to move the request to the computer doing the work and the response back to the requestor.</li>
</ul>
<h3 id="processing-speed">Processing speed</h3>

<p>Most consumers pick a computer architecture (normally <a class="uri" href="Intel" title="wikilink">Intel</a> <a class="uri" href="IA32" title="wikilink">IA32</a> architecture) to be able to run a large base of pre-existing, pre-compiled software. Being relatively uninformed on computer benchmarks, some of them pick a particular CPU based on operating frequency (see <a href="megahertz_myth" title="wikilink">megahertz myth</a>).</p>

<p>Some system designers building parallel computers pick CPUs based on the speed per dollar.</p>
<h3 id="channel-capacity">Channel capacity</h3>

<p>Channel capacity is the tightest upper bound on the rate of <a class="uri" href="information" title="wikilink">information</a> that can be reliably transmitted over a <a href="channel_(communications)" title="wikilink">communications channel</a>. By the <a href="noisy-channel_coding_theorem" title="wikilink">noisy-channel coding theorem</a>, the channel capacity of a given <a href="Channel_(communications)" title="wikilink">channel</a> is the limiting information rate (in units of <a href="information_entropy" title="wikilink">information</a> per unit time) that can be achieved with arbitrarily small error probability.<a class="footnoteRef" href="#fn4" id="fnref4"><sup>4</sup></a><a class="footnoteRef" href="#fn5" id="fnref5"><sup>5</sup></a></p>

<p><a href="Information_theory" title="wikilink">Information theory</a>, developed by <a href="Claude_E._Shannon" title="wikilink">Claude E. Shannon</a> during <a href="World_War_II" title="wikilink">World War II</a>, defines the notion of channel capacity and provides a mathematical model by which one can compute it. The key result states that the capacity of the channel, as defined above, is given by the maximum of the <a href="mutual_information" title="wikilink">mutual information</a> between the input and output of the channel, where the maximization is with respect to the input distribution.<a class="footnoteRef" href="#fn6" id="fnref6"><sup>6</sup></a></p>
<h3 id="latency">Latency</h3>

<p>Latency is a time delay between the cause and the effect of some physical change in the system being observed. Latency is a result of the limited velocity with which any physical interaction can take place. This velocity is always lower or equal to speed of light. Therefore every physical system that has spatial dimensions different from zero will experience some sort of latency.</p>

<p>The precise definition of latency depends on the system being observed and the nature of stimulation. In communications, the lower limit of latency is determined by the medium being used for communications. In reliable two-way communication systems, latency limits the maximum rate that information can be transmitted, as there is often a limit on the amount of information that is "in-flight" at any one moment. In the field of human-machine interaction, perceptible latency (delay between what the user commands and when the computer provides the results) has a strong effect on user satisfaction and usability.</p>

<p>Computers run sets of instructions called a process. In operating systems, the execution of the process can be postponed if other processes are also executing. In addition, the operating system can schedule when to perform the action that the process is commanding. For example, suppose a process commands that a computer card's voltage output be set high-low-high-low and so on at a rate of 1000 Hz. The operating system may choose to adjust the scheduling of each transition (high-low or low-high) based on an internal clock. The latency is the delay between the process instruction commanding the transition and the hardware actually transitioning the voltage from high to low or low to high.</p>

<p>System designers building <a href="real-time_computing" title="wikilink">real-time computing</a> systems want to guarantee worst-case response. That is easier to do when the CPU has low <a href="interrupt_latency" title="wikilink">interrupt latency</a> and when it has deterministic response.</p>
<h3 id="bandwidth">Bandwidth</h3>

<p>In computer networking, bandwidth is a measurement of bit-rate of available or consumed data communication resources, expressed in bits per second or multiples of it (bit/s, kbit/s, Mbit/s, Gbit/s, etc.).</p>

<p>Bandwidth sometimes defines the net bit rate (aka. peak bit rate, information rate, or physical layer useful bit rate), channel capacity, or the maximum throughput of a logical or physical communication path in a digital communication system. For example, bandwidth tests measure the maximum throughput of a computer network. The reason for this usage is that according to Hartley's law, the maximum data rate of a physical communication link is proportional to its bandwidth in hertz, which is sometimes called frequency bandwidth, spectral bandwidth, RF bandwidth, signal bandwidth or analog bandwidth.</p>
<h3 id="throughput">Throughput</h3>

<p>In general terms, throughput is the rate of production or the rate at which something can be processed.</p>

<p>In communication networks, throughput is essentially synonymous to digital bandwidth consumption. In <a href="wireless_network" title="wikilink">wireless networks</a> or <a href="cellular_system" title="wikilink">cellular systems</a>, the <a href="system_spectral_efficiency" title="wikilink">system spectral efficiency</a> in bit/s/Hz/area unit, bit/s/Hz/site or bit/s/Hz/cell, is the maximum system throughput (aggregate throughput) divided by the analog bandwidth and some measure of the system coverage area.</p>

<p>In integrated circuits, often a block in a <a href="data_flow_diagram" title="wikilink">data flow diagram</a> has a single input and a single output, and operate on discrete packets of information. Examples of such blocks are <a href="Fast_Fourier_transform" title="wikilink">FFT</a> modules or <a href="binary_multiplier" title="wikilink">binary multipliers</a>. Because the units of throughput are the reciprocal of the unit for <a href="propagation_delay" title="wikilink">propagation delay</a>, which is 'seconds per message' or 'seconds per output', throughput can be used to relate a computational device performing a dedicated function such as an <a class="uri" href="ASIC" title="wikilink">ASIC</a> or <a href="embedded_processor" title="wikilink">embedded processor</a> to a communications channel, simplifying system analysis.</p>
<h3 id="relative-efficiency">Relative efficiency</h3>
<h3 id="scalability">Scalability</h3>

<p>Scalability is the ability of a system, network, or process to handle a growing amount of work in a capable manner or its ability to be enlarged to accommodate that growth</p>
<h3 id="power-consumption">Power consumption</h3>

<p>The amount of electricity used by the computer. This becomes especially important for systems with limited power sources such as solar, batteries, human power.</p>
<h4 id="performance-per-watt">Performance per watt</h4>

<p>System designers building <a href="parallel_computing" title="wikilink">parallel computers</a>, such as <a href="Google_search_technology#Production_hardware" title="wikilink">Google's hardware</a>, pick CPUs based on their speed per watt of power, because the cost of powering the CPU outweighs the cost of the CPU itself.<a class="footnoteRef" href="#fn7" id="fnref7"><sup>7</sup></a></p>
<h3 id="compression-ratio">Compression ratio</h3>

<p>Compression is useful because it helps reduce resource usage, such as data storage space or transmission capacity. Because compressed data must be decompressed to use, this extra processing imposes computational or other costs through decompression; this situation is far from being a free lunch. Data compression is subject to a space–time complexity trade-off.</p>
<h3 id="size-and-weight">Size and weight</h3>

<p>This is an important performance feature of mobile systems, from the smart phones you keep in your pocket to the portable embedded systems in a spacecraft.</p>
<h3 id="environmental-impact">Environmental impact</h3>

<p>The effect of a computer or computers on the environment, during manufacturing and recycling as well as during use. Measurements are taken with the objectives of reducing waste, reducing hazardous materials, and minimizing a computer's <a href="ecological_footprint" title="wikilink">ecological footprint</a>.</p>
<h2 id="benchmarks">Benchmarks</h2>

<p>Because there are so many programs to test a CPU on all aspects of performance, <a href="benchmark_(computing)" title="wikilink">benchmarks</a> were developed.</p>

<p>The most famous benchmarks are the SPECint and <a class="uri" href="SPECfp" title="wikilink">SPECfp</a> benchmarks developed by <a href="Standard_Performance_Evaluation_Corporation" title="wikilink">Standard Performance Evaluation Corporation</a> and the <a class="uri" href="ConsumerMark" title="wikilink">ConsumerMark</a> benchmark developed by the Embedded Microprocessor Benchmark Consortium <a class="uri" href="EEMBC" title="wikilink">EEMBC</a>.</p>
<h2 id="software-performance-testing">Software performance testing</h2>

<p>In software engineering, performance testing is in general testing performed to determine how a system performs in terms of responsiveness and stability under a particular workload. It can also serve to investigate, measure, validate or verify other quality attributes of the system, such as scalability, reliability and resource usage.</p>

<p>Performance testing is a subset of performance engineering, an emerging computer science practice which strives to build performance into the implementation, design and architecture of a system.</p>
<h3 id="profiling-performance-analysis">Profiling (performance analysis)</h3>

<p>In <a href="software_engineering" title="wikilink">software engineering</a>, profiling ("program profiling", "software profiling") is a form of <a href="dynamic_program_analysis" title="wikilink">dynamic program analysis</a> that measures, for example, the space (memory) or time <a href="Computational_complexity_theory" title="wikilink">complexity of a program</a>, the <a href="instruction_set_simulator" title="wikilink">usage of particular instructions</a>, or frequency and duration of function calls. The most common use of profiling information is to aid program <a href="optimization_(computer_science)" title="wikilink">optimization</a>.</p>

<p>Profiling is achieved by instrumenting either the program <a href="source_code" title="wikilink">source code</a> or its binary executable form using a tool called a <em>profiler</em> (or <em>code profiler</em>). A number of different techniques may be used by profilers, such as event-based, statistical, instrumented, and simulation methods.</p>
<h2 id="performance-tuning">Performance tuning</h2>

<p>Performance tuning is the improvement of <a class="uri" href="system" title="wikilink">system</a> performance. This is typically a computer application, but the same methods can be applied to economic markets, bureaucracies or other complex systems. The motivation for such activity is called a performance problem, which can be real or anticipated. Most systems will respond to increased <a href="Load_(computing)" title="wikilink">load</a> with some degree of decreasing performance. A system's ability to accept a higher load is called <a class="uri" href="scalability" title="wikilink">scalability</a>, and modifying a system to handle a higher load is synonymous to performance tuning.</p>

<p>Systematic tuning follows these steps:</p>
<ol>
<li>Assess the problem and establish numeric values that categorize acceptable behavior.</li>
<li>Measure the performance of the system before modification.</li>
<li>Identify the part of the system that is critical for improving the performance. This is called the <a href="bottleneck_(software)" title="wikilink">bottleneck</a>.</li>
<li>Modify that part of the system to remove the bottleneck.</li>
<li>Measure the performance of the system after modification.</li>
<li>If the modification makes the performance better, adopt it. If the modification makes the performance worse, put it back to the way it was.</li>
</ol>
<h2 id="perceived-performance">Perceived performance</h2>

<p>Perceived performance, in computer engineering, refers to how quickly a software feature appears to perform its task. The concept applies mainly to user acceptance aspects.</p>

<p>The amount of time an application takes to start up, or a file to download, is not made faster by showing a startup screen (see Splash screen) or a file progress dialog box. However, it satisfies some human needs: it appears faster to the user as well as providing a visual cue to let them know the system is handling their request.</p>

<p>In most cases, increasing real performance increases perceived performance, but when real performance cannot be increased due to physical limitations, techniques can be used to increase perceived performance at the cost of marginally decreasing real performance.</p>
<h2 id="performance-equation">Performance Equation</h2>

<p>The total amount of time (<strong>t</strong>) required to execute a particular benchmark program is</p>
<dl>
<dd><strong>

<math display="inline" id="Computer_performance:0">
 <semantics>
  <mrow>
   <mi>t</mi>
   <mo>=</mo>
   <mrow>
    <mrow>
     <mi>N</mi>
     <mo>*</mo>
     <mi>C</mi>
    </mrow>
    <mo>/</mo>
    <mi>f</mi>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <ci>t</ci>
    <apply>
     <divide></divide>
     <apply>
      <times></times>
      <ci>N</ci>
      <ci>C</ci>
     </apply>
     <ci>f</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   t=N*C/f
  </annotation>
 </semantics>
</math>

</strong> , or equivalently
</dd>
<dd><strong>

<math display="inline" id="Computer_performance:1">
 <semantics>
  <mrow>
   <mi>P</mi>
   <mo>=</mo>
   <mrow>
    <mrow>
     <mi>I</mi>
     <mo>*</mo>
     <mi>f</mi>
    </mrow>
    <mo>/</mo>
    <mi>N</mi>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <ci>P</ci>
    <apply>
     <divide></divide>
     <apply>
      <times></times>
      <ci>I</ci>
      <ci>f</ci>
     </apply>
     <ci>N</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   P=I*f/N
  </annotation>
 </semantics>
</math>

</strong><ref name="shrinking">
</ref></dd>
</dl>

<p>Paul DeMone. "The Incredible Shrinking CPU". 2004. [<a class="uri" href="http://www.realworldtech.com/page.cfm?ArticleID=RWT062004172947&amp;p">http://www.realworldtech.com/page.cfm?ArticleID=RWT062004172947&amp;p;</a>;=5] </p>

<p>where</p>
<ul>
<li><strong>P</strong> = 1/t is "the performance" in terms of time-to-execute</li>
<li><strong>N</strong> is the number of instructions actually executed (the <a href="instruction_path_length" title="wikilink">instruction path length</a>). The <a href="instruction_set#Code_density" title="wikilink">code density</a> of the <a href="instruction_set" title="wikilink">instruction set</a> strongly affects N. The value of N can either be determined <strong>exactly</strong> by using an <a href="instruction_set_simulator" title="wikilink">instruction set simulator</a> (if available) or by estimation—itself based partly on estimated or actual frequency distribution of input variables and by examining generated <a href="machine_code" title="wikilink">machine code</a> from an <a href="High-level_programming_language" title="wikilink">HLL</a> compiler. It cannot be determined from the number of lines of HLL source code. N is not affected by other processes running on the same processor. The significant point here is that hardware normally does not keep track of (or at least make easily available) a value of N for executed programs. The value can therefore only be accurately determined by instruction set simulation, which is rarely practiced.</li>
</ul>
<ul>
<li><strong>f</strong> is the clock frequency in cycles per second.</li>
</ul>
<ul>
<li><strong>C</strong>=

<math display="inline" id="Computer_performance:2">
 <semantics>
  <mrow>
   <mn>1</mn>
   <mo>/</mo>
   <mi>I</mi>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <divide></divide>
    <cn type="integer">1</cn>
    <ci>I</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   1/I
  </annotation>
 </semantics>
</math>

 is the average <a href="cycles_per_instruction" title="wikilink">cycles per instruction</a> (CPI) for this benchmark.</li>
<li><strong>I</strong>=

<math display="inline" id="Computer_performance:3">
 <semantics>
  <mrow>
   <mn>1</mn>
   <mo>/</mo>
   <mi>C</mi>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <divide></divide>
    <cn type="integer">1</cn>
    <ci>C</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   1/C
  </annotation>
 </semantics>
</math>

 is the average <a href="instructions_per_cycle" title="wikilink">instructions per cycle</a> (IPC) for this benchmark.</li>
</ul>

<p>Even on one machine, a different compiler or the same compiler with different <a href="compiler_optimization" title="wikilink">compiler optimization</a> switches can change N and CPI—the benchmark executes faster if the new compiler can improve N or C without making the other worse, but often there is a trade-off between them—is it better, for example, to use a few complicated instructions that take a long time to execute, or to use instructions that execute very quickly, although it takes more of them to execute the benchmark?</p>

<p>A CPU designer is often required to implement a particular <a href="instruction_set" title="wikilink">instruction set</a>, and so cannot change N. Sometimes a designer focuses on improving performance by making significant improvements in f (with techniques such as deeper pipelines and faster caches), while (hopefully) not sacrificing too much C—leading to a <a class="uri" href="speed-demon" title="wikilink">speed-demon</a> CPU design. Sometimes a designer focuses on improving performance by making significant improvements in CPI (with techniques such as <a href="out-of-order_execution" title="wikilink">out-of-order execution</a>, <a class="uri" href="superscalar" title="wikilink">superscalar</a> CPUs, larger caches, caches with improved hit rates, improved branch prediction, <a href="speculative_execution" title="wikilink">speculative execution</a>, etc.), while (hopefully) not sacrificing too much clock frequency—leading to a brainiac CPU design.<a class="footnoteRef" href="#fn8" id="fnref8"><sup>8</sup></a> For a given instruction set (and therefore fixed N) and semiconductor process, the maximum single-thread performance (1/t) requires a balance between brainiac techniques and speedracer techniques.<a class="footnoteRef" href="#fn9" id="fnref9"><sup>9</sup></a></p>
<h2 id="see-also">See also</h2>
<ul>
<li><a href="Algorithmic_efficiency" title="wikilink">Algorithmic efficiency</a></li>
<li><a href="Computer_performance_by_orders_of_magnitude" title="wikilink">Computer performance by orders of magnitude</a></li>
<li><a href="Network_performance" title="wikilink">Network performance</a></li>
<li><a href="Optimization_(computer_science)" title="wikilink">Optimization (computer science)</a></li>
<li><a href="RAM_update_rate" title="wikilink">RAM update rate</a></li>
<li>Complete <a href="instruction_set" title="wikilink">instruction set</a></li>
</ul>
<h2 id="references">References</h2>
<references>
</references>

<p>"</p>

<p><a href="Category:Computer_performance" title="wikilink"> </a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1">Computer Performance Analysis with Mathematica by Arnold O. Allen, Academic Press, 1994. <em>$1.1 Introduction, pg 1.</em><a href="#fnref1">↩</a></li>
<li id="fn2"><a href="#fnref2">↩</a></li>
<li id="fn3"><a href="#fnref3">↩</a></li>
<li id="fn4"><a href="#fnref4">↩</a></li>
<li id="fn5"><a href="#fnref5">↩</a></li>
<li id="fn6"><a href="#fnref6">↩</a></li>
<li id="fn7"><a href="http://www.eembc.org/benchmark/consumer.asp?HTYPE=SIM">1</a><a href="http://news.cnet.com/Power+could+cost+more+than+servers,+Google+warns/2100-1010_3-5988090.html">2</a><a href="#fnref7">↩</a></li>
<li id="fn8"><a href="http://www.mdronline.com/mpr_public/editorials/edit13_17.html">"Brainiacs, Speed Demons, and Farewell"</a> by Linley Gwennap 1999<a href="#fnref8">↩</a></li>
<li id="fn9"></li>
</ol>
</section>
</body>
</html>
