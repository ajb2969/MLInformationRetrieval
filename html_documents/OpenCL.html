<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="667">OpenCL</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>OpenCL</h1>
<style>
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
<style>
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
  </style>
</body></html>
<body>
<hr/>

<p><strong>Open Computing Language</strong> (<strong>OpenCL</strong>) is a <a href="software_framework" title="wikilink">framework</a> for writing programs that execute across <a href="heterogeneous_computing" title="wikilink">heterogeneous</a> platforms consisting of <a href="central_processing_unit" title="wikilink">central processing units</a> (CPUs), <a href="graphics_processing_unit" title="wikilink">graphics processing units</a> (GPUs), digital signal processors (<a href="digital_signal_processor" title="wikilink">DSPs</a>), <a href="field-programmable_gate_array" title="wikilink">field-programmable gate arrays</a> (FPGAs) and other processors. OpenCL specifies a language (based on <a class="uri" href="C99" title="wikilink">C99</a>) for programming these devices and <a href="application_programming_interface" title="wikilink">application programming interfaces</a> (APIs) to control the platform and execute programs on the compute devices. OpenCL provides <a href="parallel_computing" title="wikilink">parallel computing</a> using task-based and data-based parallelism. OpenCL is an open standard maintained by the <a href="Non-profit_organization" title="wikilink">non-profit</a> technology consortium <a href="Khronos_Group" title="wikilink">Khronos Group</a>. Conformant implementations are available from <a class="uri" href="Altera" title="wikilink">Altera</a>, <a href="Advanced_Micro_Devices" title="wikilink">AMD</a>, <a href="Apple_Inc" title="wikilink">Apple</a>, <a href="ARM_Holdings" title="wikilink">ARM Holdings</a>, <a href="Creative_Technology" title="wikilink">Creative Technology</a>, <a class="uri" href="IBM" title="wikilink">IBM</a>, <a href="Imagination_Technologies" title="wikilink">Imagination Technologies</a>, <a class="uri" href="Intel" title="wikilink">Intel</a>, <a class="uri" href="Nvidia" title="wikilink">Nvidia</a>, <a class="uri" href="Qualcomm" title="wikilink">Qualcomm</a>, <a class="uri" href="Samsung" title="wikilink">Samsung</a>, <a class="uri" href="Vivante" title="wikilink">Vivante</a>, <a class="uri" href="Xilinx" title="wikilink">Xilinx</a>, and <a class="uri" href="ZiiLABS" title="wikilink">ZiiLABS</a>.<a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a><a class="footnoteRef" href="#fn2" id="fnref2"><sup>2</sup></a></p>
<h2 id="overview">Overview</h2>

<p>OpenCL views a computing system as consisting of a number of <em>compute devices</em>, which might be <a href="central_processing_unit" title="wikilink">central processing units</a> (CPUs) or "accelerators" such as graphics processing units (GPUs), attached to a <em>host</em> processor (a CPU). It defines a <a href="#OpenCL_C_language" title="wikilink">C-like language</a> for writing programs, called <em>kernels</em>, that execute on the compute devices. A single compute device typically consists of several <em>compute units</em>, which in turn comprise multiple <em>processing elements</em> (PEs). A single kernel execution can run on all or many of the PEs in parallel. How a compute device is subdivided into compute units and PEs is up to the vendor; a compute unit can be thought of as a "<a href="Processor_core" title="wikilink">core</a>", but the notion of core is hard to define across all the types of devices supported by OpenCL (or even within the category of "CPUs"), and the number of compute units may not correspond to the number of cores claimed in vendors' marketing literature (which may actually be counting <a href="SIMD_lane" title="wikilink">SIMD lanes</a>).<a class="footnoteRef" href="#fn3" id="fnref3"><sup>3</sup></a></p>

<p>In addition to its C-like programming language, OpenCL defines an <a href="application_programming_interface" title="wikilink">application programming interface</a> (API) that allows programs running on the host to launch kernels on the compute devices and manage device memory, which is (at least conceptually) separate from host memory. Programs in the OpenCL language are intended to be <a href="just-in-time_compilation" title="wikilink">compiled at run-time</a>, so that OpenCL-using applications are portable between implementations for various host devices.<a class="footnoteRef" href="#fn4" id="fnref4"><sup>4</sup></a> The OpenCL standard defines host APIs for <a href="C_(programming_language)" title="wikilink">C</a> and <a class="uri" href="C++" title="wikilink">C++</a>; third-party APIs exist for other programming languages such as <a href="Python_(programming_language)" title="wikilink">Python</a>,<a class="footnoteRef" href="#fn5" id="fnref5"><sup>5</sup></a> <a href="Java_(programming_language)" title="wikilink">Java</a> and <a href=".NET_Framework" title="wikilink">.NET</a>.<a class="footnoteRef" href="#fn6" id="fnref6"><sup>6</sup></a> An <a href="#Implementation" title="wikilink">implementation</a> of the OpenCL standard consists of a <a href="library_(computing)" title="wikilink">library</a> that implements the API for C and C++, and an OpenCL C <a class="uri" href="compiler" title="wikilink">compiler</a> for the compute device(s) targeted.</p>
<h3 id="memory-hierarchy">Memory hierarchy</h3>

<p>OpenCL defines a four-level <a href="memory_hierarchy" title="wikilink">memory hierarchy</a> for the compute device:<a class="footnoteRef" href="#fn7" id="fnref7"><sup>7</sup></a></p>
<ul>
<li>global memory: shared by all processing elements, but has high access latency;</li>
<li>read-only memory: smaller, low latency, writable by the host CPU but not the compute devices;</li>
<li>local memory: shared by a group of processing elements;</li>
<li>per-element private memory (<a href="Processor_register" title="wikilink">registers</a>).</li>
</ul>

<p>Not every device needs to implement each level of this hierarchy in hardware. <a href="Consistency_model" title="wikilink">Consistency</a> between the various levels in the hierarchy is relaxed, and only enforced by explicit <a href="Synchronization_(computer_science)" title="wikilink">synchronization</a> constructs, notably <a href="Memory_barrier" title="wikilink">barriers</a>.</p>

<p>Devices may or may not share memory with the host CPU.<a class="footnoteRef" href="#fn8" id="fnref8"><sup>8</sup></a> The host API provides <a href="Handle_(computing)" title="wikilink">handles</a> on device memory buffers and functions to transfer data back and forth between host and devices.</p>
<h2 id="opencl-c-language">OpenCL C language</h2>

<p>The programming language used to write computation kernels is called OpenCL C and is based on <a class="uri" href="C99" title="wikilink">C99</a>,<a class="footnoteRef" href="#fn9" id="fnref9"><sup>9</sup></a> but adapted to fit the device model in OpenCL. Memory buffers reside in specific levels of the <a href="#Memory_hierarchy" title="wikilink">memory hierarchy</a>, and <a href="Pointer_(computer_programming)" title="wikilink">pointers</a> are annotated with the region qualifiers , , , and , reflecting this. Instead of a device program having a  function, OpenCL C functions are marked  to signal that they are <a href="entry_point" title="wikilink">entry points</a> into the program to be called from the host program. <a href="Function_pointer" title="wikilink">Function pointers</a>, <a href="bit_field" title="wikilink">bit fields</a> and <a href="variable-length_array" title="wikilink">variable-length arrays</a> are omitted, <a href="recursion_(computer_science)" title="wikilink">recursion</a> is forbidden.<a class="footnoteRef" href="#fn10" id="fnref10"><sup>10</sup></a> The <a href="C_standard_library" title="wikilink">C standard library</a> is replaced by a custom set of standard functions, geared toward math programming.</p>

<p>OpenCL C is extended to facilitate use of <a href="parallel_computing" title="wikilink">parallelism</a> with vector types and operations, synchronization, and functions to work with work-items and work-groups.<a class="footnoteRef" href="#fn11" id="fnref11"><sup>11</sup></a> In particular, besides scalar types such as  and , which behave similarly to the corresponding types in C, OpenCL provides fixed-length vector types such as  (4-vector of single-precision floats); such vector types are available in lengths two, three, four, eight and sixteen for various base types.<a class="footnoteRef" href="#fn12" id="fnref12"><sup>12</sup></a> <a href="Array_programming" title="wikilink">Vectorized</a> operations on these types are intended to map onto SIMD instructions sets, e.g., <a href="Streaming_SIMD_Extensions" title="wikilink">SSE</a> or <a href="AltiVec" title="wikilink">VMX</a> when running OpenCL programs on CPUs.<a class="footnoteRef" href="#fn13" id="fnref13"><sup>13</sup></a> Other specialized types include 2-d and 3-d image types.</p>
<h3 id="example-matrix-vector-multiplication">Example: matrix-vector multiplication</h3>

<p> The following is an <a href="matrix-vector_multiplication" title="wikilink">matrix-vector multiplication</a> algorithm in OpenCL C.</p>
<div class="sourceCode"><pre class="sourceCode c"><code class="sourceCode c"><span class="co">// Multiplies A*x, leaving the result in y.</span>
<span class="co">// A is a row-major matrix, meaning the (i,j) element is at A[i*ncols+j].</span>
__kernel <span class="dt">void</span> matvec(__global <span class="dt">const</span> <span class="dt">float</span> *A, __global <span class="dt">const</span> <span class="dt">float</span> *x,
                     uint ncols, __global <span class="dt">float</span> *y)
{
    size_t i = get_global_id(<span class="dv">0</span>);              <span class="co">// Global id, used as the row index.</span>
    __global <span class="dt">float</span> <span class="dt">const</span> *a = &amp;A;[i*ncols];    <span class="co">// Pointer to the i'th row.</span>
    <span class="dt">float</span> sum = <span class="fl">0.f</span>;                          <span class="co">// Accumulator for dot product.</span>
    <span class="kw">for</span> (size_t j = <span class="dv">0</span>; j &lt; ncols; j++) {
        sum += a[j] * x[j];
    }
    y[i] = sum;
}</code></pre></div>

<p>The kernel function  computes, in each invocation, the <a href="dot_product" title="wikilink">dot product</a> of a single row of a matrix 

<math display="inline" id="OpenCL:0">
 <semantics>
  <mi>A</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>A</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   A
  </annotation>
 </semantics>
</math>

 and a vector 

<math display="inline" id="OpenCL:1">
 <semantics>
  <mi>x</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>x</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   x
  </annotation>
 </semantics>
</math>

:</p>

<p>

<math display="block" id="OpenCL:2">
 <semantics>
  <mrow>
   <msub>
    <mi>y</mi>
    <mi>i</mi>
   </msub>
   <mo>=</mo>
   <mrow>
    <msub>
     <mi>a</mi>
     <mrow>
      <mi>i</mi>
      <mo>,</mo>
      <mo>:</mo>
     </mrow>
    </msub>
    <mo>⋅</mo>
    <mi>x</mi>
   </mrow>
   <mo>=</mo>
   <mrow>
    <munder>
     <mo largeop="true" movablelimits="false" symmetric="true">∑</mo>
     <mi>j</mi>
    </munder>
    <mrow>
     <msub>
      <mi>a</mi>
      <mrow>
       <mi>i</mi>
       <mo>,</mo>
       <mi>j</mi>
      </mrow>
     </msub>
     <msub>
      <mi>x</mi>
      <mi>j</mi>
     </msub>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <and></and>
    <apply>
     <eq></eq>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>y</ci>
      <ci>i</ci>
     </apply>
     <apply>
      <ci>normal-⋅</ci>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>a</ci>
       <list>
        <ci>i</ci>
        <ci>normal-:</ci>
       </list>
      </apply>
      <ci>x</ci>
     </apply>
    </apply>
    <apply>
     <eq></eq>
     <share href="#.cmml">
     </share>
     <apply>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <sum></sum>
       <ci>j</ci>
      </apply>
      <apply>
       <times></times>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <ci>a</ci>
        <list>
         <ci>i</ci>
         <ci>j</ci>
        </list>
       </apply>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <ci>x</ci>
        <ci>j</ci>
       </apply>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   y_{i}=a_{i,:}\cdot x=\sum_{j}a_{i,j}x_{j}
  </annotation>
 </semantics>
</math>

.</p>

<p>To extend this into a full matrix-vector multiplication, the OpenCL runtime <a href="Map_(parallel_pattern)" title="wikilink">maps</a> the kernel over the rows of the matrix. On the host side, the  function does this; it takes as arguments the kernel to execute, its arguments, and a number of work-items, corresponding to the number of rows in the matrix 

<math display="inline" id="OpenCL:3">
 <semantics>
  <mi>A</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>A</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   A
  </annotation>
 </semantics>
</math>

.</p>
<h3 id="example-computing-the-fft">Example: computing the FFT</h3>

<p>This example will load a <a href="fast_Fourier_transform" title="wikilink">fast Fourier transform</a> (FFT) implementation and execute it. The implementation is shown below.<a class="footnoteRef" href="#fn14" id="fnref14"><sup>14</sup></a></p>
<div class="sourceCode"><pre class="sourceCode c"><code class="sourceCode c">  <span class="co">// create a compute context with GPU device</span>
  context = clCreateContextFromType(NULL, CL_DEVICE_TYPE_GPU, NULL, NULL, NULL);

  <span class="co">// create a command queue</span>
  clGetDeviceIDs( NULL, CL_DEVICE_TYPE_DEFAULT, <span class="dv">1</span>, &amp;device;_id, NULL );
  queue = clCreateCommandQueue(context, device_id, <span class="dv">0</span>, NULL);

  <span class="co">// allocate the buffer memory objects</span>
  memobjs[<span class="dv">0</span>] = clCreateBuffer(context, CL_MEM_READ_ONLY | CL_MEM_COPY_HOST_PTR, <span class="kw">sizeof</span>(<span class="dt">float</span>)*<span class="dv">2</span>*num_entries, srcA, NULL);
  memobjs[<span class="dv">1</span>] = clCreateBuffer(context, CL_MEM_READ_WRITE, <span class="kw">sizeof</span>(<span class="dt">float</span>)*<span class="dv">2</span>*num_entries, NULL, NULL);

  <span class="co">// create the compute program</span>
  program = clCreateProgramWithSource(context, <span class="dv">1</span>, &amp;fft1D;_1024_kernel_src, NULL, NULL);

  <span class="co">// build the compute program executable</span>
  clBuildProgram(program, <span class="dv">0</span>, NULL, NULL, NULL, NULL);

  <span class="co">// create the compute kernel</span>
  kernel = clCreateKernel(program, <span class="st">"fft1D_1024"</span>, NULL);

  <span class="co">// set the args values</span>
  clSetKernelArg(kernel, <span class="dv">0</span>, <span class="kw">sizeof</span>(cl_mem), (<span class="dt">void</span> *)&amp;memobjs;[<span class="dv">0</span>]);
  clSetKernelArg(kernel, <span class="dv">1</span>, <span class="kw">sizeof</span>(cl_mem), (<span class="dt">void</span> *)&amp;memobjs;[<span class="dv">1</span>]);
  clSetKernelArg(kernel, <span class="dv">2</span>, <span class="kw">sizeof</span>(<span class="dt">float</span>)*(local_work_size[<span class="dv">0</span>]+<span class="dv">1</span>)*<span class="dv">16</span>, NULL);
  clSetKernelArg(kernel, <span class="dv">3</span>, <span class="kw">sizeof</span>(<span class="dt">float</span>)*(local_work_size[<span class="dv">0</span>]+<span class="dv">1</span>)*<span class="dv">16</span>, NULL);

  <span class="co">// create N-D range object with work-item dimensions and execute kernel</span>
  global_work_size[<span class="dv">0</span>] = num_entries;
  local_work_size[<span class="dv">0</span>] = <span class="dv">64</span>; <span class="co">//Nvidia: 192 or 256</span>
  clEnqueueNDRangeKernel(queue, kernel, <span class="dv">1</span>, NULL, global_work_size, local_work_size, <span class="dv">0</span>, NULL, NULL);</code></pre></div>

<p>The actual calculation (based on <a href="http://www.cs.berkeley.edu/~kubitron/courses/cs258-S08/projects/reports/project6_report.pdf">Fitting FFT onto the G80 Architecture</a>):<a class="footnoteRef" href="#fn15" id="fnref15"><sup>15</sup></a></p>
<div class="sourceCode"><pre class="sourceCode c"><code class="sourceCode c">  <span class="co">// This kernel computes FFT of length 1024. The 1024 length FFT is decomposed into</span>
  <span class="co">// calls to a radix 16 function, another radix 16 function and then a radix 4 function</span>

  __kernel <span class="dt">void</span> fft1D_1024 (__global float2 *in, __global float2 *out,
                          __local <span class="dt">float</span> *sMemx, __local <span class="dt">float</span> *sMemy) {
    <span class="dt">int</span> tid = get_local_id(<span class="dv">0</span>);
    <span class="dt">int</span> blockIdx = get_group_id(<span class="dv">0</span>) * <span class="dv">1024</span> + tid;
    float2 data[<span class="dv">16</span>];

    <span class="co">// starting index of data to/from global memory</span>
    in = in + blockIdx;  out = out + blockIdx;

    globalLoads(data, in, <span class="dv">64</span>); <span class="co">// coalesced global reads</span>
    fftRadix16Pass(data);      <span class="co">// in-place radix-16 pass</span>
    twiddleFactorMul(data, tid, <span class="dv">1024</span>, <span class="dv">0</span>);

    <span class="co">// local shuffle using local memory</span>
    localShuffle(data, sMemx, sMemy, tid, (((tid &amp; <span class="dv">15</span>) * <span class="dv">65</span>) + (tid &gt;&gt; <span class="dv">4</span>)));
    fftRadix16Pass(data);               <span class="co">// in-place radix-16 pass</span>
    twiddleFactorMul(data, tid, <span class="dv">64</span>, <span class="dv">4</span>); <span class="co">// twiddle factor multiplication</span>

    localShuffle(data, sMemx, sMemy, tid, (((tid &gt;&gt; <span class="dv">4</span>) * <span class="dv">64</span>) + (tid &amp; <span class="dv">15</span>)));

    <span class="co">// four radix-4 function calls</span>
    fftRadix4Pass(data);      <span class="co">// radix-4 function number 1</span>
    fftRadix4Pass(data + <span class="dv">4</span>);  <span class="co">// radix-4 function number 2</span>
    fftRadix4Pass(data + <span class="dv">8</span>);  <span class="co">// radix-4 function number 3</span>
    fftRadix4Pass(data + <span class="dv">12</span>); <span class="co">// radix-4 function number 4</span>

    <span class="co">// coalesced global writes</span>
    globalStores(data, out, <span class="dv">64</span>);
  }</code></pre></div>

<p>A full, open source implementation of an OpenCL FFT can be found on Apple's website.<a class="footnoteRef" href="#fn16" id="fnref16"><sup>16</sup></a></p>
<h2 id="history">History</h2>

<p>OpenCL was initially developed by <a href="Apple_Inc." title="wikilink">Apple Inc.</a>, which holds <a class="uri" href="trademark" title="wikilink">trademark</a> rights, and refined into an initial proposal in collaboration with technical teams at <a href="Advanced_Micro_Devices" title="wikilink">AMD</a>, <a class="uri" href="IBM" title="wikilink">IBM</a>, <a class="uri" href="Qualcomm" title="wikilink">Qualcomm</a>, <a href="Intel_Corporation" title="wikilink">Intel</a>, and <a class="uri" href="Nvidia" title="wikilink">Nvidia</a>. Apple submitted this initial proposal to the <a href="Khronos_Group" title="wikilink">Khronos Group</a>. On June 16, 2008, the Khronos Compute Working Group was formed<a class="footnoteRef" href="#fn17" id="fnref17"><sup>17</sup></a> with representatives from CPU, GPU, embedded-processor, and software companies. This group worked for five months to finish the technical details of the specification for OpenCL 1.0 by November 18, 2008.<a class="footnoteRef" href="#fn18" id="fnref18"><sup>18</sup></a> This technical specification was reviewed by the Khronos members and approved for public release on December 8, 2008.<a class="footnoteRef" href="#fn19" id="fnref19"><sup>19</sup></a></p>
<h3 id="opencl-1.0">OpenCL 1.0</h3>

<p>OpenCL 1.0 released with <a href="Mac_OS_X_Snow_Leopard" title="wikilink">Mac OS X Snow Leopard</a> on August 28, 2009. According to an Apple press release:<a class="footnoteRef" href="#fn20" id="fnref20"><sup>20</sup></a></p>
<blockquote>

<p>Snow Leopard further extends support for modern hardware with Open Computing Language (OpenCL), which lets any application tap into the vast gigaflops of GPU computing power previously available only to graphics applications. OpenCL is based on the C programming language and has been proposed as an open standard.</p>
</blockquote>

<p>AMD decided to support OpenCL instead of the now deprecated <a href="Close_to_Metal" title="wikilink">Close to Metal</a> in its <a href="AMD_Stream_SDK" title="wikilink">Stream framework</a>.<a class="footnoteRef" href="#fn21" id="fnref21"><sup>21</sup></a><a class="footnoteRef" href="#fn22" id="fnref22"><sup>22</sup></a> <a class="uri" href="RapidMind" title="wikilink">RapidMind</a> announced their adoption of OpenCL underneath their development platform to support GPUs from multiple vendors with one interface.<a class="footnoteRef" href="#fn23" id="fnref23"><sup>23</sup></a> On December 9, 2008, Nvidia announced its intention to add full support for the OpenCL 1.0 specification to its GPU Computing Toolkit.<a class="footnoteRef" href="#fn24" id="fnref24"><sup>24</sup></a> On October 30, 2009, IBM released its first OpenCL implementation as a part of the <a href="XL_compilers" title="wikilink">XL compilers</a>.<a class="footnoteRef" href="#fn25" id="fnref25"><sup>25</sup></a></p>
<h3 id="opencl-1.1">OpenCL 1.1</h3>

<p>OpenCL 1.1 was ratified by the Khronos Group on June 14, 2010<a class="footnoteRef" href="#fn26" id="fnref26"><sup>26</sup></a> and adds significant functionality for enhanced parallel programming flexibility, functionality, and performance including:</p>
<ul>
<li>New data types including 3-component vectors and additional image formats;</li>
<li>Handling commands from multiple host threads and processing buffers across multiple devices;</li>
<li>Operations on regions of a buffer including read, write and copy of 1D, 2D, or 3D rectangular regions;</li>
<li>Enhanced use of events to drive and control command execution;</li>
<li>Additional OpenCL built-in C functions such as integer clamp, shuffle, and asynchronous strided copies;</li>
<li>Improved OpenGL interoperability through efficient sharing of images and buffers by linking OpenCL and OpenGL events.</li>
</ul>
<h3 id="opencl-1.2">OpenCL 1.2</h3>

<p>On November 15, 2011, the Khronos Group announced the OpenCL 1.2 specification,<a class="footnoteRef" href="#fn27" id="fnref27"><sup>27</sup></a> which added significant functionality over the previous versions in terms of performance and features for parallel programming. Most notable features include:</p>
<ul>
<li>Device partitioning: the ability to partition a device into sub-devices so that work assignments can be allocated to individual compute units. This is useful for reserving areas of the device to reduce latency for time-critical tasks.</li>
<li>Separate compilation and linking of objects: the functionality to compile OpenCL into external libraries for inclusion into other programs.</li>
<li>Enhanced image support: 1.2 adds support for 1D images and 1D/2D image arrays. Furthermore, the OpenGL sharing extensions now allow for OpenGL 1D textures and 1D/2D texture arrays to be used to create OpenCL images.</li>
<li>Built-in kernels: custom devices that contain specific unique functionality are now integrated more closely into the OpenCL framework. Kernels can be called to use specialised or non-programmable aspects of underlying hardware. Examples include video encoding/decoding and digital signal processors.</li>
<li>DirectX functionality: DX9 media surface sharing allows for efficient sharing between OpenCL and DX9 or <a href="DirectX_Video_Acceleration" title="wikilink">DXVA</a> media surfaces. Equally, for DX11, seamless sharing between OpenCL and DX11 surfaces is enabled.</li>
<li>The ability to force <a href="IEEE_floating_point" title="wikilink">IEEE 754</a> compliance for single precision floating point math: OpenCL by default allows the single precision versions of the division, reciprocal, and square root operation to be less accurate than the correctly rounded values that IEEE 754 requires.<a class="footnoteRef" href="#fn28" id="fnref28"><sup>28</sup></a> If the programmer passes the "-cl-fp32-correctly-rounded-divide-sqrt" command line argument to the compiler, these three operations will be computed to IEEE 754 requirements if the OpenCL implementation supports this, and will fail to compile if the OpenCL implementation does not support computing these operations to their correctly-rounded values as defined by the IEEE 754 specification.<a class="footnoteRef" href="#fn29" id="fnref29"><sup>29</sup></a> This ability is supplemented by the ability to query the OpenCL implementation to determine if it can perform these operations to IEEE 754 accuracy.<a class="footnoteRef" href="#fn30" id="fnref30"><sup>30</sup></a></li>
</ul>
<h3 id="opencl-2.0">OpenCL 2.0</h3>

<p>On November 18, 2013, the Khronos Group announced the ratification and public release of the finalized OpenCL 2.0 specification.<a class="footnoteRef" href="#fn31" id="fnref31"><sup>31</sup></a> Updates and additions to OpenCL 2.0 include:</p>
<ul>
<li>Shared virtual memory</li>
<li>Nested parallelism</li>
<li>Generic address space</li>
<li>Images</li>
<li><a href="C11_(C_standard_revision)" title="wikilink">C11</a> atomics</li>
<li>Pipes</li>
<li><a href="Android_(operating_system)" title="wikilink">Android</a> installable client driver extension</li>
</ul>
<h3 id="opencl-2.1">OpenCL 2.1</h3>

<p>The ratification and release of the OpenCL 2.1 provisional specification was announced on March 3, 2015 at the Game Developer Conference in San Francisco. It replaces OpenCL C with OpenCL C++, a subset of <a class="uri" href="C++14" title="wikilink">C++14</a>. <a href="Vulkan_API" title="wikilink">Vulkan</a> and OpenCL 2.1 share SPIR-V as an intermediate language allowing high-level language front-ends to share a common compilation target. Updates to the OpenCL API include:</p>
<ul>
<li>Additional subgroup functionality</li>
<li>Copying of kernel objects and states</li>
<li>Low-latency device timer queries</li>
<li>Ingestion of SPIR-V code by runtime</li>
<li>Execution priority hints for queues</li>
<li>Zero-sized dispatches from host</li>
</ul>

<p>AMD, ARM, Intel, HPC, and <a class="uri" href="YetiWare" title="wikilink">YetiWare</a> have declared support for OpenCL 2.1.<a class="footnoteRef" href="#fn32" id="fnref32"><sup>32</sup></a><a class="footnoteRef" href="#fn33" id="fnref33"><sup>33</sup></a></p>
<h2 id="implementations">Implementations</h2>

<p>OpenCL consists of a set of headers and a <a href="shared_object" title="wikilink">shared object</a> that is loaded at runtime. An installable client driver loader (ICD loader) must be installed on the platform for every class of vendor for which the runtime would need to support. That is, for example, in order to support Nvidia devices on a Linux platform, the Nvidia ICD would need to be installed such that the OpenCL runtime would be able to locate the ICD for the vendor and redirect the calls appropriately. The standard OpenCL header is used by the consumer application; calls to each function are then proxied by the OpenCL runtime to the appropriate driver using the ICD. Each vendor must implement each OpenCL call in their driver.<a class="footnoteRef" href="#fn34" id="fnref34"><sup>34</sup></a></p>

<p>A number of <a href="open_source_software" title="wikilink">open source</a> implementations of the OpenCL ICD exist, including freeocl<a class="footnoteRef" href="#fn35" id="fnref35"><sup>35</sup></a> and ocl-icd.<a class="footnoteRef" href="#fn36" id="fnref36"><sup>36</sup></a> An implementation of OpenCL for a number of platforms is maintained as part of the <a href="Gallium_Compute_Project" title="wikilink">Gallium Compute Project</a>,<a class="footnoteRef" href="#fn37" id="fnref37"><sup>37</sup></a> which builds on the work of the <a href="Mesa_(computer_graphics)" title="wikilink">Mesa project</a> to support multiple platforms. An implementation by Intel for its <a href="Ivy_Bridge_(microarchitecture)" title="wikilink">Ivy Bridge</a> hardware was released in 2013.<a class="footnoteRef" href="#fn38" id="fnref38"><sup>38</sup></a> This software, called "Beignet", is not based on Mesa/Gallium, which has attracted criticism from developers at AMD and <a href="Red_Hat" title="wikilink">Red Hat</a>,<a class="footnoteRef" href="#fn39" id="fnref39"><sup>39</sup></a> as well as <a href="Michael_Larabel" title="wikilink">Michael Larabel</a> of <a class="uri" href="Phoronix" title="wikilink">Phoronix</a>.<a class="footnoteRef" href="#fn40" id="fnref40"><sup>40</sup></a> A CPU-only version building on <a class="uri" href="Clang" title="wikilink">Clang</a> and <a class="uri" href="LLVM" title="wikilink">LLVM</a>, called <em>pocl</em>, is intended to be a portable OpenCL implementation.<a class="footnoteRef" href="#fn41" id="fnref41"><sup>41</sup></a></p>
<h3 id="timeline-of-vendor-implementations">Timeline of vendor implementations</h3>
<ul>
<li>December 10, 2008: AMD and Nvidia held the first public OpenCL demonstration, a 75-minute presentation at <a href="Siggraph" title="wikilink">Siggraph Asia 2008</a>. AMD showed a CPU-accelerated OpenCL demo explaining the scalability of OpenCL on one or more cores while Nvidia showed a GPU-accelerated demo.<ref></ref></li>
</ul>

<p><a class="footnoteRef" href="#fn42" id="fnref42"><sup>42</sup></a></p>
<ul>
<li>March 16, 2009: at the 4th Multicore Expo, Imagination Technologies announced the <a class="uri" href="PowerVR" title="wikilink">PowerVR</a> SGX543MP, the first GPU of this company to feature OpenCL support.<ref></ref></li>
</ul>

<p></p>
<ul>
<li>March 26, 2009: at <a href="Game_Developers_Conference" title="wikilink">GDC 2009</a>, AMD and <a href="Havok_(company)" title="wikilink">Havok</a> demonstrated the first working implementation for OpenCL accelerating <a href="Havok_(software)#Havok_Cloth_and_Destruction" title="wikilink">Havok Cloth</a> on AMD <a href="Radeon_R700#Radeon_HD_4800" title="wikilink">Radeon HD 4000 series</a> GPU.<ref></ref></li>
</ul>

<p></p>
<ul>
<li>April 20, 2009: Nvidia announced the release of its OpenCL driver and <a href="Software_development_kit" title="wikilink">SDK</a> to developers participating in its OpenCL Early Access Program.<a class="footnoteRef" href="#fn43" id="fnref43"><sup>43</sup></a></li>
<li>August 5, 2009: AMD unveiled the first development tools for its OpenCL platform as part of its <a href="ATI_Stream" title="wikilink">ATI Stream</a> SDK v2.0 Beta Program.<ref></ref></li>
</ul>

<p></p>
<ul>
<li>August 28, 2009: Apple released <a href="Mac_OS_X_Snow_Leopard" title="wikilink">Mac OS X Snow Leopard</a>, which contains a full implementation of OpenCL.<a class="footnoteRef" href="#fn44" id="fnref44"><sup>44</sup></a></li>
</ul>
<dl>
<dd>OpenCL in Snow Leopard is supported on the Nvidia GeForce 320M, GeForce GT 330M, GeForce 9400M, GeForce 9600M GT, GeForce 8600M GT, GeForce GT 120, GeForce GT 130, GeForce GTX 285, GeForce 8800 GT, GeForce 8800 GS, Quadro FX 4800, Quadro FX5600, ATI Radeon HD 4670, ATI Radeon HD 4850, Radeon HD 4870, ATI Radeon HD 5670, ATI Radeon HD 5750, ATI Radeon HD 5770 and ATI Radeon HD 5870.<a class="footnoteRef" href="#fn45" id="fnref45"><sup>45</sup></a>
</dd>
</dl>
<ul>
<li>September 28, 2009: Nvidia released its own OpenCL drivers and SDK implementation.</li>
<li>October 13, 2009: AMD released the fourth beta of the ATI Stream SDK 2.0, which provides a complete OpenCL implementation on both <a href="Radeon_R700" title="wikilink">R700</a>/<a href="Radeon_R800" title="wikilink">R800</a> GPUs and <a class="uri" href="SSE3" title="wikilink">SSE3</a> capable CPUs. The SDK is available for both Linux and Windows.<a class="footnoteRef" href="#fn46" id="fnref46"><sup>46</sup></a></li>
<li>November 26, 2009: Nvidia released drivers for OpenCL 1.0 (rev 48).</li>
</ul>
<dl>
<dd>The Apple,<a class="footnoteRef" href="#fn47" id="fnref47"><sup>47</sup></a> Nvidia,<a class="footnoteRef" href="#fn48" id="fnref48"><sup>48</sup></a> <a class="uri" href="RapidMind" title="wikilink">RapidMind</a><a class="footnoteRef" href="#fn49" id="fnref49"><sup>49</sup></a> and <a class="uri" href="Gallium3D" title="wikilink">Gallium3D</a><a class="footnoteRef" href="#fn50" id="fnref50"><sup>50</sup></a> implementations of OpenCL are all based on the <a class="uri" href="LLVM" title="wikilink">LLVM</a> Compiler technology and use the <a class="uri" href="Clang" title="wikilink">Clang</a> Compiler as its frontend.
</dd>
</dl>
<ul>
<li>October 27, 2009: <a href="S3_Graphics" title="wikilink">S3</a> released their first product supporting native OpenCL 1.0 - the Chrome 5400E embedded graphics processor.<a class="footnoteRef" href="#fn51" id="fnref51"><sup>51</sup></a></li>
<li>December 10, 2009: <a href="VIA_Technologies" title="wikilink">VIA</a> released their first product supporting OpenCL 1.0 - ChromotionHD 2.0 video processor included in VN1000 chipset.<a class="footnoteRef" href="#fn52" id="fnref52"><sup>52</sup></a></li>
<li>December 21, 2009: AMD released the production version of the ATI Stream SDK 2.0,<a class="footnoteRef" href="#fn53" id="fnref53"><sup>53</sup></a> which provides OpenCL 1.0 support for <a href="Radeon_R800" title="wikilink">R800</a> GPUs and beta support for <a href="Radeon_R700" title="wikilink">R700</a> GPUs.</li>
<li>June 1, 2010: <a class="uri" href="ZiiLABS" title="wikilink">ZiiLABS</a> released details of their first OpenCL implementation for the ZMS processor for handheld, embedded and digital home products.<a class="footnoteRef" href="#fn54" id="fnref54"><sup>54</sup></a></li>
<li>June 30, 2010: IBM released a fully conformant version of OpenCL 1.0.<a class="footnoteRef" href="#fn55" id="fnref55"><sup>55</sup></a></li>
<li>September 13, 2010: <a class="uri" href="Intel" title="wikilink">Intel</a> released details of their first OpenCL implementation for the Sandy Bridge chip architecture. Sandy Bridge will integrate Intel's newest graphics chip technology directly onto the central processing unit.<a class="footnoteRef" href="#fn56" id="fnref56"><sup>56</sup></a></li>
<li>November 15, 2010: <a href="Wolfram_Research" title="wikilink">Wolfram Research</a> released <a href="Mathematica" title="wikilink">Mathematica 8</a> with <a href="http://reference.wolfram.com/mathematica/OpenCLLink/tutorial/Overview.html">OpenCLLink</a> package.</li>
<li>March 3, 2011: <a href="Khronos_Group" title="wikilink">Khronos Group</a> announces the formation of the <a class="uri" href="WebCL" title="wikilink">WebCL</a> working group to explore defining a <a class="uri" href="JavaScript" title="wikilink">JavaScript</a> binding to OpenCL. This creates the potential to harness <a class="uri" href="GPU" title="wikilink">GPU</a> and <a href="Multi-core_processor" title="wikilink">multi-core CPU</a> parallel processing from a <a href="Web_browser" title="wikilink">Web browser</a>.<a class="footnoteRef" href="#fn57" id="fnref57"><sup>57</sup></a><a class="footnoteRef" href="#fn58" id="fnref58"><sup>58</sup></a></li>
<li>March 31, 2011: IBM released a fully conformant version of OpenCL 1.1.<a class="footnoteRef" href="#fn59" id="fnref59"><sup>59</sup></a><a class="footnoteRef" href="#fn60" id="fnref60"><sup>60</sup></a></li>
<li>April 25, 2011: IBM released OpenCL Common Runtime v0.1 for Linux on x86 Architecture.<a class="footnoteRef" href="#fn61" id="fnref61"><sup>61</sup></a></li>
<li>May 4, 2011: Nokia Research releases an open source WebCL extension for the <a class="uri" href="Firefox" title="wikilink">Firefox</a> web browser, providing a JavaScript binding to OpenCL.<a class="footnoteRef" href="#fn62" id="fnref62"><sup>62</sup></a></li>
<li>July 1, 2011: Samsung Electronics releases an open source prototype implementation of WebCL for WebKit, providing a JavaScript binding to OpenCL.<a class="footnoteRef" href="#fn63" id="fnref63"><sup>63</sup></a></li>
<li>August 8, 2011: AMD released the OpenCL-driven AMD Accelerated Parallel Processing (APP) Software Development Kit (SDK) v2.5, replacing the <a href="ATI_Stream" title="wikilink">ATI Stream</a> SDK as technology and concept.<a class="footnoteRef" href="#fn64" id="fnref64"><sup>64</sup></a></li>
<li>December 12, 2011, AMD released AMD APP SDK v2.6<a class="footnoteRef" href="#fn65" id="fnref65"><sup>65</sup></a> which contains a preview of OpenCL 1.2.</li>
<li>February 27, 2012: <a href="The_Portland_Group" title="wikilink">The Portland Group</a> released the PGI OpenCL compiler for multi-core <a href="ARM_architecture" title="wikilink">ARM</a> CPUs.<a class="footnoteRef" href="#fn66" id="fnref66"><sup>66</sup></a></li>
<li>April 17, 2012: Khronos released a WebCL working draft.<a class="footnoteRef" href="#fn67" id="fnref67"><sup>67</sup></a></li>
<li>May 6, 2013: Altera released the Altera SDK for OpenCL, version 13.0.<a class="footnoteRef" href="#fn68" id="fnref68"><sup>68</sup></a> It is conformant to OpenCL 1.0.<a class="footnoteRef" href="#fn69" id="fnref69"><sup>69</sup></a></li>
<li>November 18, 2013: Khronos announced that the specification for OpenCL 2.0 had been finalised.<a class="footnoteRef" href="#fn70" id="fnref70"><sup>70</sup></a></li>
<li>March 19, 2014: Khronos releases the WebCL 1.0 specification<a class="footnoteRef" href="#fn71" id="fnref71"><sup>71</sup></a><a class="footnoteRef" href="#fn72" id="fnref72"><sup>72</sup></a></li>
<li>August 29, 2014: Intel releases HD Graphics 5300 driver that supports OpenCL 2.0.<a class="footnoteRef" href="#fn73" id="fnref73"><sup>73</sup></a></li>
<li>September 25, 2014: AMD releases Catalyst 14.41 RC1, which includes an OpenCL 2.0 driver.<a class="footnoteRef" href="#fn74" id="fnref74"><sup>74</sup></a></li>
<li>April 13, 2015: Nvidia releases WHQL driver v350.12, which includes OpenCL 1.2 support.<a class="footnoteRef" href="#fn75" id="fnref75"><sup>75</sup></a></li>
</ul>
<h2 id="conformant-products">Conformant products</h2>

<p>The <a href="Khronos_Group" title="wikilink">Khronos Group</a> maintains an extended list of OpenCL-conformant products.<a class="footnoteRef" href="#fn76" id="fnref76"><sup>76</sup></a></p>
<table>
<thead>
<tr class="header">
<th style="text-align: left;">
<p><a href="wikt:synopsis" title="wikilink">Synopsis</a> of OpenCL conformant products<a class="footnoteRef" href="#fn77" id="fnref77"><sup>77</sup></a></p></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">
<p><a href="http://developer.amd.com/tools-and-sdks/opencl-zone/opencl-tools-sdks/amd-accelerated-parallel-processing-app-sdk/">AMD APP SDK</a> (supports OpenCL <a class="uri" href="CPU" title="wikilink">CPU</a> and <a href="accelerated_processing_unit" title="wikilink">accelerated processing unit</a> Devices)</p></td>
</tr>
<tr class="even">
<td style="text-align: left;">
<p><a href="http://software.intel.com/en-us/vcsource/tools/opencl-sdk">Intel SDK for OpenCL Applications 2013</a><a class="footnoteRef" href="#fn78" id="fnref78"><sup>78</sup></a> (supports Intel Core processors and Intel HD Graphics 4000/2500)</p></td>
</tr>
<tr class="odd">
<td style="text-align: left;">
<p><a class="uri" href="IBM" title="wikilink">IBM</a> Servers with <a href="http://www.alphaworks.ibm.com/tech/opencl">OpenCL Development Kit</a> for Linux on Power running on <a href="AltiVec#VSX" title="wikilink">Power VSX</a><a class="footnoteRef" href="#fn79" id="fnref79"><sup>79</sup></a><a class="footnoteRef" href="#fn80" id="fnref80"><sup>80</sup></a></p></td>
</tr>
<tr class="even">
<td style="text-align: left;">
<p><a class="uri" href="IBM" title="wikilink">IBM</a> <a href="http://www.alphaworks.ibm.com/tech/ocr">OpenCL Common Runtime (OCR)</a> <a class="footnoteRef" href="#fn81" id="fnref81"><sup>81</sup></a></p></td>
</tr>
<tr class="odd">
<td style="text-align: left;">
<p><a href="http://developer.nvidia.com/opencl">Nvidia OpenCL Driver and Tools</a><a class="footnoteRef" href="#fn82" id="fnref82"><sup>82</sup></a></p></td>
</tr>
</tbody>
</table>
<h2 id="extensions">Extensions</h2>

<p>Some vendors provide extended functionality over the standard OpenCL specification via the means of extensions. These are still specified by Khronos but provided by vendors within their SDKs. They often contain features that are to be implemented in the future - for example device fission functionality was originally an extension but is now provided as part of the 1.2 specification.</p>

<p>Extensions provided in the 1.2 specification include:</p>
<ul>
<li>Writing to 3D image memory objects</li>
<li><a href="Half-precision_floating-point_format" title="wikilink">Half-precision floating-point format</a></li>
<li>Sharing memory objects with OpenGL</li>
<li>Creating event objects from GL sync objects</li>
<li>Sharing memory objects with Direct3D 10</li>
<li>DX9 media Surface Sharing</li>
<li>Sharing Memory Objects with Direct3D 11</li>
</ul>
<h3 id="device-fission">Device fission</h3>

<p>Device fission - introduced fully into the OpenCL standard with version 1.2 - allows individual command queues to be used for specific areas of a device. For example, within the Intel SDK, a command queue can be created that maps directly to an individual core. AMD also provides functionality for device fission, also originally as an extension. Device fission can be used where the availability of compute is required reliably, such as in a latency sensitive environment. Fission effectively reserves areas of the device for computation.</p>
<h2 id="portability-performance-and-alternatives">Portability, performance and alternatives</h2>

<p>A key feature of OpenCL is portability, via its abstracted memory and execution model, and the programmer is not able to directly use hardware-specific technologies such as inline <a href="Parallel_Thread_Execution" title="wikilink">Parallel Thread Execution</a> (PTX) for NVidia GPUs unless they are willing to give up direct portability on other platforms. It is possible to run any OpenCL kernel on any conformant implementation.</p>

<p>However, performance of the kernel is not necessarily portable across platforms. Existing implementations have been shown to be competitive when kernel code is properly tuned, though, and <a class="uri" href="auto-tuning" title="wikilink">auto-tuning</a> has been suggested as a solution to the performance portability problem,<a class="footnoteRef" href="#fn83" id="fnref83"><sup>83</sup></a> yielding "acceptable levels of performance" in experimental linear algebra kernels.<a class="footnoteRef" href="#fn84" id="fnref84"><sup>84</sup></a> Portability of an entire application containing multiple kernels with differing behaviors was also studied, and shows that portability only required limited tradeoffs.<a class="footnoteRef" href="#fn85" id="fnref85"><sup>85</sup></a></p>

<p>A study at <a href="Delft_University" title="wikilink">Delft University</a> that compared <a class="uri" href="CUDA" title="wikilink">CUDA</a> programs and their straightforward translation into OpenCL C found CUDA to outperform OpenCL by at most 30% on the Nvidia implementation. The researchers noted that their comparison could be made fairer by applying manual optimizations to the OpenCL programs, in which case there was "no reason for OpenCL to obtain worse performance than CUDA". The performance differences could mostly be attributed to differences in the programming model (especially the memory model) and to NVIDIA's compiler optimizations for CUDA compared to those for OpenCL.<a class="footnoteRef" href="#fn86" id="fnref86"><sup>86</sup></a> Another, similar study found CUDA to perform faster data transfers to and from a GPU's memory.<a class="footnoteRef" href="#fn87" id="fnref87"><sup>87</sup></a></p>

<p>The fact that OpenCL allows workloads to be shared by CPU and GPU, executing the same programs, means that programmers can exploit both by dividing work among the devices. This leads to the problem of deciding how to partition the work, because the relative speeds of operations differ among the devices. <a href="Machine_learning" title="wikilink">Machine learning</a> has been suggested to solve this problem: Grewe and O'Boyle describe a system of <a href="support_vector_machine" title="wikilink">support vector machines</a> trained on compile-time features of program that can decide the device partitioning problem statically, without actually running the programs to measure their performance.<a class="footnoteRef" href="#fn88" id="fnref88"><sup>88</sup></a></p>
<h2 id="see-also">See also</h2>
<ul>
<li><a href="AMD_FireStream" title="wikilink">AMD FireStream</a></li>
<li><a class="uri" href="BrookGPU" title="wikilink">BrookGPU</a></li>
<li><a href="C++_AMP" title="wikilink">C++ AMP</a></li>
<li><a href="Close_to_Metal" title="wikilink">Close to Metal</a></li>
<li><a class="uri" href="CUDA" title="wikilink">CUDA</a></li>
<li><a class="uri" href="DirectCompute" title="wikilink">DirectCompute</a></li>
<li><a class="uri" href="GPGPU" title="wikilink">GPGPU</a></li>
<li><a href="Larrabee_(microarchitecture)" title="wikilink">Larrabee (microarchitecture)</a></li>
<li><a href="Lib_Sh" title="wikilink">Lib Sh</a></li>
<li><a href="List_of_OpenCL_applications" title="wikilink">List of OpenCL applications</a></li>
<li><a class="uri" href="OpenACC" title="wikilink">OpenACC</a></li>
<li><a class="uri" href="OpenGL" title="wikilink">OpenGL</a></li>
<li><a class="uri" href="OpenHMPP" title="wikilink">OpenHMPP</a></li>
<li><a class="uri" href="OpenMP" title="wikilink">OpenMP</a></li>
<li><a href="Metal_(Apple_API)" title="wikilink">Metal (Apple API)</a></li>
<li><a class="uri" href="Renderscript" title="wikilink">Renderscript</a></li>
<li><a class="uri" href="SequenceL" title="wikilink">SequenceL</a></li>
<li><a class="uri" href="SIMD" title="wikilink">SIMD</a></li>
</ul>
<h2 id="references">References</h2>
<h2 id="external-links">External links</h2>
<ul>
<li></li>
<li></li>
</ul>

<p>"</p>

<p><a href="Category:2009_software" title="wikilink">Category:2009 software</a> <a href="Category:Application_programming_interfaces" title="wikilink">Category:Application programming interfaces</a> <a href="Category:Cross-platform_software" title="wikilink">Category:Cross-platform software</a> <a class="uri" href="Category:GPGPU" title="wikilink">Category:GPGPU</a> <a href="Category:GPGPU_libraries" title="wikilink"> OpenCL</a> <a href="Category:Parallel_computing" title="wikilink">Category:Parallel computing</a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1"><a href="#fnref1">↩</a></li>
<li id="fn2"><a href="#fnref2">↩</a></li>
<li id="fn3"><a href="#fnref3">↩</a></li>
<li id="fn4"><a href="#fnref4">↩</a></li>
<li id="fn5"><a href="#fnref5">↩</a></li>
<li id="fn6"><a href="#fnref6">↩</a></li>
<li id="fn7"></li>
<li id="fn8"></li>
<li id="fn9"><a href="#fnref9">↩</a></li>
<li id="fn10">AMD. <a href="http://developer.amd.com/zones/OpenCLZone/courses/Documents/Introduction_to_OpenCL_Programming%20(201005).pdf">Introduction to OpenCL Programming 201005</a>, page 89-90<a href="#fnref10">↩</a></li>
<li id="fn11">AMD. Introduction to OpenCL Programming 201005, page 89-90<a href="#fnref11">↩</a></li>
<li id="fn12"></li>
<li id="fn13"></li>
<li id="fn14"><a href="#fnref14">↩</a></li>
<li id="fn15"><a href="#fnref15">↩</a></li>
<li id="fn16"><a href="#fnref16">↩</a></li>
<li id="fn17"><a href="#fnref17">↩</a></li>
<li id="fn18"><a href="#fnref18">↩</a></li>
<li id="fn19"><a href="#fnref19">↩</a></li>
<li id="fn20"><a href="#fnref20">↩</a></li>
<li id="fn21"><a href="#fnref21">↩</a></li>
<li id="fn22"><a href="#fnref22">↩</a></li>
<li id="fn23"><a href="#fnref23">↩</a></li>
<li id="fn24"><a href="#fnref24">↩</a></li>
<li id="fn25"><a href="#fnref25">↩</a></li>
<li id="fn26"><a href="https://www.khronos.org/news/press/releases/khronos-group-releases-opencl-1-1-parallel-computing-standard/">Khronos Drives Momentum of Parallel Computing Standard with Release of OpenCL 1.1 Specification</a><a href="#fnref26">↩</a></li>
<li id="fn27"><a href="#fnref27">↩</a></li>
<li id="fn28"><a href="#fnref28">↩</a></li>
<li id="fn29"></li>
<li id="fn30"></li>
<li id="fn31"><a href="#fnref31">↩</a></li>
<li id="fn32"><a href="#fnref32">↩</a></li>
<li id="fn33"><a href="#fnref33">↩</a></li>
<li id="fn34"><a href="#fnref34">↩</a></li>
<li id="fn35"><a href="#fnref35">↩</a></li>
<li id="fn36"><a href="#fnref36">↩</a></li>
<li id="fn37"><a href="#fnref37">↩</a></li>
<li id="fn38"><a href="#fnref38">↩</a></li>
<li id="fn39"><a href="#fnref39">↩</a></li>
<li id="fn40"><a href="#fnref40">↩</a></li>
<li id="fn41"><a href="#fnref41">↩</a></li>
<li id="fn42"><a href="#fnref42">↩</a></li>
<li id="fn43"><a href="#fnref43">↩</a></li>
<li id="fn44"><a href="#fnref44">↩</a></li>
<li id="fn45"><a href="#fnref45">↩</a></li>
<li id="fn46"><a href="#fnref46">↩</a></li>
<li id="fn47"><a href="#fnref47">↩</a></li>
<li id="fn48"><a href="#fnref48">↩</a></li>
<li id="fn49"><a href="#fnref49">↩</a></li>
<li id="fn50"><a href="#fnref50">↩</a></li>
<li id="fn51"><a href="#fnref51">↩</a></li>
<li id="fn52"><a href="#fnref52">↩</a></li>
<li id="fn53"><a href="#fnref53">↩</a></li>
<li id="fn54"><a href="#fnref54">↩</a></li>
<li id="fn55"><a href="#fnref55">↩</a></li>
<li id="fn56"><a href="#fnref56">↩</a></li>
<li id="fn57"><a href="#fnref57">↩</a></li>
<li id="fn58"><a href="#fnref58">↩</a></li>
<li id="fn59"></li>
<li id="fn60"><a href="#fnref60">↩</a></li>
<li id="fn61"><a href="#fnref61">↩</a></li>
<li id="fn62"><a href="#fnref62">↩</a></li>
<li id="fn63"><a href="#fnref63">↩</a></li>
<li id="fn64"><a href="#fnref64">↩</a></li>
<li id="fn65"><a href="#fnref65">↩</a></li>
<li id="fn66"><a href="#fnref66">↩</a></li>
<li id="fn67"><a href="#fnref67">↩</a></li>
<li id="fn68"><a href="#fnref68">↩</a></li>
<li id="fn69"><a href="#fnref69">↩</a></li>
<li id="fn70"><a href="#fnref70">↩</a></li>
<li id="fn71"><a href="#fnref71">↩</a></li>
<li id="fn72"><a href="#fnref72">↩</a></li>
<li id="fn73">[<a class="uri" href="https://downloadcenter.intel.com/Detail_Desc.aspx?agr=Y&amp;DwnldID">https://downloadcenter.intel.com/Detail_Desc.aspx?agr=Y&amp;DwnldID;</a>;=24245 Intel OpenCL 2.0 Driver]<a href="#fnref73">↩</a></li>
<li id="fn74"><a href="#fnref74">↩</a></li>
<li id="fn75"><a class="uri" href="http://us.download.nvidia.com/Windows/350.12/350.12-win8-win7-winvista-desktop-release-notes.pdf">http://us.download.nvidia.com/Windows/350.12/350.12-win8-win7-winvista-desktop-release-notes.pdf</a><a href="#fnref75">↩</a></li>
<li id="fn76"></li>
<li id="fn77"></li>
<li id="fn78"><a href="#fnref78">↩</a></li>
<li id="fn79"><a href="#fnref79">↩</a></li>
<li id="fn80"><a href="#fnref80">↩</a></li>
<li id="fn81"><a href="#fnref81">↩</a></li>
<li id="fn82"><a href="#fnref82">↩</a></li>
<li id="fn83"></li>
<li id="fn84"><a href="#fnref84">↩</a></li>
<li id="fn85"><a href="#fnref85">↩</a></li>
<li id="fn86"><a href="#fnref86">↩</a></li>
<li id="fn87"><a href="#fnref87">↩</a></li>
<li id="fn88"><a href="#fnref88">↩</a></li>
</ol>
</section>
</body>

