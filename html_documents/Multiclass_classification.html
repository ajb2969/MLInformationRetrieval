<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="1659">Multiclass classification</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>Multiclass classification</h1>
<hr/>
<dl>
<dd><em>Not to be confused with <a href="multi-label_classification" title="wikilink">multi-label classification</a>.</em>
</dd>
</dl>

<p>In <a href="machine_learning" title="wikilink">machine learning</a>, <strong>multiclass</strong> or <strong>multinomial classification</strong> is the problem of <a href="statistical_classification" title="wikilink">classifying</a> instances into one of the more than two classes (classifying instances into one of the two classes is called <a href="binary_classification" title="wikilink">binary classification</a>).</p>

<p>While some classification algorithms naturally permit the use of more than two classes, others are by nature <a href="Binary_classification" title="wikilink">binary</a> algorithms; these can, however, be turned into multinomial classifiers by a variety of strategies.</p>

<p>Multiclass classification should not be confused with <a href="multi-label_classification" title="wikilink">multi-label classification</a>, where multiple labels are to be predicted for each instance.</p>
<h2 id="general-strategies">General strategies</h2>

<p>This section discusses strategies for reducing the problem of multiclass classification to multiple binary classification problems.</p>
<h3 id="one-vs.-rest">One-vs.-rest</h3>

<p>The <em>one-vs.-rest</em><a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a> (or <em>one-vs.-all</em>, OvA or OvR) strategy involves training a single classifier per class, with the samples of that class as positive samples and all other samples as negatives. This strategy requires the base classifiers to produce a real-valued confidence score for its decision, rather than just a class label; discrete class labels alone can lead to ambiguities, where multiple classes are predicted for a single sample.<a class="footnoteRef" href="#fn2" id="fnref2"><sup>2</sup></a><a class="footnoteRef" href="#fn3" id="fnref3"><sup>3</sup></a></p>

<p>In pseudocode, the training algorithm for an OvA learner constructed from a binary classification learner 

<math display="inline" id="Multiclass_classification:0">
 <semantics>
  <mi>L</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>L</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   L
  </annotation>
 </semantics>
</math>

 is as follows:</p>
<dl>
<dd>Inputs:
<ul>
<li>

<math display="inline" id="Multiclass_classification:1">
 <semantics>
  <mi>L</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>L</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   L
  </annotation>
 </semantics>
</math>

, a learner (training algorithm for binary classifiers)</li>
<li>samples 

<math display="inline" id="Multiclass_classification:2">
 <semantics>
  <mi>X</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>X</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   X
  </annotation>
 </semantics>
</math>

</li>
<li>labels 

<math display="inline" id="Multiclass_classification:3">
 <semantics>
  <mi>y</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>y</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   y
  </annotation>
 </semantics>
</math>

 where 

<math display="inline" id="Multiclass_classification:4">
 <semantics>
  <mi>y</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>y</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   y
  </annotation>
 </semantics>
</math>

 ∈ {1, … 

<math display="inline" id="Multiclass_classification:5">
 <semantics>
  <mi>K</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>K</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   K
  </annotation>
 </semantics>
</math>

} is the label for the sample 

<math display="inline" id="Multiclass_classification:6">
 <semantics>
  <mi>X</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>X</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   X
  </annotation>
 </semantics>
</math>

</li>
</ul>
</dd>
<dd>Output:
<ul>
<li>a list of classifiers 

<math display="inline" id="Multiclass_classification:7">
 <semantics>
  <mi>f</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>f</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   f
  </annotation>
 </semantics>
</math>

 for 

<math display="inline" id="Multiclass_classification:8">
 <semantics>
  <mi>k</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>k</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   k
  </annotation>
 </semantics>
</math>

 ∈ {1, …, 

<math display="inline" id="Multiclass_classification:9">
 <semantics>
  <mi>K</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>K</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   K
  </annotation>
 </semantics>
</math>

}</li>
</ul>
</dd>
<dd>Procedure:
<ul>
<li>For each 

<math display="inline" id="Multiclass_classification:10">
 <semantics>
  <mi>k</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>k</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   k
  </annotation>
 </semantics>
</math>

 in {1, …, 

<math display="inline" id="Multiclass_classification:11">
 <semantics>
  <mi>K</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>K</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   K
  </annotation>
 </semantics>
</math>

}:
<ul>
<li>Construct a new label vector 

<math display="inline" id="Multiclass_classification:12">
 <semantics>
  <mrow>
   <msub>
    <mi>y</mi>
    <mi>i</mi>
   </msub>
   <mo>=</mo>
   <mn>1</mn>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>y</ci>
     <ci>i</ci>
    </apply>
    <cn type="integer">1</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   y_{i}=1
  </annotation>
 </semantics>
</math>

 where 

<math display="inline" id="Multiclass_classification:13">
 <semantics>
  <mrow>
   <msub>
    <mi>y</mi>
    <mi>i</mi>
   </msub>
   <mo>=</mo>
   <mi>k</mi>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>y</ci>
     <ci>i</ci>
    </apply>
    <ci>k</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   y_{i}=k
  </annotation>
 </semantics>
</math>

, 0 (or −1) elsewhere</li>
<li>Apply 

<math display="inline" id="Multiclass_classification:14">
 <semantics>
  <mi>L</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>L</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   L
  </annotation>
 </semantics>
</math>

 to 

<math display="inline" id="Multiclass_classification:15">
 <semantics>
  <mi>X</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>X</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   X
  </annotation>
 </semantics>
</math>

, 

<math display="inline" id="Multiclass_classification:16">
 <semantics>
  <mi>y</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>y</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   y
  </annotation>
 </semantics>
</math>

 to obtain 

<math display="inline" id="Multiclass_classification:17">
 <semantics>
  <mi>f</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>f</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   f
  </annotation>
 </semantics>
</math>

</li>
</ul></li>
</ul>
</dd>
</dl>

<p>Making decisions means applying all classifiers to an unseen sample 

<math display="inline" id="Multiclass_classification:18">
 <semantics>
  <mi>x</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>x</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   x
  </annotation>
 </semantics>
</math>

 and predicting the label 

<math display="inline" id="Multiclass_classification:19">
 <semantics>
  <mi>k</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>k</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   k
  </annotation>
 </semantics>
</math>

 for which the corresponding classifier reports the highest confidence score:</p>

<p>

<math display="block" id="Multiclass_classification:20">
 <semantics>
  <mrow>
   <mover accent="true">
    <mi>y</mi>
    <mo stretchy="false">^</mo>
   </mover>
   <mo>=</mo>
   <mrow>
    <mrow>
     <mi>arg</mi>
     <mrow>
      <munder>
       <mi>max</mi>
       <mrow>
        <mi>k</mi>
        <mo>∈</mo>
        <mrow>
         <mn>1</mn>
         <mi mathvariant="normal">…</mi>
         <mi>K</mi>
        </mrow>
       </mrow>
      </munder>
      <msub>
       <mi>f</mi>
       <mi>k</mi>
      </msub>
     </mrow>
    </mrow>
    <mrow>
     <mo stretchy="false">(</mo>
     <mi>x</mi>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <ci>normal-^</ci>
     <ci>y</ci>
    </apply>
    <apply>
     <times></times>
     <apply>
      <arg></arg>
      <apply>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <max></max>
        <apply>
         <in></in>
         <ci>k</ci>
         <apply>
          <times></times>
          <cn type="integer">1</cn>
          <ci>normal-…</ci>
          <ci>K</ci>
         </apply>
        </apply>
       </apply>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <ci>f</ci>
        <ci>k</ci>
       </apply>
      </apply>
     </apply>
     <ci>x</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \hat{y}=\arg\max_{k\in 1\ldots K}f_{k}(x)
  </annotation>
 </semantics>
</math>

</p>

<p>Although this strategy is popular, it is a <a class="uri" href="heuristic" title="wikilink">heuristic</a> that suffers from several problems. Firstly, the scale of the confidence values may differ between the binary classifiers. Second, even if the class distribution is balanced in the training set, the binary classification learners see unbalanced distributions because typically the set of negatives they see is much larger than the set of positives.<a class="footnoteRef" href="#fn4" id="fnref4"><sup>4</sup></a></p>
<h3 id="one-vs.-one">One-vs.-one</h3>

<p>In the <em>one-vs.-one</em> (OvO) reduction, one trains 

<math display="inline" id="Multiclass_classification:21">
 <semantics>
  <mrow>
   <mrow>
    <mi>K</mi>
    <mrow>
     <mo stretchy="false">(</mo>
     <mrow>
      <mi>K</mi>
      <mi mathvariant="normal">−</mi>
      <mn>1</mn>
     </mrow>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
   <mo>/</mo>
   <mn>2</mn>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <divide></divide>
    <apply>
     <times></times>
     <ci>K</ci>
     <apply>
      <times></times>
      <ci>K</ci>
      <ci>normal-−</ci>
      <cn type="integer">1</cn>
     </apply>
    </apply>
    <cn type="integer">2</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   K(K−1)/2
  </annotation>
 </semantics>
</math>

 binary classifiers for a 

<math display="inline" id="Multiclass_classification:22">
 <semantics>
  <mi>K</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>K</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   K
  </annotation>
 </semantics>
</math>

-way multiclass problem; each receives the samples of a pair of classes from the original training set, and must learn to distinguish these two classes. At prediction time, a voting scheme is applied: all 

<math display="inline" id="Multiclass_classification:23">
 <semantics>
  <mrow>
   <mrow>
    <mi>K</mi>
    <mrow>
     <mo stretchy="false">(</mo>
     <mrow>
      <mi>K</mi>
      <mi mathvariant="normal">−</mi>
      <mn>1</mn>
     </mrow>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
   <mo>/</mo>
   <mn>2</mn>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <divide></divide>
    <apply>
     <times></times>
     <ci>K</ci>
     <apply>
      <times></times>
      <ci>K</ci>
      <ci>normal-−</ci>
      <cn type="integer">1</cn>
     </apply>
    </apply>
    <cn type="integer">2</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   K(K−1)/2
  </annotation>
 </semantics>
</math>

 classifiers are applied to an unseen sample and the class that got the highest number of "+1" predictions gets predicted by the combined classifier.<a class="footnoteRef" href="#fn5" id="fnref5"><sup>5</sup></a></p>

<p>Like OvR, OvO suffers from ambiguities in that some regions of its input space may receive the same number of votes.<a class="footnoteRef" href="#fn6" id="fnref6"><sup>6</sup></a></p>
<h2 id="see-also">See also</h2>
<ul>
<li><a href="Binary_classification" title="wikilink">Binary classification</a></li>
<li><a href="One-class_classification" title="wikilink">One-class classification</a></li>
<li><a href="Multi-label_classification" title="wikilink">Multi-label classification</a></li>
<li><a href="perceptron#Multiclass_perceptron" title="wikilink">Multiclass perceptron</a> in <a class="uri" href="Perceptron" title="wikilink">Perceptron</a></li>
</ul>
<h2 id="notes">Notes</h2>
<h2 id="references">References</h2>

<p>"</p>

<p><a href="Category:Classification_algorithms" title="wikilink">Category:Classification algorithms</a> <a href="Category:Statistical_classification" title="wikilink">Category:Statistical classification</a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1"><a href="#fnref1">↩</a></li>
<li id="fn2"></li>
<li id="fn3">In <a href="multi-label_classification" title="wikilink">multi-label classification</a>, OvR is known as <em>binary relevance</em> and the prediction of multiple classes is considered a feature, not a problem.<a href="#fnref3">↩</a></li>
<li id="fn4"></li>
<li id="fn5"></li>
<li id="fn6"></li>
</ol>
</section>
</body>
</html>
