<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="188">Side-channel attack</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>Side-channel attack</h1>
<hr/>

<p> In <a class="uri" href="cryptography" title="wikilink">cryptography</a>, a <strong>side-channel attack</strong> is any attack based on information gained from the physical <a class="uri" href="implementation" title="wikilink">implementation</a> of a <a class="uri" href="cryptosystem" title="wikilink">cryptosystem</a>, rather than <a href="brute_force_attack" title="wikilink">brute force</a> or theoretical weaknesses in the <a href="algorithm" title="wikilink">algorithms</a> (compare <a class="uri" href="cryptanalysis" title="wikilink">cryptanalysis</a>). For example, timing information, power consumption, <a href="electromagnetic_radiation" title="wikilink">electromagnetic</a> leaks or even <a href="acoustic_cryptanalysis" title="wikilink">sound</a> can provide an extra source of information, which can be exploited to break the system. Some side-channel attacks require technical knowledge of the internal operation of the system on which the cryptography is implemented, although others such as <a href="differential_power_analysis" title="wikilink">differential power analysis</a> are effective as black-box attacks. Many powerful side-channel attacks are based on statistical methods pioneered by <a href="Paul_Kocher" title="wikilink">Paul Kocher</a>.<a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a></p>

<p>Attempts to break a cryptosystem by deceiving or coercing people with legitimate access are not typically called side-channel attacks: see <a href="social_engineering_(computer_security)" title="wikilink">social engineering</a> and <a href="rubber-hose_cryptanalysis" title="wikilink">rubber-hose cryptanalysis</a>. For attacks on computer systems themselves (which are often used to perform cryptography and thus contain <a href="cryptographic_key" title="wikilink">cryptographic keys</a> or <a href="plaintext" title="wikilink">plaintexts</a>), see <a href="computer_security" title="wikilink">computer security</a>. The rise of <a href="Web_2.0" title="wikilink">Web 2.0</a> applications and <a class="uri" href="software-as-a-service" title="wikilink">software-as-a-service</a> has also significantly raised the possibility of side-channel attacks on the web, even when transmissions between a web browser and server are encrypted (e.g., through HTTPS or WiFi encryption), according to researchers from Microsoft Research and Indiana University.<a class="footnoteRef" href="#fn2" id="fnref2"><sup>2</sup></a></p>
<h2 id="general">General</h2>

<p>General classes of side channel attack include:</p>
<ul>
<li><a href="Timing_attack" title="wikilink">Timing attack</a> — attacks based on measuring how much time various computations take to perform.</li>
<li><a href="Power_analysis" title="wikilink">Power-monitoring attack</a> — attacks that make use of varying power consumption by the hardware during computation.</li>
<li>Electromagnetic attacks — attacks based on leaked electromagnetic radiation, which can directly provide plaintexts and other information. Such measurements can be used to infer cryptographic keys using techniques equivalent to those in power analysis or can be used in non-cryptographic attacks, e.g. <a class="uri" href="TEMPEST" title="wikilink">TEMPEST</a> (aka <a href="van_Eck_phreaking" title="wikilink">van Eck phreaking</a> or radiation monitoring) attacks.</li>
<li><a href="Acoustic_cryptanalysis" title="wikilink">Acoustic cryptanalysis</a> — attacks that exploit sound produced during a computation (rather like power analysis).</li>
<li><a href="Differential_fault_analysis" title="wikilink">Differential fault analysis</a> — in which secrets are discovered by introducing faults in a computation.</li>
<li><a href="Data_remanence" title="wikilink">Data remanence</a> — in which sensitive data are read after supposedly having been deleted.</li>
<li><a href="Row_hammer" title="wikilink">Row hammer</a> — in which off-limits memory can be changed by accessing adjacent memory.</li>
</ul>

<p>In all cases, the underlying principle is that physical effects caused by the operation of a cryptosystem (<em>on the side</em>) can provide useful extra information about secrets in the system, for example, the <a href="cryptographic_key" title="wikilink">cryptographic key</a>, partial state information, full or partial <a href="plaintext" title="wikilink">plaintexts</a> and so forth. The term cryptophthora (secret degradation) is sometimes used to express the degradation of secret key material resulting from side-channel leakage.</p>
<h2 id="examples">Examples</h2>

<p>A <em>timing attack</em> watches data movement into and out of the <a href="Central_processing_unit" title="wikilink">CPU</a> or memory on the hardware running the cryptosystem or algorithm. Simply by observing variations in how long it takes to perform cryptographic operations, it might be possible to determine the entire secret key. Such attacks involve statistical analysis of timing measurements and have been demonstrated across networks.<a class="footnoteRef" href="#fn3" id="fnref3"><sup>3</sup></a></p>

<p>A <em>power-analysis attack</em> can provide even more detailed information by observing the power consumption of a hardware device such as CPU or cryptographic circuit. These attacks are roughly categorized into simple power analysis (SPA) and differential power analysis (DPA).</p>

<p>Fluctuations in current also generate <a href="electromagnetic_radiation" title="wikilink">radio waves</a>, enabling attacks that analyze measurements of electromagnetic emanations. These attacks typically involve similar statistical techniques as power-analysis attacks.</p>

<p>Non-cryptographic historical analogues to modern side-channel attacks are known. A recently declassified NSA document reveals that as far back as 1943, an engineer with Bell telephone observed decipherable spikes on an oscilloscope associated with the decrypted output of a certain encrypting teletype.<a class="footnoteRef" href="#fn4" id="fnref4"><sup>4</sup></a> According to former <a class="uri" href="MI5" title="wikilink">MI5</a> officer <a href="Peter_Wright" title="wikilink">Peter Wright</a>, the British Security Service analysed emissions from French cipher equipment in the 1960s.<a class="footnoteRef" href="#fn5" id="fnref5"><sup>5</sup></a> In the 1980s, <a href="KGB" title="wikilink">Soviet</a> eavesdroppers were suspected of having planted <a href="Surveillance_bug" title="wikilink">bugs</a> inside IBM <a class="uri" href="Selectric" title="wikilink">Selectric</a> typewriters to monitor the electrical noise generated as the type ball rotated and pitched to strike the paper; the characteristics of those signals could determine which key was pressed.<a class="footnoteRef" href="#fn6" id="fnref6"><sup>6</sup></a></p>

<p>Power consumption of devices causes heating, which is offset by cooling effects. Temperature changes create thermally induced mechanical stress. This stress can create low level <a href="acoustics" title="wikilink">acoustic</a> (i.e. <em>noise</em>) emissions from operating CPUs (about 10 kHz in some cases). Recent research by <a href="Adi_Shamir" title="wikilink">Shamir</a> et al. has suggested that information about the operation of cryptosystems and algorithms can be obtained in this way as well. This is an <a href="acoustic_cryptanalysis" title="wikilink">acoustic attack</a>; if the surface of the CPU chip, or in some cases the CPU package, can be observed, <a class="uri" href="infrared" title="wikilink">infrared</a> images can also provide information about the code being executed on the CPU, known as a <em>thermal-imaging attack</em>.</p>
<h2 id="countermeasures">Countermeasures</h2>

<p>Because side-channel attacks rely on the relationship between information emitted (leaked) through a side channel and the secret data, countermeasures fall into two main categories: (1) eliminate or reduce the release of such information and (2) eliminate the relationship between the leaked information and the secret data, that is, make the leaked information unrelated, or rather <em>uncorrelated</em>, to the secret data, typically through some form of randomization of the ciphertext that transforms the data in a way that can be undone after the cryptographic operation (e.g., decryption) is completed.</p>

<p>Under the first category, displays with special shielding to lessen electromagnetic emissions, reducing susceptibility to <a class="uri" href="TEMPEST" title="wikilink">TEMPEST</a> attacks, are now commercially available. Power line conditioning and filtering can help deter power-monitoring attacks, although such measures must be used cautiously, since even very small correlations can remain and compromise security. Physical enclosures can reduce the risk of surreptitious installation of microphones (to counter acoustic attacks) and other micro-monitoring devices (against CPU power-draw or thermal-imaging attacks).</p>

<p>Another countermeasure (still in the first category) is to jam the emitted channel with noise. For instance, a random delay can be added to deter timing attacks, although adversaries can compensate for these delays by averaging multiple measurements together (or, more generally, using more measurements in the analysis). As the amount of noise in the side channel increases, the adversary needs to collect more measurements.</p>

<p>In the case of timing attacks against targets whose computation times are quantized into discrete clock cycle counts, an effective countermeasure against is to design the software to be isochronous, that is to run in an exactly constant amount of time, independently of secret values. This makes timing attacks impossible.<a class="footnoteRef" href="#fn7" id="fnref7"><sup>7</sup></a> Such countermeasures can be difficult to implement in practice, since even individual instructions can have variable timing on some CPUs.</p>

<p>One partial countermeasure against simple power attacks, but not differential power-analysis attacks, is to design the software so that it is "PC-secure" in the "program counter security model". In a PC-secure program, the execution path does not depend on secret values. In other words, all conditional branches depend only on public information. (This is a more restrictive condition than isochronous code, but a less restrictive condition than branch-free code.) Even though multiply operations draw more power than <a class="uri" href="NOP" title="wikilink">NOP</a> on practically all CPUs, using a constant execution path prevents such operation-dependent power differences (differences in power from choosing one branch over another) from leaking any secret information.<a class="footnoteRef" href="#fn8" id="fnref8"><sup>8</sup></a> On architectures where the instruction execution time is not data-dependent, a PC-secure program is also immune to timing attacks. <a class="footnoteRef" href="#fn9" id="fnref9"><sup>9</sup></a><a class="footnoteRef" href="#fn10" id="fnref10"><sup>10</sup></a></p>

<p>Another way in which code can be non-isochronous is that modern CPUs have a memory cache: accessing infrequently used information incurs a large timing penalty, revealing some information about the frequency of use of memory blocks. Cryptographic code designed to resist cache attacks attempts to use memory in only a predictable fashion (such as accessing only the input, outputs and program data, and doing so according to a fixed pattern). For example, data-dependent <a href="look-up_table" title="wikilink">look-up tables</a> must be avoided because the cache could reveal which part of the look-up table was accessed.</p>

<p>Other partial countermeasures attempt to reduce the amount of information leaked from data-dependent power differences. Some operations use power that is correlated to the number of 1 bits in a secret value. Using a <a href="constant-weight_code" title="wikilink">constant-weight code</a> (such as using <a href="Fredkin_gate" title="wikilink">Fredkin gates</a> or dual-rail encoding) can reduce the leakage of information about the <a href="Hamming_weight" title="wikilink">Hamming weight</a> of the secret value, although exploitable correlations are likely to remain unless the balancing is perfect. This "balanced design" can be approximated in software by manipulating both the data and its complement together.<a class="footnoteRef" href="#fn11" id="fnref11"><sup>11</sup></a></p>

<p>Several "secure CPUs" have been built as <a href="asynchronous_circuit#Asynchronous_CPU" title="wikilink">asynchronous CPUs</a>; they have no global timing reference. While these CPUs were intended to make timing and power attacks more difficult,<a class="footnoteRef" href="#fn12" id="fnref12"><sup>12</sup></a> subsequent research found that timing variations in asynchronous circuits are harder to remove .</p>

<p>A typical example of the second category (decorrelation) is a technique known as <em><a href="blinding_(cryptography)" title="wikilink">blinding</a></em>. In the case of <a href="RSA_(cryptosystem)" title="wikilink">RSA</a> decryption with secret exponent 

<math display="inline" id="Side-channel_attack:0">
 <semantics>
  <mi>d</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>d</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   d
  </annotation>
 </semantics>
</math>

 and corresponding encryption exponent 

<math display="inline" id="Side-channel_attack:1">
 <semantics>
  <mi>e</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>e</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   e
  </annotation>
 </semantics>
</math>

 and modulus 

<math display="inline" id="Side-channel_attack:2">
 <semantics>
  <mi>m</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>m</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   m
  </annotation>
 </semantics>
</math>

, the technique applies as follows (for simplicity, the modular reduction by <em>m</em> is omitted in the formulas): before decrypting, that is, before computing the result of 

<math display="inline" id="Side-channel_attack:3">
 <semantics>
  <msup>
   <mi>y</mi>
   <mi>d</mi>
  </msup>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">superscript</csymbol>
    <ci>y</ci>
    <ci>d</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   y^{d}
  </annotation>
 </semantics>
</math>

 for a given ciphertext 

<math display="inline" id="Side-channel_attack:4">
 <semantics>
  <mi>y</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>y</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   y
  </annotation>
 </semantics>
</math>

, the system picks a random number 

<math display="inline" id="Side-channel_attack:5">
 <semantics>
  <mi>r</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>r</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   r
  </annotation>
 </semantics>
</math>

 and encrypts it with public exponent 

<math display="inline" id="Side-channel_attack:6">
 <semantics>
  <mi>e</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>e</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   e
  </annotation>
 </semantics>
</math>

 to obtain 

<math display="inline" id="Side-channel_attack:7">
 <semantics>
  <msup>
   <mi>r</mi>
   <mi>e</mi>
  </msup>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">superscript</csymbol>
    <ci>r</ci>
    <ci>e</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   r^{e}
  </annotation>
 </semantics>
</math>

. Then, the decryption is done on 

<math display="inline" id="Side-channel_attack:8">
 <semantics>
  <mrow>
   <mi>y</mi>
   <mo>⋅</mo>
   <msup>
    <mi>r</mi>
    <mi>e</mi>
   </msup>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <ci>normal-⋅</ci>
    <ci>y</ci>
    <apply>
     <csymbol cd="ambiguous">superscript</csymbol>
     <ci>r</ci>
     <ci>e</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   y\cdot r^{e}
  </annotation>
 </semantics>
</math>

 to obtain 

<math display="inline" id="Side-channel_attack:9">
 <semantics>
  <mrow>
   <msup>
    <mrow>
     <mo stretchy="false">(</mo>
     <mrow>
      <mi>y</mi>
      <mo>⋅</mo>
      <msup>
       <mi>r</mi>
       <mi>e</mi>
      </msup>
     </mrow>
     <mo stretchy="false">)</mo>
    </mrow>
    <mi>d</mi>
   </msup>
   <mo>=</mo>
   <mrow>
    <msup>
     <mi>y</mi>
     <mi>d</mi>
    </msup>
    <mo>⋅</mo>
    <msup>
     <mi>r</mi>
     <mrow>
      <mi>e</mi>
      <mo>⋅</mo>
      <mi>d</mi>
     </mrow>
    </msup>
   </mrow>
   <mo>=</mo>
   <mrow>
    <msup>
     <mi>y</mi>
     <mi>d</mi>
    </msup>
    <mo>⋅</mo>
    <mi>r</mi>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <and></and>
    <apply>
     <eq></eq>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <apply>
       <ci>normal-⋅</ci>
       <ci>y</ci>
       <apply>
        <csymbol cd="ambiguous">superscript</csymbol>
        <ci>r</ci>
        <ci>e</ci>
       </apply>
      </apply>
      <ci>d</ci>
     </apply>
     <apply>
      <ci>normal-⋅</ci>
      <apply>
       <csymbol cd="ambiguous">superscript</csymbol>
       <ci>y</ci>
       <ci>d</ci>
      </apply>
      <apply>
       <csymbol cd="ambiguous">superscript</csymbol>
       <ci>r</ci>
       <apply>
        <ci>normal-⋅</ci>
        <ci>e</ci>
        <ci>d</ci>
       </apply>
      </apply>
     </apply>
    </apply>
    <apply>
     <eq></eq>
     <share href="#.cmml">
     </share>
     <apply>
      <ci>normal-⋅</ci>
      <apply>
       <csymbol cd="ambiguous">superscript</csymbol>
       <ci>y</ci>
       <ci>d</ci>
      </apply>
      <ci>r</ci>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   {(y\cdot r^{e})}^{d}=y^{d}\cdot r^{e\cdot d}=y^{d}\cdot r
  </annotation>
 </semantics>
</math>

. Since the decrypting system chose 

<math display="inline" id="Side-channel_attack:10">
 <semantics>
  <mi>r</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>r</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   r
  </annotation>
 </semantics>
</math>

, it can compute its inverse modulo 

<math display="inline" id="Side-channel_attack:11">
 <semantics>
  <mi>m</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>m</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   m
  </annotation>
 </semantics>
</math>

 to cancel out the factor 

<math display="inline" id="Side-channel_attack:12">
 <semantics>
  <mi>r</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>r</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   r
  </annotation>
 </semantics>
</math>

 in the result and obtain 

<math display="inline" id="Side-channel_attack:13">
 <semantics>
  <msup>
   <mi>y</mi>
   <mi>d</mi>
  </msup>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">superscript</csymbol>
    <ci>y</ci>
    <ci>d</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   y^{d}
  </annotation>
 </semantics>
</math>

, the actual result of the decryption. For attacks that require collecting side-channel information from operations with data <em>controlled by the attacker</em>, blinding is an effective countermeasure, since the actual operation is executed on a randomized version of the data, over which the attacker has no control or even knowledge.</p>
<h2 id="see-also">See also</h2>
<ul>
<li><a href="Differential_power_analysis" title="wikilink">Differential power analysis</a></li>
<li><a href="Brute-force_attack" title="wikilink">Brute-force attack</a></li>
<li><a href="Computer_surveillance" title="wikilink">Computer surveillance</a></li>
<li><a href="Covert_channel" title="wikilink">Covert channel</a></li>
</ul>
<h2 id="references">References</h2>
<h2 id="further-reading">Further reading</h2>
<dl>
<dt>Books</dt>
</dl>
<ul>
<li></li>
</ul>
<dl>
<dt>Articles</dt>
</dl>
<ul>
<li><a href="http://www.cryptography.com/public/pdf/DPA.pdf">1</a>, Differential Power Analysis, P. Kocher, J. Jaffe, B. Jun, appeared in CRYPTO'99.</li>
<li><a href="http://www.cryptography.com/public/pdf/TimingAttacks.pdf">2</a>, Timing Attacks on Implementations of Diffie-Hellman, RSA, DSS, and Other Systems, P. Kocher.</li>
<li><a href="http://www.cryptography.com/dpa/technical/">Cryptography.com</a>, Introduction to Differential Power Analysis and Related attacks, 1998, P Kocher, J Jaffe, B Jun.</li>
<li><a href="http://csrc.nist.gov/encryption/aes/round1/conf2/papers/chari.pdf">Nist.gov</a>, a cautionary Note Regarding Evaluation of AES Candidates on Smart Cards, 1999, S Chari, C Jutla, J R Rao, P Rohatgi</li>
<li>DES and Differential Power Analysis, L Goubin and J Patarin, in Proceedings of CHES'99, Lecture Notes in Computer Science Nr 1717, Springer-Verlag</li>
<li></li>
<li></li>
<li></li>
</ul>
<h2 id="external-links">External links</h2>
<ul>
<li><a href="http://www.scientificamerican.com/article.cfm?id=hackers-can-steal-from-reflections">New side channel attack techniques</a></li>
<li><a href="http://cosade.org/">COSADE Workshop</a> International Workshop on Constructive Side-Channel Analysis and Secure Design</li>
</ul>

<p>"</p>

<p><a href="Category:Cryptographic_attacks" title="wikilink">Category:Cryptographic attacks</a> <a href="Category:Side_channel_attacks" title="wikilink"> </a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1"><a href="#fnref1">↩</a></li>
<li id="fn2"><a href="#fnref2">↩</a></li>
<li id="fn3"><a href="#fnref3">↩</a></li>
<li id="fn4"><a href="#fnref4">↩</a></li>
<li id="fn5"><a href="http://cryptome.org/tempest-time.htm">Cryptome.org</a><a href="#fnref5">↩</a></li>
<li id="fn6"><a href="#fnref6">↩</a></li>
<li id="fn7"><a href="http://www.era.lib.ed.ac.uk/bitstream/1842/860/1/Spadavecchia_thesis.pdf">"A Network-based Asynchronous Architecture for Cryptographic Devices"</a> by Ljiljana Spadavecchia 2005 in sections "3.2.3 Countermeasures", "3.4.2 Countermeasures", "3.5.6 Countermeasures", "3.5.7 Software countermeasures", "3.5.8 Hardware countermeasures", and "4.10 Side-channel analysis of asynchronous architectures".<a href="#fnref7">↩</a></li>
<li id="fn8"></li>
<li id="fn9"><a href="https://www.cs.berkeley.edu/~daw/papers/pcmodel-long.pdf">"The Program Counter Security Model: Automatic Detection and Removal of Control-Flow Side Channel Attacks"</a> by David Molnar, Matt Piotrowski, David Schultz, David Wagner (2005).<a href="#fnref9">↩</a></li>
<li id="fn10"><a href="https://www.usenix.org/legacy/events/sec05/wips/molnar.pdf">"The Program Counter Security Model: Automatic Detection and Removal of Control-Flow Side Channel Attacks" USENIX Work-in-Progress presentation of paper</a><a href="#fnref10">↩</a></li>
<li id="fn11"></li>
<li id="fn12"></li>
</ol>
</section>
</body>
</html>
