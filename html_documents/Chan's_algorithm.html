<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="28">Chan's algorithm</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>Chan's algorithm</h1>
<hr/>

<p>In <a href="computational_geometry" title="wikilink">computational geometry</a>, <strong>Chan's algorithm</strong>,<a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a> named after <a href="Timothy_M._Chan" title="wikilink">Timothy M. Chan</a>, is an optimal <a href="output-sensitive_algorithm" title="wikilink">output-sensitive algorithm</a> to compute the <a href="convex_hull" title="wikilink">convex hull</a> of a set <em>P</em> of <em>n</em> points, in 2- or 3-dimensional space. The algorithm takes O(<em>n</em> log <em>h</em>) time, where <em>h</em> is the number of vertices of the output (the convex hull). In the planar case, the algorithm combines an O(<em>n</em> log <em>n</em>) algorithm (<a href="Graham_scan" title="wikilink">Graham scan</a>, for example) with <a href="Jarvis_march" title="wikilink">Jarvis march</a>, in order to obtain an optimal O(<em>n</em> log <em>h</em>) time. Chan's algorithm is notable because it is much simpler than the <a href="Kirkpatrick–Seidel_algorithm" title="wikilink">Kirkpatrick–Seidel algorithm</a>, and it naturally extends to 3-dimensional space. This paradigm<a class="footnoteRef" href="#fn2" id="fnref2"><sup>2</sup></a> has been independently developed by Frank Nielsen in his Ph. D. thesis.<a class="footnoteRef" href="#fn3" id="fnref3"><sup>3</sup></a></p>
<h2 id="algorithm">Algorithm</h2>

<p>Initially, we assume that the value of <em>h</em> is known and make a parameter <em>m</em>=<em>h</em>. This assumption is not realistic, but we remove it later. The algorithm starts by arbitrarily partitioning <em>P</em> into at most 1+<em>n</em>/<em>m</em> subsets <em>Q</em> with at most <em>m</em> points each. Then, it computes the convex hull of each subset <em>Q</em> using an O(<em>n</em> log <em>n</em>) algorithm. Note that, as there are O(<em>n</em>/<em>m</em>) subsets of O(<em>m</em>) points each, this phase takes O(<em>n/m</em>)O(<em>m</em> log <em>m</em>) = O(<em>n</em> log <em>m</em>) time.</p>

<p>The second phase consists of executing <a href="Gift_wrapping_algorithm" title="wikilink">Jarvis's march</a> and using the precomputed convex hulls to speed up the execution. At each step in Jarvis's march, we have a point <em>p<sub>i</sub></em> in the convex hull, and need to find a point p<sub>i+1</sub> = <em>f(p<sub>i</sub>,P)</em> such that all other points of <em>P</em> are to the right of the line <em>p<sub>i</sub> p<sub>i+1</sub></em>. If we know the convex hull of a set <em>Q</em> of <em>m</em> points, then we can compute <em>f(p<sub>i</sub>,Q)</em> in O(log <em>m</em>) time, by using <a href="binary_search" title="wikilink">binary search</a>. We can compute <em>f(p<sub>i</sub>,Q)</em> for all the O(<em>n</em>/<em>m</em>) subsets <em>Q</em> in O(<em>n</em>/<em>m</em> log <em>m</em>) time. Then, we can determine <em>f(p<sub>i</sub>,P)</em> using the same technique as normally used in Jarvis's march, but only considering the points that are <em>f(p<sub>i</sub>,Q)</em> for some subset <em>Q</em>. As Jarvis's march repeats this process O(<em>h</em>) times, the second phase also takes O(<em>n</em> log <em>m</em>) time, and if <em>m=h</em>, O(<em>n</em> log <em>h</em>) time.</p>

<p>By running the two phases described above, we can compute the convex hull of <em>n</em> points in O(<em>n</em> log <em>h</em>) time, assuming that we know the value of <em>h</em>. If we make <em>m<h< em="">, ''m="" <em>m</em>="" <em>m</em>)="" <em>m</em>+1="" (but="" (we="" 2="" 5="" a="" abort="" after="" analysis,="" and="" around="" as="" better),="" but="" can="" computing="" constant="" convex="" execution="" for="" hull).="" in="" increase="" initially="" log="" may="" not="" numbers="" o(<em>n</em>="" of="" only="" our="" practice="" set="" small="" spending="" steps,="" the="" therefore="" time="" until="" use="" value="" we="" work=""&gt;h'', in which case we obtain the convex hull as a result.</h<></em></p>

<p>If we increase the value of <em>m</em> too slowly, we may need to repeat the steps mentioned before too many times, and the execution time will be large. On the other hand, if we increase the value of <em>m</em> too quickly, we risk making <em>m</em> much larger than <em>h</em>, also increasing the execution time. Chan's algorithm squares the value of <em>m</em> at each iteration, and makes sure that <em>m</em> is never larger than <em>n</em>. In other words, at iteration <em>t</em> (starting at 0), we have 

<math display="inline" id="Chan's_algorithm:0">
 <semantics>
  <mrow>
   <mi>m</mi>
   <mo>=</mo>
   <mrow>
    <mi>min</mi>
    <mrow>
     <mo stretchy="false">(</mo>
     <mi>n</mi>
     <mo>,</mo>
     <msup>
      <mn>2</mn>
      <msup>
       <mn>2</mn>
       <mi>t</mi>
      </msup>
     </msup>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <ci>m</ci>
    <apply>
     <min></min>
     <ci>n</ci>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <cn type="integer">2</cn>
      <apply>
       <csymbol cd="ambiguous">superscript</csymbol>
       <cn type="integer">2</cn>
       <ci>t</ci>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   m=\min(n,2^{2^{t}})
  </annotation>
 </semantics>
</math>

. The total running time of the algorithm is</p>

<p>

<math display="inline" id="Chan's_algorithm:1">
 <semantics>
  <mrow>
   <mrow>
    <mrow>
     <msubsup>
      <mo largeop="true" symmetric="true">∑</mo>
      <mrow>
       <mi>t</mi>
       <mo>=</mo>
       <mn>0</mn>
      </mrow>
      <mrow>
       <mo stretchy="false">⌈</mo>
       <mrow>
        <mi>log</mi>
        <mrow>
         <mi>log</mi>
         <mi>h</mi>
        </mrow>
       </mrow>
       <mo stretchy="false">⌉</mo>
      </mrow>
     </msubsup>
     <mrow>
      <mi>O</mi>
      <mrow>
       <mo>(</mo>
       <mrow>
        <mi>n</mi>
        <mrow>
         <mi>log</mi>
         <mrow>
          <mo stretchy="false">(</mo>
          <msup>
           <mn>2</mn>
           <msup>
            <mn>2</mn>
            <mi>t</mi>
           </msup>
          </msup>
          <mo stretchy="false">)</mo>
         </mrow>
        </mrow>
       </mrow>
       <mo>)</mo>
      </mrow>
     </mrow>
    </mrow>
    <mo>=</mo>
    <mrow>
     <mi>O</mi>
     <mrow>
      <mo stretchy="false">(</mo>
      <mi>n</mi>
      <mo stretchy="false">)</mo>
     </mrow>
     <mrow>
      <msubsup>
       <mo largeop="true" symmetric="true">∑</mo>
       <mrow>
        <mi>t</mi>
        <mo>=</mo>
        <mn>0</mn>
       </mrow>
       <mrow>
        <mo stretchy="false">⌈</mo>
        <mrow>
         <mi>log</mi>
         <mrow>
          <mi>log</mi>
          <mi>h</mi>
         </mrow>
        </mrow>
        <mo stretchy="false">⌉</mo>
       </mrow>
      </msubsup>
      <mrow>
       <mi>O</mi>
       <mrow>
        <mo stretchy="false">(</mo>
        <msup>
         <mn>2</mn>
         <mi>t</mi>
        </msup>
        <mo stretchy="false">)</mo>
       </mrow>
      </mrow>
     </mrow>
    </mrow>
    <mo>=</mo>
    <mrow>
     <mi>O</mi>
     <mrow>
      <mo>(</mo>
      <mrow>
       <mi>n</mi>
       <mo>⋅</mo>
       <msup>
        <mn>2</mn>
        <mrow>
         <mn>1</mn>
         <mo>+</mo>
         <mrow>
          <mo stretchy="false">⌈</mo>
          <mrow>
           <mi>log</mi>
           <mrow>
            <mi>log</mi>
            <mi>h</mi>
           </mrow>
          </mrow>
          <mo stretchy="false">⌉</mo>
         </mrow>
        </mrow>
       </msup>
      </mrow>
      <mo>)</mo>
     </mrow>
    </mrow>
    <mo>=</mo>
    <mrow>
     <mi>O</mi>
     <mrow>
      <mo stretchy="false">(</mo>
      <mrow>
       <mi>n</mi>
       <mrow>
        <mi>log</mi>
        <mi>h</mi>
       </mrow>
      </mrow>
      <mo stretchy="false">)</mo>
     </mrow>
    </mrow>
   </mrow>
   <mo>.</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <and></and>
    <apply>
     <eq></eq>
     <apply>
      <apply>
       <csymbol cd="ambiguous">superscript</csymbol>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <sum></sum>
        <apply>
         <eq></eq>
         <ci>t</ci>
         <cn type="integer">0</cn>
        </apply>
       </apply>
       <apply>
        <ceiling></ceiling>
        <apply>
         <log></log>
         <apply>
          <log></log>
          <ci>h</ci>
         </apply>
        </apply>
       </apply>
      </apply>
      <apply>
       <times></times>
       <ci>O</ci>
       <apply>
        <times></times>
        <ci>n</ci>
        <apply>
         <log></log>
         <apply>
          <csymbol cd="ambiguous">superscript</csymbol>
          <cn type="integer">2</cn>
          <apply>
           <csymbol cd="ambiguous">superscript</csymbol>
           <cn type="integer">2</cn>
           <ci>t</ci>
          </apply>
         </apply>
        </apply>
       </apply>
      </apply>
     </apply>
     <apply>
      <times></times>
      <ci>O</ci>
      <ci>n</ci>
      <apply>
       <apply>
        <csymbol cd="ambiguous">superscript</csymbol>
        <apply>
         <csymbol cd="ambiguous">subscript</csymbol>
         <sum></sum>
         <apply>
          <eq></eq>
          <ci>t</ci>
          <cn type="integer">0</cn>
         </apply>
        </apply>
        <apply>
         <ceiling></ceiling>
         <apply>
          <log></log>
          <apply>
           <log></log>
           <ci>h</ci>
          </apply>
         </apply>
        </apply>
       </apply>
       <apply>
        <times></times>
        <ci>O</ci>
        <apply>
         <csymbol cd="ambiguous">superscript</csymbol>
         <cn type="integer">2</cn>
         <ci>t</ci>
        </apply>
       </apply>
      </apply>
     </apply>
    </apply>
    <apply>
     <eq></eq>
     <share href="#.cmml">
     </share>
     <apply>
      <times></times>
      <ci>O</ci>
      <apply>
       <ci>normal-⋅</ci>
       <ci>n</ci>
       <apply>
        <csymbol cd="ambiguous">superscript</csymbol>
        <cn type="integer">2</cn>
        <apply>
         <plus></plus>
         <cn type="integer">1</cn>
         <apply>
          <ceiling></ceiling>
          <apply>
           <log></log>
           <apply>
            <log></log>
            <ci>h</ci>
           </apply>
          </apply>
         </apply>
        </apply>
       </apply>
      </apply>
     </apply>
    </apply>
    <apply>
     <eq></eq>
     <share href="#.cmml">
     </share>
     <apply>
      <times></times>
      <ci>O</ci>
      <apply>
       <times></times>
       <ci>n</ci>
       <apply>
        <log></log>
        <ci>h</ci>
       </apply>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \sum_{t=0}^{\lceil\log\log h\rceil}O\left(n\log(2^{2^{t}})\right)=O(n)\sum_{t=%
0}^{\lceil\log\log h\rceil}O(2^{t})=O\left(n\cdot 2^{1+\lceil\log\log h\rceil}%
\right)=O(n\log h).
  </annotation>
 </semantics>
</math>

</p>

<p>To generalize this construction for the 3-dimensional case, an O(<em>n</em> log <em>n</em>) algorithm to compute the 3-dimensional convex hull should be used instead of Graham scan, and a 3-dimensional version of Jarvis's march needs to be used. The time complexity remains O(<em>n</em> log <em>h</em>).</p>
<h2 id="implementation">Implementation</h2>

<p>Chan's paper contains several suggestions that may improve the practical performance of the algorithm, for example:</p>
<ul>
<li>When computing the convex hulls of the subsets, eliminate the points that are not in the convex hull from consideration in subsequent executions.</li>
</ul>
<ul>
<li>The convex hulls of larger point sets can be obtained by merging previously calculated convex hulls, instead of recomputing from scratch.</li>
</ul>
<h2 id="references">References</h2>

<p></p>

<p>"</p>

<p><a href="Category:Convex_hull_algorithms" title="wikilink">Category:Convex hull algorithms</a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1">Timothy M. Chan. "<a href="http://citeseer.ist.psu.edu/181154.html">Optimal output-sensitive convex hull algorithms in two and three dimensions</a>". <em><a href="Discrete_and_Computational_Geometry" title="wikilink">Discrete and Computational Geometry</a></em>, Vol. 16, pp.361–368. 1996.<a href="#fnref1">↩</a></li>
<li id="fn2">Frank Nielsen. "<a href="http://link.springer.com/chapter/10.1007%2F978-3-540-46515-7_21">Grouping and Querying: A Paradigm to Get Output-Sensitive Algorithms</a>". <em><a href="Discrete_and_Computational_Geometry" title="wikilink">Discrete and Computational Geometry</a></em>, LNCS 1763, pp. 250–257, 2000.<a href="#fnref2">↩</a></li>
<li id="fn3">Frank Nielsen. "<a href="http://hal.inria.fr/tel-00832414/">Adaptive Computational Geometry</a>". Ph. D thesis, INRIA, 1996.<a href="#fnref3">↩</a></li>
</ol>
</section>
</body>
</html>
