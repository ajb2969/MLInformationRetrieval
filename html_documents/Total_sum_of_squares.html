<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="747">Total sum of squares</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>Total sum of squares</h1>
<hr/>

<p>In <a href="statistics" title="wikilink">statistical data analysis</a> the <strong>total sum of squares</strong> (TSS or SST) is a quantity that appears as part of a standard way of presenting results of such analyses. It is defined as being the sum, over all observations, of the squared differences of each observation from the overall <a class="uri" href="mean" title="wikilink">mean</a>.<a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a></p>

<p>In <a href="statistics" title="wikilink">statistical</a> <a href="linear_model" title="wikilink">linear models</a>, (particularly in standard <a href="regression_model" title="wikilink">regression models</a>), the <strong>TSS</strong> is the <a href="summation" title="wikilink">sum</a> of the <a href="square_(algebra)" title="wikilink">squares</a> of the difference of the dependent variable and its <a class="uri" href="mean" title="wikilink">mean</a>:</p>

<p>

<math display="block" id="Total_sum_of_squares:0">
 <semantics>
  <mrow>
   <mi>TSS</mi>
   <mo>=</mo>
   <mrow>
    <munderover>
     <mo largeop="true" movablelimits="false" symmetric="true">âˆ‘</mo>
     <mrow>
      <mi>i</mi>
      <mo>=</mo>
      <mn>1</mn>
     </mrow>
     <mi>n</mi>
    </munderover>
    <msup>
     <mrow>
      <mo>(</mo>
      <mrow>
       <msub>
        <mi>y</mi>
        <mi>i</mi>
       </msub>
       <mo>-</mo>
       <mover accent="true">
        <mi>y</mi>
        <mo stretchy="false">Â¯</mo>
       </mover>
      </mrow>
      <mo>)</mo>
     </mrow>
     <mn>2</mn>
    </msup>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <ci>TSS</ci>
    <apply>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <sum></sum>
       <apply>
        <eq></eq>
        <ci>i</ci>
        <cn type="integer">1</cn>
       </apply>
      </apply>
      <ci>n</ci>
     </apply>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <apply>
       <minus></minus>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <ci>y</ci>
        <ci>i</ci>
       </apply>
       <apply>
        <ci>normal-Â¯</ci>
        <ci>y</ci>
       </apply>
      </apply>
      <cn type="integer">2</cn>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \mathrm{TSS}=\sum_{i=1}^{n}\left(y_{i}-\bar{y}\right)^{2}
  </annotation>
 </semantics>
</math>

</p>

<p>where 

<math display="inline" id="Total_sum_of_squares:1">
 <semantics>
  <mover accent="true">
   <mi>y</mi>
   <mo stretchy="false">Â¯</mo>
  </mover>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <ci>normal-Â¯</ci>
    <ci>y</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \bar{y}
  </annotation>
 </semantics>
</math>

 is the mean.</p>

<p>For wide classes of linear models, the total sum of squares equals the <a href="explained_sum_of_squares" title="wikilink">explained sum of squares</a> plus the <a href="residual_sum_of_squares" title="wikilink">residual sum of squares</a>. For a proof of this in the multivariate OLS case, see <a href="Explained_sum_of_squares#Partitioning_in_the_general_OLS_model" title="wikilink">partitioning in the general OLS model</a>.</p>

<p>In <a href="analysis_of_variance" title="wikilink">analysis of variance</a> (ANOVA) the total sum of squares is the sum of the so-called "within-samples" sum of squares and "between-samples" sum of squares, i.e., partitioning of the sum of squares. In <a href="multivariate_analysis_of_variance" title="wikilink">multivariate analysis of variance</a> (MANOVA) the following equation applies<a class="footnoteRef" href="#fn2" id="fnref2"><sup>2</sup></a></p>

<p>

<math display="block" id="Total_sum_of_squares:2">
 <semantics>
  <mrow>
   <mrow>
    <mi>ğ“</mi>
    <mo>=</mo>
    <mrow>
     <mi>ğ–</mi>
     <mo>+</mo>
     <mi>ğ</mi>
    </mrow>
   </mrow>
   <mo>,</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <ci>ğ“</ci>
    <apply>
     <plus></plus>
     <ci>ğ–</ci>
     <ci>ğ</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \mathbf{T}=\mathbf{W}+\mathbf{B},
  </annotation>
 </semantics>
</math>

 where <strong>T</strong> is the total sum of squares and products (SSP) <a href="Matrix_(mathematics)" title="wikilink">matrix</a>, <strong>W</strong> is the within-samples SSP matrix and <strong>B</strong> is the between-samples SSP matrix. Similar terminology may also be used in <a href="linear_discriminant_analysis" title="wikilink">linear discriminant analysis</a>, where <strong>W</strong> and <strong>B</strong> are respectively referred to as the within-groups and between-groups SSP matrics.<a class="footnoteRef" href="#fn3" id="fnref3"><sup>3</sup></a></p>
<h2 id="see-also">See also</h2>
<ul>
<li><a href="Sum_of_squares_(statistics)" title="wikilink">Sum of squares (statistics)</a></li>
<li><a href="Lack-of-fit_sum_of_squares" title="wikilink">Lack-of-fit sum of squares</a></li>
</ul>
<h2 id="references">References</h2>

<p>"</p>

<p><a href="Category:Regression_analysis" title="wikilink">Category:Regression analysis</a> <a href="Category:Least_squares" title="wikilink">Category:Least squares</a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1">Everitt, B.S. (2002) <em>The Cambridge Dictionary of Statistics</em>, CUP, ISBN 0-521-81099-X<a href="#fnref1">â†©</a></li>
<li id="fn2"> Especially chapters 11 and 12.<a href="#fnref2">â†©</a></li>
<li id="fn3"></li>
</ol>
</section>
</body>
</html>
