<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="1009">Cover's theorem</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>Cover's theorem</h1>
<hr/>

<p>Cover's Theorem is a statement in <a href="computational_learning_theory" title="wikilink">computational learning theory</a> and is one of the primary theoretical motivations for the use of non-linear <a href="kernel_methods" title="wikilink">kernel methods</a> in <a href="machine_learning" title="wikilink">machine learning</a> applications. The theorem states that given a set of training data that is not <a href="linearly_separable" title="wikilink">linearly separable</a>, one can with high probability transform it into a training set that is linearly separable by projecting it into a higher-dimensional space via some non-linear transformation.</p>

<p>The <a href="mathematical_proof" title="wikilink">proof</a> is easy. A <a href="map_(mathematics)" title="wikilink">deterministic mapping</a> may be used. Indeed, suppose there are 

<math display="inline" id="Cover's_theorem:0">
 <semantics>
  <mi>n</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>n</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   n
  </annotation>
 </semantics>
</math>

 samples. Lift them onto the vertices of the <a class="uri" href="simplex" title="wikilink">simplex</a> in the 

<math display="inline" id="Cover's_theorem:1">
 <semantics>
  <mrow>
   <mi>n</mi>
   <mo>-</mo>
   <mn>1</mn>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <minus></minus>
    <ci>n</ci>
    <cn type="integer">1</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   n-1
  </annotation>
 </semantics>
</math>

 dimensional real space. Every <a href="partition_of_a_set" title="wikilink">partition</a> of the samples into two sets is separable by a <a href="linear_separability" title="wikilink">linear separator</a>. QED.</p>
<h2 id="references">References</h2>
<ul>
<li></li>
</ul>
<ul>
<li></li>
</ul>
<ul>
<li>Mehrotra, K., Mohan, C.K., Ranka, S. (1997) <em>Elements of artificial neural networks</em>, 2nd edition. MIT Press. (Section 3.5) ISBN 0-262-13328-8 [<a class="uri" href="http://books.google.co.uk/books?id=6d68Y4Wq_R4C&amp;pg">http://books.google.co.uk/books?id=6d68Y4Wq_R4C&amp;pg;</a>;=PA88&amp;lpg;=PA88&amp;dq;=Cover's+theorem&amp;source;=bl&amp;ots;=6pEdU0CYz4&amp;sig;=V2FqwVwkYaDQgmUNk22XEjnQFpw&amp;hl;=en&amp;ei;=mYdFTNqTMpHQjAfJw5j1Bg&amp;sa;=X&amp;oi;=book_result&amp;ct;=result&amp;resnum;=7&amp;ved;=0CDAQ6AEwBg#v=onepage&amp;q;=Cover's%20theorem&amp;f;=false Google books]</li>
</ul>

<p>"</p>

<p><a href="Category:Computational_learning_theory" title="wikilink">Category:Computational learning theory</a> <a href="Category:Statistical_classification" title="wikilink">Category:Statistical classification</a> <a href="Category:Artificial_neural_networks" title="wikilink">Category:Artificial neural networks</a></p>
</body>
</html>
