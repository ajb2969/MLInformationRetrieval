<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="207">Markov process</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>Markov process</h1>
<hr/>
<figure><b>(Figure)</b>
<figcaption>Markov process example</figcaption>
</figure>

<p>In <a href="probability_theory" title="wikilink">probability theory</a> and <a class="uri" href="statistics" title="wikilink">statistics</a>, a <strong>Markov process</strong> or <strong>Markoff process</strong>, named after the Russian mathematician <a href="Andrey_Markov" title="wikilink">Andrey Markov</a>, is a <a href="stochastic_process" title="wikilink">stochastic process</a> that satisfies the <a href="Markov_property" title="wikilink">Markov property</a>. A Markov process can be thought of as 'memoryless': loosely speaking, a process satisfies the Markov property if one can make predictions for the future of the process based solely on its present state just as well as one could knowing the process's full history. i.e., <a href="conditional_probability" title="wikilink">conditional</a> on the present state of the system, its future and past are <a href="Independence_(probability_theory)" title="wikilink">independent</a>.<a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a></p>
<h2 id="introduction">Introduction</h2>

<p>A Markov process is a stochastic model that has the <a href="Markov_property" title="wikilink">Markov property</a>. It can be used to model a random system that changes states according to a transition rule that only depends on the current state. This article describes the Markov process in a very general sense, which is a concept that is usually specified further. Particularly, the system's <a href="state_space" title="wikilink">state space</a> and time parameter index needs to be specified. The following table gives an overview of the different instances of Markov processes for different levels of state space generality and for discrete time vs. continuous time.</p>
<table>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">
<p>Countable state space</p></th>
<th style="text-align: left;">
<p>Continuous or general state space</p></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">
<p>Discrete-time</p></td>
<td style="text-align: left;">
<p><a href="Markov_chain" title="wikilink">Markov chain</a> on a countable or finite state space</p></td>
<td style="text-align: left;">
<p><a href="Harris_chain" title="wikilink">Harris chain</a> (Markov chain on a general state space)</p></td>
</tr>
<tr class="even">
<td style="text-align: left;">
<p>Continuous-time</p></td>
<td style="text-align: left;">
<p><a href="Continuous-time_Markov_process" title="wikilink">Continuous-time Markov process</a></p></td>
<td style="text-align: left;">
<p>Any <a href="continuous_stochastic_process" title="wikilink">continuous stochastic process</a> with the Markov property, e.g. the <a href="Wiener_process" title="wikilink">Wiener process</a></p></td>
</tr>
</tbody>
</table>

<p>Note that there is no definitive agreement in literature on the use of some of the terms that signify special cases of Markov processes. For example, often the term "Markov chain" is used to indicate a Markov process which has a finite or countable <a class="uri" href="state-space" title="wikilink">state-space</a>, but Markov chains on a general state space fall under the same description. Similarly, a Markov chain would usually be defined for a discrete set of times (i.e. a discrete-time Markov chain)<a class="footnoteRef" href="#fn2" id="fnref2"><sup>2</sup></a> although some authors use the same terminology where "time" can take continuous values.<a class="footnoteRef" href="#fn3" id="fnref3"><sup>3</sup></a> In addition, there are other extensions of Markov processes that are referred to as such but do not necessarily fall within any of these four categories (see <a href="Markov_model" title="wikilink">Markov model</a>). Moreover, the time index need not necessarily be real-valued; like with the state space, there are conceivable processes that move through index sets with other mathematical constructs. Notice that the general state space continuous-time Markov chain is general to such a degree that it has no designated term.</p>

<p>Markov processes arise in probability and statistics in one of two ways. A <a href="stochastic_process" title="wikilink">stochastic process</a>, defined via a separate argument, may be shown mathematically to have the <a href="Markov_property" title="wikilink">Markov property</a>, and as a consequence to have the properties that can be deduced from this for all Markov processes. Alternately, in modelling a process, one may assume the process to be Markov, and take this as the basis for a construction. In modelling terms, assuming that the Markov property holds is one of a limited number of simple ways of introducing statistical dependence into a model for a stochastic process in such a way that allows the strength of dependence at different lags to decline as the lag increases.</p>
<h2 id="markov-property">Markov property</h2>
<h3 id="the-general-case">The general case</h3>

<p>Let 

<math display="inline" id="Markov_process:0">
 <semantics>
  <mrow>
   <mo stretchy="false">(</mo>
   <mi mathvariant="normal">Œ©</mi>
   <mo>,</mo>
   <mi class="ltx_font_mathcaligraphic">‚Ñ±</mi>
   <mo>,</mo>
   <mi>‚Ñô</mi>
   <mo stretchy="false">)</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <vector>
    <ci>normal-Œ©</ci>
    <ci>‚Ñ±</ci>
    <ci>‚Ñô</ci>
   </vector>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   (\Omega,\mathcal{F},\mathbb{P})
  </annotation>
 </semantics>
</math>

 be a <a href="probability_space" title="wikilink">probability space</a> with a <a href="Filtration_(mathematics)#Measure_theory" title="wikilink">filtration</a> 

<math display="inline" id="Markov_process:1">
 <semantics>
  <mrow>
   <mo stretchy="false">(</mo>
   <mrow>
    <mrow>
     <msub>
      <mi class="ltx_font_mathcaligraphic">‚Ñ±</mi>
      <mi>t</mi>
     </msub>
     <mo rspace="7.5pt">,</mo>
     <mi>t</mi>
    </mrow>
    <mo>‚àà</mo>
    <mi>T</mi>
   </mrow>
   <mo stretchy="false">)</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <in></in>
    <list>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>‚Ñ±</ci>
      <ci>t</ci>
     </apply>
     <ci>t</ci>
    </list>
    <ci>T</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   (\mathcal{F}_{t},\ t\in T)
  </annotation>
 </semantics>
</math>

, for some (<a href="totally_ordered" title="wikilink">totally ordered</a>) index set 

<math display="inline" id="Markov_process:2">
 <semantics>
  <mi>T</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>T</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   T
  </annotation>
 </semantics>
</math>

; and let 

<math display="inline" id="Markov_process:3">
 <semantics>
  <mrow>
   <mo stretchy="false">(</mo>
   <mi>S</mi>
   <mo>,</mo>
   <mi class="ltx_font_mathcaligraphic">ùíÆ</mi>
   <mo stretchy="false">)</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <interval closure="open">
    <ci>S</ci>
    <ci>ùíÆ</ci>
   </interval>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   (S,\mathcal{S})
  </annotation>
 </semantics>
</math>

 be a <a href="measure_space" title="wikilink">measure space</a>. An <em>S</em>-valued stochastic process 

<math display="inline" id="Markov_process:4">
 <semantics>
  <mrow>
   <mi>X</mi>
   <mo>=</mo>
   <mrow>
    <mo stretchy="false">(</mo>
    <msub>
     <mi>X</mi>
     <mi>t</mi>
    </msub>
    <mo rspace="7.5pt">,</mo>
    <mi>t</mi>
    <mo>‚àà</mo>
    <mi>T</mi>
    <mo stretchy="false">)</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <cerror>
    <csymbol cd="ambiguous">fragments</csymbol>
    <csymbol cd="unknown">X</csymbol>
    <eq></eq>
    <cerror>
     <csymbol cd="ambiguous">fragments</csymbol>
     <ci>normal-(</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>X</ci>
      <ci>t</ci>
     </apply>
     <ci>normal-,</ci>
     <csymbol cd="unknown">t</csymbol>
     <in></in>
     <csymbol cd="unknown">T</csymbol>
     <ci>normal-)</ci>
    </cerror>
   </cerror>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   X=(X_{t},\ t\in T)
  </annotation>
 </semantics>
</math>

 adapted to the filtration is said to possess the <strong>Markov property</strong> with respect to the 

<math display="inline" id="Markov_process:5">
 <semantics>
  <mrow>
   <mo stretchy="false">{</mo>
   <msub>
    <mi class="ltx_font_mathcaligraphic">‚Ñ±</mi>
    <mi>t</mi>
   </msub>
   <mo stretchy="false">}</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <set>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>‚Ñ±</ci>
     <ci>t</ci>
    </apply>
   </set>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \{\mathcal{F}_{t}\}
  </annotation>
 </semantics>
</math>

 if, for each 

<math display="inline" id="Markov_process:6">
 <semantics>
  <mrow>
   <mi>A</mi>
   <mo>‚àà</mo>
   <mi class="ltx_font_mathcaligraphic">ùíÆ</mi>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <in></in>
    <ci>A</ci>
    <ci>ùíÆ</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   A\in\mathcal{S}
  </annotation>
 </semantics>
</math>

 and each 

<math display="inline" id="Markov_process:7">
 <semantics>
  <mrow>
   <mrow>
    <mi>s</mi>
    <mo>,</mo>
    <mi>t</mi>
   </mrow>
   <mo>‚àà</mo>
   <mi>T</mi>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <in></in>
    <list>
     <ci>s</ci>
     <ci>t</ci>
    </list>
    <ci>T</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   s,t\in T
  </annotation>
 </semantics>
</math>

 with <em>s</em> \mathbb{P}(X_t \in A |\mathcal{F}_s) = \mathbb{P}(X_t \in A| X_s).<a class="footnoteRef" href="#fn4" id="fnref4"><sup>4</sup></a></p>

<p>A <strong>Markov process</strong> is a stochastic process which satisfies the Markov property with respect to its <a href="Stochastic_process#Natural_filtration" title="wikilink">natural filtration</a>.</p>
<h3 id="for-discrete-time-markov-chains">For discrete-time Markov chains</h3>

<p>In the case where 

<math display="inline" id="Markov_process:8">
 <semantics>
  <mi>S</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>S</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   S
  </annotation>
 </semantics>
</math>

 is a discrete set with the <a href="Sigma-algebra#Examples" title="wikilink">discrete sigma algebra</a> and 

<math display="inline" id="Markov_process:9">
 <semantics>
  <mrow>
   <mi>T</mi>
   <mo>=</mo>
   <mi>‚Ñï</mi>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <ci>T</ci>
    <ci>‚Ñï</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   T=\mathbb{N}
  </annotation>
 </semantics>
</math>

, this can be reformulated as follows:</p>

<p>

<math display="block" id="Markov_process:10">
 <semantics>
  <mrow>
   <mi>‚Ñô</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <msub>
     <mi>X</mi>
     <mi>n</mi>
    </msub>
    <mo>=</mo>
    <msub>
     <mi>x</mi>
     <mi>n</mi>
    </msub>
    <mo stretchy="false">|</mo>
    <msub>
     <mi>X</mi>
     <mrow>
      <mi>n</mi>
      <mo>-</mo>
      <mn>1</mn>
     </mrow>
    </msub>
    <mo>=</mo>
    <msub>
     <mi>x</mi>
     <mrow>
      <mi>n</mi>
      <mo>-</mo>
      <mn>1</mn>
     </mrow>
    </msub>
    <mo>,</mo>
    <msub>
     <mi>X</mi>
     <mrow>
      <mi>n</mi>
      <mo>-</mo>
      <mn>2</mn>
     </mrow>
    </msub>
    <mo>=</mo>
    <msub>
     <mi>x</mi>
     <mrow>
      <mi>n</mi>
      <mo>-</mo>
      <mn>2</mn>
     </mrow>
    </msub>
    <mo>,</mo>
    <mi mathvariant="normal">‚Ä¶</mi>
    <mo>,</mo>
    <msub>
     <mi>X</mi>
     <mn>0</mn>
    </msub>
    <mo>=</mo>
    <msub>
     <mi>x</mi>
     <mn>0</mn>
    </msub>
    <mo stretchy="false">)</mo>
   </mrow>
   <mo>=</mo>
   <mi>‚Ñô</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <msub>
     <mi>X</mi>
     <mi>n</mi>
    </msub>
    <mo>=</mo>
    <msub>
     <mi>x</mi>
     <mi>n</mi>
    </msub>
    <mo stretchy="false">|</mo>
    <msub>
     <mi>X</mi>
     <mrow>
      <mi>n</mi>
      <mo>-</mo>
      <mn>1</mn>
     </mrow>
    </msub>
    <mo>=</mo>
    <msub>
     <mi>x</mi>
     <mrow>
      <mi>n</mi>
      <mo>-</mo>
      <mn>1</mn>
     </mrow>
    </msub>
    <mo stretchy="false">)</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <cerror>
    <csymbol cd="ambiguous">fragments</csymbol>
    <csymbol cd="unknown">P</csymbol>
    <cerror>
     <csymbol cd="ambiguous">fragments</csymbol>
     <ci>normal-(</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>X</ci>
      <ci>n</ci>
     </apply>
     <eq></eq>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>x</ci>
      <ci>n</ci>
     </apply>
     <ci>normal-|</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>X</ci>
      <apply>
       <minus></minus>
       <ci>n</ci>
       <cn type="integer">1</cn>
      </apply>
     </apply>
     <eq></eq>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>x</ci>
      <apply>
       <minus></minus>
       <ci>n</ci>
       <cn type="integer">1</cn>
      </apply>
     </apply>
     <ci>normal-,</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>X</ci>
      <apply>
       <minus></minus>
       <ci>n</ci>
       <cn type="integer">2</cn>
      </apply>
     </apply>
     <eq></eq>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>x</ci>
      <apply>
       <minus></minus>
       <ci>n</ci>
       <cn type="integer">2</cn>
      </apply>
     </apply>
     <ci>normal-,</ci>
     <ci>normal-‚Ä¶</ci>
     <ci>normal-,</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>X</ci>
      <cn type="integer">0</cn>
     </apply>
     <eq></eq>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>x</ci>
      <cn type="integer">0</cn>
     </apply>
     <ci>normal-)</ci>
    </cerror>
    <eq></eq>
    <csymbol cd="unknown">P</csymbol>
    <cerror>
     <csymbol cd="ambiguous">fragments</csymbol>
     <ci>normal-(</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>X</ci>
      <ci>n</ci>
     </apply>
     <eq></eq>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>x</ci>
      <ci>n</ci>
     </apply>
     <ci>normal-|</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>X</ci>
      <apply>
       <minus></minus>
       <ci>n</ci>
       <cn type="integer">1</cn>
      </apply>
     </apply>
     <eq></eq>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>x</ci>
      <apply>
       <minus></minus>
       <ci>n</ci>
       <cn type="integer">1</cn>
      </apply>
     </apply>
     <ci>normal-)</ci>
    </cerror>
   </cerror>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \mathbb{P}(X_{n}=x_{n}|X_{n-1}=x_{n-1},X_{n-2}=x_{n-2},\dots,X_{0}=x_{0})=%
\mathbb{P}(X_{n}=x_{n}|X_{n-1}=x_{n-1})
  </annotation>
 </semantics>
</math>

.</p>
<h2 id="examples">Examples</h2>
<h3 id="gambling">Gambling</h3>

<p>Suppose that you start with $10, and you wager $1 on an unending, fair, coin toss indefinitely, or until you lose all of your money. If 

<math display="inline" id="Markov_process:11">
 <semantics>
  <msub>
   <mi>X</mi>
   <mi>n</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>X</ci>
    <ci>n</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   X_{n}
  </annotation>
 </semantics>
</math>

 represents the number of dollars you have after <em>n</em> tosses, with 

<math display="inline" id="Markov_process:12">
 <semantics>
  <mrow>
   <msub>
    <mi>X</mi>
    <mn>0</mn>
   </msub>
   <mo>=</mo>
   <mn>10</mn>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>X</ci>
     <cn type="integer">0</cn>
    </apply>
    <cn type="integer">10</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   X_{0}=10
  </annotation>
 </semantics>
</math>

, then the sequence 

<math display="inline" id="Markov_process:13">
 <semantics>
  <mrow>
   <mo stretchy="false">{</mo>
   <msub>
    <mi>X</mi>
    <mi>n</mi>
   </msub>
   <mo>:</mo>
   <mrow>
    <mi>n</mi>
    <mo>‚àà</mo>
    <mi>‚Ñï</mi>
   </mrow>
   <mo stretchy="false">}</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="latexml">conditional-set</csymbol>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>X</ci>
     <ci>n</ci>
    </apply>
    <apply>
     <in></in>
     <ci>n</ci>
     <ci>‚Ñï</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \{X_{n}:n\in\mathbb{N}\}
  </annotation>
 </semantics>
</math>

 is a Markov process. If I know that you have $12 now, then it would be expected that with even odds, you will either have $11 or $13 after the next toss. This guess is not improved by the added knowledge that you started with $10, then went up to $11, down to $10, up to $11, and then to $12.</p>

<p>The process described here is a Markov chain on a countable state space that follows a random walk.</p>
<h3 id="a-birth-death-process">A birth-death process</h3>

<p>Suppose that you are popping one hundred kernels of popcorn, and each kernel will pop at an independent, <a href="exponential_distribution" title="wikilink">exponentially-distributed</a> time. Let 

<math display="inline" id="Markov_process:14">
 <semantics>
  <msub>
   <mi>X</mi>
   <mi>t</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>X</ci>
    <ci>t</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   X_{t}
  </annotation>
 </semantics>
</math>

 denote the number of kernels which have popped up to time <em>t</em>. Then this is a <a href="continuous-time_Markov_process" title="wikilink">continuous-time Markov process</a>. If after some amount of time, I want to guess how many kernels will pop in the next second, I need only to know how many kernels have popped so far. It will not help me to know <em>when</em> they popped, so knowing 

<math display="inline" id="Markov_process:15">
 <semantics>
  <msub>
   <mi>X</mi>
   <mi>t</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>X</ci>
    <ci>t</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   X_{t}
  </annotation>
 </semantics>
</math>

 for previous times <em>t</em> will not inform my guess.</p>

<p>The process described here is an approximation of a <a href="Poisson_process" title="wikilink">Poisson process</a> - Poisson processes are also Markov processes.</p>
<h3 id="a-non-markov-example">A non-Markov example</h3>

<p>Suppose that you have a coin purse containing five quarters (each worth 25c), five nickels (each worth 5c) and five dimes (each worth 10c), and one-by-one, you randomly draw coins from the purse and set them on a table. If 

<math display="inline" id="Markov_process:16">
 <semantics>
  <msub>
   <mi>X</mi>
   <mi>n</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>X</ci>
    <ci>n</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   X_{n}
  </annotation>
 </semantics>
</math>

 represents the total value of the coins set on the table after <em>n</em> draws, with 

<math display="inline" id="Markov_process:17">
 <semantics>
  <mrow>
   <msub>
    <mi>X</mi>
    <mn>0</mn>
   </msub>
   <mo>=</mo>
   <mn>0</mn>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>X</ci>
     <cn type="integer">0</cn>
    </apply>
    <cn type="integer">0</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   X_{0}=0
  </annotation>
 </semantics>
</math>

, then the sequence 

<math display="inline" id="Markov_process:18">
 <semantics>
  <mrow>
   <mo stretchy="false">{</mo>
   <msub>
    <mi>X</mi>
    <mi>n</mi>
   </msub>
   <mo>:</mo>
   <mrow>
    <mi>n</mi>
    <mo>‚àà</mo>
    <mi>‚Ñï</mi>
   </mrow>
   <mo stretchy="false">}</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="latexml">conditional-set</csymbol>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>X</ci>
     <ci>n</ci>
    </apply>
    <apply>
     <in></in>
     <ci>n</ci>
     <ci>‚Ñï</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \{X_{n}:n\in\mathbb{N}\}
  </annotation>
 </semantics>
</math>

 is <em>not</em> a Markov process.</p>

<p>To see why this is the case, suppose that in your first six draws, you draw all five nickels, and then a quarter. So 

<math display="inline" id="Markov_process:19">
 <semantics>
  <mrow>
   <msub>
    <mi>X</mi>
    <mn>6</mn>
   </msub>
   <mo>=</mo>
   <mrow>
    <mo>$</mo>
    <mn>0.50</mn>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>X</ci>
     <cn type="integer">6</cn>
    </apply>
    <apply>
     <csymbol cd="latexml">currency-dollar</csymbol>
     <cn type="float">0.50</cn>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   X_{6}=\$0.50
  </annotation>
 </semantics>
</math>

. If we know not just 

<math display="inline" id="Markov_process:20">
 <semantics>
  <msub>
   <mi>X</mi>
   <mn>6</mn>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>X</ci>
    <cn type="integer">6</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   X_{6}
  </annotation>
 </semantics>
</math>

, but the earlier values as well, then we can determine which coins have been drawn, and we know that the next coin will not be a nickel, so we can determine that 

<math display="inline" id="Markov_process:21">
 <semantics>
  <mrow>
   <msub>
    <mi>X</mi>
    <mn>7</mn>
   </msub>
   <mo>‚â•</mo>
   <mrow>
    <mo>$</mo>
    <mn>0.60</mn>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <geq></geq>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>X</ci>
     <cn type="integer">7</cn>
    </apply>
    <apply>
     <csymbol cd="latexml">currency-dollar</csymbol>
     <cn type="float">0.60</cn>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   X_{7}\geq\$0.60
  </annotation>
 </semantics>
</math>

 with probability 1. But if we do not know the earlier values, then based only on the value 

<math display="inline" id="Markov_process:22">
 <semantics>
  <msub>
   <mi>X</mi>
   <mn>6</mn>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>X</ci>
    <cn type="integer">6</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   X_{6}
  </annotation>
 </semantics>
</math>

 we might guess that we had drawn four dimes and two nickels, in which case it would certainly be possible to draw another nickel next. Thus, our guesses about 

<math display="inline" id="Markov_process:23">
 <semantics>
  <msub>
   <mi>X</mi>
   <mn>7</mn>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>X</ci>
    <cn type="integer">7</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   X_{7}
  </annotation>
 </semantics>
</math>

 are impacted by our knowledge of values prior to 

<math display="inline" id="Markov_process:24">
 <semantics>
  <msub>
   <mi>X</mi>
   <mn>6</mn>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>X</ci>
    <cn type="integer">6</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   X_{6}
  </annotation>
 </semantics>
</math>

.</p>
<h2 id="markovian-representations">Markovian representations</h2>

<p>In some cases, apparently non-Markovian processes may still have Markovian representations, constructed by expanding the concept of the 'current' and 'future' states. For example, let <em>X</em> be a non-Markovian process. Then define a process <em>Y</em>, such that each state of <em>Y</em> represents a time-interval of states of <em>X</em>. Mathematically, this takes the form:</p>

<p>

<math display="block" id="Markov_process:25">
 <semantics>
  <mrow>
   <mrow>
    <mrow>
     <mi>Y</mi>
     <mrow>
      <mo stretchy="false">(</mo>
      <mi>t</mi>
      <mo stretchy="false">)</mo>
     </mrow>
    </mrow>
    <mo>=</mo>
    <mrow>
     <mo maxsize="120%" minsize="120%">{</mo>
     <mrow>
      <mi>X</mi>
      <mrow>
       <mo stretchy="false">(</mo>
       <mi>s</mi>
       <mo stretchy="false">)</mo>
      </mrow>
     </mrow>
     <mo>:</mo>
     <mrow>
      <mi>s</mi>
      <mo>‚àà</mo>
      <mrow>
       <mo stretchy="false">[</mo>
       <mrow>
        <mi>a</mi>
        <mrow>
         <mo stretchy="false">(</mo>
         <mi>t</mi>
         <mo stretchy="false">)</mo>
        </mrow>
       </mrow>
       <mo>,</mo>
       <mrow>
        <mi>b</mi>
        <mrow>
         <mo stretchy="false">(</mo>
         <mi>t</mi>
         <mo stretchy="false">)</mo>
        </mrow>
       </mrow>
       <mo rspace="4.2pt" stretchy="false">]</mo>
      </mrow>
     </mrow>
     <mo maxsize="120%" minsize="120%">}</mo>
    </mrow>
   </mrow>
   <mo>.</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <times></times>
     <ci>Y</ci>
     <ci>t</ci>
    </apply>
    <apply>
     <csymbol cd="latexml">conditional-set</csymbol>
     <apply>
      <times></times>
      <ci>X</ci>
      <ci>s</ci>
     </apply>
     <apply>
      <in></in>
      <ci>s</ci>
      <interval closure="closed">
       <apply>
        <times></times>
        <ci>a</ci>
        <ci>t</ci>
       </apply>
       <apply>
        <times></times>
        <ci>b</ci>
        <ci>t</ci>
       </apply>
      </interval>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   Y(t)=\big\{X(s):s\in[a(t),b(t)]\,\big\}.
  </annotation>
 </semantics>
</math>

</p>

<p>If <em>Y</em> has the Markov property, then it is a Markovian representation of <em>X</em>.</p>

<p>An example of a non-Markovian process with a Markovian representation is an <a href="Autoregressive_model" title="wikilink">autoregressive</a> <a href="time_series" title="wikilink">time series</a> of order greater than one.</p>
<h2 id="in-popular-culture">In popular culture</h2>

<p>The band <a href="Bad_Religion" title="wikilink">Bad Religion</a> has a song titled "The Markovian Process" on their album <a href="Stranger_than_Fiction_(Bad_Religion_album)" title="wikilink">Stranger Than Fiction</a>.</p>
<h2 id="see-also">See also</h2>
<ul>
<li><a href="Brownian_motion" title="wikilink">Brownian motion</a></li>
<li><a href="Dynamics_of_Markovian_particles" title="wikilink">Dynamics of Markovian particles</a></li>
<li><a href="Examples_of_Markov_chains" title="wikilink">Examples of Markov chains</a></li>
<li><a href="Interacting_particle_system" title="wikilink">Interacting particle system</a></li>
<li><a href="Stochastic_cellular_automaton" title="wikilink">Stochastic cellular automaton</a></li>
<li><a href="Markov_chain" title="wikilink">Markov chain</a></li>
<li><a href="Markov_decision_process" title="wikilink">Markov decision process</a></li>
<li><a href="Markov_model" title="wikilink">Markov model</a></li>
<li><a href="Random_walk" title="wikilink">Random walk</a></li>
<li><a href="Semi-Markov_process" title="wikilink">Semi-Markov process</a></li>
<li><a href="Markov_chain_approximation_method" title="wikilink">Markov chain approximation method</a></li>
</ul>
<h2 id="references">References</h2>
<h2 id="external-links">External links</h2>
<ul>
<li></li>
</ul>

<p><a class="uri" href="de:Markow-Kette" title="wikilink">de:Markow-Kette</a>"</p>

<p><a href="Category:Stochastic_processes" title="wikilink">Category:Stochastic processes</a> <a href="Category:Markov_processes" title="wikilink"> </a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1"><a href="http://www.britannica.com/EBchecked/topic/365797/Markov-process">Markov process (mathematics)</a> - Britannica Online Encyclopedia<a href="#fnref1">‚Ü©</a></li>
<li id="fn2">Everitt,B.S. (2002) <em>The Cambridge Dictionary of Statistics</em>. CUP. ISBN 0-521-81099-X<a href="#fnref2">‚Ü©</a></li>
<li id="fn3">Dodge, Y. <em>The Oxford Dictionary of Statistical Terms</em>, OUP. ISBN 0-19-920613-9<a href="#fnref3">‚Ü©</a></li>
<li id="fn4"><a href="#fnref4">‚Ü©</a></li>
</ol>
</section>
</body>
</html>
