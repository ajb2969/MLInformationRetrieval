<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="1700">Johnson–Lindenstrauss lemma</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>Johnson–Lindenstrauss lemma</h1>
<hr/>

<p>In mathematics, the <strong>Johnson–Lindenstrauss lemma</strong> is a result named after <a href="William_B._Johnson_(mathematician)" title="wikilink">William B. Johnson</a> and <a href="Joram_Lindenstrauss" title="wikilink">Joram Lindenstrauss</a> concerning low-distortion <a href="embedding" title="wikilink">embeddings</a> of points from high-dimensional into low-dimensional <a href="Euclidean_space" title="wikilink">Euclidean space</a>. The lemma states that a small set of points in a high-dimensional space can be embedded into a space of much lower dimension in such a way that distances between the points are nearly preserved. The map used for the embedding is at least <a href="Lipschitz_continuity" title="wikilink">Lipschitz</a>, and can even be taken to be an <a href="orthogonal_projection" title="wikilink">orthogonal projection</a>.</p>

<p>The lemma has uses in <a href="compressed_sensing" title="wikilink">compressed sensing</a>, <a href="manifold_learning" title="wikilink">manifold learning</a>, <a href="dimensionality_reduction" title="wikilink">dimensionality reduction</a>, and <a href="graph_embedding" title="wikilink">graph embedding</a>. Much of the data stored and manipulated on computers, including text and images, can be represented as points in a high-dimensional space (see <a href="vector_space_model" title="wikilink">vector space model</a> for the case of text). However, the essential algorithms for working with such data tend to become bogged down very quickly as dimension increases.<a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a> It is therefore desirable to reduce the dimensionality of the data in a way that preserves its relevant structure. The Johnson–Lindenstrauss lemma is a classic result in this vein.</p>

<p>Also the lemma is tight up to a factor log(1/<em>ε</em>), i.e. there exists a set of points of size <em>m</em> that needs dimension</p>

<p>

<math display="block" id="Johnson–Lindenstrauss_lemma:0">
 <semantics>
  <mrow>
   <mi mathvariant="normal">Ω</mi>
   <mrow>
    <mo>(</mo>
    <mfrac>
     <mrow>
      <mi>log</mi>
      <mrow>
       <mo stretchy="false">(</mo>
       <mi>m</mi>
       <mo stretchy="false">)</mo>
      </mrow>
     </mrow>
     <mrow>
      <msup>
       <mi>ε</mi>
       <mn>2</mn>
      </msup>
      <mrow>
       <mi>log</mi>
       <mrow>
        <mo stretchy="false">(</mo>
        <mrow>
         <mn>1</mn>
         <mo>/</mo>
         <mi>ε</mi>
        </mrow>
        <mo stretchy="false">)</mo>
       </mrow>
      </mrow>
     </mrow>
    </mfrac>
    <mo>)</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <ci>normal-Ω</ci>
    <apply>
     <divide></divide>
     <apply>
      <log></log>
      <ci>m</ci>
     </apply>
     <apply>
      <times></times>
      <apply>
       <csymbol cd="ambiguous">superscript</csymbol>
       <ci>ε</ci>
       <cn type="integer">2</cn>
      </apply>
      <apply>
       <log></log>
       <apply>
        <divide></divide>
        <cn type="integer">1</cn>
        <ci>ε</ci>
       </apply>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \Omega\left(\frac{\log(m)}{\varepsilon^{2}\log(1/\varepsilon)}\right)
  </annotation>
 </semantics>
</math>

</p>

<p>in order to preserve the distances between all pair of points. See 4.</p>
<h2 id="lemma">Lemma</h2>

<p>Given 0 <em>N</em>, and a number <mtpl></mtpl>, there is a linear map <em>ƒ</em> : <strong>R</strong><sup><em>N</em></sup> → <strong>R</strong><sup><em>n</em></sup> such that</p>

<p>

<math display="block" id="Johnson–Lindenstrauss_lemma:1">
 <semantics>
  <mrow>
   <mrow>
    <mrow>
     <mo stretchy="false">(</mo>
     <mrow>
      <mn>1</mn>
      <mo>-</mo>
      <mi>ε</mi>
     </mrow>
     <mo stretchy="false">)</mo>
    </mrow>
    <msup>
     <mrow>
      <mo>∥</mo>
      <mrow>
       <mi>u</mi>
       <mo>-</mo>
       <mi>v</mi>
      </mrow>
      <mo>∥</mo>
     </mrow>
     <mn>2</mn>
    </msup>
   </mrow>
   <mo>≤</mo>
   <msup>
    <mrow>
     <mo>∥</mo>
     <mrow>
      <mrow>
       <mi>f</mi>
       <mrow>
        <mo stretchy="false">(</mo>
        <mi>u</mi>
        <mo stretchy="false">)</mo>
       </mrow>
      </mrow>
      <mo>-</mo>
      <mrow>
       <mi>f</mi>
       <mrow>
        <mo stretchy="false">(</mo>
        <mi>v</mi>
        <mo stretchy="false">)</mo>
       </mrow>
      </mrow>
     </mrow>
     <mo>∥</mo>
    </mrow>
    <mn>2</mn>
   </msup>
   <mo>≤</mo>
   <mrow>
    <mrow>
     <mo stretchy="false">(</mo>
     <mrow>
      <mn>1</mn>
      <mo>+</mo>
      <mi>ε</mi>
     </mrow>
     <mo stretchy="false">)</mo>
    </mrow>
    <msup>
     <mrow>
      <mo>∥</mo>
      <mrow>
       <mi>u</mi>
       <mo>-</mo>
       <mi>v</mi>
      </mrow>
      <mo>∥</mo>
     </mrow>
     <mn>2</mn>
    </msup>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <and></and>
    <apply>
     <leq></leq>
     <apply>
      <times></times>
      <apply>
       <minus></minus>
       <cn type="integer">1</cn>
       <ci>ε</ci>
      </apply>
      <apply>
       <csymbol cd="ambiguous">superscript</csymbol>
       <apply>
        <csymbol cd="latexml">norm</csymbol>
        <apply>
         <minus></minus>
         <ci>u</ci>
         <ci>v</ci>
        </apply>
       </apply>
       <cn type="integer">2</cn>
      </apply>
     </apply>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <apply>
       <csymbol cd="latexml">norm</csymbol>
       <apply>
        <minus></minus>
        <apply>
         <times></times>
         <ci>f</ci>
         <ci>u</ci>
        </apply>
        <apply>
         <times></times>
         <ci>f</ci>
         <ci>v</ci>
        </apply>
       </apply>
      </apply>
      <cn type="integer">2</cn>
     </apply>
    </apply>
    <apply>
     <leq></leq>
     <share href="#.cmml">
     </share>
     <apply>
      <times></times>
      <apply>
       <plus></plus>
       <cn type="integer">1</cn>
       <ci>ε</ci>
      </apply>
      <apply>
       <csymbol cd="ambiguous">superscript</csymbol>
       <apply>
        <csymbol cd="latexml">norm</csymbol>
        <apply>
         <minus></minus>
         <ci>u</ci>
         <ci>v</ci>
        </apply>
       </apply>
       <cn type="integer">2</cn>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   (1-\varepsilon)\|u-v\|^{2}\leq\|f(u)-f(v)\|^{2}\leq(1+\varepsilon)\|u-v\|^{2}
  </annotation>
 </semantics>
</math>

</p>

<p>for all <em>u</em>, <em>v</em> ∈ <em>X</em>.</p>

<p>One proof of the lemma takes <em>ƒ</em> to be a suitable multiple of the orthogonal projection onto a random subspace of dimension <em>n</em> in <strong>R</strong><sup><em>N</em></sup>, and exploits the phenomenon of <a href="concentration_of_measure" title="wikilink">concentration of measure</a>.</p>

<p>Obviously an orthogonal projection will, in general, reduce the average distance between points, but the lemma can be viewed as dealing with <em>relative distances</em>, which do not change under scaling. In a nutshell, you roll the dice and obtain a random projection, which will reduce the average distance, and then you scale up the distances so that the average distance returns to its previous value. If you keep rolling the dice, you will, in polynomial random time, find a projection for which the (scaled) distances satisfy the lemma.</p>
<h2 id="alternate-statement">Alternate Statement</h2>

<p>A related lemma is the distributional JL lemma. This lemma states that for any <em>0&lt;ε</em>,<em>δ</em>k x d'', from which the matrix A is drawn such that for <em>k</em> = <em>O(ε<sup>−2</sup>log(1/δ))</em> and for any unit-length vector <em>x</em> ∈ <strong>R</strong><sup>d</sup>, the claim below holds.<a class="footnoteRef" href="#fn2" id="fnref2"><sup>2</sup></a></p>

<p>

<math display="block" id="Johnson–Lindenstrauss_lemma:2">
 <semantics>
  <mrow>
   <mi>P</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <mo stretchy="false">|</mo>
    <mo>∥</mo>
    <mi>A</mi>
    <mi>x</mi>
    <msubsup>
     <mo>∥</mo>
     <mn>2</mn>
     <mn>2</mn>
    </msubsup>
    <mo>-</mo>
    <mn>1</mn>
    <mo stretchy="false">|</mo>
    <mo>></mo>
    <mi>ε</mi>
    <mo stretchy="false">)</mo>
   </mrow>
   <mo><</mo>
   <mi>δ</mi>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <cerror>
    <csymbol cd="ambiguous">fragments</csymbol>
    <csymbol cd="unknown">P</csymbol>
    <cerror>
     <csymbol cd="ambiguous">fragments</csymbol>
     <ci>normal-(</ci>
     <ci>normal-|</ci>
     <csymbol cd="latexml">parallel-to</csymbol>
     <csymbol cd="unknown">A</csymbol>
     <csymbol cd="unknown">x</csymbol>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <csymbol cd="latexml">parallel-to</csymbol>
       <cn type="integer">2</cn>
      </apply>
      <cn type="integer">2</cn>
     </apply>
     <minus></minus>
     <cn type="integer">1</cn>
     <ci>normal-|</ci>
     <gt></gt>
     <csymbol cd="unknown">ε</csymbol>
     <ci>normal-)</ci>
    </cerror>
    <lt></lt>
    <csymbol cd="unknown">δ</csymbol>
   </cerror>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   P(|\|Ax\|_{2}^{2}-1|>\varepsilon)<\delta
  </annotation>
 </semantics>
</math>

</p>

<p>One can obtain the JL lemma from the distributional version by setting 

<math display="inline" id="Johnson–Lindenstrauss_lemma:3">
 <semantics>
  <mrow>
   <mi>x</mi>
   <mo>=</mo>
   <mrow>
    <mrow>
     <mo stretchy="false">(</mo>
     <mrow>
      <mi>u</mi>
      <mo>-</mo>
      <mi>v</mi>
     </mrow>
     <mo stretchy="false">)</mo>
    </mrow>
    <mo>/</mo>
    <msub>
     <mrow>
      <mo>∥</mo>
      <mrow>
       <mi>u</mi>
       <mo>-</mo>
       <mi>v</mi>
      </mrow>
      <mo>∥</mo>
     </mrow>
     <mn>2</mn>
    </msub>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <ci>x</ci>
    <apply>
     <divide></divide>
     <apply>
      <minus></minus>
      <ci>u</ci>
      <ci>v</ci>
     </apply>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <apply>
       <csymbol cd="latexml">norm</csymbol>
       <apply>
        <minus></minus>
        <ci>u</ci>
        <ci>v</ci>
       </apply>
      </apply>
      <cn type="integer">2</cn>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   x=(u-v)/\|u-v\|_{2}
  </annotation>
 </semantics>
</math>


 and 

<math display="inline" id="Johnson–Lindenstrauss_lemma:4">
 <semantics>
  <mrow>
   <mi>δ</mi>
   <mo><</mo>
   <mrow>
    <mn>1</mn>
    <mo>/</mo>
    <msup>
     <mi>n</mi>
     <mn>2</mn>
    </msup>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <lt></lt>
    <ci>δ</ci>
    <apply>
     <divide></divide>
     <cn type="integer">1</cn>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <ci>n</ci>
      <cn type="integer">2</cn>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \delta<1/n^{2}
  </annotation>
 </semantics>
</math>

 for some pair <em>u,v</em> both in <em>X</em>. Then the JL lemma follows by a union bound over all such pairs.</p>
<h2 id="speeding-up-the-jl-transform">Speeding up the JL Transform</h2>

<p>Given <em>A</em>, computing the matrix vector product takes <em>O(kd)</em> time. There has been a lot of work in coming up with distributions for which the matrix vector product can be computed in less than <em>O(kd)</em> time. There are two major lines of work. The first, <em>Fast Johnson Lindenstrauss Transform</em> (FJLT),<a class="footnoteRef" href="#fn3" id="fnref3"><sup>3</sup></a> was introduced by Ailon and <a href="Bernard_Chazelle" title="wikilink">Chazelle</a> in 2006. Another approach is to build a distribution supported over matrices that are sparse.<a class="footnoteRef" href="#fn4" id="fnref4"><sup>4</sup></a></p>
<h2 id="see-also">See also</h2>
<ul>
<li><a href="Random_projection" title="wikilink">Random projection</a></li>
</ul>
<h2 id="references">References</h2>
<ul>
<li>

<p>.</p></li>
<li>

<p>.</p></li>
<li>

<p>. Journal version of a paper previously appearing at PODC 2001.</p></li>
<li>

<p>.</p></li>
<li>

<p>.</p></li>
</ul>

<p>"</p>

<p><a class="uri" href="Category:Lemmas" title="wikilink">Category:Lemmas</a> <a href="Category:Metric_geometry" title="wikilink">Category:Metric geometry</a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1">For instance, writing about <a href="nearest_neighbor_search" title="wikilink">nearest neighbor search</a> in high-dimensional data sets, <a href="Jon_Kleinberg" title="wikilink">Jon Kleinberg</a> writes: "The more sophisticated algorithms typically achieve a query time that is logarithmic in <em>n</em> at the expense of an exponential dependence on the dimension <em>d</em>; indeed, even the average case analysis of heuristics such as k-d trees reveal an exponential dependence on <em>d</em> in the query time. .<a href="#fnref1">↩</a></li>
<li id="fn2">.<a href="#fnref2">↩</a></li>
<li id="fn3">.<a href="#fnref3">↩</a></li>
<li id="fn4"> Journal version of a paper previously appearing at SODA 2012.<a href="#fnref4">↩</a></li>
</ol>
</section>
</body>
</html>
