<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="480">Information cascade</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>Information cascade</h1>
<hr/>

<p>An <strong>information</strong> (or <strong>informational</strong>) <strong>cascade</strong> occurs when a person observes the actions of others and then—despite possible contradictions in his/her own private information signals—engages in the same acts. A cascade develops, then, when people “abandon their own information in favor of inferences based on earlier people’s actions”.<a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a> Information cascades provide an explanation for how such situations can occur, how likely they are to cascade incorrect information or actions, how such behavior may arise and desist rapidly, and how effective attempts to originate a cascade tend to be under different conditions.<a class="footnoteRef" href="#fn2" id="fnref2"><sup>2</sup></a> By explaining all of these things, the original Independent Cascade model sought to improve on previous models that were unable to explain cascades of irrational behavior, a cascade's fragility, or the short-lived nature of certain cascades.</p>

<p>There are five key conditions in an information cascade model:</p>
<ol>
<li>There is a decision to be made — for example, whether to adopt a new technology, wear a new style of clothing, eat in a new restaurant, or support a particular political position</li>
<li>A limited action space exists (e.g. an adopt/reject decision).<a class="footnoteRef" href="#fn3" id="fnref3"><sup>3</sup></a></li>
<li>People make the decision sequentially, and each person can observe the choices made by those who acted earlier</li>
<li>Each person has some private information that helps guide their decision.</li>
<li>A person can’t directly observe the private information that other people <em>know</em>, but he or she can make inferences about this private information from what they <em>do</em>.</li>
</ol>

<p>One assumption of Information Cascades which has been challenged is the concept that agents always make rational decisions. More social perspectives of cascades, which suggest that agents may act irrationally (e.g., against what they think is optimal) when social pressures are great, exist as complements to the concept of Information Cascades.<a class="footnoteRef" href="#fn4" id="fnref4"><sup>4</sup></a> While competing models exist, it is more often the problem that the concept of an information cascade is conflated with ideas which do not match the two key conditions of the model, such as <a href="social_proof" title="wikilink">social proof</a>, information diffusion,<a class="footnoteRef" href="#fn5" id="fnref5"><sup>5</sup></a> and <a href="social_influence" title="wikilink">social influence</a>. Indeed, the term information cascade has even been used to refer to such processes.<a class="footnoteRef" href="#fn6" id="fnref6"><sup>6</sup></a></p>
<h2 id="basic-model">Basic model</h2>
<h3 id="qualitative-example">Qualitative example</h3>

<p>Information cascades occur when external information obtained from previous participants in an event overrides one's own private signal, irrespective of the correctness of the former over the latter. The experiment conducted in <a class="footnoteRef" href="#fn7" id="fnref7"><sup>7</sup></a> is a useful example of this process. The experiment consisted of two urns labeled A and B. Urn A contains two balls labeled "a" and one labeled "b". Urn B contains one ball labeled "a" and two labeled "b". The urn from which a ball must be drawn during each run is determined randomly and with equal probabilities (from the throw of a dice). The contents of the chosen urn are emptied into a neutral container. The participants are then asked in random order to draw a marble from this container. This entire process may be termed a "run", and a number of such runs are performed.</p>

<p>Each time a participant picks up a marble, he is to decide which urn it belongs to. His decision is then announced for the benefit of the remaining participants in the room. Thus, the (n+1)th participant has information about the decisions made by all the n participants preceding him, and also his private signal which is the label on the ball that he draws during his turn. The experimenters observed that an information cascade was observed in 41 of 56 such runs. This means, in the runs where the cascade occurred, at least one participant gave precedence to earlier decisions over his own private signal. It is possible for such an occurrence to produce the wrong result. This phenomenon is known as "Reverse Cascade".</p>
<h3 id="quantitative-description">Quantitative description</h3>

<p>A person’s signal telling them to accept is denoted as "H" (a high signal, where high signifies he should accept), and a signal telling them not to accept is "L" (a low signal). The model assumes that when the correct decision is to accept, individuals will be more likely to see an "H", and conversely, when the correct decision is to reject, individuals are more likely to see an "L" signal. This is essentially a <a href="conditional_probability" title="wikilink">conditional probability</a> - the probability of "H" when the correct action is to accept, or P[H|A]. Similarly P[L|R] is the probability that an agent gets an "L" signal when the correct action is reject. If these likelihoods are represented by <em>q</em>, then <em>q</em> &gt; 0.5. This is summarized in the table below.<a class="footnoteRef" href="#fn8" id="fnref8"><sup>8</sup></a></p>
<table>
<thead>
<tr class="header">
<th style="text-align: left;">
<p>Agent signal</p></th>
<th style="text-align: left;">
<p>True probability state</p></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">
<p>Reject</p></td>
<td style="text-align: left;">
<p>Accept</p></td>
</tr>
<tr class="even">
<td style="text-align: left;">
<p><em>L</em></p></td>
<td style="text-align: left;">
<p><em>q</em></p></td>
</tr>
<tr class="odd">
<td style="text-align: left;">
<p><em>H</em></p></td>
<td style="text-align: left;">
<p><em>1-q</em></p></td>
</tr>
</tbody>
</table>

<p>The first agent determines whether or not to accept solely based on his own signal. As the model assumes that all agents act rationally, the action (accept or reject) the agent feels is more likely is the action he will choose to take. This decision can be explained using <a href="Bayes_rule" title="wikilink">Bayes rule</a>:</p>

<p>

<math display="inline" id="Information_cascade:0">
 <semantics>
  <mtable>
   <mtr>
    <mtd columnalign="right">
     <mrow>
      <mi>P</mi>
      <mrow>
       <mo>(</mo>
       <mi>A</mi>
       <mo stretchy="false">|</mo>
       <mi>H</mi>
       <mo>)</mo>
      </mrow>
     </mrow>
    </mtd>
    <mtd columnalign="left">
     <mrow>
      <mi></mi>
      <mo>=</mo>
      <mstyle displaystyle="true">
       <mfrac>
        <mrow>
         <mi>P</mi>
         <mrow>
          <mo>(</mo>
          <mi>A</mi>
          <mo>)</mo>
         </mrow>
         <mi>P</mi>
         <mrow>
          <mo>(</mo>
          <mi>H</mi>
          <mo stretchy="false">|</mo>
          <mi>A</mi>
          <mo>)</mo>
         </mrow>
        </mrow>
        <mrow>
         <mi>P</mi>
         <mrow>
          <mo>(</mo>
          <mi>H</mi>
          <mo>)</mo>
         </mrow>
        </mrow>
       </mfrac>
      </mstyle>
     </mrow>
    </mtd>
   </mtr>
   <mtr>
    <mtd></mtd>
    <mtd columnalign="left">
     <mrow>
      <mi></mi>
      <mo>=</mo>
      <mstyle displaystyle="true">
       <mfrac>
        <mrow>
         <mi>P</mi>
         <mrow>
          <mo>(</mo>
          <mi>A</mi>
          <mo>)</mo>
         </mrow>
         <mi>P</mi>
         <mrow>
          <mo>(</mo>
          <mi>H</mi>
          <mo stretchy="false">|</mo>
          <mi>A</mi>
          <mo>)</mo>
         </mrow>
        </mrow>
        <mrow>
         <mi>P</mi>
         <mrow>
          <mo>(</mo>
          <mi>A</mi>
          <mo>)</mo>
         </mrow>
         <mi>P</mi>
         <mrow>
          <mo>(</mo>
          <mi>H</mi>
          <mo stretchy="false">|</mo>
          <mi>A</mi>
          <mo>)</mo>
         </mrow>
         <mo>+</mo>
         <mi>P</mi>
         <mrow>
          <mo>(</mo>
          <mi>R</mi>
          <mo>)</mo>
         </mrow>
         <mi>P</mi>
         <mrow>
          <mo>(</mo>
          <mi>H</mi>
          <mo stretchy="false">|</mo>
          <mi>R</mi>
          <mo>)</mo>
         </mrow>
        </mrow>
       </mfrac>
      </mstyle>
     </mrow>
    </mtd>
   </mtr>
   <mtr>
    <mtd></mtd>
    <mtd columnalign="left">
     <mrow>
      <mi></mi>
      <mo>=</mo>
      <mstyle displaystyle="true">
       <mfrac>
        <mrow>
         <mi>p</mi>
         <mi>q</mi>
        </mrow>
        <mrow>
         <mrow>
          <mi>p</mi>
          <mi>q</mi>
         </mrow>
         <mo>+</mo>
         <mrow>
          <mrow>
           <mo>(</mo>
           <mrow>
            <mn>1</mn>
            <mo>-</mo>
            <mi>p</mi>
           </mrow>
           <mo>)</mo>
          </mrow>
          <mrow>
           <mo>(</mo>
           <mrow>
            <mn>1</mn>
            <mo>-</mo>
            <mi>q</mi>
           </mrow>
           <mo>)</mo>
          </mrow>
         </mrow>
        </mrow>
       </mfrac>
      </mstyle>
     </mrow>
    </mtd>
   </mtr>
   <mtr>
    <mtd></mtd>
    <mtd columnalign="left">
     <mrow>
      <mi></mi>
      <mo>></mo>
      <mi>p</mi>
     </mrow>
    </mtd>
   </mtr>
  </mtable>
  <annotation-xml encoding="MathML-Content">
   <matrix>
    <matrixrow>
     <cerror>
      <csymbol cd="ambiguous">fragments</csymbol>
      <csymbol cd="unknown">P</csymbol>
      <cerror>
       <csymbol cd="ambiguous">fragments</csymbol>
       <ci>normal-(</ci>
       <csymbol cd="unknown">A</csymbol>
       <ci>normal-|</ci>
       <csymbol cd="unknown">H</csymbol>
       <ci>normal-)</ci>
      </cerror>
     </cerror>
     <apply>
      <eq></eq>
      <csymbol cd="latexml">absent</csymbol>
      <apply>
       <divide></divide>
       <cerror>
        <csymbol cd="ambiguous">fragments</csymbol>
        <csymbol cd="unknown">P</csymbol>
        <cerror>
         <csymbol cd="ambiguous">fragments</csymbol>
         <ci>normal-(</ci>
         <csymbol cd="unknown">A</csymbol>
         <ci>normal-)</ci>
        </cerror>
        <csymbol cd="unknown">P</csymbol>
        <cerror>
         <csymbol cd="ambiguous">fragments</csymbol>
         <ci>normal-(</ci>
         <csymbol cd="unknown">H</csymbol>
         <ci>normal-|</ci>
         <csymbol cd="unknown">A</csymbol>
         <ci>normal-)</ci>
        </cerror>
       </cerror>
       <apply>
        <times></times>
        <ci>P</ci>
        <ci>H</ci>
       </apply>
      </apply>
     </apply>
    </matrixrow>
    <matrixrow>
     <cerror>
      <csymbol cd="ambiguous">missing-subexpression</csymbol>
     </cerror>
     <apply>
      <eq></eq>
      <csymbol cd="latexml">absent</csymbol>
      <apply>
       <divide></divide>
       <cerror>
        <csymbol cd="ambiguous">fragments</csymbol>
        <csymbol cd="unknown">P</csymbol>
        <cerror>
         <csymbol cd="ambiguous">fragments</csymbol>
         <ci>normal-(</ci>
         <csymbol cd="unknown">A</csymbol>
         <ci>normal-)</ci>
        </cerror>
        <csymbol cd="unknown">P</csymbol>
        <cerror>
         <csymbol cd="ambiguous">fragments</csymbol>
         <ci>normal-(</ci>
         <csymbol cd="unknown">H</csymbol>
         <ci>normal-|</ci>
         <csymbol cd="unknown">A</csymbol>
         <ci>normal-)</ci>
        </cerror>
       </cerror>
       <cerror>
        <csymbol cd="ambiguous">fragments</csymbol>
        <csymbol cd="unknown">P</csymbol>
        <cerror>
         <csymbol cd="ambiguous">fragments</csymbol>
         <ci>normal-(</ci>
         <csymbol cd="unknown">A</csymbol>
         <ci>normal-)</ci>
        </cerror>
        <csymbol cd="unknown">P</csymbol>
        <cerror>
         <csymbol cd="ambiguous">fragments</csymbol>
         <ci>normal-(</ci>
         <csymbol cd="unknown">H</csymbol>
         <ci>normal-|</ci>
         <csymbol cd="unknown">A</csymbol>
         <ci>normal-)</ci>
        </cerror>
        <plus></plus>
        <csymbol cd="unknown">P</csymbol>
        <cerror>
         <csymbol cd="ambiguous">fragments</csymbol>
         <ci>normal-(</ci>
         <csymbol cd="unknown">R</csymbol>
         <ci>normal-)</ci>
        </cerror>
        <csymbol cd="unknown">P</csymbol>
        <cerror>
         <csymbol cd="ambiguous">fragments</csymbol>
         <ci>normal-(</ci>
         <csymbol cd="unknown">H</csymbol>
         <ci>normal-|</ci>
         <csymbol cd="unknown">R</csymbol>
         <ci>normal-)</ci>
        </cerror>
       </cerror>
      </apply>
     </apply>
    </matrixrow>
    <matrixrow>
     <cerror>
      <csymbol cd="ambiguous">missing-subexpression</csymbol>
     </cerror>
     <apply>
      <eq></eq>
      <csymbol cd="latexml">absent</csymbol>
      <apply>
       <divide></divide>
       <apply>
        <times></times>
        <ci>p</ci>
        <ci>q</ci>
       </apply>
       <apply>
        <plus></plus>
        <apply>
         <times></times>
         <ci>p</ci>
         <ci>q</ci>
        </apply>
        <apply>
         <times></times>
         <apply>
          <minus></minus>
          <cn type="integer">1</cn>
          <ci>p</ci>
         </apply>
         <apply>
          <minus></minus>
          <cn type="integer">1</cn>
          <ci>q</ci>
         </apply>
        </apply>
       </apply>
      </apply>
     </apply>
    </matrixrow>
    <matrixrow>
     <cerror>
      <csymbol cd="ambiguous">missing-subexpression</csymbol>
     </cerror>
     <apply>
      <gt></gt>
      <csymbol cd="latexml">absent</csymbol>
      <ci>p</ci>
     </apply>
    </matrixrow>
   </matrix>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \begin{aligned}\displaystyle P\left(A|H\right)&\displaystyle=\frac{P\left(A%
\right)P\left(H|A\right)}{P\left(H\right)}\\
&\displaystyle=\frac{P\left(A\right)P\left(H|A\right)}{P\left(A\right)P\left(H%
|A\right)+P\left(R\right)P\left(H|R\right)}\\
&\displaystyle=\frac{pq}{pq+\left(1-p\right)\left(1-q\right)}\\
&\displaystyle>p\end{aligned}
  </annotation>
 </semantics>
</math>

</p>

<p>If the agent receives an "H" signal, then the likelihood of accepting is obtained by calculating P[A|H]. The equation says that, by virtue of the fact that <em>q</em> &gt; 0.5, the first agent, acting only on his private signal, will always increase his estimate of <em>p</em> with an "H" signal. Similarly, it can be shown that an agent will always decrease his expectation of <em>p</em> when he receives a low signal. Recalling that, if the value, "V", of accepting is equal to the value of rejecting, then an agent will accept if he believes p &gt;0.5, and reject otherwise. Because this agent started out with the assumption that both accepting and rejecting are equally viable options (p = 0.5), the observation of an "H" signal will allow him to conclude that accepting is the rational choice.</p>

<p>The second agent then considers both the first agent’s decision and his own signal, again in a rational fashion. In general, the <em>n</em>th agent considers the decisions of the previous <em>n-1</em> agents, and his own signal. He makes a decision based on Bayesian reasoning to determine the most rational choice.</p>

<p>

<math display="inline" id="Information_cascade:1">
 <semantics>
  <mrow>
   <mi>P</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <mi>A</mi>
    <mo stretchy="false">|</mo>
    <mtext>Previous</mtext>
    <mo>,</mo>
    <mtext>Personal signal</mtext>
    <mo stretchy="false">)</mo>
   </mrow>
   <mo>=</mo>
   <mfrac>
    <mrow>
     <mi>p</mi>
     <msup>
      <mi>q</mi>
      <mi>a</mi>
     </msup>
     <msup>
      <mrow>
       <mo stretchy="false">(</mo>
       <mrow>
        <mn>1</mn>
        <mo>-</mo>
        <mi>q</mi>
       </mrow>
       <mo stretchy="false">)</mo>
      </mrow>
      <mi>b</mi>
     </msup>
    </mrow>
    <mrow>
     <mrow>
      <mi>p</mi>
      <msup>
       <mi>q</mi>
       <mi>a</mi>
      </msup>
      <msup>
       <mrow>
        <mo stretchy="false">(</mo>
        <mrow>
         <mn>1</mn>
         <mo>-</mo>
         <mi>q</mi>
        </mrow>
        <mo stretchy="false">)</mo>
       </mrow>
       <mi>b</mi>
      </msup>
     </mrow>
     <mo>+</mo>
     <mrow>
      <mrow>
       <mo stretchy="false">(</mo>
       <mrow>
        <mn>1</mn>
        <mo>-</mo>
        <mi>p</mi>
       </mrow>
       <mo stretchy="false">)</mo>
      </mrow>
      <msup>
       <mrow>
        <mo stretchy="false">(</mo>
        <mrow>
         <mn>1</mn>
         <mo>-</mo>
         <mi>q</mi>
        </mrow>
        <mo stretchy="false">)</mo>
       </mrow>
       <mi>a</mi>
      </msup>
      <msup>
       <mi>q</mi>
       <mi>b</mi>
      </msup>
     </mrow>
    </mrow>
   </mfrac>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <cerror>
    <csymbol cd="ambiguous">fragments</csymbol>
    <csymbol cd="unknown">P</csymbol>
    <cerror>
     <csymbol cd="ambiguous">fragments</csymbol>
     <ci>normal-(</ci>
     <csymbol cd="unknown">A</csymbol>
     <ci>normal-|</ci>
     <mtext>Previous</mtext>
     <ci>normal-,</ci>
     <mtext>Personal signal</mtext>
     <ci>normal-)</ci>
    </cerror>
    <eq></eq>
    <apply>
     <divide></divide>
     <apply>
      <times></times>
      <ci>p</ci>
      <apply>
       <csymbol cd="ambiguous">superscript</csymbol>
       <ci>q</ci>
       <ci>a</ci>
      </apply>
      <apply>
       <csymbol cd="ambiguous">superscript</csymbol>
       <apply>
        <minus></minus>
        <cn type="integer">1</cn>
        <ci>q</ci>
       </apply>
       <ci>b</ci>
      </apply>
     </apply>
     <apply>
      <plus></plus>
      <apply>
       <times></times>
       <ci>p</ci>
       <apply>
        <csymbol cd="ambiguous">superscript</csymbol>
        <ci>q</ci>
        <ci>a</ci>
       </apply>
       <apply>
        <csymbol cd="ambiguous">superscript</csymbol>
        <apply>
         <minus></minus>
         <cn type="integer">1</cn>
         <ci>q</ci>
        </apply>
        <ci>b</ci>
       </apply>
      </apply>
      <apply>
       <times></times>
       <apply>
        <minus></minus>
        <cn type="integer">1</cn>
        <ci>p</ci>
       </apply>
       <apply>
        <csymbol cd="ambiguous">superscript</csymbol>
        <apply>
         <minus></minus>
         <cn type="integer">1</cn>
         <ci>q</ci>
        </apply>
        <ci>a</ci>
       </apply>
       <apply>
        <csymbol cd="ambiguous">superscript</csymbol>
        <ci>q</ci>
        <ci>b</ci>
       </apply>
      </apply>
     </apply>
    </apply>
   </cerror>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   P(A|\text{Previous},\text{Personal signal})=\frac{pq^{a}(1-q)^{b}}{pq^{a}(1-q)%
^{b}+(1-p)(1-q)^{a}q^{b}}
  </annotation>
 </semantics>
</math>

</p>

<p>Where "a" is the number of accepts in the previous set plus the agent’s own signal, and "b" is the number of rejects. Thus, <em>a + b = n</em>. The decision is based on how the value on the right hand side of the equation compares with <em>p</em>.<a class="footnoteRef" href="#fn9" id="fnref9"><sup>9</sup></a></p>
<h3 id="explicit-model-assumptions">Explicit model assumptions</h3>

<p>The original model makes several assumptions about human behavior and the world in which humans act,<a class="footnoteRef" href="#fn10" id="fnref10"><sup>10</sup></a> some of which are relaxed in later versions <a class="footnoteRef" href="#fn11" id="fnref11"><sup>11</sup></a> or in alternate definitions of similar problems, such as the <a href="diffusion_of_innovations" title="wikilink">diffusion of innovations</a>.</p>
<ol>
<li>Boundedly Rational Agents: The original Independent Cascade model assumes humans are boundedly rational<a class="footnoteRef" href="#fn12" id="fnref12"><sup>12</sup></a> – that is, they will always make rational decisions based on the information they can observe, but the information they observe may not be complete or correct. In other words, agents do not have complete knowledge of the world around them (which would allow them to make the correct decision in any and all situations). In this way, there is a point at which, even if a person has correct knowledge of the idea or action cascading, they can be convinced via social pressures to adopt some alternate, incorrect view of the world.</li>
<li>Incomplete Knowledge of Others: The original information cascade model assumes that agents have incomplete knowledge of the agents which precede them in the specified order. As opposed to definitions where agents have some knowledge of the "private information" held by previous agents, the current agent makes a decision based only on the observable action (whether or not to imitate) of those preceding him. It is important to note that the original creators argue this is a reason why information cascades can be caused by small shocks.</li>
<li>Behavior of all previous agents is known</li>
</ol>
<h3 id="resulting-conditions">Resulting conditions</h3>
<ol>
<li><strong>Cascades will always occur</strong>-as discussed, in the simple mode, the likelihood of a cascade occurring increases towards 1 as the number of people making decisions increases towards infinity.</li>
<li><strong>Cascades can be incorrect</strong>-because agents make decisions with both bounded rationality and probabilistic knowledge of the initial truth (e.g. whether accepting or rejecting is the correct decision), the incorrect behavior may cascade through the system.</li>
<li><strong>Cascades can be based on little information</strong>-mathematically, a cascade of an infinite length can occur based only on the decision of two people. More generally, a small set of people who strongly promote an idea as being rational can rapidly influence a much larger subset of the general population</li>
<li><strong>Cascades are fragile</strong>-because agents receive no extra information after the difference between a and b increases beyond 2, and because such differences can occur at small numbers of agents, agents considering opinions from those agents who are making decisions based on actual information can be dissuaded from a choice rather easily.<a class="footnoteRef" href="#fn13" id="fnref13"><sup>13</sup></a> thus suggests that cascades are susceptible to the release of public information.<a class="footnoteRef" href="#fn14" id="fnref14"><sup>14</sup></a> also discusses this result in the context of the underlying value p changing over time, in which case a cascade can rapidly change course.</li>
</ol>
<h2 id="responding-to-informational-cascades">Responding to informational cascades</h2>

<p>A literature exists that examines how individuals or firms might respond to the existence of informational cascades when they have products to sell but where buyers are unsure of the quality of those products. Curtis Taylor (1999) <a class="footnoteRef" href="#fn15" id="fnref15"><sup>15</sup></a> shows that when selling a house the seller might wish to start with high prices, as failure to sell with low prices is indicative of low quality and might start a cascade on not buying, while failure to sell with high prices could be construed as meaning the house is just over-priced, and prices can then be reduced to get a sale. Daniel Sgroi (2002) <a class="footnoteRef" href="#fn16" id="fnref16"><sup>16</sup></a> shows that firms might use "guinea pigs" who are given the opportunity to buy early to kick-start an informational cascade through their early and public purchasing decisions, and work by David Gill and Daniel Sgroi (2008) <a class="footnoteRef" href="#fn17" id="fnref17"><sup>17</sup></a> show that early public tests might have a similar effect (and in particular that passing a "tough test" which is biased against the seller can instigate a cascade all by itself). Bose <em>et al.</em> <a class="footnoteRef" href="#fn18" id="fnref18"><sup>18</sup></a> have examined how prices set by a monopolist might evolve in the presence of potential cascade behavior where the monopolist and consumers are unsure of a products quality.</p>
<h2 id="examples-and-fields-of-application">Examples and fields of application</h2>

<p>Information cascades occur in situations where seeing many people make the same choice provides evidence that outweighs one's own judgment. That is, one thinks: "It's more likely that I'm wrong than that all those other people are wrong. Therefore, I will do as they do."</p>

<p>In what has been termed a <a href="reputational_cascade" title="wikilink">reputational cascade</a>, late responders sometimes go along with the decisions of early responders, not just because the late responders think the early responders are right, but also because they perceive their reputation will be damaged if they dissent from the early responders.<a class="footnoteRef" href="#fn19" id="fnref19"><sup>19</sup></a></p>
<h3 id="market-cascades">Market cascades</h3>

<p>Information cascades have become one of the topics of <a href="behavioral_economics" title="wikilink">behavioral economics</a>, as they are often seen in financial markets where they can feed speculation and create cumulative and excessive <a href="market_price" title="wikilink">price moves</a>, either for the whole market (<a href="bubble_(economics)" title="wikilink">market bubble</a>...) or a specific asset, like a stock that becomes overly popular among investors.</p>

<p>Marketers also use the idea of cascades to attempt to get a buying cascade started for a new product. If they can induce an initial set of people to adopt the new product, then those who make purchasing decisions later on may also adopt the product even if it is no better than, or perhaps even worse than, competing products. This is most effective if these later consumers are able to observe the adoption decisions, but not how satisfied the early customers actually were with the choice. This is consistent with the idea that cascades arise naturally when people can see what others do but not what they know.<a class="footnoteRef" href="#fn20" id="fnref20"><sup>20</sup></a></p>

<p>Information cascades are usually considered by economists:</p>
<ul>
<li>as products of <a href="rational_expectations" title="wikilink">rational expectations</a> at their start,</li>
<li>as irrational <a href="herd_behavior" title="wikilink">herd behavior</a> if they persist for too long, which signals that collective emotions come also into play to feed the cascade.</li>
</ul>
<h3 id="social-network-analysis">Social network analysis</h3>

<p>Dotey et al.<a class="footnoteRef" href="#fn21" id="fnref21"><sup>21</sup></a> state that information flows in the form of cascades on the social network. According to the authors, analysis of virality of information cascades on a social network may lead to many useful applications like determining the most influential individuals within a network. This information can be used for <em>maximizing market effectiveness</em> or <em>influencing public opinion</em>. Various structural and temporal features of a network affect cascade virality.</p>

<p>In contrast to work on information cascades in social networks, the Social Influence Model of belief spread argues that people have some notion of the private beliefs of those in their network.<a class="footnoteRef" href="#fn22" id="fnref22"><sup>22</sup></a> The social influence model, then, relaxes the assumption of information cascades that people are acting only on observable actions taken by others. In addition, the social influence model focuses on embedding people within a social network, as opposed to a queue. Finally, the social influence model relaxes the assumption of the information cascade model that people will either complete an action or not by allowing for a continuous scale of the "strength" of an agents belief that an action should be completed.</p>
<h3 id="historical-examples">Historical examples</h3>
<ul>
<li>Small protests began in <a class="uri" href="Leipzig" title="wikilink">Leipzig</a>, Germany in 1989 with just a handful of activists challenging the <a href="German_Democratic_Republic" title="wikilink">German Democratic Republic</a>.<a class="footnoteRef" href="#fn23" id="fnref23"><sup>23</sup></a> For almost a year, protesters met every Monday growing by a few people each time.<a class="footnoteRef" href="#fn24" id="fnref24"><sup>24</sup></a> By the time the government attempted to address it in September 1989, it was too big to quash.<a class="footnoteRef" href="#fn25" id="fnref25"><sup>25</sup></a> In October, the number of protesters reached 100,000 and by the first Monday in November, over 400,000 people marched the streets of Leipzig. Two days later the <a href="Berlin_Wall" title="wikilink">Berlin Wall</a> was dismantled.<a class="footnoteRef" href="#fn26" id="fnref26"><sup>26</sup></a></li>
</ul>
<ul>
<li>The adoption rate of drought-resistant hybrid seed corn during the <a href="Great_Depression" title="wikilink">Great Depression</a> and <a href="Dust_Bowl" title="wikilink">Dust Bowl</a> was slow despite its significant improvement over the previously available seed corn. Researchers at <a href="Iowa_State_University" title="wikilink">Iowa State University</a> were interested in understanding the public's hesitation to the adoption of this significantly improved technology. After conducting 259 interviews with farmers<a class="footnoteRef" href="#fn27" id="fnref27"><sup>27</sup></a> it was observed that the slow rate of adoption was due to how the farmers valued the opinion of their friends and neighbors instead of the word of a salesman. See<a class="footnoteRef" href="#fn28" id="fnref28"><sup>28</sup></a> for the original report.</li>
</ul>
<h3 id="empirical-studies">Empirical Studies</h3>

<p>In addition to the examples above, Information Cascades have been shown to exist in several empirical studies. Perhaps the best example, given above, is.<a class="footnoteRef" href="#fn29" id="fnref29"><sup>29</sup></a> Participants stood in a line behind an urn which had balls of different colors. Sequentially, participants would pick a ball out of the urn, looks at it, and then places it back into the urn. The agent then voices their opinion of which color of balls (red or blue) there is a majority of in the urn for the rest of the participants to hear. Participants get a monetary reward if they guess correctly, forcing the concept of rationality.</p>

<p>Other examples include</p>
<ul>
<li>De Vany and Walls<a class="footnoteRef" href="#fn30" id="fnref30"><sup>30</sup></a> create a statistical model of information cascades where an action is required. They apply this model to the actions people take to go see a movie that has come out at the theatre. De Vany and Walls validate their model on this data, finding a similar <a href="Pareto_distribution" title="wikilink">Pareto distribution</a> of revenue for different movies.</li>
<li>Walden and Browne also adopt the original Information Cascade model, here into an operational model more practical for real world studies, which allows for analysis based on observed variables. Walden and Browne test their model on data about adoption of new technologies by businesses, finding support for their hypothesis that information cascades play a role in this adoption <a class="footnoteRef" href="#fn31" id="fnref31"><sup>31</sup></a></li>
</ul>
<h2 id="legal-aspects">Legal aspects</h2>

<p>The negative effects of informational cascades sometimes become a legal concern and laws have been enacted to neutralize them. <a href="Ward_Farnsworth" title="wikilink">Ward Farnsworth</a>, a law professor, analyzed the legal aspects of informational cascades and gave several examples in his book <em>The Legal Analyst</em>: in many <a href="military_court" title="wikilink">military courts</a>, the officers voting to decide a case vote in reverse rank order (the officer of the lowest rank votes first), and he suggested it may be done so the lower-ranked officers would not be tempted by the cascade to vote with the more senior officers, who are believed to have more accurate judgement; another example is that countries such as <a class="uri" href="Israel" title="wikilink">Israel</a> and <a class="uri" href="France" title="wikilink">France</a> have laws that prohibit polling days or weeks before <a href="election" title="wikilink">elections</a> to prevent the effect of informational cascade that may influence the election results.<a class="footnoteRef" href="#fn32" id="fnref32"><sup>32</sup></a></p>
<h2 id="see-also">See also</h2>
<ul>
<li><a class="uri" href="Conformity" title="wikilink">Conformity</a></li>
<li><a class="uri" href="Groupthink" title="wikilink">Groupthink</a></li>
<li><a href="Group_polarization" title="wikilink">Group polarization</a></li>
<li><a href="Herd_behavior" title="wikilink">Herd behavior</a></li>
<li><a class="uri" href="Sheeple" title="wikilink">Sheeple</a></li>
<li><a href="Social_proof" title="wikilink">Social proof</a></li>
<li><a href="Woozle_effect" title="wikilink">Woozle effect</a></li>
<li><strong>Other modelling approaches</strong>
<ul>
<li><a href="Adaptive_market_hypothesis" title="wikilink">Adaptive market hypothesis</a></li>
<li><a href="Agent-based_computational_economics" title="wikilink">Agent-based computational economics</a></li>
<li><a href="Financial_economics#Challenges_and_criticism" title="wikilink">Financial economics#Challenges and criticism</a></li>
<li><a href="Noisy_market_hypothesis" title="wikilink">Noisy market hypothesis</a></li>
<li><a href="Random_walk_hypothesis#A_non-random_walk_hypothesis" title="wikilink">Random walk hypothesis#A non-random walk hypothesis</a></li>
</ul></li>
</ul>
<h2 id="references">References</h2>
<h2 id="external-links">External links</h2>
<ul>
<li><a href="http://www.info-cascades.info/">Informational Cascades and Rational Herding: An Annotated Bibliography and Resource Reference</a></li>
<li><a href="http://people.virginia.edu/~cah2k/cascy2k.htm">A Bibliography of Information Cascades and Herd Effects</a></li>
<li>[<a class="uri" href="http://www.nytimes.com/2008/03/02/business/02view.html?_r=1&amp;ref">http://www.nytimes.com/2008/03/02/business/02view.html?_r=1&amp;ref;</a>;=business&amp;pagewanted;=all&amp;oref;=slogin How a Bubble Stayed Under the Radar, Robert Shiller] NYT article, may require login.</li>
<li><a href="http://tierneylab.blogs.nytimes.com/2007/10/09/how-the-low-fat-low-fact-cascade-just-keeps-rolling-along/">How the Low-Fat, Low-Fact Cascade Just Keeps Rolling Along, John Tierney October 9, 2007</a> NYT blog, does not require login.</li>
<li><a href="http://tierneylab.blogs.nytimes.com/2007/10/10/schopenhauer-on-cascades/">Schopenhauer on Cascades, John Tierney, October 10, 2007</a> NYT blog, does not require login.</li>
<li>[<a class="uri" href="http://www.nytimes.com/2007/04/15/magazine/15wwlnidealab.t.html?_r=3&amp;ref">http://www.nytimes.com/2007/04/15/magazine/15wwlnidealab.t.html?_r=3&amp;ref;</a>;=magazine&amp;pagewanted;=all&amp;oref;=slogin&amp;oref;=slogin&amp;oref;=slogin Is Justin Timberlake a Product of Cumulative Advantage?] Informational Cascade with another name, NYT article, may require login.</li>
<li><a href="http://www.starcitygames.com/php/news/article/12201.html">Information Cascades in Magic</a></li>
</ul>

<p>"</p>

<p><a href="Category:Behavioral_finance" title="wikilink">Category:Behavioral finance</a> <a class="uri" href="Category:Conformity" title="wikilink">Category:Conformity</a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1"><a href="#fnref1">↩</a></li>
<li id="fn2">Bikhchandani, S., <a href="David_Hirshleifer" title="wikilink">Hirshleifer, D</a>., and <a href="Ivo_Welch" title="wikilink">Welch, I</a>. (1992), "A Theory of Fads, Fashion, Custom, and Cultural Change as Informational Cascades," <em>Journal of Political Economy</em>, Volume 100, Issue 5, pp. <a href="http://www.irvinehousingblog.com/wp-content/uploads/2008/03/atheoryoffads.pdf">pp. 992-1026.</a> <strong>+</strong> button to enlarge.<a href="#fnref2">↩</a></li>
<li id="fn3"><a href="http://www.info-cascades.info">Information Cascades and Rational Herding: An Annotated Bibliography and Resource Reference</a><a href="#fnref3">↩</a></li>
<li id="fn4"><a href="#fnref4">↩</a></li>
<li id="fn5"><a href="#fnref5">↩</a></li>
<li id="fn6"><a href="#fnref6">↩</a></li>
<li id="fn7"><a href="#fnref7">↩</a></li>
<li id="fn8"></li>
<li id="fn9"></li>
<li id="fn10"></li>
<li id="fn11"></li>
<li id="fn12"><a href="#fnref12">↩</a></li>
<li id="fn13"></li>
<li id="fn14"></li>
<li id="fn15"><a href="#fnref15">↩</a></li>
<li id="fn16"><a href="#fnref16">↩</a></li>
<li id="fn17"><a href="#fnref17">↩</a></li>
<li id="fn18"><a href="#fnref18">↩</a></li>
<li id="fn19">Pierre Lemieux (2003), "Following the Herd", <em><a href="Regulation_(magazine)" title="wikilink">Regulation</a></em>, <a href="Cato_Institute" title="wikilink">Cato Institute</a>, 21. <a href="http://www.cato.org/pubs/regulation/regv26n4/v26n4-2.pdf">1</a>. Retrieved 14 July 2010.<a href="#fnref19">↩</a></li>
<li id="fn20"><a class="uri" href="http://research.ivo-welch.info/palgrave.pdf">http://research.ivo-welch.info/palgrave.pdf</a><a href="#fnref20">↩</a></li>
<li id="fn21">Dotey, A., Rom, H. and Vaca C.,Information Diffusion in Social Media. 2011, Stanford University<a href="#fnref21">↩</a></li>
<li id="fn22"><a href="#fnref22">↩</a></li>
<li id="fn23"><a href="#fnref23">↩</a></li>
<li id="fn24"></li>
<li id="fn25"></li>
<li id="fn26"></li>
<li id="fn27"><a href="#fnref27">↩</a></li>
<li id="fn28"><a href="#fnref28">↩</a></li>
<li id="fn29"></li>
<li id="fn30"><a href="#fnref30">↩</a></li>
<li id="fn31"><a href="#fnref31">↩</a></li>
<li id="fn32">Farnsworth, Ward (2007). <em>The Legal Analyst: A Toolkit for Thinking about the Law</em>. Chicago: University of Chicago Press. ISBN 0-226-23835-0<a href="#fnref32">↩</a></li>
</ol>
</section>
</body>
</html>
