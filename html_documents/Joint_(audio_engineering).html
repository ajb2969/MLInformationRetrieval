<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="736">Joint (audio engineering)</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>Joint (audio engineering)</h1>
<hr/>

<p>In <a href="audio_engineering" title="wikilink">audio engineering</a>, <strong>joint</strong> refers to a joining of several channels of similar information in order to obtain higher quality, a smaller file size, or both.</p>
<h2 id="joint-stereo">Joint stereo</h2>

<p>The term <strong>joint stereo</strong> has become prominent as the <a class="uri" href="Internet" title="wikilink">Internet</a> has allowed for the transfer of relatively low <a href="bit_rate" title="wikilink">bit rate</a>, acceptable-quality audio with modest Internet access speeds. Joint stereo refers to any number of encoding techniques used for this purpose. Two forms are described here, both of which are implemented in various ways with different <a href="codec" title="wikilink">codecs</a>, such as <a class="uri" href="MP3" title="wikilink">MP3</a>, <a href="Advanced_Audio_Coding" title="wikilink">AAC</a> and <a href="Ogg_Vorbis" title="wikilink">Ogg Vorbis</a>.</p>
<h3 id="intensity-stereo-coding">Intensity stereo coding</h3>

<p>This form of joint stereo uses a technique known as <strong>joint frequency encoding</strong>, which functions on the principle of <a href="sound_localization" title="wikilink">sound localization</a>. Human hearing is predominantly less acute at perceiving the direction of certain audio frequencies. By exploiting this characteristic, intensity stereo coding can reduce the data rate of an audio stream with little or no perceived change in apparent quality.</p>

<p>More specifically, the dominance of <em>inter-aural time differences (ITD)</em> for sound localization by humans is only present for lower frequencies. That leaves <em>inter-aural amplitude differences (IAD)</em> as the dominant location indicator for higher frequencies. The idea of <em>intensity stereo coding</em> is to merge the lower spectrum into just one channel (thus reducing overall differences between channels) and to transmit a little side information about how to <a href="Panning_(audio)" title="wikilink">pan</a> certain frequency regions to recover the <em>IAD</em> cues.</p>

<p>This type of coding does not perfectly reconstruct the original audio because of the loss of information which results in the simplification of the stereo image and can produce perceptible <a href="compression_artifacts" title="wikilink">compression artifacts</a>. However, for very low bit rates this type of coding usually yields a gain in perceived quality of the audio. It is supported by many audio compression formats (including <a class="uri" href="MP3" title="wikilink">MP3</a>, <a href="Advanced_Audio_Coding" title="wikilink">AAC</a> and <a class="uri" href="Vorbis" title="wikilink">Vorbis</a>) but not always by every <a class="uri" href="encoder" title="wikilink">encoder</a>.</p>
<h3 id="ms-stereo-coding">M/S stereo coding</h3>

<p><strong>M/S stereo coding</strong> transforms the left and right channels into a mid channel and a side channel. The mid channel is the sum of the left and right channels, or 

<math display="inline" id="Joint_(audio_engineering):0">
 <semantics>
  <mrow>
   <mi>M</mi>
   <mo>=</mo>
   <mrow>
    <mi>L</mi>
    <mo>+</mo>
    <mi>R</mi>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <ci>M</ci>
    <apply>
     <plus></plus>
     <ci>L</ci>
     <ci>R</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   M=L+R
  </annotation>
 </semantics>
</math>

. The side channel is the difference of the left and right channels, or 

<math display="inline" id="Joint_(audio_engineering):1">
 <semantics>
  <mrow>
   <mi>S</mi>
   <mo>=</mo>
   <mrow>
    <mi>L</mi>
    <mo>-</mo>
    <mi>R</mi>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <ci>S</ci>
    <apply>
     <minus></minus>
     <ci>L</ci>
     <ci>R</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   S=L-R
  </annotation>
 </semantics>
</math>

. Unlike intensity stereo coding, M/S coding is a special case of <a href="transform_coding" title="wikilink">transform coding</a>, and retains the audio perfectly without introducing artifacts. <a href="Lossless_data_compression" title="wikilink">Lossless codecs</a> such as <a class="uri" href="FLAC" title="wikilink">FLAC</a> or <a href="Monkey's_Audio" title="wikilink">Monkey's Audio</a> use M/S stereo coding because of this characteristic.</p>

<p>To reconstruct the original signal, the channels are either added 

<math display="inline" id="Joint_(audio_engineering):2">
 <semantics>
  <mrow>
   <mi>L</mi>
   <mo>=</mo>
   <mfrac>
    <mrow>
     <mi>M</mi>
     <mo>+</mo>
     <mi>S</mi>
    </mrow>
    <mn>2</mn>
   </mfrac>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <ci>L</ci>
    <apply>
     <divide></divide>
     <apply>
      <plus></plus>
      <ci>M</ci>
      <ci>S</ci>
     </apply>
     <cn type="integer">2</cn>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   L=\frac{M+S}{2}
  </annotation>
 </semantics>
</math>

 or subtracted 

<math display="inline" id="Joint_(audio_engineering):3">
 <semantics>
  <mrow>
   <mi>R</mi>
   <mo>=</mo>
   <mfrac>
    <mrow>
     <mi>M</mi>
     <mo>-</mo>
     <mi>S</mi>
    </mrow>
    <mn>2</mn>
   </mfrac>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <ci>R</ci>
    <apply>
     <divide></divide>
     <apply>
      <minus></minus>
      <ci>M</ci>
      <ci>S</ci>
     </apply>
     <cn type="integer">2</cn>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   R=\frac{M-S}{2}
  </annotation>
 </semantics>
</math>

</p>

<p>This form of coding is also sometimes known as matrix stereo and is used in many different forms of audio processing and recording equipment. It is not limited to digital systems and can even be created with passive audio <a href="transformer" title="wikilink">transformers</a> or analog <a href="amplifier" title="wikilink">amplifiers</a>. One example of the use of M/S stereo is in <a href="FM_broadcasting" title="wikilink">FM</a> stereo broadcasting, where 

<math display="inline" id="Joint_(audio_engineering):4">
 <semantics>
  <mrow>
   <mi>L</mi>
   <mo>+</mo>
   <mi>R</mi>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <plus></plus>
    <ci>L</ci>
    <ci>R</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   L+R
  </annotation>
 </semantics>
</math>

 <a href="modulation" title="wikilink">modulates</a> the <a href="carrier_wave" title="wikilink">carrier wave</a> and 

<math display="inline" id="Joint_(audio_engineering):5">
 <semantics>
  <mrow>
   <mi>L</mi>
   <mo>-</mo>
   <mi>R</mi>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <minus></minus>
    <ci>L</ci>
    <ci>R</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   L-R
  </annotation>
 </semantics>
</math>

 modulates a <a class="uri" href="subcarrier" title="wikilink">subcarrier</a>. Another example of M/S stereo is the <a href="Gramophone_record#Stereophonic_sound" title="wikilink">stereophonic microgroove record</a>. Lateral motions of a stylus represent the sum of two channels and the vertical motion represents the difference between the channels.</p>
<h2 id="joint-frequency-encoding">Joint frequency encoding</h2>

<p><strong>Joint frequency encoding</strong> is an <a href="encoder" title="wikilink">encoding</a> technique used in <a href="audio_data_compression" title="wikilink">audio data compression</a> to reduce the <a href="Bit_rate" title="wikilink">data rate</a>.</p>

<p>The idea is to merge a given frequency range of multiple sound channels together so that the resulting encoding will preserve the sound information of that range not as a bundle of separate channels but as one homogeneous data stream. This will destroy the original channel separation permanently, as the information cannot be accurately reconstructed, but will greatly lessen the amount of required storage space. Only some forms of joint stereo use the joint frequency encoding technique, such as intensity stereo coding.</p>
<h2 id="implementations">Implementations</h2>

<p>When used within the MP3 compression process, joint stereo normally employs multiple techniques, and can switch between them for each MPEG frame. Typically, a modern encoder's joint stereo mode uses M/S stereo for some frames and L/R stereo for others, whichever method yields the best result. Encoders use different algorithms to determine when to switch and how much space to allocate to each channel; quality can suffer if the switching is too frequent or if the side channel doesn't get enough bits. With some encoding software, it is possible to force the use of M/S stereo for all frames, mimicking the joint stereo mode of some early encoders like <a href="Xing_Technology" title="wikilink">Xing</a>. Within the <a class="uri" href="LAME" title="wikilink">LAME</a> encoder, this is known as forced joint stereo.<a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a></p>

<p>As with MP3, <a href="Ogg_Vorbis" title="wikilink">Ogg Vorbis</a> stereo files can employ either L/R stereo or joint stereo. When using joint stereo, both M/S stereo and intensity stereo methods may be used. As opposed to MP3 where M/S stereo (when used) is applied before quantization, an Ogg Vorbis encoder applies M/S stereo to samples in the frequency domain after quantization, making application of M/S stereo a lossless step. After this step, any frequency area can be converted to intensity stereo by removing the corresponding part of the M/S signal's side channel. Ogg Vorbis' floor function will take care of the required left-right panning.</p>
<h2 id="external-links">External links</h2>
<ul>
<li>Jürgen Herre, Fraunhofer IIS. <a href="http://dafx04.na.infn.it/WebProc/Proc/P_157.pdf"><em>From Joint Stereo to Spatial Audio Coding - Recent Progress and Standardization</em>.</a> October 2004, Paper 157, DAFx'04 7th International Conference of Digital Audio Effects.</li>
</ul>
<h2 id="references">References</h2>

<p>"</p>

<p><a href="Category:Audio_engineering" title="wikilink">Category:Audio engineering</a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1"><a href="#fnref1">↩</a></li>
</ol>
</section>
</body>
</html>
