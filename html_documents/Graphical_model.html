<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="957">Graphical model</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>Graphical model</h1>
<hr/>

<p>A <strong>graphical model</strong> or <strong>probabilistic graphical model</strong> (<strong>PGM</strong>) is a <a href="probabilistic_model" title="wikilink">probabilistic model</a> for which a <a href="graph_(mathematics)" title="wikilink">graph</a> expresses the <a href="conditional_dependence" title="wikilink">conditional dependence</a> structure between <a href="random_variable" title="wikilink">random variables</a>. They are commonly used in <a href="probability_theory" title="wikilink">probability theory</a>, <a class="uri" href="statistics" title="wikilink">statistics</a>—particularly <a href="Bayesian_statistics" title="wikilink">Bayesian statistics</a>—and <a href="machine_learning" title="wikilink">machine learning</a>.</p>
<figure><b>(Figure)</b>
<figcaption> An example of a graphical model. Each arrow indicates a dependency. In this example: D depends on A, D depends on B, D depends on C, C depends on B, and C depends on D. </figcaption>
</figure>
<h2 id="types-of-graphical-models">Types of graphical models</h2>

<p>Generally, probabilistic graphical models use a graph-based representation as the foundation for encoding a complete distribution over a multi-dimensional space and a graph that is a compact or <a href="Factor_graph" title="wikilink"> factorized</a> representation of a set of independences that hold in the specific distribution. Two branches of graphical representations of distributions are commonly used, namely, <a href="Bayesian_network" title="wikilink">Bayesian networks</a> and <a href="Markov_network" title="wikilink">Markov networks</a>. Both families encompass the properties of factorization and independences, but they differ in the set of independences they can encode and the factorization of the distribution that they induce.<a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a></p>
<h3 id="bayesian-network">Bayesian network</h3>

<p>If the network structure of the model is a <a href="directed_acyclic_graph" title="wikilink">directed acyclic graph</a>, the model represents a factorization of the joint <a class="uri" href="probability" title="wikilink">probability</a> of all random variables. More precisely, if the events are 

<math display="inline" id="Graphical_model:0">
 <semantics>
  <mrow>
   <msub>
    <mi>X</mi>
    <mn>1</mn>
   </msub>
   <mo>,</mo>
   <mi mathvariant="normal">…</mi>
   <mo>,</mo>
   <msub>
    <mi>X</mi>
    <mi>n</mi>
   </msub>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <list>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>X</ci>
     <cn type="integer">1</cn>
    </apply>
    <ci>normal-…</ci>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>X</ci>
     <ci>n</ci>
    </apply>
   </list>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   X_{1},\ldots,X_{n}
  </annotation>
 </semantics>
</math>

 then the joint probability satisfies</p>

<p>

<math display="block" id="Graphical_model:1">
 <semantics>
  <mrow>
   <mi>P</mi>
   <mrow>
    <mo stretchy="false">[</mo>
    <msub>
     <mi>X</mi>
     <mn>1</mn>
    </msub>
    <mo>,</mo>
    <mi mathvariant="normal">…</mi>
    <mo>,</mo>
    <msub>
     <mi>X</mi>
     <mi>n</mi>
    </msub>
    <mo stretchy="false">]</mo>
   </mrow>
   <mo>=</mo>
   <munderover>
    <mo largeop="true" movablelimits="false" symmetric="true">∏</mo>
    <mrow>
     <mi>i</mi>
     <mo>=</mo>
     <mn>1</mn>
    </mrow>
    <mi>n</mi>
   </munderover>
   <mi>P</mi>
   <mrow>
    <mo stretchy="false">[</mo>
    <msub>
     <mi>X</mi>
     <mi>i</mi>
    </msub>
    <mo stretchy="false">|</mo>
    <mi>p</mi>
    <msub>
     <mi>a</mi>
     <mi>i</mi>
    </msub>
    <mo stretchy="false">]</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <cerror>
    <csymbol cd="ambiguous">fragments</csymbol>
    <csymbol cd="unknown">P</csymbol>
    <cerror>
     <csymbol cd="ambiguous">fragments</csymbol>
     <ci>normal-[</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>X</ci>
      <cn type="integer">1</cn>
     </apply>
     <ci>normal-,</ci>
     <ci>normal-…</ci>
     <ci>normal-,</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>X</ci>
      <ci>n</ci>
     </apply>
     <ci>normal-]</ci>
    </cerror>
    <eq></eq>
    <apply>
     <csymbol cd="ambiguous">superscript</csymbol>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <csymbol cd="latexml">product</csymbol>
      <apply>
       <eq></eq>
       <ci>i</ci>
       <cn type="integer">1</cn>
      </apply>
     </apply>
     <ci>n</ci>
    </apply>
    <csymbol cd="unknown">P</csymbol>
    <cerror>
     <csymbol cd="ambiguous">fragments</csymbol>
     <ci>normal-[</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>X</ci>
      <ci>i</ci>
     </apply>
     <ci>normal-|</ci>
     <csymbol cd="unknown">p</csymbol>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>a</ci>
      <ci>i</ci>
     </apply>
     <ci>normal-]</ci>
    </cerror>
   </cerror>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   P[X_{1},\ldots,X_{n}]=\prod_{i=1}^{n}P[X_{i}|pa_{i}]
  </annotation>
 </semantics>
</math>

</p>

<p>where 

<math display="inline" id="Graphical_model:2">
 <semantics>
  <mrow>
   <mi>p</mi>
   <msub>
    <mi>a</mi>
    <mi>i</mi>
   </msub>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <ci>p</ci>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>a</ci>
     <ci>i</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   pa_{i}
  </annotation>
 </semantics>
</math>

 is the set of parents of node 

<math display="inline" id="Graphical_model:3">
 <semantics>
  <msub>
   <mi>X</mi>
   <mi>i</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>X</ci>
    <ci>i</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   X_{i}
  </annotation>
 </semantics>
</math>


. In other words, the <a href="joint_distribution" title="wikilink">joint distribution</a> factors into a product of conditional distributions. For example, the graphical model in the Figure shown above (which is actually not a directed acyclic graph, but an <a href="ancestral_graph" title="wikilink">ancestral graph</a>) consists of the random variables 

<math display="inline" id="Graphical_model:4">
 <semantics>
  <mrow>
   <mi>A</mi>
   <mo>,</mo>
   <mi>B</mi>
   <mo>,</mo>
   <mi>C</mi>
   <mo>,</mo>
   <mi>D</mi>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <list>
    <ci>A</ci>
    <ci>B</ci>
    <ci>C</ci>
    <ci>D</ci>
   </list>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   A,B,C,D
  </annotation>
 </semantics>
</math>

 with a joint probability density that factors as</p>

<p>

<math display="block" id="Graphical_model:5">
 <semantics>
  <mrow>
   <mi>P</mi>
   <mrow>
    <mo stretchy="false">[</mo>
    <mi>A</mi>
    <mo>,</mo>
    <mi>B</mi>
    <mo>,</mo>
    <mi>C</mi>
    <mo>,</mo>
    <mi>D</mi>
    <mo stretchy="false">]</mo>
   </mrow>
   <mo>=</mo>
   <mi>P</mi>
   <mrow>
    <mo stretchy="false">[</mo>
    <mi>A</mi>
    <mo stretchy="false">]</mo>
   </mrow>
   <mo>⋅</mo>
   <mi>P</mi>
   <mrow>
    <mo stretchy="false">[</mo>
    <mi>B</mi>
    <mo stretchy="false">]</mo>
   </mrow>
   <mo>⋅</mo>
   <mi>P</mi>
   <mrow>
    <mo stretchy="false">[</mo>
    <mi>C</mi>
    <mo stretchy="false">|</mo>
    <mi>B</mi>
    <mo>,</mo>
    <mi>D</mi>
    <mo stretchy="false">]</mo>
   </mrow>
   <mo>⋅</mo>
   <mi>P</mi>
   <mrow>
    <mo stretchy="false">[</mo>
    <mi>D</mi>
    <mo stretchy="false">|</mo>
    <mi>A</mi>
    <mo>,</mo>
    <mi>B</mi>
    <mo>,</mo>
    <mi>C</mi>
    <mo stretchy="false">]</mo>
   </mrow>
   <mo>.</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <cerror>
    <csymbol cd="ambiguous">fragments</csymbol>
    <csymbol cd="unknown">P</csymbol>
    <cerror>
     <csymbol cd="ambiguous">fragments</csymbol>
     <ci>normal-[</ci>
     <csymbol cd="unknown">A</csymbol>
     <ci>normal-,</ci>
     <csymbol cd="unknown">B</csymbol>
     <ci>normal-,</ci>
     <csymbol cd="unknown">C</csymbol>
     <ci>normal-,</ci>
     <csymbol cd="unknown">D</csymbol>
     <ci>normal-]</ci>
    </cerror>
    <eq></eq>
    <csymbol cd="unknown">P</csymbol>
    <cerror>
     <csymbol cd="ambiguous">fragments</csymbol>
     <ci>normal-[</ci>
     <csymbol cd="unknown">A</csymbol>
     <ci>normal-]</ci>
    </cerror>
    <ci>normal-⋅</ci>
    <csymbol cd="unknown">P</csymbol>
    <cerror>
     <csymbol cd="ambiguous">fragments</csymbol>
     <ci>normal-[</ci>
     <csymbol cd="unknown">B</csymbol>
     <ci>normal-]</ci>
    </cerror>
    <ci>normal-⋅</ci>
    <csymbol cd="unknown">P</csymbol>
    <cerror>
     <csymbol cd="ambiguous">fragments</csymbol>
     <ci>normal-[</ci>
     <csymbol cd="unknown">C</csymbol>
     <ci>normal-|</ci>
     <csymbol cd="unknown">B</csymbol>
     <ci>normal-,</ci>
     <csymbol cd="unknown">D</csymbol>
     <ci>normal-]</ci>
    </cerror>
    <ci>normal-⋅</ci>
    <csymbol cd="unknown">P</csymbol>
    <cerror>
     <csymbol cd="ambiguous">fragments</csymbol>
     <ci>normal-[</ci>
     <csymbol cd="unknown">D</csymbol>
     <ci>normal-|</ci>
     <csymbol cd="unknown">A</csymbol>
     <ci>normal-,</ci>
     <csymbol cd="unknown">B</csymbol>
     <ci>normal-,</ci>
     <csymbol cd="unknown">C</csymbol>
     <ci>normal-]</ci>
    </cerror>
    <ci>normal-.</ci>
   </cerror>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   P[A,B,C,D]=P[A]\cdot P[B]\cdot P[C|B,D]\cdot P[D|A,B,C].
  </annotation>
 </semantics>
</math>

</p>

<p>Any two nodes are <a href="Conditional_independence" title="wikilink">conditionally independent</a> given the values of their parents. In general, any two sets of nodes are conditionally independent given a third set if a criterion called <a href="d-separation" title="wikilink"><em>d</em>-separation</a> holds in the graph. Local independences and global independences are equivalent in Bayesian networks.</p>

<p>This type of graphical model is known as a directed graphical model, <a href="Bayesian_network" title="wikilink">Bayesian network</a>, or belief network. Classic machine learning models like <a href="hidden_Markov_models" title="wikilink">hidden Markov models</a>, <a href="neural_networks" title="wikilink">neural networks</a> and newer models such as <a href="variable-order_Markov_model" title="wikilink">variable-order Markov models</a> can be considered special cases of Bayesian networks.</p>
<h3 id="markov-random-field">Markov random field</h3>

<p>A Markov random field, also known as a Markov network, is a model over an <a href="undirected_graph" title="wikilink">undirected graph</a>. A graphical model with many repeated subunits can be represented with <a href="plate_notation" title="wikilink">plate notation</a>.</p>
<h3 id="other-types">Other types</h3>
<ul>
<li>A <a href="factor_graph" title="wikilink">factor graph</a> is an undirected <a href="bipartite_graph" title="wikilink">bipartite graph</a> connecting variables and factors. Each factor represents a function over the variables it is connected to. This is a helpful representation for understanding and implementing <a href="belief_propagation" title="wikilink">belief propagation</a>.</li>
<li>A <a href="clique_tree" title="wikilink">clique tree</a> or junction tree is a <a href="tree_(graph_theory)" title="wikilink">tree</a> of <a href="clique_(graph_theory)" title="wikilink">cliques</a>, used in the <a href="junction_tree_algorithm" title="wikilink">junction tree algorithm</a>.</li>
<li>A <a href="chain_graph" title="wikilink">chain graph</a> is a graph which may have both directed and undirected edges, but without any directed cycles (i.e. if we start at any vertex and move along the graph respecting the directions of any arrows, we cannot return to the vertex we started from if we have passed an arrow). Both directed acyclic graphs and undirected graphs are special cases of chain graphs, which can therefore provide a way of unifying and generalizing Bayesian and Markov networks.<ref></ref></li>
</ul>

<p></p>
<ul>
<li>An <a href="ancestral_graph" title="wikilink">ancestral graph</a> is a further extension, having directed, bidirected and undirected edges.<a class="footnoteRef" href="#fn2" id="fnref2"><sup>2</sup></a></li>
<li>A <a href="conditional_random_field" title="wikilink">conditional random field</a> is a <a href="discriminative_model" title="wikilink">discriminative model</a> specified over an undirected graph.</li>
<li>A <a href="restricted_Boltzmann_machine" title="wikilink">restricted Boltzmann machine</a> is a <a href="generative_model" title="wikilink">generative model</a> specified over an undirected graph.</li>
</ul>
<h2 id="applications">Applications</h2>

<p>The framework of the models, which provides algorithms for discovering and analyzing structure in complex distributions to describe them succinctly and extract the unstructured information, allows them to be constructed and utilized effectively.<a class="footnoteRef" href="#fn3" id="fnref3"><sup>3</sup></a> Applications of graphical models include <a href="information_extraction" title="wikilink">information extraction</a>, <a href="speech_recognition" title="wikilink">speech recognition</a>, <a href="computer_vision" title="wikilink">computer vision</a>, decoding of <a href="low-density_parity-check_codes" title="wikilink">low-density parity-check codes</a>, modeling of <a href="gene_regulatory_network" title="wikilink">gene regulatory networks</a>, gene finding and diagnosis of diseases, and <a href="graphical_models_for_protein_structure" title="wikilink">graphical models for protein structure</a>.</p>
<h2 id="see-also">See also</h2>
<ul>
<li><a href="Belief_propagation" title="wikilink">Belief propagation</a></li>
<li><a href="Structural_equation_model" title="wikilink">Structural equation model</a></li>
</ul>
<h2 id="notes">Notes</h2>
<h2 id="tutorial">Tutorial</h2>
<ul>
<li><a href="http://sandeep-aparajit.blogspot.com/2013/06/how-does-conditional-random-field-crf.html">Graphical models and Conditional Random Fields</a></li>
<li><a href="http://www.cs.cmu.edu/~epxing/Class/10708/">Probabilistic Graphical Models taught by Eric Xing at CMU</a></li>
</ul>
<h2 id="references-and-further-reading">References and further reading</h2>
<h3 id="books-and-book-chapters">Books and book chapters</h3>
<ul>
<li></li>
<li>

<p>A more advanced and statistically oriented book</p></li>
<li></li>
<li></li>
<li>

<p>A computational reasoning approach, where the relationships between graphs and probabilities were formally introduced.</p></li>
</ul>
<h3 id="journal-articles">Journal articles</h3>
<ul>
<li></li>
<li></li>
</ul>
<h3 id="other">Other</h3>
<ul>
<li><a href="http://research.microsoft.com/en-us/um/people/heckerman/tutorial.pdf">Heckerman's Bayes Net Learning Tutorial</a></li>
<li><a href="http://www.cs.ubc.ca/~murphyk/Bayes/bnintro.html">A Brief Introduction to Graphical Models and Bayesian Networks</a></li>
<li><a href="http://www.cedar.buffalo.edu/~srihari/CSE574">Sargur Srihari's lecture slides on probabilistic graphical models</a></li>
</ul>

<p>"</p>

<p><a href="Category:Bayesian_statistics" title="wikilink">Category:Bayesian statistics</a> <a href="Category:Statistical_models" title="wikilink">Category:Statistical models</a> <a href="Category:Graphical_models" title="wikilink"> </a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1">Koller; Friedman (2009). Probabilistic Graphical Models. Massachusetts: MIT Press. ISBN 0-262-01319-3.<a href="#fnref1">↩</a></li>
<li id="fn2"><a href="#fnref2">↩</a></li>
<li id="fn3"></li>
</ol>
</section>
</body>
</html>
