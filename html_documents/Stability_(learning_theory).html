<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="1634">Stability (learning theory)</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>Stability (learning theory)</h1>
<hr/>

<p><strong>Stability</strong>, also known as <strong>algorithmic stability</strong>, is a notion in <a href="computational_learning_theory" title="wikilink">computational learning theory</a> of how a <a href="machine_learning" title="wikilink"> machine learning algorithm</a> is perturbed by small changes to its inputs. A stable learning algorithm is one for which the prediction does not change much when the training data is modified slightly. For instance, consider a machine learning algorithm that is being trained to recognize handwritten letters of the alphabet, using 1000 examples of handwritten letters and their labels ("A" to "Z") as a training set. One way to modify this training set is to leave out an example, so that only 999 examples of handwritten letters and their labels are available. A stable learning algorithm would produce a similar <a href="statistical_classification" title="wikilink">classifier</a> with both the 1000-element and 999-element training sets.</p>

<p>Stability can be studied for many types of learning problems, from <a href="Natural_language_processing" title="wikilink">language learning</a> to <a href="inverse_problem" title="wikilink">inverse problems</a> in physics and engineering, as it is a property of the learning process rather than the type of information being learned. The study of stability gained importance in <a href="computational_learning_theory" title="wikilink">computational learning theory</a> in the 2000s when it was shown to have a connection with <a href="Machine_learning#Generalization" title="wikilink">generalization</a>. It was shown that for large classes of learning algorithms, notably <a href="empirical_risk_minimization" title="wikilink">empirical risk minimization</a> algorithms, certain types of stability ensure good generalization.</p>
<h2 id="history">History</h2>

<p>A central goal in designing a <a href="machine_learning" title="wikilink"> machine learning system</a> is to guarantee that the learning algorithm will <a href="Machine_learning#Generalization" title="wikilink">generalize</a>, or perform accurately on new examples after being trained on a finite number of them. In the 1990s, milestones were made in obtaining generalization bounds for <a href="supervised_learning" title="wikilink"> supervised learning algorithms</a>. The technique historically used to prove generalization was to show that an algorithm was <a href="consistent_estimator" title="wikilink">consistent</a>, using the <a href="uniform_convergence" title="wikilink">uniform convergence</a> properties of empirical quantities to their means. This technique was used to obtain generalization bounds for the large class of <a href="empirical_risk_minimization" title="wikilink">empirical risk minimization</a> (ERM) algorithms. An ERM algorithm is one that selects a solution from a hypothesis space 

<math display="inline" id="Stability_(learning_theory):0">
 <semantics>
  <mi>H</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>H</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   H
  </annotation>
 </semantics>
</math>

 in such a way to minimize the empirical error on a training set 

<math display="inline" id="Stability_(learning_theory):1">
 <semantics>
  <mi>S</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>S</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   S
  </annotation>
 </semantics>
</math>

.</p>

<p>A general result, proved by <a href="Vladimir_Vapnik" title="wikilink">Vladimir Vapnik</a> for an ERM binary classification algorithms, is that for any target function and input distribution, any hypothesis space 

<math display="inline" id="Stability_(learning_theory):2">
 <semantics>
  <mi>H</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>H</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   H
  </annotation>
 </semantics>
</math>

 with <a href="VC_dimension" title="wikilink">VC-dimension</a> 

<math display="inline" id="Stability_(learning_theory):3">
 <semantics>
  <mi>d</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>d</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   d
  </annotation>
 </semantics>
</math>

, and 

<math display="inline" id="Stability_(learning_theory):4">
 <semantics>
  <mi>n</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>n</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   n
  </annotation>
 </semantics>
</math>

 training examples, the algorithm is consistent and will produce a training error that is most 

<math display="inline" id="Stability_(learning_theory):5">
 <semantics>
  <mrow>
   <mi>O</mi>
   <mrow>
    <mo>(</mo>
    <msqrt>
     <mfrac>
      <mi>d</mi>
      <mi>n</mi>
     </mfrac>
    </msqrt>
    <mo>)</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <ci>O</ci>
    <apply>
     <root></root>
     <apply>
      <divide></divide>
      <ci>d</ci>
      <ci>n</ci>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   O\left(\sqrt{\frac{d}{n}}\right)
  </annotation>
 </semantics>
</math>

 (plus logarithmic factors) from the true training error. The result was later extended to almost-ERM algorithms with function classes that do not have unique minimizers.</p>

<p>Vapnik's work, using what became known as <a href="VC_theory" title="wikilink">VC theory</a>, established a relationship between generalization of a learning algorithm and properties of the hypothesis space 

<math display="inline" id="Stability_(learning_theory):6">
 <semantics>
  <mi>H</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>H</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   H
  </annotation>
 </semantics>
</math>

 of functions being learned. However, these results could not be applied to algorithms with hypothesis spaces of unbounded VC-dimension. Put another way, these results could not be applied when the information being learned had a complexity that was too large to measure. Some of the simplest machine learning algorithms, for instance, for regression have hypothesis spaces with unbounded VC-dimension. Another example is a language learning algorithms that can produce sentences of arbitrary length.</p>

<p>Stability analysis was developed in the 2000s for <a href="computational_learning_theory" title="wikilink">computational learning theory</a> and is an alternative method for obtaining generalization bounds. The stability of an algorithm is a property of the learning process, rather than a direct property of the hypothesis space 

<math display="inline" id="Stability_(learning_theory):7">
 <semantics>
  <mi>H</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>H</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   H
  </annotation>
 </semantics>
</math>

, and it can be assessed in algorithms that have hypothesis spaces with unbounded or undefined VC-dimension such as nearest neighbor. A stable learning algorithm is one for which the learned function does not change much when the training set is slightly modified, for instance by leaving out an example. A measure of <a href="Leave_one_out_error" title="wikilink">Leave one out error</a> is used in a Cross Validation Leave One Out (CVloo) algorithm to evaluate a learning algorithm's stability with respect to the loss function. As such, stability analysis is the application of <a href="sensitivity_analysis" title="wikilink">sensitivity analysis</a> to machine learning.</p>
<h2 id="summary-of-classic-results">Summary of classic results</h2>
<ul>
<li><strong>Early 1900s</strong> - Stability in learning theory was earliest described in terms of continuity of the learning map 

<math display="inline" id="Stability_(learning_theory):8">
 <semantics>
  <mi>L</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>L</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   L
  </annotation>
 </semantics>
</math>

, traced to <a href="Andrey_Nikolayevich_Tikhonov" title="wikilink">Andrey Nikolayevich Tikhonov</a>.</li>
</ul>
<ul>
<li><strong>1979</strong> - Devroye and Wagner observed that the leave-one-out behavior of an algorithm is related to its sensitivity to small changes in the sample.<a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a></li>
</ul>
<ul>
<li><strong>1999</strong> - Kearns and Ron discovered a connection between finite VC-dimension and stability.<a class="footnoteRef" href="#fn2" id="fnref2"><sup>2</sup></a></li>
</ul>
<ul>
<li><strong>2002</strong> - In a landmark paper, Bousquet and Elisseeff proposed the notion of <em>uniform hypothesis stability</em> of a learning algorithm and showed that it implies low generalization error. Uniform hypothesis stability, however, is a strong condition that does not apply to large classes of algorithms, including ERM algorithms with a hypothesis space of only two functions.<a class="footnoteRef" href="#fn3" id="fnref3"><sup>3</sup></a></li>
</ul>
<ul>
<li><strong>2002</strong> - Kutin and Niyogi extended Bousquet and Elisseeff's results by providing generalization bounds for several weaker forms of stability which they called <em>almost-everywhere stability</em>. Furthermore, they took an initial step in establishing the relationship between stability and consistency in ERM algorithms in the Probably Approximately Correct (PAC) setting.<a class="footnoteRef" href="#fn4" id="fnref4"><sup>4</sup></a></li>
</ul>
<ul>
<li><strong>2006</strong> - In an unusual publication (on a theorem!) for the journal <a href="nature_journal" title="wikilink">Nature</a>, Mukherjee et al. proved the relationship between stability and ERM consistency in the general case. They proposed a statistical form of leave-one-out-stability which they called <em>CVEEEloo stability</em>, and showed that it is a) sufficient for generalization in bounded loss classes, and b) necessary and sufficient for consistency (and thus generalization) of ERM algorithms for certain loss functions (such as the square loss, the absolute value and the binary classification loss).<a class="footnoteRef" href="#fn5" id="fnref5"><sup>5</sup></a></li>
</ul>
<ul>
<li><strong>2010</strong> - Shalev Shwartz noticed problems with the original results of Vapnik due to the complex relations between hypothesis space and loss class. They discuss stability notions that capture different loss classes and different types of learning, supervised and unsupervised.<a class="footnoteRef" href="#fn6" id="fnref6"><sup>6</sup></a></li>
</ul>
<h2 id="preliminary-definitions">Preliminary definitions</h2>

<p>We define several terms related to learning algorithms training sets, so that we can then define stability in multiple ways and present theorems from the field.</p>

<p>A machine learning algorithm, also known as a learning map 

<math display="inline" id="Stability_(learning_theory):9">
 <semantics>
  <mi>L</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>L</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   L
  </annotation>
 </semantics>
</math>

, maps a training data set, which is a set of labeled examples 

<math display="inline" id="Stability_(learning_theory):10">
 <semantics>
  <mrow>
   <mo stretchy="false">(</mo>
   <mi>x</mi>
   <mo>,</mo>
   <mi>y</mi>
   <mo stretchy="false">)</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <interval closure="open">
    <ci>x</ci>
    <ci>y</ci>
   </interval>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   (x,y)
  </annotation>
 </semantics>
</math>

, onto a function 

<math display="inline" id="Stability_(learning_theory):11">
 <semantics>
  <mi>f</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>f</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   f
  </annotation>
 </semantics>
</math>

 from 

<math display="inline" id="Stability_(learning_theory):12">
 <semantics>
  <mi>X</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>X</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   X
  </annotation>
 </semantics>
</math>

 to 

<math display="inline" id="Stability_(learning_theory):13">
 <semantics>
  <mi>Y</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>Y</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   Y
  </annotation>
 </semantics>
</math>

, where 

<math display="inline" id="Stability_(learning_theory):14">
 <semantics>
  <mi>X</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>X</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   X
  </annotation>
 </semantics>
</math>

 and 

<math display="inline" id="Stability_(learning_theory):15">
 <semantics>
  <mi>Y</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>Y</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   Y
  </annotation>
 </semantics>
</math>

 are in the same space of the training examples. The functions 

<math display="inline" id="Stability_(learning_theory):16">
 <semantics>
  <mi>f</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>f</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   f
  </annotation>
 </semantics>
</math>

 are selected from a hypothesis space of functions called 

<math display="inline" id="Stability_(learning_theory):17">
 <semantics>
  <mi>H</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>H</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   H
  </annotation>
 </semantics>
</math>

.</p>

<p>The training set from which an algorithm learns is defined as</p>

<p>

<math display="inline" id="Stability_(learning_theory):18">
 <semantics>
  <mrow>
   <mi>S</mi>
   <mo>=</mo>
   <mrow>
    <mo stretchy="false">{</mo>
    <msub>
     <mi>z</mi>
     <mn>1</mn>
    </msub>
    <mo>=</mo>
    <mrow>
     <mo stretchy="false">(</mo>
     <msub>
      <mi>x</mi>
      <mn>1</mn>
     </msub>
     <mo rspace="7.5pt">,</mo>
     <msub>
      <mi>y</mi>
      <mn>1</mn>
     </msub>
     <mo rspace="7.5pt" stretchy="false">)</mo>
    </mrow>
    <mo>,</mo>
    <mo>.</mo>
    <mo>.</mo>
    <mo rspace="7.5pt">,</mo>
    <msub>
     <mi>z</mi>
     <mi>m</mi>
    </msub>
    <mo>=</mo>
    <mrow>
     <mo stretchy="false">(</mo>
     <msub>
      <mi>x</mi>
      <mi>m</mi>
     </msub>
     <mo rspace="7.5pt">,</mo>
     <msub>
      <mi>y</mi>
      <mi>m</mi>
     </msub>
     <mo stretchy="false">)</mo>
    </mrow>
    <mo stretchy="false">}</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <cerror>
    <csymbol cd="ambiguous">fragments</csymbol>
    <csymbol cd="unknown">S</csymbol>
    <eq></eq>
    <cerror>
     <csymbol cd="ambiguous">fragments</csymbol>
     <ci>normal-{</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>z</ci>
      <cn type="integer">1</cn>
     </apply>
     <eq></eq>
     <cerror>
      <csymbol cd="ambiguous">fragments</csymbol>
      <ci>normal-(</ci>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>x</ci>
       <cn type="integer">1</cn>
      </apply>
      <ci>normal-,</ci>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>y</ci>
       <cn type="integer">1</cn>
      </apply>
      <ci>normal-)</ci>
     </cerror>
     <ci>normal-,</ci>
     <ci>normal-.</ci>
     <ci>normal-.</ci>
     <ci>normal-,</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>z</ci>
      <ci>m</ci>
     </apply>
     <eq></eq>
     <cerror>
      <csymbol cd="ambiguous">fragments</csymbol>
      <ci>normal-(</ci>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>x</ci>
       <ci>m</ci>
      </apply>
      <ci>normal-,</ci>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>y</ci>
       <ci>m</ci>
      </apply>
      <ci>normal-)</ci>
     </cerror>
     <ci>normal-}</ci>
    </cerror>
   </cerror>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   S=\{z_{1}=(x_{1},\ y_{1})\ ,..,\ z_{m}=(x_{m},\ y_{m})\}
  </annotation>
 </semantics>
</math>

</p>

<p>and is of size 

<math display="inline" id="Stability_(learning_theory):19">
 <semantics>
  <mi>m</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>m</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   m
  </annotation>
 </semantics>
</math>

 in 

<math display="inline" id="Stability_(learning_theory):20">
 <semantics>
  <mrow>
   <mi>Z</mi>
   <mo>=</mo>
   <mrow>
    <mi>X</mi>
    <mo>×</mo>
    <mi>Y</mi>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <ci>Z</ci>
    <apply>
     <times></times>
     <ci>X</ci>
     <ci>Y</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   Z=X\times Y
  </annotation>
 </semantics>
</math>

</p>

<p>drawn i.i.d. from an unknown distribution D.</p>

<p>Thus, the learning map 

<math display="inline" id="Stability_(learning_theory):21">
 <semantics>
  <mi>L</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>L</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   L
  </annotation>
 </semantics>
</math>

 is defined as a mapping from 

<math display="inline" id="Stability_(learning_theory):22">
 <semantics>
  <msub>
   <mi>Z</mi>
   <mi>m</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>Z</ci>
    <ci>m</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   Z_{m}
  </annotation>
 </semantics>
</math>

 into 

<math display="inline" id="Stability_(learning_theory):23">
 <semantics>
  <mi>H</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>H</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   H
  </annotation>
 </semantics>
</math>

, mapping a training set 

<math display="inline" id="Stability_(learning_theory):24">
 <semantics>
  <mi>S</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>S</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   S
  </annotation>
 </semantics>
</math>

 onto a function 

<math display="inline" id="Stability_(learning_theory):25">
 <semantics>
  <msub>
   <mi>f</mi>
   <mi>S</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>f</ci>
    <ci>S</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   f_{S}
  </annotation>
 </semantics>
</math>

 from 

<math display="inline" id="Stability_(learning_theory):26">
 <semantics>
  <mi>X</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>X</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   X
  </annotation>
 </semantics>
</math>

 to 

<math display="inline" id="Stability_(learning_theory):27">
 <semantics>
  <mi>Y</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>Y</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   Y
  </annotation>
 </semantics>
</math>

. Here, we consider only deterministic algorithms where 

<math display="inline" id="Stability_(learning_theory):28">
 <semantics>
  <mi>L</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>L</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   L
  </annotation>
 </semantics>
</math>

 is symmetric with respect to 

<math display="inline" id="Stability_(learning_theory):29">
 <semantics>
  <mi>S</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>S</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   S
  </annotation>
 </semantics>
</math>

, i.e. it does not depend on the order of the elements in the training set. Furthermore, we assume that all functions are measurable and all sets are countable.</p>

<p>The loss 

<math display="inline" id="Stability_(learning_theory):30">
 <semantics>
  <mi>V</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>V</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   V
  </annotation>
 </semantics>
</math>

 of a hypothesis 

<math display="inline" id="Stability_(learning_theory):31">
 <semantics>
  <mi>f</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>f</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   f
  </annotation>
 </semantics>
</math>

 with respect to an example 

<math display="inline" id="Stability_(learning_theory):32">
 <semantics>
  <mrow>
   <mi>z</mi>
   <mo>=</mo>
   <mrow>
    <mo stretchy="false">(</mo>
    <mi>x</mi>
    <mo>,</mo>
    <mi>y</mi>
    <mo stretchy="false">)</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <ci>z</ci>
    <interval closure="open">
     <ci>x</ci>
     <ci>y</ci>
    </interval>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   z=(x,y)
  </annotation>
 </semantics>
</math>

 is then defined as 

<math display="inline" id="Stability_(learning_theory):33">
 <semantics>
  <mrow>
   <mrow>
    <mi>V</mi>
    <mrow>
     <mo stretchy="false">(</mo>
     <mi>f</mi>
     <mo>,</mo>
     <mi>z</mi>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
   <mo>=</mo>
   <mrow>
    <mi>V</mi>
    <mrow>
     <mo stretchy="false">(</mo>
     <mrow>
      <mi>f</mi>
      <mrow>
       <mo stretchy="false">(</mo>
       <mi>x</mi>
       <mo stretchy="false">)</mo>
      </mrow>
     </mrow>
     <mo>,</mo>
     <mi>y</mi>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <times></times>
     <ci>V</ci>
     <interval closure="open">
      <ci>f</ci>
      <ci>z</ci>
     </interval>
    </apply>
    <apply>
     <times></times>
     <ci>V</ci>
     <interval closure="open">
      <apply>
       <times></times>
       <ci>f</ci>
       <ci>x</ci>
      </apply>
      <ci>y</ci>
     </interval>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   V(f,z)=V(f(x),y)
  </annotation>
 </semantics>
</math>

.</p>

<p>The empirical error of 

<math display="inline" id="Stability_(learning_theory):34">
 <semantics>
  <mi>f</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>f</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   f
  </annotation>
 </semantics>
</math>

 is 

<math display="inline" id="Stability_(learning_theory):35">
 <semantics>
  <mrow>
   <mrow>
    <msub>
     <mi>I</mi>
     <mi>S</mi>
    </msub>
    <mrow>
     <mo stretchy="false">[</mo>
     <mi>f</mi>
     <mo stretchy="false">]</mo>
    </mrow>
   </mrow>
   <mo>=</mo>
   <mrow>
    <mfrac>
     <mn>1</mn>
     <mi>n</mi>
    </mfrac>
    <mrow>
     <mo largeop="true" symmetric="true">∑</mo>
     <mrow>
      <mi>V</mi>
      <mrow>
       <mo stretchy="false">(</mo>
       <mi>f</mi>
       <mo>,</mo>
       <msub>
        <mi>z</mi>
        <mi>i</mi>
       </msub>
       <mo stretchy="false">)</mo>
      </mrow>
     </mrow>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <times></times>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>I</ci>
      <ci>S</ci>
     </apply>
     <apply>
      <csymbol cd="latexml">delimited-[]</csymbol>
      <ci>f</ci>
     </apply>
    </apply>
    <apply>
     <times></times>
     <apply>
      <divide></divide>
      <cn type="integer">1</cn>
      <ci>n</ci>
     </apply>
     <apply>
      <sum></sum>
      <apply>
       <times></times>
       <ci>V</ci>
       <interval closure="open">
        <ci>f</ci>
        <apply>
         <csymbol cd="ambiguous">subscript</csymbol>
         <ci>z</ci>
         <ci>i</ci>
        </apply>
       </interval>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   I_{S}[f]=\frac{1}{n}\sum V(f,z_{i})
  </annotation>
 </semantics>
</math>

.</p>

<p>The true error of 

<math display="inline" id="Stability_(learning_theory):36">
 <semantics>
  <mi>f</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>f</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   f
  </annotation>
 </semantics>
</math>

 is 

<math display="inline" id="Stability_(learning_theory):37">
 <semantics>
  <mrow>
   <mrow>
    <mi>I</mi>
    <mrow>
     <mo stretchy="false">[</mo>
     <mi>f</mi>
     <mo stretchy="false">]</mo>
    </mrow>
   </mrow>
   <mo>=</mo>
   <mrow>
    <msub>
     <mi>𝔼</mi>
     <mi>z</mi>
    </msub>
    <mi>V</mi>
    <mrow>
     <mo stretchy="false">(</mo>
     <mi>f</mi>
     <mo>,</mo>
     <mi>z</mi>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <times></times>
     <ci>I</ci>
     <apply>
      <csymbol cd="latexml">delimited-[]</csymbol>
      <ci>f</ci>
     </apply>
    </apply>
    <apply>
     <times></times>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>𝔼</ci>
      <ci>z</ci>
     </apply>
     <ci>V</ci>
     <interval closure="open">
      <ci>f</ci>
      <ci>z</ci>
     </interval>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   I[f]=\mathbb{E}_{z}V(f,z)
  </annotation>
 </semantics>
</math>

</p>

<p>Given a training set S of size m, we will build, for all i = 1....,m, modified training sets as follows:</p>
<ul>
<li>By removing the i-th element</li>
</ul>

<p>

<math display="inline" id="Stability_(learning_theory):38">
 <semantics>
  <mrow>
   <msup>
    <mi>S</mi>
    <mrow>
     <mo stretchy="false">|</mo>
     <mi>i</mi>
    </mrow>
   </msup>
   <mo>=</mo>
   <mrow>
    <mo stretchy="false">{</mo>
    <msub>
     <mi>z</mi>
     <mn>1</mn>
    </msub>
    <mo>,</mo>
    <mi mathvariant="normal">…</mi>
    <mo rspace="7.5pt">,</mo>
    <msub>
     <mi>z</mi>
     <mrow>
      <mi>i</mi>
      <mo>-</mo>
      <mn>1</mn>
     </mrow>
    </msub>
    <mo rspace="7.5pt">,</mo>
    <msub>
     <mi>z</mi>
     <mrow>
      <mi>i</mi>
      <mo>+</mo>
      <mn>1</mn>
     </mrow>
    </msub>
    <mo>,</mo>
    <mi mathvariant="normal">…</mi>
    <mo rspace="7.5pt">,</mo>
    <msub>
     <mi>z</mi>
     <mi>m</mi>
    </msub>
    <mo stretchy="false">}</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <csymbol cd="ambiguous">superscript</csymbol>
     <ci>S</ci>
     <cerror>
      <csymbol cd="ambiguous">fragments</csymbol>
      <ci>normal-|</ci>
      <csymbol cd="unknown">i</csymbol>
     </cerror>
    </apply>
    <set>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>z</ci>
      <cn type="integer">1</cn>
     </apply>
     <ci>normal-…</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>z</ci>
      <apply>
       <minus></minus>
       <ci>i</ci>
       <cn type="integer">1</cn>
      </apply>
     </apply>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>z</ci>
      <apply>
       <plus></plus>
       <ci>i</ci>
       <cn type="integer">1</cn>
      </apply>
     </apply>
     <ci>normal-…</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>z</ci>
      <ci>m</ci>
     </apply>
    </set>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   S^{|i}=\{z_{1},...,\ z_{i-1},\ z_{i+1},...,\ z_{m}\}
  </annotation>
 </semantics>
</math>

</p>
<ul>
<li>By replacing the i-th element</li>
</ul>

<p>

<math display="inline" id="Stability_(learning_theory):39">
 <semantics>
  <mrow>
   <msup>
    <mi>S</mi>
    <mi>i</mi>
   </msup>
   <mo>=</mo>
   <mrow>
    <mo stretchy="false">{</mo>
    <msub>
     <mi>z</mi>
     <mn>1</mn>
    </msub>
    <mo>,</mo>
    <mi mathvariant="normal">…</mi>
    <mo rspace="7.5pt">,</mo>
    <msub>
     <mi>z</mi>
     <mrow>
      <mi>i</mi>
      <mo>-</mo>
      <mn>1</mn>
     </mrow>
    </msub>
    <mo rspace="7.5pt">,</mo>
    <msubsup>
     <mi>z</mi>
     <mi>i</mi>
     <msup>
      <mi></mi>
      <mo>′</mo>
     </msup>
    </msubsup>
    <mo rspace="7.5pt">,</mo>
    <msub>
     <mi>z</mi>
     <mrow>
      <mi>i</mi>
      <mo>+</mo>
      <mn>1</mn>
     </mrow>
    </msub>
    <mo>,</mo>
    <mi mathvariant="normal">…</mi>
    <mo rspace="7.5pt">,</mo>
    <msub>
     <mi>z</mi>
     <mi>m</mi>
    </msub>
    <mo stretchy="false">}</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <csymbol cd="ambiguous">superscript</csymbol>
     <ci>S</ci>
     <ci>i</ci>
    </apply>
    <set>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>z</ci>
      <cn type="integer">1</cn>
     </apply>
     <ci>normal-…</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>z</ci>
      <apply>
       <minus></minus>
       <ci>i</ci>
       <cn type="integer">1</cn>
      </apply>
     </apply>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>z</ci>
       <ci>i</ci>
      </apply>
      <apply>
       <ci>normal-′</ci>
      </apply>
     </apply>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>z</ci>
      <apply>
       <plus></plus>
       <ci>i</ci>
       <cn type="integer">1</cn>
      </apply>
     </apply>
     <ci>normal-…</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>z</ci>
      <ci>m</ci>
     </apply>
    </set>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   S^{i}=\{z_{1},...,\ z_{i-1},\ z_{i}^{^{\prime}},\ z_{i+1},...,\ z_{m}\}
  </annotation>
 </semantics>
</math>

</p>
<h2 id="definitions-of-stability">Definitions of stability</h2>
<h3 id="hypothesis-stability">Hypothesis Stability</h3>

<p>An algorithm 

<math display="inline" id="Stability_(learning_theory):40">
 <semantics>
  <mi>L</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>L</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   L
  </annotation>
 </semantics>
</math>

 has hypothesis stability β with respect to the loss function V if the following holds:</p>

<p>

<math display="inline" id="Stability_(learning_theory):41">
 <semantics>
  <mrow>
   <mrow>
    <mrow>
     <mrow>
      <mo>∀</mo>
      <mi>i</mi>
     </mrow>
     <mo>∈</mo>
     <mrow>
      <mo stretchy="false">{</mo>
      <mn>1</mn>
      <mo>,</mo>
      <mi mathvariant="normal">…</mi>
      <mo>,</mo>
      <mi>m</mi>
      <mo stretchy="false">}</mo>
     </mrow>
    </mrow>
    <mo>,</mo>
    <mrow>
     <mrow>
      <msub>
       <mi>𝔼</mi>
       <mrow>
        <mi>S</mi>
        <mo>,</mo>
        <mi>z</mi>
       </mrow>
      </msub>
      <mrow>
       <mo stretchy="false">[</mo>
       <mrow>
        <mo stretchy="false">|</mo>
        <mrow>
         <mrow>
          <mi>V</mi>
          <mrow>
           <mo stretchy="false">(</mo>
           <msub>
            <mi>f</mi>
            <mi>S</mi>
           </msub>
           <mo>,</mo>
           <mi>z</mi>
           <mo stretchy="false">)</mo>
          </mrow>
         </mrow>
         <mo>-</mo>
         <mrow>
          <mi>V</mi>
          <mrow>
           <mo stretchy="false">(</mo>
           <msub>
            <mi>f</mi>
            <msup>
             <mi>S</mi>
             <mrow>
              <mo stretchy="false">|</mo>
              <mi>i</mi>
             </mrow>
            </msup>
           </msub>
           <mo>,</mo>
           <mi>z</mi>
           <mo stretchy="false">)</mo>
          </mrow>
         </mrow>
        </mrow>
        <mo stretchy="false">|</mo>
       </mrow>
       <mo stretchy="false">]</mo>
      </mrow>
     </mrow>
     <mo>≤</mo>
     <mi>β</mi>
    </mrow>
   </mrow>
   <mo>.</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">formulae-sequence</csymbol>
    <apply>
     <in></in>
     <apply>
      <csymbol cd="latexml">for-all</csymbol>
      <ci>i</ci>
     </apply>
     <set>
      <cn type="integer">1</cn>
      <ci>normal-…</ci>
      <ci>m</ci>
     </set>
    </apply>
    <apply>
     <leq></leq>
     <apply>
      <times></times>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>𝔼</ci>
       <list>
        <ci>S</ci>
        <ci>z</ci>
       </list>
      </apply>
      <apply>
       <csymbol cd="latexml">delimited-[]</csymbol>
       <apply>
        <abs></abs>
        <apply>
         <minus></minus>
         <apply>
          <times></times>
          <ci>V</ci>
          <interval closure="open">
           <apply>
            <csymbol cd="ambiguous">subscript</csymbol>
            <ci>f</ci>
            <ci>S</ci>
           </apply>
           <ci>z</ci>
          </interval>
         </apply>
         <apply>
          <times></times>
          <ci>V</ci>
          <interval closure="open">
           <apply>
            <csymbol cd="ambiguous">subscript</csymbol>
            <ci>f</ci>
            <apply>
             <csymbol cd="ambiguous">superscript</csymbol>
             <ci>S</ci>
             <cerror>
              <csymbol cd="ambiguous">fragments</csymbol>
              <ci>normal-|</ci>
              <csymbol cd="unknown">i</csymbol>
             </cerror>
            </apply>
           </apply>
           <ci>z</ci>
          </interval>
         </apply>
        </apply>
       </apply>
      </apply>
     </apply>
     <ci>β</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \forall i\in\{1,...,m\},\mathbb{E}_{S,z}[|V(f_{S},z)-V(f_{S^{|i}},z)|]\leq\beta.
  </annotation>
 </semantics>
</math>

</p>
<h3 id="point-wise-hypothesis-stability">Point-wise Hypothesis Stability</h3>

<p>An algorithm 

<math display="inline" id="Stability_(learning_theory):42">
 <semantics>
  <mi>L</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>L</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   L
  </annotation>
 </semantics>
</math>

 has point-wise hypothesis stability β with respect to the loss function V if the following holds:</p>

<p>

<math display="inline" id="Stability_(learning_theory):43">
 <semantics>
  <mrow>
   <mrow>
    <mrow>
     <mrow>
      <mo>∀</mo>
      <mi>i</mi>
     </mrow>
     <mo rspace="7.5pt">∈</mo>
     <mrow>
      <mo stretchy="false">{</mo>
      <mn>1</mn>
      <mo>,</mo>
      <mi mathvariant="normal">…</mi>
      <mo>,</mo>
      <mi>m</mi>
      <mo stretchy="false">}</mo>
     </mrow>
    </mrow>
    <mo>,</mo>
    <mrow>
     <mrow>
      <msub>
       <mi>𝔼</mi>
       <mi>S</mi>
      </msub>
      <mrow>
       <mo stretchy="false">[</mo>
       <mrow>
        <mo stretchy="false">|</mo>
        <mrow>
         <mrow>
          <mi>V</mi>
          <mrow>
           <mo stretchy="false">(</mo>
           <msub>
            <mi>f</mi>
            <mi>S</mi>
           </msub>
           <mo>,</mo>
           <msub>
            <mi>z</mi>
            <mi>i</mi>
           </msub>
           <mo stretchy="false">)</mo>
          </mrow>
         </mrow>
         <mo>-</mo>
         <mrow>
          <mi>V</mi>
          <mrow>
           <mo stretchy="false">(</mo>
           <msub>
            <mi>f</mi>
            <msup>
             <mi>S</mi>
             <mrow>
              <mo stretchy="false">|</mo>
              <mi>i</mi>
             </mrow>
            </msup>
           </msub>
           <mo>,</mo>
           <msub>
            <mi>z</mi>
            <mi>i</mi>
           </msub>
           <mo stretchy="false">)</mo>
          </mrow>
         </mrow>
        </mrow>
        <mo stretchy="false">|</mo>
       </mrow>
       <mo stretchy="false">]</mo>
      </mrow>
     </mrow>
     <mo>≤</mo>
     <mi>β</mi>
    </mrow>
   </mrow>
   <mo>.</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">formulae-sequence</csymbol>
    <apply>
     <in></in>
     <apply>
      <csymbol cd="latexml">for-all</csymbol>
      <ci>i</ci>
     </apply>
     <set>
      <cn type="integer">1</cn>
      <ci>normal-…</ci>
      <ci>m</ci>
     </set>
    </apply>
    <apply>
     <leq></leq>
     <apply>
      <times></times>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>𝔼</ci>
       <ci>S</ci>
      </apply>
      <apply>
       <csymbol cd="latexml">delimited-[]</csymbol>
       <apply>
        <abs></abs>
        <apply>
         <minus></minus>
         <apply>
          <times></times>
          <ci>V</ci>
          <interval closure="open">
           <apply>
            <csymbol cd="ambiguous">subscript</csymbol>
            <ci>f</ci>
            <ci>S</ci>
           </apply>
           <apply>
            <csymbol cd="ambiguous">subscript</csymbol>
            <ci>z</ci>
            <ci>i</ci>
           </apply>
          </interval>
         </apply>
         <apply>
          <times></times>
          <ci>V</ci>
          <interval closure="open">
           <apply>
            <csymbol cd="ambiguous">subscript</csymbol>
            <ci>f</ci>
            <apply>
             <csymbol cd="ambiguous">superscript</csymbol>
             <ci>S</ci>
             <cerror>
              <csymbol cd="ambiguous">fragments</csymbol>
              <ci>normal-|</ci>
              <csymbol cd="unknown">i</csymbol>
             </cerror>
            </apply>
           </apply>
           <apply>
            <csymbol cd="ambiguous">subscript</csymbol>
            <ci>z</ci>
            <ci>i</ci>
           </apply>
          </interval>
         </apply>
        </apply>
       </apply>
      </apply>
     </apply>
     <ci>β</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \forall i\in\ \{1,...,m\},\mathbb{E}_{S}[|V(f_{S},z_{i})-V(f_{S^{|i}},z_{i})|]%
\leq\beta.
  </annotation>
 </semantics>
</math>

</p>
<h3 id="error-stability">Error Stability</h3>

<p>An algorithm 

<math display="inline" id="Stability_(learning_theory):44">
 <semantics>
  <mi>L</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>L</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   L
  </annotation>
 </semantics>
</math>

 has error stability β with respect to the loss function V if the following holds:</p>

<p>

<math display="inline" id="Stability_(learning_theory):45">
 <semantics>
  <mrow>
   <mrow>
    <mrow>
     <mo>∀</mo>
     <mi>S</mi>
    </mrow>
    <mo>∈</mo>
    <msup>
     <mi>Z</mi>
     <mi>m</mi>
    </msup>
   </mrow>
   <mo>,</mo>
   <mrow>
    <mrow>
     <mrow>
      <mo>∀</mo>
      <mi>i</mi>
     </mrow>
     <mo>∈</mo>
     <mrow>
      <mo stretchy="false">{</mo>
      <mn>1</mn>
      <mo>,</mo>
      <mi mathvariant="normal">…</mi>
      <mo>,</mo>
      <mi>m</mi>
      <mo stretchy="false">}</mo>
     </mrow>
    </mrow>
    <mo>,</mo>
    <mrow>
     <mrow>
      <mo stretchy="false">|</mo>
      <mrow>
       <mrow>
        <msub>
         <mi>𝔼</mi>
         <mi>z</mi>
        </msub>
        <mrow>
         <mo stretchy="false">[</mo>
         <mrow>
          <mi>V</mi>
          <mrow>
           <mo stretchy="false">(</mo>
           <msub>
            <mi>f</mi>
            <mi>S</mi>
           </msub>
           <mo>,</mo>
           <mi>z</mi>
           <mo stretchy="false">)</mo>
          </mrow>
         </mrow>
         <mo stretchy="false">]</mo>
        </mrow>
       </mrow>
       <mo>-</mo>
       <mrow>
        <msub>
         <mi>𝔼</mi>
         <mi>z</mi>
        </msub>
        <mrow>
         <mo stretchy="false">[</mo>
         <mrow>
          <mi>V</mi>
          <mrow>
           <mo stretchy="false">(</mo>
           <msub>
            <mi>f</mi>
            <msup>
             <mi>S</mi>
             <mrow>
              <mo stretchy="false">|</mo>
              <mi>i</mi>
             </mrow>
            </msup>
           </msub>
           <mo>,</mo>
           <mi>z</mi>
           <mo stretchy="false">)</mo>
          </mrow>
         </mrow>
         <mo stretchy="false">]</mo>
        </mrow>
       </mrow>
      </mrow>
      <mo stretchy="false">|</mo>
     </mrow>
     <mo>≤</mo>
     <mi>β</mi>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">formulae-sequence</csymbol>
    <apply>
     <in></in>
     <apply>
      <csymbol cd="latexml">for-all</csymbol>
      <ci>S</ci>
     </apply>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <ci>Z</ci>
      <ci>m</ci>
     </apply>
    </apply>
    <apply>
     <csymbol cd="ambiguous">formulae-sequence</csymbol>
     <apply>
      <in></in>
      <apply>
       <csymbol cd="latexml">for-all</csymbol>
       <ci>i</ci>
      </apply>
      <set>
       <cn type="integer">1</cn>
       <ci>normal-…</ci>
       <ci>m</ci>
      </set>
     </apply>
     <apply>
      <leq></leq>
      <apply>
       <abs></abs>
       <apply>
        <minus></minus>
        <apply>
         <times></times>
         <apply>
          <csymbol cd="ambiguous">subscript</csymbol>
          <ci>𝔼</ci>
          <ci>z</ci>
         </apply>
         <apply>
          <csymbol cd="latexml">delimited-[]</csymbol>
          <apply>
           <times></times>
           <ci>V</ci>
           <interval closure="open">
            <apply>
             <csymbol cd="ambiguous">subscript</csymbol>
             <ci>f</ci>
             <ci>S</ci>
            </apply>
            <ci>z</ci>
           </interval>
          </apply>
         </apply>
        </apply>
        <apply>
         <times></times>
         <apply>
          <csymbol cd="ambiguous">subscript</csymbol>
          <ci>𝔼</ci>
          <ci>z</ci>
         </apply>
         <apply>
          <csymbol cd="latexml">delimited-[]</csymbol>
          <apply>
           <times></times>
           <ci>V</ci>
           <interval closure="open">
            <apply>
             <csymbol cd="ambiguous">subscript</csymbol>
             <ci>f</ci>
             <apply>
              <csymbol cd="ambiguous">superscript</csymbol>
              <ci>S</ci>
              <cerror>
               <csymbol cd="ambiguous">fragments</csymbol>
               <ci>normal-|</ci>
               <csymbol cd="unknown">i</csymbol>
              </cerror>
             </apply>
            </apply>
            <ci>z</ci>
           </interval>
          </apply>
         </apply>
        </apply>
       </apply>
      </apply>
      <ci>β</ci>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \forall S\in Z^{m},\forall i\in\{1,...,m\},|\mathbb{E}_{z}[V(f_{S},z)]-\mathbb%
{E}_{z}[V(f_{S^{|i}},z)]|\leq\beta
  </annotation>
 </semantics>
</math>

</p>
<h3 id="uniform-stability">Uniform Stability</h3>

<p>An algorithm 

<math display="inline" id="Stability_(learning_theory):46">
 <semantics>
  <mi>L</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>L</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   L
  </annotation>
 </semantics>
</math>

 has uniform stability β with respect to the loss function V if the following holds:</p>

<p>

<math display="inline" id="Stability_(learning_theory):47">
 <semantics>
  <mrow>
   <mrow>
    <mrow>
     <mo>∀</mo>
     <mi>S</mi>
    </mrow>
    <mo>∈</mo>
    <msup>
     <mi>Z</mi>
     <mi>m</mi>
    </msup>
   </mrow>
   <mo>,</mo>
   <mrow>
    <mrow>
     <mrow>
      <mo>∀</mo>
      <mi>i</mi>
     </mrow>
     <mo>∈</mo>
     <mrow>
      <mo stretchy="false">{</mo>
      <mn>1</mn>
      <mo>,</mo>
      <mi mathvariant="normal">…</mi>
      <mo>,</mo>
      <mi>m</mi>
      <mo stretchy="false">}</mo>
     </mrow>
    </mrow>
    <mo>,</mo>
    <mrow>
     <mrow>
      <msub>
       <mo>sup</mo>
       <mrow>
        <mi>z</mi>
        <mo>∈</mo>
        <mi>Z</mi>
       </mrow>
      </msub>
      <mrow>
       <mo stretchy="false">|</mo>
       <mrow>
        <mrow>
         <mi>V</mi>
         <mrow>
          <mo stretchy="false">(</mo>
          <msub>
           <mi>f</mi>
           <mi>S</mi>
          </msub>
          <mo>,</mo>
          <mi>z</mi>
          <mo stretchy="false">)</mo>
         </mrow>
        </mrow>
        <mo>-</mo>
        <mrow>
         <mi>V</mi>
         <mrow>
          <mo stretchy="false">(</mo>
          <msub>
           <mi>f</mi>
           <msup>
            <mi>S</mi>
            <mi>i</mi>
           </msup>
          </msub>
          <mo>,</mo>
          <mi>z</mi>
          <mo stretchy="false">)</mo>
         </mrow>
        </mrow>
       </mrow>
       <mo stretchy="false">|</mo>
      </mrow>
     </mrow>
     <mo>≤</mo>
     <mi>β</mi>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">formulae-sequence</csymbol>
    <apply>
     <in></in>
     <apply>
      <csymbol cd="latexml">for-all</csymbol>
      <ci>S</ci>
     </apply>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <ci>Z</ci>
      <ci>m</ci>
     </apply>
    </apply>
    <apply>
     <csymbol cd="ambiguous">formulae-sequence</csymbol>
     <apply>
      <in></in>
      <apply>
       <csymbol cd="latexml">for-all</csymbol>
       <ci>i</ci>
      </apply>
      <set>
       <cn type="integer">1</cn>
       <ci>normal-…</ci>
       <ci>m</ci>
      </set>
     </apply>
     <apply>
      <leq></leq>
      <apply>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <csymbol cd="latexml">supremum</csymbol>
        <apply>
         <in></in>
         <ci>z</ci>
         <ci>Z</ci>
        </apply>
       </apply>
       <apply>
        <abs></abs>
        <apply>
         <minus></minus>
         <apply>
          <times></times>
          <ci>V</ci>
          <interval closure="open">
           <apply>
            <csymbol cd="ambiguous">subscript</csymbol>
            <ci>f</ci>
            <ci>S</ci>
           </apply>
           <ci>z</ci>
          </interval>
         </apply>
         <apply>
          <times></times>
          <ci>V</ci>
          <interval closure="open">
           <apply>
            <csymbol cd="ambiguous">subscript</csymbol>
            <ci>f</ci>
            <apply>
             <csymbol cd="ambiguous">superscript</csymbol>
             <ci>S</ci>
             <ci>i</ci>
            </apply>
           </apply>
           <ci>z</ci>
          </interval>
         </apply>
        </apply>
       </apply>
      </apply>
      <ci>β</ci>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \forall S\in Z^{m},\forall i\in\{1,...,m\},\sup_{z\in Z}|V(f_{S},z)-V(f_{S^{i}%
},z)|\leq\beta
  </annotation>
 </semantics>
</math>

</p>

<p>A probabilistic version of uniform stability β is:</p>

<p>

<math display="inline" id="Stability_(learning_theory):48">
 <semantics>
  <mrow>
   <mo>∀</mo>
   <mi>S</mi>
   <mo>∈</mo>
   <msup>
    <mi>Z</mi>
    <mi>m</mi>
   </msup>
   <mo>,</mo>
   <mo>∀</mo>
   <mi>i</mi>
   <mo>∈</mo>
   <mrow>
    <mo stretchy="false">{</mo>
    <mn>1</mn>
    <mo>,</mo>
    <mi mathvariant="normal">…</mi>
    <mo>,</mo>
    <mi>m</mi>
    <mo stretchy="false">}</mo>
   </mrow>
   <mo>,</mo>
   <msub>
    <mi>ℙ</mi>
    <mi>S</mi>
   </msub>
   <mrow>
    <mo stretchy="false">{</mo>
    <msub>
     <mo>sup</mo>
     <mrow>
      <mi>z</mi>
      <mo>∈</mo>
      <mi>Z</mi>
     </mrow>
    </msub>
    <mo stretchy="false">|</mo>
    <mi>V</mi>
    <mrow>
     <mo stretchy="false">(</mo>
     <msub>
      <mi>f</mi>
      <mi>S</mi>
     </msub>
     <mo>,</mo>
     <mi>z</mi>
     <mo stretchy="false">)</mo>
    </mrow>
    <mo>-</mo>
    <mi>V</mi>
    <mrow>
     <mo stretchy="false">(</mo>
     <msub>
      <mi>f</mi>
      <msup>
       <mi>S</mi>
       <mi>i</mi>
      </msup>
     </msub>
     <mo>,</mo>
     <mi>z</mi>
     <mo stretchy="false">)</mo>
    </mrow>
    <mo stretchy="false">|</mo>
    <mo>≤</mo>
    <mi>β</mi>
    <mo stretchy="false">}</mo>
   </mrow>
   <mo>≥</mo>
   <mn>1</mn>
   <mo>-</mo>
   <mi>δ</mi>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <cerror>
    <csymbol cd="ambiguous">fragments</csymbol>
    <csymbol cd="latexml">for-all</csymbol>
    <csymbol cd="unknown">S</csymbol>
    <in></in>
    <apply>
     <csymbol cd="ambiguous">superscript</csymbol>
     <ci>Z</ci>
     <ci>m</ci>
    </apply>
    <ci>normal-,</ci>
    <csymbol cd="latexml">for-all</csymbol>
    <csymbol cd="unknown">i</csymbol>
    <in></in>
    <cerror>
     <csymbol cd="ambiguous">fragments</csymbol>
     <ci>normal-{</ci>
     <cn type="integer">1</cn>
     <ci>normal-,</ci>
     <ci>normal-…</ci>
     <ci>normal-,</ci>
     <csymbol cd="unknown">m</csymbol>
     <ci>normal-}</ci>
    </cerror>
    <ci>normal-,</ci>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>ℙ</ci>
     <ci>S</ci>
    </apply>
    <cerror>
     <csymbol cd="ambiguous">fragments</csymbol>
     <ci>normal-{</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <csymbol cd="latexml">supremum</csymbol>
      <apply>
       <in></in>
       <ci>z</ci>
       <ci>Z</ci>
      </apply>
     </apply>
     <ci>normal-|</ci>
     <csymbol cd="unknown">V</csymbol>
     <cerror>
      <csymbol cd="ambiguous">fragments</csymbol>
      <ci>normal-(</ci>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>f</ci>
       <ci>S</ci>
      </apply>
      <ci>normal-,</ci>
      <csymbol cd="unknown">z</csymbol>
      <ci>normal-)</ci>
     </cerror>
     <minus></minus>
     <csymbol cd="unknown">V</csymbol>
     <cerror>
      <csymbol cd="ambiguous">fragments</csymbol>
      <ci>normal-(</ci>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>f</ci>
       <apply>
        <csymbol cd="ambiguous">superscript</csymbol>
        <ci>S</ci>
        <ci>i</ci>
       </apply>
      </apply>
      <ci>normal-,</ci>
      <csymbol cd="unknown">z</csymbol>
      <ci>normal-)</ci>
     </cerror>
     <ci>normal-|</ci>
     <leq></leq>
     <csymbol cd="unknown">β</csymbol>
     <ci>normal-}</ci>
    </cerror>
    <geq></geq>
    <cn type="integer">1</cn>
    <minus></minus>
    <csymbol cd="unknown">δ</csymbol>
   </cerror>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \forall S\in Z^{m},\forall i\in\{1,...,m\},\mathbb{P}_{S}\{\sup_{z\in Z}|V(f_{%
S},z)-V(f_{S^{i}},z)|\leq\beta\}\geq 1-\delta
  </annotation>
 </semantics>
</math>

</p>
<h3 id="leave-one-out-cross-validation-cvloo-stability">Leave-one-out cross-validation (CVloo) Stability</h3>

<p>An algorithm 

<math display="inline" id="Stability_(learning_theory):49">
 <semantics>
  <mi>L</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>L</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   L
  </annotation>
 </semantics>
</math>

 has CVloo stability β with respect to the loss function V if the following holds:</p>

<p>

<math display="inline" id="Stability_(learning_theory):50">
 <semantics>
  <mrow>
   <mo>∀</mo>
   <mi>i</mi>
   <mo>∈</mo>
   <mrow>
    <mo stretchy="false">{</mo>
    <mn>1</mn>
    <mo>,</mo>
    <mi mathvariant="normal">…</mi>
    <mo>,</mo>
    <mi>m</mi>
    <mo stretchy="false">}</mo>
   </mrow>
   <mo>,</mo>
   <msub>
    <mi>ℙ</mi>
    <mi>S</mi>
   </msub>
   <mrow>
    <mo stretchy="false">{</mo>
    <msub>
     <mo>sup</mo>
     <mrow>
      <mi>z</mi>
      <mo>∈</mo>
      <mi>Z</mi>
     </mrow>
    </msub>
    <mo stretchy="false">|</mo>
    <mi>V</mi>
    <mrow>
     <mo stretchy="false">(</mo>
     <msub>
      <mi>f</mi>
      <mi>S</mi>
     </msub>
     <mo>,</mo>
     <msub>
      <mi>z</mi>
      <mi>i</mi>
     </msub>
     <mo stretchy="false">)</mo>
    </mrow>
    <mo>-</mo>
    <mi>V</mi>
    <mrow>
     <mo stretchy="false">(</mo>
     <msub>
      <mi>f</mi>
      <msup>
       <mi>S</mi>
       <mrow>
        <mo stretchy="false">|</mo>
        <mi>i</mi>
       </mrow>
      </msup>
     </msub>
     <mo>,</mo>
     <msub>
      <mi>z</mi>
      <mi>i</mi>
     </msub>
     <mo stretchy="false">)</mo>
    </mrow>
    <mo stretchy="false">|</mo>
    <mo>≤</mo>
    <msub>
     <mi>β</mi>
     <mrow>
      <mi>C</mi>
      <mi>V</mi>
     </mrow>
    </msub>
    <mo stretchy="false">}</mo>
   </mrow>
   <mo>≥</mo>
   <mn>1</mn>
   <mo>-</mo>
   <msub>
    <mi>δ</mi>
    <mrow>
     <mi>C</mi>
     <mi>V</mi>
    </mrow>
   </msub>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <cerror>
    <csymbol cd="ambiguous">fragments</csymbol>
    <csymbol cd="latexml">for-all</csymbol>
    <csymbol cd="unknown">i</csymbol>
    <in></in>
    <cerror>
     <csymbol cd="ambiguous">fragments</csymbol>
     <ci>normal-{</ci>
     <cn type="integer">1</cn>
     <ci>normal-,</ci>
     <ci>normal-…</ci>
     <ci>normal-,</ci>
     <csymbol cd="unknown">m</csymbol>
     <ci>normal-}</ci>
    </cerror>
    <ci>normal-,</ci>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>ℙ</ci>
     <ci>S</ci>
    </apply>
    <cerror>
     <csymbol cd="ambiguous">fragments</csymbol>
     <ci>normal-{</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <csymbol cd="latexml">supremum</csymbol>
      <apply>
       <in></in>
       <ci>z</ci>
       <ci>Z</ci>
      </apply>
     </apply>
     <ci>normal-|</ci>
     <csymbol cd="unknown">V</csymbol>
     <cerror>
      <csymbol cd="ambiguous">fragments</csymbol>
      <ci>normal-(</ci>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>f</ci>
       <ci>S</ci>
      </apply>
      <ci>normal-,</ci>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>z</ci>
       <ci>i</ci>
      </apply>
      <ci>normal-)</ci>
     </cerror>
     <minus></minus>
     <csymbol cd="unknown">V</csymbol>
     <cerror>
      <csymbol cd="ambiguous">fragments</csymbol>
      <ci>normal-(</ci>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>f</ci>
       <apply>
        <csymbol cd="ambiguous">superscript</csymbol>
        <ci>S</ci>
        <cerror>
         <csymbol cd="ambiguous">fragments</csymbol>
         <ci>normal-|</ci>
         <csymbol cd="unknown">i</csymbol>
        </cerror>
       </apply>
      </apply>
      <ci>normal-,</ci>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>z</ci>
       <ci>i</ci>
      </apply>
      <ci>normal-)</ci>
     </cerror>
     <ci>normal-|</ci>
     <leq></leq>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>β</ci>
      <apply>
       <times></times>
       <ci>C</ci>
       <ci>V</ci>
      </apply>
     </apply>
     <ci>normal-}</ci>
    </cerror>
    <geq></geq>
    <cn type="integer">1</cn>
    <minus></minus>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>δ</ci>
     <apply>
      <times></times>
      <ci>C</ci>
      <ci>V</ci>
     </apply>
    </apply>
   </cerror>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \forall i\in\{1,...,m\},\mathbb{P}_{S}\{\sup_{z\in Z}|V(f_{S},z_{i})-V(f_{S^{|%
i}},z_{i})|\leq\beta_{CV}\}\geq 1-\delta_{CV}
  </annotation>
 </semantics>
</math>

</p>
<h3 id="expected-leave-one-out-error-eloo_err-stability">Expected-leave-one-out error (

<math display="inline" id="Stability_(learning_theory):51">
 <semantics>
  <mrow>
   <mi>E</mi>
   <mi>l</mi>
   <mi>o</mi>
   <msub>
    <mi>o</mi>
    <mrow>
     <mi>e</mi>
     <mi>r</mi>
     <mi>r</mi>
    </mrow>
   </msub>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <ci>E</ci>
    <ci>l</ci>
    <ci>o</ci>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>o</ci>
     <apply>
      <times></times>
      <ci>e</ci>
      <ci>r</ci>
      <ci>r</ci>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   Eloo_{err}
  </annotation>
 </semantics>
</math>

) Stability</h3>

<p>An algorithm 

<math display="inline" id="Stability_(learning_theory):52">
 <semantics>
  <mi>L</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>L</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   L
  </annotation>
 </semantics>
</math>

 has 

<math display="inline" id="Stability_(learning_theory):53">
 <semantics>
  <mrow>
   <mi>E</mi>
   <mi>l</mi>
   <mi>o</mi>
   <msub>
    <mi>o</mi>
    <mrow>
     <mi>e</mi>
     <mi>r</mi>
     <mi>r</mi>
    </mrow>
   </msub>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <ci>E</ci>
    <ci>l</ci>
    <ci>o</ci>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>o</ci>
     <apply>
      <times></times>
      <ci>e</ci>
      <ci>r</ci>
      <ci>r</ci>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   Eloo_{err}
  </annotation>
 </semantics>
</math>

 stability if for each n there exists a 

<math display="inline" id="Stability_(learning_theory):54">
 <semantics>
  <msubsup>
   <mi>β</mi>
   <mrow>
    <mi>E</mi>
    <mi>L</mi>
   </mrow>
   <mi>m</mi>
  </msubsup>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">superscript</csymbol>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>β</ci>
     <apply>
      <times></times>
      <ci>E</ci>
      <ci>L</ci>
     </apply>
    </apply>
    <ci>m</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \beta_{EL}^{m}
  </annotation>
 </semantics>
</math>

 and a 

<math display="inline" id="Stability_(learning_theory):55">
 <semantics>
  <msubsup>
   <mi>δ</mi>
   <mrow>
    <mi>E</mi>
    <mi>L</mi>
   </mrow>
   <mi>m</mi>
  </msubsup>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">superscript</csymbol>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>δ</ci>
     <apply>
      <times></times>
      <ci>E</ci>
      <ci>L</ci>
     </apply>
    </apply>
    <ci>m</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \delta_{EL}^{m}
  </annotation>
 </semantics>
</math>

 such that:</p>

<p>

<math display="inline" id="Stability_(learning_theory):56">
 <semantics>
  <mrow>
   <mo>∀</mo>
   <mi>i</mi>
   <mo>∈</mo>
   <mrow>
    <mo stretchy="false">{</mo>
    <mn>1</mn>
    <mo>,</mo>
    <mi mathvariant="normal">…</mi>
    <mo>,</mo>
    <mi>m</mi>
    <mo stretchy="false">}</mo>
   </mrow>
   <mo>,</mo>
   <msub>
    <mi>ℙ</mi>
    <mi>S</mi>
   </msub>
   <mrow>
    <mo stretchy="false">{</mo>
    <mo stretchy="false">|</mo>
    <mi>I</mi>
    <mrow>
     <mo stretchy="false">[</mo>
     <msub>
      <mi>f</mi>
      <mi>S</mi>
     </msub>
     <mo stretchy="false">]</mo>
    </mrow>
    <mo>-</mo>
    <mfrac>
     <mn>1</mn>
     <mi>m</mi>
    </mfrac>
    <msubsup>
     <mo largeop="true" symmetric="true">∑</mo>
     <mrow>
      <mi>i</mi>
      <mo>=</mo>
      <mn>1</mn>
     </mrow>
     <mi>m</mi>
    </msubsup>
    <mi>V</mi>
    <mrow>
     <mo stretchy="false">(</mo>
     <msub>
      <mi>f</mi>
      <msup>
       <mi>S</mi>
       <mrow>
        <mo stretchy="false">|</mo>
        <mi>i</mi>
       </mrow>
      </msup>
     </msub>
     <mo>,</mo>
     <msub>
      <mi>z</mi>
      <mi>i</mi>
     </msub>
     <mo stretchy="false">)</mo>
    </mrow>
    <mo stretchy="false">|</mo>
    <mo>≤</mo>
    <msubsup>
     <mi>β</mi>
     <mrow>
      <mi>E</mi>
      <mi>L</mi>
     </mrow>
     <mi>m</mi>
    </msubsup>
    <mo stretchy="false">}</mo>
   </mrow>
   <mo>≥</mo>
   <mn>1</mn>
   <mo>-</mo>
   <msubsup>
    <mi>δ</mi>
    <mrow>
     <mi>E</mi>
     <mi>L</mi>
    </mrow>
    <mi>m</mi>
   </msubsup>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <cerror>
    <csymbol cd="ambiguous">fragments</csymbol>
    <csymbol cd="latexml">for-all</csymbol>
    <csymbol cd="unknown">i</csymbol>
    <in></in>
    <cerror>
     <csymbol cd="ambiguous">fragments</csymbol>
     <ci>normal-{</ci>
     <cn type="integer">1</cn>
     <ci>normal-,</ci>
     <ci>normal-…</ci>
     <ci>normal-,</ci>
     <csymbol cd="unknown">m</csymbol>
     <ci>normal-}</ci>
    </cerror>
    <ci>normal-,</ci>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>ℙ</ci>
     <ci>S</ci>
    </apply>
    <cerror>
     <csymbol cd="ambiguous">fragments</csymbol>
     <ci>normal-{</ci>
     <ci>normal-|</ci>
     <csymbol cd="unknown">I</csymbol>
     <cerror>
      <csymbol cd="ambiguous">fragments</csymbol>
      <ci>normal-[</ci>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>f</ci>
       <ci>S</ci>
      </apply>
      <ci>normal-]</ci>
     </cerror>
     <minus></minus>
     <apply>
      <divide></divide>
      <cn type="integer">1</cn>
      <ci>m</ci>
     </apply>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <sum></sum>
       <apply>
        <eq></eq>
        <ci>i</ci>
        <cn type="integer">1</cn>
       </apply>
      </apply>
      <ci>m</ci>
     </apply>
     <csymbol cd="unknown">V</csymbol>
     <cerror>
      <csymbol cd="ambiguous">fragments</csymbol>
      <ci>normal-(</ci>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>f</ci>
       <apply>
        <csymbol cd="ambiguous">superscript</csymbol>
        <ci>S</ci>
        <cerror>
         <csymbol cd="ambiguous">fragments</csymbol>
         <ci>normal-|</ci>
         <csymbol cd="unknown">i</csymbol>
        </cerror>
       </apply>
      </apply>
      <ci>normal-,</ci>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>z</ci>
       <ci>i</ci>
      </apply>
      <ci>normal-)</ci>
     </cerror>
     <ci>normal-|</ci>
     <leq></leq>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>β</ci>
       <apply>
        <times></times>
        <ci>E</ci>
        <ci>L</ci>
       </apply>
      </apply>
      <ci>m</ci>
     </apply>
     <ci>normal-}</ci>
    </cerror>
    <geq></geq>
    <cn type="integer">1</cn>
    <minus></minus>
    <apply>
     <csymbol cd="ambiguous">superscript</csymbol>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>δ</ci>
      <apply>
       <times></times>
       <ci>E</ci>
       <ci>L</ci>
      </apply>
     </apply>
     <ci>m</ci>
    </apply>
   </cerror>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \forall i\in\{1,...,m\},\mathbb{P}_{S}\{|I[f_{S}]-\frac{1}{m}\sum_{i=1}^{m}V(f%
_{S^{|i}},z_{i})|\leq\beta_{EL}^{m}\}\geq 1-\delta_{EL}^{m}
  </annotation>
 </semantics>
</math>

, with 

<math display="inline" id="Stability_(learning_theory):57">
 <semantics>
  <msubsup>
   <mi>β</mi>
   <mrow>
    <mi>E</mi>
    <mi>L</mi>
   </mrow>
   <mi>m</mi>
  </msubsup>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">superscript</csymbol>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>β</ci>
     <apply>
      <times></times>
      <ci>E</ci>
      <ci>L</ci>
     </apply>
    </apply>
    <ci>m</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \beta_{EL}^{m}
  </annotation>
 </semantics>
</math>

 and 

<math display="inline" id="Stability_(learning_theory):58">
 <semantics>
  <msubsup>
   <mi>δ</mi>
   <mrow>
    <mi>E</mi>
    <mi>L</mi>
   </mrow>
   <mi>m</mi>
  </msubsup>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">superscript</csymbol>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>δ</ci>
     <apply>
      <times></times>
      <ci>E</ci>
      <ci>L</ci>
     </apply>
    </apply>
    <ci>m</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \delta_{EL}^{m}
  </annotation>
 </semantics>
</math>

 going to zero for 

<math display="inline" id="Stability_(learning_theory):59">
 <semantics>
  <mrow>
   <mi>n</mi>
   <mo>→</mo>
   <mo>inf</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <ci>normal-→</ci>
    <ci>n</ci>
    <csymbol cd="latexml">infimum</csymbol>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   n\rightarrow\inf
  </annotation>
 </semantics>
</math>

</p>
<h2 id="classic-theorems">Classic theorems</h2>

<p><strong>From Bousquet and Elisseeff (02)</strong>:</p>

<p>For symmetric learning algorithms with bounded loss, if the algorithm has Uniform Stability with the probabilistic definition above, then the algorithm generalizes.</p>

<p>Uniform Stability is a strong condition which is not met by all algorithms but is, surprisingly, met by the large and important class of Regularization algorithms. The generalization bound is given in the article.</p>

<p><strong>From Mukherjee et al. (06)</strong>:</p>
<ul>
<li>For symmetric learning algorithms with bounded loss, if the algorithm has <em>both</em> Leave-one-out cross-validation (CVloo) Stability and Expected-leave-one-out error (

<math display="inline" id="Stability_(learning_theory):60">
 <semantics>
  <mrow>
   <mi>E</mi>
   <mi>l</mi>
   <mi>o</mi>
   <msub>
    <mi>o</mi>
    <mrow>
     <mi>e</mi>
     <mi>r</mi>
     <mi>r</mi>
    </mrow>
   </msub>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <ci>E</ci>
    <ci>l</ci>
    <ci>o</ci>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>o</ci>
     <apply>
      <times></times>
      <ci>e</ci>
      <ci>r</ci>
      <ci>r</ci>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   Eloo_{err}
  </annotation>
 </semantics>
</math>

) Stability as defined above, then the algorithm generalizes.</li>
<li>Neither condition alone is sufficient for generalization. However, both together ensure generalization (while the converse is not true).</li>
<li>For ERM algorithms specifically (say for the square loss), Leave-one-out cross-validation (CVloo) Stability is both necessary and sufficient for consistency and generalization.</li>
</ul>

<p>This is an important result for the foundations of learning theory, because it shows that two previously unrelated properties of an algorithm, stability and consistency, are equivalent for ERM (and certain loss functions). The generalization bound is given in the article.</p>
<h2 id="algorithms-that-are-stable">Algorithms that are stable</h2>

<p>This is a list of algorithms that have been shown to be stable, and the article where the associated generalization bounds are provided.</p>
<ul>
<li><a href="Linear_regression" title="wikilink">Linear regression</a><ref>Elisseeff, A. A study about algorithmic stability and</ref></li>
</ul>

<p><code>their relation to generalization performances. Technical</code><br/>
<code>report. (2000)</code></p>

<p></p>
<ul>
<li>k-NN classifier with a {0-1} loss function.<a class="footnoteRef" href="#fn7" id="fnref7"><sup>7</sup></a></li>
<li><a href="Support_Vector_Machine" title="wikilink">Support Vector Machine</a> (SVM) classification with a bounded kernel and where the regularizer is a norm in a Reproducing Kernel Hilbert Space. A large regularization constant 

<math display="inline" id="Stability_(learning_theory):61">
 <semantics>
  <mi>C</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>C</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   C
  </annotation>
 </semantics>
</math>

 leads to good stability.<a class="footnoteRef" href="#fn8" id="fnref8"><sup>8</sup></a></li>
<li>Soft margin SVM classification.<a class="footnoteRef" href="#fn9" id="fnref9"><sup>9</sup></a></li>
<li><a href="regularization_(machine_learning)" title="wikilink">Regularized</a> Least Squares regression.<a class="footnoteRef" href="#fn10" id="fnref10"><sup>10</sup></a></li>
<li>The minimum relative entropy algorithm for classification.<a class="footnoteRef" href="#fn11" id="fnref11"><sup>11</sup></a></li>
<li>A version of <a href="bootstrap_aggregating" title="wikilink">bagging</a> regularizers with the number 

<math display="inline" id="Stability_(learning_theory):62">
 <semantics>
  <mi>k</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>k</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   k
  </annotation>
 </semantics>
</math>

 of regressors increasing with 

<math display="inline" id="Stability_(learning_theory):63">
 <semantics>
  <mi>n</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>n</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   n
  </annotation>
 </semantics>
</math>

.<ref>Rifkin, R. Everything Old is New Again: A fresh</ref></li>
</ul>

<p><code>look at historical approaches in machine learning. Ph.D. Thesis, MIT, 2002</code></p>
<ul>
<li>Multi-class SVM classification.<ref>Rifkin, R. Everything Old is New Again: A fresh</ref></li>
</ul>

<p><code>look at historical approaches in machine learning. Ph.D. Thesis, MIT, 2002</code></p>
<h2 id="references">References</h2>
<h2 id="further-reading">Further reading</h2>
<ul>
<li>S.Kutin and P.Niyogi.Almost-everywhere algorithmic stability and generalization error. In Proc. of UAI 18, 2002</li>
<li>S. Rakhlin, S. Mukherjee, and T. Poggio. Stability results in learning theory. Analysis and Applications, 3(4):397–419, 2005</li>
<li>V.N. Vapnik. The Nature of Statistical Learning Theory. Springer, 1995</li>
<li>Vapnik, V., Statistical Learning Theory. Wiley, New York, 1998</li>
<li>Poggio, T., Rifkin, R., Mukherjee, S. and Niyogi, P., "Learning Theory: general conditions for predictivity", Nature, Vol. 428, 419-422, 2004</li>
<li>Andre Elisseeff, Theodoros Evgeniou, Massimiliano Pontil, Stability of Randomized Learning Algorithms, Journal of Machine Learning Research 6, 55–79, 2010</li>
<li>Elisseeff, A. Pontil, M., Leave-one-out Error and Stability of Learning Algorithms with Applications, NATO SCIENCE SERIES SUB SERIES III COMPUTER AND SYSTEMS SCIENCES, 2003, VOL 190, pages 111-130</li>
<li>Shalev Shwartz, S., Shamir,O., Srebro, N.,Sridharan, K., Learnability, Stability and Uniform Convergence, Journal of Machine Learning Research, 11(Oct):2635-2670, 2010</li>
</ul>

<p>"</p>

<p><a href="Category:Machine_learning" title="wikilink">Category:Machine learning</a> <a class="uri" href="Category:Learning" title="wikilink">Category:Learning</a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1">L. Devroye and Wagner, Distribution-free performance bounds for potential function rules, IEEE Trans. Inform. Theory 25(5) (1979) 601–604.<a href="#fnref1">↩</a></li>
<li id="fn2">M. Kearns and <a href="Dana_Ron" title="wikilink">D. Ron</a>, Algorithmic stability and sanity-check bounds for leave-one-out cross-validation, Neural Comput. 11(6) (1999) 1427–1453.<a href="#fnref2">↩</a></li>
<li id="fn3">O. Bousquet and A. Elisseeff. Stability and generalization. J. Mach. Learn. Res., 2:499–526, 2002.<a href="#fnref3">↩</a></li>
<li id="fn4">S. Kutin and P. Niyogi, Almost-everywhere algorithmic stability and generalization error, Technical Report TR-2002-03, University of Chicago (2002).<a href="#fnref4">↩</a></li>
<li id="fn5">S. Mukherjee, P. Niyogi, T. Poggio, and R. M. Rifkin. Learning theory: stability is sufficient for generalization and necessary and sufficient for consistency of empirical risk minimization. Adv. Comput. Math., 25(1-3):161–193, 2006.<a href="#fnref5">↩</a></li>
<li id="fn6">Shalev Shwartz, S., Shamir,O., Srebro, N.,Sridharan, K., Learnability, Stability and Uniform Convergence, Journal of Machine Learning Research, 11(Oct):2635-2670, 2010.<a href="#fnref6">↩</a></li>
<li id="fn7">L. Devroye and Wagner, Distribution-free performance bounds for potential function rules, IEEE Trans. Inform. Theory 25(5) (1979) 601–604.<a href="#fnref7">↩</a></li>
<li id="fn8">O. Bousquet and A. Elisseeff. Stability and generalization. J. Mach. Learn. Res., 2:499–526, 2002.<a href="#fnref8">↩</a></li>
<li id="fn9">O. Bousquet and A. Elisseeff. Stability and generalization. J. Mach. Learn. Res., 2:499–526, 2002.<a href="#fnref9">↩</a></li>
<li id="fn10">O. Bousquet and A. Elisseeff. Stability and generalization. J. Mach. Learn. Res., 2:499–526, 2002.<a href="#fnref10">↩</a></li>
<li id="fn11">O. Bousquet and A. Elisseeff. Stability and generalization. J. Mach. Learn. Res., 2:499–526, 2002.<a href="#fnref11">↩</a></li>
</ol>
</section>
</body>
</html>
