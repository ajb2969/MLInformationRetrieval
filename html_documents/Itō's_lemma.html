<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title offset="969">Itō's lemma</title>
   <script type="text/javascript"
      src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js">
    </script>
</head>
<body>
<h1>Itō's lemma</h1>
<hr/>
<p>In <a class="uri" href="mathematics" title="wikilink">mathematics</a>, <strong>Itō's lemma</strong> is an identity used in <a href="Itō_calculus" title="wikilink">Itō calculus</a> to find the <a href="differential_(calculus)" title="wikilink">differential</a> of a time-dependent function of a <a href="stochastic_process" title="wikilink">stochastic process</a>. It serves as the stochastic calculus counterpart of the <a href="chain_rule" title="wikilink">chain rule</a>. Typically, it is memorized by forming the <a href="Taylor_series" title="wikilink">Taylor series</a> expansion of the function up to its second derivatives and identifying the square of an increment in the <a href="Wiener_process" title="wikilink">Wiener process</a> with an increment in time. The lemma is widely employed in <a href="mathematical_finance" title="wikilink">mathematical finance</a>, and its best known application is in the derivation of the <a href="Black–Scholes_equation" title="wikilink">Black–Scholes equation</a> for option values.</p>
<p>Itō's lemma, which is named after <a href="Kiyoshi_Itō" title="wikilink">Kiyoshi Itō</a>, is occasionally referred to as the Itō–Döblin theorem in recognition of the recently discovered work of <a href="Wolfgang_Döblin" title="wikilink">Wolfgang Döblin</a>.<a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a></p>
<p>Note that while Ito's lemma was proved by Kiyoshi Itō, <a href="Itô's_theorem" title="wikilink">Itô's theorem</a>, a result in <a href="group_theory" title="wikilink">group theory</a>, is due to <a href="Noboru_Itô" title="wikilink">Noboru Itô</a>.<a class="footnoteRef" href="#fn2" id="fnref2"><sup>2</sup></a></p>
<h2 id="informal-derivation">Informal derivation</h2>
<p>A formal proof of the lemma relies on taking the limit of a sequence of random variables. This approach is not presented here since it involves a number of technical details. Instead, we give a sketch of how one can derive Itō's lemma by expanding a Taylor series and applying the rules of stochastic calculus.</p>
<p>Assume <mtpl></mtpl> is a <a href="Itō_calculus#Itō_processes" title="wikilink">Itō drift-diffusion process</a> that satisfies the <a href="stochastic_differential_equation" title="wikilink">stochastic differential equation</a></p>
<p><span class="LaTeX">$$dX_t= \mu_t \, dt + \sigma_t \, dB_t,$$</span></p>
<p>where <mtpl></mtpl> is a <a href="Wiener_process" title="wikilink">Wiener process</a>. If <span class="LaTeX">$f ( t , x )$</span> is a twice-differentiable scalar function, its expansion in a <a href="Taylor_series" title="wikilink">Taylor series</a> is</p>
<p><span class="LaTeX">$$df = \frac{\partial f}{\partial t}\,dt + \frac{\partial f}{\partial x}\,dx + \frac{1}{2}\frac{\partial^2 f}{\partial x^2}\,dx^2 + \cdots .$$</span></p>
<p>Substituting <mtpl></mtpl> for <span class="LaTeX">$x$</span> and <mtpl></mtpl> for <mtpl></mtpl> gives</p>
<p><span class="LaTeX">$$df = \frac{\partial f}{\partial t}\,dt + \frac{\partial f}{\partial x}(\mu_t\,dt + \sigma_t\,dB_t) + \frac{1}{2}\frac{\partial^2 f}{\partial x^2} \left (\mu_t^2\,dt^2 + 2\mu_t\sigma_t\,dt\,dB_t + \sigma_t^2\,dB_t^2 \right ) + \cdots.$$</span></p>
<p>In the limit as <span class="LaTeX">$dt → 0$</span>, the terms <mtpl></mtpl> and <mtpl></mtpl> tend to zero faster than <mtpl></mtpl>, which is <span class="LaTeX">$O ( dt )$</span>. Setting the <mtpl></mtpl> and <mtpl></mtpl> terms to zero, substituting <span class="LaTeX">$dt$</span> for <mtpl></mtpl>, and collecting the <span class="LaTeX">$dt$</span> and <span class="LaTeX">$dB$</span> terms, we obtain</p>
<p><span class="LaTeX">$$df = \left(\frac{\partial f}{\partial t} + \mu_t\frac{\partial f}{\partial x} + \frac{\sigma_t^2}{2}\frac{\partial^2 f}{\partial x^2}\right)dt + \sigma_t\frac{\partial f}{\partial x}\,dB_t$$</span></p>
<p>as required.</p>
<h2 id="mathematical-formulation-of-itōs-lemma">Mathematical formulation of Itō's lemma</h2>
<p>In the following subsections we discuss versions of Itō's lemma for different types of stochastic processes.</p>
<h3 id="itō-drift-diffusion-processes">Itō drift-diffusion processes</h3>
<p>In its simplest form, Itō's lemma states the following: for an <a href="Itō_calculus#Itō_processes" title="wikilink">Itō drift-diffusion process</a></p>
<p><span class="LaTeX">$$dX_t= \mu_t \, dt + \sigma_t \, dB_t$$</span></p>
<p>and any twice <a class="uri" href="differentiable" title="wikilink">differentiable</a> scalar function <span class="LaTeX">$f ( t , x )$</span> of two real variables <span class="LaTeX">$t$</span> and <span class="LaTeX">$x$</span>, one has</p>
<p><span class="LaTeX">$$df(t,X_t) =\left(\frac{\partial f}{\partial t} + \mu_t \frac{\partial f}{\partial x} + \frac{\sigma_t^2}{2}\frac{\partial^2f}{\partial x^2}\right)dt+ \sigma_t \frac{\partial f}{\partial x}\,dB_t.$$</span></p>
<p>This immediately implies that <mtpl></mtpl> is itself an Itō drift-diffusion process.</p>
<p>In higher dimensions, if <span class="LaTeX">$\mathbf{X}_t = (X^1_t, X^2_t, \ldots, X^n_t)^T$</span> is a vector of Itō processes such that</p>
<p><span class="LaTeX">$$d\mathbf{X}_t = \boldsymbol{\mu}_t\, dt + \mathbf{G}_t\, d\mathbf{B}_t$$</span></p>
<p>for a vector <span class="LaTeX">$\boldsymbol{\mu}_t$</span> and matrix <span class="LaTeX">$\mathbf{G}_t$</span>, Itō's lemma then states that</p>
<p><span class="LaTeX">$$\begin{align}
df(t,\mathbf{X}_t) &= \frac{\partial f}{\partial t}\, dt + \left (\nabla_\mathbf{X} f \right )^T\, d\mathbf{X}_t + \frac{1}{2} \left(d\mathbf{X}_t \right )^T \left( H_\mathbf{X} f \right) \, d\mathbf{X}_t, \\
                   &= \left\{ \frac{\partial f}{\partial t} + \left (\nabla_\mathbf{X} f \right)^T \boldsymbol{\mu}_t + \frac{1}{2}\text{Tr}\left[ \mathbf{G}_t^T \left( H_\mathbf{X} f \right) \mathbf{G}_t \right] \right\} dt + \left (\nabla_\mathbf{X} f \right)^T \mathbf{G}_t\, d\mathbf{B}_t
\end{align}$$</span></p>
<p>where <mtpl></mtpl> is the <a class="uri" href="gradient" title="wikilink">gradient</a> of <span class="LaTeX">$f$</span> w.r.t. <span class="LaTeX">$X$</span>, <mtpl></mtpl> is the <a href="Hessian_matrix" title="wikilink">Hessian matrix</a> of <span class="LaTeX">$f$</span> w.r.t. <span class="LaTeX">$X$</span>, and <span class="LaTeX">$Tr$</span> is the trace operator.</p>
<h3 id="poisson-jump-processes">Poisson jump processes</h3>
<p>We may also define functions on discontinuous stochastic processes.</p>
<p>Let <span class="LaTeX">$h$</span> be the jump intensity. The <a href="Poisson_process" title="wikilink">Poisson process</a> model for jumps is that the probability of one jump in the interval <span class="LaTeX">$t t , t + Δ t$</span> is <span class="LaTeX">$h Δ t$</span> plus higher order terms. <span class="LaTeX">$h$</span> could be a constant, a deterministic function of time, or a stochastic process. The survival probability <mtpl></mtpl> is the probability that no jump has occurred in the interval <span class="LaTeX">$0, t$</span>. The change in the survival probability is</p>
<p><span class="LaTeX">$$d p_s(t) = -p_s(t) h(t) \, dt.$$</span></p>
<p>So</p>
<p><span class="LaTeX">$$p_s(t) = \exp \left(-\int_0^t h(u) \, du \right).$$</span></p>
<p>Let <span class="LaTeX">$S ( t )$</span> be a discontinuous stochastic process. Write <span class="LaTeX">$S(t^-)$</span> for the value of <em>S</em> as we approach <em>t</em> from the left. Write <span class="LaTeX">$d_j S(t)$</span> for the non-infinitesimal change in <span class="LaTeX">$S ( t )$</span> as a result of a jump. Then</p>
<p><span class="LaTeX">$$d_j S(t)=\lim_{\Delta t \to 0}(S(t+\Delta t)-S(t^-))$$</span></p>
<p>Let <em>z</em> be the magnitude of the jump and let <span class="LaTeX">$\eta(S(t^-),z)$</span> be the <a href="Probability_distribution" title="wikilink">distribution</a> of <em>z</em>. The expected magnitude of the jump is</p>
<p><span class="LaTeX">$$E[d_j S(t)]=h(S(t^-)) \, dt \int_z z \eta(S(t^-),z) \, dz.$$</span></p>
<p>Define <span class="LaTeX">$d J_S(t)$</span>, a <a href="compensated_process" title="wikilink">compensated process</a> and <a href="Martingale_(probability_theory)" title="wikilink">martingale</a>, as</p>
<p><span class="LaTeX">$$d J_S(t)=d_j S(t)-E[d_j S(t)]=S(t)-S(t^-) - \left ( h(S(t^-))\int_z z \eta \left (S(t^-),z \right) \, dz \right ) \, dt.$$</span></p>
<p>Then</p>
<p><span class="LaTeX">$$d_j S(t) = E[d_j S(t)] + d J_S(t) = h(S(t^-)) \left  (\int_z z \eta(S(t^-),z) \, dz \right ) dt + d J_S(t).$$</span></p>
<p>Consider a function <span class="LaTeX">$g(S(t),t)$</span> of jump process <span class="LaTeX">$dS ( t )$</span>. If <span class="LaTeX">$S ( t )$</span> jumps by <span class="LaTeX">$Δ s$</span> then <span class="LaTeX">$g ( t )$</span> jumps by <span class="LaTeX">$Δ g$</span>. <span class="LaTeX">$Δ g$</span> is drawn from distribution <span class="LaTeX">$\eta_g()$</span> which may depend on <span class="LaTeX">$g(t^-)$</span>, <em>dg</em> and <span class="LaTeX">$S(t^-)$</span>. The jump part of <span class="LaTeX">$g$</span> is</p>
<p><span class="LaTeX">$$g(t)-g(t^-) =h(t) \, dt \int_{\Delta g} \, \Delta g \eta_g(\cdot) \, d\Delta g + d J_g(t).$$</span></p>
<p>If <span class="LaTeX">$S$</span> contains drift, diffusion and jump parts, then Itō's Lemma for <span class="LaTeX">$g(S(t),t)$</span> is</p>
<p><span class="LaTeX">$$d g(t) = \left( \frac{\partial g}{\partial t}+\mu \frac{\partial g}{\partial S}+\frac{\sigma^2}{2} \frac{\partial^2 g}{\partial S^2} + h(t) \int_{\Delta g} \left (\Delta g \eta_g(\cdot) \, d{\Delta}g \right ) \, \right) dt + \frac{\partial g}{\partial S} \sigma \, d W(t) + d J_g(t).$$</span></p>
<p>Itō's lemma for a process which is the sum of a drift-diffusion process and a jump process is just the sum of the Itō's lemma for the individual parts.</p>
<h3 id="non-continuous-semimartingales">Non-continuous semimartingales</h3>
<p>Itō's lemma can also be applied to general <span class="LaTeX">$d$</span>-dimensional <a href="semimartingale" title="wikilink">semimartingales</a>, which need not be continuous. In general, a semimartingale is a <a class="uri" href="càdlàg" title="wikilink">càdlàg</a> process, and an additional term needs to be added to the formula to ensure that the jumps of the process are correctly given by Itō's lemma. For any cadlag process <mtpl></mtpl>, the left limit in <span class="LaTeX">$t$</span> is denoted by <mtpl></mtpl>, which is a left-continuous process. The jumps are written as <mtpl> <em>Y<sub>t</sub></em> − <em>Y<sub>t−</sub></em>}}</mtpl>. Then, Itō's lemma states that if <mtpl> (<em>X</em><sup>1</sup>, <em>X</em><sup>2</sup>, ..., <em>X<sup>d</sup></em>)}}</mtpl> is a <span class="LaTeX">$d$</span>-dimensional semimartingale and <em>f</em> is a twice continuously differentiable real valued function on <mtpl></mtpl> then <em>f</em>(<em>X</em>) is a semimartingale, and</p>
<p><span class="LaTeX">$$\begin{align}
f(X_t)
&=
f(X_0)
+\sum_{i=1}^d\int_0^t f_{i}(X_{s-})\,dX^i_s
+ \frac{1}{2}\sum_{i,j=1}^d \int_0^t f_{i,j}(X_{s-})\,d[X^i,X^j]_s\\
&\qquad+ \sum_{s\le t} \left(\Delta f(X_s)-\sum_{i=1}^df_{i}(X_{s-})\,\Delta X^i_s
-\frac{1}{2}\sum_{i,j=1}^d f_{i,j}(X_{s-})\,\Delta X^i_s \, \Delta X^j_s\right).
\end{align}$$</span></p>
<p>This differs from the formula for continuous semimartingales by the additional term summing over the jumps of <em>X</em>, which ensures that the jump of the right hand side at time <span class="LaTeX">$t$</span> is Δ<em>f</em>(<em>X<sub>t</sub></em>).</p>
<h2 id="examples">Examples</h2>
<h3 id="geometric-brownian-motion">Geometric Brownian motion</h3>
<p>A process S is said to follow a <a href="geometric_Brownian_motion" title="wikilink">geometric Brownian motion</a> with volatility <em>σ</em> and drift <em>μ</em> if it satisfies the <a href="stochastic_differential_equation" title="wikilink">stochastic differential equation</a> <span class="LaTeX">$dS = S ( σdB + μdt )$</span>, for a Brownian motion <em>B</em>. Applying Itō's lemma with <em>f</em>(<em>S</em>) = log(<em>S</em>) gives</p>
<p><span class="LaTeX">$$\begin{align}
d\log(S) & = f^\prime(S)\,dS + \frac{1}{2}f^{\prime\prime} (S)S^2\sigma^2 \,dt \\
& = \frac{1}{S} \left( \sigma S\,dB + \mu S\,dt\right) - \frac{1}{2}\sigma^2\,dt \\
&= \sigma\,dB +\left (\mu-\tfrac{\sigma^2}{2} \right )\,dt.
\end{align}$$</span></p>
<p>It follows that</p>
<p><span class="LaTeX">$$\log (S_t) = \log (S_0) + \sigma B_t + \left (\mu-\tfrac{\sigma^2}{2} \right )t,$$</span></p>
<p>exponentiating gives the expression for <em>S</em>,</p>
<p><span class="LaTeX">$$S_t=S_0\exp\left(\sigma B_t+ \left (\mu-\tfrac{\sigma^2}{2} \right )t\right).$$</span></p>
<p>The correction term of <mtpl></mtpl> corresponds to the difference between the median and mean of the <a href="log-normal_distribution" title="wikilink">log-normal distribution</a>, or equivalently for this distribution, the geometric mean and arithmetic mean, with the median (geometric mean) being lower. This is due to the <a href="AM–GM_inequality" title="wikilink">AM–GM inequality</a>, and corresponds to the logarithm being convex down, so the correction term can accordingly be interpreted as a <a href="convexity_correction" title="wikilink">convexity correction</a>. This is an infinitesimal version of the fact that the <a href="annualized_return" title="wikilink">annualized return</a> is less than the average return, with the difference proportional to the variance. See <a href="Log-normal_distribution#Geometric_moments" title="wikilink">geometric moments of the log-normal distribution</a> for further discussion.</p>
<p>The same factor of <mtpl></mtpl> appears in the <em>d</em><sub>1</sub> and <em>d</em><sub>2</sub> auxiliary variables of the <a href="Black–Scholes_formula" title="wikilink">Black–Scholes formula</a>, and can be <a href="Black–Scholes#Interpretation" title="wikilink">interpreted</a> as a consequence of Itō's lemma.</p>
<h3 id="doléans-dade-exponential">Doléans-Dade exponential</h3>
<p>The <a href="Doléans-Dade_exponential" title="wikilink">Doléans-Dade exponential</a> (or stochastic exponential) of a continuous semimartingale <em>X</em> can be defined as the solution to the SDE <span class="LaTeX">$dY = Y dX$</span> with initial condition <mtpl> 1}}</mtpl>. It is sometimes denoted by <span class="LaTeX">$ ( X )$</span>. Applying Itō's lemma with <em>f</em>(<em>Y</em>) = log(<em>Y</em>) gives</p>
<p><span class="LaTeX">$$\begin{align}
d\log(Y) &= \frac{1}{Y}\,dY -\frac{1}{2Y^2}\,d[Y] \\
&= dX - \tfrac{1}{2}\,d[X].
\end{align}$$</span></p>
<p>Exponentiating gives the solution</p>
<p><span class="LaTeX">$$Y_t = \exp\left(X_t-X_0-\tfrac{1}{2} [X]_t\right).$$</span></p>
<h3 id="blackscholes-formula">Black–Scholes formula</h3>
<p>Itō's lemma can be used to derive the <a href="Black–Scholes#The_Black.E2.80.93Scholes_equation" title="wikilink">Black–Scholes equation</a> for an <a href="Option_(finance)" title="wikilink">option</a>. Suppose a stock price follows a <a href="geometric_Brownian_motion" title="wikilink">geometric Brownian motion</a> given by the stochastic differential equation <span class="LaTeX">$dS = S ( σdB + μ dt )$</span>. Then, if the value of an option at time <span class="LaTeX">$t$</span> is <em>f</em>(<em>t</em>, <em>S<sub>t</sub></em>), Itō's lemma gives</p>
<p><span class="LaTeX">$$df(t,S_t) = \left(\frac{\partial f}{\partial t} + \frac{1}{2}\left(S_t\sigma\right)^2\frac{\partial^2 f}{\partial S^2}\right)\,dt +\frac{\partial f}{\partial S}\,dS_t.$$</span></p>
<p>The term <span class="LaTeX">$∂\frac{f}{∂} dS$</span> represents the change in value in time <em>dt</em> of the trading strategy consisting of holding an amount <span class="LaTeX">$∂\frac{f}{∂}$</span> of the stock. If this trading strategy is followed, and any cash held is assumed to grow at the risk free rate <em>r</em>, then the total value <em>V</em> of this portfolio satisfies the <a href="Stochastic_differential_equation" title="wikilink">SDE</a></p>
<p><span class="LaTeX">$$dV_t = r\left(V_t-\frac{\partial f}{\partial S}S_t\right)\,dt + \frac{\partial f}{\partial S}\,dS_t.$$</span></p>
<p>This strategy replicates the option if <em>V</em> = <em>f</em>(<em>t</em>,<em>S</em>). Combining these equations gives the celebrated Black–Scholes equation</p>
<p><span class="LaTeX">$$\frac{\partial f}{\partial t} + \frac{\sigma^2S^2}{2}\frac{\partial^2 f}{\partial S^2} + rS\frac{\partial f}{\partial S}-rf = 0.$$</span></p>
<h2 id="see-also">See also</h2>
<ul>
<li><a href="Wiener_process" title="wikilink">Wiener process</a></li>
<li><a href="Itō_calculus" title="wikilink">Itō calculus</a></li>
<li><a href="Feynman–Kac_formula" title="wikilink">Feynman–Kac formula</a></li>
</ul>
<h2 id="notes">Notes</h2>
<h2 id="references">References</h2>
<ul>
<li><a href="Kiyoshi_Itō" title="wikilink">Kiyoshi Itō</a> (1944). Stochastic Integral. <em>Proc. Imperial Acad. Tokyo</em> <strong>20</strong>, 519-524. This is the paper with the Ito Formula; [<a class="uri" href="http://projecteuclid.org/DPubS?service=UI&version">http://projecteuclid.org/DPubS?service=UI&version</a>;=1.0&verb;=Display&handle;=euclid.pja/1195572786 <em>Online</em>]</li>
<li><a href="Kiyoshi_Itō" title="wikilink">Kiyoshi Itō</a> (1951). On stochastic differential equations. <em>Memoirs, American Mathematical Society</em> <strong>4</strong>, 1–51. <a href="http://archive.org/details/onstochasticdiff029540mbp"><em>Online</em></a></li>
<li><a href="Bernt_Øksendal" title="wikilink">Bernt Øksendal</a> (2000). <em>Stochastic Differential Equations. An Introduction with Applications</em>, 5th edition, corrected 2nd printing. Springer. ISBN 3-540-63720-6. Sections 4.1 and 4.2.</li>
</ul>
<h2 id="external-links">External links</h2>
<ul>
<li><a href="http://www2.sjsu.edu/faculty/watkins/ito.htm">Derivation</a>, Prof. Thayer Watkins</li>
<li><a href="http://www.ftsmodules.com/public/texts/optiontutor/chap6.8.htm">Informal proof</a>, optiontutor</li>
</ul>
<p>"</p>
<p><a href="Category:Stochastic_calculus" title="wikilink">Category:Stochastic calculus</a> <a class="uri" href="Category:Lemmas" title="wikilink">Category:Lemmas</a> <a class="uri" href="Category:Equations" title="wikilink">Category:Equations</a> <a href="Category:Probability_theorems" title="wikilink">Category:Probability theorems</a> <a href="Category:Statistical_theorems" title="wikilink">Category:Statistical theorems</a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1"><a href="http://mahalanobis.twoday.net/stories/756201/">"Stochastic Calculus :: Itô–Döblin formula", Michael Stastny</a><a href="#fnref1">↩</a></li>
<li id="fn2"><a href="http://mathworld.wolfram.com/ItosLemma.html">Ito's Lemma - from Wolfram MathWorld.</a><a href="#fnref2">↩</a></li>
</ol>
</section>
</body>
</html>
