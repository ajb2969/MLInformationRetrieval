<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="381">Clustering high-dimensional data</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>Clustering high-dimensional data</h1>
<hr/>

<p><strong>Clustering high-dimensional data</strong> is the <a href="cluster_analysis" title="wikilink">cluster analysis</a> of data with anywhere from a few dozen to many thousands of <a href="dimension" title="wikilink">dimensions</a>. Such high-dimensional data spaces are often encountered in areas such as medicine, where <a href="DNA_microarray" title="wikilink">DNA microarray</a> technology can produce a large number of measurements at once, and the clustering of text documents, where, if a word-frequency vector is used, the number of dimensions equals the <a href="Heaps'_law" title="wikilink">size of the vocabulary</a>.</p>
<h2 id="problems">Problems</h2>

<p>Four problems need to be overcome for clustering in high-dimensional data:<a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a></p>
<ul>
<li>Multiple dimensions are hard to think in, impossible to visualize, and, due to the exponential growth of the number of possible values with each dimension, complete enumeration of all subspaces becomes intractable with increasing dimensionality. This problem is known as the <a href="curse_of_dimensionality" title="wikilink">curse of dimensionality</a>.</li>
<li>The concept of distance becomes less precise as the number of dimensions grows, since the distance between any two points in a given dataset converges. The discrimination of the nearest and farthest point in particular becomes meaningless:</li>
</ul>
<dl>
<dd><dl>
<dd>

<math display="inline" id="Clustering_high-dimensional_data:0">
 <semantics>
  <mrow>
   <mrow>
    <msub>
     <mo>lim</mo>
     <mrow>
      <mi>d</mi>
      <mo>→</mo>
      <mi mathvariant="normal">∞</mi>
     </mrow>
    </msub>
    <mfrac>
     <mrow>
      <mrow>
       <mi>d</mi>
       <mi>i</mi>
       <mi>s</mi>
       <msub>
        <mi>t</mi>
        <mi>max</mi>
       </msub>
      </mrow>
      <mo>-</mo>
      <mrow>
       <mi>d</mi>
       <mi>i</mi>
       <mi>s</mi>
       <msub>
        <mi>t</mi>
        <mi>min</mi>
       </msub>
      </mrow>
     </mrow>
     <mrow>
      <mi>d</mi>
      <mi>i</mi>
      <mi>s</mi>
      <msub>
       <mi>t</mi>
       <mi>min</mi>
      </msub>
     </mrow>
    </mfrac>
   </mrow>
   <mo>=</mo>
   <mn>0</mn>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <limit></limit>
      <apply>
       <ci>normal-→</ci>
       <ci>d</ci>
       <infinity></infinity>
      </apply>
     </apply>
     <apply>
      <divide></divide>
      <apply>
       <minus></minus>
       <apply>
        <times></times>
        <ci>d</ci>
        <ci>i</ci>
        <ci>s</ci>
        <apply>
         <csymbol cd="ambiguous">subscript</csymbol>
         <ci>t</ci>
         <max></max>
        </apply>
       </apply>
       <apply>
        <times></times>
        <ci>d</ci>
        <ci>i</ci>
        <ci>s</ci>
        <apply>
         <csymbol cd="ambiguous">subscript</csymbol>
         <ci>t</ci>
         <min></min>
        </apply>
       </apply>
      </apply>
      <apply>
       <times></times>
       <ci>d</ci>
       <ci>i</ci>
       <ci>s</ci>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <ci>t</ci>
        <min></min>
       </apply>
      </apply>
     </apply>
    </apply>
    <cn type="integer">0</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \lim_{d\to\infty}\frac{dist_{\max}-dist_{\min}}{dist_{\min}}=0
  </annotation>
 </semantics>
</math>


</dd>
</dl>
</dd>
</dl>
<ul>
<li>A cluster is intended to group objects that are related, based on observations of their attribute's values. However, given a large number of attributes some of the attributes will usually not be meaningful for a given cluster. For example, in <a href="newborn_screening" title="wikilink">newborn screening</a> a cluster of samples might identify newborns that share similar blood values, which might lead to insights about the relevance of certain blood values for a disease. But for different diseases, different blood values might form a cluster, and other values might be uncorrelated. This is known as the <em>local feature relevance</em> problem: different clusters might be found in different subspaces, so a global filtering of attributes is not sufficient.</li>
<li>Given a large number of attributes, it is likely that some attributes are <a class="uri" href="correlated" title="wikilink">correlated</a>. Hence, clusters might exist in arbitrarily oriented <a href="affine_subspace" title="wikilink">affine subspaces</a>.</li>
</ul>

<p>Recent research indicates that the discrimination problems only occur when there is a high number of irrelevant dimensions, and that shared-nearest-neighbor approaches can improve results.<a class="footnoteRef" href="#fn2" id="fnref2"><sup>2</sup></a></p>
<h2 id="approaches">Approaches</h2>

<p>Approaches towards clustering in axis-parallel or arbitrarily oriented <a href="affine_subspace" title="wikilink">affine subspaces</a> differ in how they interpret the overall goal, which is finding clusters in data with high dimensionality.<a class="footnoteRef" href="#fn3" id="fnref3"><sup>3</sup></a> An overall different approach is to find clusters based on <a class="uri" href="pattern" title="wikilink">pattern</a> in the data matrix, often referred to as <a class="uri" href="biclustering" title="wikilink">biclustering</a>, which is a technique frequently utilized in <a class="uri" href="bioinformatics" title="wikilink">bioinformatics</a>.</p>
<h3 id="subspace-clustering">Subspace clustering</h3>
<figure><b>(Figure)</b>
<figcaption>Example 2D space with subspace clusters</figcaption>
</figure>

<p>Subspace clustering is the task of detecting <em>all</em> clusters in <em>all subspaces</em>. This means that a point might be a member of multiple clusters, each existing in a different subspace. Subspaces can either be axis-parallel or affine. The term is often used synonymously with general clustering in high-dimensional data.</p>

<p>The image on the right shows a mere two-dimensional space where a number of clusters can be identified. In the one-dimensional subspaces, the clusters 

<math display="inline" id="Clustering_high-dimensional_data:1">
 <semantics>
  <msub>
   <mi>c</mi>
   <mi>a</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>c</ci>
    <ci>a</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   c_{a}
  </annotation>
 </semantics>
</math>

 (in subspace 

<math display="inline" id="Clustering_high-dimensional_data:2">
 <semantics>
  <mrow>
   <mo stretchy="false">{</mo>
   <mi>x</mi>
   <mo stretchy="false">}</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <set>
    <ci>x</ci>
   </set>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \{x\}
  </annotation>
 </semantics>
</math>

) and 

<math display="inline" id="Clustering_high-dimensional_data:3">
 <semantics>
  <msub>
   <mi>c</mi>
   <mi>b</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>c</ci>
    <ci>b</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   c_{b}
  </annotation>
 </semantics>
</math>

, 

<math display="inline" id="Clustering_high-dimensional_data:4">
 <semantics>
  <msub>
   <mi>c</mi>
   <mi>c</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>c</ci>
    <ci>c</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   c_{c}
  </annotation>
 </semantics>
</math>

, 

<math display="inline" id="Clustering_high-dimensional_data:5">
 <semantics>
  <msub>
   <mi>c</mi>
   <mi>d</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>c</ci>
    <ci>d</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   c_{d}
  </annotation>
 </semantics>
</math>

 (in subspace 

<math display="inline" id="Clustering_high-dimensional_data:6">
 <semantics>
  <mrow>
   <mo stretchy="false">{</mo>
   <mi>y</mi>
   <mo stretchy="false">}</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <set>
    <ci>y</ci>
   </set>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \{y\}
  </annotation>
 </semantics>
</math>

) can be found. 

<math display="inline" id="Clustering_high-dimensional_data:7">
 <semantics>
  <msub>
   <mi>c</mi>
   <mi>c</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>c</ci>
    <ci>c</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   c_{c}
  </annotation>
 </semantics>
</math>

 cannot be considered a cluster in a two-dimensional (sub-)space, since it is too sparsely distributed in the 

<math display="inline" id="Clustering_high-dimensional_data:8">
 <semantics>
  <mi>x</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>x</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   x
  </annotation>
 </semantics>
</math>

 axis. In two dimensions, the two clusters 

<math display="inline" id="Clustering_high-dimensional_data:9">
 <semantics>
  <msub>
   <mi>c</mi>
   <mrow>
    <mi>a</mi>
    <mi>b</mi>
   </mrow>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>c</ci>
    <apply>
     <times></times>
     <ci>a</ci>
     <ci>b</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   c_{ab}
  </annotation>
 </semantics>
</math>

 and 

<math display="inline" id="Clustering_high-dimensional_data:10">
 <semantics>
  <msub>
   <mi>c</mi>
   <mrow>
    <mi>a</mi>
    <mi>d</mi>
   </mrow>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>c</ci>
    <apply>
     <times></times>
     <ci>a</ci>
     <ci>d</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   c_{ad}
  </annotation>
 </semantics>
</math>

 can be identified.</p>

<p>The problem of subspace clustering is given by the fact that there are 

<math display="inline" id="Clustering_high-dimensional_data:11">
 <semantics>
  <msup>
   <mn>2</mn>
   <mi>d</mi>
  </msup>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">superscript</csymbol>
    <cn type="integer">2</cn>
    <ci>d</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   2^{d}
  </annotation>
 </semantics>
</math>

 different subspaces of a space with 

<math display="inline" id="Clustering_high-dimensional_data:12">
 <semantics>
  <mi>d</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>d</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   d
  </annotation>
 </semantics>
</math>

 dimensions. If the subspaces are not axis-parallel, an infinite number of subspaces is possible. Hence, subspace clustering algorithm utilize some kind of <a class="uri" href="heuristic" title="wikilink">heuristic</a> to remain computationally feasible, at the risk of producing inferior results. For example, the <em>downward-closure property</em> (cf. <a href="association_rule_learning" title="wikilink">association rules</a>) can be used to build higher-dimensional subspaces only by combining lower-dimensional ones, as any subspace T containing a cluster, will result in a full space S also to contain that cluster (i.e. S ⊆ T), an approach taken by most of the traditional algorithms such as CLIQUE,<a class="footnoteRef" href="#fn4" id="fnref4"><sup>4</sup></a> <a class="uri" href="SUBCLU" title="wikilink">SUBCLU</a>.<a class="footnoteRef" href="#fn5" id="fnref5"><sup>5</sup></a> It is also possible to define a subspace using different degrees of relevance for each dimension, an approach taken by iMWK-Means.<a class="footnoteRef" href="#fn6" id="fnref6"><sup>6</sup></a></p>
<h3 id="projected-clustering">Projected clustering</h3>

<p>Projected clustering seeks to assign each point to a unique cluster, but clusters may exist in different subspaces. The general approach is to use a special <a href="distance_function" title="wikilink">distance function</a> together with a regular <a href="cluster_analysis" title="wikilink">clustering algorithm</a>.</p>

<p>For example, the PreDeCon algorithm checks which attributes seem to support a clustering for each point, and adjusts the distance function such that dimensions with low <a class="uri" href="variance" title="wikilink">variance</a> are amplified in the distance function.<a class="footnoteRef" href="#fn7" id="fnref7"><sup>7</sup></a> In the figure above, the cluster 

<math display="inline" id="Clustering_high-dimensional_data:13">
 <semantics>
  <msub>
   <mi>c</mi>
   <mi>c</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>c</ci>
    <ci>c</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   c_{c}
  </annotation>
 </semantics>
</math>

 might be found using <a class="uri" href="DBSCAN" title="wikilink">DBSCAN</a> with a distance function that places less emphasis on the 

<math display="inline" id="Clustering_high-dimensional_data:14">
 <semantics>
  <mi>x</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>x</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   x
  </annotation>
 </semantics>
</math>

-axis and thus exaggerates the low difference in the 

<math display="inline" id="Clustering_high-dimensional_data:15">
 <semantics>
  <mi>y</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>y</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   y
  </annotation>
 </semantics>
</math>

-axis sufficiently enough to group the points into a cluster.</p>

<p>PROCLUS uses a similar approach with a <a class="uri" href="k-medoid" title="wikilink">k-medoid</a> clustering.<a class="footnoteRef" href="#fn8" id="fnref8"><sup>8</sup></a> Initial medoids are guessed, and for each medoid the subspace spanned by attributes with low variance is determined. Points are assigned to the medoid closest, considering only the subspace of that medoid in determining the distance. The algorithm then proceeds as the regular <a href="Partitioning_Around_Medoids" title="wikilink">PAM</a> algorithm.</p>

<p>If the distance function weights attributes differently, but never with 0 (and hence never drops irrelevant attributes), the algorithm is called a <em>"soft"-projected clustering algorithm</em>.</p>
<h3 id="hybrid-approaches">Hybrid approaches</h3>

<p>Not all algorithms try to either find a unique cluster assignment for each point or all clusters in all subspaces; many settle for a result in between, where a number of possibly overlapping, but not necessarily exhaustive set of clusters are found. An example is FIRES, which is from its basic approach a subspace clustering algorithm, but uses a <a class="uri" href="heuristic" title="wikilink">heuristic</a> too aggressive to credibly produce all subspace clusters.<a class="footnoteRef" href="#fn9" id="fnref9"><sup>9</sup></a></p>
<h3 id="correlation-clustering">Correlation clustering</h3>

<p>Another type of subspaces is considered in <a href="Correlation_clustering" title="wikilink">Correlation clustering (Data Mining)</a>.</p>
<h2 id="software">Software</h2>
<ul>
<li><a class="uri" href="ELKI" title="wikilink">ELKI</a> includes various subspace and correlation clustering algorithms</li>
</ul>
<h2 id="references">References</h2>
<references>
</references>

<p>"</p>

<p><a href="Category:Cluster_analysis" title="wikilink">Category:Cluster analysis</a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1"><a href="#fnref1">↩</a></li>
<li id="fn2"><a href="#fnref2">↩</a></li>
<li id="fn3"></li>
<li id="fn4"><a href="#fnref4">↩</a></li>
<li id="fn5"><a href="#fnref5">↩</a></li>
<li id="fn6"><a href="#fnref6">↩</a></li>
<li id="fn7"><a href="#fnref7">↩</a></li>
<li id="fn8"><a href="#fnref8">↩</a></li>
<li id="fn9"><a href="#fnref9">↩</a></li>
</ol>
</section>
</body>
</html>
