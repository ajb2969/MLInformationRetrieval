<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="971">Directed acyclic graph</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>Directed acyclic graph</h1>
<hr/>

<p> In <a class="uri" href="mathematics" title="wikilink">mathematics</a> and <a href="computer_science" title="wikilink">computer science</a>, a <strong>directed acyclic graph</strong> (<strong>DAG</strong> ), is a <a href="directed_graph" title="wikilink">directed graph</a> with no <a href="Cycle_graph#Directed_cycle_graph" title="wikilink">directed cycles</a>. That is, it is formed by a collection of <a href="Vertex_(graph_theory)" title="wikilink">vertices</a> and <a href="edge_(graph_theory)" title="wikilink">directed edges</a>, each edge connecting one vertex to another, such that there is no way to start at some vertex <em>v</em> and follow a sequence of edges that eventually loops back to <em>v</em> again.<a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a><a class="footnoteRef" href="#fn2" id="fnref2"><sup>2</sup></a><a class="footnoteRef" href="#fn3" id="fnref3"><sup>3</sup></a></p>

<p>DAGs may be used to model many different kinds of information. The <a class="uri" href="reachability" title="wikilink">reachability</a> relation in a DAG forms a <a href="partial_order" title="wikilink">partial order</a>, and any <a href="finite_set" title="wikilink">finite</a> partial order may be represented by a DAG using reachability. A collection of tasks that must be ordered into a sequence, subject to constraints that certain tasks must be performed earlier than others, may be represented as a DAG with a vertex for each task and an edge for each constraint; algorithms for <a href="topological_ordering" title="wikilink">topological ordering</a> may be used to generate a valid sequence. Additionally, DAGs may be used as a space-efficient representation of a collection of sequences with overlapping subsequences. DAGs are also used to represent systems of events or potential events and the <a href="causality" title="wikilink">causal relationships</a> between them. DAGs may also be used to model processes in which data flows in a consistent direction through a network of processors, or states of a repository in a version-control system.</p>

<p>The corresponding concept for <a href="undirected_graph" title="wikilink">undirected graphs</a> is a <a href="forest_(graph_theory)" title="wikilink">forest</a>, an undirected graph without cycles. Choosing an orientation for a forest produces a special kind of directed acyclic graph called a <a class="uri" href="polytree" title="wikilink">polytree</a>. However there are many other kinds of directed acyclic graph that are not formed by orienting the edges of an undirected acyclic graph. Moreover, every undirected graph has an <a href="acyclic_orientation" title="wikilink">acyclic orientation</a>, an assignment of a direction for its edges that makes it into a directed acyclic graph. For these reasons it would be more accurate to call directed acyclic graphs <strong>acyclic directed graphs</strong> or <strong>acyclic digraphs</strong>.</p>
<h2 id="mathematical-properties">Mathematical properties</h2>
<h3 id="reachability-transitive-closure-and-transitive-reduction">Reachability, transitive closure, and transitive reduction</h3>

<p> Each directed acyclic graph gives rise to a <a href="partial_order" title="wikilink">partial order</a> ≤ on its vertices, where <em>u</em> ≤ <em>v</em> exactly when there exists a directed path from <em>u</em> to <em>v</em> in the DAG.<a class="footnoteRef" href="#fn4" id="fnref4"><sup>4</sup></a> However, many different DAGs may give rise to this same <a class="uri" href="reachability" title="wikilink">reachability</a> relation:<a class="footnoteRef" href="#fn5" id="fnref5"><sup>5</sup></a> for example, the DAG with two edges <em>a</em> → <em>b</em> and <em>b</em> → <em>c</em> has the same reachability as the graph with three edges <em>a</em> → <em>b</em>, <em>b</em> → <em>c</em>, and <em>a</em> → <em>c</em>. If <em>G</em> is a DAG, its <a href="transitive_reduction" title="wikilink">transitive reduction</a> is the graph with the fewest edges that represents the same reachability as <em>G</em>, and its <a href="transitive_closure" title="wikilink">transitive closure</a> is the graph with the most edges that represents the same reachability. The transitive reduction and transitive closure are both uniquely defined for DAGs; in contrast, for a directed graph that is not acyclic, there can be more than one minimal subgraph with the same reachability relation.<a class="footnoteRef" href="#fn6" id="fnref6"><sup>6</sup></a></p>

<p>The transitive closure of <em>G</em> has an edge <em>u</em> → <em>v</em> for every related pair <em>u</em> ≤ <em>v</em> of distinct elements in the reachability relation of <em>G</em>, and may therefore be thought of as a direct translation of the reachability relation ≤ into graph-theoretic terms: every partially ordered set may be translated into a DAG in this way. If a DAG <em>G</em> represents a partial order ≤, then the transitive reduction of <em>G</em> is a subgraph of <em>G</em> with an edge <em>u</em> → <em>v</em> for every pair in the <a href="covering_relation" title="wikilink">covering relation</a> of ≤; transitive reductions are useful in visualizing the partial orders they represent, because they have fewer edges than other graphs representing the same orders and therefore lead to simpler <a href="graph_drawing" title="wikilink">graph drawings</a>. A <a href="Hasse_diagram" title="wikilink">Hasse diagram</a> of a partial order is a drawing of the transitive reduction in which the orientation of each edge is shown by placing the starting vertex of the edge in a lower position than its ending vertex.<a class="footnoteRef" href="#fn7" id="fnref7"><sup>7</sup></a></p>
<h3 id="topological-ordering">Topological ordering</h3>

<p>Every directed acyclic graph has a <a href="topological_ordering" title="wikilink">topological ordering</a>, an ordering of the vertices such that the starting endpoint of every edge occurs earlier in the ordering than the ending endpoint of the edge. In general, this ordering is not unique; a DAG has a unique topological ordering if and only if it has a directed path containing all the vertices, in which case the ordering is the same as the order in which the vertices appear in the path.<a class="footnoteRef" href="#fn8" id="fnref8"><sup>8</sup></a> The family of topological orderings of a DAG is the same as the family of <a href="linear_extension" title="wikilink">linear extensions</a> of the reachability relation for the DAG,<a class="footnoteRef" href="#fn9" id="fnref9"><sup>9</sup></a> so any two graphs representing the same partial order have the same set of topological orders.</p>
<h3 id="combinatorial-enumeration">Combinatorial enumeration</h3>

<p>The <a href="graph_enumeration" title="wikilink">graph enumeration</a> problem of counting directed acyclic graphs was studied by .<a class="footnoteRef" href="#fn10" id="fnref10"><sup>10</sup></a> The number of DAGs on <em>n</em> labeled nodes, for <em>n</em> = 0, 1, 2, 3, …, (allowing these numbers to appear in any order in a topological ordering of the DAG) is</p>
<dl>
<dd>1, 1, 3, 25, 543, 29281, 3781503, … .
</dd>
</dl>

<p>These numbers may be computed by the <a href="recurrence_relation" title="wikilink">recurrence relation</a></p>

<p>

<math display="block" id="Directed_acyclic_graph:0">
 <semantics>
  <mrow>
   <mrow>
    <msub>
     <mi>a</mi>
     <mi>n</mi>
    </msub>
    <mo>=</mo>
    <mrow>
     <munderover>
      <mo largeop="true" movablelimits="false" symmetric="true">∑</mo>
      <mrow>
       <mi>k</mi>
       <mo>=</mo>
       <mn>1</mn>
      </mrow>
      <mi>n</mi>
     </munderover>
     <mrow>
      <msup>
       <mrow>
        <mo stretchy="false">(</mo>
        <mrow>
         <mo>-</mo>
         <mn>1</mn>
        </mrow>
        <mo stretchy="false">)</mo>
       </mrow>
       <mrow>
        <mi>k</mi>
        <mo>-</mo>
        <mn>1</mn>
       </mrow>
      </msup>
      <mrow>
       <mo>(</mo>
       <mtable columnspacing="0.4em" rowspacing="0.2ex">
        <mtr>
         <mtd>
          <mi>n</mi>
         </mtd>
        </mtr>
        <mtr>
         <mtd>
          <mi>k</mi>
         </mtd>
        </mtr>
       </mtable>
       <mo>)</mo>
      </mrow>
      <msup>
       <mn>2</mn>
       <mrow>
        <mi>k</mi>
        <mrow>
         <mo stretchy="false">(</mo>
         <mrow>
          <mi>n</mi>
          <mo>-</mo>
          <mi>k</mi>
         </mrow>
         <mo stretchy="false">)</mo>
        </mrow>
       </mrow>
      </msup>
      <msub>
       <mi>a</mi>
       <mrow>
        <mi>n</mi>
        <mo>-</mo>
        <mi>k</mi>
       </mrow>
      </msub>
     </mrow>
    </mrow>
   </mrow>
   <mo>.</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>a</ci>
     <ci>n</ci>
    </apply>
    <apply>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <sum></sum>
       <apply>
        <eq></eq>
        <ci>k</ci>
        <cn type="integer">1</cn>
       </apply>
      </apply>
      <ci>n</ci>
     </apply>
     <apply>
      <times></times>
      <apply>
       <csymbol cd="ambiguous">superscript</csymbol>
       <apply>
        <minus></minus>
        <cn type="integer">1</cn>
       </apply>
       <apply>
        <minus></minus>
        <ci>k</ci>
        <cn type="integer">1</cn>
       </apply>
      </apply>
      <apply>
       <csymbol cd="latexml">binomial</csymbol>
       <ci>n</ci>
       <ci>k</ci>
      </apply>
      <apply>
       <csymbol cd="ambiguous">superscript</csymbol>
       <cn type="integer">2</cn>
       <apply>
        <times></times>
        <ci>k</ci>
        <apply>
         <minus></minus>
         <ci>n</ci>
         <ci>k</ci>
        </apply>
       </apply>
      </apply>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>a</ci>
       <apply>
        <minus></minus>
        <ci>n</ci>
        <ci>k</ci>
       </apply>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   a_{n}=\sum_{k=1}^{n}(-1)^{k-1}{n\choose k}2^{k(n-k)}a_{n-k}.
  </annotation>
 </semantics>
</math>

<a class="footnoteRef" href="#fn11" id="fnref11"><sup>11</sup></a> <a href="Eric_W._Weisstein" title="wikilink">Eric W. Weisstein</a> conjectured,<a class="footnoteRef" href="#fn12" id="fnref12"><sup>12</sup></a> and  proved,<a class="footnoteRef" href="#fn13" id="fnref13"><sup>13</sup></a> that the same numbers count the <a href="(0,1)_matrix" title="wikilink">(0,1) matrices</a> in which all <a href="eigenvalue" title="wikilink">eigenvalues</a> are positive <a href="real_number" title="wikilink">real numbers</a>. The proof is <a href="bijective_proof" title="wikilink">bijective</a>: a matrix <em>A</em> is an <a href="adjacency_matrix" title="wikilink">adjacency matrix</a> of a DAG if and only if <em>A</em> + <em>I</em> is a (0,1) matrix with all eigenvalues positive, where <em>I</em> denotes the identity matrix. Because a DAG cannot have <a href="Loop_(graph_theory)" title="wikilink">self-loops</a>, its adjacency matrix must have a zero diagonal, so adding <em>I</em> preserves the property that all matrix coefficients are 0 or 1.</p>
<h3 id="related-families-of-graphs">Related families of graphs</h3>

<p>A <a class="uri" href="polytree" title="wikilink">polytree</a> is a directed graph formed by orienting the edges of a <a href="tree_(graph_theory)" title="wikilink">free tree</a>.<a class="footnoteRef" href="#fn14" id="fnref14"><sup>14</sup></a> Every polytree is a DAG. In particular, this is true of the <a href="Arborescence_(graph_theory)" title="wikilink">arborescences</a> formed by directing all edges outwards from the root of a tree. A <a class="uri" href="multitree" title="wikilink">multitree</a> (also called a strongly unambiguous graph or a mangrove) is a directed graph in which there is at most one directed path (in either direction) between any two nodes; equivalently, it is a DAG in which, for every node <em>v</em>, the set of nodes reachable from <em>v</em> forms a tree.<a class="footnoteRef" href="#fn15" id="fnref15"><sup>15</sup></a></p>
<h2 id="computational-problems">Computational problems</h2>
<h3 id="topological-sorting-and-recognition">Topological sorting and recognition</h3>

<p><a href="Topological_sorting" title="wikilink">Topological sorting</a> is the algorithmic problem of finding topological orderings; it can be solved in linear time.<a class="footnoteRef" href="#fn16" id="fnref16"><sup>16</sup></a> Kahn's algorithm for topological sorting builds the vertex ordering directly, by maintaining a list of vertices that have no edges connecting them to vertices that have not already been listed, and repeatedly adding one such vertex to the end of the list that is being built.<a class="footnoteRef" href="#fn17" id="fnref17"><sup>17</sup></a> Alternatively, a topological ordering may be constructed by reversing a <a class="uri" href="postorder" title="wikilink">postorder</a> numbering of a <a href="depth-first_search" title="wikilink">depth-first search</a> graph traversal.<a class="footnoteRef" href="#fn18" id="fnref18"><sup>18</sup></a></p>

<p>It is also possible to check whether a given directed graph is a DAG in linear time, either by attempting to find a topological ordering and then testing for each edge whether the resulting ordering is valid<a class="footnoteRef" href="#fn19" id="fnref19"><sup>19</sup></a> or alternatively, for some topological sorting algorithms, by verifying that the algorithm successfully orders all the vertices without meeting an error condition.<a class="footnoteRef" href="#fn20" id="fnref20"><sup>20</sup></a></p>
<h3 id="construction-from-cyclic-graphs">Construction from cyclic graphs</h3>

<p>Any undirected graph may be made into a DAG by choosing a <a href="total_order" title="wikilink">total order</a> for its vertices and orienting every edge from the earlier endpoint in the order to the later endpoint. However, different total orders may lead to the same <a href="acyclic_orientation" title="wikilink">acyclic orientation</a>. The number of acyclic orientations is equal to |χ(−1)|, where χ is the <a href="chromatic_polynomial" title="wikilink">chromatic polynomial</a> of the given graph.<a class="footnoteRef" href="#fn21" id="fnref21"><sup>21</sup></a></p>

<p>Any directed graph may be made into a DAG by removing a <a href="feedback_vertex_set" title="wikilink">feedback vertex set</a> or a <a href="feedback_arc_set" title="wikilink">feedback arc set</a>. However, the smallest such set is <a class="uri" href="NP-hard" title="wikilink">NP-hard</a> to find.<a class="footnoteRef" href="#fn22" id="fnref22"><sup>22</sup></a> An arbitrary directed graph may also be transformed into a DAG, called its <a href="condensation_(graph_theory)" title="wikilink">condensation</a>, by contracting each of its <a href="strongly_connected_component" title="wikilink">strongly connected components</a> into a single supervertex.<a class="footnoteRef" href="#fn23" id="fnref23"><sup>23</sup></a> When the graph is already acyclic, its smallest feedback vertex sets and feedback arc sets are <a href="empty_set" title="wikilink">empty</a>, and its condensation is the graph itself.</p>
<h3 id="transitive-closure-and-transitive-reduction">Transitive closure and transitive reduction</h3>

<p>The transitive closure of a given DAG, with <em>n</em> vertices and <em>m</em> edges, may be constructed in time <em>O</em>(<em>mn</em>) by using either <a href="breadth-first_search" title="wikilink">breadth-first search</a> or <a href="depth-first_search" title="wikilink">depth-first search</a> to test reachability from each vertex.<a class="footnoteRef" href="#fn24" id="fnref24"><sup>24</sup></a> Alternatively, it can be solved in time <em>O</em>(<em>n</em><sup><em>ω</em></sup>) where <em>ω</em> , p. 496.</p>

<p>In all of these transitive closure algorithms, it is possible to distinguish pairs of vertices that are reachable by at least one path of length two or more from pairs that can only be connected by a length-one path. The transitive reduction consists of the edges that form length-one paths that are the only paths connecting their endpoints. Therefore, the transitive reduction can be constructed in the same asymptotic time bounds as the transitive closure.<a class="footnoteRef" href="#fn25" id="fnref25"><sup>25</sup></a></p>
<h3 id="closure-problem">Closure problem</h3>

<p>The <a href="closure_problem" title="wikilink">closure problem</a> takes as input a directed acyclic graph with weights on its vertices and seeks the minimum (or maximum) weight of a closure, a set of vertices with no outgoing edges. (The problem may be formulated for directed graphs without the assumption of acyclicity, but with no greater generality, because in this case it is equivalent to the same problem on the condensation of the graph.) It may be solved in polynomial time using a reduction to the <a href="maximum_flow_problem" title="wikilink">maximum flow problem</a>.<a class="footnoteRef" href="#fn26" id="fnref26"><sup>26</sup></a></p>
<h2 id="applications">Applications</h2>
<h3 id="path-algorithms">Path algorithms</h3>

<p>Some algorithms become simpler when used on DAGs instead of general graphs, based on the principle of topological ordering. For example, it is possible to find <a href="shortest_path" title="wikilink">shortest paths</a> and <a href="longest_path_problem" title="wikilink">longest paths</a> from a given starting vertex in DAGs in linear time by processing the vertices in a topological order, and calculating the path length for each vertex to be the minimum or maximum length obtained via any of its incoming edges.<a class="footnoteRef" href="#fn27" id="fnref27"><sup>27</sup></a> In contrast, for arbitrary graphs the shortest path may require slower algorithms such as <a href="Dijkstra's_algorithm" title="wikilink">Dijkstra's algorithm</a> or the <a href="Bellman–Ford_algorithm" title="wikilink">Bellman–Ford algorithm</a>,<a class="footnoteRef" href="#fn28" id="fnref28"><sup>28</sup></a> and longest paths in arbitrary graphs are <a class="uri" href="NP-hard" title="wikilink">NP-hard</a> to find.<a class="footnoteRef" href="#fn29" id="fnref29"><sup>29</sup></a></p>
<h3 id="scheduling">Scheduling</h3>

<p>DAG representations of partial orderings have many applications in <a href="Job_Shop_Scheduling" title="wikilink">scheduling problems</a> for systems of tasks with ordering constraints.<a class="footnoteRef" href="#fn30" id="fnref30"><sup>30</sup></a> For instance, a DAG may be used to describe the dependencies between cells of a <a class="uri" href="spreadsheet" title="wikilink">spreadsheet</a>: if one cell is computed by a formula involving the value of a second cell, draw a DAG edge from the second cell to the first one. If the input values to the spreadsheet change, all of the remaining values of the spreadsheet may be recomputed with a single evaluation per cell, by topologically ordering the cells and re-evaluating each cell in this order.<a class="footnoteRef" href="#fn31" id="fnref31"><sup>31</sup></a> Similar problems of task ordering arise in <a href="makefile" title="wikilink">makefiles</a> for program compilation,<a class="footnoteRef" href="#fn32" id="fnref32"><sup>32</sup></a> <a href="instruction_scheduling" title="wikilink">instruction scheduling</a> for low-level computer program optimization,<a class="footnoteRef" href="#fn33" id="fnref33"><sup>33</sup></a> and <a href="Program_Evaluation_and_Review_Technique" title="wikilink">PERT scheduling</a> for management of large human projects.<a class="footnoteRef" href="#fn34" id="fnref34"><sup>34</sup></a> <a href="Dependency_graph" title="wikilink">Dependency graphs</a> without <a href="circular_dependency" title="wikilink">circular dependencies</a> form directed acyclic graphs.</p>
<h3 id="data-processing-networks">Data processing networks</h3>

<p>A directed graph may be used to represent a network of processing elements; in this formulation, data enters a processing element through its incoming edges and leaves the element through its outgoing edges. Examples of this include the following:</p>
<ul>
<li>In electronic circuit design, static <a href="combinational_logic" title="wikilink">combinational logic</a> blocks can be represented as an acyclic system of <a href="logic_gate" title="wikilink">logic gates</a> that computes a function of an input, where the input and output of the function are represented as individual <a href="bit" title="wikilink">bits</a>. In general, the output of these blocks cannot be used as the input unless it is captured by a register or state element which maintains its acyclic properties. <a class="footnoteRef" href="#fn35" id="fnref35"><sup>35</sup></a> Electronic circuit schematics either on paper or in a database are a form of directed acyclic graphs using instances or components to form a directed reference to a lower level component. Electronic circuits themselves are not necessarily acyclic or directed.</li>
<li><a class="uri" href="Dataflow" title="wikilink">Dataflow</a> programming languages describe systems of values that are related to each other by a directed acyclic graph. When one value changes, its successors are recalculated; each value is evaluated as a function of its predecessors in the DAG.<a class="footnoteRef" href="#fn36" id="fnref36"><sup>36</sup></a></li>
<li>In <a href="compiler" title="wikilink">compilers</a>, straight line code (that is, sequences of statements without loops or conditional branches) may be represented by a DAG describing the inputs and outputs of each of the arithmetic operations performed within the code; this representation allows the compiler to perform <a href="common_subexpression_elimination" title="wikilink">common subexpression elimination</a> efficiently.<a class="footnoteRef" href="#fn37" id="fnref37"><sup>37</sup></a></li>
<li>In most <a class="uri" href="spreadsheet" title="wikilink">spreadsheet</a> systems, the <a href="dependency_graph" title="wikilink">dependency graph</a> that connects one cell to another if the first cell stores a formula that uses the value in the second cell must be a directed acyclic graph. Cycles of dependencies are disallowed because they cause the cells involved in the cycle to not have a well-defined value. Additionally, requiring the dependencies to be acyclic allows a <a href="topological_sort" title="wikilink">topological sort</a> to be used to schedule the recalculations of cell values when the spreadsheet is changed.<a class="footnoteRef" href="#fn38" id="fnref38"><sup>38</sup></a></li>
</ul>
<h3 id="causal-structures">Causal structures</h3>

<p>Graphs that have vertices representing events, and edges representing <a href="causality" title="wikilink">causal relations</a> between events, are often acyclic<a class="footnoteRef" href="#fn39" id="fnref39"><sup>39</sup></a> – arranging the vertices in linear order of time, all arrows point in the same direction as time, from parent to child (due to causality affecting the future, not the past), and thus have no loops.</p>

<p>For instance, a <a href="Bayesian_network" title="wikilink">Bayesian network</a> represents a system of probabilistic events as nodes in a directed acyclic graph, in which the likelihood of an event may be calculated from the likelihoods of its predecessors in the DAG.<a class="footnoteRef" href="#fn40" id="fnref40"><sup>40</sup></a> In this context, the <a href="moral_graph" title="wikilink">moral graph</a> of a DAG is the undirected graph created by adding an (undirected) edge between all parents of the same node (sometimes called <em>marrying</em>), and then replacing all directed edges by undirected edges.<a class="footnoteRef" href="#fn41" id="fnref41"><sup>41</sup></a></p>

<p>Another type of graph with a similar causal structure is an <a href="influence_diagram" title="wikilink">influence diagram</a>, the nodes of which represent either decisions to be made or unknown information, and the edges of which represent causal influences from one node to another.<a class="footnoteRef" href="#fn42" id="fnref42"><sup>42</sup></a> In <a class="uri" href="epidemiology" title="wikilink">epidemiology</a>, for instance, these diagrams are often used to estimate the expected value of different choices for intervention.<a class="footnoteRef" href="#fn43" id="fnref43"><sup>43</sup></a><a class="footnoteRef" href="#fn44" id="fnref44"><sup>44</sup></a> The role of DAGs in these applications is to convert causal assumptions into conditional independencies constraints, which can be read from the DAG using Pearl's <em>d</em>-separation<a class="footnoteRef" href="#fn45" id="fnref45"><sup>45</sup></a> and tested in the data.</p>
<h3 id="genealogy-and-version-history">Genealogy and version history</h3>

<p><a href="Family_tree" title="wikilink">Family trees</a> may also be seen as directed acyclic graphs, with a vertex for each family member and an edge for each parent-child relationship.<a class="footnoteRef" href="#fn46" id="fnref46"><sup>46</sup></a> Despite the name, these graphs are not necessarily trees because of the possibility of marriages between distant relatives (so a child has a common ancestor on both the mother's and father's side) causing <a href="pedigree_collapse" title="wikilink">pedigree collapse</a>. (The graphs of <a class="uri" href="matrilineal" title="wikilink">matrilineal</a> descent ("mother" relationships between women) and <a class="uri" href="patrilineal" title="wikilink">patrilineal</a> descent ("father" relationships between men) are trees within this graph.) Because <a href="Bootstrap_paradox#Involving_people" title="wikilink">no one can become their own ancestor</a>, these graphs are acyclic.</p>

<p>For the same reason, the version history of a <a href="distributed_revision_control" title="wikilink">distributed revision control</a> system generally has the structure of a directed acyclic graph, in which there is a vertex for each revision and an edge connecting pairs of revisions that were directly derived from each other; these are not trees in general due to merges.<a class="footnoteRef" href="#fn47" id="fnref47"><sup>47</sup></a></p>

<p>In many <a href="randomization" title="wikilink">randomized</a> <a href="algorithm" title="wikilink">algorithms</a> in <a href="computational_geometry" title="wikilink">computational geometry</a>, the algorithm maintains a <em>history DAG</em> representing the version history of a geometric structure over the course of a sequence of changes to the structure. For instance in a <a href="Randomized_algorithm#Randomized_incremental_constructions_in_geometry" title="wikilink">randomized incremental</a> algorithm for <a href="Delaunay_triangulation" title="wikilink">Delaunay triangulation</a>, the triangulation changes by replacing one triangle by three smaller triangles when each point is added, and by "flip" operations that replace pairs of triangles by a different pair of triangles. The history DAG for this algorithm has a vertex for each triangle constructed as part of the algorithm, and edges from each triangle to the two or three other triangles that replace it. Tracing a path through this DAG representing the sequence of triangles that contain an individual point allows <a href="point_location" title="wikilink">point location</a> queries to be answered efficiently.<a class="footnoteRef" href="#fn48" id="fnref48"><sup>48</sup></a></p>
<h3 id="data-compression">Data compression</h3>

<p>Another type of application of directed acyclic graphs arises in the concise representation of a set of <a href="sequence" title="wikilink">sequences</a> as <a href="path_(graph_theory)" title="wikilink">paths</a> in a graph. For example, the <a href="directed_acyclic_word_graph" title="wikilink">directed acyclic word graph</a> is a <a href="data_structure" title="wikilink">data structure</a> in computer science formed by a directed acyclic graph with a single source and with edges labeled by letters or symbols; the paths from the source to the sinks in this graph represent a set of <a href="String_(computer_science)" title="wikilink">strings</a>, such as English words.<a class="footnoteRef" href="#fn49" id="fnref49"><sup>49</sup></a> Any set of sequences can be represented as paths in a tree, by forming a tree node for every prefix of a sequence and making the parent of one of these nodes represent the sequence with one fewer element; the tree formed in this way for a set of strings is called a <a class="uri" href="trie" title="wikilink">trie</a>. A directed acyclic word graph saves space over a trie by allowing paths to diverge and rejoin, so that a set of words with the same possible suffixes can be represented by a single tree node.</p>

<p>The same idea of using a DAG to represent a family of paths occurs in the <a href="binary_decision_diagram" title="wikilink">binary decision diagram</a>,<a class="footnoteRef" href="#fn50" id="fnref50"><sup>50</sup></a><a class="footnoteRef" href="#fn51" id="fnref51"><sup>51</sup></a> a DAG-based data structure for representing binary functions. In a binary decision diagram, each non-sink vertex is labeled by the name of a binary variable, and each sink and each edge is labeled by a 0 or 1. The function value for any <a href="truth_assignment" title="wikilink">truth assignment</a> to the variables is the value at the sink found by following a path, starting from the single source vertex, that at each non-sink vertex follows the outgoing edge labeled with the value of that vertex's variable. Just as directed acyclic word graphs can be viewed as a compressed form of tries, binary decision diagrams can be viewed as compressed forms of <a href="decision_tree" title="wikilink">decision trees</a> that save space by allowing paths to rejoin when they agree on the results of all remaining decisions.</p>
<h2 id="references">References</h2>
<h2 id="external-links">External links</h2>
<ul>
<li></li>
</ul>

<p><a href="de:Gerichteter_azyklischer_Graph" title="wikilink">de:Gerichteter azyklischer Graph</a>"</p>

<p><a href="Category:Directed_graphs" title="wikilink">Category:Directed graphs</a> <a href="Category:Graphical_models" title="wikilink">Category:Graphical models</a> <a href="Category:Statistical_models" title="wikilink">Category:Statistical models</a> <a class="uri" href="Category:Databases" title="wikilink">Category:Databases</a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1">.<a href="#fnref1">↩</a></li>
<li id="fn2">.<a href="#fnref2">↩</a></li>
<li id="fn3">.<a href="#fnref3">↩</a></li>
<li id="fn4">.<a href="#fnref4">↩</a></li>
<li id="fn5">.<a href="#fnref5">↩</a></li>
<li id="fn6">.<a href="#fnref6">↩</a></li>
<li id="fn7">.<a href="#fnref7">↩</a></li>
<li id="fn8">.<a href="#fnref8">↩</a></li>
<li id="fn9">.<a href="#fnref9">↩</a></li>
<li id="fn10">. See also .<a href="#fnref10">↩</a></li>
<li id="fn11"></li>
<li id="fn12"><a href="#fnref12">↩</a></li>
<li id="fn13">, Article 04.3.3.<a href="#fnref13">↩</a></li>
<li id="fn14">.<a href="#fnref14">↩</a></li>
<li id="fn15">.<a href="#fnref15">↩</a></li>
<li id="fn16"> Section 22.4, Topological sort, pp. 549–552.<a href="#fnref16">↩</a></li>
<li id="fn17"></li>
<li id="fn18"></li>
<li id="fn19">For <a href="depth-first_search" title="wikilink">depth-first search</a> based topological sorting algorithm, this validity check can be interleaved with the topological sorting algorithm itself; see e.g. .<a href="#fnref19">↩</a></li>
<li id="fn20">, pp. 50–51.<a href="#fnref20">↩</a></li>
<li id="fn21">.<a href="#fnref21">↩</a></li>
<li id="fn22">, Problems GT7 and GT8, pp. 191–192.<a href="#fnref22">↩</a></li>
<li id="fn23">.<a href="#fnref23">↩</a></li>
<li id="fn24">, p. 495.<a href="#fnref24">↩</a></li>
<li id="fn25">, p. 38.<a href="#fnref25">↩</a></li>
<li id="fn26">.<a href="#fnref26">↩</a></li>
<li id="fn27">Cormen et al. 2001, Section 24.2, Single-source shortest paths in directed acyclic graphs, pp. 592–595.<a href="#fnref27">↩</a></li>
<li id="fn28">Cormen et al. 2001, Sections 24.1, The Bellman–Ford algorithm, pp. 588–592, and 24.3, Dijkstra's algorithm, pp. 595–601.<a href="#fnref28">↩</a></li>
<li id="fn29">Cormen et al. 2001, p. 966.<a href="#fnref29">↩</a></li>
<li id="fn30">, p. 469.<a href="#fnref30">↩</a></li>
<li id="fn31">.<a href="#fnref31">↩</a></li>
<li id="fn32"></li>
<li id="fn33">.<a href="#fnref33">↩</a></li>
<li id="fn34">.<a href="#fnref34">↩</a></li>
<li id="fn35">.<a href="#fnref35">↩</a></li>
<li id="fn36">.<a href="#fnref36">↩</a></li>
<li id="fn37">.<a href="#fnref37">↩</a></li>
<li id="fn38"></li>
<li id="fn39">.<a href="#fnref39">↩</a></li>
<li id="fn40">.<a href="#fnref40">↩</a></li>
<li id="fn41">.<a href="#fnref41">↩</a></li>
<li id="fn42">.<a href="#fnref42">↩</a></li>
<li id="fn43">.<a href="#fnref43">↩</a></li>
<li id="fn44"><a href="#fnref44">↩</a></li>
<li id="fn45"><a href="#fnref45">↩</a></li>
<li id="fn46">.<a href="#fnref46">↩</a></li>
<li id="fn47">.<a href="#fnref47">↩</a></li>
<li id="fn48">.<a href="#fnref48">↩</a></li>
<li id="fn49">.<a href="#fnref49">↩</a></li>
<li id="fn50">.<a href="#fnref50">↩</a></li>
<li id="fn51">.<a href="#fnref51">↩</a></li>
</ol>
</section>
</body>
</html>
