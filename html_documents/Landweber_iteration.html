<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title offset="138">Landweber iteration</title>
   <script type="text/javascript"
      src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js">
    </script>
</head>
<body>
<h1>Landweber iteration</h1>
<hr/>
<p>The <strong>Landweber iteration</strong> or <strong>Landweber algorithm</strong> is an algorithm to solve <a class="uri" href="ill-posed" title="wikilink">ill-posed</a> linear <a href="inverse_problems" title="wikilink">inverse problems</a>, and it has been extended to solve non-linear problems that involve constraints. The method was first proposed in the 1950s,<a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a> and it can be now viewed as a special case of many other more general methods.<a class="footnoteRef" href="#fn2" id="fnref2"><sup>2</sup></a></p>
<h2 id="basic-algorithm">Basic algorithm</h2>
<p>The original Landweber algorithm <a class="footnoteRef" href="#fn3" id="fnref3"><sup>3</sup></a> attempts to recover a signal <em>x</em> from measurements <em>y</em>. The linear version assumes that <span class="LaTeX">$y=Ax$</span> for a <a href="linear_operator" title="wikilink">linear operator</a> <em>A</em>. When the problem is in finite <a class="uri" href="dimensions" title="wikilink">dimensions</a>, <em>A</em> is just a matrix.</p>
<p>When <em>A</em> is <a class="uri" href="nonsingular" title="wikilink">nonsingular</a>, then an explicit solution is <span class="LaTeX">$x = A^{-1} y$</span>. However, if <em>A</em> is <a class="uri" href="ill-conditioned" title="wikilink">ill-conditioned</a>, the explicit solution is a poor choice since it is sensitive to any errors made on <em>y</em>. If <em>A</em> is <a href="Mathematical_singularity" title="wikilink">singular</a>, this explicit solution doesn't even exist. The Landweber algorithm is an attempt to <a href="Regularization_(mathematics)" title="wikilink">regularize</a> the problem, and is one of the alternatives to <a href="Tikhonov_regularization" title="wikilink">Tikhonov regularization</a>. We may view the Landweber algorithm as solving:</p>
<p><span class="LaTeX">$$\min_x  \|Ax-y\|_2^2/2$$</span></p>
<p>using an iterative method. For <a class="uri" href="ill-posed" title="wikilink">ill-posed</a> problems, the iterative method may be purposefully stopped before convergence.</p>
<p>The algorithm is given by the update</p>
<p><span class="LaTeX">$$x_{k+1} = x_{k} - \omega A^*(Ax_k - y).$$</span></p>
<p>where the relaxation factor <span class="LaTeX">$\omega$</span> satisfies <span class="LaTeX">$0 < \omega < 2/\sigma_1^2$</span>. Here <span class="LaTeX">$\sigma_1$</span> is the largest <a href="singular_value_decomposition" title="wikilink">singular value</a> of <span class="LaTeX">$A$</span>. If we write <span class="LaTeX">$f(x) = \|Ax-y\|_2^2 /2$</span>, then the update can be written in terms of the <a class="uri" href="gradient" title="wikilink">gradient</a></p>
<p><span class="LaTeX">$$x_{k+1} = x_k - \omega \nabla f(x_k)$$</span></p>
<p>and hence the algorithm is a special case of <a href="gradient_descent" title="wikilink">gradient descent</a>.</p>
<p>Discussion of the Landweber iteration as a <a href="regularization_(mathematics)" title="wikilink">regularization</a> algorithm can be found in.<a class="footnoteRef" href="#fn4" id="fnref4"><sup>4</sup></a><a class="footnoteRef" href="#fn5" id="fnref5"><sup>5</sup></a></p>
<h2 id="nonlinear-extension">Nonlinear extension</h2>
<p>In general, the updates generated by <span class="LaTeX">$x_{k+1} = x_{k} - \tau \nabla f(x_k)$</span> will generate a sequence <span class="LaTeX">$f(x_k)$</span> that <a href="convergence_(mathematics)" title="wikilink">converges</a> to a minimizer of <em>f</em> whenever <em>f</em> is <a href="convex_function" title="wikilink">convex</a> and the stepsize <span class="LaTeX">$\tau$</span> is chosen such that <span class="LaTeX">$0 < \tau < 2/( \|A\|^2 )$</span> where <span class="LaTeX">$\|\cdot \|$</span> is the <a href="spectral_norm" title="wikilink">spectral norm</a>.</p>
<p>Since this is special type of gradient descent, there currently is not much benefit to analyzing it on its own as the nonlinear Landweber, but such analysis was performed historically by many communities not aware of unifying frameworks.</p>
<p>The nonlinear Landweber problem has been studied in many papers in many communities; see, for example,.<a class="footnoteRef" href="#fn6" id="fnref6"><sup>6</sup></a></p>
<h2 id="extension-to-constrained-problems">Extension to constrained problems</h2>
<p>If <em>f</em> is a <a href="convex_function" title="wikilink">convex function</a> and <em>C</em> is a <a href="convex_set" title="wikilink">convex set</a>, then the problem</p>
<p><span class="LaTeX">$$\min_{x \in C} f(x)$$</span></p>
<p>can be solved by the constrained, nonlinear Landweber iteration, given by:</p>
<p><span class="LaTeX">$$x_{k+1} = \mathcal{P}_C( x_{k} - \tau \nabla f(x_k) )$$</span></p>
<p>where <span class="LaTeX">$\mathcal{P}$</span> is the <a href="projection_(mathematics)" title="wikilink">projection</a> onto the set <em>C</em>. Convergence is guaranteed when <span class="LaTeX">$0 < \tau < 2/( \|A\|^2 )$</span>.<a class="footnoteRef" href="#fn7" id="fnref7"><sup>7</sup></a> This is again a special case of <a href="projected_gradient_descent" title="wikilink">projected gradient descent</a> (which is a special case of the <a href="Forward–backward_algorithm_(operator_splitting)" title="wikilink">forward–backward algorithm</a>) as discussed in.<a class="footnoteRef" href="#fn8" id="fnref8"><sup>8</sup></a></p>
<h2 id="applications">Applications</h2>
<p>Since the method has been around since the 1950s, it has been adopted and rediscovered by many scientific communities, especially those studying ill-posed problems. In <a href="X-ray_computed_tomography" title="wikilink">X-ray computed tomography</a> it is called SIRT - simultaneous iterative reconstruction technique. It has also been used in the <a href="computer_vision" title="wikilink">computer vision</a> community<a class="footnoteRef" href="#fn9" id="fnref9"><sup>9</sup></a> and the signal restoration community.<a class="footnoteRef" href="#fn10" id="fnref10"><sup>10</sup></a> It is also used in <a href="image_processing" title="wikilink">image processing</a>, since many image problems, such as <a class="uri" href="deconvolution" title="wikilink">deconvolution</a>, are ill-posed. Variants of this method have been used also in sparse approximation problems and compressed sensing settings.<a class="footnoteRef" href="#fn11" id="fnref11"><sup>11</sup></a></p>
<h2 id="references">References</h2>
<references>
<p><a class="footnoteRef" href="#fn12" id="fnref12"><sup>12</sup></a> <a class="footnoteRef" href="#fn13" id="fnref13"><sup>13</sup></a></p>
</references>
<p>"</p>
<p><a href="Category:Image_processing" title="wikilink">Category:Image processing</a> <a href="Category:Inverse_problems" title="wikilink">Category:Inverse problems</a> <a href="Category:Gradient_methods" title="wikilink">Category:Gradient methods</a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1"></li>
<li id="fn2"></li>
<li id="fn3"></li>
<li id="fn4">Louis, A.K. (1989): Inverse und schlecht gestellte Probleme. Stuttgart, Teubner<a href="#fnref4">↩</a></li>
<li id="fn5">Vainikko, G.M., Veretennikov, A.Y. (1986): Iteration Procedures in Ill-Posed Problems. Moscow, Nauka (in Russian)<a href="#fnref5">↩</a></li>
<li id="fn6">A convergence analysis of the Landweber iteration for nonlinear ill-posed problems Martin Hanke, Andreas Neubauer and Otmar Scherzer. NUMERISCHE MATHEMATIK Volume 72, Number 1 (1995), 21-37, DOI: 10.1007/s002110050158<a href="#fnref6">↩</a></li>
<li id="fn7">Eicke, B.: Iteration methods for convexly constrained ill-posed problems in Hilbert space. Numer. Funct. Anal. Optim. 13, 413–429 (1992)<a href="#fnref7">↩</a></li>
<li id="fn8"></li>
<li id="fn9">Johansson, B., Elfving, T., Kozlovc, V., Censor, Y., Forssen, P.E., Granlund, G.; "The application of an oblique-projected Landweber method to a model of supervised learning", Math. Comput. Modelling, vol 43, pp 892–909 (2006)<a href="#fnref9">↩</a></li>
<li id="fn10">Trussell, H.J., Civanlar, M.R.: The Landweber iteration and projection onto convex sets. IEEE Trans. Acoust., Speech, Signal Process. 33, 1632–1634 (1985)<a href="#fnref10">↩</a></li>
<li id="fn11"><a href="#fnref11">↩</a></li>
<li id="fn12">Landweber, L. (1951): An iteration formula for Fredholm integral equations of the ﬁrst kind. Amer. J. Math. 73, 615–624<a href="#fnref12">↩</a></li>
<li id="fn13">P. L. Combettes and J.-C. Pesquet, "Proximal splitting methods in signal processing," in: Fixed-Point Algorithms for Inverse Problems in Science and Engineering, (H. H. Bauschke, <a href="Regina_S._Burachik" title="wikilink">R. S. Burachik</a>, P. L. Combettes, V. Elser, D. R. Luke, and H. Wolkowicz, Editors), pp. 185–212. Springer, New York, 2011. <a href="http://www.ann.jussieu.fr/~plc/prox.pdf">PDF</a><a href="#fnref13">↩</a></li>
</ol>
</section>
</body>
</html>
