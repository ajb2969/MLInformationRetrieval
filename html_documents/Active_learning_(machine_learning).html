<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="306">Active learning (machine learning)</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>Active learning (machine learning)</h1>
<hr/>

<p><strong>Active learning</strong> is a special case of <a href="semi-supervised_learning" title="wikilink">semi-supervised machine learning</a> in which a learning algorithm is able to interactively query the user (or some other information source) to obtain the desired outputs at new data points. In statistics literature it is sometimes also called <a href="optimal_experimental_design" title="wikilink">optimal experimental design</a>.<a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a><a class="footnoteRef" href="#fn2" id="fnref2"><sup>2</sup></a></p>

<p>There are situations in which unlabeled data is abundant but manually labeling is expensive. In such a scenario, learning algorithms can actively query the user/teacher for labels. This type of iterative supervised learning is called active learning. Since the learner chooses the examples, the number of examples to learn a concept can often be much lower than the number required in normal supervised learning. With this approach, there is a risk that the algorithm be overwhelmed by uninformative examples. Recent developments are dedicated to hybrid active learning<a class="footnoteRef" href="#fn3" id="fnref3"><sup>3</sup></a> and active learning in a single-pass (on-line) context,<a class="footnoteRef" href="#fn4" id="fnref4"><sup>4</sup></a> combining concepts from the field of Machine Learning (e.g., <a href="Conflict_(process)" title="wikilink">conflict</a> and <a class="uri" href="ignorance" title="wikilink">ignorance</a>) with adaptive, incremental learning policies in the field of <a href="Online_machine_learning" title="wikilink">Online machine learning</a>.</p>
<h2 id="definitions">Definitions</h2>

<p>Let 

<math display="inline" id="Active_learning_(machine_learning):0">
 <semantics>
  <mi>T</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>T</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   T
  </annotation>
 </semantics>
</math>

 be the total set of all data under consideration. For example, in a protein engineering problem, 

<math display="inline" id="Active_learning_(machine_learning):1">
 <semantics>
  <mi>T</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>T</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   T
  </annotation>
 </semantics>
</math>

 would include all proteins that are known to have a certain interesting activity and all additional proteins that one might want to test for that activity.</p>

<p>During each iteration, 

<math display="inline" id="Active_learning_(machine_learning):2">
 <semantics>
  <mi>i</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>i</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   i
  </annotation>
 </semantics>
</math>

, 

<math display="inline" id="Active_learning_(machine_learning):3">
 <semantics>
  <mi>T</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>T</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   T
  </annotation>
 </semantics>
</math>


 is broken up into three subsets</p>
<ol>
<li>

<math display="inline" id="Active_learning_(machine_learning):4">
 <semantics>
  <msub>
   <mi>ùêì</mi>
   <mrow>
    <mi>K</mi>
    <mo>,</mo>
    <mi>i</mi>
   </mrow>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>ùêì</ci>
    <list>
     <ci>K</ci>
     <ci>i</ci>
    </list>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \mathbf{T}_{K,i}
  </annotation>
 </semantics>
</math>

: Data points where the label is <strong>known</strong>.</li>
<li>

<math display="inline" id="Active_learning_(machine_learning):5">
 <semantics>
  <msub>
   <mi>ùêì</mi>
   <mrow>
    <mi>U</mi>
    <mo>,</mo>
    <mi>i</mi>
   </mrow>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>ùêì</ci>
    <list>
     <ci>U</ci>
     <ci>i</ci>
    </list>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \mathbf{T}_{U,i}
  </annotation>
 </semantics>
</math>

: Data points where the label is <strong>unknown</strong>.</li>
<li>

<math display="inline" id="Active_learning_(machine_learning):6">
 <semantics>
  <msub>
   <mi>ùêì</mi>
   <mrow>
    <mi>C</mi>
    <mo>,</mo>
    <mi>i</mi>
   </mrow>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>ùêì</ci>
    <list>
     <ci>C</ci>
     <ci>i</ci>
    </list>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \mathbf{T}_{C,i}
  </annotation>
 </semantics>
</math>

: A subset of 

<math display="inline" id="Active_learning_(machine_learning):7">
 <semantics>
  <msub>
   <mi>T</mi>
   <mrow>
    <mi>U</mi>
    <mo>,</mo>
    <mi>i</mi>
   </mrow>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>T</ci>
    <list>
     <ci>U</ci>
     <ci>i</ci>
    </list>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   T_{U,i}
  </annotation>
 </semantics>
</math>

 that is <strong>chosen</strong> to be labeled.</li>
</ol>

<p>Most of the current research in active learning involves the best method to choose the data points for 

<math display="inline" id="Active_learning_(machine_learning):8">
 <semantics>
  <msub>
   <mi>T</mi>
   <mrow>
    <mi>C</mi>
    <mo>,</mo>
    <mi>i</mi>
   </mrow>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>T</ci>
    <list>
     <ci>C</ci>
     <ci>i</ci>
    </list>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   T_{C,i}
  </annotation>
 </semantics>
</math>


.</p>
<h2 id="query-strategies">Query strategies</h2>

<p>Algorithms for determining which data points should be labeled can be organized into a number of different categories:<a class="footnoteRef" href="#fn5" id="fnref5"><sup>5</sup></a></p>
<ul>
<li>Uncertainty sampling: label those points for which the current model is least certain as to what the correct output should be</li>
</ul>
<ul>
<li>Query by committee: a variety of models are trained on the current labeled data, and vote on the output for unlabeled data; label those points for which the "committee" disagrees the most</li>
</ul>
<ul>
<li>Expected model change: label those points that would most change the current model</li>
</ul>
<ul>
<li>Expected error reduction: label those points that would most reduce the model's generalization error</li>
</ul>
<ul>
<li>Variance reduction: label those points that would minimize output variance, which is one of the components of error</li>
</ul>
<ul>
<li>Balance exploration and exploitation: the choice of examples to label is seen as a dilemma between the exploration and the exploitation over the data space representation. This strategy manages this compromise by modelling the active learning problem as a contextual bandit problem. For example, Bouneffouf et at. <a class="footnoteRef" href="#fn6" id="fnref6"><sup>6</sup></a> propose a sequential algorithm named Active Thompson Sampling (ATS), which, in each round, assigns a sampling distribution on the pool, samples one point from this distribution, and queries the oracle for this sample point label.</li>
</ul>

<p>A wide variety of algorithms have been studied that fall into these categories.<a class="footnoteRef" href="#fn7" id="fnref7"><sup>7</sup></a><a class="footnoteRef" href="#fn8" id="fnref8"><sup>8</sup></a></p>
<h2 id="minimum-marginal-hyperplane">Minimum Marginal Hyperplane</h2>

<p>Some active learning algorithms are built upon <a href="Support_vector_machine" title="wikilink">Support vector machines (SVMs)</a> and exploit the structure of the SVM to determine which data points to label. Such methods usually calculate the <a href="margin_(machine_learning)" title="wikilink">margin</a>, 

<math display="inline" id="Active_learning_(machine_learning):9">
 <semantics>
  <mi>W</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>W</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   W
  </annotation>
 </semantics>
</math>

, of each unlabeled datum in 

<math display="inline" id="Active_learning_(machine_learning):10">
 <semantics>
  <msub>
   <mi>T</mi>
   <mrow>
    <mi>U</mi>
    <mo>,</mo>
    <mi>i</mi>
   </mrow>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>T</ci>
    <list>
     <ci>U</ci>
     <ci>i</ci>
    </list>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   T_{U,i}
  </annotation>
 </semantics>
</math>

 and treat 

<math display="inline" id="Active_learning_(machine_learning):11">
 <semantics>
  <mi>W</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>W</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   W
  </annotation>
 </semantics>
</math>

 as an 

<math display="inline" id="Active_learning_(machine_learning):12">
 <semantics>
  <mi>n</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>n</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   n
  </annotation>
 </semantics>
</math>

-dimensional distance from that datum to the separating hyperplane.</p>

<p>Minimum Marginal Hyperplane methods assume that the data with the smallest 

<math display="inline" id="Active_learning_(machine_learning):13">
 <semantics>
  <mi>W</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>W</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   W
  </annotation>
 </semantics>
</math>


 are those that the SVM is most uncertain about and therefore should be placed in 

<math display="inline" id="Active_learning_(machine_learning):14">
 <semantics>
  <msub>
   <mi>T</mi>
   <mrow>
    <mi>C</mi>
    <mo>,</mo>
    <mi>i</mi>
   </mrow>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>T</ci>
    <list>
     <ci>C</ci>
     <ci>i</ci>
    </list>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   T_{C,i}
  </annotation>
 </semantics>
</math>

 to be labeled. Other similar methods, such as Maximum Marginal Hyperplane, choose data with the largest 

<math display="inline" id="Active_learning_(machine_learning):15">
 <semantics>
  <mi>W</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>W</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   W
  </annotation>
 </semantics>
</math>

. Tradeoff methods choose a mix of the smallest and largest 

<math display="inline" id="Active_learning_(machine_learning):16">
 <semantics>
  <mi>W</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>W</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   W
  </annotation>
 </semantics>
</math>

s.</p>
<h2 id="see-also">See also</h2>
<ul>
<li><a href="Proactive_learning" title="wikilink">Proactive learning</a></li>
</ul>
<h2 id="notes">Notes</h2>
<h2 id="other-references">Other references</h2>
<ul>
<li><a href="http://ActiveIntelligence.org">N. Rubens</a>, D. Kaplan, M. Sugiyama. Recommender Systems Handbook: Active Learning in Recommender Systems (eds. F. Ricci, P.B. Kantor, L. Rokach,B. Shapira). Springer, 2011 <a href="http://activeintelligence.org/wp-content/papercite-data/pdf/Rubens-Active-Learning-RecSysHB2010.pdf">1</a>, <a href="http://activeintelligence.org/research/al-rs/">2</a>.</li>
<li><a href="http://hunch.net/~active_learning/">Active Learning Tutorial</a>, S. Dasgupta and J. Langford.</li>
</ul>

<p>"</p>

<p><a href="Category:Machine_learning" title="wikilink">Category:Machine learning</a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1">.<a href="#fnref1">‚Ü©</a></li>
<li id="fn2"><a href="#fnref2">‚Ü©</a></li>
<li id="fn3"></li>
<li id="fn4"></li>
<li id="fn5"></li>
<li id="fn6"></li>
<li id="fn7"></li>
<li id="fn8"></li>
</ol>
</section>
</body>
</html>
