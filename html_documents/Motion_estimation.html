<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="873">Motion estimation</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>Motion estimation</h1>
<h
<p>r&gt;<strong>Motion estimation</strong> is the process of determining <a href="motion_vector" title="wikilink">motion vectors</a> that describe the transformation from one 2D image to another; usually from adjacent <a href="video_frame" title="wikilink">frames</a> in a video sequence. It is an <a href="well-posed_problem" title="wikilink">ill-posed problem</a> as the motion is in three dimensions but the images are a projection of the 3D scene onto a 2D plane. The motion vectors may relate to the whole image (global motion estimation) or specific parts, such as rectangular blocks, arbitrary shaped patches or even per <a class="uri" href="pixel" title="wikilink">pixel</a>. The motion vectors may be represented by a translational model or many other models that can approximate the motion of a real video camera, such as rotation and translation in all three dimensions and zoom.</h
<p></body></html>

<p>More often than not, the term <a href="motion_estimation" title="wikilink">motion estimation</a> and the term <a href="optical_flow" title="wikilink">optical flow</a> are used interchangeably.</p>
<h2 id="algorithms">Algorithms</h2>

<p>The methods for finding motion vectors can be categorised into pixel based methods ("direct") and feature based methods ("indirect"). A famous debate resulted in two papers from the opposing factions being produced to try to establish a conclusion.<a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a><a class="footnoteRef" href="#fn2" id="fnref2"><sup>2</sup></a></p>
<h3 id="direct-methods">Direct Methods</h3>
<ul>
<li><a href="Block-matching_algorithm" title="wikilink">Block-matching algorithm</a></li>
<li><a href="Phase_correlation" title="wikilink">Phase correlation</a> and frequency domain methods</li>
<li>Pixel recursive algorithms</li>
<li><a href="Optical_flow" title="wikilink">Optical flow</a></li>
</ul>
<h3 id="indirect-methods">Indirect Methods</h3>

<p><em>Indirect methods</em> use features, such as <a href="corner_detection" title="wikilink">corner detection</a>, and match corresponding features between frames, usually with a statistical function applied over a local or global area. The purpose of the statistical function is to remove matches that do not correspond to the actual motion.</p>

<p>Statistical functions that have been successfully used include <a class="uri" href="RANSAC" title="wikilink">RANSAC</a>.</p>
<h2 id="applications">Applications</h2>
<h3 id="video-coding">Video Coding</h3>

<p>Applying the motion vectors to an image to synthesize the transformation to the next image is called <a href="motion_compensation" title="wikilink">motion compensation</a>. As a way of exploiting temporal redundancy, motion estimation and compensation are key parts of <a href="video_compression" title="wikilink">video compression</a>. Almost all video coding standards use block-based motion estimation and compensation such as the <a class="uri" href="MPEG" title="wikilink">MPEG</a> series including the most recent <a class="uri" href="HEVC" title="wikilink">HEVC</a>.</p>
<h2 id="references">References</h2>
<references>
</references>

<p>"</p>

<p><a href="Category:Video_processing" title="wikilink">Category:Video processing</a> <a href="Category:Motion_(physics)" title="wikilink">Category:Motion (physics)</a> <a href="Category:Estimation_theory" title="wikilink">Category:Estimation theory</a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1">Philip H.S. Torr and Andrew Zisserman: Feature Based Methods for Structure and Motion Estimation, ICCV Workshop on Vision Algorithms, pages 278-294, 1999<a href="#fnref1">↩</a></li>
<li id="fn2">Michal Irani and P. Anandan: About Direct Methods, ICCV Workshop on Vision Algorithms, pages 267-277, 1999.<a href="#fnref2">↩</a></li>
</ol>
</section>


