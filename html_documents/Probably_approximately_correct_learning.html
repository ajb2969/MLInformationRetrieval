<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="500">Probably approximately correct learning</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>Probably approximately correct learning</h1>
<hr/>

<p>In <a href="computational_learning_theory" title="wikilink">computational learning theory</a>, <strong>probably approximately correct learning</strong> (<strong>PAC learning</strong>) is a framework for mathematical analysis of <a href="machine_learning" title="wikilink">machine learning</a>. It was proposed in 1984 by <a href="Leslie_Valiant" title="wikilink">Leslie Valiant</a>.<a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a></p>

<p>In this framework, the learner receives samples and must select a generalization function (called the <em>hypothesis</em>) from a certain class of possible functions. The goal is that, with high probability (the "probably" part), the selected function will have low <a href="generalization_error" title="wikilink">generalization error</a> (the "approximately correct" part). The learner must be able to learn the concept given any arbitrary approximation ratio, probability of success, or <a href="Empirical_distribution_function" title="wikilink">distribution of the samples</a>.</p>

<p>The model was later extended to treat noise (misclassified samples).</p>

<p>An important innovation of the PAC framework is the introduction of <a href="computational_complexity_theory" title="wikilink">computational complexity theory</a> concepts to machine learning. In particular, the learner is expected to find efficient functions (time and space requirements bounded to a <a class="uri" href="polynomial" title="wikilink">polynomial</a> of the example size), and the learner itself must implement an efficient procedure (requiring an example count bounded to a polynomial of the concept size, modified by the approximation and <a class="uri" href="likelihood" title="wikilink">likelihood</a> bounds).</p>
<h2 id="definitions-and-terminology">Definitions and terminology</h2>

<p>In order to give the definition for something that is PAC-learnable, we first have to introduce some terminology.<a class="footnoteRef" href="#fn2" id="fnref2"><sup>2</sup></a> <a class="footnoteRef" href="#fn3" id="fnref3"><sup>3</sup></a></p>

<p>For the following definitions, two examples will be used. The first is the problem of <a href="character_recognition" title="wikilink">character recognition</a> given an array of 

<math display="inline" id="Probably_approximately_correct_learning:0">
 <semantics>
  <mi>n</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>n</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   n
  </annotation>
 </semantics>
</math>

 bits encoding a binary-valued image. The other example is the problem of finding an interval that will correctly classify points within the interval as positive and the points outside of the range as negative.</p>

<p>Let 

<math display="inline" id="Probably_approximately_correct_learning:1">
 <semantics>
  <mi>X</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>X</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   X
  </annotation>
 </semantics>
</math>

 be a set called the <em>instance space</em> or the encoding of all the samples, and each <em>instance</em> have length assigned. In the character recognition problem, the instance space is 

<math display="inline" id="Probably_approximately_correct_learning:2">
 <semantics>
  <mrow>
   <mi>X</mi>
   <mo>=</mo>
   <msup>
    <mrow>
     <mo stretchy="false">{</mo>
     <mn>0</mn>
     <mo>,</mo>
     <mn>1</mn>
     <mo stretchy="false">}</mo>
    </mrow>
    <mi>n</mi>
   </msup>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <ci>X</ci>
    <apply>
     <csymbol cd="ambiguous">superscript</csymbol>
     <set>
      <cn type="integer">0</cn>
      <cn type="integer">1</cn>
     </set>
     <ci>n</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   X=\{0,1\}^{n}
  </annotation>
 </semantics>
</math>

. In the interval problem the instance space is 

<math display="inline" id="Probably_approximately_correct_learning:3">
 <semantics>
  <mrow>
   <mi>X</mi>
   <mo>=</mo>
   <mi>ℝ</mi>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <ci>X</ci>
    <ci>ℝ</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   X=\mathbb{R}
  </annotation>
 </semantics>
</math>


, where 

<math display="inline" id="Probably_approximately_correct_learning:4">
 <semantics>
  <mi>ℝ</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>ℝ</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \mathbb{R}
  </annotation>
 </semantics>
</math>

 denotes the set of all real numbers.</p>

<p>A <em>concept</em> is a subset 

<math display="inline" id="Probably_approximately_correct_learning:5">
 <semantics>
  <mrow>
   <mi>c</mi>
   <mo>⊂</mo>
   <mi>X</mi>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <subset></subset>
    <ci>c</ci>
    <ci>X</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   c\subset X
  </annotation>
 </semantics>
</math>

. One concept is the set of all patterns of bits in 

<math display="inline" id="Probably_approximately_correct_learning:6">
 <semantics>
  <mrow>
   <mi>X</mi>
   <mo>=</mo>
   <msup>
    <mrow>
     <mo stretchy="false">{</mo>
     <mn>0</mn>
     <mo>,</mo>
     <mn>1</mn>
     <mo stretchy="false">}</mo>
    </mrow>
    <mi>n</mi>
   </msup>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <ci>X</ci>
    <apply>
     <csymbol cd="ambiguous">superscript</csymbol>
     <set>
      <cn type="integer">0</cn>
      <cn type="integer">1</cn>
     </set>
     <ci>n</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   X=\{0,1\}^{n}
  </annotation>
 </semantics>
</math>

 that encode a picture of the letter "P". An example concept from the second example is the set of all of the numbers between 

<math display="inline" id="Probably_approximately_correct_learning:7">
 <semantics>
  <mrow>
   <mi>π</mi>
   <mo>/</mo>
   <mn>2</mn>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <divide></divide>
    <ci>π</ci>
    <cn type="integer">2</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \pi/2
  </annotation>
 </semantics>
</math>

 and 

<math display="inline" id="Probably_approximately_correct_learning:8">
 <semantics>
  <msqrt>
   <mn>10</mn>
  </msqrt>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <root></root>
    <cn type="integer">10</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \sqrt{10}
  </annotation>
 </semantics>
</math>


. A <em><a href="concept_class" title="wikilink">concept class</a></em> 

<math display="inline" id="Probably_approximately_correct_learning:9">
 <semantics>
  <mi>C</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>C</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   C
  </annotation>
 </semantics>
</math>

 is a set of concepts over 

<math display="inline" id="Probably_approximately_correct_learning:10">
 <semantics>
  <mi>X</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>X</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   X
  </annotation>
 </semantics>
</math>

. This could be the set of all subsets of the array of bits that are skeletonized 4-connected (width of the font is 1).</p>

<p>Let 

<math display="inline" id="Probably_approximately_correct_learning:11">
 <semantics>
  <mrow>
   <mi>E</mi>
   <mi>X</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <mi>c</mi>
    <mo>,</mo>
    <mi>D</mi>
    <mo stretchy="false">)</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <ci>E</ci>
    <ci>X</ci>
    <interval closure="open">
     <ci>c</ci>
     <ci>D</ci>
    </interval>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   EX(c,D)
  </annotation>
 </semantics>
</math>

 be a procedure that draws an example, 

<math display="inline" id="Probably_approximately_correct_learning:12">
 <semantics>
  <mi>x</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>x</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   x
  </annotation>
 </semantics>
</math>

, using a probability distribution 

<math display="inline" id="Probably_approximately_correct_learning:13">
 <semantics>
  <mi>D</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>D</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   D
  </annotation>
 </semantics>
</math>


 and gives the correct label 

<math display="inline" id="Probably_approximately_correct_learning:14">
 <semantics>
  <mrow>
   <mi>c</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <mi>x</mi>
    <mo stretchy="false">)</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <ci>c</ci>
    <ci>x</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   c(x)
  </annotation>
 </semantics>
</math>

, that is 1 if 

<math display="inline" id="Probably_approximately_correct_learning:15">
 <semantics>
  <mrow>
   <mi>x</mi>
   <mo>∈</mo>
   <mi>c</mi>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <in></in>
    <ci>x</ci>
    <ci>c</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   x\in c
  </annotation>
 </semantics>
</math>

 and 0 otherwise.</p>

<p>Say that there is an algorithm 

<math display="inline" id="Probably_approximately_correct_learning:16">
 <semantics>
  <mi>A</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>A</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   A
  </annotation>
 </semantics>
</math>

 that given access to 

<math display="inline" id="Probably_approximately_correct_learning:17">
 <semantics>
  <mrow>
   <mi>E</mi>
   <mi>X</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <mi>c</mi>
    <mo>,</mo>
    <mi>D</mi>
    <mo stretchy="false">)</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <ci>E</ci>
    <ci>X</ci>
    <interval closure="open">
     <ci>c</ci>
     <ci>D</ci>
    </interval>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   EX(c,D)
  </annotation>
 </semantics>
</math>

 and inputs 

<math display="inline" id="Probably_approximately_correct_learning:18">
 <semantics>
  <mi>ϵ</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>ϵ</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \epsilon
  </annotation>
 </semantics>
</math>


 and 

<math display="inline" id="Probably_approximately_correct_learning:19">
 <semantics>
  <mi>δ</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>δ</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \delta
  </annotation>
 </semantics>
</math>

 that, with probability of at least 

<math display="inline" id="Probably_approximately_correct_learning:20">
 <semantics>
  <mrow>
   <mn>1</mn>
   <mo>-</mo>
   <mi>δ</mi>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <minus></minus>
    <cn type="integer">1</cn>
    <ci>δ</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   1-\delta
  </annotation>
 </semantics>
</math>

, 

<math display="inline" id="Probably_approximately_correct_learning:21">
 <semantics>
  <mi>A</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>A</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   A
  </annotation>
 </semantics>
</math>

 outputs a hypothesis 

<math display="inline" id="Probably_approximately_correct_learning:22">
 <semantics>
  <mrow>
   <mi>h</mi>
   <mo>∈</mo>
   <mi>C</mi>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <in></in>
    <ci>h</ci>
    <ci>C</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   h\in C
  </annotation>
 </semantics>
</math>

 that has error less than or equal to 

<math display="inline" id="Probably_approximately_correct_learning:23">
 <semantics>
  <mi>ϵ</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>ϵ</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \epsilon
  </annotation>
 </semantics>
</math>


 with examples drawn from 

<math display="inline" id="Probably_approximately_correct_learning:24">
 <semantics>
  <mi>X</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>X</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   X
  </annotation>
 </semantics>
</math>

 with the distribution 

<math display="inline" id="Probably_approximately_correct_learning:25">
 <semantics>
  <mi>D</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>D</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   D
  </annotation>
 </semantics>
</math>

. If there is such an algorithm for every concept 

<math display="inline" id="Probably_approximately_correct_learning:26">
 <semantics>
  <mrow>
   <mi>c</mi>
   <mo>∈</mo>
   <mi>C</mi>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <in></in>
    <ci>c</ci>
    <ci>C</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   c\in C
  </annotation>
 </semantics>
</math>

, for every distribution 

<math display="inline" id="Probably_approximately_correct_learning:27">
 <semantics>
  <mi>D</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>D</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   D
  </annotation>
 </semantics>
</math>

 over 

<math display="inline" id="Probably_approximately_correct_learning:28">
 <semantics>
  <mi>X</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>X</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   X
  </annotation>
 </semantics>
</math>


, and for all 

<math display="inline" id="Probably_approximately_correct_learning:29">
 <semantics>
  <mrow>
   <mn>0</mn>
   <mo><</mo>
   <mi>ϵ</mi>
   <mo><</mo>
   <mrow>
    <mn>1</mn>
    <mo>/</mo>
    <mn>2</mn>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <and></and>
    <apply>
     <lt></lt>
     <cn type="integer">0</cn>
     <ci>ϵ</ci>
    </apply>
    <apply>
     <lt></lt>
     <share href="#.cmml">
     </share>
     <apply>
      <divide></divide>
      <cn type="integer">1</cn>
      <cn type="integer">2</cn>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   0<\epsilon<1/2
  </annotation>
 </semantics>
</math>

 and 

<math display="inline" id="Probably_approximately_correct_learning:30">
 <semantics>
  <mrow>
   <mn>0</mn>
   <mo><</mo>
   <mi>δ</mi>
   <mo><</mo>
   <mrow>
    <mn>1</mn>
    <mo>/</mo>
    <mn>2</mn>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <and></and>
    <apply>
     <lt></lt>
     <cn type="integer">0</cn>
     <ci>δ</ci>
    </apply>
    <apply>
     <lt></lt>
     <share href="#.cmml">
     </share>
     <apply>
      <divide></divide>
      <cn type="integer">1</cn>
      <cn type="integer">2</cn>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   0<\delta<1/2
  </annotation>
 </semantics>
</math>

 then 

<math display="inline" id="Probably_approximately_correct_learning:31">
 <semantics>
  <mi>C</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>C</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   C
  </annotation>
 </semantics>
</math>

 is <strong>PAC learnable</strong> (or <em>distribution-free PAC learnable</em>). We can also say that 

<math display="inline" id="Probably_approximately_correct_learning:32">
 <semantics>
  <mi>A</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>A</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   A
  </annotation>
 </semantics>
</math>

 is a <strong>PAC learning algorithm</strong> for 

<math display="inline" id="Probably_approximately_correct_learning:33">
 <semantics>
  <mi>C</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>C</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   C
  </annotation>
 </semantics>
</math>


.</p>

<p>An algorithm runs in time 

<math display="inline" id="Probably_approximately_correct_learning:34">
 <semantics>
  <mi>t</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>t</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   t
  </annotation>
 </semantics>
</math>

 if it draws at most 

<math display="inline" id="Probably_approximately_correct_learning:35">
 <semantics>
  <mi>t</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>t</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   t
  </annotation>
 </semantics>
</math>

 examples and requires at most 

<math display="inline" id="Probably_approximately_correct_learning:36">
 <semantics>
  <mi>t</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>t</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   t
  </annotation>
 </semantics>
</math>

 time steps. A concept class is <strong>efficiently PAC learnable</strong> if it is <em>PAC learnable</em> by an algorithm that runs in time polynomial in 

<math display="inline" id="Probably_approximately_correct_learning:37">
 <semantics>
  <mrow>
   <mn>1</mn>
   <mo>/</mo>
   <mi>ϵ</mi>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <divide></divide>
    <cn type="integer">1</cn>
    <ci>ϵ</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   1/\epsilon
  </annotation>
 </semantics>
</math>

, 

<math display="inline" id="Probably_approximately_correct_learning:38">
 <semantics>
  <mrow>
   <mn>1</mn>
   <mo>/</mo>
   <mi>δ</mi>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <divide></divide>
    <cn type="integer">1</cn>
    <ci>δ</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   1/\delta
  </annotation>
 </semantics>
</math>


 and <em>instance</em> length.</p>
<h2 id="equivalence">Equivalence</h2>

<p>Under some regularity conditions these three conditions are equivalent:</p>
<ol>
<li>The concept class <em>C</em> is <strong>PAC learnable</strong>.</li>
<li>The <a href="VC_dimension" title="wikilink">VC dimension</a> of <em>C</em> is finite.</li>
<li><em>C</em> is a uniform <a href="Glivenko-Cantelli_class" title="wikilink">Glivenko-Cantelli class</a>.</li>
</ol>
<h2 id="references">References</h2>
<references>
</references>
<h2 id="further-reading">Further reading</h2>
<ul>
<li>M. Kearns, U. Vazirani. <em>An Introduction to Computational Learning Theory.</em> MIT Press, 1994. A textbook.</li>
<li>D. Haussler. <a href="http://www.cs.iastate.edu/~honavar/pac.pdf">Overview of the Probably Approximately Correct (PAC) Learning Framework</a>. An introduction to the topic.</li>
<li>L. Valiant. <a href="http://www.probablyapproximatelycorrect.com/"><em>Probably Approximately Correct.</em></a> Basic Books, 2013. In which Valiant argues that PAC learning describes how organisms evolve and learn.</li>
</ul>

<p>"</p>

<p><a href="Category:Computational_learning_theory" title="wikilink">Category:Computational learning theory</a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1">L. Valiant. <em><a href="http://web.mit.edu/6.435/www/Valiant84.pdf">A theory of the learnable.</a></em> Communications of the ACM, 27, 1984.<a href="#fnref1">↩</a></li>
<li id="fn2">Kearns and Vazirani, pg. 1-12,<a href="#fnref2">↩</a></li>
<li id="fn3">Balas Kausik Natarajan, Machine Learning , A Theoretical Approach, Morgan Kaufmann Publishers, 1991<a href="#fnref3">↩</a></li>
</ol>
</section>
</body>
</html>
