<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title offset="1021">Chain rule (probability)</title>
   <script type="text/javascript"
      src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js">
    </script>
</head>
<body>
<h1>Chain rule (probability)</h1>
<hr/>
<p>In <a class="uri" href="probability" title="wikilink">probability</a> theory, the <strong>chain rule</strong> (also called the <strong>general product rule</strong><a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a><a class="footnoteRef" href="#fn2" id="fnref2"><sup>2</sup></a>) permits the calculation of any member of the <a href="joint_distribution" title="wikilink">joint distribution</a> of a set of <a href="random_variables" title="wikilink">random variables</a> using only <a href="conditional_probabilities" title="wikilink">conditional probabilities</a>. The rule is useful in the study of <a href="Bayesian_network" title="wikilink">Bayesian networks</a>, which describe a probability distribution in terms of conditional probabilities.</p>
<p>Consider an indexed set of sets <small><span class="LaTeX">$A_1, \ldots , A_n$</span></small>. To find the value of this member of the joint distribution, we can apply the definition of conditional probability to obtain:</p>
<dl>
<dd><dl>
<dd><span class="LaTeX">$\mathrm  P(A_n, \ldots , A_1)  = \mathrm P(A_n | A_{n-1}, \ldots , A_1) \cdot\mathrm P( A_{n-1}, \ldots , A_1)$</span>
</dd>
</dl>
</dd>
</dl>
<p>Repeating this process with each final term creates the product:</p>
<dl>
<dd><dl>
<dd><span class="LaTeX">$\mathrm  P\left(\bigcap_{k=1}^n A_k\right)  = \prod_{k=1}^n  \mathrm P\left(A_k \,\Bigg|\, \bigcap_{j=1}^{k-1} A_j\right)$</span>
</dd>
</dl>
</dd>
</dl>
<p>With four variables, the chain rule produces this product of conditional probabilities:</p>
<dl>
<dd><dl>
<dd><span class="LaTeX">$\mathrm P(A_4, A_3, A_2, A_1) = \mathrm P(A_4 \mid A_3, A_2, A_1)\cdot \mathrm P(A_3 \mid A_2, A_1)\cdot \mathrm P(A_2 \mid A_1)\cdot \mathrm P(A_1)$</span>
</dd>
</dl>
</dd>
</dl>
<p>This rule is illustrated in the following example. Urn 1 has 1 black ball and 2 white balls and Urn 2 has 1 black ball and 3 white balls. Suppose we pick an urn at random and then select a ball from that urn. Let event A be choosing the first urn: P(A) = P(~A) = 1/2. Let event B be the chance we choose a white ball. The chance of choosing a white ball, given that we've chosen the first urn, is P(B|A) = 2/3. Event A, B would be their intersection: choosing the first urn and a white ball from it. The probability can be found by the chain rule for probability:</p>
<dl>
<dd><dl>
<dd><span class="LaTeX">$\mathrm P(A, B)=\mathrm P(B \mid A) \mathrm P(A) = 2/3 \times 1/2 = 1/3$</span>.
</dd>
</dl>
</dd>
</dl>
<h2 id="references">References</h2>
<ul>
<li>
<p>, p. 496.</p></li>
<li><a href="https://www.ibm.com/developerworks/mydeveloperworks/blogs/nlp/entry/the_chain_rule_of_probability">"The Chain Rule of Probability"</a>, <em><a class="uri" href="developerWorks" title="wikilink">developerWorks</a></em>, Nov 3, 2012.</li>
</ul>
<p>"</p>
<p><a href="Category:Probability_theory" title="wikilink">Category:Probability theory</a> <a href="Category:Bayesian_inference" title="wikilink">Category:Bayesian inference</a> <a href="Category:Bayesian_statistics" title="wikilink">Category:Bayesian statistics</a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1"><a href="#fnref1">↩</a></li>
<li id="fn2"><a href="#fnref2">↩</a></li>
</ol>
</section>
</body>
</html>
