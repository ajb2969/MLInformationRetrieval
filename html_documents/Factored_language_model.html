<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="389">Factored language model</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>Factored language model</h1>
<hr/>

<p>The <strong>factored language model</strong> (<strong>FLM</strong>) is an extension of a conventional <a href="language_model" title="wikilink">language model</a> introduced by Jeff Bilmes and Katrin Kirchoff in 2003. In an FLM, each word is viewed as a vector of <em>k</em> factors

<math display="block" id="Factored_language_model:0">
 <semantics>
  <mrow>
   <mrow>
    <msub>
     <mi>w</mi>
     <mi>i</mi>
    </msub>
    <mo>=</mo>
    <mrow>
     <mo stretchy="false">{</mo>
     <msubsup>
      <mi>f</mi>
      <mi>i</mi>
      <mn>1</mn>
     </msubsup>
     <mo>,</mo>
     <mi mathvariant="normal">…</mi>
     <mo>,</mo>
     <msubsup>
      <mi>f</mi>
      <mi>i</mi>
      <mi>k</mi>
     </msubsup>
     <mo stretchy="false">}</mo>
    </mrow>
   </mrow>
   <mo>.</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>w</ci>
     <ci>i</ci>
    </apply>
    <set>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>f</ci>
       <ci>i</ci>
      </apply>
      <cn type="integer">1</cn>
     </apply>
     <ci>normal-…</ci>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>f</ci>
       <ci>i</ci>
      </apply>
      <ci>k</ci>
     </apply>
    </set>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   w_{i}=\{f_{i}^{1},...,f_{i}^{k}\}.
  </annotation>
 </semantics>
</math>

 An FLM provides the probabilistic model 

<math display="inline" id="Factored_language_model:1">
 <semantics>
  <mrow>
   <mi>P</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <mi>f</mi>
    <mo stretchy="false">|</mo>
    <msub>
     <mi>f</mi>
     <mn>1</mn>
    </msub>
    <mo>,</mo>
    <mi mathvariant="normal">…</mi>
    <mo>,</mo>
    <msub>
     <mi>f</mi>
     <mi>N</mi>
    </msub>
    <mo stretchy="false">)</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <cerror>
    <csymbol cd="ambiguous">fragments</csymbol>
    <csymbol cd="unknown">P</csymbol>
    <cerror>
     <csymbol cd="ambiguous">fragments</csymbol>
     <ci>normal-(</ci>
     <csymbol cd="unknown">f</csymbol>
     <ci>normal-|</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>f</ci>
      <cn type="integer">1</cn>
     </apply>
     <ci>normal-,</ci>
     <ci>normal-…</ci>
     <ci>normal-,</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>f</ci>
      <ci>N</ci>
     </apply>
     <ci>normal-)</ci>
    </cerror>
   </cerror>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   P(f|f_{1},...,f_{N})
  </annotation>
 </semantics>
</math>

 where the prediction of a factor 

<math display="inline" id="Factored_language_model:2">
 <semantics>
  <mi>f</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>f</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   f
  </annotation>
 </semantics>
</math>

 is based on 

<math display="inline" id="Factored_language_model:3">
 <semantics>
  <mi>N</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>N</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   N
  </annotation>
 </semantics>
</math>

 parents 

<math display="inline" id="Factored_language_model:4">
 <semantics>
  <mrow>
   <mo stretchy="false">{</mo>
   <msub>
    <mi>f</mi>
    <mn>1</mn>
   </msub>
   <mo>,</mo>
   <mi mathvariant="normal">…</mi>
   <mo>,</mo>
   <msub>
    <mi>f</mi>
    <mi>N</mi>
   </msub>
   <mo stretchy="false">}</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <set>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>f</ci>
     <cn type="integer">1</cn>
    </apply>
    <ci>normal-…</ci>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>f</ci>
     <ci>N</ci>
    </apply>
   </set>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \{f_{1},...,f_{N}\}
  </annotation>
 </semantics>
</math>

. For example, if 

<math display="inline" id="Factored_language_model:5">
 <semantics>
  <mi>w</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>w</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   w
  </annotation>
 </semantics>
</math>

 represents a word token and 

<math display="inline" id="Factored_language_model:6">
 <semantics>
  <mi>t</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>t</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   t
  </annotation>
 </semantics>
</math>

 represents a <a href="Part_of_speech" title="wikilink">Part of speech</a> tag for English, the expression 

<math display="inline" id="Factored_language_model:7">
 <semantics>
  <mrow>
   <mi>P</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <msub>
     <mi>w</mi>
     <mi>i</mi>
    </msub>
    <mo stretchy="false">|</mo>
    <msub>
     <mi>w</mi>
     <mrow>
      <mi>i</mi>
      <mo>-</mo>
      <mn>2</mn>
     </mrow>
    </msub>
    <mo>,</mo>
    <msub>
     <mi>w</mi>
     <mrow>
      <mi>i</mi>
      <mo>-</mo>
      <mn>1</mn>
     </mrow>
    </msub>
    <mo>,</mo>
    <msub>
     <mi>t</mi>
     <mrow>
      <mi>i</mi>
      <mo>-</mo>
      <mn>1</mn>
     </mrow>
    </msub>
    <mo stretchy="false">)</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <cerror>
    <csymbol cd="ambiguous">fragments</csymbol>
    <csymbol cd="unknown">P</csymbol>
    <cerror>
     <csymbol cd="ambiguous">fragments</csymbol>
     <ci>normal-(</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>w</ci>
      <ci>i</ci>
     </apply>
     <ci>normal-|</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>w</ci>
      <apply>
       <minus></minus>
       <ci>i</ci>
       <cn type="integer">2</cn>
      </apply>
     </apply>
     <ci>normal-,</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>w</ci>
      <apply>
       <minus></minus>
       <ci>i</ci>
       <cn type="integer">1</cn>
      </apply>
     </apply>
     <ci>normal-,</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>t</ci>
      <apply>
       <minus></minus>
       <ci>i</ci>
       <cn type="integer">1</cn>
      </apply>
     </apply>
     <ci>normal-)</ci>
    </cerror>
   </cerror>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   P(w_{i}|w_{i-2},w_{i-1},t_{i-1})
  </annotation>
 </semantics>
</math>

 gives a model for predicting current word token based on a traditional <a class="uri" href="Ngram" title="wikilink">Ngram</a> model as well as the <a href="Part_of_speech" title="wikilink">Part of speech</a> tag of the previous word.</p>

<p>A major advantage of factored language models is that they allow users to specify linguistic knowledge such as the relationship between word tokens and <a href="Part_of_speech" title="wikilink">Part of speech</a> in English, or morphological information (stems, root, etc.) in Arabic.</p>

<p>Like <a class="uri" href="N-gram" title="wikilink">N-gram</a> models, smoothing techniques are necessary in parameter estimation. In particular, generalized back-off is used in training an FLM.</p>
<h2 id="references">References</h2>
<ul>
<li></li>
</ul>

<p>"</p>

<p><a href="Category:Language_modeling" title="wikilink">Category:Language modeling</a> <a href="Category:Statistical_natural_language_processing" title="wikilink">Category:Statistical natural language processing</a> <a href="Category:Probabilistic_models" title="wikilink">Category:Probabilistic models</a></p>
</body>
</html>
