<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="95">Bias of an estimator</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>Bias of an estimator</h1>
<hr/>

<p>In <a class="uri" href="statistics" title="wikilink">statistics</a>, the <strong>bias</strong> (or <strong>bias function</strong>) of an <a class="uri" href="estimator" title="wikilink">estimator</a> is the difference between this estimator's <a href="expected_value" title="wikilink">expected value</a> and the true value of the parameter being estimated. An estimator or decision rule with zero bias is called <strong>unbiased</strong>. Otherwise the estimator is said to be <strong>biased</strong>. In statistics, "bias" is an objective statement about a function, and while not a desired property, it is not pejorative, unlike the ordinary English use of the term "<a href="Bias_(disambiguation)" title="wikilink">bias</a>".</p>

<p>Bias can also be measured with respect to the <a class="uri" href="median" title="wikilink">median</a>, rather than the mean (expected value), in which case one distinguishes <em>median</em>-unbiased from the usual <em>mean</em>-unbiasedness property. Bias is related to <a href="Consistent_estimator" title="wikilink">consistency</a> in that consistent estimators are convergent and <em>asymptotically</em> unbiased (hence converge to the correct value), though individual estimators in a consistent sequence may be biased (so long as the bias converges to zero); see <a href="Consistent_estimator#Bias_versus_consistency" title="wikilink">bias versus consistency</a>.</p>

<p>All else equal, an unbiased estimator is preferable to a biased estimator, but in practice all else is not equal, and biased estimators are frequently used, generally with small bias. When a biased estimator is used, the bias is also estimated. A biased estimator may be used for various reasons: because an unbiased estimator does not exist without further assumptions about a population or is difficult to compute (as in <a href="unbiased_estimation_of_standard_deviation" title="wikilink">unbiased estimation of standard deviation</a>); because an estimator is median-unbiased but not mean-unbiased (or the reverse); because a biased estimator reduces some <a href="loss_function" title="wikilink">loss function</a> (particularly <a href="mean_squared_error" title="wikilink">mean squared error</a>) compared with unbiased estimators (notably in <a href="shrinkage_estimator" title="wikilink">shrinkage estimators</a>); or because in some cases being unbiased is too strong a condition, and the only unbiased estimators are not useful. Further, mean-unbiasedness is not preserved under non-linear transformations, though median-unbiasedness is (see <a href="#Effect_of_transformations" title="wikilink">effect of transformations</a>); for example, the <a href="sample_variance" title="wikilink">sample variance</a> is an unbiased estimator for the population variance, but its square root, the <a href="sample_standard_deviation" title="wikilink">sample standard deviation</a>, is a biased estimator for the population standard deviation. These are all illustrated below.</p>
<h2 id="definition">Definition</h2>

<p>Suppose we have a <a href="statistical_model" title="wikilink">statistical model</a>, parameterized by a real number <em>θ</em>, giving rise to a probability distribution for observed data, 

<math display="inline" id="Bias_of_an_estimator:0">
 <semantics>
  <mrow>
   <msub>
    <mi>P</mi>
    <mi>θ</mi>
   </msub>
   <mrow>
    <mo stretchy="false">(</mo>
    <mi>x</mi>
    <mo stretchy="false">)</mo>
   </mrow>
   <mo>=</mo>
   <mi>P</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <mi>x</mi>
    <mo>∣</mo>
    <mi>θ</mi>
    <mo stretchy="false">)</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <cerror>
    <csymbol cd="ambiguous">fragments</csymbol>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>P</ci>
     <ci>θ</ci>
    </apply>
    <cerror>
     <csymbol cd="ambiguous">fragments</csymbol>
     <ci>normal-(</ci>
     <csymbol cd="unknown">x</csymbol>
     <ci>normal-)</ci>
    </cerror>
    <eq></eq>
    <csymbol cd="unknown">P</csymbol>
    <cerror>
     <csymbol cd="ambiguous">fragments</csymbol>
     <ci>normal-(</ci>
     <csymbol cd="unknown">x</csymbol>
     <ci>normal-∣</ci>
     <csymbol cd="unknown">θ</csymbol>
     <ci>normal-)</ci>
    </cerror>
   </cerror>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   P_{\theta}(x)=P(x\mid\theta)
  </annotation>
 </semantics>
</math>

, and a statistic <em>θ</em><sup>^</sup> which serves as an <a class="uri" href="estimator" title="wikilink">estimator</a> of <em>θ</em> based on any observed data 

<math display="inline" id="Bias_of_an_estimator:1">
 <semantics>
  <mi>x</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>x</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   x
  </annotation>
 </semantics>
</math>

. That is, we assume that our data follows some unknown distribution 

<math display="inline" id="Bias_of_an_estimator:2">
 <semantics>
  <mrow>
   <msub>
    <mi>P</mi>
    <mi>θ</mi>
   </msub>
   <mrow>
    <mo stretchy="false">(</mo>
    <mi>x</mi>
    <mo stretchy="false">)</mo>
   </mrow>
   <mo>=</mo>
   <mi>P</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <mi>x</mi>
    <mo>∣</mo>
    <mi>θ</mi>
    <mo stretchy="false">)</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <cerror>
    <csymbol cd="ambiguous">fragments</csymbol>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>P</ci>
     <ci>θ</ci>
    </apply>
    <cerror>
     <csymbol cd="ambiguous">fragments</csymbol>
     <ci>normal-(</ci>
     <csymbol cd="unknown">x</csymbol>
     <ci>normal-)</ci>
    </cerror>
    <eq></eq>
    <csymbol cd="unknown">P</csymbol>
    <cerror>
     <csymbol cd="ambiguous">fragments</csymbol>
     <ci>normal-(</ci>
     <csymbol cd="unknown">x</csymbol>
     <ci>normal-∣</ci>
     <csymbol cd="unknown">θ</csymbol>
     <ci>normal-)</ci>
    </cerror>
   </cerror>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   P_{\theta}(x)=P(x\mid\theta)
  </annotation>
 </semantics>
</math>

 (where <em>θ</em> is a fixed constant that is part of this distribution, but is unknown), and then we construct some estimator <em>θ</em><sup>^</sup> that maps observed data to values that we hope are close to <em>θ</em>. Then the <strong>bias</strong> of this estimator (relative to the parameter <em>θ</em>) is defined to be</p>

<p>

<math display="block" id="Bias_of_an_estimator:3">
 <semantics>
  <mrow>
   <mrow>
    <mrow>
     <msub>
      <mo>Bias</mo>
      <mi>θ</mi>
     </msub>
     <mrow>
      <mo rspace="4.2pt" stretchy="false">[</mo>
      <mpadded width="+1.7pt">
       <mover accent="true">
        <mi>θ</mi>
        <mo stretchy="false">^</mo>
       </mover>
      </mpadded>
      <mo stretchy="false">]</mo>
     </mrow>
    </mrow>
    <mo>=</mo>
    <mrow>
     <mrow>
      <msub>
       <mo>E</mo>
       <mi>θ</mi>
      </msub>
      <mrow>
       <mo rspace="4.2pt" stretchy="false">[</mo>
       <mpadded width="+1.7pt">
        <mover accent="true">
         <mi>θ</mi>
         <mo stretchy="false">^</mo>
        </mover>
       </mpadded>
       <mo stretchy="false">]</mo>
      </mrow>
     </mrow>
     <mo>-</mo>
     <mi>θ</mi>
    </mrow>
    <mo>=</mo>
    <mrow>
     <msub>
      <mo>E</mo>
      <mi>θ</mi>
     </msub>
     <mrow>
      <mo rspace="4.2pt" stretchy="false">[</mo>
      <mrow>
       <mover accent="true">
        <mi>θ</mi>
        <mo stretchy="false">^</mo>
       </mover>
       <mo>-</mo>
       <mpadded width="+1.7pt">
        <mi>θ</mi>
       </mpadded>
      </mrow>
      <mo stretchy="false">]</mo>
     </mrow>
    </mrow>
   </mrow>
   <mo>,</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <and></and>
    <apply>
     <eq></eq>
     <apply>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>Bias</ci>
       <ci>θ</ci>
      </apply>
      <apply>
       <ci>normal-^</ci>
       <ci>θ</ci>
      </apply>
     </apply>
     <apply>
      <minus></minus>
      <apply>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <ci>normal-E</ci>
        <ci>θ</ci>
       </apply>
       <apply>
        <ci>normal-^</ci>
        <ci>θ</ci>
       </apply>
      </apply>
      <ci>θ</ci>
     </apply>
    </apply>
    <apply>
     <eq></eq>
     <share href="#.cmml">
     </share>
     <apply>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>normal-E</ci>
       <ci>θ</ci>
      </apply>
      <apply>
       <minus></minus>
       <apply>
        <ci>normal-^</ci>
        <ci>θ</ci>
       </apply>
       <ci>θ</ci>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \operatorname{Bias}_{\theta}[\,\hat{\theta}\,]=\operatorname{E}_{\theta}[\,%
\hat{\theta}\,]-\theta=\operatorname{E}_{\theta}[\,\hat{\theta}-\theta\,],
  </annotation>
 </semantics>
</math>

</p>

<p>where 

<math display="inline" id="Bias_of_an_estimator:4">
 <semantics>
  <msub>
   <mo>E</mo>
   <mi>θ</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>normal-E</ci>
    <ci>θ</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \operatorname{E}_{\theta}
  </annotation>
 </semantics>
</math>

 denotes <a href="expected_value" title="wikilink">expected value</a> over the distribution 

<math display="inline" id="Bias_of_an_estimator:5">
 <semantics>
  <mrow>
   <msub>
    <mi>P</mi>
    <mi>θ</mi>
   </msub>
   <mrow>
    <mo stretchy="false">(</mo>
    <mi>x</mi>
    <mo stretchy="false">)</mo>
   </mrow>
   <mo>=</mo>
   <mi>P</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <mi>x</mi>
    <mo>∣</mo>
    <mi>θ</mi>
    <mo stretchy="false">)</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <cerror>
    <csymbol cd="ambiguous">fragments</csymbol>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>P</ci>
     <ci>θ</ci>
    </apply>
    <cerror>
     <csymbol cd="ambiguous">fragments</csymbol>
     <ci>normal-(</ci>
     <csymbol cd="unknown">x</csymbol>
     <ci>normal-)</ci>
    </cerror>
    <eq></eq>
    <csymbol cd="unknown">P</csymbol>
    <cerror>
     <csymbol cd="ambiguous">fragments</csymbol>
     <ci>normal-(</ci>
     <csymbol cd="unknown">x</csymbol>
     <ci>normal-∣</ci>
     <csymbol cd="unknown">θ</csymbol>
     <ci>normal-)</ci>
    </cerror>
   </cerror>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   P_{\theta}(x)=P(x\mid\theta)
  </annotation>
 </semantics>
</math>

, i.e. averaging over all possible observations 

<math display="inline" id="Bias_of_an_estimator:6">
 <semantics>
  <mi>x</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>x</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   x
  </annotation>
 </semantics>
</math>

. The second equation follows since <em>θ</em> is measurable with respect to the conditional distribution 

<math display="inline" id="Bias_of_an_estimator:7">
 <semantics>
  <mrow>
   <mi>P</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <mi>x</mi>
    <mo>∣</mo>
    <mi>θ</mi>
    <mo stretchy="false">)</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <cerror>
    <csymbol cd="ambiguous">fragments</csymbol>
    <csymbol cd="unknown">P</csymbol>
    <cerror>
     <csymbol cd="ambiguous">fragments</csymbol>
     <ci>normal-(</ci>
     <csymbol cd="unknown">x</csymbol>
     <ci>normal-∣</ci>
     <csymbol cd="unknown">θ</csymbol>
     <ci>normal-)</ci>
    </cerror>
   </cerror>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   P(x\mid\theta)
  </annotation>
 </semantics>
</math>

.</p>

<p>An estimator is said to be <strong>unbiased</strong> if its bias is equal to zero for all values of parameter <em>θ</em>.</p>

<p>There are more general notions of bias and unbiasedness. What this article calls "bias" is called "<em>mean</em>-bias", to distinguish <em>mean</em>-bias from the other notions, with the notable ones being "<em>median</em>-unbiased" estimators. For more details, the general theory of unbiased estimators is briefly discussed near the end of this article.</p>

<p>In a simulation experiment concerning the properties of an estimator, the bias of the estimator may be assessed using the <a href="mean_signed_difference" title="wikilink">mean signed difference</a>.</p>
<h2 id="examples">Examples</h2>
<h3 id="sample-variance">Sample variance</h3>

<p>The <a href="sample_variance" title="wikilink">sample variance</a> of a random variable demonstrates two aspects of estimator bias: firstly, the naive estimator is biased, which can be corrected by a scale factor; second, the unbiased estimator is not optimal in terms of <a href="mean_squared_error" title="wikilink">mean squared error</a> (MSE), which can be minimized by using a different scale factor, resulting in a biased estimator with lower MSE than the unbiased estimator. Concretely, the naive estimator sums the squared deviations and divides by <em>n,</em> which is biased. Dividing instead by <em>n</em> − 1 yields an unbiased estimator. Conversely, MSE can be minimized by dividing by a different number (depending on distribution), but this results in a biased estimator. This number is always larger than <em>n</em> − 1, so this is known as a <a href="shrinkage_estimator" title="wikilink">shrinkage estimator</a>, as it "shrinks" the unbiased estimator towards zero; for the normal distribution the optimal value is <em>n</em> + 1.</p>

<p>Suppose <em>X</em><sub>1</sub>, ..., <em>X</em><sub><em>n</em></sub> are <a href="independent_and_identically_distributed" title="wikilink">independent and identically distributed</a> (i.i.d.) random variables with <a href="expected_value" title="wikilink">expectation</a> <em>μ</em> and <a class="uri" href="variance" title="wikilink">variance</a> <em>σ</em><sup>2</sup>. If the <a href="sample_mean" title="wikilink">sample mean</a> and uncorrected <a href="sample_variance" title="wikilink">sample variance</a> are defined as</p>

<p>

<math display="block" id="Bias_of_an_estimator:8">
 <semantics>
  <mrow>
   <mrow>
    <mrow>
     <mover accent="true">
      <mi>X</mi>
      <mo>¯</mo>
     </mover>
     <mo>=</mo>
     <mrow>
      <mfrac>
       <mn>1</mn>
       <mi>n</mi>
      </mfrac>
      <mrow>
       <munderover>
        <mo largeop="true" movablelimits="false" symmetric="true">∑</mo>
        <mrow>
         <mi>i</mi>
         <mo>=</mo>
         <mn>1</mn>
        </mrow>
        <mi>n</mi>
       </munderover>
       <msub>
        <mi>X</mi>
        <mi>i</mi>
       </msub>
      </mrow>
     </mrow>
    </mrow>
    <mo rspace="22.5pt">,</mo>
    <mrow>
     <msup>
      <mi>S</mi>
      <mn>2</mn>
     </msup>
     <mo>=</mo>
     <mrow>
      <mfrac>
       <mn>1</mn>
       <mi>n</mi>
      </mfrac>
      <mrow>
       <munderover>
        <mo largeop="true" movablelimits="false" symmetric="true">∑</mo>
        <mrow>
         <mi>i</mi>
         <mo>=</mo>
         <mn>1</mn>
        </mrow>
        <mi>n</mi>
       </munderover>
       <msup>
        <mrow>
         <mo>(</mo>
         <mrow>
          <msub>
           <mi>X</mi>
           <mi>i</mi>
          </msub>
          <mo>-</mo>
          <mpadded width="+1.7pt">
           <mover accent="true">
            <mi>X</mi>
            <mo>¯</mo>
           </mover>
          </mpadded>
         </mrow>
         <mo>)</mo>
        </mrow>
        <mn>2</mn>
       </msup>
      </mrow>
     </mrow>
    </mrow>
   </mrow>
   <mo>,</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">formulae-sequence</csymbol>
    <apply>
     <eq></eq>
     <apply>
      <ci>normal-¯</ci>
      <ci>X</ci>
     </apply>
     <apply>
      <times></times>
      <apply>
       <divide></divide>
       <cn type="integer">1</cn>
       <ci>n</ci>
      </apply>
      <apply>
       <apply>
        <csymbol cd="ambiguous">superscript</csymbol>
        <apply>
         <csymbol cd="ambiguous">subscript</csymbol>
         <sum></sum>
         <apply>
          <eq></eq>
          <ci>i</ci>
          <cn type="integer">1</cn>
         </apply>
        </apply>
        <ci>n</ci>
       </apply>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <ci>X</ci>
        <ci>i</ci>
       </apply>
      </apply>
     </apply>
    </apply>
    <apply>
     <eq></eq>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <ci>S</ci>
      <cn type="integer">2</cn>
     </apply>
     <apply>
      <times></times>
      <apply>
       <divide></divide>
       <cn type="integer">1</cn>
       <ci>n</ci>
      </apply>
      <apply>
       <apply>
        <csymbol cd="ambiguous">superscript</csymbol>
        <apply>
         <csymbol cd="ambiguous">subscript</csymbol>
         <sum></sum>
         <apply>
          <eq></eq>
          <ci>i</ci>
          <cn type="integer">1</cn>
         </apply>
        </apply>
        <ci>n</ci>
       </apply>
       <apply>
        <csymbol cd="ambiguous">superscript</csymbol>
        <apply>
         <minus></minus>
         <apply>
          <csymbol cd="ambiguous">subscript</csymbol>
          <ci>X</ci>
          <ci>i</ci>
         </apply>
         <apply>
          <ci>normal-¯</ci>
          <ci>X</ci>
         </apply>
        </apply>
        <cn type="integer">2</cn>
       </apply>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \overline{X}=\frac{1}{n}\sum_{i=1}^{n}X_{i},\qquad S^{2}=\frac{1}{n}\sum_{i=1}%
^{n}\left(X_{i}-\overline{X}\,\right)^{2},
  </annotation>
 </semantics>
</math>

</p>

<p>then <em>S</em><sup>2</sup> is a biased estimator of <em>σ</em><sup>2</sup>, because</p>

<p>

<math display="inline" id="Bias_of_an_estimator:9">
 <semantics>
  <mrow>
   <mo>E</mo>
   <mrow>
    <mo stretchy="false">[</mo>
    <msup>
     <mi>S</mi>
     <mn>2</mn>
    </msup>
    <mo stretchy="false">]</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <ci>normal-E</ci>
    <apply>
     <csymbol cd="ambiguous">superscript</csymbol>
     <ci>S</ci>
     <cn type="integer">2</cn>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \displaystyle\operatorname{E}[S^{2}]
  </annotation>
 </semantics>
</math>


</p>

<p>In other words, the expected value of the uncorrected sample variance does not equal the population variance <em>σ</em><sup>2</sup>, unless multiplied by a normalization factor. The sample mean, on the other hand, is an unbiased<a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a> estimator of the population mean <em>μ</em>.</p>

<p>The reason that <em>S</em><sup>2</sup> is biased stems from the fact that the sample mean is an <a href="ordinary_least_squares" title="wikilink">ordinary least squares</a> (OLS) estimator for <em>μ</em>

<math display="block" id="Bias_of_an_estimator:10">
 <semantics>
  <mover accent="true">
   <mi>X</mi>
   <mo>¯</mo>
  </mover>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <ci>normal-¯</ci>
    <ci>X</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \overline{X}
  </annotation>
 </semantics>
</math>

 is the number that makes the sum 

<math display="inline" id="Bias_of_an_estimator:11">
 <semantics>
  <mrow>
   <msubsup>
    <mo largeop="true" symmetric="true">∑</mo>
    <mrow>
     <mi>i</mi>
     <mo>=</mo>
     <mn>1</mn>
    </mrow>
    <mi>n</mi>
   </msubsup>
   <msup>
    <mrow>
     <mo stretchy="false">(</mo>
     <mrow>
      <msub>
       <mi>X</mi>
       <mi>i</mi>
      </msub>
      <mo>-</mo>
      <mover accent="true">
       <mi>X</mi>
       <mo>¯</mo>
      </mover>
     </mrow>
     <mo stretchy="false">)</mo>
    </mrow>
    <mn>2</mn>
   </msup>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <apply>
     <csymbol cd="ambiguous">superscript</csymbol>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <sum></sum>
      <apply>
       <eq></eq>
       <ci>i</ci>
       <cn type="integer">1</cn>
      </apply>
     </apply>
     <ci>n</ci>
    </apply>
    <apply>
     <csymbol cd="ambiguous">superscript</csymbol>
     <apply>
      <minus></minus>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>X</ci>
       <ci>i</ci>
      </apply>
      <apply>
       <ci>normal-¯</ci>
       <ci>X</ci>
      </apply>
     </apply>
     <cn type="integer">2</cn>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \sum_{i=1}^{n}(X_{i}-\overline{X})^{2}
  </annotation>
 </semantics>
</math>

 as small as possible. That is, when any other number is plugged into this sum, the sum can only increase. In particular, the choice 

<math display="inline" id="Bias_of_an_estimator:12">
 <semantics>
  <mrow>
   <mi>μ</mi>
   <mo>≠</mo>
   <mover accent="true">
    <mi>X</mi>
    <mo>¯</mo>
   </mover>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <neq></neq>
    <ci>μ</ci>
    <apply>
     <ci>normal-¯</ci>
     <ci>X</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \mu\neq\overline{X}
  </annotation>
 </semantics>
</math>


 gives,</p>

<p>

<math display="block" id="Bias_of_an_estimator:13">
 <semantics>
  <mrow>
   <mrow>
    <mrow>
     <mfrac>
      <mn>1</mn>
      <mi>n</mi>
     </mfrac>
     <mrow>
      <munderover>
       <mo largeop="true" movablelimits="false" symmetric="true">∑</mo>
       <mrow>
        <mi>i</mi>
        <mo>=</mo>
        <mn>1</mn>
       </mrow>
       <mi>n</mi>
      </munderover>
      <msup>
       <mrow>
        <mo stretchy="false">(</mo>
        <mrow>
         <msub>
          <mi>X</mi>
          <mi>i</mi>
         </msub>
         <mo>-</mo>
         <mover accent="true">
          <mi>X</mi>
          <mo>¯</mo>
         </mover>
        </mrow>
        <mo stretchy="false">)</mo>
       </mrow>
       <mn>2</mn>
      </msup>
     </mrow>
    </mrow>
    <mo><</mo>
    <mrow>
     <mfrac>
      <mn>1</mn>
      <mi>n</mi>
     </mfrac>
     <mrow>
      <munderover>
       <mo largeop="true" movablelimits="false" symmetric="true">∑</mo>
       <mrow>
        <mi>i</mi>
        <mo>=</mo>
        <mn>1</mn>
       </mrow>
       <mi>n</mi>
      </munderover>
      <msup>
       <mrow>
        <mo stretchy="false">(</mo>
        <mrow>
         <msub>
          <mi>X</mi>
          <mi>i</mi>
         </msub>
         <mo>-</mo>
         <mi>μ</mi>
        </mrow>
        <mo stretchy="false">)</mo>
       </mrow>
       <mn>2</mn>
      </msup>
     </mrow>
    </mrow>
   </mrow>
   <mo>,</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <lt></lt>
    <apply>
     <times></times>
     <apply>
      <divide></divide>
      <cn type="integer">1</cn>
      <ci>n</ci>
     </apply>
     <apply>
      <apply>
       <csymbol cd="ambiguous">superscript</csymbol>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <sum></sum>
        <apply>
         <eq></eq>
         <ci>i</ci>
         <cn type="integer">1</cn>
        </apply>
       </apply>
       <ci>n</ci>
      </apply>
      <apply>
       <csymbol cd="ambiguous">superscript</csymbol>
       <apply>
        <minus></minus>
        <apply>
         <csymbol cd="ambiguous">subscript</csymbol>
         <ci>X</ci>
         <ci>i</ci>
        </apply>
        <apply>
         <ci>normal-¯</ci>
         <ci>X</ci>
        </apply>
       </apply>
       <cn type="integer">2</cn>
      </apply>
     </apply>
    </apply>
    <apply>
     <times></times>
     <apply>
      <divide></divide>
      <cn type="integer">1</cn>
      <ci>n</ci>
     </apply>
     <apply>
      <apply>
       <csymbol cd="ambiguous">superscript</csymbol>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <sum></sum>
        <apply>
         <eq></eq>
         <ci>i</ci>
         <cn type="integer">1</cn>
        </apply>
       </apply>
       <ci>n</ci>
      </apply>
      <apply>
       <csymbol cd="ambiguous">superscript</csymbol>
       <apply>
        <minus></minus>
        <apply>
         <csymbol cd="ambiguous">subscript</csymbol>
         <ci>X</ci>
         <ci>i</ci>
        </apply>
        <ci>μ</ci>
       </apply>
       <cn type="integer">2</cn>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \frac{1}{n}\sum_{i=1}^{n}(X_{i}-\overline{X})^{2}<\frac{1}{n}\sum_{i=1}^{n}(X_%
{i}-\mu)^{2},
  </annotation>
 </semantics>
</math>

 and then</p>

<p>

<math display="inline" id="Bias_of_an_estimator:14">
 <semantics>
  <mrow>
   <mo>E</mo>
   <mrow>
    <mo stretchy="false">[</mo>
    <msup>
     <mi>S</mi>
     <mn>2</mn>
    </msup>
    <mo stretchy="false">]</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <ci>normal-E</ci>
    <apply>
     <csymbol cd="ambiguous">superscript</csymbol>
     <ci>S</ci>
     <cn type="integer">2</cn>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \displaystyle\operatorname{E}[S^{2}]
  </annotation>
 </semantics>
</math>


</p>

<p>Note that the usual definition of sample variance is</p>

<p>

<math display="block" id="Bias_of_an_estimator:15">
 <semantics>
  <mrow>
   <mrow>
    <msup>
     <mi>s</mi>
     <mn>2</mn>
    </msup>
    <mo>=</mo>
    <mrow>
     <mfrac>
      <mn>1</mn>
      <mrow>
       <mi>n</mi>
       <mo>-</mo>
       <mn>1</mn>
      </mrow>
     </mfrac>
     <mrow>
      <munderover>
       <mo largeop="true" movablelimits="false" symmetric="true">∑</mo>
       <mrow>
        <mi>i</mi>
        <mo>=</mo>
        <mn>1</mn>
       </mrow>
       <mi>n</mi>
      </munderover>
      <msup>
       <mrow>
        <mo stretchy="false">(</mo>
        <mrow>
         <msub>
          <mi>X</mi>
          <mi>i</mi>
         </msub>
         <mo>-</mo>
         <mpadded width="+1.7pt">
          <mover accent="true">
           <mi>X</mi>
           <mo>¯</mo>
          </mover>
         </mpadded>
        </mrow>
        <mo stretchy="false">)</mo>
       </mrow>
       <mn>2</mn>
      </msup>
     </mrow>
    </mrow>
   </mrow>
   <mo>,</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <csymbol cd="ambiguous">superscript</csymbol>
     <ci>s</ci>
     <cn type="integer">2</cn>
    </apply>
    <apply>
     <times></times>
     <apply>
      <divide></divide>
      <cn type="integer">1</cn>
      <apply>
       <minus></minus>
       <ci>n</ci>
       <cn type="integer">1</cn>
      </apply>
     </apply>
     <apply>
      <apply>
       <csymbol cd="ambiguous">superscript</csymbol>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <sum></sum>
        <apply>
         <eq></eq>
         <ci>i</ci>
         <cn type="integer">1</cn>
        </apply>
       </apply>
       <ci>n</ci>
      </apply>
      <apply>
       <csymbol cd="ambiguous">superscript</csymbol>
       <apply>
        <minus></minus>
        <apply>
         <csymbol cd="ambiguous">subscript</csymbol>
         <ci>X</ci>
         <ci>i</ci>
        </apply>
        <apply>
         <ci>normal-¯</ci>
         <ci>X</ci>
        </apply>
       </apply>
       <cn type="integer">2</cn>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   s^{2}=\frac{1}{n-1}\sum_{i=1}^{n}(X_{i}-\overline{X}\,)^{2},
  </annotation>
 </semantics>
</math>

</p>

<p>and this is an unbiased estimator of the population variance. This can be seen by noting the following formula, which follows from the <a href="Variance#Sum_of_uncorrelated_variables_.28Bienaym.C3.A9_formula.29" title="wikilink">Bienaymé formula</a>, for the term in the inequality for the expectation of the uncorrected sample variance above:</p>

<p>

<math display="block" id="Bias_of_an_estimator:16">
 <semantics>
  <mrow>
   <mrow>
    <mrow>
     <mo>E</mo>
     <mrow>
      <mo maxsize="120%" minsize="120%">[</mo>
      <msup>
       <mrow>
        <mo stretchy="false">(</mo>
        <mrow>
         <mover accent="true">
          <mi>X</mi>
          <mo>¯</mo>
         </mover>
         <mo>-</mo>
         <mi>μ</mi>
        </mrow>
        <mo stretchy="false">)</mo>
       </mrow>
       <mn>2</mn>
      </msup>
      <mo maxsize="120%" minsize="120%">]</mo>
     </mrow>
    </mrow>
    <mo>=</mo>
    <mrow>
     <mfrac>
      <mn>1</mn>
      <mi>n</mi>
     </mfrac>
     <msup>
      <mi>σ</mi>
      <mn>2</mn>
     </msup>
    </mrow>
   </mrow>
   <mo>.</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <ci>normal-E</ci>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <apply>
       <minus></minus>
       <apply>
        <ci>normal-¯</ci>
        <ci>X</ci>
       </apply>
       <ci>μ</ci>
      </apply>
      <cn type="integer">2</cn>
     </apply>
    </apply>
    <apply>
     <times></times>
     <apply>
      <divide></divide>
      <cn type="integer">1</cn>
      <ci>n</ci>
     </apply>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <ci>σ</ci>
      <cn type="integer">2</cn>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \operatorname{E}\big[(\overline{X}-\mu)^{2}\big]=\frac{1}{n}\sigma^{2}.
  </annotation>
 </semantics>
</math>

 The ratio between the biased (uncorrected) and unbiased estimates of the variance is known as <a href="Bessel's_correction" title="wikilink">Bessel's correction</a>.</p>
<h3 id="estimating-a-poisson-probability">Estimating a Poisson probability</h3>

<p>A far more extreme case of a biased estimator being better than any unbiased estimator arises from the <a href="Poisson_distribution" title="wikilink">Poisson distribution</a>.<a class="footnoteRef" href="#fn2" id="fnref2"><sup>2</sup></a><a class="footnoteRef" href="#fn3" id="fnref3"><sup>3</sup></a> Suppose that <em>X</em> has a Poisson distribution with expectation λ. Suppose it is desired to estimate</p>

<p>

<math display="block" id="Bias_of_an_estimator:17">
 <semantics>
  <mrow>
   <mo>P</mo>
   <msup>
    <mrow>
     <mo stretchy="false">(</mo>
     <mi>X</mi>
     <mo>=</mo>
     <mn>0</mn>
     <mo stretchy="false">)</mo>
    </mrow>
    <mn>2</mn>
   </msup>
   <mo>=</mo>
   <msup>
    <mi>e</mi>
    <mrow>
     <mo>-</mo>
     <mrow>
      <mn>2</mn>
      <mi>λ</mi>
     </mrow>
    </mrow>
   </msup>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <cerror>
    <csymbol cd="ambiguous">fragments</csymbol>
    <ci>normal-P</ci>
    <apply>
     <csymbol cd="ambiguous">superscript</csymbol>
     <cerror>
      <csymbol cd="ambiguous">fragments</csymbol>
      <ci>normal-(</ci>
      <csymbol cd="unknown">X</csymbol>
      <eq></eq>
      <cn type="integer">0</cn>
      <ci>normal-)</ci>
     </cerror>
     <cn type="integer">2</cn>
    </apply>
    <eq></eq>
    <apply>
     <csymbol cd="ambiguous">superscript</csymbol>
     <ci>e</ci>
     <apply>
      <minus></minus>
      <apply>
       <times></times>
       <cn type="integer">2</cn>
       <ci>λ</ci>
      </apply>
     </apply>
    </apply>
    <ci></ci>
   </cerror>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \operatorname{P}(X=0)^{2}=e^{-2\lambda}\quad
  </annotation>
 </semantics>
</math>

</p>

<p>with a sample of size 1. (For example, when incoming calls at a telephone switchboard are modeled as a Poisson process, and λ is the average number of calls per minute, then <em>e</em><sup>−2λ</sup> is the probability that no calls arrive in the next two minutes.)</p>

<p>Since the expectation of an unbiased estimator δ(<em>X</em>) is equal to the estimand, i.e.</p>

<p>

<math display="block" id="Bias_of_an_estimator:18">
 <semantics>
  <mrow>
   <mrow>
    <mrow>
     <mi>E</mi>
     <mrow>
      <mo stretchy="false">(</mo>
      <mrow>
       <mi>δ</mi>
       <mrow>
        <mo stretchy="false">(</mo>
        <mi>X</mi>
        <mo stretchy="false">)</mo>
       </mrow>
      </mrow>
      <mo stretchy="false">)</mo>
     </mrow>
    </mrow>
    <mo>=</mo>
    <mrow>
     <munderover>
      <mo largeop="true" movablelimits="false" symmetric="true">∑</mo>
      <mrow>
       <mi>x</mi>
       <mo>=</mo>
       <mn>0</mn>
      </mrow>
      <mi mathvariant="normal">∞</mi>
     </munderover>
     <mrow>
      <mi>δ</mi>
      <mrow>
       <mo stretchy="false">(</mo>
       <mi>x</mi>
       <mo stretchy="false">)</mo>
      </mrow>
      <mfrac>
       <mrow>
        <msup>
         <mi>λ</mi>
         <mi>x</mi>
        </msup>
        <msup>
         <mi>e</mi>
         <mrow>
          <mo>-</mo>
          <mi>λ</mi>
         </mrow>
        </msup>
       </mrow>
       <mrow>
        <mi>x</mi>
        <mo lspace="0pt" rspace="3.5pt">!</mo>
       </mrow>
      </mfrac>
     </mrow>
    </mrow>
    <mo>=</mo>
    <msup>
     <mi>e</mi>
     <mrow>
      <mo>-</mo>
      <mrow>
       <mn>2</mn>
       <mi>λ</mi>
      </mrow>
     </mrow>
    </msup>
   </mrow>
   <mo>,</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <and></and>
    <apply>
     <eq></eq>
     <apply>
      <times></times>
      <ci>E</ci>
      <apply>
       <times></times>
       <ci>δ</ci>
       <ci>X</ci>
      </apply>
     </apply>
     <apply>
      <apply>
       <csymbol cd="ambiguous">superscript</csymbol>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <sum></sum>
        <apply>
         <eq></eq>
         <ci>x</ci>
         <cn type="integer">0</cn>
        </apply>
       </apply>
       <infinity></infinity>
      </apply>
      <apply>
       <times></times>
       <ci>δ</ci>
       <ci>x</ci>
       <apply>
        <divide></divide>
        <apply>
         <times></times>
         <apply>
          <csymbol cd="ambiguous">superscript</csymbol>
          <ci>λ</ci>
          <ci>x</ci>
         </apply>
         <apply>
          <csymbol cd="ambiguous">superscript</csymbol>
          <ci>e</ci>
          <apply>
           <minus></minus>
           <ci>λ</ci>
          </apply>
         </apply>
        </apply>
        <apply>
         <factorial></factorial>
         <ci>x</ci>
        </apply>
       </apply>
      </apply>
     </apply>
    </apply>
    <apply>
     <eq></eq>
     <share href="#.cmml">
     </share>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <ci>e</ci>
      <apply>
       <minus></minus>
       <apply>
        <times></times>
        <cn type="integer">2</cn>
        <ci>λ</ci>
       </apply>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   E(\delta(X))=\sum_{x=0}^{\infty}\delta(x)\frac{\lambda^{x}e^{-\lambda}}{x!}=e^%
{-2\lambda},
  </annotation>
 </semantics>
</math>

</p>

<p>the only function of the data constituting an unbiased estimator is</p>

<p>

<math display="block" id="Bias_of_an_estimator:19">
 <semantics>
  <mrow>
   <mrow>
    <mrow>
     <mi>δ</mi>
     <mrow>
      <mo stretchy="false">(</mo>
      <mi>x</mi>
      <mo stretchy="false">)</mo>
     </mrow>
    </mrow>
    <mo>=</mo>
    <msup>
     <mrow>
      <mo stretchy="false">(</mo>
      <mrow>
       <mo>-</mo>
       <mn>1</mn>
      </mrow>
      <mo stretchy="false">)</mo>
     </mrow>
     <mi>x</mi>
    </msup>
   </mrow>
   <mo>.</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <times></times>
     <ci>δ</ci>
     <ci>x</ci>
    </apply>
    <apply>
     <csymbol cd="ambiguous">superscript</csymbol>
     <apply>
      <minus></minus>
      <cn type="integer">1</cn>
     </apply>
     <ci>x</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \delta(x)=(-1)^{x}.\,
  </annotation>
 </semantics>
</math>

</p>

<p>To see this, note that when decomposing e<sup>−λ</sup> from the above expression for expectation, the sum that is left is a <a href="Taylor_series" title="wikilink">Taylor series</a> expansion of e<sup>−λ</sup> as well, yielding e<sup>−λ</sup>e<sup>−λ</sup> = e<sup>−2λ</sup> (see <a href="Characterizations_of_the_exponential_function" title="wikilink">Characterizations of the exponential function</a>).</p>

<p>If the observed value of <em>X</em> is 100, then the estimate is 1, although the true value of the quantity being estimated is very likely to be near 0, which is the opposite extreme. And, if <em>X</em> is observed to be 101, then the estimate is even more absurd: It is −1, although the quantity being estimated must be positive.</p>

<p>The (biased) <a href="maximum_likelihood" title="wikilink">maximum likelihood estimator</a></p>

<p>

<math display="block" id="Bias_of_an_estimator:20">
 <semantics>
  <mrow>
   <msup>
    <mi>e</mi>
    <mrow>
     <mo>-</mo>
     <mrow>
      <mn>2</mn>
      <mi>X</mi>
     </mrow>
    </mrow>
   </msup>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">superscript</csymbol>
    <ci>e</ci>
    <apply>
     <minus></minus>
     <apply>
      <times></times>
      <cn type="integer">2</cn>
      <ci>X</ci>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   e^{-2{X}}\quad
  </annotation>
 </semantics>
</math>

</p>

<p>is far better than this unbiased estimator. Not only is its value always positive but it is also more accurate in the sense that its <a href="mean_squared_error" title="wikilink">mean squared error</a></p>

<p>

<math display="block" id="Bias_of_an_estimator:21">
 <semantics>
  <mrow>
   <mrow>
    <msup>
     <mi>e</mi>
     <mrow>
      <mo>-</mo>
      <mrow>
       <mn>4</mn>
       <mi>λ</mi>
      </mrow>
     </mrow>
    </msup>
    <mo>-</mo>
    <mrow>
     <mn>2</mn>
     <msup>
      <mi>e</mi>
      <mrow>
       <mi>λ</mi>
       <mrow>
        <mo stretchy="false">(</mo>
        <mrow>
         <mrow>
          <mn>1</mn>
          <mo>/</mo>
          <msup>
           <mi>e</mi>
           <mn>2</mn>
          </msup>
         </mrow>
         <mo>-</mo>
         <mn>3</mn>
        </mrow>
        <mo stretchy="false">)</mo>
       </mrow>
      </mrow>
     </msup>
    </mrow>
   </mrow>
   <mo>+</mo>
   <mpadded width="+1.7pt">
    <msup>
     <mi>e</mi>
     <mrow>
      <mi>λ</mi>
      <mrow>
       <mo stretchy="false">(</mo>
       <mrow>
        <mrow>
         <mn>1</mn>
         <mo>/</mo>
         <msup>
          <mi>e</mi>
          <mn>4</mn>
         </msup>
        </mrow>
        <mo>-</mo>
        <mn>1</mn>
       </mrow>
       <mo stretchy="false">)</mo>
      </mrow>
     </mrow>
    </msup>
   </mpadded>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <plus></plus>
    <apply>
     <minus></minus>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <ci>e</ci>
      <apply>
       <minus></minus>
       <apply>
        <times></times>
        <cn type="integer">4</cn>
        <ci>λ</ci>
       </apply>
      </apply>
     </apply>
     <apply>
      <times></times>
      <cn type="integer">2</cn>
      <apply>
       <csymbol cd="ambiguous">superscript</csymbol>
       <ci>e</ci>
       <apply>
        <times></times>
        <ci>λ</ci>
        <apply>
         <minus></minus>
         <apply>
          <divide></divide>
          <cn type="integer">1</cn>
          <apply>
           <csymbol cd="ambiguous">superscript</csymbol>
           <ci>e</ci>
           <cn type="integer">2</cn>
          </apply>
         </apply>
         <cn type="integer">3</cn>
        </apply>
       </apply>
      </apply>
     </apply>
    </apply>
    <apply>
     <csymbol cd="ambiguous">superscript</csymbol>
     <ci>e</ci>
     <apply>
      <times></times>
      <ci>λ</ci>
      <apply>
       <minus></minus>
       <apply>
        <divide></divide>
        <cn type="integer">1</cn>
        <apply>
         <csymbol cd="ambiguous">superscript</csymbol>
         <ci>e</ci>
         <cn type="integer">4</cn>
        </apply>
       </apply>
       <cn type="integer">1</cn>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   e^{-4\lambda}-2e^{\lambda(1/e^{2}-3)}+e^{\lambda(1/e^{4}-1)}\,
  </annotation>
 </semantics>
</math>

</p>

<p>is smaller; compare the unbiased estimator's MSE of</p>

<p>

<math display="block" id="Bias_of_an_estimator:22">
 <semantics>
  <mrow>
   <mrow>
    <mn>1</mn>
    <mo>-</mo>
    <msup>
     <mi>e</mi>
     <mrow>
      <mo>-</mo>
      <mrow>
       <mn>4</mn>
       <mi>λ</mi>
      </mrow>
     </mrow>
    </msup>
   </mrow>
   <mo>.</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <minus></minus>
    <cn type="integer">1</cn>
    <apply>
     <csymbol cd="ambiguous">superscript</csymbol>
     <ci>e</ci>
     <apply>
      <minus></minus>
      <apply>
       <times></times>
       <cn type="integer">4</cn>
       <ci>λ</ci>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   1-e^{-4\lambda}.\,
  </annotation>
 </semantics>
</math>

</p>

<p>The MSEs are functions of the true value λ. The bias of the maximum-likelihood estimator is:</p>

<p>

<math display="block" id="Bias_of_an_estimator:23">
 <semantics>
  <mrow>
   <mrow>
    <msup>
     <mi>e</mi>
     <mrow>
      <mo>-</mo>
      <mrow>
       <mn>2</mn>
       <mi>λ</mi>
      </mrow>
     </mrow>
    </msup>
    <mo>-</mo>
    <msup>
     <mi>e</mi>
     <mrow>
      <mi>λ</mi>
      <mrow>
       <mo stretchy="false">(</mo>
       <mrow>
        <mrow>
         <mn>1</mn>
         <mo>/</mo>
         <msup>
          <mi>e</mi>
          <mn>2</mn>
         </msup>
        </mrow>
        <mo>-</mo>
        <mn>1</mn>
       </mrow>
       <mo stretchy="false">)</mo>
      </mrow>
     </mrow>
    </msup>
   </mrow>
   <mo>.</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <minus></minus>
    <apply>
     <csymbol cd="ambiguous">superscript</csymbol>
     <ci>e</ci>
     <apply>
      <minus></minus>
      <apply>
       <times></times>
       <cn type="integer">2</cn>
       <ci>λ</ci>
      </apply>
     </apply>
    </apply>
    <apply>
     <csymbol cd="ambiguous">superscript</csymbol>
     <ci>e</ci>
     <apply>
      <times></times>
      <ci>λ</ci>
      <apply>
       <minus></minus>
       <apply>
        <divide></divide>
        <cn type="integer">1</cn>
        <apply>
         <csymbol cd="ambiguous">superscript</csymbol>
         <ci>e</ci>
         <cn type="integer">2</cn>
        </apply>
       </apply>
       <cn type="integer">1</cn>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   e^{-2\lambda}-e^{\lambda(1/e^{2}-1)}.\,
  </annotation>
 </semantics>
</math>

</p>
<h3 id="maximum-of-a-discrete-uniform-distribution">Maximum of a discrete uniform distribution</h3>

<p>The bias of maximum-likelihood estimators can be substantial. Consider a case where <em>n</em> tickets numbered from 1 through to <em>n</em> are placed in a box and one is selected at random, giving a value <em>X</em>. If <em>n</em> is unknown, then the maximum-likelihood estimator of <em>n</em> is <em>X</em>, even though the expectation of <em>X</em> is only (<em>n</em> + 1)/2; we can be certain only that <em>n</em> is at least <em>X</em> and is probably more. In this case, the natural unbiased estimator is 2<em>X</em> − 1.</p>
<h2 id="median-unbiased-estimators">Median-unbiased estimators</h2>

<p>The theory of median-unbiased estimators was revived by <a href="http://www.universityofcalifornia.edu/senate/inmemoriam/georgewbrown.htm">George W. Brown</a> in 1947:<a class="footnoteRef" href="#fn4" id="fnref4"><sup>4</sup></a></p>
<blockquote>

<p>An estimate of a one-dimensional parameter θ will be said to be median-unbiased, if, for fixed θ, the median of the distribution of the estimate is at the value θ; i.e., the estimate underestimates just as often as it overestimates. This requirement seems for most purposes to accomplish as much as the mean-unbiased requirement and has the additional property that it is invariant under one-to-one transformation.</p>
</blockquote>

<p>Further properties of median-unbiased estimators have been noted by Lehmann, Birnbaum, van der Vaart and Pfanzagl. In particular, median-unbiased estimators exist in cases where mean-unbiased and <a href="maximum_likelihood" title="wikilink">maximum-likelihood</a> estimators do not exist. Besides being invariant under <a href="injective_function" title="wikilink">one-to-one transformations</a>, median-unbiased estimators have surprising <a href="robust_statistics" title="wikilink">robustness</a>. Unfortunately, there is no analogue of Rao-Blackwell Theorem for median-unbiased estimation (see, the book Robust and Non-Robust Models in Statistics by Lev B. Klebanov, Svetlozat T. Rachev and Frank J. Fabozzi, Nova Scientific Publishers, Inc. New York, 2009 (and references there)).</p>
<h2 id="bias-with-respect-to-other-loss-functions">Bias with respect to other loss functions</h2>

<p>Any minimum-variance <em>mean</em>-unbiased estimator minimizes the <a href="Risk_(statistics)" title="wikilink">risk</a> (<a href="expected_loss" title="wikilink">expected loss</a>) with respect to the squared-error <a href="loss_function" title="wikilink">loss function</a> (among mean-unbiased estimators), as observed by <a class="uri" href="Gauss" title="wikilink">Gauss</a>. A minimum-<a href="average_absolute_deviation" title="wikilink">average absolute deviation</a> <em><a class="uri" href="median" title="wikilink">median</a></em>-unbiased estimator minimizes the risk with respect to the <a href="absolute_value" title="wikilink">absolute</a> loss function (among median-unbiased estimators), as observed by <a class="uri" href="Laplace" title="wikilink">Laplace</a>.<a class="footnoteRef" href="#fn5" id="fnref5"><sup>5</sup></a> Other loss functions are used in <a href="statistical_theory" title="wikilink">statistical theory</a>, particularly in <a href="robust_statistics" title="wikilink">robust statistics</a>.. Connections between loss functions and unbiased estimation were studied in many works. Detailed description of corresponding results is given in Chapter 3 of the book Robust and Non-Robust Models in Statistics by Lev B. Klebanov, Svetlozat T. Rachev and Frank J. Fabozzi, Nova Scientific Publishers, Inc. New York, 2009 (and references there).</p>
<h2 id="effect-of-transformations">Effect of transformations</h2>

<p>Note that, when a transformation is applied to a mean-unbiased estimator, the result need not be a mean-unbiased estimator of its corresponding population statistic. By <a href="Jensen's_inequality" title="wikilink">Jensen's inequality</a>, a <a href="convex_function" title="wikilink">convex function</a> as transformation will introduce positive bias, while a <a href="concave_function" title="wikilink">concave function</a> will introduce negative bias, and a function of mixed convexity may introduce bias in either direction, depending on the specific function and distribution. That is, for a non-linear function <em>f</em> and a mean-unbiased estimator <em>U</em> of a parameter <em>p</em>, the composite estimator <em>f</em>(<em>U</em>) need not be a mean-unbiased estimator of <em>f</em>(<em>p</em>). For example, the <a href="square_root" title="wikilink">square root</a> of the unbiased estimator of the population <a class="uri" href="variance" title="wikilink">variance</a> is <em>not</em> a mean-unbiased estimator of the population <a href="standard_deviation" title="wikilink">standard deviation</a>: the square root of the unbiased <a href="sample_variance" title="wikilink">sample variance</a>, the corrected <a href="sample_standard_deviation" title="wikilink">sample standard deviation</a>, is biased. The bias depends both on the sampling distribution of the estimator and on the transform, and can be quite involved to calculate – see <a href="unbiased_estimation_of_standard_deviation" title="wikilink">unbiased estimation of standard deviation</a> for a discussion in this case.</p>
<h2 id="bias-variance-and-mean-squared-error">Bias, variance and mean squared error</h2>
<figure><b>(Figure)</b>
<figcaption>Sampling distributions of two alternative estimators for a parameter β<sub>0</sub>. Although β<sub>1</sub><sup>^</sup> is unbiased, it is clearly inferior to the biased β<sub>2</sub><sup>^</sup>.<br/>
<br/>
<a href="Ridge_regression" title="wikilink">Ridge regression</a> is one example of a technique where allowing a little bias may lead to a considerable reduction in variance, and more reliable estimates overall.</figcaption>
</figure>

<p>While bias quantifies the <em>average</em> difference to be expected between an estimator and an underlying parameter, an estimator based on a finite sample can additionally be expected to differ from the parameter due to the randomness in the sample.</p>

<p>One measure which is used to try to reflect both types of difference is the <a href="mean_square_error" title="wikilink">mean square error</a>,</p>

<p>

<math display="block" id="Bias_of_an_estimator:24">
 <semantics>
  <mrow>
   <mrow>
    <mrow>
     <mo>MSE</mo>
     <mrow>
      <mo stretchy="false">(</mo>
      <mover accent="true">
       <mi>θ</mi>
       <mo stretchy="false">^</mo>
      </mover>
      <mo stretchy="false">)</mo>
     </mrow>
    </mrow>
    <mo>=</mo>
    <mrow>
     <mo>E</mo>
     <mrow>
      <mo maxsize="120%" minsize="120%">[</mo>
      <msup>
       <mrow>
        <mo stretchy="false">(</mo>
        <mrow>
         <mover accent="true">
          <mi>θ</mi>
          <mo stretchy="false">^</mo>
         </mover>
         <mo>-</mo>
         <mi>θ</mi>
        </mrow>
        <mo stretchy="false">)</mo>
       </mrow>
       <mn>2</mn>
      </msup>
      <mo maxsize="120%" minsize="120%">]</mo>
     </mrow>
    </mrow>
   </mrow>
   <mo>.</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <ci>MSE</ci>
     <apply>
      <ci>normal-^</ci>
      <ci>θ</ci>
     </apply>
    </apply>
    <apply>
     <ci>normal-E</ci>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <apply>
       <minus></minus>
       <apply>
        <ci>normal-^</ci>
        <ci>θ</ci>
       </apply>
       <ci>θ</ci>
      </apply>
      <cn type="integer">2</cn>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \operatorname{MSE}(\hat{\theta})=\operatorname{E}\big[(\hat{\theta}-\theta)^{2%
}\big].
  </annotation>
 </semantics>
</math>

</p>

<p>This can be shown to be equal to the square of the bias, plus the variance:</p>

<p>

<math display="inline" id="Bias_of_an_estimator:25">
 <semantics>
  <mrow>
   <mrow>
    <mo>MSE</mo>
    <mrow>
     <mo stretchy="false">(</mo>
     <mover accent="true">
      <mi>θ</mi>
      <mo stretchy="false">^</mo>
     </mover>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
   <mo>=</mo>
   <mi></mi>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <ci>MSE</ci>
     <apply>
      <ci>normal-^</ci>
      <ci>θ</ci>
     </apply>
    </apply>
    <csymbol cd="latexml">absent</csymbol>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \displaystyle\operatorname{MSE}(\hat{\theta})=
  </annotation>
 </semantics>
</math>


</p>

<p>When the parameter is a vector, an analogous decomposition applies:<a class="footnoteRef" href="#fn6" id="fnref6"><sup>6</sup></a></p>

<p>

<math display="block" id="Bias_of_an_estimator:26">
 <semantics>
  <mrow>
   <mrow>
    <mo>MSE</mo>
    <mrow>
     <mo stretchy="false">(</mo>
     <mover accent="true">
      <mi>θ</mi>
      <mo stretchy="false">^</mo>
     </mover>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
   <mo>=</mo>
   <mrow>
    <mrow>
     <mo>trace</mo>
     <mrow>
      <mo stretchy="false">(</mo>
      <mrow>
       <mo>Var</mo>
       <mrow>
        <mo stretchy="false">(</mo>
        <mover accent="true">
         <mi>θ</mi>
         <mo stretchy="false">^</mo>
        </mover>
        <mo stretchy="false">)</mo>
       </mrow>
      </mrow>
      <mo stretchy="false">)</mo>
     </mrow>
    </mrow>
    <mo>+</mo>
    <msup>
     <mrow>
      <mo>∥</mo>
      <mrow>
       <mo>Bias</mo>
       <mrow>
        <mo stretchy="false">(</mo>
        <mover accent="true">
         <mi>θ</mi>
         <mo stretchy="false">^</mo>
        </mover>
        <mo>,</mo>
        <mi>θ</mi>
        <mo stretchy="false">)</mo>
       </mrow>
      </mrow>
      <mo>∥</mo>
     </mrow>
     <mn>2</mn>
    </msup>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <ci>MSE</ci>
     <apply>
      <ci>normal-^</ci>
      <ci>θ</ci>
     </apply>
    </apply>
    <apply>
     <plus></plus>
     <apply>
      <ci>trace</ci>
      <apply>
       <ci>Var</ci>
       <apply>
        <ci>normal-^</ci>
        <ci>θ</ci>
       </apply>
      </apply>
     </apply>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <apply>
       <csymbol cd="latexml">norm</csymbol>
       <apply>
        <ci>Bias</ci>
        <apply>
         <ci>normal-^</ci>
         <ci>θ</ci>
        </apply>
        <ci>θ</ci>
       </apply>
      </apply>
      <cn type="integer">2</cn>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \operatorname{MSE}(\hat{\theta})=\operatorname{trace}(\operatorname{Var}(\hat{%
\theta}))+\left\|\operatorname{Bias}(\hat{\theta},\theta)\right\|^{2}
  </annotation>
 </semantics>
</math>

 where</p>

<p>

<math display="block" id="Bias_of_an_estimator:27">
 <semantics>
  <mrow>
   <mo>trace</mo>
   <mrow>
    <mo stretchy="false">(</mo>
    <mrow>
     <mo>Var</mo>
     <mrow>
      <mo stretchy="false">(</mo>
      <mover accent="true">
       <mi>θ</mi>
       <mo stretchy="false">^</mo>
      </mover>
      <mo stretchy="false">)</mo>
     </mrow>
    </mrow>
    <mo stretchy="false">)</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <ci>trace</ci>
    <apply>
     <ci>Var</ci>
     <apply>
      <ci>normal-^</ci>
      <ci>θ</ci>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \operatorname{trace}(\operatorname{Var}(\hat{\theta}))
  </annotation>
 </semantics>
</math>

 is the trace of the covariance matrix of the estimator.</p>

<p>An estimator that minimises the bias will not necessarily minimise the mean square error.</p>
<h3 id="example-estimation-of-population-variance">Example: Estimation of population variance</h3>

<p>For example,<a class="footnoteRef" href="#fn7" id="fnref7"><sup>7</sup></a> suppose an estimator of the form</p>

<p>

<math display="block" id="Bias_of_an_estimator:28">
 <semantics>
  <mrow>
   <msup>
    <mi>T</mi>
    <mn>2</mn>
   </msup>
   <mo>=</mo>
   <mrow>
    <mi>c</mi>
    <mrow>
     <munderover>
      <mo largeop="true" movablelimits="false" symmetric="true">∑</mo>
      <mrow>
       <mi>i</mi>
       <mo>=</mo>
       <mn>1</mn>
      </mrow>
      <mi>n</mi>
     </munderover>
     <msup>
      <mrow>
       <mo>(</mo>
       <mrow>
        <msub>
         <mi>X</mi>
         <mi>i</mi>
        </msub>
        <mo>-</mo>
        <mpadded width="+1.7pt">
         <mover accent="true">
          <mi>X</mi>
          <mo>¯</mo>
         </mover>
        </mpadded>
       </mrow>
       <mo>)</mo>
      </mrow>
      <mn>2</mn>
     </msup>
    </mrow>
   </mrow>
   <mo>=</mo>
   <mrow>
    <mi>c</mi>
    <mi>n</mi>
    <msup>
     <mi>S</mi>
     <mn>2</mn>
    </msup>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <and></and>
    <apply>
     <eq></eq>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <ci>T</ci>
      <cn type="integer">2</cn>
     </apply>
     <apply>
      <times></times>
      <ci>c</ci>
      <apply>
       <apply>
        <csymbol cd="ambiguous">superscript</csymbol>
        <apply>
         <csymbol cd="ambiguous">subscript</csymbol>
         <sum></sum>
         <apply>
          <eq></eq>
          <ci>i</ci>
          <cn type="integer">1</cn>
         </apply>
        </apply>
        <ci>n</ci>
       </apply>
       <apply>
        <csymbol cd="ambiguous">superscript</csymbol>
        <apply>
         <minus></minus>
         <apply>
          <csymbol cd="ambiguous">subscript</csymbol>
          <ci>X</ci>
          <ci>i</ci>
         </apply>
         <apply>
          <ci>normal-¯</ci>
          <ci>X</ci>
         </apply>
        </apply>
        <cn type="integer">2</cn>
       </apply>
      </apply>
     </apply>
    </apply>
    <apply>
     <eq></eq>
     <share href="#.cmml">
     </share>
     <apply>
      <times></times>
      <ci>c</ci>
      <ci>n</ci>
      <apply>
       <csymbol cd="ambiguous">superscript</csymbol>
       <ci>S</ci>
       <cn type="integer">2</cn>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   T^{2}=c\sum_{i=1}^{n}\left(X_{i}-\overline{X}\,\right)^{2}=cnS^{2}
  </annotation>
 </semantics>
</math>

</p>

<p>is sought for the population variance as above, but this time to minimise the MSE:</p>

<p>

<math display="inline" id="Bias_of_an_estimator:29">
 <semantics>
  <mrow>
   <mo>MSE</mo>
   <mo>=</mo>
   <mi></mi>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <ci>MSE</ci>
    <csymbol cd="latexml">absent</csymbol>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \displaystyle\operatorname{MSE}=
  </annotation>
 </semantics>
</math>


</p>

<p>If the variables <em>X</em><sub>1</sub> ... <em>X</em><sub><em>n</em></sub> follow a normal distribution, then <em>nS</em><sup>2</sup>/σ<sup>2</sup> has a <a href="chi-squared_distribution" title="wikilink">chi-squared distribution</a> with <em>n</em> − 1 degrees of freedom, giving:</p>

<p>

<math display="block" id="Bias_of_an_estimator:30">
 <semantics>
  <mrow>
   <mrow>
    <mrow>
     <mo>E</mo>
     <mrow>
      <mo stretchy="false">[</mo>
      <mrow>
       <mi>n</mi>
       <msup>
        <mi>S</mi>
        <mn>2</mn>
       </msup>
      </mrow>
      <mo stretchy="false">]</mo>
     </mrow>
    </mrow>
    <mo>=</mo>
    <mrow>
     <mrow>
      <mo stretchy="false">(</mo>
      <mrow>
       <mi>n</mi>
       <mo>-</mo>
       <mn>1</mn>
      </mrow>
      <mo stretchy="false">)</mo>
     </mrow>
     <msup>
      <mi>σ</mi>
      <mn>2</mn>
     </msup>
     <mtext>and</mtext>
     <mrow>
      <mo>Var</mo>
      <mrow>
       <mo stretchy="false">(</mo>
       <mrow>
        <mi>n</mi>
        <msup>
         <mi>S</mi>
         <mn>2</mn>
        </msup>
       </mrow>
       <mo stretchy="false">)</mo>
      </mrow>
     </mrow>
    </mrow>
    <mo>=</mo>
    <mrow>
     <mn>2</mn>
     <mrow>
      <mo stretchy="false">(</mo>
      <mrow>
       <mi>n</mi>
       <mo>-</mo>
       <mn>1</mn>
      </mrow>
      <mo stretchy="false">)</mo>
     </mrow>
     <msup>
      <mi>σ</mi>
      <mn>4</mn>
     </msup>
    </mrow>
   </mrow>
   <mo>.</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <and></and>
    <apply>
     <eq></eq>
     <apply>
      <ci>normal-E</ci>
      <apply>
       <times></times>
       <ci>n</ci>
       <apply>
        <csymbol cd="ambiguous">superscript</csymbol>
        <ci>S</ci>
        <cn type="integer">2</cn>
       </apply>
      </apply>
     </apply>
     <apply>
      <times></times>
      <apply>
       <minus></minus>
       <ci>n</ci>
       <cn type="integer">1</cn>
      </apply>
      <apply>
       <csymbol cd="ambiguous">superscript</csymbol>
       <ci>σ</ci>
       <cn type="integer">2</cn>
      </apply>
      <mtext>and</mtext>
      <apply>
       <ci>Var</ci>
       <apply>
        <times></times>
        <ci>n</ci>
        <apply>
         <csymbol cd="ambiguous">superscript</csymbol>
         <ci>S</ci>
         <cn type="integer">2</cn>
        </apply>
       </apply>
      </apply>
     </apply>
    </apply>
    <apply>
     <eq></eq>
     <share href="#.cmml">
     </share>
     <apply>
      <times></times>
      <cn type="integer">2</cn>
      <apply>
       <minus></minus>
       <ci>n</ci>
       <cn type="integer">1</cn>
      </apply>
      <apply>
       <csymbol cd="ambiguous">superscript</csymbol>
       <ci>σ</ci>
       <cn type="integer">4</cn>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \operatorname{E}[nS^{2}]=(n-1)\sigma^{2}\text{ and }\operatorname{Var}(nS^{2})%
=2(n-1)\sigma^{4}.
  </annotation>
 </semantics>
</math>

</p>

<p>and so</p>

<p>

<math display="block" id="Bias_of_an_estimator:31">
 <semantics>
  <mrow>
   <mo>MSE</mo>
   <mo>=</mo>
   <mrow>
    <mrow>
     <msup>
      <mrow>
       <mo stretchy="false">(</mo>
       <mrow>
        <mrow>
         <mi>c</mi>
         <mrow>
          <mo stretchy="false">(</mo>
          <mrow>
           <mi>n</mi>
           <mo>-</mo>
           <mn>1</mn>
          </mrow>
          <mo stretchy="false">)</mo>
         </mrow>
        </mrow>
        <mo>-</mo>
        <mn>1</mn>
       </mrow>
       <mo stretchy="false">)</mo>
      </mrow>
      <mn>2</mn>
     </msup>
     <msup>
      <mi>σ</mi>
      <mn>4</mn>
     </msup>
    </mrow>
    <mo>+</mo>
    <mrow>
     <mn>2</mn>
     <msup>
      <mi>c</mi>
      <mn>2</mn>
     </msup>
     <mrow>
      <mo stretchy="false">(</mo>
      <mrow>
       <mi>n</mi>
       <mo>-</mo>
       <mn>1</mn>
      </mrow>
      <mo stretchy="false">)</mo>
     </mrow>
     <msup>
      <mi>σ</mi>
      <mn>4</mn>
     </msup>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <ci>MSE</ci>
    <apply>
     <plus></plus>
     <apply>
      <times></times>
      <apply>
       <csymbol cd="ambiguous">superscript</csymbol>
       <apply>
        <minus></minus>
        <apply>
         <times></times>
         <ci>c</ci>
         <apply>
          <minus></minus>
          <ci>n</ci>
          <cn type="integer">1</cn>
         </apply>
        </apply>
        <cn type="integer">1</cn>
       </apply>
       <cn type="integer">2</cn>
      </apply>
      <apply>
       <csymbol cd="ambiguous">superscript</csymbol>
       <ci>σ</ci>
       <cn type="integer">4</cn>
      </apply>
     </apply>
     <apply>
      <times></times>
      <cn type="integer">2</cn>
      <apply>
       <csymbol cd="ambiguous">superscript</csymbol>
       <ci>c</ci>
       <cn type="integer">2</cn>
      </apply>
      <apply>
       <minus></minus>
       <ci>n</ci>
       <cn type="integer">1</cn>
      </apply>
      <apply>
       <csymbol cd="ambiguous">superscript</csymbol>
       <ci>σ</ci>
       <cn type="integer">4</cn>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \operatorname{MSE}=(c(n-1)-1)^{2}\sigma^{4}+2c^{2}(n-1)\sigma^{4}
  </annotation>
 </semantics>
</math>

</p>

<p>With a little algebra it can be confirmed that it is <em>c</em> = 1/(<em>n</em> + 1) which minimises this combined loss function, rather than <em>c</em> = 1/(<em>n</em> − 1) which minimises just the bias term.</p>

<p>More generally it is only in restricted classes of problems that there will be an estimator that minimises the MSE independently of the parameter values.</p>

<p>However it is very common that there may be perceived to be a <em>bias–variance tradeoff</em>, such that a small increase in bias can be traded for a larger decrease in variance, resulting in a more desirable estimator overall.</p>
<h2 id="bayesian-view">Bayesian view</h2>

<p>Most bayesians are rather unconcerned about unbiasedness (at least in the formal sampling-theory sense above) of their estimates. For example, Gelman <em>et al</em> (1995) write: "From a Bayesian perspective, the principle of unbiasedness is reasonable in the limit of large samples, but otherwise it is potentially misleading."<a class="footnoteRef" href="#fn8" id="fnref8"><sup>8</sup></a></p>

<p>Fundamentally, the difference between the <a href="Bayesian_statistics" title="wikilink">Bayesian approach</a> and the sampling-theory approach above is that in the sampling-theory approach the parameter is taken as fixed, and then probability distributions of a statistic are considered, based on the predicted sampling distribution of the data. For a Bayesian, however, it is the <em>data</em> which is known, and fixed, and it is the unknown parameter for which an attempt is made to construct a probability distribution, using <a href="Bayes'_theorem" title="wikilink">Bayes' theorem</a>:</p>

<p>

<math display="block" id="Bias_of_an_estimator:32">
 <semantics>
  <mrow>
   <mi>p</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <mi>θ</mi>
    <mo>∣</mo>
    <mi>D</mi>
    <mo>,</mo>
    <mi>I</mi>
    <mo stretchy="false">)</mo>
   </mrow>
   <mo>∝</mo>
   <mi>p</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <mi>θ</mi>
    <mo>∣</mo>
    <mi>I</mi>
    <mo stretchy="false">)</mo>
   </mrow>
   <mi>p</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <mi>D</mi>
    <mo>∣</mo>
    <mi>θ</mi>
    <mo>,</mo>
    <mi>I</mi>
    <mo stretchy="false">)</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <cerror>
    <csymbol cd="ambiguous">fragments</csymbol>
    <csymbol cd="unknown">p</csymbol>
    <cerror>
     <csymbol cd="ambiguous">fragments</csymbol>
     <ci>normal-(</ci>
     <csymbol cd="unknown">θ</csymbol>
     <ci>normal-∣</ci>
     <csymbol cd="unknown">D</csymbol>
     <ci>normal-,</ci>
     <csymbol cd="unknown">I</csymbol>
     <ci>normal-)</ci>
    </cerror>
    <csymbol cd="latexml">proportional-to</csymbol>
    <csymbol cd="unknown">p</csymbol>
    <cerror>
     <csymbol cd="ambiguous">fragments</csymbol>
     <ci>normal-(</ci>
     <csymbol cd="unknown">θ</csymbol>
     <ci>normal-∣</ci>
     <csymbol cd="unknown">I</csymbol>
     <ci>normal-)</ci>
    </cerror>
    <csymbol cd="unknown">p</csymbol>
    <cerror>
     <csymbol cd="ambiguous">fragments</csymbol>
     <ci>normal-(</ci>
     <csymbol cd="unknown">D</csymbol>
     <ci>normal-∣</ci>
     <csymbol cd="unknown">θ</csymbol>
     <ci>normal-,</ci>
     <csymbol cd="unknown">I</csymbol>
     <ci>normal-)</ci>
    </cerror>
   </cerror>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   p(\theta\mid D,I)\propto p(\theta\mid I)p(D\mid\theta,I)
  </annotation>
 </semantics>
</math>

</p>

<p>Here the second term, the <a href="Likelihood_function" title="wikilink">likelihood</a> of the data given the unknown parameter value θ, depends just on the data obtained and the modelling of the data generation process. However a Bayesian calculation also includes the first term, the <a href="prior_probability" title="wikilink">prior probability</a> for θ, which takes account of everything the analyst may know or suspect about θ <em>before</em> the data comes in. This information plays no part in the sampling-theory approach; indeed any attempt to include it would be considered "bias" away from what was pointed to purely by the data. To the extent that Bayesian calculations include prior information, it is therefore essentially inevitable that their results will not be "unbiased" in sampling theory terms.</p>

<p>But the results of a Bayesian approach can differ from the sampling theory approach even if the Bayesian tries to adopt an "uninformative" prior.</p>

<p>For example, consider again the estimation of an unknown population variance σ<sup>2</sup> of a Normal distribution with unknown mean, where it is desired to optimise <em>c</em> in the expected loss function</p>

<p>

<math display="block" id="Bias_of_an_estimator:33">
 <semantics>
  <mrow>
   <mo>ExpectedLoss</mo>
   <mo>=</mo>
   <mrow>
    <mo>E</mo>
    <mrow>
     <mo>[</mo>
     <msup>
      <mrow>
       <mo>(</mo>
       <mrow>
        <mrow>
         <mi>c</mi>
         <mi>n</mi>
         <msup>
          <mi>S</mi>
          <mn>2</mn>
         </msup>
        </mrow>
        <mo>-</mo>
        <msup>
         <mi>σ</mi>
         <mn>2</mn>
        </msup>
       </mrow>
       <mo>)</mo>
      </mrow>
      <mn>2</mn>
     </msup>
     <mo>]</mo>
    </mrow>
   </mrow>
   <mo>=</mo>
   <mrow>
    <mo>E</mo>
    <mrow>
     <mo>[</mo>
     <mrow>
      <msup>
       <mi>σ</mi>
       <mn>4</mn>
      </msup>
      <msup>
       <mrow>
        <mo>(</mo>
        <mrow>
         <mrow>
          <mi>c</mi>
          <mi>n</mi>
          <mstyle displaystyle="false">
           <mfrac>
            <msup>
             <mi>S</mi>
             <mn>2</mn>
            </msup>
            <msup>
             <mi>σ</mi>
             <mn>2</mn>
            </msup>
           </mfrac>
          </mstyle>
         </mrow>
         <mo>-</mo>
         <mn>1</mn>
        </mrow>
        <mo>)</mo>
       </mrow>
       <mn>2</mn>
      </msup>
     </mrow>
     <mo>]</mo>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <and></and>
    <apply>
     <eq></eq>
     <ci>ExpectedLoss</ci>
     <apply>
      <ci>normal-E</ci>
      <apply>
       <csymbol cd="ambiguous">superscript</csymbol>
       <apply>
        <minus></minus>
        <apply>
         <times></times>
         <ci>c</ci>
         <ci>n</ci>
         <apply>
          <csymbol cd="ambiguous">superscript</csymbol>
          <ci>S</ci>
          <cn type="integer">2</cn>
         </apply>
        </apply>
        <apply>
         <csymbol cd="ambiguous">superscript</csymbol>
         <ci>σ</ci>
         <cn type="integer">2</cn>
        </apply>
       </apply>
       <cn type="integer">2</cn>
      </apply>
     </apply>
    </apply>
    <apply>
     <eq></eq>
     <share href="#.cmml">
     </share>
     <apply>
      <ci>normal-E</ci>
      <apply>
       <times></times>
       <apply>
        <csymbol cd="ambiguous">superscript</csymbol>
        <ci>σ</ci>
        <cn type="integer">4</cn>
       </apply>
       <apply>
        <csymbol cd="ambiguous">superscript</csymbol>
        <apply>
         <minus></minus>
         <apply>
          <times></times>
          <ci>c</ci>
          <ci>n</ci>
          <apply>
           <divide></divide>
           <apply>
            <csymbol cd="ambiguous">superscript</csymbol>
            <ci>S</ci>
            <cn type="integer">2</cn>
           </apply>
           <apply>
            <csymbol cd="ambiguous">superscript</csymbol>
            <ci>σ</ci>
            <cn type="integer">2</cn>
           </apply>
          </apply>
         </apply>
         <cn type="integer">1</cn>
        </apply>
        <cn type="integer">2</cn>
       </apply>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \operatorname{ExpectedLoss}=\operatorname{E}\left[\left(cnS^{2}-\sigma^{2}%
\right)^{2}\right]=\operatorname{E}\left[\sigma^{4}\left(cn\tfrac{S^{2}}{%
\sigma^{2}}-1\right)^{2}\right]
  </annotation>
 </semantics>
</math>

</p>

<p>A standard choice of uninformative prior for this problem is the <a href="Jeffreys_prior#Gaussian_distribution_with_standard_deviation_parameter" title="wikilink">Jeffreys prior</a>, 

<math display="inline" id="Bias_of_an_estimator:34">
 <semantics>
  <mrow>
   <mrow>
    <mi>p</mi>
    <mrow>
     <mo stretchy="false">(</mo>
     <msup>
      <mi>σ</mi>
      <mn>2</mn>
     </msup>
     <mo rspace="5.3pt" stretchy="false">)</mo>
    </mrow>
   </mrow>
   <mo>∝</mo>
   <mrow>
    <mn>1</mn>
    <mo>/</mo>
    <msup>
     <mi>σ</mi>
     <mn>2</mn>
    </msup>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="latexml">proportional-to</csymbol>
    <apply>
     <times></times>
     <ci>p</ci>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <ci>σ</ci>
      <cn type="integer">2</cn>
     </apply>
    </apply>
    <apply>
     <divide></divide>
     <cn type="float">1</cn>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <ci>σ</ci>
      <cn type="integer">2</cn>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \scriptstyle{p(\sigma^{2})\;\propto\;1/\sigma^{2}}
  </annotation>
 </semantics>
</math>

, which is equivalent to adopting a rescaling-invariant flat prior for <strong>ln( σ<sup>2</sup>)</strong>.</p>

<p>One consequence of adopting this prior is that <em>S</em><sup>2</sup>/σ<sup>2</sup> remains a <a href="pivotal_quantity" title="wikilink">pivotal quantity</a>, i.e. the probability distribution of <em>S</em><sup>2</sup>/σ<sup>2</sup> depends only on <em>S</em><sup>2</sup>/σ<sup>2</sup>, independent of the value of <em>S</em><sup>2</sup> or σ<sup>2</sup>:</p>

<p>

<math display="block" id="Bias_of_an_estimator:35">
 <semantics>
  <mrow>
   <mi>p</mi>
   <mrow>
    <mo>(</mo>
    <mstyle displaystyle="false">
     <mfrac>
      <msup>
       <mi>S</mi>
       <mn>2</mn>
      </msup>
      <msup>
       <mi>σ</mi>
       <mn>2</mn>
      </msup>
     </mfrac>
    </mstyle>
    <mo>∣</mo>
    <msup>
     <mi>S</mi>
     <mn>2</mn>
    </msup>
    <mo>)</mo>
   </mrow>
   <mo>=</mo>
   <mi>p</mi>
   <mrow>
    <mo>(</mo>
    <mstyle displaystyle="false">
     <mfrac>
      <msup>
       <mi>S</mi>
       <mn>2</mn>
      </msup>
      <msup>
       <mi>σ</mi>
       <mn>2</mn>
      </msup>
     </mfrac>
    </mstyle>
    <mo>∣</mo>
    <msup>
     <mi>σ</mi>
     <mn>2</mn>
    </msup>
    <mo>)</mo>
   </mrow>
   <mo>=</mo>
   <mi>g</mi>
   <mrow>
    <mo>(</mo>
    <mstyle displaystyle="false">
     <mfrac>
      <msup>
       <mi>S</mi>
       <mn>2</mn>
      </msup>
      <msup>
       <mi>σ</mi>
       <mn>2</mn>
      </msup>
     </mfrac>
    </mstyle>
    <mo>)</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <cerror>
    <csymbol cd="ambiguous">fragments</csymbol>
    <csymbol cd="unknown">p</csymbol>
    <cerror>
     <csymbol cd="ambiguous">fragments</csymbol>
     <ci>normal-(</ci>
     <apply>
      <divide></divide>
      <apply>
       <csymbol cd="ambiguous">superscript</csymbol>
       <ci>S</ci>
       <cn type="integer">2</cn>
      </apply>
      <apply>
       <csymbol cd="ambiguous">superscript</csymbol>
       <ci>σ</ci>
       <cn type="integer">2</cn>
      </apply>
     </apply>
     <ci>normal-∣</ci>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <ci>S</ci>
      <cn type="integer">2</cn>
     </apply>
     <ci>normal-)</ci>
    </cerror>
    <eq></eq>
    <csymbol cd="unknown">p</csymbol>
    <cerror>
     <csymbol cd="ambiguous">fragments</csymbol>
     <ci>normal-(</ci>
     <apply>
      <divide></divide>
      <apply>
       <csymbol cd="ambiguous">superscript</csymbol>
       <ci>S</ci>
       <cn type="integer">2</cn>
      </apply>
      <apply>
       <csymbol cd="ambiguous">superscript</csymbol>
       <ci>σ</ci>
       <cn type="integer">2</cn>
      </apply>
     </apply>
     <ci>normal-∣</ci>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <ci>σ</ci>
      <cn type="integer">2</cn>
     </apply>
     <ci>normal-)</ci>
    </cerror>
    <eq></eq>
    <csymbol cd="unknown">g</csymbol>
    <cerror>
     <csymbol cd="ambiguous">fragments</csymbol>
     <ci>normal-(</ci>
     <apply>
      <divide></divide>
      <apply>
       <csymbol cd="ambiguous">superscript</csymbol>
       <ci>S</ci>
       <cn type="integer">2</cn>
      </apply>
      <apply>
       <csymbol cd="ambiguous">superscript</csymbol>
       <ci>σ</ci>
       <cn type="integer">2</cn>
      </apply>
     </apply>
     <ci>normal-)</ci>
    </cerror>
   </cerror>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   p\left(\tfrac{S^{2}}{\sigma^{2}}\mid S^{2}\right)=p\left(\tfrac{S^{2}}{\sigma^%
{2}}\mid\sigma^{2}\right)=g\left(\tfrac{S^{2}}{\sigma^{2}}\right)
  </annotation>
 </semantics>
</math>

</p>

<p>However, whilst</p>

<p>

<math display="block" id="Bias_of_an_estimator:36">
 <semantics>
  <mrow>
   <mrow>
    <msub>
     <mo>E</mo>
     <mrow>
      <mi>p</mi>
      <mrow>
       <mo stretchy="false">(</mo>
       <msup>
        <mi>S</mi>
        <mn>2</mn>
       </msup>
       <mo>∣</mo>
       <msup>
        <mi>σ</mi>
        <mn>2</mn>
       </msup>
       <mo stretchy="false">)</mo>
      </mrow>
     </mrow>
    </msub>
    <mrow>
     <mo>[</mo>
     <mrow>
      <msup>
       <mi>σ</mi>
       <mn>4</mn>
      </msup>
      <msup>
       <mrow>
        <mo>(</mo>
        <mrow>
         <mrow>
          <mi>c</mi>
          <mi>n</mi>
          <mstyle displaystyle="false">
           <mfrac>
            <msup>
             <mi>S</mi>
             <mn>2</mn>
            </msup>
            <msup>
             <mi>σ</mi>
             <mn>2</mn>
            </msup>
           </mfrac>
          </mstyle>
         </mrow>
         <mo>-</mo>
         <mn>1</mn>
        </mrow>
        <mo>)</mo>
       </mrow>
       <mn>2</mn>
      </msup>
     </mrow>
     <mo>]</mo>
    </mrow>
   </mrow>
   <mo>=</mo>
   <mrow>
    <msup>
     <mi>σ</mi>
     <mn>4</mn>
    </msup>
    <mrow>
     <msub>
      <mo>E</mo>
      <mrow>
       <mi>p</mi>
       <mrow>
        <mo stretchy="false">(</mo>
        <msup>
         <mi>S</mi>
         <mn>2</mn>
        </msup>
        <mo>∣</mo>
        <msup>
         <mi>σ</mi>
         <mn>2</mn>
        </msup>
        <mo stretchy="false">)</mo>
       </mrow>
      </mrow>
     </msub>
     <mrow>
      <mo>[</mo>
      <msup>
       <mrow>
        <mo>(</mo>
        <mrow>
         <mrow>
          <mi>c</mi>
          <mi>n</mi>
          <mstyle displaystyle="false">
           <mfrac>
            <msup>
             <mi>S</mi>
             <mn>2</mn>
            </msup>
            <msup>
             <mi>σ</mi>
             <mn>2</mn>
            </msup>
           </mfrac>
          </mstyle>
         </mrow>
         <mo>-</mo>
         <mn>1</mn>
        </mrow>
        <mo>)</mo>
       </mrow>
       <mn>2</mn>
      </msup>
      <mo>]</mo>
     </mrow>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>normal-E</ci>
      <cerror>
       <csymbol cd="ambiguous">fragments</csymbol>
       <csymbol cd="unknown">p</csymbol>
       <cerror>
        <csymbol cd="ambiguous">fragments</csymbol>
        <ci>normal-(</ci>
        <apply>
         <csymbol cd="ambiguous">superscript</csymbol>
         <ci>S</ci>
         <cn type="integer">2</cn>
        </apply>
        <ci>normal-∣</ci>
        <apply>
         <csymbol cd="ambiguous">superscript</csymbol>
         <ci>σ</ci>
         <cn type="integer">2</cn>
        </apply>
        <ci>normal-)</ci>
       </cerror>
      </cerror>
     </apply>
     <apply>
      <times></times>
      <apply>
       <csymbol cd="ambiguous">superscript</csymbol>
       <ci>σ</ci>
       <cn type="integer">4</cn>
      </apply>
      <apply>
       <csymbol cd="ambiguous">superscript</csymbol>
       <apply>
        <minus></minus>
        <apply>
         <times></times>
         <ci>c</ci>
         <ci>n</ci>
         <apply>
          <divide></divide>
          <apply>
           <csymbol cd="ambiguous">superscript</csymbol>
           <ci>S</ci>
           <cn type="integer">2</cn>
          </apply>
          <apply>
           <csymbol cd="ambiguous">superscript</csymbol>
           <ci>σ</ci>
           <cn type="integer">2</cn>
          </apply>
         </apply>
        </apply>
        <cn type="integer">1</cn>
       </apply>
       <cn type="integer">2</cn>
      </apply>
     </apply>
    </apply>
    <apply>
     <times></times>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <ci>σ</ci>
      <cn type="integer">4</cn>
     </apply>
     <apply>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>normal-E</ci>
       <cerror>
        <csymbol cd="ambiguous">fragments</csymbol>
        <csymbol cd="unknown">p</csymbol>
        <cerror>
         <csymbol cd="ambiguous">fragments</csymbol>
         <ci>normal-(</ci>
         <apply>
          <csymbol cd="ambiguous">superscript</csymbol>
          <ci>S</ci>
          <cn type="integer">2</cn>
         </apply>
         <ci>normal-∣</ci>
         <apply>
          <csymbol cd="ambiguous">superscript</csymbol>
          <ci>σ</ci>
          <cn type="integer">2</cn>
         </apply>
         <ci>normal-)</ci>
        </cerror>
       </cerror>
      </apply>
      <apply>
       <csymbol cd="ambiguous">superscript</csymbol>
       <apply>
        <minus></minus>
        <apply>
         <times></times>
         <ci>c</ci>
         <ci>n</ci>
         <apply>
          <divide></divide>
          <apply>
           <csymbol cd="ambiguous">superscript</csymbol>
           <ci>S</ci>
           <cn type="integer">2</cn>
          </apply>
          <apply>
           <csymbol cd="ambiguous">superscript</csymbol>
           <ci>σ</ci>
           <cn type="integer">2</cn>
          </apply>
         </apply>
        </apply>
        <cn type="integer">1</cn>
       </apply>
       <cn type="integer">2</cn>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \operatorname{E}_{p(S^{2}\mid\sigma^{2})}\left[\sigma^{4}\left(cn\tfrac{S^{2}}%
{\sigma^{2}}-1\right)^{2}\right]=\sigma^{4}\operatorname{E}_{p(S^{2}\mid\sigma%
^{2})}\left[\left(cn\tfrac{S^{2}}{\sigma^{2}}-1\right)^{2}\right]
  </annotation>
 </semantics>
</math>

</p>

<p>in contrast</p>

<p>

<math display="block" id="Bias_of_an_estimator:37">
 <semantics>
  <mrow>
   <mrow>
    <msub>
     <mo>E</mo>
     <mrow>
      <mi>p</mi>
      <mrow>
       <mo stretchy="false">(</mo>
       <msup>
        <mi>σ</mi>
        <mn>2</mn>
       </msup>
       <mo>∣</mo>
       <msup>
        <mi>S</mi>
        <mn>2</mn>
       </msup>
       <mo stretchy="false">)</mo>
      </mrow>
     </mrow>
    </msub>
    <mrow>
     <mo>[</mo>
     <mrow>
      <msup>
       <mi>σ</mi>
       <mn>4</mn>
      </msup>
      <msup>
       <mrow>
        <mo>(</mo>
        <mrow>
         <mrow>
          <mi>c</mi>
          <mi>n</mi>
          <mstyle displaystyle="false">
           <mfrac>
            <msup>
             <mi>S</mi>
             <mn>2</mn>
            </msup>
            <msup>
             <mi>σ</mi>
             <mn>2</mn>
            </msup>
           </mfrac>
          </mstyle>
         </mrow>
         <mo>-</mo>
         <mn>1</mn>
        </mrow>
        <mo>)</mo>
       </mrow>
       <mn>2</mn>
      </msup>
     </mrow>
     <mo>]</mo>
    </mrow>
   </mrow>
   <mo>≠</mo>
   <mrow>
    <msup>
     <mi>σ</mi>
     <mn>4</mn>
    </msup>
    <mrow>
     <msub>
      <mo>E</mo>
      <mrow>
       <mi>p</mi>
       <mrow>
        <mo stretchy="false">(</mo>
        <msup>
         <mi>σ</mi>
         <mn>2</mn>
        </msup>
        <mo>∣</mo>
        <msup>
         <mi>S</mi>
         <mn>2</mn>
        </msup>
        <mo stretchy="false">)</mo>
       </mrow>
      </mrow>
     </msub>
     <mrow>
      <mo>[</mo>
      <msup>
       <mrow>
        <mo>(</mo>
        <mrow>
         <mrow>
          <mi>c</mi>
          <mi>n</mi>
          <mstyle displaystyle="false">
           <mfrac>
            <msup>
             <mi>S</mi>
             <mn>2</mn>
            </msup>
            <msup>
             <mi>σ</mi>
             <mn>2</mn>
            </msup>
           </mfrac>
          </mstyle>
         </mrow>
         <mo>-</mo>
         <mn>1</mn>
        </mrow>
        <mo>)</mo>
       </mrow>
       <mn>2</mn>
      </msup>
      <mo>]</mo>
     </mrow>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <neq></neq>
    <apply>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>normal-E</ci>
      <cerror>
       <csymbol cd="ambiguous">fragments</csymbol>
       <csymbol cd="unknown">p</csymbol>
       <cerror>
        <csymbol cd="ambiguous">fragments</csymbol>
        <ci>normal-(</ci>
        <apply>
         <csymbol cd="ambiguous">superscript</csymbol>
         <ci>σ</ci>
         <cn type="integer">2</cn>
        </apply>
        <ci>normal-∣</ci>
        <apply>
         <csymbol cd="ambiguous">superscript</csymbol>
         <ci>S</ci>
         <cn type="integer">2</cn>
        </apply>
        <ci>normal-)</ci>
       </cerror>
      </cerror>
     </apply>
     <apply>
      <times></times>
      <apply>
       <csymbol cd="ambiguous">superscript</csymbol>
       <ci>σ</ci>
       <cn type="integer">4</cn>
      </apply>
      <apply>
       <csymbol cd="ambiguous">superscript</csymbol>
       <apply>
        <minus></minus>
        <apply>
         <times></times>
         <ci>c</ci>
         <ci>n</ci>
         <apply>
          <divide></divide>
          <apply>
           <csymbol cd="ambiguous">superscript</csymbol>
           <ci>S</ci>
           <cn type="integer">2</cn>
          </apply>
          <apply>
           <csymbol cd="ambiguous">superscript</csymbol>
           <ci>σ</ci>
           <cn type="integer">2</cn>
          </apply>
         </apply>
        </apply>
        <cn type="integer">1</cn>
       </apply>
       <cn type="integer">2</cn>
      </apply>
     </apply>
    </apply>
    <apply>
     <times></times>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <ci>σ</ci>
      <cn type="integer">4</cn>
     </apply>
     <apply>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>normal-E</ci>
       <cerror>
        <csymbol cd="ambiguous">fragments</csymbol>
        <csymbol cd="unknown">p</csymbol>
        <cerror>
         <csymbol cd="ambiguous">fragments</csymbol>
         <ci>normal-(</ci>
         <apply>
          <csymbol cd="ambiguous">superscript</csymbol>
          <ci>σ</ci>
          <cn type="integer">2</cn>
         </apply>
         <ci>normal-∣</ci>
         <apply>
          <csymbol cd="ambiguous">superscript</csymbol>
          <ci>S</ci>
          <cn type="integer">2</cn>
         </apply>
         <ci>normal-)</ci>
        </cerror>
       </cerror>
      </apply>
      <apply>
       <csymbol cd="ambiguous">superscript</csymbol>
       <apply>
        <minus></minus>
        <apply>
         <times></times>
         <ci>c</ci>
         <ci>n</ci>
         <apply>
          <divide></divide>
          <apply>
           <csymbol cd="ambiguous">superscript</csymbol>
           <ci>S</ci>
           <cn type="integer">2</cn>
          </apply>
          <apply>
           <csymbol cd="ambiguous">superscript</csymbol>
           <ci>σ</ci>
           <cn type="integer">2</cn>
          </apply>
         </apply>
        </apply>
        <cn type="integer">1</cn>
       </apply>
       <cn type="integer">2</cn>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \operatorname{E}_{p(\sigma^{2}\mid S^{2})}\left[\sigma^{4}\left(cn\tfrac{S^{2}%
}{\sigma^{2}}-1\right)^{2}\right]\neq\sigma^{4}\operatorname{E}_{p(\sigma^{2}%
\mid S^{2})}\left[\left(cn\tfrac{S^{2}}{\sigma^{2}}-1\right)^{2}\right]
  </annotation>
 </semantics>
</math>

</p>

<p>— when the expectation is taken over the probability distribution of σ<sup>2</sup> given <em>S</em><sup>2</sup>, as it is in the Bayesian case, rather than <em>S</em><sup>2</sup> given σ<sup>2</sup>, one can no longer take σ<sup>4</sup> as a constant and factor it out. The consequence of this is that, compared to the sampling-theory calculation, the Bayesian calculation puts more weight on larger values of σ<sup>2</sup>, properly taking into account (as the sampling-theory calculation cannot) that under this squared-loss function the consequence of underestimating large values of σ<sup>2</sup> is more costly in squared-loss terms than that of overestimating small values of σ<sup>2</sup>.</p>

<p>The worked-out Bayesian calculation gives a <a href="scaled_inverse_chi-squared_distribution" title="wikilink">scaled inverse chi-squared distribution</a> with <em>n</em> − 1 degrees of freedom for the posterior probability distribution of σ<sup>2</sup>. The expected loss is minimised when <em>cnS</em><sup>2</sup> = 2&gt;; this occurs when <em>c</em> = 1/(<em>n</em> − 3).</p>

<p>Even with an uninformative prior, therefore, a Bayesian calculation may not give the same expected-loss minimising result as the corresponding sampling-theory calculation.</p>
<h2 id="see-also">See also</h2>
<ul>
<li><a href="Omitted-variable_bias" title="wikilink">Omitted-variable bias</a></li>
<li><a href="Consistent_estimator" title="wikilink">Consistent estimator</a></li>
<li><a href="Estimation_theory" title="wikilink">Estimation theory</a></li>
<li><a href="Expected_loss" title="wikilink">Expected loss</a></li>
<li><a href="Expected_value" title="wikilink">Expected value</a></li>
<li><a href="Loss_function" title="wikilink">Loss function</a></li>
<li><a class="uri" href="Median" title="wikilink">Median</a></li>
<li><a href="Statistical_decision_theory" title="wikilink">Statistical decision theory</a></li>
<li><a href="Optimism_bias" title="wikilink">Optimism bias</a></li>
</ul>
<h2 id="notes">Notes</h2>
<h2 id="references">References</h2>
<ul>
<li><a href="http://www.universityofcalifornia.edu/senate/inmemoriam/georgewbrown.htm">Brown, George W.</a> "On Small-Sample Estimation." <em>The Annals of Mathematical Statistics</em>,  18, no. 4 (Dec., 1947), pp. 582–585. .</li>
<li><a href="Erich_Leo_Lehmann" title="wikilink">Lehmann, E. L.</a> "A General Concept of Unbiasedness" <em>The Annals of Mathematical Statistics</em>,  22, no. 4 (Dec., 1951), pp. 587–592. .</li>
<li><a href="Allan_Birnbaum" title="wikilink">Allan Birnbaum</a>, 1961. "A Unified Theory of Estimation, I", <em>The Annals of Mathematical Statistics</em>,  32, no. 1 (Mar., 1961), pp. 112–135.</li>
<li>Van der Vaart, H. R., 1961. "Some Extensions of the Idea of Bias" <em>The Annals of Mathematical Statistics</em>,  32, no. 2 (June 1961), pp. 436–447.</li>
<li>Pfanzagl, Johann. 1994. <em>Parametric Statistical Theory</em>. Walter de Gruyter.</li>
<li>

<p>.</p></li>
<li></li>
<li></li>
</ul>
<h2 id="external-links">External links</h2>
<ul>
<li>

<p></p></li>
</ul>

<p><a href="es:Sesgo_estadístico" title="wikilink">es:Sesgo estadístico</a>"</p>

<p><a href="Category:Statistical_theory" title="wikilink">Category:Statistical theory</a> <a href="Category:Point_estimation_performance" title="wikilink">Category:Point estimation performance</a> <a href="Category:Bias" title="wikilink">estimator, of an</a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1"><a href="#fnref1">↩</a></li>
<li id="fn2">J. P. Romano and A. F. Siegel (1986) <em>Counterexamples in Probability and Statistics</em>, Wadsworth &amp; Brooks / Cole, Monterey, California, USA, p. 168<a href="#fnref2">↩</a></li>
<li id="fn3"><a href="#fnref3">↩</a></li>
<li id="fn4">Brown (1947), page 583<a href="#fnref4">↩</a></li>
<li id="fn5"><a href="#fnref5">↩</a></li>
<li id="fn6"><a href="#fnref6">↩</a></li>
<li id="fn7">Morris H. DeGroot (1986), <em>Probability and Statistics</em> (2nd edition), Addison-Wesley. ISBN 0-201-11366-X. Pp. 414–5.<br/>
But  e.g. discussion in Casella and Berger (2001), <em>Statistical Inference</em> (2nd edition), Duxbury. ISBN 0534243126. P. 332.<a href="#fnref7">↩</a></li>
<li id="fn8">A. Gelman <em>et al</em> (1995), <em>Bayesian Data Analysis</em>, Chapman and Hall. ISBN 0-412-03991-5. p. 108.<a href="#fnref8">↩</a></li>
</ol>
</section>
</body>
</html>
