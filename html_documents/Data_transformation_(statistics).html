<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="864">Data transformation (statistics)</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>Data transformation (statistics)</h1>
<hr/>

<p> In <a class="uri" href="statistics" title="wikilink">statistics</a>, <strong>data <a href="Transformation_(mathematics)" title="wikilink">transformation</a></strong> is the application of a deterministic mathematical <a href="function_(mathematics)" title="wikilink">function</a> to each point in a <a class="uri" href="data" title="wikilink">data</a> set — that is, each data point <em>z<sub>i</sub></em> is replaced with the transformed value <em>y<sub>i</sub></em> = <em>f</em>(<em>z<sub>i</sub></em>), where <em>f</em> is a function. Transforms are usually applied so that the data appear to more closely meet the assumptions of a <a href="statistical_inference" title="wikilink">statistical inference</a> procedure that is to be applied, or to improve the interpretability or appearance of <a href="statistical_graphics" title="wikilink">graphs</a>.</p>

<p>Nearly always, the function that is used to transform the data is <a href="inverse_function" title="wikilink">invertible</a>, and generally is <a href="continuous_function" title="wikilink">continuous</a>. The transformation is usually applied to a collection of comparable measurements. For example, if we are working with data on peoples' incomes in some <a class="uri" href="currency" title="wikilink">currency</a> unit, it would be common to transform each person's income value by the <a class="uri" href="logarithm" title="wikilink">logarithm</a> function.</p>
<h2 id="reasons-for-transforming-data">Reasons for transforming data</h2>

<p>Guidance for how data should be transformed, or whether a transformation should be applied at all, should come from the particular statistical analysis to be performed. For example, a simple way to construct an approximate 95% <a href="confidence_interval" title="wikilink">confidence interval</a> for the population mean is to take the <a href="arithmetic_mean" title="wikilink">sample mean</a> plus or minus two <a href="standard_error" title="wikilink">standard error</a> units. However, the constant factor 2 used here is particular to the <a href="normal_distribution" title="wikilink">normal distribution</a>, and is only applicable if the sample mean varies approximately normally. The <a href="central_limit_theorem" title="wikilink">central limit theorem</a> states that in many situations, the sample mean does vary normally if the sample size is reasonably large. However if the <a href="statistical_population" title="wikilink">population</a> is substantially <a href="skewness" title="wikilink">skewed</a> and the sample size is at most moderate, the approximation provided by the central limit theorem can be poor, and the resulting confidence interval will likely have the wrong <a href="coverage_probability" title="wikilink">coverage probability</a>. Thus, when there is evidence of substantial skew in the data, it is common to transform the data to a <a href="symmetry" title="wikilink">symmetric</a> <a href="probability_distribution" title="wikilink">distribution</a> before constructing a confidence interval. If desired, the confidence interval can then be transformed back to the original scale using the inverse of the transformation that was applied to the data.</p>

<p>Data can also be transformed to make it easier to visualize them. For example, suppose we have a scatterplot in which the points are the countries of the world, and the data values being plotted are the land area and population of each country. If the plot is made using untransformed data (e.g. square kilometers for area and the number of people for population), most of the countries would be plotted in tight cluster of points in the lower left corner of the graph. The few countries with very large areas and/or populations would be spread thinly around most of the graph's area. Simply rescaling units (e.g. to thousand square kilometers, or to millions of people) will not change this. However, following <a href="logarithm" title="wikilink">logarithmic</a> transformations of both area and population, the points will be spread more uniformly in the graph.</p>

<p>A final reason that data can be transformed is to improve interpretability, even if no formal statistical analysis or visualization is to be performed. For example, suppose we are comparing <a href="automobile" title="wikilink">cars</a> in terms of their fuel economy. These data are usually presented as "kilometers per liter" or "miles per gallon." However if the goal is to assess how much additional fuel a person would use in one year when driving one car compared to another, it is more natural to work with the data transformed by the <a href="multiplicative_inverse" title="wikilink">reciprocal</a> function, yielding liters per kilometer, or gallons per mile.</p>
<h2 id="data-transformation-in-regression">Data transformation in regression</h2>

<p><a href="Linear_regression" title="wikilink">Linear regression</a> is a statistical technique for relating a <a href="dependent_and_independent_variables" title="wikilink">dependent variable</a> <em>Y</em> to one or more independent variables <em>X</em>. The simplest regression models capture a <a class="uri" href="linear" title="wikilink">linear</a> relationship between the <a href="expected_value" title="wikilink">expected value</a> of <em>Y</em> and each <a href="dependent_and_independent_variables" title="wikilink">independent variable</a> (when the other independent variables are held fixed). If linearity fails to hold, even approximately, it is sometimes possible to transform either the independent or dependent variables in the regression model to improve the linearity.</p>

<p>Another assumption of linear regression is that the <a class="uri" href="variance" title="wikilink">variance</a> be the same for each possible expected value (this is known as <a class="uri" href="homoscedasticity" title="wikilink">homoscedasticity</a>). Univariate normality is not needed for <a href="least_squares" title="wikilink">least squares</a> estimates of the regression parameters to be meaningful (see <a href="Gauss-Markov_theorem" title="wikilink">Gauss-Markov theorem</a>). However confidence intervals and <a href="hypothesis_test" title="wikilink">hypothesis tests</a> will have better statistical properties if the variables exhibit multivariate normality. This can be assessed empirically by plotting the fitted values against the <a href="errors_and_residuals_in_statistics" title="wikilink">residuals</a>, and by inspecting the <a href="Q-Q_plot" title="wikilink">normal quantile plot</a> of the residuals. Note that it is not relevant whether the dependent variable <em>Y</em> is <a href="marginal_distribution" title="wikilink">marginally</a> normally distributed.</p>
<h2 id="examples-of-transformations">Examples of transformations</h2>

<p><strong>Equation:</strong> 

<math display="inline" id="Data_transformation_(statistics):0">
 <semantics>
  <mrow>
   <mi>Y</mi>
   <mo>=</mo>
   <mrow>
    <mi>a</mi>
    <mo>+</mo>
    <mrow>
     <mi>b</mi>
     <mi>X</mi>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <ci>Y</ci>
    <apply>
     <plus></plus>
     <ci>a</ci>
     <apply>
      <times></times>
      <ci>b</ci>
      <ci>X</ci>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   Y=a+bX
  </annotation>
 </semantics>
</math>

</p>
<dl>
<dd><strong>Meaning:</strong> A unit increase in X is associated with an average of b units increase in Y.
</dd>
</dl>

<p><strong>Equation:</strong> 

<math display="inline" id="Data_transformation_(statistics):1">
 <semantics>
  <mrow>
   <mrow>
    <mi>log</mi>
    <mrow>
     <mo stretchy="false">(</mo>
     <mi>Y</mi>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
   <mo>=</mo>
   <mrow>
    <mi>a</mi>
    <mo>+</mo>
    <mrow>
     <mi>b</mi>
     <mi>X</mi>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <log></log>
     <ci>Y</ci>
    </apply>
    <apply>
     <plus></plus>
     <ci>a</ci>
     <apply>
      <times></times>
      <ci>b</ci>
      <ci>X</ci>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \log(Y)=a+bX
  </annotation>
 </semantics>
</math>

     (From exponentiating both sides of the equation

<math display="block" id="Data_transformation_(statistics):2">
 <semantics>
  <mrow>
   <mi>Y</mi>
   <mo>=</mo>
   <mrow>
    <msup>
     <mi>e</mi>
     <mi>a</mi>
    </msup>
    <msup>
     <mi>e</mi>
     <mrow>
      <mi>b</mi>
      <mi>X</mi>
     </mrow>
    </msup>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <ci>Y</ci>
    <apply>
     <times></times>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <ci>e</ci>
      <ci>a</ci>
     </apply>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <ci>e</ci>
      <apply>
       <times></times>
       <ci>b</ci>
       <ci>X</ci>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   Y=e^{a}e^{bX}
  </annotation>
 </semantics>
</math>

)</p>
<dl>
<dd><strong>Meaning:</strong> A unit increase in X is associated with an average of 100b% increase in Y.
</dd>
</dl>

<p><strong>Equation:</strong> 

<math display="inline" id="Data_transformation_(statistics):3">
 <semantics>
  <mrow>
   <mi>Y</mi>
   <mo>=</mo>
   <mrow>
    <mi>a</mi>
    <mo>+</mo>
    <mrow>
     <mi>b</mi>
     <mrow>
      <mi>log</mi>
      <mrow>
       <mo stretchy="false">(</mo>
       <mi>X</mi>
       <mo stretchy="false">)</mo>
      </mrow>
     </mrow>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <ci>Y</ci>
    <apply>
     <plus></plus>
     <ci>a</ci>
     <apply>
      <times></times>
      <ci>b</ci>
      <apply>
       <log></log>
       <ci>X</ci>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   Y=a+b\log(X)
  </annotation>
 </semantics>
</math>

</p>
<dl>
<dd><strong>Meaning:</strong> A 1% increase in X is associated with an average b/100 units increase in Y.
</dd>
</dl>

<p><strong>Equation:</strong> 

<math display="inline" id="Data_transformation_(statistics):4">
 <semantics>
  <mrow>
   <mrow>
    <mi>log</mi>
    <mrow>
     <mo stretchy="false">(</mo>
     <mi>Y</mi>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
   <mo>=</mo>
   <mrow>
    <mi>a</mi>
    <mo>+</mo>
    <mrow>
     <mi>b</mi>
     <mrow>
      <mi>log</mi>
      <mrow>
       <mo stretchy="false">(</mo>
       <mi>X</mi>
       <mo stretchy="false">)</mo>
      </mrow>
     </mrow>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <log></log>
     <ci>Y</ci>
    </apply>
    <apply>
     <plus></plus>
     <ci>a</ci>
     <apply>
      <times></times>
      <ci>b</ci>
      <apply>
       <log></log>
       <ci>X</ci>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \log(Y)=a+b\log(X)
  </annotation>
 </semantics>
</math>

     (From exponentiating both sides of the equation

<math display="block" id="Data_transformation_(statistics):5">
 <semantics>
  <mrow>
   <mi>Y</mi>
   <mo>=</mo>
   <mrow>
    <msup>
     <mi>e</mi>
     <mi>a</mi>
    </msup>
    <msup>
     <mi>X</mi>
     <mi>b</mi>
    </msup>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <ci>Y</ci>
    <apply>
     <times></times>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <ci>e</ci>
      <ci>a</ci>
     </apply>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <ci>X</ci>
      <ci>b</ci>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   Y=e^{a}X^{b}
  </annotation>
 </semantics>
</math>

)</p>
<dl>
<dd><strong>Meaning:</strong> A 1% increase in X is associated with a b% increase in Y.
</dd>
</dl>
<h2 id="common-transformations">Common transformations</h2>

<p>The <a class="uri" href="logarithm" title="wikilink">logarithm</a> and <a href="square_root" title="wikilink">square root</a> transformations are commonly used for positive data, and the <a href="multiplicative_inverse" title="wikilink">multiplicative inverse</a> (reciprocal) transformation can be used for non-zero data. The <a href="power_transform" title="wikilink">power transformation</a> is a family of transformations parametrized by a non-negative value λ that includes the logarithm, square root, and multiplicative inverse as special cases. To approach data transformation systematically, it is possible to use <a href="estimation_theory" title="wikilink">statistical estimation</a> techniques to estimate the parameter λ in the power transformation, thereby identifying the transformation that is approximately the most appropriate in a given setting. Since the power transformation family also includes the identity transformation, this approach can also indicate whether it would be best to analyze the data without a transformation. In regression analysis, this approach is known as the <em>Box-Cox technique</em>.</p>

<p>The reciprocal and some power transformations can be meaningfully applied to data that include both positive and negative values (the power transformation is invertible over all real numbers if λ is an odd integer). However when both negative and positive values are observed, it is more common to begin by adding a constant to all values, producing a set of non-negative data to which any power transformation can be applied.</p>

<p>A common situation where a data transformation is applied is when a value of interest ranges over several <a href="order_of_magnitude" title="wikilink">orders of magnitude</a>. Many physical and social phenomena exhibit such behavior — incomes, species populations, galaxy sizes, and rainfall volumes, to name a few. Power transforms, and in particular the logarithm, can often be used to induce symmetry in such data. The logarithm is often favored because it is easy to interpret its result in terms of "fold changes."</p>

<p>The logarithm also has a useful effect on ratios. If we are comparing positive quantities <em>X</em> and <em>Y</em> using the ratio <em>X</em> / <em>Y</em>, then if <em>X</em>  <em>Y</em>, the ratio is in the half-line (1,∞), where the ratio of 1 corresponds to equality. In an analysis where <em>X</em> and <em>Y</em> are treated symmetrically, the log-ratio log(<em>X</em> / <em>Y</em>) is zero in the case of equality, and it has the property that if <em>X</em> is <em>K</em> times greater than <em>Y</em>, the log-ratio is the equidistant from zero as in the situation where <em>Y</em> is <em>K</em> times greater than <em>X</em> (the log-ratios are log(<em>K</em>) and −log(<em>K</em>) in these two situations).</p>

<p>If values are naturally restricted to be in the range 0 to 1, not including the end-points, then a <a href="logit" title="wikilink">logit transformation</a> may be appropriate: this yields values in the range (−∞,∞).</p>
<h2 id="transforming-to-normality">Transforming to normality</h2>

<p>It is not always necessary or desirable to transform a data set to resemble a normal distribution. However if symmetry or normality are desired, they can often be induced through one of the power transformations.</p>

<p>To assess whether normality has been achieved, a graphical approach is usually more informative than a formal statistical test. A <a href="Q-Q_plot" title="wikilink">normal quantile plot</a> is commonly used to assess the fit of a data set to a normal population. Alternatively, rules of thumb based on the sample <a class="uri" href="skewness" title="wikilink">skewness</a> and <a class="uri" href="kurtosis" title="wikilink">kurtosis</a> have also been proposed, such as having skewness in the range of −0.8 to 0.8 and kurtosis in the range of −3.0 to 3.0.</p>
<h2 id="transforming-to-a-uniform-distribution">Transforming to a uniform distribution</h2>

<p>If we observe a set of <em>n</em> values <em>X</em><sub>1</sub>, ..., <em>X</em><sub><em>n</em></sub> with no ties (i.e. there are <em>n</em> distinct values), we can replace <em>X</em><sub><em>i</em></sub> with the transformed value <em>Y</em><sub><em>i</em></sub> = <em>k</em>, where <em>k</em> is defined such that <em>X</em><sub><em>i</em></sub> is the <em>k</em><sup>th</sup> largest among all the <em>X</em> values. This is called the <em>rank transform</em>, and creates data with a perfect fit to a <a href="Uniform_distribution_(discrete)" title="wikilink">uniform distribution</a>. This approach has a <a href="statistical_population" title="wikilink">population</a> analogue. If <em>X</em> is any <a href="random_variable" title="wikilink">random variable</a>, and <em>F</em> is the <a href="cumulative_distribution_function" title="wikilink">cumulative distribution function</a> of <em>X</em>, then as long as <em>F</em> is invertible, the random variable <em>U</em> = F(<em>X</em>) follows a uniform distribution on the <a href="unit_interval" title="wikilink">unit interval</a> [0,1].</p>

<p>From a uniform distribution, we can transform to any distribution with an invertible cumulative distribution function. If <em>G</em> is an invertible cumulative distribution function, and <em>U</em> is a uniformly distributed random variable, then the random variable <em>G</em><sup>−1</sup>(<em>U</em>) has <em>G</em> as its cumulative distribution function.</p>
<h2 id="variance-stabilizing-transformations">Variance stabilizing transformations</h2>

<p>Many types of statistical data exhibit a "<a class="uri" href="variance" title="wikilink">variance</a>-on-mean relationship", meaning that the variability is different for data values with different <a href="expected_values" title="wikilink">expected values</a>. As an example, in comparing different populations in the world, the variance of income tends to increase with mean income. If we consider a number of small area units (e.g., counties in the United States) and obtain the mean and variance of incomes within each county, it is common that the counties with higher mean income also have higher variances.</p>

<p>A <a href="variance-stabilizing_transformation" title="wikilink">variance-stabilizing transformation</a> aims to remove a variance-on-mean relationship, so that the variance becomes constant relative to the mean. Examples of variance-stabilizing transformations are the <a href="Fisher_transformation" title="wikilink">Fisher transformation</a> for the sample correlation coefficient, the <a href="square_root" title="wikilink">square root</a> transformation or <a href="Anscombe_transformation" title="wikilink">Anscombe transformation</a> for <a href="Poisson_distribution" title="wikilink">Poisson</a> data (count data), the <a href="Box-Cox_transformation" title="wikilink">Box-Cox transformation</a> for regression analysis and the <a href="angular_transformation" title="wikilink">arcsine square root transformation or angular transformation</a> for proportions (<a class="uri" href="binomial" title="wikilink">binomial</a> data). While commonly used for statistical analysis of proportional data, the arcsine square root transformation is not recommended because <a href="logistic_regression" title="wikilink">logistic regression</a> or a <a href="logit_transformation" title="wikilink">logit transformation</a> are more appropriate for binomial or non-binomial proportions, respectively, especially due to decreased <a href="Type_I_and_type_II_errors" title="wikilink">type-II error</a>.<a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a></p>
<h2 id="transformations-for-multivariate-data">Transformations for multivariate data</h2>

<p>Univariate functions can be applied point-wise to multivariate data to modify their marginal distributions. It is also possible to modify some attributes of a multivariate distribution using an appropriately constructed transformation. For example, when working with <a href="time_series" title="wikilink">time series</a> and other types of sequential data, it is common to <a href="finite_difference" title="wikilink">difference</a> the data to improve <a href="stationary_process" title="wikilink">stationarity</a>. If data are observed as random vectors <em>X</em><sub>i</sub> with <a href="covariance_matrix" title="wikilink">covariance matrix</a> Σ, a <a href="linear_transformation" title="wikilink">linear transformation</a> can be used to decorrelate the data. To do this, use the <a href="Cholesky_decomposition" title="wikilink">Cholesky decomposition</a> to express Σ = <em>A</em> <em>A</em>'. Then the transformed vector <em>Y</em><sub>i</sub> = <em>A</em><sup>−1</sup><em>X</em><sub>i</sub> has the <a href="identity_matrix" title="wikilink">identity matrix</a> as its covariance matrix.</p>
<h2 id="see-also">See also</h2>
<ul>
<li><a class="uri" href="Logit" title="wikilink">Logit</a></li>
<li><a class="uri" href="Arcsin" title="wikilink">Arcsin</a> (transformation)</li>
</ul>
<h2 id="references">References</h2>
<h2 id="external-links">External links</h2>
<ul>
<li><a href="http://www.sportsci.org/resource/stats/logtrans.html">Log transformation</a></li>
<li><a href="http://www.bmj.com/cgi/content/full/312/7038/1079">Transformations, means, and confidence intervals</a></li>
<li><a href="http://www.r-statistics.com/2013/05/log-transformations-for-skewed-and-wide-distributions-from-practical-data-science-with-r/">Log Transformations for Skewed and Wide Distributions</a> - discussing the log and the "signed logarithm" transformations (A chapter from "Practical Data Science with R").</li>
</ul>

<p>"</p>

<p><a href="Category:Data_analysis" title="wikilink">Category:Data analysis</a> <a class="uri" href="Category:Transforms" title="wikilink">Category:Transforms</a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1"><a href="#fnref1">↩</a></li>
</ol>
</section>
</body>
</html>
