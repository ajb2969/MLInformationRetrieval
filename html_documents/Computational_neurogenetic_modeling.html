<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="64">Computational neurogenetic modeling</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>Computational neurogenetic modeling</h1>
<hr/>

<p><strong>Computational neurogenetic modeling (CNGM)</strong> is concerned with the study and development of dynamic <a href="neuronal_modeling" title="wikilink">neuronal models</a> for modeling brain functions with respect to <a href="gene" title="wikilink">genes</a> and dynamic interactions between genes. These include <a href="neural_network_models" title="wikilink">neural network models</a> and their integration with gene network models. This area brings together knowledge from various scientific disciplines, such as <a href="computer_science" title="wikilink">computer</a> and <a href="information_science" title="wikilink">information science</a>, <a class="uri" href="neuroscience" title="wikilink">neuroscience</a> and <a href="cognitive_science" title="wikilink">cognitive science</a>, <a class="uri" href="genetics" title="wikilink">genetics</a> and <a href="molecular_biology" title="wikilink">molecular biology</a>, as well as <a class="uri" href="engineering" title="wikilink">engineering</a>.</p>
<h2 id="levels-of-processing">Levels of processing</h2>
<h3 id="molecular-kinetics">Molecular kinetics</h3>

<p>Models of the <a href="Chemical_kinetics" title="wikilink">kinetics</a> of proteins and <a href="ion_channels" title="wikilink">ion channels</a> associated with <a class="uri" href="neuron" title="wikilink">neuron</a> activity represent the lowest level of modeling in a computational neurogenetic model. The altered activity of proteins in some diseases, such as the <a href="amyloid_beta" title="wikilink">amyloid beta</a> protein in <a href="Alzheimer's_disease" title="wikilink">Alzheimer's disease</a>, must be modeled at the molecular level to accurately predict the effect on cognition.<a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a> Ion channels, which are vital to the propagation of <a href="action_potentials" title="wikilink">action potentials</a>, are another molecule that may be modeled to more accurately reflect biological processes. For instance, to accurately model <a href="synaptic_plasticity" title="wikilink">synaptic plasticity</a> (the strengthening or weakening of <a href="synapse" title="wikilink">synapses</a>) and memory, it is necessary to model the activity of the <a href="NMDA_receptor" title="wikilink">NMDA receptor</a> (NMDAR). The speed at which the NMDA receptor lets Calcium ions into the cell in response to <a class="uri" href="Glutamate" title="wikilink">Glutamate</a> is an important determinant of <a href="Long-term_potentiation" title="wikilink">Long-term potentiation</a> via the insertion of <a href="AMPA_receptor" title="wikilink">AMPA receptors</a> (AMPAR) into the <a href="plasma_membrane" title="wikilink">plasma membrane</a> at the synapse of the postsynaptic cell (the cell that receives the neurotransmitters from the presynaptic cell).<a class="footnoteRef" href="#fn2" id="fnref2"><sup>2</sup></a></p>
<h3 id="genetic-regulatory-network">Genetic regulatory network</h3>

<p> In most models of neural systems neurons are the most basic unit modeled.<a class="footnoteRef" href="#fn3" id="fnref3"><sup>3</sup></a> In computational neurogenetic modeling, to better simulate processes that are responsible for synaptic activity and connectivity, the genes responsible are modeled for each <a class="uri" href="neuron" title="wikilink">neuron</a>.</p>

<p>A <a href="gene_regulatory_network" title="wikilink">gene regulatory network</a>, protein regulatory network, or gene/protein regulatory network, is the level of processing in a computational neurogenetic model that models the interactions of <a href="gene" title="wikilink">genes</a> and proteins relevant to synaptic activity and general cell functions. Genes and proteins are modeled as individual <a href="Node_(graph_theory)" title="wikilink">nodes</a>, and the interactions that influence a gene are modeled as excitatory (increases gene/protein expression) or inhibitory (decreases gene/protein expression) inputs that are weighted to reflect the effect a gene or protein is having on another gene or protein. Gene regulatory networks are typically designed using data from <a href="DNA_microarrays" title="wikilink">microarrays</a>.<a class="footnoteRef" href="#fn4" id="fnref4"><sup>4</sup></a></p>

<p>Modeling of genes and proteins allows individual responses of neurons in an artificial neural network that mimic responses in biological nervous systems, such as division (adding new neurons to the artificial neural network), creation of proteins to expand their cell membrane and foster <a class="uri" href="neurite" title="wikilink">neurite</a> outgrowth (and thus stronger connections with other neurons), up-regulate or down-regulate receptors at synapses (increasing or decreasing the weight (strength) of synaptic inputs), uptake more <a class="uri" href="neurotransmitters" title="wikilink">neurotransmitters</a>, change into different types of neurons, or die due to <a class="uri" href="necrosis" title="wikilink">necrosis</a> or <a class="uri" href="apoptosis" title="wikilink">apoptosis</a>. The creation and analysis of these networks can be divided into two sub-areas of research: the gene up-regulation that is involved in the normal functions of a neuron, such as growth, metabolism, and synapsing; and the effects of mutated genes on neurons and cognitive functions.<a class="footnoteRef" href="#fn5" id="fnref5"><sup>5</sup></a></p>
<h3 id="artificial-neural-network">Artificial neural network</h3>

<p> An <a href="artificial_neural_network" title="wikilink">artificial neural network</a> generally refers to any computational model that mimics the <a href="central_nervous_system" title="wikilink">central nervous system</a>, with capabilities such as learning and pattern recognition. With regards to computational neurogenetic modeling, however, it is often used to refer to those specifically designed for biological accuracy rather than computational efficiency. Individual neurons are the basic unit of an artificial neural network, with each neuron acting as a node. Each node receives weighted signals from other nodes that are either <a href="excitatory_postsynaptic_potential" title="wikilink">excitatory</a> or <a href="Inhibitory_postsynaptic_potential" title="wikilink">inhibitory</a>. To determine the output, a <a href="transfer_function" title="wikilink">transfer function</a> (or <a href="activation_function" title="wikilink">activation function</a>) evaluates the sum of the weighted signals and, in some artificial neural networks, their input rate. Signal weights are strengthened (<a href="long-term_potentiation" title="wikilink">long-term potentiation</a>) or weakened (<a href="long-term_depression" title="wikilink">long-term depression</a>) depending on how synchronous the presynaptic and postsynaptic activation rates are (<a href="Hebbian_theory" title="wikilink">Hebbian theory</a>).<a class="footnoteRef" href="#fn6" id="fnref6"><sup>6</sup></a></p>

<p>The synaptic activity of individual neurons is modeled using equations to determine the temporal (and in some cases, spatial) summation of synaptic signals, <a href="membrane_potential" title="wikilink">membrane potential</a>, threshold for action potential generation, the absolute and relative <a href="Refractory_period_(physiology)" title="wikilink">refractory period</a>, and optionally ion receptor channel <a href="Chemical_kinetics" title="wikilink">kinetics</a> and <a href="Gaussian_noise" title="wikilink">Gaussian noise</a> (to increase biological accuracy by incorporation of random elements). In addition to connectivity, some types of artificial neural networks, such as <a href="spiking_neural_network" title="wikilink">spiking neural networks</a>, also model the distance between neurons, and its effect on the synaptic weight (the strength of a synaptic transmission).<a class="footnoteRef" href="#fn7" id="fnref7"><sup>7</sup></a></p>
<h3 id="combining-gene-regulatory-networks-and-artificial-neural-networks">Combining gene regulatory networks and artificial neural networks</h3>

<p>For the parameters in the gene regulatory network to affect the neurons in the artificial neural network as intended there must be some connection between them. In an organizational context, each node (neuron) in the artificial neural network has its own gene regulatory network associated with it. The weights (and in some networks, frequencies of synaptic transmission to the node), and the resulting membrane potential of the node (including whether an <a href="action_potential" title="wikilink">action potential</a> is produced or not), affect the expression of different genes in the gene regulatory network. Factors affecting connections between neurons, such as <a href="synaptic_plasticity" title="wikilink">synaptic plasticity</a>, can be modeled by inputting the values of synaptic activity-associated genes and proteins to a function that re-evaluates the weight of an input from a particular neuron in the artificial neural network.</p>
<h3 id="incorporation-of-other-cell-types">Incorporation of other cell types</h3>

<p>Other cell types besides neurons can be modeled as well. <a href="Glial_cells" title="wikilink">Glial cells</a>, such as <a class="uri" href="astroglia" title="wikilink">astroglia</a> and <a class="uri" href="microglia" title="wikilink">microglia</a>, as well as <a href="endothelial_cells" title="wikilink">endothelial cells</a>, could be included in an artificial neural network. This would enable modeling of diseases where pathological effects may occur from sources other than neurons, such as Alzheimer's disease.<a class="footnoteRef" href="#fn8" id="fnref8"><sup>8</sup></a></p>
<h2 id="factors-affecting-choice-of-artificial-neural-network">Factors affecting choice of artificial neural network</h2>

<p>While the term artificial neural network is usually used in computational neurogenetic modeling to refer to models of the central nervous system meant to possess biological accuracy, the general use of the term can be applied to many gene regulatory networks as well.</p>
<h3 id="time-variance">Time variance</h3>

<p>Artificial neural networks, depending on type, may or may not take into account the timing of inputs. Those that do, such as <a href="spiking_neural_network" title="wikilink">spiking neural networks</a>, fire only when the pooled inputs reach a membrane potential is reached. Because this mimics the firing of biological neurons, spiking neural networks are viewed as a more biologically accurate model of synaptic activity.<a class="footnoteRef" href="#fn9" id="fnref9"><sup>9</sup></a></p>
<h3 id="growth-and-shrinkage">Growth and shrinkage</h3>

<p>To accurately model the central nervous system, creation and death of neurons should be modeled as well.<a class="footnoteRef" href="#fn10" id="fnref10"><sup>10</sup></a> To accomplish this, constructive artificial neural networks that are able to grow or shrink to adapt to inputs are often used. <a href="Evolving_classification_function" title="wikilink">Evolving connectionist systems</a> are a subtype of constructive artificial neural networks (<a href="Evolving_classification_function" title="wikilink">evolving</a> in this case referring to changing the structure of its neural network rather than <a href="Evolutionary_computation" title="wikilink">by mutation and natural selection</a>).<a class="footnoteRef" href="#fn11" id="fnref11"><sup>11</sup></a></p>
<h3 id="randomness">Randomness</h3>

<p>Both synaptic transmission and gene-protein interactions are <a href="Stochastic_process" title="wikilink">stochastic</a> in nature. To model biological nervous systems with greater fidelity some form of randomness is often introduced into the network. Artificial neural networks modified in this manner are often labeled as probabilistic versions of their neural network sub-type (e.g., p<a href="spiking_neural_network" title="wikilink">SNN</a>).<a class="footnoteRef" href="#fn12" id="fnref12"><sup>12</sup></a></p>
<h3 id="incorporation-of-fuzzy-logic">Incorporation of fuzzy logic</h3>

<p><a href="Fuzzy_logic" title="wikilink">Fuzzy logic</a> is a system of reasoning that enables an artificial neural network to deal in non-<a href="Binary_data" title="wikilink">binary</a> and linguistic variables. Biological data is often unable to be processed using <a href="Boolean_logic" title="wikilink">Boolean logic</a>, and moreover accurate modeling of the capabilities of biological nervous systems requires fuzzy logic. Therefore, artificial neural networks that incorporate it, such as <a href="Evolving_classification_function" title="wikilink">evolving fuzzy neural networks (EFuNN) or Dynamic Evolving Neural-Fuzzy Inference Systems (DENFIS)</a>, are often used in computational neurogenetic modeling. The use of fuzzy logic is especially relevant in gene regulatory networks, as the modeling of protein binding strength often requires non-binary variables.<a class="footnoteRef" href="#fn13" id="fnref13"><sup>13</sup></a><a class="footnoteRef" href="#fn14" id="fnref14"><sup>14</sup></a></p>
<h3 id="types-of-learning">Types of learning</h3>

<p>Artificial Neural Networks designed to simulate of the human brain require an ability to learn a variety of tasks that is not required by those designed to accomplish a specific task. <a href="Supervised_learning" title="wikilink">Supervised learning</a> is a mechanism by which an artificial neural network can learn by receiving a number of inputs with a correct output already known. An example of an artificial neural network that uses supervised learning is a <a href="multilayer_perceptron" title="wikilink">multilayer perceptron</a> (MLP). In <a href="unsupervised_learning" title="wikilink">unsupervised learning</a>, an artificial neural network is trained using only inputs. Unsupervised learning is the learning mechanism by which a type of artificial neural network known as a <a href="self-organizing_map" title="wikilink">self-organizing map</a> (SOM) learns. Some types of artificial neural network, such as evolving connectionist systems, can learn in both a supervised and unsupervised manner.<a class="footnoteRef" href="#fn15" id="fnref15"><sup>15</sup></a></p>
<h2 id="improvement">Improvement</h2>

<p>Both gene regulatory networks and artificial neural networks have two main strategies for improving their accuracy. In both cases the output of the network is measured against known biological data using some function, and subsequent improvements are made by altering the structure of the network. A common test of accuracy for artificial neural networks is to compare some parameter of the model to data acquired from biological neural systems, such as from an <a class="uri" href="EEG" title="wikilink">EEG</a>.<a class="footnoteRef" href="#fn16" id="fnref16"><sup>16</sup></a> In the case of EEG recordings, the <a href="local_field_potential" title="wikilink">local field potential</a> (LFP) of the artificial neural network is taken and compared to EEG data acquired from human patients. The <a href="relative_intensity_ratios" title="wikilink">relative intensity ratio</a> (RIRs) and <a href="fast_Fourier_transform" title="wikilink">fast Fourier transform</a> (FFT) of the EEG are compared with those generated by the artificial neural networks to determine the accuracy of the model.<a class="footnoteRef" href="#fn17" id="fnref17"><sup>17</sup></a></p>
<h3 id="genetic-algorithm">Genetic algorithm</h3>

<p><embed src="A-Numerical-Approach-to-Ion-Channel-Modelling-Using-Whole-Cell-Voltage-Clamp-Recordings-and-a-pcbi.0030169.sv001.ogv" title="fig:An example of a model being refined through successive generations, using a genetic algorithm, to match experimental data."></embed> Because the amount of data on the interplay of genes and neurons and their effects is not enough to construct a rigorous model, <a href="evolutionary_computation" title="wikilink">evolutionary computation</a> is used to optimize artificial neural networks and gene regulatory networks, a common technique being the <a href="genetic_algorithm" title="wikilink">genetic algorithm</a>. A genetic algorithm is a process that can be used to refine models by mimicking the process of natural selection observed in biological ecosystems. The primary advantages are that, due to not requiring derivative information, it can be applied to <a href="black_box" title="wikilink">black box</a> problems and <a href="Evolutionary_multimodal_optimization" title="wikilink">multimodal optimization</a>. The typical process for using genetic algorithms to refine a gene regulatory network is: first, create a population; next, to create offspring via a crossover operation and evaluate their fitness; then, on a group chosen for high fitness, simulate mutation via a mutation operator; finally, taking the now mutated group, repeat this process until a desired level of fitness is demonstrated. <a class="footnoteRef" href="#fn18" id="fnref18"><sup>18</sup></a></p>
<h3 id="evolving-systems">Evolving systems</h3>

<p>Methods by which artificial neural networks may alter their structure without simulated mutation and fitness selection have been developed. A <a href="Evolving_classification_function" title="wikilink">dynamically evolving neural network</a> is one approach, as the creation of new connections and new neurons can be modeled as the system adapts to new data. This enables the network to evolve in modeling accuracy without simulated natural selection. One method by which dynamically evolving networks may be optimized, called evolving layer neuron aggregation, combines neurons with sufficiently similar input weights into one neuron. This can take place during the training of the network, referred to as online aggregation, or between periods of training, referred to as offline aggregation. Experiments have suggested that offline aggregation is more efficient.<a class="footnoteRef" href="#fn19" id="fnref19"><sup>19</sup></a></p>
<h2 id="potential-applications">Potential applications</h2>

<p>A variety of potential applications have been suggested for accurate computational neurogenetic models, such as simulating genetic diseases, examining the impact of potential treatments,<a class="footnoteRef" href="#fn20" id="fnref20"><sup>20</sup></a> better understanding of learning and cognition,<a class="footnoteRef" href="#fn21" id="fnref21"><sup>21</sup></a> and development of hardware able to interface with neurons.<a class="footnoteRef" href="#fn22" id="fnref22"><sup>22</sup></a></p>

<p>The simulation of disease states is of particular interest, as modeling both the neurons and their genes and proteins allows linking genetic mutations and protein abnormalities to pathological effects in the central nervous system. Among those diseases suggested as being possible targets of computational neurogenetic modeling based analysis are epilepsy, schizophrenia, mental retardation, brain aging and Alzheimer's disease, and Parkinson's disease.<a class="footnoteRef" href="#fn23" id="fnref23"><sup>23</sup></a></p>
<h2 id="see-also">See also</h2>
<ul>
<li><a class="uri" href="Memristor" title="wikilink">Memristor</a></li>
</ul>
<h2 id="references">References</h2>
<h2 id="external-links">External links</h2>
<ul>
<li><a class="uri" href="http://ecos.watts.net.nz/Algorithms/">http://ecos.watts.net.nz/Algorithms/</a></li>
</ul>

<p>"</p>

<p><a href="Category:Cognitive_science" title="wikilink">Category:Cognitive science</a> <a href="Category:Artificial_neural_networks" title="wikilink">Category:Artificial neural networks</a> <a href="Category:Articles_containing_video_clips" title="wikilink">Category:Articles containing video clips</a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1"><a href="#fnref1">↩</a></li>
<li id="fn2"></li>
<li id="fn3"></li>
<li id="fn4"></li>
<li id="fn5"><a href="#fnref5">↩</a></li>
<li id="fn6"></li>
<li id="fn7"></li>
<li id="fn8"></li>
<li id="fn9"></li>
<li id="fn10"></li>
<li id="fn11"></li>
<li id="fn12"><a href="#fnref12">↩</a></li>
<li id="fn13"></li>
<li id="fn14"><a href="#fnref14">↩</a></li>
<li id="fn15"></li>
<li id="fn16"><a href="#fnref16">↩</a></li>
<li id="fn17"><a href="#fnref17">↩</a></li>
<li id="fn18"><a href="#fnref18">↩</a></li>
<li id="fn19"></li>
<li id="fn20"><a href="#fnref20">↩</a></li>
<li id="fn21"><a href="#fnref21">↩</a></li>
<li id="fn22"><a href="#fnref22">↩</a></li>
<li id="fn23"><a href="#fnref23">↩</a></li>
</ol>
</section>
</body>
</html>
