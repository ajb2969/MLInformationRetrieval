<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="1007">Jensen–Shannon divergence</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>Jensen–Shannon divergence</h1>
<hr>In [[probability theory]] and [[statistics]], the '''[[Johan Jensen (mathematician)|Jensen]]–[[Claude Shannon|Shannon]] divergence''' is a popular method of measuring the similarity between two [[probability distribution]]s.  It is also known as '''information radius''' ('''IRad''')<ref>{{cite book |author=Hinrich Schütze; Christopher D. Manning|title=Foundations of Statistical Natural Language Processing |publisher=MIT Press |location=Cambridge, Mass |year=1999 |isbn=0-262-13360-1 |url=http://nlp.stanford.edu/fsnlp/ |doi= |page=304}}</ref> or '''total divergence to the average'''.<ref>{{cite journal|title=Similarity-Based Methods For Word Sense Disambiguation|journal=Proceedings of the Thirty-Fifth Annual Meeting of the Association for Computational Linguistics and Eighth Conference of the European Chapter of the Association for Computational Linguistics|year=1997|first=Ido|last=Dagan|author2=Lillian Lee |author3=Fernando Pere

<p>ira |volume=|issue=|pages=pp. 56–63|id= |url=<a class="uri" href="http://citeseer.ist.psu.edu/dagan97similaritybased.html|accessdate=2008-03-09|doi=10.3115/979617.979625">http://citeseer.ist.psu.edu/dagan97similaritybased.html|accessdate=2008-03-09|doi=10.3115/979617.979625</a> }} It is based on the <a href="Kullback–Leibler_divergence" title="wikilink">Kullback–Leibler divergence</a>, with some notable (and useful) differences, including that it is symmetric and it is always a finite value. The square root of the Jensen–Shannon divergence is a <a href="Metric_(mathematics)" title="wikilink">metric</a> often referred to as Jensen-Shannon distance.<a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a><a class="footnoteRef" href="#fn2" id="fnref2"><sup>2</sup></a></p>
<h2 id="definition">Definition</h2>

<p>Consider the set 

<math display="inline" id="Jensen–Shannon_divergence:0">
<semantics>
<mrow>
<msubsup>
<mi>M</mi>
<mo>+</mo>
<mn>1</mn>
</msubsup>
<mrow>
<mo stretchy="false">(</mo>
<mi>A</mi>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<times></times>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>M</ci>
<plus></plus>
</apply>
<cn type="integer">1</cn>
</apply>
<ci>A</ci>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   M_{+}^{1}(A)
  </annotation>
</semantics>
</math>

 of probability distributions where A is a set provided with some <a href="Sigma-algebra" title="wikilink">σ-algebra</a> of measurable subsets. In particular we can take A to be a finite or countable set with all subsets being measurable.</p>

<p>The Jensen–Shannon divergence (JSD) 

<math display="inline" id="Jensen–Shannon_divergence:1">
<semantics>
<mrow>
<mrow>
<mrow>
<mrow>
<msubsup>
<mi>M</mi>
<mo>+</mo>
<mn>1</mn>
</msubsup>
<mrow>
<mo stretchy="false">(</mo>
<mi>A</mi>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
<mo>×</mo>
<msubsup>
<mi>M</mi>
<mo>+</mo>
<mn>1</mn>
</msubsup>
</mrow>
<mrow>
<mo stretchy="false">(</mo>
<mi>A</mi>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
<mo>→</mo>
<mrow>
<mo stretchy="false">[</mo>
<mn>0</mn>
<mo>,</mo>
<mi mathvariant="normal">∞</mi>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<ci>normal-→</ci>
<apply>
<times></times>
<apply>
<times></times>
<apply>
<times></times>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>M</ci>
<plus></plus>
</apply>
<cn type="integer">1</cn>
</apply>
<ci>A</ci>
</apply>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>M</ci>
<plus></plus>
</apply>
<cn type="integer">1</cn>
</apply>
</apply>
<ci>A</ci>
</apply>
<interval closure="closed-open">
<cn type="integer">0</cn>
<infinity></infinity>
</interval>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   M_{+}^{1}(A)\times M_{+}^{1}(A)\rightarrow[0,\infty{})
  </annotation>
</semantics>
</math>

 is a symmetrized and smoothed version of the <a href="Kullback–Leibler_divergence" title="wikilink">Kullback–Leibler divergence</a>
<math display="inline" id="Jensen–Shannon_divergence:2">
<semantics>
<mrow>
<mi>D</mi>
<mrow>
<mo stretchy="false">(</mo>
<mi>P</mi>
<mo>∥</mo>
<mi>Q</mi>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
<annotation-xml encoding="MathML-Content">
<cerror>
<csymbol cd="ambiguous">fragments</csymbol>
<csymbol cd="unknown">D</csymbol>
<cerror>
<csymbol cd="ambiguous">fragments</csymbol>
<ci>normal-(</ci>
<csymbol cd="unknown">P</csymbol>
<csymbol cd="latexml">parallel-to</csymbol>
<csymbol cd="unknown">Q</csymbol>
<ci>normal-)</ci>
</cerror>
</cerror>
</annotation-xml>
<annotation encoding="application/x-tex">
   D(P\parallel Q)
  </annotation>
</semantics>
</math>

. It is defined by</p>

<p>
<math display="block" id="Jensen–Shannon_divergence:3">
<semantics>
<mrow>
<mi>JSD</mi>
<mrow>
<mo stretchy="false">(</mo>
<mi>P</mi>
<mo>∥</mo>
<mi>Q</mi>
<mo stretchy="false">)</mo>
</mrow>
<mo>=</mo>
<mfrac>
<mn>1</mn>
<mn>2</mn>
</mfrac>
<mi>D</mi>
<mrow>
<mo stretchy="false">(</mo>
<mi>P</mi>
<mo>∥</mo>
<mi>M</mi>
<mo stretchy="false">)</mo>
</mrow>
<mo>+</mo>
<mfrac>
<mn>1</mn>
<mn>2</mn>
</mfrac>
<mi>D</mi>
<mrow>
<mo stretchy="false">(</mo>
<mi>Q</mi>
<mo>∥</mo>
<mi>M</mi>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
<annotation-xml encoding="MathML-Content">
<cerror>
<csymbol cd="ambiguous">fragments</csymbol>
<csymbol cd="unknown">JSD</csymbol>
<cerror>
<csymbol cd="ambiguous">fragments</csymbol>
<ci>normal-(</ci>
<csymbol cd="unknown">P</csymbol>
<csymbol cd="latexml">parallel-to</csymbol>
<csymbol cd="unknown">Q</csymbol>
<ci>normal-)</ci>
</cerror>
<eq></eq>
<apply>
<divide></divide>
<cn type="integer">1</cn>
<cn type="integer">2</cn>
</apply>
<csymbol cd="unknown">D</csymbol>
<cerror>
<csymbol cd="ambiguous">fragments</csymbol>
<ci>normal-(</ci>
<csymbol cd="unknown">P</csymbol>
<csymbol cd="latexml">parallel-to</csymbol>
<csymbol cd="unknown">M</csymbol>
<ci>normal-)</ci>
</cerror>
<plus></plus>
<apply>
<divide></divide>
<cn type="integer">1</cn>
<cn type="integer">2</cn>
</apply>
<csymbol cd="unknown">D</csymbol>
<cerror>
<csymbol cd="ambiguous">fragments</csymbol>
<ci>normal-(</ci>
<csymbol cd="unknown">Q</csymbol>
<csymbol cd="latexml">parallel-to</csymbol>
<csymbol cd="unknown">M</csymbol>
<ci>normal-)</ci>
</cerror>
</cerror>
</annotation-xml>
<annotation encoding="application/x-tex">
   {\rm JSD}(P\parallel Q)=\frac{1}{2}D(P\parallel M)+\frac{1}{2}D(Q\parallel M)
  </annotation>
</semantics>
</math>
</p>

<p>where 

<math display="inline" id="Jensen–Shannon_divergence:4">
<semantics>
<mrow>
<mi>M</mi>
<mo>=</mo>
<mrow>
<mfrac>
<mn>1</mn>
<mn>2</mn>
</mfrac>
<mrow>
<mo stretchy="false">(</mo>
<mrow>
<mi>P</mi>
<mo>+</mo>
<mi>Q</mi>
</mrow>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<eq></eq>
<ci>M</ci>
<apply>
<times></times>
<apply>
<divide></divide>
<cn type="integer">1</cn>
<cn type="integer">2</cn>
</apply>
<apply>
<plus></plus>
<ci>P</ci>
<ci>Q</ci>
</apply>
</apply>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   M=\frac{1}{2}(P+Q)
  </annotation>
</semantics>
</math>
</p>

<p>A more general definition, allowing for the comparison of more than two probability distributions, is:</p>

<p>
<math display="block" id="Jensen–Shannon_divergence:5">
<semantics>
<mrow>
<mrow>
<msub>
<mi>JSD</mi>
<mrow>
<msub>
<mi>π</mi>
<mn>1</mn>
</msub>
<mo>,</mo>
<mi mathvariant="normal">…</mi>
<mo>,</mo>
<msub>
<mi>π</mi>
<mi>n</mi>
</msub>
</mrow>
</msub>
<mrow>
<mo stretchy="false">(</mo>
<msub>
<mi>P</mi>
<mn>1</mn>
</msub>
<mo>,</mo>
<msub>
<mi>P</mi>
<mn>2</mn>
</msub>
<mo>,</mo>
<mi mathvariant="normal">…</mi>
<mo>,</mo>
<msub>
<mi>P</mi>
<mi>n</mi>
</msub>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
<mo>=</mo>
<mrow>
<mrow>
<mi>H</mi>
<mrow>
<mo>(</mo>
<mrow>
<munderover>
<mo largeop="true" movablelimits="false" symmetric="true">∑</mo>
<mrow>
<mi>i</mi>
<mo>=</mo>
<mn>1</mn>
</mrow>
<mi>n</mi>
</munderover>
<mrow>
<msub>
<mi>π</mi>
<mi>i</mi>
</msub>
<msub>
<mi>P</mi>
<mi>i</mi>
</msub>
</mrow>
</mrow>
<mo>)</mo>
</mrow>
</mrow>
<mo>-</mo>
<mrow>
<munderover>
<mo largeop="true" movablelimits="false" symmetric="true">∑</mo>
<mrow>
<mi>i</mi>
<mo>=</mo>
<mn>1</mn>
</mrow>
<mi>n</mi>
</munderover>
<mrow>
<msub>
<mi>π</mi>
<mi>i</mi>
</msub>
<mi>H</mi>
<mrow>
<mo stretchy="false">(</mo>
<msub>
<mi>P</mi>
<mi>i</mi>
</msub>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
</mrow>
</mrow>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<eq></eq>
<apply>
<times></times>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>JSD</ci>
<list>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>π</ci>
<cn type="integer">1</cn>
</apply>
<ci>normal-…</ci>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>π</ci>
<ci>n</ci>
</apply>
</list>
</apply>
<vector>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>P</ci>
<cn type="integer">1</cn>
</apply>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>P</ci>
<cn type="integer">2</cn>
</apply>
<ci>normal-…</ci>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>P</ci>
<ci>n</ci>
</apply>
</vector>
</apply>
<apply>
<minus></minus>
<apply>
<times></times>
<ci>H</ci>
<apply>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<sum></sum>
<apply>
<eq></eq>
<ci>i</ci>
<cn type="integer">1</cn>
</apply>
</apply>
<ci>n</ci>
</apply>
<apply>
<times></times>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>π</ci>
<ci>i</ci>
</apply>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>P</ci>
<ci>i</ci>
</apply>
</apply>
</apply>
</apply>
<apply>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<sum></sum>
<apply>
<eq></eq>
<ci>i</ci>
<cn type="integer">1</cn>
</apply>
</apply>
<ci>n</ci>
</apply>
<apply>
<times></times>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>π</ci>
<ci>i</ci>
</apply>
<ci>H</ci>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>P</ci>
<ci>i</ci>
</apply>
</apply>
</apply>
</apply>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   {\rm JSD}_{\pi_{1},\ldots,\pi_{n}}(P_{1},P_{2},\ldots,P_{n})=H\left(\sum_{i=1}%
^{n}\pi_{i}P_{i}\right)-\sum_{i=1}^{n}\pi_{i}H(P_{i})
  </annotation>
</semantics>
</math>
</p>

<p>where 

<math display="inline" id="Jensen–Shannon_divergence:6">
<semantics>
<mrow>
<msub>
<mi>π</mi>
<mn>1</mn>
</msub>
<mo>,</mo>
<mi mathvariant="normal">…</mi>
<mo>,</mo>
<msub>
<mi>π</mi>
<mi>n</mi>
</msub>
</mrow>
<annotation-xml encoding="MathML-Content">
<list>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>π</ci>
<cn type="integer">1</cn>
</apply>
<ci>normal-…</ci>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>π</ci>
<ci>n</ci>
</apply>
</list>
</annotation-xml>
<annotation encoding="application/x-tex">
   \pi_{1},\ldots,\pi_{n}
  </annotation>
</semantics>
</math>

 are weights that are selected for the probability distributions 

<math display="inline" id="Jensen–Shannon_divergence:7">
<semantics>
<mrow>
<msub>
<mi>P</mi>
<mn>1</mn>
</msub>
<mo>,</mo>
<msub>
<mi>P</mi>
<mn>2</mn>
</msub>
<mo>,</mo>
<mi mathvariant="normal">…</mi>
<mo>,</mo>
<msub>
<mi>P</mi>
<mi>n</mi>
</msub>
</mrow>
<annotation-xml encoding="MathML-Content">
<list>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>P</ci>
<cn type="integer">1</cn>
</apply>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>P</ci>
<cn type="integer">2</cn>
</apply>
<ci>normal-…</ci>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>P</ci>
<ci>n</ci>
</apply>
</list>
</annotation-xml>
<annotation encoding="application/x-tex">
   P_{1},P_{2},\ldots,P_{n}
  </annotation>
</semantics>
</math>

 and 

<math display="inline" id="Jensen–Shannon_divergence:8">
<semantics>
<mrow>
<mi>H</mi>
<mrow>
<mo stretchy="false">(</mo>
<mi>P</mi>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<times></times>
<ci>H</ci>
<ci>P</ci>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   H(P)
  </annotation>
</semantics>
</math>


 is the <a href="Shannon_entropy" title="wikilink">Shannon entropy</a> for distribution 

<math display="inline" id="Jensen–Shannon_divergence:9">
<semantics>
<mi>P</mi>
<annotation-xml encoding="MathML-Content">
<ci>P</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   P
  </annotation>
</semantics>
</math>

. For the two-distribution case described above,</p>

<p>
<math display="block" id="Jensen–Shannon_divergence:10">
<semantics>
<mrow>
<mrow>
<mrow>
<msub>
<mi>P</mi>
<mn>1</mn>
</msub>
<mo>=</mo>
<mi>P</mi>
</mrow>
<mo>,</mo>
<mrow>
<mrow>
<msub>
<mi>P</mi>
<mn>2</mn>
</msub>
<mo>=</mo>
<mi>Q</mi>
</mrow>
<mo>,</mo>
<mrow>
<msub>
<mi>π</mi>
<mn>1</mn>
</msub>
<mo>=</mo>
<msub>
<mi>π</mi>
<mn>2</mn>
</msub>
<mo>=</mo>
<mfrac>
<mn>1</mn>
<mn>2</mn>
</mfrac>
</mrow>
</mrow>
</mrow>
<mo>.</mo>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<csymbol cd="ambiguous">formulae-sequence</csymbol>
<apply>
<eq></eq>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>P</ci>
<cn type="integer">1</cn>
</apply>
<ci>P</ci>
</apply>
<apply>
<csymbol cd="ambiguous">formulae-sequence</csymbol>
<apply>
<eq></eq>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>P</ci>
<cn type="integer">2</cn>
</apply>
<ci>Q</ci>
</apply>
<apply>
<and></and>
<apply>
<eq></eq>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>π</ci>
<cn type="integer">1</cn>
</apply>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>π</ci>
<cn type="integer">2</cn>
</apply>
</apply>
<apply>
<eq></eq>
<share href="#.cmml">
</share>
<apply>
<divide></divide>
<cn type="integer">1</cn>
<cn type="integer">2</cn>
</apply>
</apply>
</apply>
</apply>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   P_{1}=P,P_{2}=Q,\pi_{1}=\pi_{2}=\frac{1}{2}.
  </annotation>
</semantics>
</math>
</p>
<h2 id="bounds">Bounds</h2>

<p>The Jensen–Shannon divergence is bounded by 1, given that one uses the base 2 logarithm.<a class="footnoteRef" href="#fn3" id="fnref3"><sup>3</sup></a></p>

<p>
<math display="block" id="Jensen–Shannon_divergence:11">
<semantics>
<mrow>
<mn>0</mn>
<mo>≤</mo>
<mi>JSD</mi>
<mrow>
<mo stretchy="false">(</mo>
<mi>P</mi>
<mo>∥</mo>
<mi>Q</mi>
<mo stretchy="false">)</mo>
</mrow>
<mo>≤</mo>
<mn>1</mn>
</mrow>
<annotation-xml encoding="MathML-Content">
<cerror>
<csymbol cd="ambiguous">fragments</csymbol>
<cn type="integer">0</cn>
<leq></leq>
<csymbol cd="unknown">JSD</csymbol>
<cerror>
<csymbol cd="ambiguous">fragments</csymbol>
<ci>normal-(</ci>
<csymbol cd="unknown">P</csymbol>
<csymbol cd="latexml">parallel-to</csymbol>
<csymbol cd="unknown">Q</csymbol>
<ci>normal-)</ci>
</cerror>
<leq></leq>
<cn type="integer">1</cn>
</cerror>
</annotation-xml>
<annotation encoding="application/x-tex">
   0\leq{\rm JSD}(P\parallel Q)\leq 1
  </annotation>
</semantics>
</math>
</p>

<p>For log base e, or ln, which is commonly used in statistical thermodynamics, the upper bound is ln(2):</p>

<p>
<math display="block" id="Jensen–Shannon_divergence:12">
<semantics>
<mrow>
<mn>0</mn>
<mo>≤</mo>
<mi>JSD</mi>
<mrow>
<mo stretchy="false">(</mo>
<mi>P</mi>
<mo>∥</mo>
<mi>Q</mi>
<mo stretchy="false">)</mo>
</mrow>
<mo>≤</mo>
<mi>ln</mi>
<mrow>
<mo stretchy="false">(</mo>
<mn>2</mn>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
<annotation-xml encoding="MathML-Content">
<cerror>
<csymbol cd="ambiguous">fragments</csymbol>
<cn type="integer">0</cn>
<leq></leq>
<csymbol cd="unknown">JSD</csymbol>
<cerror>
<csymbol cd="ambiguous">fragments</csymbol>
<ci>normal-(</ci>
<csymbol cd="unknown">P</csymbol>
<csymbol cd="latexml">parallel-to</csymbol>
<csymbol cd="unknown">Q</csymbol>
<ci>normal-)</ci>
</cerror>
<leq></leq>
<ln></ln>
<cerror>
<csymbol cd="ambiguous">fragments</csymbol>
<ci>normal-(</ci>
<cn type="integer">2</cn>
<ci>normal-)</ci>
</cerror>
</cerror>
</annotation-xml>
<annotation encoding="application/x-tex">
   0\leq{\rm JSD}(P\parallel Q)\leq\ln(2)
  </annotation>
</semantics>
</math>
</p>
<h2 id="relation-to-mutual-information">Relation to mutual information</h2>

<p>The Jensen–Shannon divergence is the <a href="mutual_information" title="wikilink">mutual information</a> between a random variable 

<math display="inline" id="Jensen–Shannon_divergence:13">
<semantics>
<mi>X</mi>
<annotation-xml encoding="MathML-Content">
<ci>X</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   X
  </annotation>
</semantics>
</math>


 associated to a <a href="mixture_distribution" title="wikilink">mixture distribution</a> between 

<math display="inline" id="Jensen–Shannon_divergence:14">
<semantics>
<mi>P</mi>
<annotation-xml encoding="MathML-Content">
<ci>P</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   P
  </annotation>
</semantics>
</math>

 and 

<math display="inline" id="Jensen–Shannon_divergence:15">
<semantics>
<mi>Q</mi>
<annotation-xml encoding="MathML-Content">
<ci>Q</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   Q
  </annotation>
</semantics>
</math>

 and the binary indicator variable 

<math display="inline" id="Jensen–Shannon_divergence:16">
<semantics>
<mi>Z</mi>
<annotation-xml encoding="MathML-Content">
<ci>Z</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   Z
  </annotation>
</semantics>
</math>

 that is used to switch between 

<math display="inline" id="Jensen–Shannon_divergence:17">
<semantics>
<mi>P</mi>
<annotation-xml encoding="MathML-Content">
<ci>P</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   P
  </annotation>
</semantics>
</math>

 and 

<math display="inline" id="Jensen–Shannon_divergence:18">
<semantics>
<mi>Q</mi>
<annotation-xml encoding="MathML-Content">
<ci>Q</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   Q
  </annotation>
</semantics>
</math>


 to produce the mixture. Let 

<math display="inline" id="Jensen–Shannon_divergence:19">
<semantics>
<mi>X</mi>
<annotation-xml encoding="MathML-Content">
<ci>X</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   X
  </annotation>
</semantics>
</math>

 be some abstract function on the underlying set of events that discriminates well between events, and choose the value of 

<math display="inline" id="Jensen–Shannon_divergence:20">
<semantics>
<mi>X</mi>
<annotation-xml encoding="MathML-Content">
<ci>X</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   X
  </annotation>
</semantics>
</math>

 according to 

<math display="inline" id="Jensen–Shannon_divergence:21">
<semantics>
<mi>P</mi>
<annotation-xml encoding="MathML-Content">
<ci>P</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   P
  </annotation>
</semantics>
</math>

 if 

<math display="inline" id="Jensen–Shannon_divergence:22">
<semantics>
<mrow>
<mi>Z</mi>
<mo>=</mo>
<mn>0</mn>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<eq></eq>
<ci>Z</ci>
<cn type="integer">0</cn>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   Z=0
  </annotation>
</semantics>
</math>

 and according to 

<math display="inline" id="Jensen–Shannon_divergence:23">
<semantics>
<mi>Q</mi>
<annotation-xml encoding="MathML-Content">
<ci>Q</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   Q
  </annotation>
</semantics>
</math>


 if 

<math display="inline" id="Jensen–Shannon_divergence:24">
<semantics>
<mrow>
<mi>Z</mi>
<mo>=</mo>
<mn>1</mn>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<eq></eq>
<ci>Z</ci>
<cn type="integer">1</cn>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   Z=1
  </annotation>
</semantics>
</math>

. That is, we are choosing 

<math display="inline" id="Jensen–Shannon_divergence:25">
<semantics>
<mi>X</mi>
<annotation-xml encoding="MathML-Content">
<ci>X</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   X
  </annotation>
</semantics>
</math>

 according to the probability measure 

<math display="inline" id="Jensen–Shannon_divergence:26">
<semantics>
<mrow>
<mi>M</mi>
<mo>=</mo>
<mrow>
<mrow>
<mo stretchy="false">(</mo>
<mrow>
<mi>P</mi>
<mo>+</mo>
<mi>Q</mi>
</mrow>
<mo stretchy="false">)</mo>
</mrow>
<mo>/</mo>
<mn>2</mn>
</mrow>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<eq></eq>
<ci>M</ci>
<apply>
<divide></divide>
<apply>
<plus></plus>
<ci>P</ci>
<ci>Q</ci>
</apply>
<cn type="integer">2</cn>
</apply>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   M=(P+Q)/2
  </annotation>
</semantics>
</math>

, and its distribution is the mixture distribution. We compute</p>

<p>
<math display="inline" id="Jensen–Shannon_divergence:27">
<semantics>
<mrow>
<mi>I</mi>
<mrow>
<mo stretchy="false">(</mo>
<mi>X</mi>
<mo>;</mo>
<mi>Z</mi>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<times></times>
<ci>I</ci>
<list>
<ci>X</ci>
<ci>Z</ci>
</list>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   \displaystyle I(X;Z)
  </annotation>
</semantics>
</math>


 It follows from the above result that the Jensen–Shannon divergence is bounded by 0 and 1 because mutual information is non-negative and bounded by 

<math display="inline" id="Jensen–Shannon_divergence:28">
<semantics>
<mrow>
<mrow>
<mi>H</mi>
<mrow>
<mo stretchy="false">(</mo>
<mi>Z</mi>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
<mo>=</mo>
<mn>1</mn>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<eq></eq>
<apply>
<times></times>
<ci>H</ci>
<ci>Z</ci>
</apply>
<cn type="integer">1</cn>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   H(Z)=1
  </annotation>
</semantics>
</math>

. The JSD is not always bounded by 0 and 1: the upper limit of 1 arises here because we are considering the specific case involving the binary variable 

<math display="inline" id="Jensen–Shannon_divergence:29">
<semantics>
<mi>Z</mi>
<annotation-xml encoding="MathML-Content">
<ci>Z</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   Z
  </annotation>
</semantics>
</math>

.</p>

<p>One can apply the same principle to a joint distribution and the product of its two marginal distribution (in analogy to Kullback–Leibler divergence and mutual information) and to measure how reliably one can decide if a given response comes from the joint distribution or the product distribution—subject to the assumption that these are the only two possibilities.<a class="footnoteRef" href="#fn4" id="fnref4"><sup>4</sup></a></p>
<h2 id="quantum-jensenshannon-divergence">Quantum Jensen–Shannon divergence</h2>

<p>The generalization of probability distributions on <a href="density_matrices" title="wikilink">density matrices</a> allows to define quantum Jensen–Shannon divergence (QJSD).<a class="footnoteRef" href="#fn5" id="fnref5"><sup>5</sup></a><a class="footnoteRef" href="#fn6" id="fnref6"><sup>6</sup></a> It is defined for a set of <a href="density_matrices" title="wikilink">density matrices</a>
<math display="inline" id="Jensen–Shannon_divergence:30">
<semantics>
<mrow>
<mo stretchy="false">(</mo>
<msub>
<mi>ρ</mi>
<mn>1</mn>
</msub>
<mo>,</mo>
<mi mathvariant="normal">…</mi>
<mo>,</mo>
<msub>
<mi>ρ</mi>
<mi>n</mi>
</msub>
<mo stretchy="false">)</mo>
</mrow>
<annotation-xml encoding="MathML-Content">
<vector>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>ρ</ci>
<cn type="integer">1</cn>
</apply>
<ci>normal-…</ci>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>ρ</ci>
<ci>n</ci>
</apply>
</vector>
</annotation-xml>
<annotation encoding="application/x-tex">
   (\rho_{1},\ldots,\rho_{n})
  </annotation>
</semantics>
</math>

 and probability distribution 

<math display="inline" id="Jensen–Shannon_divergence:31">
<semantics>
<mrow>
<mi>π</mi>
<mo>=</mo>
<mrow>
<mo stretchy="false">(</mo>
<msub>
<mi>π</mi>
<mn>1</mn>
</msub>
<mo>,</mo>
<mi mathvariant="normal">…</mi>
<mo>,</mo>
<msub>
<mi>π</mi>
<mi>n</mi>
</msub>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<eq></eq>
<ci>π</ci>
<vector>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>π</ci>
<cn type="integer">1</cn>
</apply>
<ci>normal-…</ci>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>π</ci>
<ci>n</ci>
</apply>
</vector>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   \pi=(\pi_{1},\ldots,\pi_{n})
  </annotation>
</semantics>
</math>

 as</p>

<p>
<math display="block" id="Jensen–Shannon_divergence:32">
<semantics>
<mrow>
<mrow>
<mi>QJSD</mi>
<mrow>
<mo stretchy="false">(</mo>
<msub>
<mi>ρ</mi>
<mn>1</mn>
</msub>
<mo>,</mo>
<mi mathvariant="normal">…</mi>
<mo>,</mo>
<msub>
<mi>ρ</mi>
<mi>n</mi>
</msub>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
<mo>=</mo>
<mrow>
<mrow>
<mi>S</mi>
<mrow>
<mo>(</mo>
<mrow>
<munderover>
<mo largeop="true" movablelimits="false" symmetric="true">∑</mo>
<mrow>
<mi>i</mi>
<mo>=</mo>
<mn>1</mn>
</mrow>
<mi>n</mi>
</munderover>
<mrow>
<msub>
<mi>π</mi>
<mi>i</mi>
</msub>
<msub>
<mi>ρ</mi>
<mi>i</mi>
</msub>
</mrow>
</mrow>
<mo>)</mo>
</mrow>
</mrow>
<mo>-</mo>
<mrow>
<munderover>
<mo largeop="true" movablelimits="false" symmetric="true">∑</mo>
<mrow>
<mi>i</mi>
<mo>=</mo>
<mn>1</mn>
</mrow>
<mi>n</mi>
</munderover>
<mrow>
<msub>
<mi>π</mi>
<mi>i</mi>
</msub>
<mi>S</mi>
<mrow>
<mo stretchy="false">(</mo>
<msub>
<mi>ρ</mi>
<mi>i</mi>
</msub>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
</mrow>
</mrow>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<eq></eq>
<apply>
<times></times>
<ci>QJSD</ci>
<vector>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>ρ</ci>
<cn type="integer">1</cn>
</apply>
<ci>normal-…</ci>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>ρ</ci>
<ci>n</ci>
</apply>
</vector>
</apply>
<apply>
<minus></minus>
<apply>
<times></times>
<ci>S</ci>
<apply>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<sum></sum>
<apply>
<eq></eq>
<ci>i</ci>
<cn type="integer">1</cn>
</apply>
</apply>
<ci>n</ci>
</apply>
<apply>
<times></times>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>π</ci>
<ci>i</ci>
</apply>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>ρ</ci>
<ci>i</ci>
</apply>
</apply>
</apply>
</apply>
<apply>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<sum></sum>
<apply>
<eq></eq>
<ci>i</ci>
<cn type="integer">1</cn>
</apply>
</apply>
<ci>n</ci>
</apply>
<apply>
<times></times>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>π</ci>
<ci>i</ci>
</apply>
<ci>S</ci>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>ρ</ci>
<ci>i</ci>
</apply>
</apply>
</apply>
</apply>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   {\rm QJSD}(\rho_{1},\ldots,\rho_{n})=S\left(\sum_{i=1}^{n}\pi_{i}\rho_{i}%
\right)-\sum_{i=1}^{n}\pi_{i}S(\rho_{i})
  </annotation>
</semantics>
</math>
</p>

<p>where 

<math display="inline" id="Jensen–Shannon_divergence:33">
<semantics>
<mrow>
<mi>S</mi>
<mrow>
<mo stretchy="false">(</mo>
<msub>
<mi>π</mi>
<mi>i</mi>
</msub>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<times></times>
<ci>S</ci>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>π</ci>
<ci>i</ci>
</apply>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   S(\pi_{i})
  </annotation>
</semantics>
</math>

 is the <a href="von_Neumann_entropy" title="wikilink">von Neumann entropy</a>. This quantity was introduced in <a href="quantum_information" title="wikilink">quantum information</a> theory, where it is called the Holevo information: it gives the upper bound for amount of classical information encoded by the quantum states 

<math display="inline" id="Jensen–Shannon_divergence:34">
<semantics>
<mrow>
<mo stretchy="false">(</mo>
<msub>
<mi>ρ</mi>
<mn>1</mn>
</msub>
<mo>,</mo>
<mi mathvariant="normal">…</mi>
<mo>,</mo>
<msub>
<mi>ρ</mi>
<mi>n</mi>
</msub>
<mo stretchy="false">)</mo>
</mrow>
<annotation-xml encoding="MathML-Content">
<vector>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>ρ</ci>
<cn type="integer">1</cn>
</apply>
<ci>normal-…</ci>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>ρ</ci>
<ci>n</ci>
</apply>
</vector>
</annotation-xml>
<annotation encoding="application/x-tex">
   (\rho_{1},\ldots,\rho_{n})
  </annotation>
</semantics>
</math>

 under the prior distribution 

<math display="inline" id="Jensen–Shannon_divergence:35">
<semantics>
<mi>π</mi>
<annotation-xml encoding="MathML-Content">
<ci>π</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   \pi
  </annotation>
</semantics>
</math>

 (see <a href="Holevo's_theorem" title="wikilink">Holevo's theorem</a>)<a class="footnoteRef" href="#fn7" id="fnref7"><sup>7</sup></a> Quantum Jensen–Shannon divergence for 

<math display="inline" id="Jensen–Shannon_divergence:36">
<semantics>
<mrow>
<mi>π</mi>
<mo>=</mo>
<mrow>
<mo>(</mo>
<mfrac>
<mn>1</mn>
<mn>2</mn>
</mfrac>
<mo>,</mo>
<mfrac>
<mn>1</mn>
<mn>2</mn>
</mfrac>
<mo>)</mo>
</mrow>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<eq></eq>
<ci>π</ci>
<interval closure="open">
<apply>
<divide></divide>
<cn type="integer">1</cn>
<cn type="integer">2</cn>
</apply>
<apply>
<divide></divide>
<cn type="integer">1</cn>
<cn type="integer">2</cn>
</apply>
</interval>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   \pi=\left(\frac{1}{2},\frac{1}{2}\right)
  </annotation>
</semantics>
</math>

 and two density matrices is a symmetric function, everywhere defined, bounded and equal to zero only if two <a href="density_matrices" title="wikilink">density matrices</a> are the same. It is a square of a metric for <a href="pure_states" title="wikilink">pure states</a><a class="footnoteRef" href="#fn8" id="fnref8"><sup>8</sup></a> but it is unknown whether the metric property holds in general.<a class="footnoteRef" href="#fn9" id="fnref9"><sup>9</sup></a> The <a href="Bures_metric" title="wikilink">Bures metric</a> is closely related to the quantum JS divergence; it is the quantum analog of the <a href="Fisher_information_metric" title="wikilink">Fisher information metric</a>.</p>
<h2 id="applications">Applications</h2>

<p>The Jensen–Shannon divergence has been applied in <a class="uri" href="bioinformatics" title="wikilink">bioinformatics</a> and <a href="genome_comparison" title="wikilink">genome comparison</a>,<a class="footnoteRef" href="#fn10" id="fnref10"><sup>10</sup></a><a class="footnoteRef" href="#fn11" id="fnref11"><sup>11</sup></a> in protein surface comparison,<a class="footnoteRef" href="#fn12" id="fnref12"><sup>12</sup></a> in the social sciences,<a class="footnoteRef" href="#fn13" id="fnref13"><sup>13</sup></a> in the quantitative study of history,<a class="footnoteRef" href="#fn14" id="fnref14"><sup>14</sup></a> and in machine learning.<a class="footnoteRef" href="#fn15" id="fnref15"><sup>15</sup></a></p>
<h2 id="notes">Notes</h2>
<h2 id="further-reading">Further reading</h2>
<ul>
<li></li>
<li></li>
</ul>
<h2 id="external-links">External links</h2>
<ul>
<li><a href="https://github.com/evansenter/diverge">Ruby gem for calculating JS divergence</a></li>
<li><a href="http://pynchon.googlecode.com/hg/pynchon/bio/alg/entropy.py">Python code for calculating JS divergence</a></li>
</ul>

<p>"</p>

<p><a href="Category:Statistical_distance_measures" title="wikilink">Category:Statistical distance measures</a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1"><a href="#fnref1">↩</a></li>
<li id="fn2"><a href="#fnref2">↩</a></li>
<li id="fn3"></li>
<li id="fn4"><a href="#fnref4">↩</a></li>
<li id="fn5"><a href="#fnref5">↩</a></li>
<li id="fn6"><a href="#fnref6">↩</a></li>
<li id="fn7">. English translation: <em>Probl. Inf. Transm</em>., 9, 177–183 (1975)) <a href="#fnref7">↩</a></li>
<li id="fn8"><a href="#fnref8">↩</a></li>
<li id="fn9"></li>
<li id="fn10"></li>
<li id="fn11"></li>
<li id="fn12"></li>
<li id="fn13"></li>
<li id="fn14"></li>
<li id="fn15">Ian J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, Yoshua Bengio, "Generative Adversarial Networks", NIPS 2014. <a class="uri" href="http://arxiv.org/abs/1406.2661">http://arxiv.org/abs/1406.2661</a><a href="#fnref15">↩</a></li>
</ol>
</section>
</ref></hr></body>
</html>
