<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="1165">Variable-order Markov model</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>Variable-order Markov model</h1>
<hr/>

<p>In <a href="stochastic_processes" title="wikilink">stochastic processes</a>, <strong>Variable-order Markov (VOM) models</strong> are an important class of models that extend the well known <a href="Markov_chain" title="wikilink">Markov chain</a> models. In contrast to the Markov chain models, where each <a href="random_variable" title="wikilink">random variable</a> in a sequence with a <a href="Markov_property" title="wikilink">Markov property</a> depends on a fixed number of random variables, in VOM models this number of conditioning random variables may vary based on the specific observed realization.</p>

<p>This realization sequence is often called the <em>context</em>; therefore the VOM models are also called <em>context trees</em>.<a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a> The flexibility in the number of conditioning random variables turns out to be of real advantage for many applications, such as <a href="statistical_analysis" title="wikilink">statistical analysis</a>, <a href="Statistical_classification" title="wikilink">classification</a> and <a class="uri" href="prediction" title="wikilink">prediction</a>.<a class="footnoteRef" href="#fn2" id="fnref2"><sup>2</sup></a><a class="footnoteRef" href="#fn3" id="fnref3"><sup>3</sup></a><a class="footnoteRef" href="#fn4" id="fnref4"><sup>4</sup></a></p>
<h2 id="example">Example</h2>

<p>Consider for example a sequence of <a href="random_variable" title="wikilink">random variables</a>, each of which takes a value from the ternary <a class="uri" href="alphabet" title="wikilink">alphabet</a> {<em>a</em>, <em>b</em>, <em>c</em>}. Specifically, consider the string <em>aaabcaaabcaaabcaaabc...aaabc</em> constructed from infinite concatenations of the sub-string <em>aaabc</em>.</p>

<p>The VOM model of maximal order 2 can approximate the above string using <em>only</em> the following five <a href="conditional_probability" title="wikilink">conditional probability</a> components: {Pr(<em>a</em>|<em>aa</em>) = 0.5, Pr(<em>b</em>|<em>aa</em>) = 0.5, Pr(<em>c</em>|<em>b</em>) = 1.0, Pr(<em>a</em>|<em>c</em>)= 1.0, Pr(<em>a</em>|<em>ca</em>)= 1.0}.</p>

<p>In this example, Pr(<em>c</em>|<em>ab</em>) = Pr(<em>c</em>|<em>b</em>) = 1.0; therefore, the shorter context <em>b</em> is sufficient to determine the next character. Similarly, the VOM model of maximal order 3 can generate the string exactly using only five conditional probability components, which are all equal to 1.0.</p>

<p>To construct the <a href="Markov_chain" title="wikilink">Markov chain</a> of order 1 for the next character in that string, one must estimate the following 9 conditional probability components: {Pr(<em>a</em>|<em>a</em>), Pr(<em>a</em>|<em>b</em>), Pr(<em>a</em>|<em>c</em>), Pr(<em>b</em>|<em>a</em>), Pr(<em>b</em>|<em>b</em>), Pr(<em>b</em>|<em>c</em>), Pr(<em>c</em>|<em>a</em>), Pr(<em>c</em>|<em>b</em>), Pr(<em>c</em>|<em>c</em>)}. To construct the Markov chain of order 2 for the next character, one must estimate 27 conditional probability components: {Pr(<em>a</em>|<em>aa</em>), Pr(<em>a</em>|<em>ab</em>), ..., Pr(<em>c</em>|<em>cc</em>)}. And to construct the Markov chain of order three for the next character one must estimate the following 81 conditional probability components: {Pr(<em>a</em>|<em>aaa</em>), Pr(<em>a</em>|<em>aab</em>), ..., Pr(<em>c</em>|<em>ccc</em>)}.</p>

<p>In practical settings there is seldom sufficient data to accurately estimate the <a href="exponential_growth" title="wikilink">exponentially increasing</a> number of conditional probability components as the order of the Markov chain increases.</p>

<p>The variable-order Markov model assumes that in realistic settings, there are certain realizations of states (represented by contexts) in which some past states are independent from the future states; accordingly, "a great reduction in the number of model parameters can be achieved."<a class="footnoteRef" href="#fn5" id="fnref5"><sup>5</sup></a></p>
<h2 id="definition">Definition</h2>

<p>Let 

<math display="inline" id="Variable-order_Markov_model:0">
 <semantics>
  <mi>A</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>A</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   A
  </annotation>
 </semantics>
</math>

 be a state space (finite <a class="uri" href="alphabet" title="wikilink">alphabet</a>) of size |A|.</p>

<p>Consider a sequence with the <a href="Markov_property" title="wikilink">Markov property</a> 

<math display="inline" id="Variable-order_Markov_model:1">
 <semantics>
  <mrow>
   <msubsup>
    <mi>x</mi>
    <mn>1</mn>
    <mi>n</mi>
   </msubsup>
   <mo>=</mo>
   <mrow>
    <msub>
     <mi>x</mi>
     <mn>1</mn>
    </msub>
    <msub>
     <mi>x</mi>
     <mn>2</mn>
    </msub>
    <mi mathvariant="normal">…</mi>
    <msub>
     <mi>x</mi>
     <mi>n</mi>
    </msub>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <csymbol cd="ambiguous">superscript</csymbol>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>x</ci>
      <cn type="integer">1</cn>
     </apply>
     <ci>n</ci>
    </apply>
    <apply>
     <times></times>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>x</ci>
      <cn type="integer">1</cn>
     </apply>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>x</ci>
      <cn type="integer">2</cn>
     </apply>
     <ci>normal-…</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>x</ci>
      <ci>n</ci>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   x_{1}^{n}=x_{1}x_{2}\dots x_{n}
  </annotation>
 </semantics>
</math>

 of 

<math display="inline" id="Variable-order_Markov_model:2">
 <semantics>
  <mi>n</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>n</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   n
  </annotation>
 </semantics>
</math>

 realizations of <a href="random_variable" title="wikilink">random variables</a>, where 

<math display="inline" id="Variable-order_Markov_model:3">
 <semantics>
  <mrow>
   <msub>
    <mi>x</mi>
    <mi>i</mi>
   </msub>
   <mo>∈</mo>
   <mi>A</mi>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <in></in>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>x</ci>
     <ci>i</ci>
    </apply>
    <ci>A</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   x_{i}\in A
  </annotation>
 </semantics>
</math>

 is the state (symbol) at position 

<math display="inline" id="Variable-order_Markov_model:4">
 <semantics>
  <mi>i</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>i</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   i
  </annotation>
 </semantics>
</math>

 1≤

<math display="inline" id="Variable-order_Markov_model:5">
 <semantics>
  <mi>i</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>i</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   i
  </annotation>
 </semantics>
</math>

≤

<math display="inline" id="Variable-order_Markov_model:6">
 <semantics>
  <mi>n</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>n</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   n
  </annotation>
 </semantics>
</math>

, and the concatenation of states 

<math display="inline" id="Variable-order_Markov_model:7">
 <semantics>
  <msub>
   <mi>x</mi>
   <mi>i</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>x</ci>
    <ci>i</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   x_{i}
  </annotation>
 </semantics>
</math>

 and 

<math display="inline" id="Variable-order_Markov_model:8">
 <semantics>
  <msub>
   <mi>x</mi>
   <mrow>
    <mi>i</mi>
    <mo>+</mo>
    <mn>1</mn>
   </mrow>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>x</ci>
    <apply>
     <plus></plus>
     <ci>i</ci>
     <cn type="integer">1</cn>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   x_{i+1}
  </annotation>
 </semantics>
</math>

 is denoted by 

<math display="inline" id="Variable-order_Markov_model:9">
 <semantics>
  <mrow>
   <msub>
    <mi>x</mi>
    <mi>i</mi>
   </msub>
   <msub>
    <mi>x</mi>
    <mrow>
     <mi>i</mi>
     <mo>+</mo>
     <mn>1</mn>
    </mrow>
   </msub>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>x</ci>
     <ci>i</ci>
    </apply>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>x</ci>
     <apply>
      <plus></plus>
      <ci>i</ci>
      <cn type="integer">1</cn>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   x_{i}x_{i+1}
  </annotation>
 </semantics>
</math>

.</p>

<p>Given a training set of observed states, 

<math display="inline" id="Variable-order_Markov_model:10">
 <semantics>
  <msubsup>
   <mi>x</mi>
   <mn>1</mn>
   <mi>n</mi>
  </msubsup>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">superscript</csymbol>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>x</ci>
     <cn type="integer">1</cn>
    </apply>
    <ci>n</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   x_{1}^{n}
  </annotation>
 </semantics>
</math>

, the construction algorithm of the VOM models<a class="footnoteRef" href="#fn6" id="fnref6"><sup>6</sup></a><a class="footnoteRef" href="#fn7" id="fnref7"><sup>7</sup></a><a class="footnoteRef" href="#fn8" id="fnref8"><sup>8</sup></a> learns a model 

<math display="inline" id="Variable-order_Markov_model:11">
 <semantics>
  <mi>P</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>P</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   P
  </annotation>
 </semantics>
</math>

 that provides a <a class="uri" href="probability" title="wikilink">probability</a> assignment for each state in the sequence given its past (previously observed symbols) or future states.</p>

<p>Specifically, the learner generates a <a href="conditional_distribution" title="wikilink">conditional probability distribution</a> 

<math display="inline" id="Variable-order_Markov_model:12">
 <semantics>
  <mrow>
   <mi>P</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <msub>
     <mi>x</mi>
     <mi>i</mi>
    </msub>
    <mo stretchy="false">|</mo>
    <mi>s</mi>
    <mo stretchy="false">)</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <cerror>
    <csymbol cd="ambiguous">fragments</csymbol>
    <csymbol cd="unknown">P</csymbol>
    <cerror>
     <csymbol cd="ambiguous">fragments</csymbol>
     <ci>normal-(</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>x</ci>
      <ci>i</ci>
     </apply>
     <ci>normal-|</ci>
     <csymbol cd="unknown">s</csymbol>
     <ci>normal-)</ci>
    </cerror>
   </cerror>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   P(x_{i}|s)
  </annotation>
 </semantics>
</math>

 for a symbol 

<math display="inline" id="Variable-order_Markov_model:13">
 <semantics>
  <mrow>
   <msub>
    <mi>x</mi>
    <mi>i</mi>
   </msub>
   <mo>∈</mo>
   <mi>A</mi>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <in></in>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>x</ci>
     <ci>i</ci>
    </apply>
    <ci>A</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   x_{i}\in A
  </annotation>
 </semantics>
</math>

 given a context 

<math display="inline" id="Variable-order_Markov_model:14">
 <semantics>
  <mrow>
   <mi>s</mi>
   <mo>∈</mo>
   <msup>
    <mi>A</mi>
    <mo>*</mo>
   </msup>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <in></in>
    <ci>s</ci>
    <apply>
     <csymbol cd="ambiguous">superscript</csymbol>
     <ci>A</ci>
     <times></times>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   s\in A^{*}
  </annotation>
 </semantics>
</math>

, where the * sign represents a sequence of states of any length, including the empty context.</p>

<p>VOM models attempt to estimate <a href="conditional_distribution" title="wikilink">conditional distributions</a> of the form 

<math display="inline" id="Variable-order_Markov_model:15">
 <semantics>
  <mrow>
   <mi>P</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <msub>
     <mi>x</mi>
     <mi>i</mi>
    </msub>
    <mo stretchy="false">|</mo>
    <mi>s</mi>
    <mo stretchy="false">)</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <cerror>
    <csymbol cd="ambiguous">fragments</csymbol>
    <csymbol cd="unknown">P</csymbol>
    <cerror>
     <csymbol cd="ambiguous">fragments</csymbol>
     <ci>normal-(</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>x</ci>
      <ci>i</ci>
     </apply>
     <ci>normal-|</ci>
     <csymbol cd="unknown">s</csymbol>
     <ci>normal-)</ci>
    </cerror>
   </cerror>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   P(x_{i}|s)
  </annotation>
 </semantics>
</math>

 where the context length |

<math display="inline" id="Variable-order_Markov_model:16">
 <semantics>
  <mi>s</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>s</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   s
  </annotation>
 </semantics>
</math>

|≤

<math display="inline" id="Variable-order_Markov_model:17">
 <semantics>
  <mi>D</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>D</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   D
  </annotation>
 </semantics>
</math>

 varies depending on the available statistics. In contrast, conventional <a href="Markov_chain" title="wikilink">Markov models</a> attempt to estimate these <a href="conditional_distribution" title="wikilink">conditional distributions</a> by assuming a fixed contexts' length |

<math display="inline" id="Variable-order_Markov_model:18">
 <semantics>
  <mi>s</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>s</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   s
  </annotation>
 </semantics>
</math>

|=

<math display="inline" id="Variable-order_Markov_model:19">
 <semantics>
  <mi>D</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>D</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   D
  </annotation>
 </semantics>
</math>

 and, hence, can be considered as special cases of the VOM models.</p>

<p>Effectively, for a given training sequence, the VOM models are found to obtain better model parameterization than the fixed-order <a href="Markov_chain" title="wikilink">Markov models</a> that leads to a better <a class="uri" href="variance" title="wikilink">variance</a>-bias tradeoff of the learned models.<a class="footnoteRef" href="#fn9" id="fnref9"><sup>9</sup></a><a class="footnoteRef" href="#fn10" id="fnref10"><sup>10</sup></a><a class="footnoteRef" href="#fn11" id="fnref11"><sup>11</sup></a></p>
<h2 id="application-areas">Application areas</h2>

<p>Various efficient algorithms have been devised for estimating the parameters of the VOM model.<a class="footnoteRef" href="#fn12" id="fnref12"><sup>12</sup></a></p>

<p>VOM models have been successfully applied to areas such as <a href="machine_learning" title="wikilink">machine learning</a>, <a href="information_theory" title="wikilink">information theory</a> and <a class="uri" href="bioinformatics" title="wikilink">bioinformatics</a>, including specific applications such as <a href="code" title="wikilink">coding</a> and <a href="data_compression" title="wikilink">data compression</a>,<a class="footnoteRef" href="#fn13" id="fnref13"><sup>13</sup></a> document compression,<a class="footnoteRef" href="#fn14" id="fnref14"><sup>14</sup></a> classification and identification of <a class="uri" href="DNA" title="wikilink">DNA</a> and <a href="protein" title="wikilink">protein sequences</a>,<a class="footnoteRef" href="#fn15" id="fnref15"><sup>15</sup></a> <a href="http://www.eng.tau.ac.il/~bengal/VOMBAT.pdf">1</a><a class="footnoteRef" href="#fn16" id="fnref16"><sup>16</sup></a> <a href="statistical_process_control" title="wikilink">statistical process control</a>,<a class="footnoteRef" href="#fn17" id="fnref17"><sup>17</sup></a> <a href="spam_filtering" title="wikilink">spam filtering</a>,<a class="footnoteRef" href="#fn18" id="fnref18"><sup>18</sup></a> <a class="uri" href="haplotyping" title="wikilink">haplotyping</a><a class="footnoteRef" href="#fn19" id="fnref19"><sup>19</sup></a> and others.</p>
<h2 id="see-also">See also</h2>
<ul>
<li><a href="Examples_of_Markov_chains" title="wikilink">Examples of Markov chains</a></li>
<li><a href="Variable_order_Bayesian_network" title="wikilink">Variable order Bayesian network</a></li>
<li><a href="Markov_process" title="wikilink">Markov process</a></li>
<li><a href="Markov_chain_Monte_Carlo" title="wikilink">Markov chain Monte Carlo</a></li>
<li><a href="Semi-Markov_process" title="wikilink">Semi-Markov process</a></li>
<li><a href="Artificial_intelligence" title="wikilink">Artificial intelligence</a></li>
</ul>
<h2 id="references">References</h2>

<p>"</p>

<p><a href="Category:Markov_models" title="wikilink">Category:Markov models</a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1"><a href="#fnref1">↩</a></li>
<li id="fn2"><a href="#fnref2">↩</a></li>
<li id="fn3"><a href="#fnref3">↩</a></li>
<li id="fn4"><a href="#fnref4">↩</a></li>
<li id="fn5"></li>
<li id="fn6"></li>
<li id="fn7"></li>
<li id="fn8"></li>
<li id="fn9"></li>
<li id="fn10"></li>
<li id="fn11"></li>
<li id="fn12"></li>
<li id="fn13"></li>
<li id="fn14"></li>
<li id="fn15"><a href="#fnref15">↩</a></li>
<li id="fn16"></li>
<li id="fn17"></li>
<li id="fn18"><a href="#fnref18">↩</a></li>
<li id="fn19">Browning, Sharon R. "Multilocus association mapping using variable-length Markov chains." The American Journal of Human Genetics 78.6 (2006): 903-913.<a href="#fnref19">↩</a></li>
</ol>
</section>
</body>
</html>
