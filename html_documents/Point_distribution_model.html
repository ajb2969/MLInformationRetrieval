<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="1862">Point distribution model</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>Point distribution model</h1>
<hr/>

<p>The <strong>point distribution model</strong> is a model for representing the mean geometry of a shape and some statistical modes of geometric variation inferred from a training set of shapes.</p>
<h2 id="background">Background</h2>

<p>It has been developed by Cootes,<a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a> Taylor <em>et al.</em><a class="footnoteRef" href="#fn2" id="fnref2"><sup>2</sup></a> and became a standard in <a href="computer_vision" title="wikilink">computer vision</a> for the <a href="statistical_shape_analysis" title="wikilink">statistical study of shape</a><a class="footnoteRef" href="#fn3" id="fnref3"><sup>3</sup></a> and for <a href="image_segmentation" title="wikilink">segmentation</a> of <a href="medical_imaging" title="wikilink">medical images</a><a class="footnoteRef" href="#fn4" id="fnref4"><sup>4</sup></a> where shape priors really help interpretation of noisy and low-contrasted <a href="pixel" title="wikilink">pixels</a>/<a href="voxel" title="wikilink">voxels</a>. The latter point leads to <a href="active_shape_model" title="wikilink">active shape models</a> (ASM) and <a href="active_appearance_model" title="wikilink">active appearance models</a> (AAM).</p>

<p>Point distribution models rely on <a href="landmark_point" title="wikilink">landmark points</a>. A landmark is an annotating point posed by an anatomist onto a given locus for every shape instance across the training set population. For instance, the same landmark will designate the tip of the <a href="index_finger" title="wikilink">index finger</a> in a training set of 2D hands outlines. <a href="Principal_component_analysis" title="wikilink">Principal component analysis</a> (PCA), for instance, is a relevant tool for studying correlations of movement between groups of landmarks among the training set population. Typically, it might detect that all the landmarks located along the same finger move exactly together across the training set examples showing different finger spacing for a flat-posed hands collection.</p>
<h2 id="details">Details</h2>

<p>First, a set of training images are manually landmarked with enough corresponding landmarks to sufficiently approximate the geometry of the original shapes. These landmarks are aligned using the <a href="generalized_procrustes_analysis" title="wikilink">generalized procrustes analysis</a>, which minimizes the least squared error between the points.</p>

<p>

<math display="inline" id="Point_distribution_model:0">
 <semantics>
  <mi>k</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>k</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   k
  </annotation>
 </semantics>
</math>

 aligned landmarks in two dimensions are given as</p>

<p>

<math display="block" id="Point_distribution_model:1">
 <semantics>
  <mrow>
   <mi>𝐗</mi>
   <mo>=</mo>
   <mrow>
    <mo stretchy="false">(</mo>
    <msub>
     <mi>x</mi>
     <mn>1</mn>
    </msub>
    <mo>,</mo>
    <msub>
     <mi>y</mi>
     <mn>1</mn>
    </msub>
    <mo>,</mo>
    <mi mathvariant="normal">…</mi>
    <mo>,</mo>
    <msub>
     <mi>x</mi>
     <mi>k</mi>
    </msub>
    <mo>,</mo>
    <msub>
     <mi>y</mi>
     <mi>k</mi>
    </msub>
    <mo stretchy="false">)</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <ci>𝐗</ci>
    <vector>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>x</ci>
      <cn type="integer">1</cn>
     </apply>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>y</ci>
      <cn type="integer">1</cn>
     </apply>
     <ci>normal-…</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>x</ci>
      <ci>k</ci>
     </apply>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>y</ci>
      <ci>k</ci>
     </apply>
    </vector>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \mathbf{X}=(x_{1},y_{1},\ldots,x_{k},y_{k})
  </annotation>
 </semantics>
</math>

.</p>

<p>It's important to note that each landmark 

<math display="inline" id="Point_distribution_model:2">
 <semantics>
  <mrow>
   <mi>i</mi>
   <mo>∈</mo>
   <mrow>
    <mo stretchy="false">{</mo>
    <mn>1</mn>
    <mo>,</mo>
    <mrow>
     <mi mathvariant="normal">…</mi>
     <mi>k</mi>
    </mrow>
    <mo stretchy="false">}</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <in></in>
    <ci>i</ci>
    <set>
     <cn type="integer">1</cn>
     <apply>
      <times></times>
      <ci>normal-…</ci>
      <ci>k</ci>
     </apply>
    </set>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   i\in\{1,\ldots k\}
  </annotation>
 </semantics>
</math>

 should represent the same anatomical location. For example, landmark #3, 

<math display="inline" id="Point_distribution_model:3">
 <semantics>
  <mrow>
   <mo stretchy="false">(</mo>
   <msub>
    <mi>x</mi>
    <mn>3</mn>
   </msub>
   <mo>,</mo>
   <msub>
    <mi>y</mi>
    <mn>3</mn>
   </msub>
   <mo stretchy="false">)</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <interval closure="open">
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>x</ci>
     <cn type="integer">3</cn>
    </apply>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>y</ci>
     <cn type="integer">3</cn>
    </apply>
   </interval>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   (x_{3},y_{3})
  </annotation>
 </semantics>
</math>


 might represent the tip of the ring finger across all training images.</p>

<p>Now the shape outlines are reduced to sequences of 

<math display="inline" id="Point_distribution_model:4">
 <semantics>
  <mi>k</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>k</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   k
  </annotation>
 </semantics>
</math>

 landmarks, so that a given training shape is defined as the vector 

<math display="inline" id="Point_distribution_model:5">
 <semantics>
  <mrow>
   <mi>𝐗</mi>
   <mo>∈</mo>
   <msup>
    <mi>ℝ</mi>
    <mrow>
     <mn>2</mn>
     <mi>k</mi>
    </mrow>
   </msup>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <in></in>
    <ci>𝐗</ci>
    <apply>
     <csymbol cd="ambiguous">superscript</csymbol>
     <ci>ℝ</ci>
     <apply>
      <times></times>
      <cn type="integer">2</cn>
      <ci>k</ci>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \mathbf{X}\in\mathbb{R}^{2k}
  </annotation>
 </semantics>
</math>

. Assuming the scattering is <a href="gaussian_distribution" title="wikilink">gaussian</a> in this space, PCA is used to compute normalized <a class="uri" href="eigenvectors" title="wikilink">eigenvectors</a> and <a class="uri" href="eigenvalues" title="wikilink">eigenvalues</a> of the <a href="covariance_matrix" title="wikilink">covariance matrix</a> across all training shapes. The matrix of the top 

<math display="inline" id="Point_distribution_model:6">
 <semantics>
  <mi>d</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>d</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   d
  </annotation>
 </semantics>
</math>

 eigenvectors is given as 

<math display="inline" id="Point_distribution_model:7">
 <semantics>
  <mrow>
   <mi>𝐏</mi>
   <mo>∈</mo>
   <msup>
    <mi>ℝ</mi>
    <mrow>
     <mrow>
      <mn>2</mn>
      <mi>k</mi>
     </mrow>
     <mo>×</mo>
     <mi>d</mi>
    </mrow>
   </msup>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <in></in>
    <ci>𝐏</ci>
    <apply>
     <csymbol cd="ambiguous">superscript</csymbol>
     <ci>ℝ</ci>
     <apply>
      <times></times>
      <apply>
       <times></times>
       <cn type="integer">2</cn>
       <ci>k</ci>
      </apply>
      <ci>d</ci>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \mathbf{P}\in\mathbb{R}^{2k\times d}
  </annotation>
 </semantics>
</math>

, and each eigenvector describes a principal mode of variation along the set.</p>

<p>Finally, a <a href="linear_combination" title="wikilink">linear combination</a> of the eigenvectors is used to define a new shape 

<math display="inline" id="Point_distribution_model:8">
 <semantics>
  <msup>
   <mi>𝐗</mi>
   <mo>′</mo>
  </msup>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">superscript</csymbol>
    <ci>𝐗</ci>
    <ci>normal-′</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \mathbf{X}^{\prime}
  </annotation>
 </semantics>
</math>


, mathematically defined as:</p>

<p>

<math display="block" id="Point_distribution_model:9">
 <semantics>
  <mrow>
   <msup>
    <mi>𝐗</mi>
    <mo>′</mo>
   </msup>
   <mo>=</mo>
   <mrow>
    <mover accent="true">
     <mi>𝐗</mi>
     <mo>¯</mo>
    </mover>
    <mo>+</mo>
    <mi>𝐏𝐛</mi>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <csymbol cd="ambiguous">superscript</csymbol>
     <ci>𝐗</ci>
     <ci>normal-′</ci>
    </apply>
    <apply>
     <plus></plus>
     <apply>
      <ci>normal-¯</ci>
      <ci>𝐗</ci>
     </apply>
     <ci>𝐏𝐛</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \mathbf{X}^{\prime}=\overline{\mathbf{X}}+\mathbf{P}\mathbf{b}
  </annotation>
 </semantics>
</math>

</p>

<p>where 

<math display="inline" id="Point_distribution_model:10">
 <semantics>
  <mover accent="true">
   <mi>𝐗</mi>
   <mo>¯</mo>
  </mover>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <ci>normal-¯</ci>
    <ci>𝐗</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \overline{\mathbf{X}}
  </annotation>
 </semantics>
</math>

 is defined as the mean shape across all training images, and 

<math display="inline" id="Point_distribution_model:11">
 <semantics>
  <mi>𝐛</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>𝐛</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \mathbf{b}
  </annotation>
 </semantics>
</math>

 is a vector of scaling values for each principal component. Therefore, by modifying the variable 

<math display="inline" id="Point_distribution_model:12">
 <semantics>
  <mi>𝐛</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>𝐛</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \mathbf{b}
  </annotation>
 </semantics>
</math>

 an infinite number of shapes can be defined. To ensure that the new shapes are all within the variation seen in the training set, it is common to only allow each element of 

<math display="inline" id="Point_distribution_model:13">
 <semantics>
  <mi>𝐛</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>𝐛</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \mathbf{b}
  </annotation>
 </semantics>
</math>


 to be within 

<math display="inline" id="Point_distribution_model:14">
 <semantics>
  <mo>±</mo>
  <annotation-xml encoding="MathML-Content">
   <csymbol cd="latexml">plus-or-minus</csymbol>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \pm
  </annotation>
 </semantics>
</math>

3 standard deviations, where the standard deviation of a given principal component is defined as the square root of its corresponding eigenvalue.</p>

<p>PDM's can be extended to any arbitrary number of dimensions, but are typically used in 2D image and 3D volume applications (where each landmark point is 

<math display="inline" id="Point_distribution_model:15">
 <semantics>
  <msup>
   <mi>ℝ</mi>
   <mn>2</mn>
  </msup>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">superscript</csymbol>
    <ci>ℝ</ci>
    <cn type="integer">2</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \mathbb{R}^{2}
  </annotation>
 </semantics>
</math>

 or 

<math display="inline" id="Point_distribution_model:16">
 <semantics>
  <msup>
   <mi>ℝ</mi>
   <mn>3</mn>
  </msup>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">superscript</csymbol>
    <ci>ℝ</ci>
    <cn type="integer">3</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \mathbb{R}^{3}
  </annotation>
 </semantics>
</math>

).</p>
<h2 id="discussion">Discussion</h2>

<p>An eigenvector, interpreted in <a href="euclidean_space" title="wikilink">euclidean space</a>, can be seen as a sequence of 

<math display="inline" id="Point_distribution_model:17">
 <semantics>
  <mi>k</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>k</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   k
  </annotation>
 </semantics>
</math>

 euclidean vectors associated to corresponding landmark and designating a compound move for the whole shape. Global nonlinear variation is usually well handled provided nonlinear variation is kept to a reasonable level. Typically, a twisting <a href="nematode_worm" title="wikilink">nematode worm</a> is used as an example in the teaching of <a href="kernel_PCA" title="wikilink">kernel PCA</a>-based methods.</p>

<p>Due to the PCA properties: eigenvectors are mutually <a class="uri" href="orthogonal" title="wikilink">orthogonal</a>, form a basis of the training set cloud in the shape space, and cross at the 0 in this space, which represents the mean shape. Also, PCA is a traditional way of fitting a closed ellipsoid to a Gaussian cloud of points (whatever their dimension): this suggests the concept of bounded variation.</p>

<p>The idea behind PDM's is that eigenvectors can be linearly combined to create an infinity of new shape instances that will 'look like' the one in the training set. The coefficients are bounded alike the values of the corresponding eigenvalues, so as to ensure the generated 2n/3n-dimensional dot will remain into the hyper-ellipsoidal allowed domain—<a href="allowable_shape_domain" title="wikilink">allowable shape domain</a> (ASD).<a class="footnoteRef" href="#fn5" id="fnref5"><sup>5</sup></a></p>
<h2 id="references">References</h2>
<references>
</references>
<h2 id="see-also">See also</h2>
<ul>
<li><a href="Procrustes_analysis" title="wikilink">Procrustes analysis</a></li>
</ul>
<h2 id="external-links">External links</h2>
<ul>
<li><a href="http://www.isbe.man.ac.uk/~bim/Models/index.html">Flexible Models for Computer Vision</a>, Tim Cootes, Manchester University.</li>
<li><a href="http://www.icaen.uiowa.edu/~dip/LECTURE/Understanding3.html">A practical introduction to PDM and ASMs</a>.</li>
</ul>

<p>"</p>

<p><a href="Category:Computer_vision" title="wikilink">Category:Computer vision</a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1"><a href="#fnref1">↩</a></li>
<li id="fn2"><a href="#fnref2">↩</a></li>
<li id="fn3"><a href="#fnref3">↩</a></li>
<li id="fn4"></li>
<li id="fn5"></li>
</ol>
</section>
</body>
</html>
