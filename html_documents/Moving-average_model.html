<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title offset="1607">Moving-average model</title>
   <script type="text/javascript"
      src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js">
    </script>
</head>
<body>
<h1>Moving-average model</h1>
<hr/>
<p>In <a href="time_series_analysis" title="wikilink">time series analysis</a>, the <strong>moving-average</strong> (<strong>MA</strong>) model is a common approach for modeling <a class="uri" href="univariate" title="wikilink">univariate</a> time series. The notation MA(<em>q</em>) refers to the moving average model of order <em>q</em>:</p>
<p><span class="LaTeX">$$X_t = \mu + \varepsilon_t + \theta_1 \varepsilon_{t-1} + \cdots + \theta_q \varepsilon_{t-q} \,$$</span></p>
<p>where μ is the mean of the series, the <em>θ</em><sub>1</sub>, ..., <em>θ</em><sub><em>q</em></sub> are the parameters of the model and the <em>ε</em><sub><em>t</em></sub>, <em>ε</em><sub><em>t</em>−1</sub>,..., <em>ε</em><sub><em>t</em>−q</sub> are <a href="white_noise" title="wikilink">white noise</a> error terms. The value of <em>q</em> is called the order of the MA model. This can be equivalently written in terms of the <a href="backshift_operator" title="wikilink">backshift operator</a> <em>B</em> as</p>
<p><span class="LaTeX">$$X_t = \mu + (1 + \theta_1 B + \cdots + \theta_q B^q)\varepsilon_t.$$</span></p>
<p>Thus, a moving-average model is conceptually a <a href="linear_regression" title="wikilink">linear regression</a> of the current value of the series against current and previous (unobserved) white noise error terms or random shocks. The random shocks at each point are assumed to be mutually independent and to come from the same distribution, typically a <a href="normal_distribution" title="wikilink">normal distribution</a>, with location at zero and constant scale.</p>
<h2 id="interpretation">Interpretation</h2>
<p>The moving-average model is essentially a <a href="finite_impulse_response" title="wikilink">finite impulse response</a> filter applied to white noise, with some additional interpretation placed on it. The role of the random shocks in the MA model differs from their role in the <a href="autoregressive_model" title="wikilink">autoregressive (AR) model</a> in two ways. First, they are propagated to future values of the time series directly: for example, <span class="LaTeX">$\varepsilon _{t-1}$</span> appears directly on the right side of the equation for <span class="LaTeX">$X_t$</span>. In contrast, in an AR model <span class="LaTeX">$\varepsilon _{t-1}$</span> does not appear on the right side of the <span class="LaTeX">$X_t$</span> equation, but it does appear on the right side of the <span class="LaTeX">$X_{t-1}$</span> equation, and <span class="LaTeX">$X_{t-1}$</span> appears on the right side of the <span class="LaTeX">$X_t$</span> equation, giving only an indirect effect of <span class="LaTeX">$\varepsilon_{t-1}$</span> on <span class="LaTeX">$X_t$</span>. Second, in the MA model a shock affects <span class="LaTeX">$X$</span> values only for the current period and <em>q</em> periods into the future; in contrast, in the AR model a shock affects <span class="LaTeX">$X$</span> values infinitely far into the future, because <span class="LaTeX">$\varepsilon _t$</span> affects <span class="LaTeX">$X_t$</span>, which affects <span class="LaTeX">$X_{t+1}$</span>, which affects <span class="LaTeX">$X_{t+2}$</span>, and so on forever.</p>
<h2 id="deciding-appropriateness-of-the-ma-model">Deciding appropriateness of the MA model</h2>
<p>Sometimes the <a href="autocorrelation_function" title="wikilink">autocorrelation function</a> (ACF) and <a href="partial_autocorrelation_function" title="wikilink">partial autocorrelation function</a> (PACF) will suggest that an MA model would be a better model choice and sometimes both AR and MA terms should be used in the same model (see <a href="Box-Jenkins#Identify_p_and_q" title="wikilink">Box-Jenkins#Identify p and q</a>).</p>
<h2 id="fitting-the-model">Fitting the model</h2>
<p>Fitting the MA estimates is more complicated than with <a href="autoregressive_model" title="wikilink">autoregressive models</a> (AR models) because the lagged error terms are not observable. This means that iterative <a href="Curve_fitting" title="wikilink">non-linear fitting</a> procedures need to be used in place of linear least squares.</p>
<h3 id="choosing-the-order-q">Choosing the order q</h3>
<p>The <a href="autocorrelation_function" title="wikilink">autocorrelation function</a> of an MA(<em>q</em>) process becomes zero at lag <em>q</em> + 1 and greater, so we determine the appropriate maximum lag for the estimation by examining the sample autocorrelation function to see where it becomes insignificantly different from zero for all lags beyond a certain lag, which is designated as the maximum lag <em>q</em>.</p>
<h2 id="see-also">See also</h2>
<ul>
<li><a href="Autoregressive_moving-average_model" title="wikilink">Autoregressive moving-average model</a></li>
<li><a href="Autoregressive_model" title="wikilink">Autoregressive model</a></li>
</ul>
<h2 id="further-reading">Further reading</h2>
<ul>
<li></li>
</ul>
<h2 id="external-links">External links</h2>
<ul>
<li><a href="http://www.itl.nist.gov/div898/handbook/pmc/section4/pmc444.htm">Common approaches to univariate time series</a></li>
</ul>
<p>"</p>
<p><a class="uri" href="Category:Noise" title="wikilink">Category:Noise</a> <a href="Category:Time_series_models" title="wikilink">Category:Time series models</a></p>
</body>
</html>
