<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="1039">Pseudo-random number sampling</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>Pseudo-random number sampling</h1>
<hr/>

<p><strong>Pseudo-random number sampling</strong> or <strong>non-uniform pseudo-random variate generation</strong> is the <a href="Numerical_analysis" title="wikilink">numerical</a> practice of generating <a href="pseudo-random_number" title="wikilink">pseudo-random numbers</a> that are distributed according to a given <a href="probability_distribution" title="wikilink">probability distribution</a>.</p>

<p>Methods of sampling a non-<a href="Uniform_distribution_(continuous)" title="wikilink">uniform distribution</a> are typically based on the availability of a <a href="pseudo-random_number_generator" title="wikilink">pseudo-random number generator</a> producing numbers <em>X</em> that are uniformly distributed. Computational algorithms are then used to manipulate a single <a href="random_variate" title="wikilink">random variate</a>, <em>X</em>, or often several such variates, into a new random variate <em>Y</em> such that these values have the required distribution.</p>

<p>Historically, basic methods of pseudo-random number sampling were developed for <a href="Monte-Carlo_method" title="wikilink">Monte-Carlo simulations</a> in the <a href="Manhattan_project" title="wikilink">Manhattan project</a>; they were first published by <a href="John_von_Neumann" title="wikilink">John von Neumann</a> in the early 1950s.</p>
<h2 id="finite-discrete-distributions">Finite discrete distributions</h2>

<p>For a <a href="discrete_probability_distribution" title="wikilink">discrete probability distribution</a> with a finite number <em>n</em> of indices at which the <a href="probability_mass_function" title="wikilink">probability mass function</a> <em>f</em> takes non-zero values, the basic sampling algorithm is straightforward. The interval [0, 1) is divided in <em>n</em> intervals [0, <em>f</em>(1)), [<em>f</em>(1), <em>f</em>(1) + <em>f</em>(2)), ... The width of interval <em>i</em> equals the probability <em>f</em>(<em>i</em>). One draws a uniformly distributed pseudo-random number <em>X</em>, and searches for the index <em>i</em> of the corresponding interval. The so determined <em>i</em> will have the distribution <em>f</em>(<em>i</em>).</p>

<p>Formalizing this idea becomes easier by using the cumulative distribution function</p>

<p>

<math display="block" id="Pseudo-random_number_sampling:0">
 <semantics>
  <mrow>
   <mrow>
    <mrow>
     <mi>F</mi>
     <mrow>
      <mo stretchy="false">(</mo>
      <mi>i</mi>
      <mo stretchy="false">)</mo>
     </mrow>
    </mrow>
    <mo>=</mo>
    <mrow>
     <munderover>
      <mo largeop="true" movablelimits="false" symmetric="true">∑</mo>
      <mrow>
       <mi>j</mi>
       <mo>=</mo>
       <mn>1</mn>
      </mrow>
      <mi>i</mi>
     </munderover>
     <mrow>
      <mi>f</mi>
      <mrow>
       <mo stretchy="false">(</mo>
       <mi>j</mi>
       <mo stretchy="false">)</mo>
      </mrow>
     </mrow>
    </mrow>
   </mrow>
   <mo>.</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <times></times>
     <ci>F</ci>
     <ci>i</ci>
    </apply>
    <apply>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <sum></sum>
       <apply>
        <eq></eq>
        <ci>j</ci>
        <cn type="integer">1</cn>
       </apply>
      </apply>
      <ci>i</ci>
     </apply>
     <apply>
      <times></times>
      <ci>f</ci>
      <ci>j</ci>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   F(i)=\sum_{j=1}^{i}f(j).
  </annotation>
 </semantics>
</math>

 It is convenient to set <em>F</em>(0) = 0. The <em>n</em> intervals are then simply [<em>F</em>(0), <em>F</em>(1)), [<em>F</em>(1), <em>F</em>(2)), ..., [<em>F</em>(<em>n</em> − 1), <em>F</em>(<em>n</em>)). The main computational task is then to determine <em>i</em> for which <em>F</em>(<em>i</em> − 1) ≤ <em>X</em> Ripley (1987)  also called the <em>cutpoint method</em>.<a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a></p>
<ul>
<li><a href="Alias_method" title="wikilink">Alias method</a>, computational time is constant, using some pre-computed tables.</li>
<li>There are other methods that cost constant time.<a class="footnoteRef" href="#fn2" id="fnref2"><sup>2</sup></a></li>
</ul>
<h2 id="continuous-distributions">Continuous distributions</h2>

<p>Generic methods for generating <a href="statistical_independence" title="wikilink">independent</a> samples:</p>
<ul>
<li><a href="Rejection_sampling" title="wikilink">Rejection sampling</a> for arbitrary density functions</li>
<li><a href="Inverse_transform_sampling" title="wikilink">Inverse transform sampling</a> for distributions whose CDF is known</li>
<li><a href="Slice_sampling" title="wikilink">Slice sampling</a></li>
<li><a href="Ziggurat_algorithm" title="wikilink">Ziggurat algorithm</a>, for monotonously decreasing density functions as well as symmetric unimodal distributions</li>
<li><a href="Convolution_random_number_generator" title="wikilink">Convolution random number generator</a>, not a sampling method in itself: it describes the use of arithmetics on top of one or more existing sampling methods to generate more involved distributions.</li>
</ul>

<p>Generic methods for generating <a class="uri" href="correlated" title="wikilink">correlated</a> samples (often necessary for unusually-shaped or high-dimensional distributions):</p>
<ul>
<li><a href="Markov_chain_Monte_Carlo" title="wikilink">Markov chain Monte Carlo</a>, the general principle</li>
<li><a href="Metropolis–Hastings_algorithm" title="wikilink">Metropolis–Hastings algorithm</a></li>
<li><a href="Gibbs_sampling" title="wikilink">Gibbs sampling</a></li>
<li><a href="Slice_sampling" title="wikilink">Slice sampling</a></li>
<li><a href="Reversible-jump_Markov_chain_Monte_Carlo" title="wikilink">Reversible-jump Markov chain Monte Carlo</a>, when the number of dimensions is not fixed (e.g. when estimating a <a href="mixture_model" title="wikilink">mixture model</a> and simultaneously estimating the number of mixture components)</li>
<li><a href="Particle_filter" title="wikilink">Particle filters</a>, when the observed data is connected in a <a href="Markov_chain" title="wikilink">Markov chain</a> and should be processed sequentially</li>
</ul>

<p>For generating a <a href="normal_distribution" title="wikilink">normal distribution</a>:</p>
<ul>
<li><a href="Box–Muller_transform" title="wikilink">Box–Muller transform</a></li>
<li><a href="Marsaglia_polar_method" title="wikilink">Marsaglia polar method</a></li>
</ul>

<p>For generating a <a href="Poisson_distribution" title="wikilink">Poisson distribution</a>:</p>
<ul>
<li>See <a href="Poisson_distribution#Generating_Poisson-distributed_random_variables" title="wikilink">Poisson distribution#Generating Poisson-distributed random variables</a></li>
</ul>
<h2 id="software-libraries">Software Libraries</h2>

<p><a href="GNU_Scientific_Library" title="wikilink">GNU Scientific Library</a> has a section entitled "Random Number Distributions" with routines for sampling under more than twenty different distributions.</p>
<h2 id="footnotes">Footnotes</h2>
<h2 id="literature">Literature</h2>
<ul>
<li>Devroye, L. (1986) <em>Non-Uniform Random Variate Generation.</em> New York: Springer</li>
<li>Fishman, G.S. (1996) <em>Monte Carlo. Concepts, Algorithms, and Applications.</em> New York: Springer</li>
<li>Hörmann, W.; J Leydold, G Derflinger (2004,2011) <em>Automatic Nonuniform Random Variate Generation.</em> Berlin: Springer.</li>
<li><a href="Donald_Knuth" title="wikilink">Knuth, D.E.</a> (1997) <em><a href="The_Art_of_Computer_Programming" title="wikilink">The Art of Computer Programming</a></em>, Vol. 2 <em>Seminumerical Algorithms</em>, Chapter 3.4.1 (3rd edition).</li>
<li>Ripley, B.D. (1987) <em>Stochastic Simulation</em>. Wiley.</li>
</ul>

<p>"</p>

<p><a href="Category:Pseudorandom_number_generators" title="wikilink">Category:Pseudorandom number generators</a> <a href="Category:Non-uniform_random_numbers" title="wikilink">Category:Non-uniform random numbers</a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1">Fishman (1996) <a href="#fnref1">↩</a></li>
<li id="fn2">Fishman (1996) <a href="#fnref2">↩</a></li>
</ol>
</section>
</body>
</html>
