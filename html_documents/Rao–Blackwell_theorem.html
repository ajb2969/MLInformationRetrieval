<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="630">Rao–Blackwell theorem</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>Rao–Blackwell theorem</h1>
<hr/>

<p>In <a class="uri" href="statistics" title="wikilink">statistics</a>, the <strong>Rao–Blackwell theorem</strong>, sometimes referred to as the <strong>Rao–Blackwell–Kolmogorov theorem</strong>, is a result which characterizes the transformation of an arbitrarily crude <a class="uri" href="estimator" title="wikilink">estimator</a> into an estimator that is optimal by the <a href="mean_squared_error" title="wikilink">mean-squared-error</a> criterion or any of a variety of similar criteria.</p>

<p>The Rao–Blackwell theorem states that if <em>g</em>(<em>X</em>) is any kind of <a class="uri" href="estimator" title="wikilink">estimator</a> of a parameter θ, then the <a href="conditional_expectation" title="wikilink">conditional expectation</a> of <em>g</em>(<em>X</em>) given <em>T</em>(<em>X</em>), where <em>T</em> is a <a href="sufficient_statistic" title="wikilink">sufficient statistic</a>, is typically a better estimator of θ, and is never worse. Sometimes one can very easily construct a very crude estimator <em>g</em>(<em>X</em>), and then evaluate that conditional expected value to get an estimator that is in various senses optimal.</p>

<p>The theorem is named after <a href="Calyampudi_Radhakrishna_Rao" title="wikilink">Calyampudi Radhakrishna Rao</a> and <a href="David_Blackwell" title="wikilink">David Blackwell</a>. The process of transforming an estimator using the Rao–Blackwell theorem is sometimes called <strong>Rao–Blackwellization</strong>. The transformed <a class="uri" href="estimator" title="wikilink">estimator</a> is called the <strong>Rao–Blackwell estimator</strong>.</p>
<h2 id="definitions">Definitions</h2>
<ul>
<li>An <a class="uri" href="estimator" title="wikilink">estimator</a> δ(<em>X</em>) is an <em>observable</em> random variable (i.e. a <a class="uri" href="statistic" title="wikilink">statistic</a>) used for estimating some <em>unobservable</em> quantity. For example, one may be unable to observe the average height of <em>all</em> male students at the University of X, but one may observe the heights of a random sample of 40 of them. The average height of those 40—the "sample average"—may be used as an estimator of the unobservable "population average".</li>
</ul>
<ul>
<li>A <a href="sufficiency_(statistics)" title="wikilink">sufficient statistic</a> <em>T</em>(<em>X</em>) is a statistic calculated from data <em>X</em> to estimate some parameter θ for which it is true that no other statistic which can be calculated from data X provides any additional information about θ. It is defined as an <em>observable</em> <a href="random_variable" title="wikilink">random variable</a> such that the <a href="conditional_probability" title="wikilink">conditional probability</a> distribution of all observable data <em>X</em> given <em>T</em>(<em>X</em>) does not depend on the <em>unobservable</em> parameter θ, such as the mean or standard deviation of the whole population from which the data <em>X</em> was taken. In the most frequently cited examples, the "unobservable" quantities are parameters that parametrize a known family of <a href="probability_distribution" title="wikilink">probability distributions</a> according to which the data are distributed.</li>
</ul>
<dl>
<dd><dl>
<dd>In other words, a <a href="sufficiency_(statistics)" title="wikilink">sufficient statistic</a> <em>T(X)</em> for a parameter θ is a <a class="uri" href="statistic" title="wikilink">statistic</a> such that the <a href="conditional_probability" title="wikilink">conditional distribution</a> of the data <em>X</em>, given <em>T</em>(<em>X</em>), does not depend on the parameter θ.
</dd>
</dl>
</dd>
</dl>
<ul>
<li>A <strong>Rao–Blackwell estimator</strong> δ<sub>1</sub>(<em>X</em>) of an unobservable quantity θ is the conditional <a href="expected_value" title="wikilink">expected value</a> E(δ(<em>X</em>) | <em>T</em>(<em>X</em>)) of some estimator δ(<em>X</em>) given a sufficient statistic <em>T</em>(<em>X</em>). Call δ(<em>X</em>) the <strong>"original estimator"</strong> and δ<sub>1</sub>(<em>X</em>) the <strong>"improved estimator"</strong>. It is important that the improved estimator be <em>observable</em>, i.e. that it not depend on θ. Generally, the conditional expected value of one function of these data given another function of these data <em>does</em> depend on θ, but the very definition of sufficiency given above entails that this one does not.</li>
</ul>
<ul>
<li>The <em><a href="mean_squared_error" title="wikilink">mean squared error</a></em> of an estimator is the expected value of the square of its deviation from the unobservable quantity being estimated.</li>
</ul>
<h2 id="the-theorem">The theorem</h2>
<h3 id="mean-squared-error-version">Mean-squared-error version</h3>

<p>One case of Rao–Blackwell theorem states:</p>
<dl>
<dd>The mean squared error of the Rao–Blackwell estimator does not exceed that of the original estimator.
</dd>
</dl>

<p>In other words</p>

<p>

<math display="block" id="Rao–Blackwell_theorem:0">
 <semantics>
  <mrow>
   <mrow>
    <mrow>
     <mo>E</mo>
     <mrow>
      <mo stretchy="false">(</mo>
      <msup>
       <mrow>
        <mo stretchy="false">(</mo>
        <mrow>
         <mrow>
          <msub>
           <mi>δ</mi>
           <mn>1</mn>
          </msub>
          <mrow>
           <mo stretchy="false">(</mo>
           <mi>X</mi>
           <mo stretchy="false">)</mo>
          </mrow>
         </mrow>
         <mo>-</mo>
         <mi>θ</mi>
        </mrow>
        <mo stretchy="false">)</mo>
       </mrow>
       <mn>2</mn>
      </msup>
      <mo stretchy="false">)</mo>
     </mrow>
    </mrow>
    <mo>≤</mo>
    <mrow>
     <mo>E</mo>
     <mrow>
      <mo stretchy="false">(</mo>
      <msup>
       <mrow>
        <mo stretchy="false">(</mo>
        <mrow>
         <mrow>
          <mi>δ</mi>
          <mrow>
           <mo stretchy="false">(</mo>
           <mi>X</mi>
           <mo stretchy="false">)</mo>
          </mrow>
         </mrow>
         <mo>-</mo>
         <mi>θ</mi>
        </mrow>
        <mo stretchy="false">)</mo>
       </mrow>
       <mn>2</mn>
      </msup>
      <mo stretchy="false">)</mo>
     </mrow>
    </mrow>
   </mrow>
   <mo>.</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <leq></leq>
    <apply>
     <ci>normal-E</ci>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <apply>
       <minus></minus>
       <apply>
        <times></times>
        <apply>
         <csymbol cd="ambiguous">subscript</csymbol>
         <ci>δ</ci>
         <cn type="integer">1</cn>
        </apply>
        <ci>X</ci>
       </apply>
       <ci>θ</ci>
      </apply>
      <cn type="integer">2</cn>
     </apply>
    </apply>
    <apply>
     <ci>normal-E</ci>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <apply>
       <minus></minus>
       <apply>
        <times></times>
        <ci>δ</ci>
        <ci>X</ci>
       </apply>
       <ci>θ</ci>
      </apply>
      <cn type="integer">2</cn>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \operatorname{E}((\delta_{1}(X)-\theta)^{2})\leq\operatorname{E}((\delta(X)-%
\theta)^{2}).\,\!
  </annotation>
 </semantics>
</math>

</p>

<p>The essential tools of the proof besides the definition above are the <a href="law_of_total_expectation" title="wikilink">law of total expectation</a> and the fact that for any random variable <em>Y</em>, E(<em>Y</em><sup>2</sup>) cannot be less than [E(<em>Y</em>)]<sup>2</sup>. That inequality is a case of <a href="Jensen's_inequality" title="wikilink">Jensen's inequality</a>, although it may also be shown to follow instantly from the frequently mentioned fact that</p>

<p>

<math display="block" id="Rao–Blackwell_theorem:1">
 <semantics>
  <mrow>
   <mrow>
    <mn>0</mn>
    <mo>≤</mo>
    <mrow>
     <mo>Var</mo>
     <mrow>
      <mo stretchy="false">(</mo>
      <mi>Y</mi>
      <mo stretchy="false">)</mo>
     </mrow>
    </mrow>
    <mo>=</mo>
    <mrow>
     <mo>E</mo>
     <mrow>
      <mo stretchy="false">(</mo>
      <msup>
       <mrow>
        <mo stretchy="false">(</mo>
        <mrow>
         <mi>Y</mi>
         <mo>-</mo>
         <mrow>
          <mo>E</mo>
          <mrow>
           <mo stretchy="false">(</mo>
           <mi>Y</mi>
           <mo stretchy="false">)</mo>
          </mrow>
         </mrow>
        </mrow>
        <mo stretchy="false">)</mo>
       </mrow>
       <mn>2</mn>
      </msup>
      <mo stretchy="false">)</mo>
     </mrow>
    </mrow>
    <mo>=</mo>
    <mrow>
     <mrow>
      <mo>E</mo>
      <mrow>
       <mo stretchy="false">(</mo>
       <msup>
        <mi>Y</mi>
        <mn>2</mn>
       </msup>
       <mo stretchy="false">)</mo>
      </mrow>
     </mrow>
     <mo>-</mo>
     <msup>
      <mrow>
       <mo stretchy="false">(</mo>
       <mrow>
        <mo>E</mo>
        <mrow>
         <mo stretchy="false">(</mo>
         <mi>Y</mi>
         <mo stretchy="false">)</mo>
        </mrow>
       </mrow>
       <mo stretchy="false">)</mo>
      </mrow>
      <mn>2</mn>
     </msup>
    </mrow>
   </mrow>
   <mo>.</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <and></and>
    <apply>
     <leq></leq>
     <cn type="integer">0</cn>
     <apply>
      <ci>Var</ci>
      <ci>Y</ci>
     </apply>
    </apply>
    <apply>
     <eq></eq>
     <share href="#.cmml">
     </share>
     <apply>
      <ci>normal-E</ci>
      <apply>
       <csymbol cd="ambiguous">superscript</csymbol>
       <apply>
        <minus></minus>
        <ci>Y</ci>
        <apply>
         <ci>normal-E</ci>
         <ci>Y</ci>
        </apply>
       </apply>
       <cn type="integer">2</cn>
      </apply>
     </apply>
    </apply>
    <apply>
     <eq></eq>
     <share href="#.cmml">
     </share>
     <apply>
      <minus></minus>
      <apply>
       <ci>normal-E</ci>
       <apply>
        <csymbol cd="ambiguous">superscript</csymbol>
        <ci>Y</ci>
        <cn type="integer">2</cn>
       </apply>
      </apply>
      <apply>
       <csymbol cd="ambiguous">superscript</csymbol>
       <apply>
        <ci>normal-E</ci>
        <ci>Y</ci>
       </apply>
       <cn type="integer">2</cn>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   0\leq\operatorname{Var}(Y)=\operatorname{E}((Y-\operatorname{E}(Y))^{2})=%
\operatorname{E}(Y^{2})-(\operatorname{E}(Y))^{2}.\,\!
  </annotation>
 </semantics>
</math>

</p>
<h3 id="convex-loss-generalization">Convex loss generalization</h3>

<p>The more general version of the Rao–Blackwell theorem speaks of the "expected loss" or <a href="risk_function" title="wikilink">risk function</a>:</p>

<p>

<math display="block" id="Rao–Blackwell_theorem:2">
 <semantics>
  <mrow>
   <mrow>
    <mo>E</mo>
    <mrow>
     <mo stretchy="false">(</mo>
     <mrow>
      <mi>L</mi>
      <mrow>
       <mo stretchy="false">(</mo>
       <mrow>
        <msub>
         <mi>δ</mi>
         <mn>1</mn>
        </msub>
        <mrow>
         <mo stretchy="false">(</mo>
         <mi>X</mi>
         <mo stretchy="false">)</mo>
        </mrow>
       </mrow>
       <mo stretchy="false">)</mo>
      </mrow>
     </mrow>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
   <mo>≤</mo>
   <mrow>
    <mo>E</mo>
    <mrow>
     <mo stretchy="false">(</mo>
     <mrow>
      <mi>L</mi>
      <mrow>
       <mo stretchy="false">(</mo>
       <mrow>
        <mi>δ</mi>
        <mrow>
         <mo stretchy="false">(</mo>
         <mi>X</mi>
         <mo stretchy="false">)</mo>
        </mrow>
       </mrow>
       <mo stretchy="false">)</mo>
      </mrow>
     </mrow>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <leq></leq>
    <apply>
     <ci>normal-E</ci>
     <apply>
      <times></times>
      <ci>L</ci>
      <apply>
       <times></times>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <ci>δ</ci>
        <cn type="integer">1</cn>
       </apply>
       <ci>X</ci>
      </apply>
     </apply>
    </apply>
    <apply>
     <ci>normal-E</ci>
     <apply>
      <times></times>
      <ci>L</ci>
      <apply>
       <times></times>
       <ci>δ</ci>
       <ci>X</ci>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \operatorname{E}(L(\delta_{1}(X)))\leq\operatorname{E}(L(\delta(X)))\,\!
  </annotation>
 </semantics>
</math>

</p>

<p>where the "loss function" <em>L</em> may be any <a href="convex_function" title="wikilink">convex function</a>. For the proof of the more general version, Jensen's inequality cannot be dispensed with.</p>
<h2 id="properties">Properties</h2>

<p>The improved estimator is <a href="bias_of_an_estimator" title="wikilink">unbiased</a> if and only if the original estimator is unbiased, as may be seen at once by using the <a href="law_of_total_expectation" title="wikilink">law of total expectation</a>. The theorem holds regardless of whether biased or unbiased estimators are used.</p>

<p>The theorem seems very weak: it says only that the Rao–Blackwell estimator is no worse than the original estimator. In practice, however, the improvement is often enormous.</p>
<h2 id="example">Example</h2>

<p>Phone calls arrive at a switchboard according to a <a href="Poisson_process" title="wikilink">Poisson process</a> at an average rate of λ per minute. This rate is not observable, but the numbers <em>X</em><sub>1</sub>, ..., <em>X</em><sub><em>n</em></sub> of phone calls that arrived during <em>n</em> successive one-minute periods are observed. It is desired to estimate the probability <em>e</em><sup>−λ</sup> that the next one-minute period passes with no phone calls.</p>

<p>An <em>extremely</em> crude estimator of the desired probability is</p>

<p>

<math display="block" id="Rao–Blackwell_theorem:3">
 <semantics>
  <mrow>
   <msub>
    <mi>δ</mi>
    <mn>0</mn>
   </msub>
   <mo>=</mo>
   <mrow>
    <mo>{</mo>
    <mtable displaystyle="true">
     <mtr>
      <mtd columnalign="center">
       <mn>1</mn>
      </mtd>
      <mtd columnalign="center">
       <mrow>
        <mrow>
         <mrow>
          <mpadded width="+5pt">
           <mtext>if</mtext>
          </mpadded>
          <msub>
           <mi>X</mi>
           <mn>1</mn>
          </msub>
         </mrow>
         <mo>=</mo>
         <mn>0</mn>
        </mrow>
        <mo>,</mo>
       </mrow>
      </mtd>
     </mtr>
     <mtr>
      <mtd columnalign="center">
       <mn>0</mn>
      </mtd>
      <mtd columnalign="center">
       <mtext>otherwise,</mtext>
      </mtd>
     </mtr>
    </mtable>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <cerror>
    <csymbol cd="ambiguous">fragments</csymbol>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>δ</ci>
     <cn type="integer">0</cn>
    </apply>
    <eq></eq>
    <cerror>
     <csymbol cd="ambiguous">fragments</csymbol>
     <ci>normal-{</ci>
     <matrix>
      <matrixrow>
       <cn type="integer">1</cn>
       <apply>
        <eq></eq>
        <apply>
         <times></times>
         <mtext>if</mtext>
         <apply>
          <csymbol cd="ambiguous">subscript</csymbol>
          <ci>X</ci>
          <cn type="integer">1</cn>
         </apply>
        </apply>
        <cn type="integer">0</cn>
       </apply>
      </matrixrow>
      <matrixrow>
       <cn type="integer">0</cn>
       <mtext>otherwise,</mtext>
      </matrixrow>
     </matrix>
    </cerror>
   </cerror>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \delta_{0}=\left\{\begin{matrix}1&\text{if}\ X_{1}=0,\\
0&\text{otherwise,}\end{matrix}\right.
  </annotation>
 </semantics>
</math>

</p>

<p>i.e., it estimates this probability to be 1 if no phone calls arrived in the first minute and zero otherwise. Despite the apparent limitations of this estimator, the result given by its Rao–Blackwellization is a very good estimator.</p>

<p>The sum</p>

<p>

<math display="block" id="Rao–Blackwell_theorem:4">
 <semantics>
  <mrow>
   <msub>
    <mi>S</mi>
    <mi>n</mi>
   </msub>
   <mo>=</mo>
   <mrow>
    <munderover>
     <mo largeop="true" movablelimits="false" symmetric="true">∑</mo>
     <mrow>
      <mi>i</mi>
      <mo>=</mo>
      <mn>1</mn>
     </mrow>
     <mi>n</mi>
    </munderover>
    <msub>
     <mi>X</mi>
     <mi>i</mi>
    </msub>
   </mrow>
   <mo>=</mo>
   <mrow>
    <msub>
     <mi>X</mi>
     <mn>1</mn>
    </msub>
    <mo>+</mo>
    <mi mathvariant="normal">⋯</mi>
    <mo>+</mo>
    <msub>
     <mi>X</mi>
     <mi>n</mi>
    </msub>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <and></and>
    <apply>
     <eq></eq>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>S</ci>
      <ci>n</ci>
     </apply>
     <apply>
      <apply>
       <csymbol cd="ambiguous">superscript</csymbol>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <sum></sum>
        <apply>
         <eq></eq>
         <ci>i</ci>
         <cn type="integer">1</cn>
        </apply>
       </apply>
       <ci>n</ci>
      </apply>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>X</ci>
       <ci>i</ci>
      </apply>
     </apply>
    </apply>
    <apply>
     <eq></eq>
     <share href="#.cmml">
     </share>
     <apply>
      <plus></plus>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>X</ci>
       <cn type="integer">1</cn>
      </apply>
      <ci>normal-⋯</ci>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>X</ci>
       <ci>n</ci>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   S_{n}=\sum_{i=1}^{n}X_{i}=X_{1}+\cdots+X_{n}\,\!
  </annotation>
 </semantics>
</math>

</p>

<p>can be readily shown to be a sufficient statistic for λ, i.e., the <em>conditional</em> distribution of the data <em>X</em><sub>1</sub>, ..., <em>X</em><sub><em>n</em></sub>, depends on λ only through this sum. Therefore, we find the Rao–Blackwell estimator</p>

<p>

<math display="block" id="Rao–Blackwell_theorem:5">
 <semantics>
  <mrow>
   <mrow>
    <msub>
     <mi>δ</mi>
     <mn>1</mn>
    </msub>
    <mo>=</mo>
    <mrow>
     <mo>E</mo>
     <mrow>
      <mo stretchy="false">(</mo>
      <msub>
       <mi>δ</mi>
       <mn>0</mn>
      </msub>
      <mo>∣</mo>
      <mrow>
       <msub>
        <mi>S</mi>
        <mi>n</mi>
       </msub>
       <mo>=</mo>
       <msub>
        <mi>s</mi>
        <mi>n</mi>
       </msub>
      </mrow>
      <mo stretchy="false">)</mo>
     </mrow>
    </mrow>
   </mrow>
   <mo>.</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>δ</ci>
     <cn type="integer">1</cn>
    </apply>
    <apply>
     <ci>normal-E</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>δ</ci>
      <cn type="integer">0</cn>
     </apply>
     <apply>
      <eq></eq>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>S</ci>
       <ci>n</ci>
      </apply>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>s</ci>
       <ci>n</ci>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \delta_{1}=\operatorname{E}(\delta_{0}\mid S_{n}=s_{n}).
  </annotation>
 </semantics>
</math>

</p>

<p>After doing some algebra we have</p>

<p>

<math display="inline" id="Rao–Blackwell_theorem:6">
 <semantics>
  <msub>
   <mi>δ</mi>
   <mn>1</mn>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>δ</ci>
    <cn type="integer">1</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \displaystyle\delta_{1}
  </annotation>
 </semantics>
</math>


</p>

<p>Since the average number of calls arriving during the first <em>n</em> minutes is <em>n</em>λ, one might not be surprised if this estimator has a fairly high probability (if <em>n</em> is big) of being close to</p>

<p>

<math display="block" id="Rao–Blackwell_theorem:7">
 <semantics>
  <mrow>
   <mrow>
    <msup>
     <mrow>
      <mo>(</mo>
      <mrow>
       <mn>1</mn>
       <mo>-</mo>
       <mfrac>
        <mn>1</mn>
        <mi>n</mi>
       </mfrac>
      </mrow>
      <mo>)</mo>
     </mrow>
     <mrow>
      <mi>n</mi>
      <mi>λ</mi>
     </mrow>
    </msup>
    <mo>≈</mo>
    <msup>
     <mi>e</mi>
     <mrow>
      <mo>-</mo>
      <mi>λ</mi>
     </mrow>
    </msup>
   </mrow>
   <mo>.</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <approx></approx>
    <apply>
     <csymbol cd="ambiguous">superscript</csymbol>
     <apply>
      <minus></minus>
      <cn type="integer">1</cn>
      <apply>
       <divide></divide>
       <cn type="integer">1</cn>
       <ci>n</ci>
      </apply>
     </apply>
     <apply>
      <times></times>
      <ci>n</ci>
      <ci>λ</ci>
     </apply>
    </apply>
    <apply>
     <csymbol cd="ambiguous">superscript</csymbol>
     <ci>e</ci>
     <apply>
      <minus></minus>
      <ci>λ</ci>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \left(1-{1\over n}\right)^{n\lambda}\approx e^{-\lambda}.
  </annotation>
 </semantics>
</math>

</p>

<p>So δ<sub>1</sub> is clearly a very much improved estimator of that last quantity. In fact, since <em>S</em><sub><em>n</em></sub> is <a href="completeness_(statistics)" title="wikilink">complete</a> and δ<sub>0</sub> is unbiased, δ<sub>1</sub> is the unique minimum variance unbiased estimator by the <a href="Lehmann–Scheffé_theorem" title="wikilink">Lehmann–Scheffé theorem</a>.</p>
<h2 id="idempotence">Idempotence</h2>

<p>The Rao–Blackwell process is <a class="uri" href="idempotent" title="wikilink">idempotent</a>. Using it to improve the already improved estimator does not obtain a further improvement, but merely returns as its output the same improved estimator.</p>
<h2 id="completeness-and-lehmannscheffé-minimum-variance">Completeness and Lehmann–Scheffé minimum variance</h2>

<p>If the conditioning statistic is both complete and sufficient, and the starting estimator is unbiased, then the Rao–Blackwell estimator is the unique "<a href="minimum-variance_unbiased_estimator" title="wikilink">best unbiased estimator</a>": see <a href="Lehmann–Scheffé_theorem" title="wikilink">Lehmann–Scheffé theorem</a>.</p>
<h2 id="see-also">See also</h2>
<ul>
<li><a href="Basu's_theorem" title="wikilink">Basu's theorem</a> — Another result on complete sufficient and ancillary statistics</li>
<li><a href="C._R._Rao" title="wikilink">C. R. Rao</a></li>
<li><a href="David_Blackwell" title="wikilink">David Blackwell</a></li>
</ul>
<h2 id="references">References</h2>
<ul>
<li></li>
<li></li>
</ul>
<ul>
<li>Radhakrishna Rao, C. "Information and accuracy attainable in the estimation of statistical parameters." Bulletin of the Calcutta Mathematical Society 37, no. 3 (1945): 81-91.</li>
</ul>
<h2 id="external-links">External links</h2>
<ul>
<li></li>
</ul>

<p>"</p>

<p><a href="Category:Statistical_theorems" title="wikilink">Category:Statistical theorems</a> <a href="Category:Estimation_theory" title="wikilink">Category:Estimation theory</a></p>
</body>
</html>
