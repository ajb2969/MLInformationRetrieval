<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="836">Maximum likelihood sequence estimation</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>Maximum likelihood sequence estimation</h1>
<hr/>

<p><strong>Maximum likelihood sequence estimation</strong> (<strong>MLSE</strong>) is a mathematical algorithm to extract useful data out of a noisy data stream.</p>
<h2 id="theory">Theory</h2>

<p>For an optimized detector for digital signals the priority is not to reconstruct the transmitter signal, but it should do a best estimation of the transmitted data with the least possible number of errors. The receiver emulates the distorted channel. All possible transmitted data streams are fed into this distorted channel model. The receiver compares the time response with the actual received signal and determines the most likely signal. In cases that are most computationally straightforward, <a href="root_mean_square_deviation" title="wikilink">root mean square deviation</a> can be used as the decision criterion<a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a> for the lowest error probability.</p>
<h2 id="background">Background</h2>

<p>Suppose that there is an underlying signal {<em>x</em>(<em>t</em>)}, of which an observed signal {<em>r</em>(<em>t</em>)} is available. The observed signal <em>r</em> is related to <em>x</em> via a transformation that may be nonlinear and may involve attenuation, and would usually involve the incorporation of <a href="random_noise" title="wikilink">random noise</a>. The <a href="statistical_parameter" title="wikilink">statistical parameters</a> of this transformation are assumed known. The problem to be solved is to use the observations {<em>r</em>(<em>t</em>)} to create a good estimate of {<em>x</em>(<em>t</em>)}.</p>

<p>Maximum likelihood sequence estimation is formally the application of <a href="maximum_likelihood" title="wikilink">maximum likelihood</a> to this problem. That is, the estimate of {<em>x</em>(<em>t</em>)} is defined to be sequence of values which maximize the functional</p>

<p>

<math display="block" id="Maximum_likelihood_sequence_estimation:0">
 <semantics>
  <mrow>
   <mi>L</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <mi>x</mi>
    <mo stretchy="false">)</mo>
   </mrow>
   <mo>=</mo>
   <mi>p</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <mi>r</mi>
    <mo>∣</mo>
    <mi>x</mi>
    <mo stretchy="false">)</mo>
   </mrow>
   <mo>,</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <cerror>
    <csymbol cd="ambiguous">fragments</csymbol>
    <csymbol cd="unknown">L</csymbol>
    <cerror>
     <csymbol cd="ambiguous">fragments</csymbol>
     <ci>normal-(</ci>
     <csymbol cd="unknown">x</csymbol>
     <ci>normal-)</ci>
    </cerror>
    <eq></eq>
    <csymbol cd="unknown">p</csymbol>
    <cerror>
     <csymbol cd="ambiguous">fragments</csymbol>
     <ci>normal-(</ci>
     <csymbol cd="unknown">r</csymbol>
     <ci>normal-∣</ci>
     <csymbol cd="unknown">x</csymbol>
     <ci>normal-)</ci>
    </cerror>
    <ci>normal-,</ci>
   </cerror>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   L(x)=p(r\mid x),
  </annotation>
 </semantics>
</math>

 where <em>p</em>(<em>r</em> | <em>x</em>) denotes the conditional joint probability density function of the observed series {<em>r</em>(<em>t</em>)} given that the underlying series has the values {<em>x</em>(<em>t</em>)}.</p>

<p>In contrast, the related method of maximum a posteriori estimation is formally the application of the <a href="maximum_a_posteriori" title="wikilink">maximum a posteriori</a> (MAP) estimation approach. This is more complex than maximum likelihood sequence estimation and requires a known distribution (in <a href="Bayesian_inference" title="wikilink">Bayesian terms</a>, a <a href="prior_distribution" title="wikilink">prior distribution</a>) for the underlying signal. In this case the estimate of {<em>x</em>(<em>t</em>)} is defined to be sequence of values which maximize the functional</p>

<p>

<math display="block" id="Maximum_likelihood_sequence_estimation:1">
 <semantics>
  <mrow>
   <mi>P</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <mi>x</mi>
    <mo stretchy="false">)</mo>
   </mrow>
   <mo>=</mo>
   <mi>p</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <mi>x</mi>
    <mo>∣</mo>
    <mi>r</mi>
    <mo stretchy="false">)</mo>
   </mrow>
   <mo>,</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <cerror>
    <csymbol cd="ambiguous">fragments</csymbol>
    <csymbol cd="unknown">P</csymbol>
    <cerror>
     <csymbol cd="ambiguous">fragments</csymbol>
     <ci>normal-(</ci>
     <csymbol cd="unknown">x</csymbol>
     <ci>normal-)</ci>
    </cerror>
    <eq></eq>
    <csymbol cd="unknown">p</csymbol>
    <cerror>
     <csymbol cd="ambiguous">fragments</csymbol>
     <ci>normal-(</ci>
     <csymbol cd="unknown">x</csymbol>
     <ci>normal-∣</ci>
     <csymbol cd="unknown">r</csymbol>
     <ci>normal-)</ci>
    </cerror>
    <ci>normal-,</ci>
   </cerror>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   P(x)=p(x\mid r),
  </annotation>
 </semantics>
</math>

 where <em>p</em>(<em>x</em> | <em>r</em>) denotes the conditional joint probability density function of the underlying series {<em>x</em>(<em>t</em>)} given that the observed series has taken the values {<em>r</em>(<em>t</em>)}. <a href="Bayes'_theorem" title="wikilink">Bayes' theorem</a> implies that</p>

<p>

<math display="block" id="Maximum_likelihood_sequence_estimation:2">
 <semantics>
  <mrow>
   <mi>P</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <mi>x</mi>
    <mo stretchy="false">)</mo>
   </mrow>
   <mo>=</mo>
   <mi>p</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <mi>x</mi>
    <mo>∣</mo>
    <mi>r</mi>
    <mo stretchy="false">)</mo>
   </mrow>
   <mo>=</mo>
   <mfrac>
    <mrow>
     <mi>p</mi>
     <mrow>
      <mo stretchy="false">(</mo>
      <mi>r</mi>
      <mo>∣</mo>
      <mi>x</mi>
      <mo stretchy="false">)</mo>
     </mrow>
     <mi>p</mi>
     <mrow>
      <mo stretchy="false">(</mo>
      <mi>x</mi>
      <mo stretchy="false">)</mo>
     </mrow>
    </mrow>
    <mrow>
     <mi>p</mi>
     <mrow>
      <mo stretchy="false">(</mo>
      <mi>r</mi>
      <mo stretchy="false">)</mo>
     </mrow>
    </mrow>
   </mfrac>
   <mo>.</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <cerror>
    <csymbol cd="ambiguous">fragments</csymbol>
    <csymbol cd="unknown">P</csymbol>
    <cerror>
     <csymbol cd="ambiguous">fragments</csymbol>
     <ci>normal-(</ci>
     <csymbol cd="unknown">x</csymbol>
     <ci>normal-)</ci>
    </cerror>
    <eq></eq>
    <csymbol cd="unknown">p</csymbol>
    <cerror>
     <csymbol cd="ambiguous">fragments</csymbol>
     <ci>normal-(</ci>
     <csymbol cd="unknown">x</csymbol>
     <ci>normal-∣</ci>
     <csymbol cd="unknown">r</csymbol>
     <ci>normal-)</ci>
    </cerror>
    <eq></eq>
    <apply>
     <divide></divide>
     <cerror>
      <csymbol cd="ambiguous">fragments</csymbol>
      <csymbol cd="unknown">p</csymbol>
      <cerror>
       <csymbol cd="ambiguous">fragments</csymbol>
       <ci>normal-(</ci>
       <csymbol cd="unknown">r</csymbol>
       <ci>normal-∣</ci>
       <csymbol cd="unknown">x</csymbol>
       <ci>normal-)</ci>
      </cerror>
      <csymbol cd="unknown">p</csymbol>
      <cerror>
       <csymbol cd="ambiguous">fragments</csymbol>
       <ci>normal-(</ci>
       <csymbol cd="unknown">x</csymbol>
       <ci>normal-)</ci>
      </cerror>
     </cerror>
     <apply>
      <times></times>
      <ci>p</ci>
      <ci>r</ci>
     </apply>
    </apply>
    <ci>normal-.</ci>
   </cerror>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   P(x)=p(x\mid r)=\frac{p(r\mid x)p(x)}{p(r)}.
  </annotation>
 </semantics>
</math>

</p>

<p>In cases where the contribution of random noise is additive and has a <a href="multivariate_normal_distribution" title="wikilink">multivariate normal distribution</a>, the problem of maximum likelihood sequence estimation can be reduced to that of a <a href="least_squares" title="wikilink">least squares</a> minimization.</p>
<h2 id="see-also">See also</h2>
<ul>
<li><a href="Maximum-likelihood_estimation" title="wikilink">Maximum-likelihood estimation</a></li>
<li><a href="Partial_response_maximum_likelihood" title="wikilink">Partial response maximum likelihood</a></li>
</ul>
<h2 id="references">References</h2>
<h2 id="further-reading">Further reading</h2>
<ul>
<li></li>
<li></li>
<li>Crivelli, D. E.; Carrer, H. S., Hueda, M. R. (2005) <a href="http://www.scielo.org.ar/pdf/laar/v35n2/v35n2a04.pdf">"Performance evaluation of maximum likelihood sequence estimation receivers in lightwave systems with optical amplifiers"</a>, Latin American Applied Research'', 35 (2), 95–98.</li>
<li>Katz, G., Sadot, D., Mahlab, U., and Levy, A.(2008) "Channel estimators for maximum-likelihood sequence estimation in direct-detection optical communications", <em>Optical Engineering</em> 47 (4), 045003. </li>
</ul>
<h2 id="external-links">External links</h2>
<ul>
<li></li>
</ul>

<p>"</p>

<p><a href="Category:Telecommunications_techniques" title="wikilink">Category:Telecommunications techniques</a> <a href="Category:Error_detection_and_correction" title="wikilink">Category:Error detection and correction</a> <a href="Category:Signal_estimation" title="wikilink">Category:Signal estimation</a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1">G. Bosco, P. Poggiolini, and M. Visintin, "Performance Analysis of MLSE Receivers Based on the Square-Root Metric," J. Lightwave Technol. 26, 2098–2109 (2008)<a href="#fnref1">↩</a></li>
</ol>
</section>
</body>
</html>
