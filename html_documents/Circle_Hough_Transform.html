<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="1483">Circle Hough Transform</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>Circle Hough Transform</h1>
<hr/>

<p>The <strong>circle Hough Transform</strong> (<strong>CHT</strong>) is a <a href="feature_extraction" title="wikilink">feature extraction</a> technique for detecting circles. It is a specialization of <a href="Hough_Transform" title="wikilink">Hough Transform</a>. The purpose of the technique is to find circles in imperfect image inputs. The circle candidates are produced by “voting” in the Hough parameter space and then select the local maxima in a so-called accumulator matrix.</p>
<h2 id="theory">Theory</h2>

<p>In a two dimensional space, a circle can by described by:</p>

<p>

<math display="block" id="Circle_Hough_Transform:0">
 <semantics>
  <mrow>
   <mrow>
    <msup>
     <mrow>
      <mo>(</mo>
      <mrow>
       <mi>x</mi>
       <mo>-</mo>
       <mi>a</mi>
      </mrow>
      <mo>)</mo>
     </mrow>
     <mn>2</mn>
    </msup>
    <mo>+</mo>
    <msup>
     <mrow>
      <mo>(</mo>
      <mrow>
       <mi>y</mi>
       <mo>-</mo>
       <mi>b</mi>
      </mrow>
      <mo>)</mo>
     </mrow>
     <mn>2</mn>
    </msup>
   </mrow>
   <mo>=</mo>
   <mrow>
    <msup>
     <mi>r</mi>
     <mn>2</mn>
    </msup>
    <mrow>
     <mo stretchy="false">(</mo>
     <mn>1</mn>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <plus></plus>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <apply>
       <minus></minus>
       <ci>x</ci>
       <ci>a</ci>
      </apply>
      <cn type="integer">2</cn>
     </apply>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <apply>
       <minus></minus>
       <ci>y</ci>
       <ci>b</ci>
      </apply>
      <cn type="integer">2</cn>
     </apply>
    </apply>
    <list>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <ci>r</ci>
      <cn type="integer">2</cn>
     </apply>
     <cn type="integer">1</cn>
    </list>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \left(x-a\right)^{2}+\left(y-b\right)^{2}=r^{2}\ \ \ \ \ (1)
  </annotation>
 </semantics>
</math>

 where (a,b) is the center of the circle, and r is the radius. If a 2D point (x,y) is fixed, then the parameters can be found according to (1). The parameter space would be three dimensional, (a, b, r). And all the parameters that satisfying (x, y) would lie on the surface of an inverted right-angled cone whose apex is at (x, y, 0). In the 3D space, the circle parameters can be identified by the intersection of many conic surfaces that are defined by points on the 2D circle. This process can be divided into two stages. The first stage is fixing radius then find the optimal center of circles in a 2D parameter space. The second stage is to find the optimal radius in a one dimensional parameter space.</p>
<h3 id="find-parameters-with-known-radius-r">Find parameters with Known radius R</h3>

<p>If the radius is fixed, then the parameter space would be reduced to 2D (the position of the circle center). For each point (x, y) on the original circle, it can define a circle centered at (x, y) with radius R according to (1). The intersection point of all such circles in the parameter space would be corresponding to the center point of the original circle.</p>

<p> Consider 4 points on a circle in the original image (left). The circle Hough transform is shown in the right. Note that the radius is assumed to be known. For each (x,y) of the four points (white points) in the original image, it can define a circle in the Hough parameter space centered at (x, y) with radius r. An accumulator matrix is used for tracking the intersection point. In the parameter space, the voting number of points through which the circle passing would be increased by one. Then the local maxima point (the red point in the center in the right figure) can be found. The position (a, b) of the maxima would be the center of the original circle.</p>
<h3 id="multiple-circles-with-known-radius-r">Multiple circles with known radius R</h3>

<p>Multiple circles with same radius can be found with the same technique. </p>

<p>Note that, in the accumulator matrix (right fig), there would be at least 3 local maxima points.</p>
<h3 id="accumulator-matrix-and-voting">Accumulator matrix and voting</h3>

<p>In practice, an accumulator matrix is introduced to find the intersection point in the parameter space. First, we need to divide the parameter space into “buckets” using a grid and produce an accumulator matrix according to the grid. The element in the accumulator matrix denotes the number of “circles” in the parameter space that passing through the corresponding grid cell in the parameter space. The number is also called “voting number”. Initially, every element in the matrix is zeros. Then for each “edge” point in the original space, we can formulate a circle in the parameter space and increase the voting number of the grid cell which the circle passing through. This process is called “voting”.</p>

<p>After voting, we can find local maxima in the accumulator matrix. The positions of the local maxima are corresponding to the circle centers in the original space.</p>
<h3 id="find-circle-parameter-with-unknown-radius">Find circle parameter with unknown radius</h3>

<p>Since the parameter space is 3D, the accumulator matrix would be 3D, too. We can iterate through possible radiuses and for each radius, we use the previous technique. Finally, find the local maxima in the 3D accumulator matrix.</p>
<h2 id="examples">Examples</h2>
<h3 id="find-circles-in-shoeprint">Find circles in shoeprint</h3>
<figure><b>(Figure)</b>
<figcaption>Find circles in shoeprint</figcaption>
</figure>

<p>The original picture (right) is first turned into a binary image (left) using a threshold and Gaussian filter. Then edges (mid) are found from it using canny edge detection. After this, all the edge points are used by the Circle Hough Transform to find underlying circle structure.</p>
<h2 id="limitations">Limitations</h2>

<p>Since the parameter space of CHT is three dimensional, it may require lots of storage and computation. Choosing bigger grid size can ameliorate this problem.</p>

<p>However, choose an appropriate grid size is difficult. Since too coarse a grid can lead to large values of the vote being obtained falsely because many quite different structures correspond to a single bucket. Too fine a grid can lead to structures not being found because votes resulting from tokens that are not exactly aligned end up in different buckets, and no bucket has a large vote.</p>

<p>Also, CHT is not very robust to noise.</p>
<h2 id="extensions">Extensions</h2>
<h3 id="adaptive-hough-transform">Adaptive Hough Transform</h3>

<p>J. Illingworth and J. Kittler <a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a> introduced this method for implementing Hough Transform efficiently. The AHT uses a small accumulator array and the idea of a flexible iterative "coarse to fine" accumulation and search strategy to identify significant peaks in the Hough parameter spaces. This method is substantially superior to the standard Hough Transform implementation in both storage and computational requirements.</p>
<h2 id="application">Application</h2>
<h3 id="people-counting">People Counting</h3>

<p>Since the head would be similar to a circle in an image. CHT can be used for detecting heads in a picture, so as to count the number of persons in the image.<a class="footnoteRef" href="#fn2" id="fnref2"><sup>2</sup></a></p>
<h2 id="implementation-code">Implementation code</h2>
<ul>
<li><a class="uri" href="http://www.mathworks.com/matlabcentral/fileexchange/4985-circle-detection-via-standard-hough-transform">http://www.mathworks.com/matlabcentral/fileexchange/4985-circle-detection-via-standard-hough-transform</a></li>
<li><a class="uri" href="http://opencv-python-tutroals.readthedocs.org/en/latest/py_tutorials/py_imgproc/py_houghcircles/py_houghcircles.html">http://opencv-python-tutroals.readthedocs.org/en/latest/py_tutorials/py_imgproc/py_houghcircles/py_houghcircles.html</a></li>
</ul>
<h2 id="see-also">See also</h2>
<ul>
<li><a href="Hough_transform" title="wikilink">Hough transform</a></li>
<li><a href="Generalised_Hough_transform" title="wikilink">Generalised Hough transform</a></li>
<li><a href="Randomized_Hough_transform" title="wikilink">Randomized Hough transform</a></li>
<li><a class="uri" href="https://www.cis.rit.edu/class/simg782/lectures/lecture_10/lec782_05_10.pdf">https://www.cis.rit.edu/class/simg782/lectures/lecture_10/lec782_05_10.pdf</a></li>
</ul>
<h2 id="references">References</h2>

<p>"</p>

<p><a href="Category:Feature_detection_(computer_vision)" title="wikilink">Category:Feature detection (computer vision)</a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1">J. Illingworth and J. Kittler, “The Adaptive Hough Transform,” PAMI-9 , Issue: 5, 1987, pp 690-698<a href="#fnref1">↩</a></li>
<li id="fn2">Hong Liu, Yueliang Qian and Shouxun Lin , “DETECTING PERSONS USING HOUGH CIRCLE TRANSFORM IN SURVEILLANCE VIDEO”<a href="#fnref2">↩</a></li>
</ol>
</section>
</body>
</html>
