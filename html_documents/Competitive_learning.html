<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="1636">Competitive learning</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>Competitive learning</h1>
<hr/>

<p><strong>Competitive learning</strong> is a form of <a href="unsupervised_learning" title="wikilink">unsupervised learning</a> in <a href="artificial_neural_networks" title="wikilink">artificial neural networks</a>, in which nodes compete for the right to respond to a subset of the input data.<a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a> A variant of <a href="Hebbian_learning" title="wikilink">Hebbian learning</a>, competitive learning works by increasing the specialization of each node in the network. It is well suited to finding <a href="cluster_analysis" title="wikilink">clusters</a> within data.</p>

<p>Models and algorithms based on the principle of competitive learning include <a href="vector_quantization" title="wikilink">vector quantization</a> and <a href="self-organising_map" title="wikilink">self-organising maps</a> (Kohonen maps).</p>
<h2 id="architecture-and-implementation">Architecture and implementation</h2>
<figure><b>(Figure)</b>
<figcaption>Competitive neural network architecture</figcaption>
</figure>

<p>Competitive Learning is usually implemented with Neural Networks that contain a hidden layer which is commonly known as “competitive layer”.<a class="footnoteRef" href="#fn2" id="fnref2"><sup>2</sup></a> Every competitive neuron i is described by a vector of weights 

<math display="inline" id="Competitive_learning:0">
 <semantics>
  <mrow>
   <msub>
    <mi>𝐰</mi>
    <mi>i</mi>
   </msub>
   <mo>=</mo>
   <msup>
    <mrow>
     <mo>(</mo>
     <msub>
      <mi>w</mi>
      <mrow>
       <mi>i</mi>
       <mn>1</mn>
      </mrow>
     </msub>
     <mo>,</mo>
     <mo>.</mo>
     <mo>.</mo>
     <mo>,</mo>
     <msub>
      <mi>w</mi>
      <mrow>
       <mi>i</mi>
       <mi>d</mi>
      </mrow>
     </msub>
     <mo>)</mo>
    </mrow>
    <mi>T</mi>
   </msup>
   <mo>,</mo>
   <mi>i</mi>
   <mo>=</mo>
   <mn>1</mn>
   <mo>,</mo>
   <mo>.</mo>
   <mo>.</mo>
   <mo>,</mo>
   <mi>M</mi>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <cerror>
    <csymbol cd="ambiguous">fragments</csymbol>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>𝐰</ci>
     <ci>i</ci>
    </apply>
    <eq></eq>
    <apply>
     <csymbol cd="ambiguous">superscript</csymbol>
     <cerror>
      <csymbol cd="ambiguous">fragments</csymbol>
      <ci>normal-(</ci>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>w</ci>
       <apply>
        <times></times>
        <ci>i</ci>
        <cn type="integer">1</cn>
       </apply>
      </apply>
      <ci>normal-,</ci>
      <ci>normal-.</ci>
      <ci>normal-.</ci>
      <ci>normal-,</ci>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>w</ci>
       <apply>
        <times></times>
        <ci>i</ci>
        <ci>d</ci>
       </apply>
      </apply>
      <ci>normal-)</ci>
     </cerror>
     <ci>T</ci>
    </apply>
    <ci>normal-,</ci>
    <csymbol cd="unknown">i</csymbol>
    <eq></eq>
    <cn type="integer">1</cn>
    <ci>normal-,</ci>
    <ci>normal-.</ci>
    <ci>normal-.</ci>
    <ci>normal-,</ci>
    <csymbol cd="unknown">M</csymbol>
   </cerror>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   {\mathbf{w}}_{i}=\left({w_{i1},..,w_{id}}\right)^{T},i=1,..,M
  </annotation>
 </semantics>
</math>

 and calculates the similarity measure between the input data 

<math display="inline" id="Competitive_learning:1">
 <semantics>
  <mrow>
   <msup>
    <mi>𝐱</mi>
    <mi>n</mi>
   </msup>
   <mo>=</mo>
   <msup>
    <mrow>
     <mo>(</mo>
     <msub>
      <mi>x</mi>
      <mrow>
       <mi>n</mi>
       <mn>1</mn>
      </mrow>
     </msub>
     <mo>,</mo>
     <mo>.</mo>
     <mo>.</mo>
     <mo>,</mo>
     <msub>
      <mi>x</mi>
      <mrow>
       <mi>n</mi>
       <mi>d</mi>
      </mrow>
     </msub>
     <mo>)</mo>
    </mrow>
    <mi>T</mi>
   </msup>
   <mo>∈</mo>
   <msup>
    <mi>ℝ</mi>
    <mi>d</mi>
   </msup>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <cerror>
    <csymbol cd="ambiguous">fragments</csymbol>
    <apply>
     <csymbol cd="ambiguous">superscript</csymbol>
     <ci>𝐱</ci>
     <ci>n</ci>
    </apply>
    <eq></eq>
    <apply>
     <csymbol cd="ambiguous">superscript</csymbol>
     <cerror>
      <csymbol cd="ambiguous">fragments</csymbol>
      <ci>normal-(</ci>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>x</ci>
       <apply>
        <times></times>
        <ci>n</ci>
        <cn type="integer">1</cn>
       </apply>
      </apply>
      <ci>normal-,</ci>
      <ci>normal-.</ci>
      <ci>normal-.</ci>
      <ci>normal-,</ci>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>x</ci>
       <apply>
        <times></times>
        <ci>n</ci>
        <ci>d</ci>
       </apply>
      </apply>
      <ci>normal-)</ci>
     </cerror>
     <ci>T</ci>
    </apply>
    <in></in>
    <apply>
     <csymbol cd="ambiguous">superscript</csymbol>
     <ci>ℝ</ci>
     <ci>d</ci>
    </apply>
   </cerror>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   {\mathbf{x}}^{n}=\left({x_{n1},..,x_{nd}}\right)^{T}\in\mathbb{R}^{d}
  </annotation>
 </semantics>
</math>

 and the weight vector 

<math display="inline" id="Competitive_learning:2">
 <semantics>
  <msub>
   <mi>𝐰</mi>
   <mi>i</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>𝐰</ci>
    <ci>i</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   {\mathbf{w}}_{i}
  </annotation>
 </semantics>
</math>

 .</p>

<p>For every input vector, the competitive neurons “compete” with each other to see which one of them is the most similar to that particular input vector. The winner neuron m sets its output 

<math display="inline" id="Competitive_learning:3">
 <semantics>
  <mrow>
   <msub>
    <mi>o</mi>
    <mi>i</mi>
   </msub>
   <mo>=</mo>
   <mn>1</mn>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>o</ci>
     <ci>i</ci>
    </apply>
    <cn type="integer">1</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   o_{i}=1
  </annotation>
 </semantics>
</math>

 and all the other competitive neurons set their output 

<math display="inline" id="Competitive_learning:4">
 <semantics>
  <mrow>
   <msub>
    <mi>o</mi>
    <mi>i</mi>
   </msub>
   <mo>=</mo>
   <mn>0</mn>
   <mo>,</mo>
   <mi>i</mi>
   <mo>=</mo>
   <mn>1</mn>
   <mo>,</mo>
   <mo>.</mo>
   <mo>.</mo>
   <mo>,</mo>
   <mi>M</mi>
   <mo>,</mo>
   <mi>i</mi>
   <mo>≠</mo>
   <mi>m</mi>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <cerror>
    <csymbol cd="ambiguous">fragments</csymbol>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>o</ci>
     <ci>i</ci>
    </apply>
    <eq></eq>
    <cn type="integer">0</cn>
    <ci>normal-,</ci>
    <csymbol cd="unknown">i</csymbol>
    <eq></eq>
    <cn type="integer">1</cn>
    <ci>normal-,</ci>
    <ci>normal-.</ci>
    <ci>normal-.</ci>
    <ci>normal-,</ci>
    <csymbol cd="unknown">M</csymbol>
    <ci>normal-,</ci>
    <csymbol cd="unknown">i</csymbol>
    <neq></neq>
    <csymbol cd="unknown">m</csymbol>
   </cerror>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   o_{i}=0,i=1,..,M,i\neq m
  </annotation>
 </semantics>
</math>

.</p>

<p>Usually, in order to measure similarity the inverse of the Euclidean distance is used

<math display="block" id="Competitive_learning:5">
 <semantics>
  <mrow>
   <mo>∥</mo>
   <mrow>
    <mi>𝐱</mi>
    <mo>-</mo>
    <msub>
     <mi>𝐰</mi>
     <mi>i</mi>
    </msub>
   </mrow>
   <mo>∥</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="latexml">norm</csymbol>
    <apply>
     <minus></minus>
     <ci>𝐱</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>𝐰</ci>
      <ci>i</ci>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \left\|{{\mathbf{x}}-{\mathbf{w}}_{i}}\right\|
  </annotation>
 </semantics>
</math>

 between the input vector 

<math display="inline" id="Competitive_learning:6">
 <semantics>
  <msup>
   <mi>𝐱</mi>
   <mi>n</mi>
  </msup>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">superscript</csymbol>
    <ci>𝐱</ci>
    <ci>n</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   {\mathbf{x}}^{n}
  </annotation>
 </semantics>
</math>

 and the weight vector 

<math display="inline" id="Competitive_learning:7">
 <semantics>
  <msub>
   <mi>𝐰</mi>
   <mi>i</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>𝐰</ci>
    <ci>i</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   {\mathbf{w}}_{i}
  </annotation>
 </semantics>
</math>

.</p>
<h2 id="example-algorithm">Example algorithm</h2>

<p>Here is a simple competitive learning algorithm to find three clusters within some input data.</p>

<p>1. (Set-up.) Let a set of sensors all feed into three different nodes, so that every node is connected to every sensor. Let the weights that each node gives to its sensors be set randomly between 0.0 and 1.0. Let the output of each node be the sum of all its sensors, each sensor's signal strength being multiplied by its weight.</p>

<p>2. When the net is shown an input, the node with the highest output is deemed the winner. The input is classified as being within the cluster corresponding to that node.</p>

<p>3. The winner updates each of its weights, moving weight from the connections that gave it weaker signals to the connections that gave it stronger signals.</p>

<p>Thus, as more data are received, each node converges on the centre of the cluster that it has come to represent and activates more strongly for inputs in this cluster and more weakly for inputs in other clusters.</p>
<h2 id="see-also">See also</h2>
<ul>
<li><a href="Ensemble_learning" title="wikilink">Ensemble learning</a></li>
<li><a href="Pandemonium_architecture" title="wikilink">Pandemonium architecture</a></li>
</ul>
<h2 id="references">References</h2>
<h2 id="further-information-and-software">Further Information and Software</h2>
<ul>
<li><a href="http://www.demogng.de/JavaPaper/t.html">Draft Report "Some Competitive Learning Methods"</a> (contains descriptions of several related algos)</li>
<li><a href="http://www.demogng.de">DemoGNG - Java simulator for competitive learning methods</a></li>
</ul>

<p>"</p>

<p><a href="Category:Artificial_neural_networks" title="wikilink">Category:Artificial neural networks</a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1"><a href="#fnref1">↩</a></li>
<li id="fn2"><a href="#fnref2">↩</a></li>
</ol>
</section>
</body>
</html>
