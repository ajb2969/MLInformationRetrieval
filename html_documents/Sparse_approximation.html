<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="56">Sparse approximation</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>Sparse approximation</h1>
<hr/>

<p>A <strong>sparse approximation</strong> is a <a href="Sparsity" title="wikilink">sparse</a> vector that approximately solves a system of equations. Techniques for finding sparse approximations have found wide use in applications such as image processing, audio processing, biology, and document analysis.</p>
<h2 id="sparse-decomposition">Sparse decomposition</h2>
<h3 id="noiseless-observations">Noiseless observations</h3>

<p>Consider a <a href="System_of_linear_equations" title="wikilink">linear system of equations</a> 

<math display="inline" id="Sparse_approximation:0">
 <semantics>
  <mrow>
   <mi>x</mi>
   <mo>=</mo>
   <mrow>
    <mi>D</mi>
    <mi>α</mi>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <ci>x</ci>
    <apply>
     <times></times>
     <ci>D</ci>
     <ci>α</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   x=D\alpha
  </annotation>
 </semantics>
</math>

, where 

<math display="inline" id="Sparse_approximation:1">
 <semantics>
  <mi>D</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>D</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   D
  </annotation>
 </semantics>
</math>

 is an <a href="underdetermined_system" title="wikilink">underdetermined</a> 

<math display="inline" id="Sparse_approximation:2">
 <semantics>
  <mrow>
   <mi>m</mi>
   <mo>×</mo>
   <mi>p</mi>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <ci>m</ci>
    <ci>p</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   m\times p
  </annotation>
 </semantics>
</math>

 <a href="matrix_(mathematics)" title="wikilink">matrix</a> 

<math display="inline" id="Sparse_approximation:3">
 <semantics>
  <mrow>
   <mo stretchy="false">(</mo>
   <mrow>
    <mi>m</mi>
    <mo>≪</mo>
    <mi>p</mi>
   </mrow>
   <mo stretchy="false">)</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="latexml">much-less-than</csymbol>
    <ci>m</ci>
    <ci>p</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   (m\ll p)
  </annotation>
 </semantics>
</math>

 and 

<math display="inline" id="Sparse_approximation:4">
 <semantics>
  <mrow>
   <mrow>
    <mi>x</mi>
    <mo>∈</mo>
    <msup>
     <mi>ℝ</mi>
     <mi>m</mi>
    </msup>
   </mrow>
   <mo>,</mo>
   <mrow>
    <mi>α</mi>
    <mo>∈</mo>
    <msup>
     <mi>ℝ</mi>
     <mi>p</mi>
    </msup>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">formulae-sequence</csymbol>
    <apply>
     <in></in>
     <ci>x</ci>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <ci>ℝ</ci>
      <ci>m</ci>
     </apply>
    </apply>
    <apply>
     <in></in>
     <ci>α</ci>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <ci>ℝ</ci>
      <ci>p</ci>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   x\in\mathbb{R}^{m},\alpha\in\mathbb{R}^{p}
  </annotation>
 </semantics>
</math>

. 

<math display="inline" id="Sparse_approximation:5">
 <semantics>
  <mi>D</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>D</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   D
  </annotation>
 </semantics>
</math>

, called as the dictionary or the design matrix, is given. The problem is to estimate the signal 

<math display="inline" id="Sparse_approximation:6">
 <semantics>
  <mi>α</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>α</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \alpha
  </annotation>
 </semantics>
</math>

, subject to the constraint that it is sparse. The underlying motivation for sparse decomposition problems is that even though the observed values are in high-dimensional 

<math display="inline" id="Sparse_approximation:7">
 <semantics>
  <mrow>
   <mo stretchy="false">(</mo>
   <mi>m</mi>
   <mo stretchy="false">)</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <ci>m</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   (m)
  </annotation>
 </semantics>
</math>

 space, the actual signal is organized in some lower-dimensional subspace 

<math display="inline" id="Sparse_approximation:8">
 <semantics>
  <mrow>
   <mo stretchy="false">(</mo>
   <mrow>
    <mi>k</mi>
    <mo>≪</mo>
    <mi>m</mi>
   </mrow>
   <mo stretchy="false">)</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="latexml">much-less-than</csymbol>
    <ci>k</ci>
    <ci>m</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   (k\ll m)
  </annotation>
 </semantics>
</math>

.</p>

<p>Sparsity implies that only a few components of 

<math display="inline" id="Sparse_approximation:9">
 <semantics>
  <mi>α</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>α</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \alpha
  </annotation>
 </semantics>
</math>

 are non-zero and the rest are zero. This implies that 

<math display="inline" id="Sparse_approximation:10">
 <semantics>
  <mi>x</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>x</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   x
  </annotation>
 </semantics>
</math>

 can be decomposed as a linear combination of only a few 

<math display="inline" id="Sparse_approximation:11">
 <semantics>
  <mrow>
   <mi>m</mi>
   <mo>×</mo>
   <mn>1</mn>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <ci>m</ci>
    <cn type="integer">1</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   m\times 1
  </annotation>
 </semantics>
</math>

 vectors in 

<math display="inline" id="Sparse_approximation:12">
 <semantics>
  <mi>D</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>D</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   D
  </annotation>
 </semantics>
</math>

, called atoms. 

<math display="inline" id="Sparse_approximation:13">
 <semantics>
  <mi>D</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>D</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   D
  </annotation>
 </semantics>
</math>

 itself is over-complete 

<math display="inline" id="Sparse_approximation:14">
 <semantics>
  <mrow>
   <mo stretchy="false">(</mo>
   <mrow>
    <mi>m</mi>
    <mo>≪</mo>
    <mi>p</mi>
   </mrow>
   <mo stretchy="false">)</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="latexml">much-less-than</csymbol>
    <ci>m</ci>
    <ci>p</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   (m\ll p)
  </annotation>
 </semantics>
</math>

. Such vectors are called as the <a href="Basis_vectors" title="wikilink">basis</a> of 

<math display="inline" id="Sparse_approximation:15">
 <semantics>
  <mi>x</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>x</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   x
  </annotation>
 </semantics>
</math>

. However, unlike other <a href="Dimensionality_reduction" title="wikilink">dimensionality reducing</a> decomposition techniques such as <a href="Principal_component_analysis" title="wikilink">Principal Component Analysis</a>, the basis vectors are not required to be orthogonal.</p>

<p>The sparse decomposition problem is represented as,</p>

<p>

<math display="block" id="Sparse_approximation:16">
 <semantics>
  <mrow>
   <mrow>
    <mrow>
     <munder>
      <mi>min</mi>
      <mrow>
       <mi>α</mi>
       <mo>∈</mo>
       <msup>
        <mi>ℝ</mi>
        <mi>p</mi>
       </msup>
      </mrow>
     </munder>
     <msub>
      <mrow>
       <mo>∥</mo>
       <mi>α</mi>
       <mo>∥</mo>
      </mrow>
      <mn>0</mn>
     </msub>
     <mtext>such that</mtext>
     <mi>x</mi>
    </mrow>
    <mo>=</mo>
    <mrow>
     <mi>D</mi>
     <mi>α</mi>
    </mrow>
   </mrow>
   <mo>,</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <times></times>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <min></min>
      <apply>
       <in></in>
       <ci>α</ci>
       <apply>
        <csymbol cd="ambiguous">superscript</csymbol>
        <ci>ℝ</ci>
        <ci>p</ci>
       </apply>
      </apply>
     </apply>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <apply>
       <csymbol cd="latexml">norm</csymbol>
       <ci>α</ci>
      </apply>
      <cn type="integer">0</cn>
     </apply>
     <mtext>such that</mtext>
     <ci>x</ci>
    </apply>
    <apply>
     <times></times>
     <ci>D</ci>
     <ci>α</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \min_{\alpha\in\mathbb{R}^{p}}\|\alpha\|_{0}\text{ such that }x=D\alpha,
  </annotation>
 </semantics>
</math>

 where 

<math display="inline" id="Sparse_approximation:17">
 <semantics>
  <mrow>
   <msub>
    <mrow>
     <mo>∥</mo>
     <mi>α</mi>
     <mo>∥</mo>
    </mrow>
    <mn>0</mn>
   </msub>
   <mo>=</mo>
   <mrow>
    <mi mathvariant="normal">#</mi>
    <mrow>
     <mo stretchy="false">{</mo>
     <mi>i</mi>
     <mo>:</mo>
     <mrow>
      <mrow>
       <msub>
        <mi>α</mi>
        <mi>i</mi>
       </msub>
       <mo>≠</mo>
       <mn>0</mn>
      </mrow>
      <mo rspace="4.2pt">,</mo>
      <mrow>
       <mi>i</mi>
       <mo>=</mo>
       <mrow>
        <mn>1</mn>
        <mo>,</mo>
        <mi mathvariant="normal">…</mi>
        <mo>,</mo>
        <mi>p</mi>
       </mrow>
      </mrow>
     </mrow>
     <mo stretchy="false">}</mo>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <apply>
      <csymbol cd="latexml">norm</csymbol>
      <ci>α</ci>
     </apply>
     <cn type="integer">0</cn>
    </apply>
    <apply>
     <times></times>
     <ci>normal-#</ci>
     <apply>
      <csymbol cd="latexml">conditional-set</csymbol>
      <ci>i</ci>
      <apply>
       <csymbol cd="ambiguous">formulae-sequence</csymbol>
       <apply>
        <neq></neq>
        <apply>
         <csymbol cd="ambiguous">subscript</csymbol>
         <ci>α</ci>
         <ci>i</ci>
        </apply>
        <cn type="integer">0</cn>
       </apply>
       <apply>
        <eq></eq>
        <ci>i</ci>
        <list>
         <cn type="integer">1</cn>
         <ci>normal-…</ci>
         <ci>p</ci>
        </list>
       </apply>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \|\alpha\|_{0}=\#\{i:\alpha_{i}\neq 0,\,i=1,\ldots,p\}
  </annotation>
 </semantics>
</math>

 is a pseudo-norm, 

<math display="inline" id="Sparse_approximation:18">
 <semantics>
  <msub>
   <mi>l</mi>
   <mn>0</mn>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>l</ci>
    <cn type="integer">0</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   l_{0}
  </annotation>
 </semantics>
</math>

, which counts the number of non-zero components of 

<math display="inline" id="Sparse_approximation:19">
 <semantics>
  <mrow>
   <mi>α</mi>
   <mo>=</mo>
   <msup>
    <mrow>
     <mo stretchy="false">[</mo>
     <msub>
      <mi>α</mi>
      <mn>1</mn>
     </msub>
     <mo>,</mo>
     <mi mathvariant="normal">…</mi>
     <mo>,</mo>
     <msub>
      <mi>α</mi>
      <mi>p</mi>
     </msub>
     <mo stretchy="false">]</mo>
    </mrow>
    <mi>T</mi>
   </msup>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <ci>α</ci>
    <apply>
     <csymbol cd="ambiguous">superscript</csymbol>
     <list>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>α</ci>
       <cn type="integer">1</cn>
      </apply>
      <ci>normal-…</ci>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>α</ci>
       <ci>p</ci>
      </apply>
     </list>
     <ci>T</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \alpha=[\alpha_{1},\ldots,\alpha_{p}]^{T}
  </annotation>
 </semantics>
</math>

. This problem is NP-Hard with a reduction to NP-complete subset selection problems in <a href="combinatorial_optimization" title="wikilink">combinatorial optimization</a>. A convex <a href="Relaxation_(approximation)" title="wikilink">relaxation</a> of the problem can instead be obtained by taking the 

<math display="inline" id="Sparse_approximation:20">
 <semantics>
  <msub>
   <mi>l</mi>
   <mn>1</mn>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>l</ci>
    <cn type="integer">1</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   l_{1}
  </annotation>
 </semantics>
</math>

 norm instead of the 

<math display="inline" id="Sparse_approximation:21">
 <semantics>
  <msub>
   <mi>l</mi>
   <mn>0</mn>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>l</ci>
    <cn type="integer">0</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   l_{0}
  </annotation>
 </semantics>
</math>

 norm, where 

<math display="inline" id="Sparse_approximation:22">
 <semantics>
  <mrow>
   <msub>
    <mrow>
     <mo>∥</mo>
     <mi>α</mi>
     <mo>∥</mo>
    </mrow>
    <mn>1</mn>
   </msub>
   <mo>=</mo>
   <mrow>
    <msubsup>
     <mo largeop="true" symmetric="true">∑</mo>
     <mrow>
      <mi>i</mi>
      <mo>=</mo>
      <mn>1</mn>
     </mrow>
     <mi>p</mi>
    </msubsup>
    <mrow>
     <mo stretchy="false">|</mo>
     <msub>
      <mi>α</mi>
      <mi>i</mi>
     </msub>
     <mo stretchy="false">|</mo>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <apply>
      <csymbol cd="latexml">norm</csymbol>
      <ci>α</ci>
     </apply>
     <cn type="integer">1</cn>
    </apply>
    <apply>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <sum></sum>
       <apply>
        <eq></eq>
        <ci>i</ci>
        <cn type="integer">1</cn>
       </apply>
      </apply>
      <ci>p</ci>
     </apply>
     <apply>
      <abs></abs>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>α</ci>
       <ci>i</ci>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \|\alpha\|_{1}=\sum_{i=1}^{p}|\alpha_{i}|
  </annotation>
 </semantics>
</math>

. The 

<math display="inline" id="Sparse_approximation:23">
 <semantics>
  <msub>
   <mi>l</mi>
   <mn>1</mn>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>l</ci>
    <cn type="integer">1</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   l_{1}
  </annotation>
 </semantics>
</math>

 norm induces sparsity under certain conditions.<a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a></p>
<h3 id="noisy-observations">Noisy observations</h3>

<p>Often the observations 

<math display="inline" id="Sparse_approximation:24">
 <semantics>
  <mi>x</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>x</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   x
  </annotation>
 </semantics>
</math>

 are noisy. By imposing an <a href="L2_norm#Euclidean_norm" title="wikilink">

<math display="inline" id="Sparse_approximation:25">
 <semantics>
  <msub>
   <mi>l</mi>
   <mn>2</mn>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>l</ci>
    <cn type="integer">2</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   l_{2}
  </annotation>
 </semantics>
</math>

</a> norm on the data-fitting term and relaxing the equality constraint, the sparse decomposition problem is given by,</p>

<p>

<math display="block" id="Sparse_approximation:26">
 <semantics>
  <mrow>
   <mrow>
    <mrow>
     <mrow>
      <munder>
       <mi>min</mi>
       <mrow>
        <mi>α</mi>
        <mo>∈</mo>
        <msup>
         <mi>ℝ</mi>
         <mi>p</mi>
        </msup>
       </mrow>
      </munder>
      <mfrac>
       <mn>1</mn>
       <mn>2</mn>
      </mfrac>
     </mrow>
     <msubsup>
      <mrow>
       <mo>∥</mo>
       <mrow>
        <mi>x</mi>
        <mo>-</mo>
        <mrow>
         <mi>D</mi>
         <mi>α</mi>
        </mrow>
       </mrow>
       <mo>∥</mo>
      </mrow>
      <mn>2</mn>
      <mn>2</mn>
     </msubsup>
    </mrow>
    <mo>+</mo>
    <mrow>
     <mi>λ</mi>
     <msub>
      <mrow>
       <mo>∥</mo>
       <mi>α</mi>
       <mo>∥</mo>
      </mrow>
      <mn>1</mn>
     </msub>
    </mrow>
   </mrow>
   <mo>,</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <plus></plus>
    <apply>
     <times></times>
     <apply>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <min></min>
       <apply>
        <in></in>
        <ci>α</ci>
        <apply>
         <csymbol cd="ambiguous">superscript</csymbol>
         <ci>ℝ</ci>
         <ci>p</ci>
        </apply>
       </apply>
      </apply>
      <apply>
       <divide></divide>
       <cn type="integer">1</cn>
       <cn type="integer">2</cn>
      </apply>
     </apply>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <apply>
        <csymbol cd="latexml">norm</csymbol>
        <apply>
         <minus></minus>
         <ci>x</ci>
         <apply>
          <times></times>
          <ci>D</ci>
          <ci>α</ci>
         </apply>
        </apply>
       </apply>
       <cn type="integer">2</cn>
      </apply>
      <cn type="integer">2</cn>
     </apply>
    </apply>
    <apply>
     <times></times>
     <ci>λ</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <apply>
       <csymbol cd="latexml">norm</csymbol>
       <ci>α</ci>
      </apply>
      <cn type="integer">1</cn>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \min_{\alpha\in\mathbb{R}^{p}}\frac{1}{2}\|x-D\alpha\|_{2}^{2}+\lambda\|\alpha%
\|_{1},
  </annotation>
 </semantics>
</math>

 where 

<math display="inline" id="Sparse_approximation:27">
 <semantics>
  <mi>λ</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>λ</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \lambda
  </annotation>
 </semantics>
</math>

 is a <a href="slack_variable" title="wikilink">slack variable</a> and 

<math display="inline" id="Sparse_approximation:28">
 <semantics>
  <msub>
   <mrow>
    <mo>∥</mo>
    <mi>α</mi>
    <mo>∥</mo>
   </mrow>
   <mn>1</mn>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <apply>
     <csymbol cd="latexml">norm</csymbol>
     <ci>α</ci>
    </apply>
    <cn type="integer">1</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \|\alpha\|_{1}
  </annotation>
 </semantics>
</math>

 is the sparsity-inducing term. The slack variable balances the trade-off between fitting the data perfectly, and employing a sparse solution.</p>
<h2 id="variations">Variations</h2>

<p>There are several variations to the basic sparse approximation problem.</p>
<h3 id="structured-sparsity">Structured sparsity</h3>

<p>In the original version of the problem, any atoms in the dictionary can be picked. In the structured (block) sparsity model, instead of picking atoms individually, groups of atoms are to be picked. These groups can be overlapping and of varying size. The objective is to represent 

<math display="inline" id="Sparse_approximation:29">
 <semantics>
  <mi>x</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>x</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   x
  </annotation>
 </semantics>
</math>

 such that it is sparse in the number of groups selected. Such groups appear naturally in many problems. For example, in object classification problems the atoms can represent images, and groups can represent category of objects.</p>
<h3 id="collaborative-sparse-coding">Collaborative sparse coding</h3>

<p>The original version of the problem is defined for only a single point 

<math display="inline" id="Sparse_approximation:30">
 <semantics>
  <mi>x</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>x</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   x
  </annotation>
 </semantics>
</math>

 and its noisy observation. Often, a single point can have more than one sparse representation with similar data fitting errors. In the collaborative sparse coding model, more than one observation of the same point is available. Hence, the data fitting error is defined as the sum of the 

<math display="inline" id="Sparse_approximation:31">
 <semantics>
  <msub>
   <mi>l</mi>
   <mn>2</mn>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>l</ci>
    <cn type="integer">2</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   l_{2}
  </annotation>
 </semantics>
</math>

 norm for all points.</p>
<h2 id="algorithms">Algorithms</h2>

<p>There are several algorithms that have been developed for solving sparse approximation problem.</p>
<h3 id="matching-pursuit">Matching pursuit</h3>

<p><a href="Matching_pursuit" title="wikilink">Matching pursuit</a> is a greedy iterative algorithm for approximatively solving the original 

<math display="inline" id="Sparse_approximation:32">
 <semantics>
  <msub>
   <mi>l</mi>
   <mn>0</mn>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>l</ci>
    <cn type="integer">0</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   l_{0}
  </annotation>
 </semantics>
</math>

 pseudo-norm problem. Matching pursuit works by finding a basis vector in 

<math display="inline" id="Sparse_approximation:33">
 <semantics>
  <mi>D</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>D</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   D
  </annotation>
 </semantics>
</math>

 that maximizes the correlation with the residual (initialized to 

<math display="inline" id="Sparse_approximation:34">
 <semantics>
  <mi>x</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>x</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   x
  </annotation>
 </semantics>
</math>

), and then recomputing the residual and coefficients by projecting the residual on all atoms in the dictionary using existing coefficients. Matching pursuit suffers from the drawback that an atom can be picked multiple times which is addressed in orthogonal matching pursuit.</p>
<h3 id="orthogonal-matching-pursuit">Orthogonal matching pursuit</h3>

<p>Orthogonal Matching Pursuit is similar to Matching Pursuit, except that an atom once picked, cannot be picked again. The algorithm maintains an active set of atoms already picked, and adds a new atom at each iteration. The residual is projected on to a linear combination of all atoms in the active set, so that an orthogonal updated residual is obtained. Both Matching Pursuit and Orthogonal Matching Pursuit use the 

<math display="inline" id="Sparse_approximation:35">
 <semantics>
  <msub>
   <mi>l</mi>
   <mn>0</mn>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>l</ci>
    <cn type="integer">0</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   l_{0}
  </annotation>
 </semantics>
</math>

 norm.</p>
<h3 id="lasso">LASSO</h3>

<p>The <a href="lasso_(statistics)" title="wikilink">LASSO method</a> solves the 

<math display="inline" id="Sparse_approximation:36">
 <semantics>
  <msub>
   <mi>l</mi>
   <mn>1</mn>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>l</ci>
    <cn type="integer">1</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   l_{1}
  </annotation>
 </semantics>
</math>

 norm version of the problem. In LASSO, instead of projecting the residual on some atom as in Matching Pursuit, the residual is moved by a small step in the direction of the atom iteratively.</p>
<h3 id="projected-gradient-descent">Projected Gradient Descent</h3>

<p>Projected Gradient Descent methods operate in a similar fashion with the Gradient Descent: the current gradient provides the information to point to new search directions. Since we are looking for a sparse solution, the putative solutions are projected onto the sparse scaffold of 

<math display="inline" id="Sparse_approximation:37">
 <semantics>
  <mi>k</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>k</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   k
  </annotation>
 </semantics>
</math>

 vectors.<a class="footnoteRef" href="#fn2" id="fnref2"><sup>2</sup></a> <a class="footnoteRef" href="#fn3" id="fnref3"><sup>3</sup></a> Because the projection can often be viewed as a thresholding operator, the described algorithm is also known as Iterative Thresholding algorithm. <a class="footnoteRef" href="#fn4" id="fnref4"><sup>4</sup></a> The specific form of the thresholding operator is closely related to the chosen penalty function. For 

<math display="inline" id="Sparse_approximation:38">
 <semantics>
  <msub>
   <mi mathvariant="normal">ℓ</mi>
   <mn>0</mn>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>normal-ℓ</ci>
    <cn type="integer">0</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \ell_{0}
  </annotation>
 </semantics>
</math>

 norm, the corresponding thresholding operator is known as hard thresholding. For 

<math display="inline" id="Sparse_approximation:39">
 <semantics>
  <msub>
   <mi mathvariant="normal">ℓ</mi>
   <mn>1</mn>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>normal-ℓ</ci>
    <cn type="integer">1</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \ell_{1}
  </annotation>
 </semantics>
</math>

 norm, the corresponding thresholding operator is known as soft thresholding.</p>
<h3 id="other-methods">Other methods</h3>

<p>There are several other methods for solving sparse decomposition problems<a class="footnoteRef" href="#fn5" id="fnref5"><sup>5</sup></a></p>
<ul>
<li>Homotopy method</li>
<li>Coordinate descent</li>
<li>First order/proximal methods</li>
<li>Dantzig selector<a class="footnoteRef" href="#fn6" id="fnref6"><sup>6</sup></a></li>
</ul>
<h2 id="applications">Applications</h2>

<p>Sparse approximation has been used in image processing, biology, document analysis, and audio analysis for representation, compression, and estimation.</p>
<h3 id="audio-analysis">Audio Analysis</h3>

<p>In the audio domain, sparse approximation has been applied to the analysis of speech, environmental sounds, and music. For classification of everyday sound samples, Adiloglu et al.<a class="footnoteRef" href="#fn7" id="fnref7"><sup>7</sup></a> decomposed sounds in terms of a dictionary of Gammatone functions. Applying matching pursuit, they yielded a point pattern of time-frequency components. They then defined a dissimilarity of two sounds via a one-to-one correspondence between the most prominent atoms of two sounds. Scholler and Purwins <a class="footnoteRef" href="#fn8" id="fnref8"><sup>8</sup></a> have used sparse approximation for the classification of drum sounds based on atom counts resulting from a sparse approximation with a learned sound dictionary including the optimisation of the atom length.</p>
<h2 id="see-also">See also</h2>
<ul>
<li><a href="Compressed_sensing" title="wikilink">Compressed sensing</a></li>
<li><a href="Spectral_estimation" title="wikilink">Spectral estimation</a></li>
<li><a class="uri" href="K-SVD" title="wikilink">K-SVD</a></li>
</ul>
<h2 id="references">References</h2>
<references>
</references>

<p>"</p>

<p><a href="Category:Numerical_linear_algebra" title="wikilink">Category:Numerical linear algebra</a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1"><a href="#fnref1">↩</a></li>
<li id="fn2"><a href="#fnref2">↩</a></li>
<li id="fn3"><a href="#fnref3">↩</a></li>
<li id="fn4"><a href="#fnref4">↩</a></li>
<li id="fn5"><a href="#fnref5">↩</a></li>
<li id="fn6"><a href="#fnref6">↩</a></li>
<li id="fn7"><a href="#fnref7">↩</a></li>
<li id="fn8"><a href="#fnref8">↩</a></li>
</ol>
</section>
</body>
</html>
