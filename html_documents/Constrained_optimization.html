<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="1166">Constrained optimization</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>Constrained optimization</h1>
<hr/>

<p>In <a href="mathematical_optimization" title="wikilink">mathematical optimization</a>, <strong>constrained optimization</strong> (in some contexts called <strong>constraint optimization</strong>) is the process of optimizing an objective function with respect to some <a href="variable_(mathematics)" title="wikilink">variables</a> in the presence of <a href="Constraint_(mathematics)" title="wikilink">constraints</a> on those variables. The objective function is either a <a href="Loss_function" title="wikilink">cost function</a> or <a href="energy_function" title="wikilink">energy function</a> which is to be <a href="minimize" title="wikilink">minimized</a>, or a <a href="reward_function" title="wikilink">reward function</a> or <a href="utility_function" title="wikilink">utility function</a>, which is to be <a href="maximize" title="wikilink">maximized</a>. Constraints can be either <em>hard constraints</em> which set conditions for the variables that are required to be satisfied, or <em>soft constraints</em> which have some variable values that are penalized in the objective function if, and based on the extent that, the conditions on the variables are not satisfied.</p>
<h2 id="general-form">General form</h2>

<p>A general constrained minimization problem may be written as follows:</p>

<p>

<math display="block" id="Constrained_optimization:0">
 <semantics>
  <mtable displaystyle="true">
   <mtr>
    <mtd columnalign="right">
     <mi>min</mi>
    </mtd>
    <mtd></mtd>
    <mtd columnalign="left">
     <mrow>
      <mi>f</mi>
      <mrow>
       <mo stretchy="false">(</mo>
       <mi>ùê±</mi>
       <mo stretchy="false">)</mo>
      </mrow>
     </mrow>
    </mtd>
    <mtd></mtd>
   </mtr>
   <mtr>
    <mtd columnalign="right">
     <mrow>
      <mpadded width="+3.3pt">
       <mi>subject</mi>
      </mpadded>
      <mi>to</mi>
     </mrow>
    </mtd>
    <mtd></mtd>
    <mtd columnalign="left">
     <mrow>
      <mrow>
       <msub>
        <mi>g</mi>
        <mi>i</mi>
       </msub>
       <mrow>
        <mo stretchy="false">(</mo>
        <mi>ùê±</mi>
        <mo stretchy="false">)</mo>
       </mrow>
      </mrow>
      <mo>=</mo>
      <msub>
       <mi>c</mi>
       <mi>i</mi>
      </msub>
     </mrow>
    </mtd>
    <mtd columnalign="left">
     <mrow>
      <mrow>
       <mtext>for</mtext>
       <mi>i</mi>
      </mrow>
      <mo>=</mo>
      <mrow>
       <mn>1</mn>
       <mo>,</mo>
       <mi mathvariant="normal">‚Ä¶</mi>
       <mo>,</mo>
       <mi>n</mi>
       <mtext>Equality constraints</mtext>
      </mrow>
     </mrow>
    </mtd>
   </mtr>
   <mtr>
    <mtd></mtd>
    <mtd></mtd>
    <mtd columnalign="left">
     <mrow>
      <mrow>
       <msub>
        <mi>h</mi>
        <mi>j</mi>
       </msub>
       <mrow>
        <mo stretchy="false">(</mo>
        <mi>ùê±</mi>
        <mo stretchy="false">)</mo>
       </mrow>
      </mrow>
      <mo>‚âß</mo>
      <msub>
       <mi>d</mi>
       <mi>j</mi>
      </msub>
     </mrow>
    </mtd>
    <mtd columnalign="left">
     <mrow>
      <mrow>
       <mtext>for</mtext>
       <mi>j</mi>
      </mrow>
      <mo>=</mo>
      <mrow>
       <mn>1</mn>
       <mo>,</mo>
       <mi mathvariant="normal">‚Ä¶</mi>
       <mo>,</mo>
       <mi>m</mi>
       <mtext>Inequality constraints</mtext>
      </mrow>
     </mrow>
    </mtd>
   </mtr>
  </mtable>
  <annotation-xml encoding="MathML-Content">
   <matrix>
    <matrixrow>
     <min></min>
     <cerror>
      <csymbol cd="ambiguous">missing-subexpression</csymbol>
     </cerror>
     <apply>
      <times></times>
      <ci>f</ci>
      <ci>ùê±</ci>
     </apply>
     <cerror>
      <csymbol cd="ambiguous">missing-subexpression</csymbol>
     </cerror>
    </matrixrow>
    <matrixrow>
     <apply>
      <times></times>
      <ci>subject</ci>
      <ci>to</ci>
     </apply>
     <cerror>
      <csymbol cd="ambiguous">missing-subexpression</csymbol>
     </cerror>
     <apply>
      <eq></eq>
      <apply>
       <times></times>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <ci>g</ci>
        <ci>i</ci>
       </apply>
       <ci>ùê±</ci>
      </apply>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>c</ci>
       <ci>i</ci>
      </apply>
     </apply>
     <apply>
      <eq></eq>
      <apply>
       <times></times>
       <mtext>for</mtext>
       <ci>i</ci>
      </apply>
      <list>
       <cn type="integer">1</cn>
       <ci>normal-‚Ä¶</ci>
       <ci>n</ci>
       <mtext>Equality constraints</mtext>
      </list>
     </apply>
    </matrixrow>
    <matrixrow>
     <cerror>
      <csymbol cd="ambiguous">missing-subexpression</csymbol>
     </cerror>
     <cerror>
      <csymbol cd="ambiguous">missing-subexpression</csymbol>
     </cerror>
     <apply>
      <geq></geq>
      <apply>
       <times></times>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <ci>h</ci>
        <ci>j</ci>
       </apply>
       <ci>ùê±</ci>
      </apply>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>d</ci>
       <ci>j</ci>
      </apply>
     </apply>
     <apply>
      <eq></eq>
      <apply>
       <times></times>
       <mtext>for</mtext>
       <ci>j</ci>
      </apply>
      <list>
       <cn type="integer">1</cn>
       <ci>normal-‚Ä¶</ci>
       <ci>m</ci>
       <mtext>Inequality constraints</mtext>
      </list>
     </apply>
    </matrixrow>
   </matrix>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \begin{array}[]{rcll}\min&&f(\mathbf{x})&\\
\mathrm{subject~{}to}&&g_{i}(\mathbf{x})=c_{i}&\text{for }i=1,\ldots,n\quad%
\text{Equality constraints}\\
&&h_{j}(\mathbf{x})\geqq d_{j}&\text{for }j=1,\ldots,m\quad\text{Inequality %
constraints}\end{array}
  </annotation>
 </semantics>
</math>

</p>

<p>where 

<math display="inline" id="Constrained_optimization:1">
 <semantics>
  <mrow>
   <mrow>
    <mrow>
     <msub>
      <mi>g</mi>
      <mi>i</mi>
     </msub>
     <mrow>
      <mo stretchy="false">(</mo>
      <mi>ùê±</mi>
      <mo stretchy="false">)</mo>
     </mrow>
    </mrow>
    <mo>=</mo>
    <mrow>
     <mpadded width="+3.3pt">
      <msub>
       <mi>c</mi>
       <mi>i</mi>
      </msub>
     </mpadded>
     <mpadded width="+3.3pt">
      <mi>for</mi>
     </mpadded>
     <mi>i</mi>
    </mrow>
    <mo>=</mo>
    <mn>1</mn>
   </mrow>
   <mo>,</mo>
   <mrow>
    <mi mathvariant="normal">‚Ä¶</mi>
    <mo>,</mo>
    <mi>n</mi>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">formulae-sequence</csymbol>
    <apply>
     <and></and>
     <apply>
      <eq></eq>
      <apply>
       <times></times>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <ci>g</ci>
        <ci>i</ci>
       </apply>
       <ci>ùê±</ci>
      </apply>
      <apply>
       <times></times>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <ci>c</ci>
        <ci>i</ci>
       </apply>
       <ci>for</ci>
       <ci>i</ci>
      </apply>
     </apply>
     <apply>
      <eq></eq>
      <share href="#.cmml">
      </share>
      <cn type="integer">1</cn>
     </apply>
    </apply>
    <list>
     <ci>normal-‚Ä¶</ci>
     <ci>n</ci>
    </list>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   g_{i}(\mathbf{x})=c_{i}~{}\mathrm{for~{}}i=1,\ldots,n
  </annotation>
 </semantics>
</math>

 and 

<math display="inline" id="Constrained_optimization:2">
 <semantics>
  <mrow>
   <mrow>
    <mrow>
     <msub>
      <mi>h</mi>
      <mi>j</mi>
     </msub>
     <mrow>
      <mo stretchy="false">(</mo>
      <mi>ùê±</mi>
      <mo stretchy="false">)</mo>
     </mrow>
    </mrow>
    <mo>‚â•</mo>
    <mrow>
     <mpadded width="+3.3pt">
      <msub>
       <mi>d</mi>
       <mi>j</mi>
      </msub>
     </mpadded>
     <mpadded width="+3.3pt">
      <mi>for</mi>
     </mpadded>
     <mi>j</mi>
    </mrow>
    <mo>=</mo>
    <mn>1</mn>
   </mrow>
   <mo>,</mo>
   <mrow>
    <mi mathvariant="normal">‚Ä¶</mi>
    <mo>,</mo>
    <mi>m</mi>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">formulae-sequence</csymbol>
    <apply>
     <and></and>
     <apply>
      <geq></geq>
      <apply>
       <times></times>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <ci>h</ci>
        <ci>j</ci>
       </apply>
       <ci>ùê±</ci>
      </apply>
      <apply>
       <times></times>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <ci>d</ci>
        <ci>j</ci>
       </apply>
       <ci>for</ci>
       <ci>j</ci>
      </apply>
     </apply>
     <apply>
      <eq></eq>
      <share href="#.cmml">
      </share>
      <cn type="integer">1</cn>
     </apply>
    </apply>
    <list>
     <ci>normal-‚Ä¶</ci>
     <ci>m</ci>
    </list>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   h_{j}(\mathbf{x})\geq d_{j}~{}\mathrm{for~{}}j=1,\ldots,m
  </annotation>
 </semantics>
</math>

 are constraints that are required to be satisfied; these are called <a href="Constraint_(mathematics)#Hard_and_soft_constraints" title="wikilink">hard constraints</a>.</p>

<p>In some problems, often called <em>constraint optimization problems</em>, the objective function is actually the sum of cost functions, each of which penalizes the extent (if any) to which a <a href="Constraint_(mathematics)#Hard_and_soft_constraints" title="wikilink">soft constraint</a> (a constraint which is preferred but not required to be satisfied) is violated.</p>
<h2 id="solution-methods">Solution methods</h2>

<p>Many unconstrained optimization algorithms can be adapted to the constrained case, often via the use of a <a href="penalty_method" title="wikilink">penalty method</a>. However, search steps taken by the unconstrained method may be unacceptable for the constrained problem, leading to a lack of convergence. This is referred to as the Maratos effect.<a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a></p>
<h3 id="equality-constraints">Equality constraints</h3>

<p>If the constrained problem has only equality constraints, the method of <a href="Lagrange_multipliers" title="wikilink">Lagrange multipliers</a> can be used to convert it into an unconstrained problem whose number of variables is the original number of variables plus the original number of equality constraints. Alternatively, if the constraints are all equality constraints and are all linear, they can be solved for some of the variables in terms of the others, and the former can be substituted out of the objective function, leaving an unconstrained problem in a smaller number of variables.</p>
<h3 id="inequality-constraints">Inequality constraints</h3>

<p>With inequality constraints, the problem can be characterized in terms of the <a href="Geometric_Optimality_conditions" title="wikilink">Geometric Optimality conditions</a>, <a href="Fritz_John_conditions" title="wikilink">Fritz John conditions</a> and <a href="Karush‚ÄìKuhn‚ÄìTucker_conditions" title="wikilink">Karush‚ÄìKuhn‚ÄìTucker conditions</a>, in which simple problems may be solvable.</p>
<h3 id="linear-programming">Linear programming</h3>

<p>If the objective function and all of the hard constraints are linear, then the problem is a <a href="linear_programming" title="wikilink">linear programming</a> problem. This can be solved by the <a href="simplex_method" title="wikilink">simplex method</a>, which usually works in <a href="polynomial_time" title="wikilink">polynomial time</a> in the problem size but is not guaranteed to, or by <a href="interior_point_method" title="wikilink">interior point methods</a> which are guaranteed to work in polynomial time.</p>
<h3 id="quadratic-programming">Quadratic programming</h3>

<p>If all the hard constraints are linear but the objective function is quadratic, the problem is a <a href="quadratic_programming" title="wikilink">quadratic programming</a> problem. It can still be solved in polynomial time by the <a href="ellipsoid_method" title="wikilink">ellipsoid method</a> if the objective function is <a href="Convex_function" title="wikilink">convex</a>; otherwise the problem is <a href="NP_hard" title="wikilink">NP hard</a>.</p>
<h3 id="constraint-optimization-problems">Constraint optimization problems</h3>
<h4 id="branch-and-bound">Branch and bound</h4>

<p>Constraint optimization can be solved by <a href="branch_and_bound" title="wikilink">branch and bound</a> algorithms. These are backtracking algorithms storing the cost of the best solution found during execution and use it for avoiding part of the search. More precisely, whenever the algorithm encounters a partial solution that cannot be extended to form a solution of better cost than the stored best cost, the algorithm backtracks, instead of trying to extend this solution.</p>

<p>Assuming that cost is to be maximized, the efficiency of these algorithms depends on how the cost that can be obtained from extending a partial solution is evaluated. Indeed, if the algorithm can backtrack from a partial solution, part of the search is skipped. The lower the estimated cost, the better the algorithm, as a lower estimated cost is more likely to be lower than the best cost of solution found so far.</p>

<p>On the other hand, this estimated cost cannot be lower than the effective cost that can be obtained by extending the solution, as otherwise the algorithm could backtrack while a solution better than the best found so far exists. As a result, the algorithm requires an upper bound on the cost that can be obtained from extending a partial solution, and this upper bound should be as small as possible.</p>

<p>A variation of this approach called Hansen's method uses <a href="Interval_arithmetic#History" title="wikilink">interval methods</a>.<a class="footnoteRef" href="#fn2" id="fnref2"><sup>2</sup></a> It inherently implements rectangular constraints.</p>
<h5 id="first-choice-bounding-functions">First-choice bounding functions</h5>

<p>One way for evaluating this upper bound for a partial solution is to consider each soft constraint separately. For each soft constraint, the maximal possible value for any assignment to the unassigned variables is assumed. The sum of these values is an upper bound because the soft constraints cannot assume a higher value. It is exact because the maximal values of soft constraints may derive from different evaluations: a soft constraint may be maximal for 

<math display="inline" id="Constrained_optimization:3">
 <semantics>
  <mrow>
   <mi>x</mi>
   <mo>=</mo>
   <mi>a</mi>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <ci>x</ci>
    <ci>a</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   x=a
  </annotation>
 </semantics>
</math>

 while another constraint is maximal for 

<math display="inline" id="Constrained_optimization:4">
 <semantics>
  <mrow>
   <mi>x</mi>
   <mo>=</mo>
   <mi>b</mi>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <ci>x</ci>
    <ci>b</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   x=b
  </annotation>
 </semantics>
</math>

.</p>
<h5 id="russian-doll-search">Russian doll search</h5>

<p>This method<a class="footnoteRef" href="#fn3" id="fnref3"><sup>3</sup></a> runs a branch-and-bound algorithm on 

<math display="inline" id="Constrained_optimization:5">
 <semantics>
  <mi>n</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>n</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   n
  </annotation>
 </semantics>
</math>

 problems, where 

<math display="inline" id="Constrained_optimization:6">
 <semantics>
  <mi>n</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>n</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   n
  </annotation>
 </semantics>
</math>

 is the number of variables. Each such problem is the subproblem obtained by dropping a sequence of variables 

<math display="inline" id="Constrained_optimization:7">
 <semantics>
  <mrow>
   <msub>
    <mi>x</mi>
    <mn>1</mn>
   </msub>
   <mo>,</mo>
   <mi mathvariant="normal">‚Ä¶</mi>
   <mo>,</mo>
   <msub>
    <mi>x</mi>
    <mi>i</mi>
   </msub>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <list>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>x</ci>
     <cn type="integer">1</cn>
    </apply>
    <ci>normal-‚Ä¶</ci>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>x</ci>
     <ci>i</ci>
    </apply>
   </list>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   x_{1},\ldots,x_{i}
  </annotation>
 </semantics>
</math>

 from the original problem, along with the constraints containing them. After the problem on variables 

<math display="inline" id="Constrained_optimization:8">
 <semantics>
  <mrow>
   <msub>
    <mi>x</mi>
    <mrow>
     <mi>i</mi>
     <mo>+</mo>
     <mn>1</mn>
    </mrow>
   </msub>
   <mo>,</mo>
   <mi mathvariant="normal">‚Ä¶</mi>
   <mo>,</mo>
   <msub>
    <mi>x</mi>
    <mi>n</mi>
   </msub>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <list>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>x</ci>
     <apply>
      <plus></plus>
      <ci>i</ci>
      <cn type="integer">1</cn>
     </apply>
    </apply>
    <ci>normal-‚Ä¶</ci>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>x</ci>
     <ci>n</ci>
    </apply>
   </list>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   x_{i+1},\ldots,x_{n}
  </annotation>
 </semantics>
</math>

 is solved, its optimal cost can be used as an upper bound while solving the other problems,</p>

<p>In particular, the cost estimate of a solution having 

<math display="inline" id="Constrained_optimization:9">
 <semantics>
  <mrow>
   <msub>
    <mi>x</mi>
    <mrow>
     <mi>i</mi>
     <mo>+</mo>
     <mn>1</mn>
    </mrow>
   </msub>
   <mo>,</mo>
   <mi mathvariant="normal">‚Ä¶</mi>
   <mo>,</mo>
   <msub>
    <mi>x</mi>
    <mi>n</mi>
   </msub>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <list>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>x</ci>
     <apply>
      <plus></plus>
      <ci>i</ci>
      <cn type="integer">1</cn>
     </apply>
    </apply>
    <ci>normal-‚Ä¶</ci>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>x</ci>
     <ci>n</ci>
    </apply>
   </list>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   x_{i+1},\ldots,x_{n}
  </annotation>
 </semantics>
</math>

 as unassigned variables is added to the cost that derives from the evaluated variables. Virtually, this corresponds on ignoring the evaluated variables and solving the problem on the unassigned ones, except that the latter problem has already been solved. More precisely, the cost of soft constraints containing both assigned and unassigned variables is estimated as above (or using an arbitrary other method); the cost of soft constraints containing only unassigned variables is instead estimated using the optimal solution of the corresponding problem, which is already known at this point.</p>

<p>There is similarity between the Russian Doll Search method and <a href="Dynamic_programming" title="wikilink">Dynamic Programming</a>. Like Dynamic Programming,Russian Doll Search solves sub-problems in order to solve the whole problem. But, whereas Dynamic Programming directly combines the results obtained on sub-problems to get the result of the whole problem, Russian Doll Search only uses them as bounds during its search.</p>
<h4 id="bucket-elimination">Bucket elimination</h4>

<p>The <a href="bucket_elimination" title="wikilink">bucket elimination</a> algorithm can be adapted for constraint optimization. A given variable can be indeed removed from the problem by replacing all soft constraints containing it with a new soft constraint. The cost of this new constraint is computed assuming a maximal value for every value of the removed variable. Formally, if 

<math display="inline" id="Constrained_optimization:10">
 <semantics>
  <mi>x</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>x</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   x
  </annotation>
 </semantics>
</math>

 is the variable to be removed, 

<math display="inline" id="Constrained_optimization:11">
 <semantics>
  <mrow>
   <msub>
    <mi>C</mi>
    <mn>1</mn>
   </msub>
   <mo>,</mo>
   <mi mathvariant="normal">‚Ä¶</mi>
   <mo>,</mo>
   <msub>
    <mi>C</mi>
    <mi>n</mi>
   </msub>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <list>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>C</ci>
     <cn type="integer">1</cn>
    </apply>
    <ci>normal-‚Ä¶</ci>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>C</ci>
     <ci>n</ci>
    </apply>
   </list>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   C_{1},\ldots,C_{n}
  </annotation>
 </semantics>
</math>

 are the soft constraints containing it, and 

<math display="inline" id="Constrained_optimization:12">
 <semantics>
  <mrow>
   <msub>
    <mi>y</mi>
    <mn>1</mn>
   </msub>
   <mo>,</mo>
   <mi mathvariant="normal">‚Ä¶</mi>
   <mo>,</mo>
   <msub>
    <mi>y</mi>
    <mi>m</mi>
   </msub>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <list>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>y</ci>
     <cn type="integer">1</cn>
    </apply>
    <ci>normal-‚Ä¶</ci>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>y</ci>
     <ci>m</ci>
    </apply>
   </list>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   y_{1},\ldots,y_{m}
  </annotation>
 </semantics>
</math>

 are their variables except 

<math display="inline" id="Constrained_optimization:13">
 <semantics>
  <mi>x</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>x</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   x
  </annotation>
 </semantics>
</math>

, the new soft constraint is defined by:</p>

<p>

<math display="block" id="Constrained_optimization:14">
 <semantics>
  <mrow>
   <mi>C</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <msub>
     <mi>y</mi>
     <mn>1</mn>
    </msub>
    <mo>=</mo>
    <msub>
     <mi>a</mi>
     <mn>1</mn>
    </msub>
    <mo>,</mo>
    <mi mathvariant="normal">‚Ä¶</mi>
    <mo>,</mo>
    <msub>
     <mi>y</mi>
     <mi>n</mi>
    </msub>
    <mo>=</mo>
    <msub>
     <mi>a</mi>
     <mi>n</mi>
    </msub>
    <mo stretchy="false">)</mo>
   </mrow>
   <mo>=</mo>
   <munder>
    <mi>max</mi>
    <mi>a</mi>
   </munder>
   <munder>
    <mo largeop="true" movablelimits="false" symmetric="true">‚àë</mo>
    <mi>i</mi>
   </munder>
   <msub>
    <mi>C</mi>
    <mi>i</mi>
   </msub>
   <mrow>
    <mo stretchy="false">(</mo>
    <mi>x</mi>
    <mo>=</mo>
    <mi>a</mi>
    <mo>,</mo>
    <msub>
     <mi>y</mi>
     <mn>1</mn>
    </msub>
    <mo>=</mo>
    <msub>
     <mi>a</mi>
     <mn>1</mn>
    </msub>
    <mo>,</mo>
    <mi mathvariant="normal">‚Ä¶</mi>
    <mo>,</mo>
    <msub>
     <mi>y</mi>
     <mi>n</mi>
    </msub>
    <mo>=</mo>
    <msub>
     <mi>a</mi>
     <mi>n</mi>
    </msub>
    <mo stretchy="false">)</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <cerror>
    <csymbol cd="ambiguous">fragments</csymbol>
    <csymbol cd="unknown">C</csymbol>
    <cerror>
     <csymbol cd="ambiguous">fragments</csymbol>
     <ci>normal-(</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>y</ci>
      <cn type="integer">1</cn>
     </apply>
     <eq></eq>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>a</ci>
      <cn type="integer">1</cn>
     </apply>
     <ci>normal-,</ci>
     <ci>normal-‚Ä¶</ci>
     <ci>normal-,</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>y</ci>
      <ci>n</ci>
     </apply>
     <eq></eq>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>a</ci>
      <ci>n</ci>
     </apply>
     <ci>normal-)</ci>
    </cerror>
    <eq></eq>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <max></max>
     <ci>a</ci>
    </apply>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <sum></sum>
     <ci>i</ci>
    </apply>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>C</ci>
     <ci>i</ci>
    </apply>
    <cerror>
     <csymbol cd="ambiguous">fragments</csymbol>
     <ci>normal-(</ci>
     <csymbol cd="unknown">x</csymbol>
     <eq></eq>
     <csymbol cd="unknown">a</csymbol>
     <ci>normal-,</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>y</ci>
      <cn type="integer">1</cn>
     </apply>
     <eq></eq>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>a</ci>
      <cn type="integer">1</cn>
     </apply>
     <ci>normal-,</ci>
     <ci>normal-‚Ä¶</ci>
     <ci>normal-,</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>y</ci>
      <ci>n</ci>
     </apply>
     <eq></eq>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>a</ci>
      <ci>n</ci>
     </apply>
     <ci>normal-)</ci>
    </cerror>
   </cerror>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   C(y_{1}=a_{1},\ldots,y_{n}=a_{n})=\max_{a}\sum_{i}C_{i}(x=a,y_{1}=a_{1},\ldots%
,y_{n}=a_{n})
  </annotation>
 </semantics>
</math>

</p>

<p>Bucket elimination works with an (arbitrary) ordering of the variables. Every variable is associated a bucket of constraints; the bucket of a variable contains all constraints having the variable has the highest in the order. Bucket elimination proceed from the last variable to the first. For each variable, all constraints of the bucket are replaced as above to remove the variable. The resulting constraint is then placed in the appropriate bucket.</p>
<h2 id="see-also">See also</h2>
<ul>
<li><a href="Integer_programming" title="wikilink">Integer programming</a></li>
<li><a href="Distributed_constraint_optimization" title="wikilink">Distributed constraint optimization</a></li>
<li><a href="Penalty_method" title="wikilink">Penalty method</a></li>
</ul>
<h2 id="references">References</h2>
<ul>
<li></li>
</ul>

<p>"</p>

<p><a href="Category:Mathematical_optimization" title="wikilink">Category:Mathematical optimization</a> <a href="Category:Constraint_programming" title="wikilink">Category:Constraint programming</a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1">Wenyu Sun; Ya-Xiang Yua (2010). <em>Optimization Theory and Methods: Nonlinear Programming</em>, Springer, ISBN 978-1441937650. p. 541<a href="#fnref1">‚Ü©</a></li>
<li id="fn2"><a href="#fnref2">‚Ü©</a></li>
<li id="fn3">Verfaillie, G√©rard, Michel Lema√Ætre, and Thomas Schiex. "Russian doll search for solving constraint optimization problems." AAAI/IAAI, Vol. 1. 1996.<a href="#fnref3">‚Ü©</a></li>
</ol>
</section>
</body>
</html>
