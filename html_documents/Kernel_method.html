<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="329">Kernel method</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>Kernel method</h1>
<hr/>

<p>In <a href="machine_learning" title="wikilink">machine learning</a>, <strong>kernel methods</strong> are a class of algorithms for <a href="pattern_analysis" title="wikilink">pattern analysis</a>, whose best known member is the <a href="support_vector_machine" title="wikilink">support vector machine</a> (SVM). The general task of pattern analysis is to find and study general types of relations (for example <a href="Cluster_analysis" title="wikilink">clusters</a>, <a href="ranking" title="wikilink">rankings</a>, <a href="principal_components" title="wikilink">principal components</a>, <a href="correlation" title="wikilink">correlations</a>, <a href="Statistical_classification" title="wikilink">classifications</a>) in datasets. For many algorithms that solve these tasks, the data in raw representation have to be explicitly transformed into <a href="feature_vector" title="wikilink">feature vector</a> representations via a user-specified <em>feature map</em>: in contrast, kernel methods require only a user-specified <em>kernel</em>, i.e., a <a href="similarity_function" title="wikilink">similarity function</a> over pairs of data points in raw representation.</p>

<p>Kernel methods owe their name to the use of <a href="Positive-definite_kernel" title="wikilink">kernel functions</a>, which enable them to operate in a high-dimensional, <em>implicit</em> feature space without ever computing the coordinates of the data in that space, but rather by simply computing the <a href="inner_product" title="wikilink">inner products</a> between the images of all pairs of data in the feature space. This operation is often computationally cheaper than the explicit computation of the coordinates. This approach is called the "<strong>kernel trick</strong>". Kernel functions have been introduced for sequence data, <a href="Graph_kernel" title="wikilink">graphs</a>, text, images, as well as vectors.</p>

<p>Algorithms capable of operating with kernels include the <a href="kernel_perceptron" title="wikilink">kernel perceptron</a>, support vector machines (SVM), <a href="Gaussian_process" title="wikilink">Gaussian processes</a>, <a href="principal_components_analysis" title="wikilink">principal components analysis</a> (PCA), <a href="canonical_correlation_analysis" title="wikilink">canonical correlation analysis</a>, <a href="ridge_regression" title="wikilink">ridge regression</a>, <a href="spectral_clustering" title="wikilink">spectral clustering</a>, <a href="Adaptive_filter" title="wikilink">linear adaptive filters</a> and many others. Any <a href="linear_model" title="wikilink">linear model</a> can be turned into a non-linear model by applying the kernel trick to the model: replacing its features (predictors) by a kernel function.</p>

<p>Most kernel algorithms are based on <a href="convex_optimization" title="wikilink">convex optimization</a> or <a href="Eigenvalue,_eigenvector_and_eigenspace" title="wikilink">eigenproblems</a> and are statistically well-founded. Typically, their statistical properties are analyzed using <a href="statistical_learning_theory" title="wikilink">statistical learning theory</a> (for example, using <a href="Rademacher_complexity" title="wikilink">Rademacher complexity</a>).</p>
<h2 id="motivation-and-informal-explanation">Motivation and informal explanation</h2>

<p>Kernel methods can be thought of as <a href="instance-based_learning" title="wikilink">instance-based learners</a>: rather than learning some fixed set of parameters corresponding to the features of their inputs, they instead "remember" the 

<math display="inline" id="Kernel_method:0">
 <semantics>
  <mi>i</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>i</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   i
  </annotation>
 </semantics>
</math>

-th training example 

<math display="inline" id="Kernel_method:1">
 <semantics>
  <mrow>
   <mo stretchy="false">(</mo>
   <msub>
    <mi>ğ±</mi>
    <mi>i</mi>
   </msub>
   <mo>,</mo>
   <msub>
    <mi>y</mi>
    <mi>i</mi>
   </msub>
   <mo stretchy="false">)</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <interval closure="open">
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>ğ±</ci>
     <ci>i</ci>
    </apply>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>y</ci>
     <ci>i</ci>
    </apply>
   </interval>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   (\mathbf{x}_{i},y_{i})
  </annotation>
 </semantics>
</math>

 by learning a corresponding weight 

<math display="inline" id="Kernel_method:2">
 <semantics>
  <msub>
   <mi>w</mi>
   <mi>i</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>w</ci>
    <ci>i</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   w_{i}
  </annotation>
 </semantics>
</math>

. Prediction for unlabeled inputs, i.e., those not in the training set, is treated by the application of a <a href="similarity_function" title="wikilink">similarity function</a> 

<math display="inline" id="Kernel_method:3">
 <semantics>
  <mi>k</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>k</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   k
  </annotation>
 </semantics>
</math>

, called a <strong>kernel</strong>, between the unlabeled input 

<math display="inline" id="Kernel_method:4">
 <semantics>
  <msup>
   <mi>ğ±</mi>
   <mo>â€²</mo>
  </msup>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">superscript</csymbol>
    <ci>ğ±</ci>
    <ci>normal-â€²</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \mathbf{x^{\prime}}
  </annotation>
 </semantics>
</math>

 and each of the training inputs 

<math display="inline" id="Kernel_method:5">
 <semantics>
  <msub>
   <mi>ğ±</mi>
   <mi>i</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>ğ±</ci>
    <ci>i</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \mathbf{x}_{i}
  </annotation>
 </semantics>
</math>

. For instance, a kernelized <a href="binary_classifier" title="wikilink">binary classifier</a> typically computes a weighted sum of similarities</p>

<p>

<math display="block" id="Kernel_method:6">
 <semantics>
  <mrow>
   <mover accent="true">
    <mi>y</mi>
    <mo stretchy="false">^</mo>
   </mover>
   <mo>=</mo>
   <mrow>
    <mo>sgn</mo>
    <mrow>
     <munderover>
      <mo largeop="true" movablelimits="false" symmetric="true">âˆ‘</mo>
      <mrow>
       <mi>i</mi>
       <mo>=</mo>
       <mn>1</mn>
      </mrow>
      <mi>n</mi>
     </munderover>
     <mrow>
      <msub>
       <mi>w</mi>
       <mi>i</mi>
      </msub>
      <msub>
       <mi>y</mi>
       <mi>i</mi>
      </msub>
      <mi>k</mi>
      <mrow>
       <mo stretchy="false">(</mo>
       <msub>
        <mi>ğ±</mi>
        <mi>i</mi>
       </msub>
       <mo>,</mo>
       <msup>
        <mi>ğ±</mi>
        <mo>â€²</mo>
       </msup>
       <mo stretchy="false">)</mo>
      </mrow>
     </mrow>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <ci>normal-^</ci>
     <ci>y</ci>
    </apply>
    <apply>
     <times></times>
     <ci>sgn</ci>
     <apply>
      <apply>
       <csymbol cd="ambiguous">superscript</csymbol>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <sum></sum>
        <apply>
         <eq></eq>
         <ci>i</ci>
         <cn type="integer">1</cn>
        </apply>
       </apply>
       <ci>n</ci>
      </apply>
      <apply>
       <times></times>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <ci>w</ci>
        <ci>i</ci>
       </apply>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <ci>y</ci>
        <ci>i</ci>
       </apply>
       <ci>k</ci>
       <interval closure="open">
        <apply>
         <csymbol cd="ambiguous">subscript</csymbol>
         <ci>ğ±</ci>
         <ci>i</ci>
        </apply>
        <apply>
         <csymbol cd="ambiguous">superscript</csymbol>
         <ci>ğ±</ci>
         <ci>normal-â€²</ci>
        </apply>
       </interval>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \hat{y}=\operatorname{sgn}\sum_{i=1}^{n}w_{i}y_{i}k(\mathbf{x}_{i},\mathbf{x^{%
\prime}})
  </annotation>
 </semantics>
</math>

,</p>

<p>where</p>
<ul>
<li>

<math display="inline" id="Kernel_method:7">
 <semantics>
  <mrow>
   <mover accent="true">
    <mi>y</mi>
    <mo stretchy="false">^</mo>
   </mover>
   <mo>âˆˆ</mo>
   <mrow>
    <mo stretchy="false">{</mo>
    <mrow>
     <mo>-</mo>
     <mn>1</mn>
    </mrow>
    <mo>,</mo>
    <mrow>
     <mo>+</mo>
     <mn>1</mn>
    </mrow>
    <mo stretchy="false">}</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <in></in>
    <apply>
     <ci>normal-^</ci>
     <ci>y</ci>
    </apply>
    <set>
     <apply>
      <minus></minus>
      <cn type="integer">1</cn>
     </apply>
     <apply>
      <plus></plus>
      <cn type="integer">1</cn>
     </apply>
    </set>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \hat{y}\in\{-1,+1\}
  </annotation>
 </semantics>
</math>

 is the kernelized binary classifier's predicted label for the unlabeled input 

<math display="inline" id="Kernel_method:8">
 <semantics>
  <msup>
   <mi>ğ±</mi>
   <mo>â€²</mo>
  </msup>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">superscript</csymbol>
    <ci>ğ±</ci>
    <ci>normal-â€²</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \mathbf{x^{\prime}}
  </annotation>
 </semantics>
</math>

 whose hidden true label 

<math display="inline" id="Kernel_method:9">
 <semantics>
  <mi>y</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>y</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   y
  </annotation>
 </semantics>
</math>

 is of interest;</li>
<li>

<math display="inline" id="Kernel_method:10">
 <semantics>
  <mrow>
   <mi>k</mi>
   <mo>:</mo>
   <mrow>
    <mrow>
     <mi class="ltx_font_mathcaligraphic">ğ’³</mi>
     <mo>Ã—</mo>
     <mi class="ltx_font_mathcaligraphic">ğ’³</mi>
    </mrow>
    <mo>â†’</mo>
    <mi>â„</mi>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <ci>normal-:</ci>
    <ci>k</ci>
    <apply>
     <ci>normal-â†’</ci>
     <apply>
      <times></times>
      <ci>ğ’³</ci>
      <ci>ğ’³</ci>
     </apply>
     <ci>â„</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   k\colon\mathcal{X}\times\mathcal{X}\to\mathbb{R}
  </annotation>
 </semantics>
</math>

 is the kernel function that measures similarity between any pair of inputs 

<math display="inline" id="Kernel_method:11">
 <semantics>
  <mrow>
   <mrow>
    <mi>ğ±</mi>
    <mo>,</mo>
    <msup>
     <mi>ğ±</mi>
     <mo>â€²</mo>
    </msup>
   </mrow>
   <mo>âˆˆ</mo>
   <mi class="ltx_font_mathcaligraphic">ğ’³</mi>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <in></in>
    <list>
     <ci>ğ±</ci>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <ci>ğ±</ci>
      <ci>normal-â€²</ci>
     </apply>
    </list>
    <ci>ğ’³</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \mathbf{x},\mathbf{x^{\prime}}\in\mathcal{X}
  </annotation>
 </semantics>
</math>

;</li>
<li>the sum ranges over the 

<math display="inline" id="Kernel_method:12">
 <semantics>
  <mi>n</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>n</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   n
  </annotation>
 </semantics>
</math>

 labeled examples 

<math display="inline" id="Kernel_method:13">
 <semantics>
  <msubsup>
   <mrow>
    <mo stretchy="false">{</mo>
    <mrow>
     <mo stretchy="false">(</mo>
     <msub>
      <mi>ğ±</mi>
      <mi>i</mi>
     </msub>
     <mo>,</mo>
     <msub>
      <mi>y</mi>
      <mi>i</mi>
     </msub>
     <mo stretchy="false">)</mo>
    </mrow>
    <mo stretchy="false">}</mo>
   </mrow>
   <mrow>
    <mi>i</mi>
    <mo>=</mo>
    <mn>1</mn>
   </mrow>
   <mi>n</mi>
  </msubsup>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">superscript</csymbol>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <set>
      <interval closure="open">
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <ci>ğ±</ci>
        <ci>i</ci>
       </apply>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <ci>y</ci>
        <ci>i</ci>
       </apply>
      </interval>
     </set>
     <apply>
      <eq></eq>
      <ci>i</ci>
      <cn type="integer">1</cn>
     </apply>
    </apply>
    <ci>n</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \{(\mathbf{x}_{i},y_{i})\}_{i=1}^{n}
  </annotation>
 </semantics>
</math>

 in the classifier's training set, with 

<math display="inline" id="Kernel_method:14">
 <semantics>
  <mrow>
   <msub>
    <mi>y</mi>
    <mi>i</mi>
   </msub>
   <mo>âˆˆ</mo>
   <mrow>
    <mo stretchy="false">{</mo>
    <mrow>
     <mo>-</mo>
     <mn>1</mn>
    </mrow>
    <mo>,</mo>
    <mrow>
     <mo>+</mo>
     <mn>1</mn>
    </mrow>
    <mo stretchy="false">}</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <in></in>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>y</ci>
     <ci>i</ci>
    </apply>
    <set>
     <apply>
      <minus></minus>
      <cn type="integer">1</cn>
     </apply>
     <apply>
      <plus></plus>
      <cn type="integer">1</cn>
     </apply>
    </set>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   y_{i}\in\{-1,+1\}
  </annotation>
 </semantics>
</math>

;</li>
<li>the 

<math display="inline" id="Kernel_method:15">
 <semantics>
  <mrow>
   <msub>
    <mi>w</mi>
    <mi>i</mi>
   </msub>
   <mo>âˆˆ</mo>
   <mi>â„</mi>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <in></in>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>w</ci>
     <ci>i</ci>
    </apply>
    <ci>â„</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   w_{i}\in\mathbb{R}
  </annotation>
 </semantics>
</math>

 are the weights for the training examples, as determined by the learning algorithm;</li>
<li>the <a href="sign_function" title="wikilink">sign function</a> 

<math display="inline" id="Kernel_method:16">
 <semantics>
  <mo>sgn</mo>
  <annotation-xml encoding="MathML-Content">
   <ci>sgn</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \operatorname{sgn}
  </annotation>
 </semantics>
</math>

 determines whether the predicted classification 

<math display="inline" id="Kernel_method:17">
 <semantics>
  <mover accent="true">
   <mi>y</mi>
   <mo stretchy="false">^</mo>
  </mover>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <ci>normal-^</ci>
    <ci>y</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \hat{y}
  </annotation>
 </semantics>
</math>

 comes out positive or negative.</li>
</ul>

<p>Kernel classifiers were described as early as the 1960s, with the invention of the <a href="kernel_perceptron" title="wikilink">kernel perceptron</a>.<a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a> They rose to great prominence with the popularity of the <a href="support_vector_machine" title="wikilink">support vector machine</a> (SVM) in the 1990s, when the SVM was found to be competitive with <a href="artificial_neural_network" title="wikilink">neural networks</a> on tasks such as <a href="handwriting_recognition" title="wikilink">handwriting recognition</a>.</p>
<h2 id="mathematics">Mathematics</h2>

<p>The kernel trick avoids the explicit mapping that is needed to get linear <a href="learning_algorithms" title="wikilink">learning algorithms</a> to learn a nonlinear function or <a href="decision_boundary" title="wikilink">decision boundary</a>. For all 

<math display="inline" id="Kernel_method:18">
 <semantics>
  <mi>ğ±</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>ğ±</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \mathbf{x}
  </annotation>
 </semantics>
</math>

 and 

<math display="inline" id="Kernel_method:19">
 <semantics>
  <msup>
   <mi>ğ±</mi>
   <mo>â€²</mo>
  </msup>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">superscript</csymbol>
    <ci>ğ±</ci>
    <ci>normal-â€²</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \mathbf{x^{\prime}}
  </annotation>
 </semantics>
</math>

 in the input space 

<math display="inline" id="Kernel_method:20">
 <semantics>
  <mi class="ltx_font_mathcaligraphic">ğ’³</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>ğ’³</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \mathcal{X}
  </annotation>
 </semantics>
</math>

, certain functions 

<math display="inline" id="Kernel_method:21">
 <semantics>
  <mrow>
   <mi>k</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <mi>ğ±</mi>
    <mo>,</mo>
    <msup>
     <mi>ğ±</mi>
     <mo>â€²</mo>
    </msup>
    <mo stretchy="false">)</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <ci>k</ci>
    <interval closure="open">
     <ci>ğ±</ci>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <ci>ğ±</ci>
      <ci>normal-â€²</ci>
     </apply>
    </interval>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   k(\mathbf{x},\mathbf{x^{\prime}})
  </annotation>
 </semantics>
</math>

 can be expressed as an <a href="inner_product" title="wikilink">inner product</a> in another space 

<math display="inline" id="Kernel_method:22">
 <semantics>
  <mi class="ltx_font_mathcaligraphic">ğ’±</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>ğ’±</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \mathcal{V}
  </annotation>
 </semantics>
</math>

. The function 

<math display="inline" id="Kernel_method:23">
 <semantics>
  <mrow>
   <mi>k</mi>
   <mo>:</mo>
   <mrow>
    <mrow>
     <mi class="ltx_font_mathcaligraphic">ğ’³</mi>
     <mo>Ã—</mo>
     <mi class="ltx_font_mathcaligraphic">ğ’³</mi>
    </mrow>
    <mo>â†’</mo>
    <mi>â„</mi>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <ci>normal-:</ci>
    <ci>k</ci>
    <apply>
     <ci>normal-â†’</ci>
     <apply>
      <times></times>
      <ci>ğ’³</ci>
      <ci>ğ’³</ci>
     </apply>
     <ci>â„</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   k\colon\mathcal{X}\times\mathcal{X}\to\mathbb{R}
  </annotation>
 </semantics>
</math>

 is often referred to as a <em>kernel</em> or a <em><a href="kernel_function" title="wikilink">kernel function</a></em>; the word "kernel" is used in different ways throughout mathematics.</p>

<p>If one is insightful regarding a particular machine learning problem, one may manually construct a "feature map" 

<math display="inline" id="Kernel_method:24">
 <semantics>
  <mrow>
   <mi>Ï†</mi>
   <mo>:</mo>
   <mrow>
    <mi class="ltx_font_mathcaligraphic">ğ’³</mi>
    <mo>â†’</mo>
    <mi class="ltx_font_mathcaligraphic">ğ’±</mi>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <ci>normal-:</ci>
    <ci>Ï†</ci>
    <apply>
     <ci>normal-â†’</ci>
     <ci>ğ’³</ci>
     <ci>ğ’±</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \varphi\colon\mathcal{X}\to\mathcal{V}
  </annotation>
 </semantics>
</math>

 such that</p>

<p>

<math display="block" id="Kernel_method:25">
 <semantics>
  <mrow>
   <mrow>
    <mi>k</mi>
    <mrow>
     <mo stretchy="false">(</mo>
     <mi>ğ±</mi>
     <mo>,</mo>
     <msup>
      <mi>ğ±</mi>
      <mo>â€²</mo>
     </msup>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
   <mo>=</mo>
   <msub>
    <mrow>
     <mo stretchy="false">âŸ¨</mo>
     <mrow>
      <mi>Ï†</mi>
      <mrow>
       <mo stretchy="false">(</mo>
       <mi>ğ±</mi>
       <mo stretchy="false">)</mo>
      </mrow>
     </mrow>
     <mo>,</mo>
     <mrow>
      <mi>Ï†</mi>
      <mrow>
       <mo stretchy="false">(</mo>
       <msup>
        <mi>ğ±</mi>
        <mo>â€²</mo>
       </msup>
       <mo stretchy="false">)</mo>
      </mrow>
     </mrow>
     <mo stretchy="false">âŸ©</mo>
    </mrow>
    <mi class="ltx_font_mathcaligraphic">ğ’±</mi>
   </msub>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <times></times>
     <ci>k</ci>
     <interval closure="open">
      <ci>ğ±</ci>
      <apply>
       <csymbol cd="ambiguous">superscript</csymbol>
       <ci>ğ±</ci>
       <ci>normal-â€²</ci>
      </apply>
     </interval>
    </apply>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <list>
      <apply>
       <times></times>
       <ci>Ï†</ci>
       <ci>ğ±</ci>
      </apply>
      <apply>
       <times></times>
       <ci>Ï†</ci>
       <apply>
        <csymbol cd="ambiguous">superscript</csymbol>
        <ci>ğ±</ci>
        <ci>normal-â€²</ci>
       </apply>
      </apply>
     </list>
     <ci>ğ’±</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   k(\mathbf{x},\mathbf{x^{\prime}})=\langle\varphi(\mathbf{x}),\varphi(\mathbf{x%
^{\prime}})\rangle_{\mathcal{V}}
  </annotation>
 </semantics>
</math>

 and verify that 

<math display="inline" id="Kernel_method:26">
 <semantics>
  <msub>
   <mrow>
    <mo stretchy="false">âŸ¨</mo>
    <mo>â‹…</mo>
    <mo>,</mo>
    <mo>â‹…</mo>
    <mo stretchy="false">âŸ©</mo>
   </mrow>
   <mi class="ltx_font_mathcaligraphic">ğ’±</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <list>
     <ci>normal-â‹…</ci>
     <ci>normal-â‹…</ci>
    </list>
    <ci>ğ’±</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \langle\cdot,\cdot\rangle_{\mathcal{V}}
  </annotation>
 </semantics>
</math>

 is indeed an inner product. In fact, an explicit representation for 

<math display="inline" id="Kernel_method:27">
 <semantics>
  <mi>Ï†</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>Ï†</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \varphi
  </annotation>
 </semantics>
</math>

 is not required: it suffices to show that 

<math display="inline" id="Kernel_method:28">
 <semantics>
  <mi class="ltx_font_mathcaligraphic">ğ’±</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>ğ’±</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \mathcal{V}
  </annotation>
 </semantics>
</math>

 is an <a href="inner_product_space" title="wikilink">inner product space</a>. Conveniently, based on <a href="Mercer's_theorem" title="wikilink">Mercer's theorem</a>, it suffices to equip 

<math display="inline" id="Kernel_method:29">
 <semantics>
  <mi class="ltx_font_mathcaligraphic">ğ’³</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>ğ’³</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \mathcal{X}
  </annotation>
 </semantics>
</math>

 with one's choice of <a href="Measure_(mathematics)" title="wikilink">measure</a> and verify that 

<math display="inline" id="Kernel_method:30">
 <semantics>
  <mi>k</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>k</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   k
  </annotation>
 </semantics>
</math>

 satisfies <a href="Mercer's_condition" title="wikilink">Mercer's condition</a>.</p>

<p>Mercer's theorem is stated in a general mathematical setting with implications in the theory of <a href="integral_equations" title="wikilink">integral equations</a>. However, the general statement is more than what is required for understanding the kernel trick. Given a finite observation set 

<math display="inline" id="Kernel_method:31">
 <semantics>
  <mi>X</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>X</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   X
  </annotation>
 </semantics>
</math>

, one can select the <a href="counting_measure" title="wikilink">counting measure</a> 

<math display="inline" id="Kernel_method:32">
 <semantics>
  <mrow>
   <mrow>
    <mi>Î¼</mi>
    <mrow>
     <mo stretchy="false">(</mo>
     <mi>T</mi>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
   <mo>=</mo>
   <mrow>
    <mo stretchy="false">|</mo>
    <mi>T</mi>
    <mo stretchy="false">|</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <times></times>
     <ci>Î¼</ci>
     <ci>T</ci>
    </apply>
    <apply>
     <abs></abs>
     <ci>T</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \mu(T)=|T|
  </annotation>
 </semantics>
</math>

 for all 

<math display="inline" id="Kernel_method:33">
 <semantics>
  <mrow>
   <mi>T</mi>
   <mo>âŠ‚</mo>
   <mi>X</mi>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <subset></subset>
    <ci>T</ci>
    <ci>X</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   T\subset X
  </annotation>
 </semantics>
</math>

. Then the integral in Mercer's theorem reduces to a simple summation</p>

<p>

<math display="block" id="Kernel_method:34">
 <semantics>
  <mrow>
   <mrow>
    <munderover>
     <mo largeop="true" movablelimits="false" symmetric="true">âˆ‘</mo>
     <mrow>
      <mi>i</mi>
      <mo>=</mo>
      <mn>1</mn>
     </mrow>
     <mi>n</mi>
    </munderover>
    <mrow>
     <munderover>
      <mo largeop="true" movablelimits="false" symmetric="true">âˆ‘</mo>
      <mrow>
       <mi>j</mi>
       <mo>=</mo>
       <mn>1</mn>
      </mrow>
      <mi>n</mi>
     </munderover>
     <mrow>
      <mi>k</mi>
      <mrow>
       <mo stretchy="false">(</mo>
       <msub>
        <mi>ğ±</mi>
        <mi>i</mi>
       </msub>
       <mo>,</mo>
       <msub>
        <mi>ğ±</mi>
        <mi>j</mi>
       </msub>
       <mo stretchy="false">)</mo>
      </mrow>
      <msub>
       <mi>c</mi>
       <mi>i</mi>
      </msub>
      <msub>
       <mi>c</mi>
       <mi>j</mi>
      </msub>
     </mrow>
    </mrow>
   </mrow>
   <mo>â‰¥</mo>
   <mn>0</mn>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <geq></geq>
    <apply>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <sum></sum>
       <apply>
        <eq></eq>
        <ci>i</ci>
        <cn type="integer">1</cn>
       </apply>
      </apply>
      <ci>n</ci>
     </apply>
     <apply>
      <apply>
       <csymbol cd="ambiguous">superscript</csymbol>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <sum></sum>
        <apply>
         <eq></eq>
         <ci>j</ci>
         <cn type="integer">1</cn>
        </apply>
       </apply>
       <ci>n</ci>
      </apply>
      <apply>
       <times></times>
       <ci>k</ci>
       <interval closure="open">
        <apply>
         <csymbol cd="ambiguous">subscript</csymbol>
         <ci>ğ±</ci>
         <ci>i</ci>
        </apply>
        <apply>
         <csymbol cd="ambiguous">subscript</csymbol>
         <ci>ğ±</ci>
         <ci>j</ci>
        </apply>
       </interval>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <ci>c</ci>
        <ci>i</ci>
       </apply>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <ci>c</ci>
        <ci>j</ci>
       </apply>
      </apply>
     </apply>
    </apply>
    <cn type="integer">0</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \sum_{i=1}^{n}\sum_{j=1}^{n}k(\mathbf{x}_{i},\mathbf{x}_{j})c_{i}c_{j}\geq 0
  </annotation>
 </semantics>
</math>

 for all finite sequences of points 

<math display="inline" id="Kernel_method:35">
 <semantics>
  <mrow>
   <mo stretchy="false">(</mo>
   <msub>
    <mi>ğ±</mi>
    <mn>1</mn>
   </msub>
   <mo>,</mo>
   <mi mathvariant="normal">â€¦</mi>
   <mo>,</mo>
   <msub>
    <mi>ğ±</mi>
    <mi>n</mi>
   </msub>
   <mo stretchy="false">)</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <vector>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>ğ±</ci>
     <cn type="integer">1</cn>
    </apply>
    <ci>normal-â€¦</ci>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>ğ±</ci>
     <ci>n</ci>
    </apply>
   </vector>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   (\mathbf{x}_{1},\ldots,\mathbf{x}_{n})
  </annotation>
 </semantics>
</math>

 in 

<math display="inline" id="Kernel_method:36">
 <semantics>
  <mi class="ltx_font_mathcaligraphic">ğ’³</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>ğ’³</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \mathcal{X}
  </annotation>
 </semantics>
</math>

 and all choices of 

<math display="inline" id="Kernel_method:37">
 <semantics>
  <mi>n</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>n</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   n
  </annotation>
 </semantics>
</math>

 real-valued coefficients 

<math display="inline" id="Kernel_method:38">
 <semantics>
  <mrow>
   <mo stretchy="false">(</mo>
   <msub>
    <mi>c</mi>
    <mn>1</mn>
   </msub>
   <mo>,</mo>
   <mi mathvariant="normal">â€¦</mi>
   <mo>,</mo>
   <msub>
    <mi>c</mi>
    <mi>n</mi>
   </msub>
   <mo stretchy="false">)</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <vector>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>c</ci>
     <cn type="integer">1</cn>
    </apply>
    <ci>normal-â€¦</ci>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>c</ci>
     <ci>n</ci>
    </apply>
   </vector>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   (c_{1},\dots,c_{n})
  </annotation>
 </semantics>
</math>

 (cf. <a href="positive_definite_kernel" title="wikilink">positive definite kernel</a>).</p>

<p>Some algorithms that depend on arbitrary relationships in the native space 

<math display="inline" id="Kernel_method:39">
 <semantics>
  <mi class="ltx_font_mathcaligraphic">ğ’³</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>ğ’³</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \mathcal{X}
  </annotation>
 </semantics>
</math>

 would, in fact, have a linear interpretation in a different setting: the range space of 

<math display="inline" id="Kernel_method:40">
 <semantics>
  <mi>Ï†</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>Ï†</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \varphi
  </annotation>
 </semantics>
</math>

. The linear interpretation gives us insight about the algorithm. Furthermore, there is often no need to compute 

<math display="inline" id="Kernel_method:41">
 <semantics>
  <mi>Ï†</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>Ï†</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \varphi
  </annotation>
 </semantics>
</math>

 directly during computation, as is the case with <a href="support_vector_machines" title="wikilink">support vector machines</a>. Some cite this running time shortcut as the primary benefit. Researchers also use it to justify the meanings and properties of existing algorithms.</p>

<p>Theoretically, a <a href="Gram_matrix" title="wikilink">Gram matrix</a> 

<math display="inline" id="Kernel_method:42">
 <semantics>
  <mrow>
   <mi>ğŠ</mi>
   <mo>âˆˆ</mo>
   <msup>
    <mi>â„</mi>
    <mrow>
     <mi>n</mi>
     <mo>Ã—</mo>
     <mi>n</mi>
    </mrow>
   </msup>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <in></in>
    <ci>ğŠ</ci>
    <apply>
     <csymbol cd="ambiguous">superscript</csymbol>
     <ci>â„</ci>
     <apply>
      <times></times>
      <ci>n</ci>
      <ci>n</ci>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \mathbf{K}\in\mathbb{R}^{n\times n}
  </annotation>
 </semantics>
</math>

 with respect to 

<math display="inline" id="Kernel_method:43">
 <semantics>
  <mrow>
   <mo stretchy="false">{</mo>
   <msub>
    <mi>ğ±</mi>
    <mn>1</mn>
   </msub>
   <mo>,</mo>
   <mi mathvariant="normal">â€¦</mi>
   <mo>,</mo>
   <msub>
    <mi>ğ±</mi>
    <mi>n</mi>
   </msub>
   <mo stretchy="false">}</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <set>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>ğ±</ci>
     <cn type="integer">1</cn>
    </apply>
    <ci>normal-â€¦</ci>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>ğ±</ci>
     <ci>n</ci>
    </apply>
   </set>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \{\mathbf{x}_{1},\ldots,\mathbf{x}_{n}\}
  </annotation>
 </semantics>
</math>

 (sometimes also called a "kernel matrix"<a class="footnoteRef" href="#fn2" id="fnref2"><sup>2</sup></a>), where 

<math display="inline" id="Kernel_method:44">
 <semantics>
  <mrow>
   <mi>ğŠ</mi>
   <mo>=</mo>
   <msub>
    <mrow>
     <mo stretchy="false">(</mo>
     <mrow>
      <mi>k</mi>
      <mrow>
       <mo stretchy="false">(</mo>
       <msub>
        <mi>ğ±</mi>
        <mi>i</mi>
       </msub>
       <mo>,</mo>
       <msub>
        <mi>ğ±</mi>
        <mi>j</mi>
       </msub>
       <mo stretchy="false">)</mo>
      </mrow>
     </mrow>
     <mo stretchy="false">)</mo>
    </mrow>
    <mrow>
     <mi>i</mi>
     <mi>j</mi>
    </mrow>
   </msub>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <ci>ğŠ</ci>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <apply>
      <times></times>
      <ci>k</ci>
      <interval closure="open">
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <ci>ğ±</ci>
        <ci>i</ci>
       </apply>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <ci>ğ±</ci>
        <ci>j</ci>
       </apply>
      </interval>
     </apply>
     <apply>
      <times></times>
      <ci>i</ci>
      <ci>j</ci>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \mathbf{K}=(k(\mathbf{x}_{i},\mathbf{x}_{j}))_{ij}
  </annotation>
 </semantics>
</math>

, must be <a href="Positive-definite_matrix" title="wikilink">positive semi-definite (PSD)</a>.<a class="footnoteRef" href="#fn3" id="fnref3"><sup>3</sup></a> Empirically, for machine learning heuristics, choices of a function 

<math display="inline" id="Kernel_method:45">
 <semantics>
  <mi>k</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>k</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   k
  </annotation>
 </semantics>
</math>

 that do not satisfy Mercer's condition may still perform reasonably if 

<math display="inline" id="Kernel_method:46">
 <semantics>
  <mi>k</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>k</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   k
  </annotation>
 </semantics>
</math>

 at least approximates the intuitive idea of similarity.<a class="footnoteRef" href="#fn4" id="fnref4"><sup>4</sup></a> Regardless of whether 

<math display="inline" id="Kernel_method:47">
 <semantics>
  <mi>k</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>k</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   k
  </annotation>
 </semantics>
</math>

 is a Mercer kernel, 

<math display="inline" id="Kernel_method:48">
 <semantics>
  <mi>k</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>k</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   k
  </annotation>
 </semantics>
</math>

 may still be referred to as a "kernel".</p>

<p>If the kernel function 

<math display="inline" id="Kernel_method:49">
 <semantics>
  <mi>k</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>k</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   k
  </annotation>
 </semantics>
</math>

 is also a <a href="covariance_function" title="wikilink">covariance function</a> as used in <a href="Gaussian_processes" title="wikilink">Gaussian processes</a>, then the Gram matrix 

<math display="inline" id="Kernel_method:50">
 <semantics>
  <mi>ğŠ</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>ğŠ</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \mathbf{K}
  </annotation>
 </semantics>
</math>

 can also be called a <a href="covariance_matrix" title="wikilink">covariance matrix</a>.<a class="footnoteRef" href="#fn5" id="fnref5"><sup>5</sup></a></p>

<p>Finally, suppose that 

<math display="inline" id="Kernel_method:51">
 <semantics>
  <mi>ğŠ</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>ğŠ</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \mathbf{K}
  </annotation>
 </semantics>
</math>

 is a square matrix. Then 

<math display="inline" id="Kernel_method:52">
 <semantics>
  <mrow>
   <msup>
    <mi>ğŠ</mi>
    <mi mathvariant="normal">T</mi>
   </msup>
   <mi>ğŠ</mi>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <apply>
     <csymbol cd="ambiguous">superscript</csymbol>
     <ci>ğŠ</ci>
     <ci>normal-T</ci>
    </apply>
    <ci>ğŠ</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \mathbf{K}^{\mathrm{T}}\mathbf{K}
  </annotation>
 </semantics>
</math>

 is a PSD matrix.</p>
<h2 id="applications">Applications</h2>

<p>Application areas of kernel methods are diverse and include <a class="uri" href="geostatistics" title="wikilink">geostatistics</a>,<a class="footnoteRef" href="#fn6" id="fnref6"><sup>6</sup></a> <a class="uri" href="kriging" title="wikilink">kriging</a>, <a href="inverse_distance_weighting" title="wikilink">inverse distance weighting</a>, <a href="3D_reconstruction" title="wikilink">3D reconstruction</a>, <a class="uri" href="bioinformatics" title="wikilink">bioinformatics</a>, <a class="uri" href="chemoinformatics" title="wikilink">chemoinformatics</a>, <a href="information_extraction" title="wikilink">information extraction</a> and <a href="handwriting_recognition" title="wikilink">handwriting recognition</a>.</p>
<h2 id="popular-kernels">Popular kernels</h2>
<ul>
<li><a href="Fisher_kernel" title="wikilink">Fisher kernel</a></li>
<li><a href="Graph_kernel" title="wikilink">Graph kernels</a></li>
<li><a href="Polynomial_kernel" title="wikilink">Polynomial kernel</a></li>
<li><a href="RBF_kernel" title="wikilink">RBF kernel</a></li>
<li><a href="String_kernel" title="wikilink">String kernels</a></li>
</ul>
<h2 id="see-also">See also</h2>
<ul>
<li><a href="Kernel_regression" title="wikilink">Kernel regression</a></li>
<li><a href="Kernel_smoothing" title="wikilink">Kernel smoothing</a></li>
<li><a href="Kernel_methods_for_vector_output" title="wikilink">Kernel methods for vector output</a></li>
</ul>
<h2 id="notes">Notes</h2>
<h2 id="references">References</h2>
<ul>
<li></li>
<li></li>
</ul>
<h2 id="external-links">External links</h2>
<ul>
<li><a href="http://www.kernel-machines.org">Kernel-Machines Org</a>â€”community website</li>
<li><a href="http://www.support-vector-machines.org">www.support-vector-machines.org</a> <em>(Literature, Review, Software, Links related to Support Vector Machines - Academic Site)</em></li>
<li><a href="http://onlineprediction.net/?n=Main.KernelMethods">onlineprediction.net Kernel Methods Article</a></li>
</ul>

<p>"</p>

<p><a href="Category:Kernel_methods_for_machine_learning" title="wikilink">Category:Kernel methods for machine learning</a> <a class="uri" href="Category:Geostatistics" title="wikilink">Category:Geostatistics</a> <a href="Category:Classification_algorithms" title="wikilink">Category:Classification algorithms</a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1"> Cited in <a href="#fnref1">â†©</a></li>
<li id="fn2"><a href="#fnref2">â†©</a></li>
<li id="fn3"><a href="#fnref3">â†©</a></li>
<li id="fn4"><a class="uri" href="http://www.svms.org/mercer/">http://www.svms.org/mercer/</a><a href="#fnref4">â†©</a></li>
<li id="fn5"><a href="#fnref5">â†©</a></li>
<li id="fn6"><a href="#fnref6">â†©</a></li>
</ol>
</section>
</body>
</html>
