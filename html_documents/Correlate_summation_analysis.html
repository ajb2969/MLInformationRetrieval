<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="1664">Correlate summation analysis</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>Correlate summation analysis</h1>
<hr/>

<p><strong>Correlate summation analysis</strong> is a <a href="data_mining" title="wikilink">data mining</a> method. It is designed to find the <a href="Variable_(mathematics)" title="wikilink">variables</a> that are most <a href="covariance" title="wikilink">covariant</a> with all of the other variables being studied, relative to <a href="Data_clustering" title="wikilink">clustering</a>. Aggregate correlate summation is the product of the totaled negative <a class="uri" href="logarithm" title="wikilink">logarithm</a> of the <a href="p-value" title="wikilink">p-values</a> for all of the <a href="correlation" title="wikilink">correlations</a> to a given variable and its (normalized) <a href="standard_deviation" title="wikilink">standard deviation</a>-to-<a class="uri" href="mean" title="wikilink">mean</a> quotient. Discrete correlate summation is the product of the totaled absolute value of the logarithm of the p-value ratios between two groups' correlations to a given variable and its absolute value of the logarithm of the group mean ratios.</p>
<h2 id="correlate-summation-template">Correlate summation template</h2>

<p>This zipped Excel template performs a correlate summation analysis for up to 100 variables for 4 groups of 15 subjects:</p>

<p><a href="http://sites.google.com/site/correlatesummationtemplate/Home/correlate-summation-template/correlate.zip?attredirects=0">1</a></p>

<p>The paper <a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a> describing the method is embedded in the spreadsheet.</p>
<h2 id="discrete-correlate-summation">Discrete correlate summation</h2>

<p>Given two groups, a correlation <a href="matrix_(mathematics)" title="wikilink">matrix</a> (<em>m</em> by <em>m</em>) was constructed for <em>m</em> variables for each group. Each column represents all of the correlations (<em>r</em>) between a given variable and each of the other variables. For variables with either heterogeneous or homogeneous numbers of data points (<em>n</em>), the <em>n</em> for each individual correlation was calculated by assigning each data point with a value of one and taking the sum of the products for each pair in that correlation.</p>

<p>The correlations were tested for linearity using <a href="Student's_t-distribution" title="wikilink">Student's t-distribution</a> to evaluate:</p>

<p>

<math display="block" id="Correlate_summation_analysis:0">
 <semantics>
  <mrow>
   <mi>t</mi>
   <mo>=</mo>
   <mfrac>
    <mrow>
     <mo stretchy="false">|</mo>
     <mi>r</mi>
     <mo stretchy="false">|</mo>
    </mrow>
    <msqrt>
     <mfrac>
      <mrow>
       <mn>1</mn>
       <mo>-</mo>
       <msup>
        <mi>r</mi>
        <mn>2</mn>
       </msup>
      </mrow>
      <mrow>
       <mi>n</mi>
       <mo>-</mo>
       <mn>2</mn>
      </mrow>
     </mfrac>
    </msqrt>
   </mfrac>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <ci>t</ci>
    <apply>
     <divide></divide>
     <apply>
      <abs></abs>
      <ci>r</ci>
     </apply>
     <apply>
      <root></root>
      <apply>
       <divide></divide>
       <apply>
        <minus></minus>
        <cn type="integer">1</cn>
        <apply>
         <csymbol cd="ambiguous">superscript</csymbol>
         <ci>r</ci>
         <cn type="integer">2</cn>
        </apply>
       </apply>
       <apply>
        <minus></minus>
        <ci>n</ci>
        <cn type="integer">2</cn>
       </apply>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   t=\frac{|r|}{\sqrt{\frac{1-r^{2}}{n-2}}}
  </annotation>
 </semantics>
</math>

</p>

<p>for (<em>n</em> − 2) degrees of freedom, returning two tails.<a class="footnoteRef" href="#fn2" id="fnref2"><sup>2</sup></a></p>

<p>The correlation matrices were thus transformed into linear probability matrices. For the two groups, the absolute value of the logarithm of the ratio of each comparison’s p-value gives a log correlation ratio that is larger as the ratio approaches zero or infinity. Each column was totaled to form the discrete correlate summation array. As in the log correlation ratio (log<sub>cr</sub>), the log mean ratio (log<sub>mr</sub>) for the two groups’ means was acquired for each variable. The correlate summation was then multiplied by the log mean ratio, to yield the discrete mean-correlate summation (DCΣ<sub>x</sub>).<a class="footnoteRef" href="#fn3" id="fnref3"><sup>3</sup></a></p>
<h2 id="aggregate-correlate-summation">Aggregate correlate summation</h2>

<p>As in the discrete correlate summation, a linear probability matrix was calculated for all of the data (no grouping). The negative logarithm was taken for all of the p-values; the columns were totaled to give the aggregate correlate summation (ACΣ) array. The standard deviation for each variable is divided by its mean to normalize the variances between variables. Data with a <a href="bimodal_distribution" title="wikilink">bimodal distribution</a> will have a larger normalized standard deviation (nSD) than will data with a <a href="normal_distribution" title="wikilink">normal distribution</a>. The nSD array multiplied by the ACΣ array yielded the aggregate mean-correlate summation (ACΣ<sub>x</sub>).<a class="footnoteRef" href="#fn4" id="fnref4"><sup>4</sup></a></p>
<h2 id="non-linear-modeling">Non-linear modeling</h2>

<p>A linear correlation between variables for a given sample set is typically the initial step in the investigation of relationships, which may lead to an underlying mechanism. The variation (either inherent or in response to a challenge) in a given population gives rise to correlations of variables of which only a portion of the <a href="sigmoid_function" title="wikilink">sigmoidal</a> (<a href="Control_system" title="wikilink">control</a>) relationship may be evident. Generally in the face of data that defies <a href="linear_regression" title="wikilink">linear regression</a>, data patterns indicate <a href="power_(mathematics)" title="wikilink">power</a> relationship of the general type:</p>

<p>

<math display="block" id="Correlate_summation_analysis:1">
 <semantics>
  <mrow>
   <mi>y</mi>
   <mo>=</mo>
   <mrow>
    <mi>m</mi>
    <msup>
     <mi>x</mi>
     <mi>a</mi>
    </msup>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <ci>y</ci>
    <apply>
     <times></times>
     <ci>m</ci>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <ci>x</ci>
      <ci>a</ci>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   y=mx^{a}
  </annotation>
 </semantics>
</math>

</p>

<p>Type 1: <em>a</em>  1 is a power function</p>

<p>(In all five cases a <a href="log-log_plot" title="wikilink">log-log plot</a> yields a linear curve.) <a class="footnoteRef" href="#fn5" id="fnref5"><sup>5</sup></a></p>

<p>On a positive sigmoidal/<a href="logistic_curve" title="wikilink">logistic curve</a>, the initial, intermediate and late portions resemble power, linear and root functions, respectively. Also, the late portion of a negative control function is reminiscent of a hyperbolic curve.</p>

<p>In an analysis of variable correlation, the sigmoidal relationship of the entire (unsampled in some cases) data range should be considered. This type of analysis is accomplished by regression with either a logistic curve or <a href="simple_linear_regression" title="wikilink">simple linear regression</a> with further investigation of the Type 1, 3 and 5 power relationships.<a class="footnoteRef" href="#fn6" id="fnref6"><sup>6</sup></a></p>
<h2 id="references">References</h2>

<p>"</p>

<p><a href="Category:Covariance_and_correlation" title="wikilink">Category:Covariance and correlation</a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1"><a href="#fnref1">↩</a></li>
<li id="fn2">Swinscow, T. (1997) <em><a href="http://www.bmj.com/collections/statsbk/11.dtl">Statistics at Square One</a></em>. BMJ Publishing Group.<a href="#fnref2">↩</a></li>
<li id="fn3"></li>
<li id="fn4"></li>
<li id="fn5">Mandel, J. (1984) <em>The Statistical Analysis of Experimental Data</em>. Dover Publications, Mineola, NY.<a href="#fnref5">↩</a></li>
<li id="fn6"></li>
</ol>
</section>
</body>
</html>
