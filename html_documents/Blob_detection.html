<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="1176">Blob detection</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>Blob detection</h1>
<hr/>

<p>In <a href="computer_vision" title="wikilink">computer vision</a>, <strong>blob detection</strong> methods are aimed at detecting regions in a <a href="digital_image" title="wikilink">digital image</a> that differ in properties, such as brightness or color, compared to surrounding regions. Informally, a blob is a region of an image in which some properties are constant or approximately constant; all the points in a blob can be considered in some sense to be similar to each other.</p>

<p>Given some property of interest expressed as a function of position on the image, there are two main classes of blob detectors: (i) <em><a href="Differential_calculus" title="wikilink">differential</a> methods</em>, which are based on derivatives of the function with respect to position, and (ii) <em>methods based on local <a href="Maxima_and_minima" title="wikilink">extrema</a></em>, which are based on finding the local maxima and minima of the function. With the more recent terminology used in the field, these detectors can also be referred to as <em>interest point operators</em>, or alternatively interest region operators (see also <a href="interest_point_detection" title="wikilink">interest point detection</a> and <a href="corner_detection" title="wikilink">corner detection</a>).</p>

<p>There are several motivations for studying and developing blob detectors. One main reason is to provide complementary information about regions, which is not obtained from <a href="edge_detection" title="wikilink">edge detectors</a> or <a href="corner_detection" title="wikilink">corner detectors</a>. In early work in the area, blob detection was used to obtain regions of interest for further processing. These regions could signal the presence of objects or parts of objects in the image domain with application to <a href="object_recognition" title="wikilink">object recognition</a> and/or object <a href="video_tracking" title="wikilink">tracking</a>. In other domains, such as <a href="Image_histogram" title="wikilink">histogram</a> analysis, blob descriptors can also be used for peak detection with application to <a href="segmentation_(image_processing)" title="wikilink">segmentation</a>. Another common use of blob descriptors is as main primitives for <a href="wikt:texture" title="wikilink">texture</a> analysis and texture recognition. In more recent work, blob descriptors have found increasingly popular use as <a href="interest_point_detection" title="wikilink">interest points</a> for wide baseline <a href="image_registration" title="wikilink">stereo matching</a> and to signal the presence of informative image features for appearance-based object recognition based on local image statistics. There is also the related notion of <a href="ridge_detection" title="wikilink">ridge detection</a> to signal the presence of elongated objects.</p>
<h2 id="the-laplacian-of-gaussian">The Laplacian of Gaussian</h2>

<p>One of the first and also most common blob detectors is based on the <a class="uri" href="Laplacian" title="wikilink">Laplacian</a> of the <a href="Gaussian_filter" title="wikilink">Gaussian</a> (LoG). Given an input image 

<math display="inline" id="Blob_detection:0">
 <semantics>
  <mrow>
   <mi>f</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <mi>x</mi>
    <mo>,</mo>
    <mi>y</mi>
    <mo stretchy="false">)</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <ci>f</ci>
    <interval closure="open">
     <ci>x</ci>
     <ci>y</ci>
    </interval>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   f(x,y)
  </annotation>
 </semantics>
</math>

, this image is <a href="Convolution" title="wikilink">convolved</a> by a Gaussian kernel</p>

<p>

<math display="block" id="Blob_detection:1">
 <semantics>
  <mrow>
   <mrow>
    <mi>g</mi>
    <mrow>
     <mo stretchy="false">(</mo>
     <mi>x</mi>
     <mo>,</mo>
     <mi>y</mi>
     <mo>,</mo>
     <mi>t</mi>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
   <mo>=</mo>
   <mrow>
    <mfrac>
     <mn>1</mn>
     <mrow>
      <mn>2</mn>
      <mi>π</mi>
      <msup>
       <mi>t</mi>
       <mn>2</mn>
      </msup>
     </mrow>
    </mfrac>
    <msup>
     <mi>e</mi>
     <mrow>
      <mo>-</mo>
      <mfrac>
       <mrow>
        <msup>
         <mi>x</mi>
         <mn>2</mn>
        </msup>
        <mo>+</mo>
        <msup>
         <mi>y</mi>
         <mn>2</mn>
        </msup>
       </mrow>
       <mrow>
        <mn>2</mn>
        <msup>
         <mi>t</mi>
         <mn>2</mn>
        </msup>
       </mrow>
      </mfrac>
     </mrow>
    </msup>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <times></times>
     <ci>g</ci>
     <vector>
      <ci>x</ci>
      <ci>y</ci>
      <ci>t</ci>
     </vector>
    </apply>
    <apply>
     <times></times>
     <apply>
      <divide></divide>
      <cn type="integer">1</cn>
      <apply>
       <times></times>
       <cn type="integer">2</cn>
       <ci>π</ci>
       <apply>
        <csymbol cd="ambiguous">superscript</csymbol>
        <ci>t</ci>
        <cn type="integer">2</cn>
       </apply>
      </apply>
     </apply>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <ci>e</ci>
      <apply>
       <minus></minus>
       <apply>
        <divide></divide>
        <apply>
         <plus></plus>
         <apply>
          <csymbol cd="ambiguous">superscript</csymbol>
          <ci>x</ci>
          <cn type="integer">2</cn>
         </apply>
         <apply>
          <csymbol cd="ambiguous">superscript</csymbol>
          <ci>y</ci>
          <cn type="integer">2</cn>
         </apply>
        </apply>
        <apply>
         <times></times>
         <cn type="integer">2</cn>
         <apply>
          <csymbol cd="ambiguous">superscript</csymbol>
          <ci>t</ci>
          <cn type="integer">2</cn>
         </apply>
        </apply>
       </apply>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   g(x,y,t)=\frac{1}{2\pi t^{2}}e^{-\frac{x^{2}+y^{2}}{2t^{2}}}
  </annotation>
 </semantics>
</math>

</p>

<p>at a certain scale 

<math display="inline" id="Blob_detection:2">
 <semantics>
  <mi>t</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>t</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   t
  </annotation>
 </semantics>
</math>

 to give a <a href="scale_space_representation" title="wikilink">scale space representation</a> 

<math display="inline" id="Blob_detection:3">
 <semantics>
  <mrow>
   <mrow>
    <mi>L</mi>
    <mrow>
     <mo stretchy="false">(</mo>
     <mi>x</mi>
     <mo>,</mo>
     <mi>y</mi>
     <mo>;</mo>
     <mi>t</mi>
     <mo rspace="7.5pt" stretchy="false">)</mo>
    </mrow>
   </mrow>
   <mo>=</mo>
   <mrow>
    <mrow>
     <mrow>
      <mi>g</mi>
      <mrow>
       <mo stretchy="false">(</mo>
       <mi>x</mi>
       <mo>,</mo>
       <mi>y</mi>
       <mo>,</mo>
       <mi>t</mi>
       <mo stretchy="false">)</mo>
      </mrow>
     </mrow>
     <mo>*</mo>
     <mi>f</mi>
    </mrow>
    <mrow>
     <mo stretchy="false">(</mo>
     <mi>x</mi>
     <mo>,</mo>
     <mi>y</mi>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <times></times>
     <ci>L</ci>
     <vector>
      <ci>x</ci>
      <ci>y</ci>
      <ci>t</ci>
     </vector>
    </apply>
    <apply>
     <times></times>
     <apply>
      <times></times>
      <apply>
       <times></times>
       <ci>g</ci>
       <vector>
        <ci>x</ci>
        <ci>y</ci>
        <ci>t</ci>
       </vector>
      </apply>
      <ci>f</ci>
     </apply>
     <interval closure="open">
      <ci>x</ci>
      <ci>y</ci>
     </interval>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   L(x,y;t)\ =g(x,y,t)*f(x,y)
  </annotation>
 </semantics>
</math>

. Then, the result of applying the <a class="uri" href="Laplacian" title="wikilink">Laplacian</a> operator</p>

<p>

<math display="block" id="Blob_detection:4">
 <semantics>
  <mrow>
   <mrow>
    <msup>
     <mo>∇</mo>
     <mn>2</mn>
    </msup>
    <mi>L</mi>
   </mrow>
   <mo>=</mo>
   <mrow>
    <msub>
     <mi>L</mi>
     <mrow>
      <mi>x</mi>
      <mi>x</mi>
     </mrow>
    </msub>
    <mo>+</mo>
    <msub>
     <mi>L</mi>
     <mrow>
      <mi>y</mi>
      <mi>y</mi>
     </mrow>
    </msub>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <ci>normal-∇</ci>
      <cn type="integer">2</cn>
     </apply>
     <ci>L</ci>
    </apply>
    <apply>
     <plus></plus>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>L</ci>
      <apply>
       <times></times>
       <ci>x</ci>
       <ci>x</ci>
      </apply>
     </apply>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>L</ci>
      <apply>
       <times></times>
       <ci>y</ci>
       <ci>y</ci>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \nabla^{2}L=L_{xx}+L_{yy}
  </annotation>
 </semantics>
</math>

 is computed, which usually results in strong positive responses for dark blobs of extent 

<math display="inline" id="Blob_detection:5">
 <semantics>
  <msqrt>
   <mrow>
    <mn>2</mn>
    <mi>t</mi>
   </mrow>
  </msqrt>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <root></root>
    <apply>
     <times></times>
     <cn type="integer">2</cn>
     <ci>t</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \sqrt{2t}
  </annotation>
 </semantics>
</math>

 and strong negative responses for bright blobs of similar size. A main problem when applying this operator at a single scale, however, is that the operator response is strongly dependent on the relationship between the size of the blob structures in the image domain and the size of the Gaussian kernel used for pre-smoothing. In order to automatically capture blobs of different (unknown) size in the image domain, a multi-scale approach is therefore necessary.</p>

<p>A straightforward way to obtain a <em>multi-scale blob detector with automatic scale selection</em> is to consider the <em>scale-normalized Laplacian operator</em></p>

<p>

<math display="block" id="Blob_detection:6">
 <semantics>
  <mrow>
   <mrow>
    <mrow>
     <msubsup>
      <mo>∇</mo>
      <mrow>
       <mi>n</mi>
       <mi>o</mi>
       <mi>r</mi>
       <mi>m</mi>
      </mrow>
      <mn>2</mn>
     </msubsup>
     <mi>L</mi>
    </mrow>
    <mrow>
     <mo stretchy="false">(</mo>
     <mi>x</mi>
     <mo>,</mo>
     <mi>y</mi>
     <mo>;</mo>
     <mi>t</mi>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
   <mo>=</mo>
   <mrow>
    <mi>t</mi>
    <mrow>
     <mo stretchy="false">(</mo>
     <mrow>
      <msub>
       <mi>L</mi>
       <mrow>
        <mi>x</mi>
        <mi>x</mi>
       </mrow>
      </msub>
      <mo>+</mo>
      <msub>
       <mi>L</mi>
       <mrow>
        <mi>y</mi>
        <mi>y</mi>
       </mrow>
      </msub>
     </mrow>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <times></times>
     <apply>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <apply>
        <csymbol cd="ambiguous">superscript</csymbol>
        <ci>normal-∇</ci>
        <cn type="integer">2</cn>
       </apply>
       <apply>
        <times></times>
        <ci>n</ci>
        <ci>o</ci>
        <ci>r</ci>
        <ci>m</ci>
       </apply>
      </apply>
      <ci>L</ci>
     </apply>
     <vector>
      <ci>x</ci>
      <ci>y</ci>
      <ci>t</ci>
     </vector>
    </apply>
    <apply>
     <times></times>
     <ci>t</ci>
     <apply>
      <plus></plus>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>L</ci>
       <apply>
        <times></times>
        <ci>x</ci>
        <ci>x</ci>
       </apply>
      </apply>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>L</ci>
       <apply>
        <times></times>
        <ci>y</ci>
        <ci>y</ci>
       </apply>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \nabla^{2}_{norm}L(x,y;t)=t(L_{xx}+L_{yy})
  </annotation>
 </semantics>
</math>

 and to detect <em>scale-space maxima/minima</em>, that are points that are <em>simultaneously local maxima/minima of 

<math display="inline" id="Blob_detection:7">
 <semantics>
  <mrow>
   <msubsup>
    <mo>∇</mo>
    <mrow>
     <mi>n</mi>
     <mi>o</mi>
     <mi>r</mi>
     <mi>m</mi>
    </mrow>
    <mn>2</mn>
   </msubsup>
   <mi>L</mi>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <ci>normal-∇</ci>
      <cn type="integer">2</cn>
     </apply>
     <apply>
      <times></times>
      <ci>n</ci>
      <ci>o</ci>
      <ci>r</ci>
      <ci>m</ci>
     </apply>
    </apply>
    <ci>L</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \nabla^{2}_{norm}L
  </annotation>
 </semantics>
</math>

 with respect to both space and scale</em> (Lindeberg 1994, 1998). Thus, given a discrete two-dimensional input image 

<math display="inline" id="Blob_detection:8">
 <semantics>
  <mrow>
   <mi>f</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <mi>x</mi>
    <mo>,</mo>
    <mi>y</mi>
    <mo stretchy="false">)</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <ci>f</ci>
    <interval closure="open">
     <ci>x</ci>
     <ci>y</ci>
    </interval>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   f(x,y)
  </annotation>
 </semantics>
</math>

 a three-dimensional discrete scale-space volume 

<math display="inline" id="Blob_detection:9">
 <semantics>
  <mrow>
   <mi>L</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <mi>x</mi>
    <mo>,</mo>
    <mi>y</mi>
    <mo>,</mo>
    <mi>t</mi>
    <mo stretchy="false">)</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <ci>L</ci>
    <vector>
     <ci>x</ci>
     <ci>y</ci>
     <ci>t</ci>
    </vector>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   L(x,y,t)
  </annotation>
 </semantics>
</math>

 is computed and a point is regarded as a bright (dark) blob if the value at this point is greater (smaller) than the value in all its 26 neighbours. Thus, simultaneous selection of interest points 

<math display="inline" id="Blob_detection:10">
 <semantics>
  <mrow>
   <mo stretchy="false">(</mo>
   <mover accent="true">
    <mi>x</mi>
    <mo stretchy="false">^</mo>
   </mover>
   <mo>,</mo>
   <mover accent="true">
    <mi>y</mi>
    <mo stretchy="false">^</mo>
   </mover>
   <mo stretchy="false">)</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <interval closure="open">
    <apply>
     <ci>normal-^</ci>
     <ci>x</ci>
    </apply>
    <apply>
     <ci>normal-^</ci>
     <ci>y</ci>
    </apply>
   </interval>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   (\hat{x},\hat{y})
  </annotation>
 </semantics>
</math>

 and scales 

<math display="inline" id="Blob_detection:11">
 <semantics>
  <mover accent="true">
   <mi>t</mi>
   <mo stretchy="false">^</mo>
  </mover>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <ci>normal-^</ci>
    <ci>t</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \hat{t}
  </annotation>
 </semantics>
</math>

 is performed according to</p>

<p>

<math display="block" id="Blob_detection:12">
 <semantics>
  <mrow>
   <mrow>
    <mo stretchy="false">(</mo>
    <mover accent="true">
     <mi>x</mi>
     <mo stretchy="false">^</mo>
    </mover>
    <mo>,</mo>
    <mover accent="true">
     <mi>y</mi>
     <mo stretchy="false">^</mo>
    </mover>
    <mo>;</mo>
    <mover accent="true">
     <mi>t</mi>
     <mo stretchy="false">^</mo>
    </mover>
    <mo stretchy="false">)</mo>
   </mrow>
   <mo>=</mo>
   <mrow>
    <msub>
     <mo>argmaxminlocal</mo>
     <mrow>
      <mo stretchy="false">(</mo>
      <mi>x</mi>
      <mo>,</mo>
      <mi>y</mi>
      <mo>;</mo>
      <mi>t</mi>
      <mo stretchy="false">)</mo>
     </mrow>
    </msub>
    <mrow>
     <mo stretchy="false">(</mo>
     <mrow>
      <mrow>
       <msubsup>
        <mo>∇</mo>
        <mrow>
         <mi>n</mi>
         <mi>o</mi>
         <mi>r</mi>
         <mi>m</mi>
        </mrow>
        <mn>2</mn>
       </msubsup>
       <mi>L</mi>
      </mrow>
      <mrow>
       <mo stretchy="false">(</mo>
       <mi>x</mi>
       <mo>,</mo>
       <mi>y</mi>
       <mo>;</mo>
       <mi>t</mi>
       <mo stretchy="false">)</mo>
      </mrow>
     </mrow>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <vector>
     <apply>
      <ci>normal-^</ci>
      <ci>x</ci>
     </apply>
     <apply>
      <ci>normal-^</ci>
      <ci>y</ci>
     </apply>
     <apply>
      <ci>normal-^</ci>
      <ci>t</ci>
     </apply>
    </vector>
    <apply>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>argmaxminlocal</ci>
      <vector>
       <ci>x</ci>
       <ci>y</ci>
       <ci>t</ci>
      </vector>
     </apply>
     <apply>
      <times></times>
      <apply>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <apply>
         <csymbol cd="ambiguous">superscript</csymbol>
         <ci>normal-∇</ci>
         <cn type="integer">2</cn>
        </apply>
        <apply>
         <times></times>
         <ci>n</ci>
         <ci>o</ci>
         <ci>r</ci>
         <ci>m</ci>
        </apply>
       </apply>
       <ci>L</ci>
      </apply>
      <vector>
       <ci>x</ci>
       <ci>y</ci>
       <ci>t</ci>
      </vector>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   (\hat{x},\hat{y};\hat{t})=\operatorname{argmaxminlocal}_{(x,y;t)}(\nabla^{2}_{%
norm}L(x,y;t))
  </annotation>
 </semantics>
</math>

. Note that this notion of blob provides a concise and mathematically precise operational definition of the notion of "blob", which directly leads to an efficient and robust algorithm for blob detection. Some basic properties of blobs defined from scale-space maxima of the normalized Laplacian operator are that the responses are covariant with translations, rotations and rescalings in the image domain. Thus, if a scale-space maximum is assumed at a point 

<math display="inline" id="Blob_detection:13">
 <semantics>
  <mrow>
   <mo stretchy="false">(</mo>
   <msub>
    <mi>x</mi>
    <mn>0</mn>
   </msub>
   <mo>,</mo>
   <msub>
    <mi>y</mi>
    <mn>0</mn>
   </msub>
   <mo>;</mo>
   <msub>
    <mi>t</mi>
    <mn>0</mn>
   </msub>
   <mo stretchy="false">)</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <vector>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>x</ci>
     <cn type="integer">0</cn>
    </apply>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>y</ci>
     <cn type="integer">0</cn>
    </apply>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>t</ci>
     <cn type="integer">0</cn>
    </apply>
   </vector>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   (x_{0},y_{0};t_{0})
  </annotation>
 </semantics>
</math>

 then under a rescaling of the image by a scale factor 

<math display="inline" id="Blob_detection:14">
 <semantics>
  <mi>s</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>s</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   s
  </annotation>
 </semantics>
</math>

, there will be a scale-space maximum at 

<math display="inline" id="Blob_detection:15">
 <semantics>
  <mrow>
   <mo stretchy="false">(</mo>
   <mrow>
    <mi>s</mi>
    <msub>
     <mi>x</mi>
     <mn>0</mn>
    </msub>
   </mrow>
   <mo>,</mo>
   <mrow>
    <mi>s</mi>
    <msub>
     <mi>y</mi>
     <mn>0</mn>
    </msub>
   </mrow>
   <mo>;</mo>
   <mrow>
    <msup>
     <mi>s</mi>
     <mn>2</mn>
    </msup>
    <msub>
     <mi>t</mi>
     <mn>0</mn>
    </msub>
   </mrow>
   <mo stretchy="false">)</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <vector>
    <apply>
     <times></times>
     <ci>s</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>x</ci>
      <cn type="integer">0</cn>
     </apply>
    </apply>
    <apply>
     <times></times>
     <ci>s</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>y</ci>
      <cn type="integer">0</cn>
     </apply>
    </apply>
    <apply>
     <times></times>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <ci>s</ci>
      <cn type="integer">2</cn>
     </apply>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>t</ci>
      <cn type="integer">0</cn>
     </apply>
    </apply>
   </vector>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   (sx_{0},sy_{0};s^{2}t_{0})
  </annotation>
 </semantics>
</math>

 in the rescaled image (Lindeberg 1998). This in practice highly useful property implies that besides the specific topic of Laplacian blob detection, <em>local maxima/minima of the scale-normalized Laplacian are also used for scale selection in other contexts</em>, such as in <a href="corner_detection" title="wikilink">corner detection</a>, scale-adaptive feature tracking (Bretzner and Lindeberg 1998), in the <a href="scale-invariant_feature_transform" title="wikilink">scale-invariant feature transform</a> (Lowe 2004) as well as other image descriptors for image matching and <a href="object_recognition" title="wikilink">object recognition</a>.</p>

<p>The scale selection properties of the Laplacian operator and other closely scale-space interest point detectors are analyzed in detail in (Lindeberg 2013a).<a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a> In (Lindeberg 2013b)<a class="footnoteRef" href="#fn2" id="fnref2"><sup>2</sup></a> it is shown that there exist other scale-space interest point detectors, such as the determinant of the Hessian operator, that perform better than Laplacian operator or its difference-of-Gaussians approximation for image-based matching using local SIFT-like image descriptors.</p>
<h2 id="the-difference-of-gaussians-approach">The difference of Gaussians approach</h2>

<p>From the fact that the <a href="scale_space_representation" title="wikilink">scale space representation</a> 

<math display="inline" id="Blob_detection:16">
 <semantics>
  <mrow>
   <mi>L</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <mi>x</mi>
    <mo>,</mo>
    <mi>y</mi>
    <mo>,</mo>
    <mi>t</mi>
    <mo stretchy="false">)</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <ci>L</ci>
    <vector>
     <ci>x</ci>
     <ci>y</ci>
     <ci>t</ci>
    </vector>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   L(x,y,t)
  </annotation>
 </semantics>
</math>

 satisfies the <a href="diffusion_equation" title="wikilink">diffusion equation</a></p>

<p>

<math display="block" id="Blob_detection:17">
 <semantics>
  <mrow>
   <mrow>
    <msub>
     <mo>∂</mo>
     <mi>t</mi>
    </msub>
    <mi>L</mi>
   </mrow>
   <mo>=</mo>
   <mrow>
    <mfrac>
     <mn>1</mn>
     <mn>2</mn>
    </mfrac>
    <mrow>
     <msup>
      <mo>∇</mo>
      <mn>2</mn>
     </msup>
     <mi>L</mi>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <partialdiff></partialdiff>
      <ci>t</ci>
     </apply>
     <ci>L</ci>
    </apply>
    <apply>
     <times></times>
     <apply>
      <divide></divide>
      <cn type="integer">1</cn>
      <cn type="integer">2</cn>
     </apply>
     <apply>
      <apply>
       <csymbol cd="ambiguous">superscript</csymbol>
       <ci>normal-∇</ci>
       <cn type="integer">2</cn>
      </apply>
      <ci>L</ci>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \partial_{t}L=\frac{1}{2}\nabla^{2}L
  </annotation>
 </semantics>
</math>

 it follows that the Laplacian of the Gaussian operator 

<math display="inline" id="Blob_detection:18">
 <semantics>
  <mrow>
   <mrow>
    <msup>
     <mo>∇</mo>
     <mn>2</mn>
    </msup>
    <mi>L</mi>
   </mrow>
   <mrow>
    <mo stretchy="false">(</mo>
    <mi>x</mi>
    <mo>,</mo>
    <mi>y</mi>
    <mo>,</mo>
    <mi>t</mi>
    <mo stretchy="false">)</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <apply>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <ci>normal-∇</ci>
      <cn type="integer">2</cn>
     </apply>
     <ci>L</ci>
    </apply>
    <vector>
     <ci>x</ci>
     <ci>y</ci>
     <ci>t</ci>
    </vector>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \nabla^{2}L(x,y,t)
  </annotation>
 </semantics>
</math>

 can also be computed as the limit case of the difference between two Gaussian smoothed images (<a href="scale_space_representation" title="wikilink">scale space representations</a>)</p>

<p>

<math display="inline" id="Blob_detection:19">
 <semantics>
  <mrow>
   <mrow>
    <msubsup>
     <mo>∇</mo>
     <mrow>
      <mi>n</mi>
      <mi>o</mi>
      <mi>r</mi>
      <mi>m</mi>
     </mrow>
     <mn>2</mn>
    </msubsup>
    <mi>L</mi>
   </mrow>
   <mrow>
    <mo stretchy="false">(</mo>
    <mi>x</mi>
    <mo>,</mo>
    <mi>y</mi>
    <mo>;</mo>
    <mi>t</mi>
    <mo stretchy="false">)</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <apply>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <apply>
       <csymbol cd="ambiguous">superscript</csymbol>
       <ci>normal-∇</ci>
       <cn type="integer">2</cn>
      </apply>
      <apply>
       <times></times>
       <ci>n</ci>
       <ci>o</ci>
       <ci>r</ci>
       <ci>m</ci>
      </apply>
     </apply>
     <ci>L</ci>
    </apply>
    <vector>
     <ci>x</ci>
     <ci>y</ci>
     <ci>t</ci>
    </vector>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \displaystyle\nabla^{2}_{norm}L(x,y;t)
  </annotation>
 </semantics>
</math>


. In the computer vision literature, this approach is referred to as the <a href="difference_of_Gaussians" title="wikilink">difference of Gaussians</a> (DoG) approach. Besides minor technicalities, however, this operator is in essence similar to the <a class="uri" href="Laplacian" title="wikilink">Laplacian</a> and can be seen as an approximation of the Laplacian operator. In a similar fashion as for the Laplacian blob detector, blobs can be detected from scale-space extrema of differences of Gaussians—see Lindeberg (2012) for the explicit relation between the difference-of-Gaussian operator and the scale-normalized Laplacian operator. This approach is for instance used in the <a href="scale-invariant_feature_transform" title="wikilink">scale-invariant feature transform</a> (SIFT) algorithm—see Lowe (2004).</p>
<h2 id="the-determinant-of-the-hessian">The determinant of the Hessian</h2>

<p>By considering the scale-normalized determinant of the Hessian, also referred to as the <a href="Monge–Ampère_equation" title="wikilink">Monge–Ampère operator</a>,</p>

<p>

<math display="block" id="Blob_detection:20">
 <semantics>
  <mrow>
   <mrow>
    <mrow>
     <mo>det</mo>
     <mrow>
      <mi>H</mi>
      <mi>L</mi>
     </mrow>
    </mrow>
    <mrow>
     <mo stretchy="false">(</mo>
     <mi>x</mi>
     <mo>,</mo>
     <mi>y</mi>
     <mo>;</mo>
     <mi>t</mi>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
   <mo>=</mo>
   <mrow>
    <msup>
     <mi>t</mi>
     <mn>2</mn>
    </msup>
    <mrow>
     <mo stretchy="false">(</mo>
     <mrow>
      <mrow>
       <msub>
        <mi>L</mi>
        <mrow>
         <mi>x</mi>
         <mi>x</mi>
        </mrow>
       </msub>
       <msub>
        <mi>L</mi>
        <mrow>
         <mi>y</mi>
         <mi>y</mi>
        </mrow>
       </msub>
      </mrow>
      <mo>-</mo>
      <msubsup>
       <mi>L</mi>
       <mrow>
        <mi>x</mi>
        <mi>y</mi>
       </mrow>
       <mn>2</mn>
      </msubsup>
     </mrow>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <times></times>
     <apply>
      <ci>det</ci>
      <apply>
       <times></times>
       <ci>H</ci>
       <ci>L</ci>
      </apply>
     </apply>
     <vector>
      <ci>x</ci>
      <ci>y</ci>
      <ci>t</ci>
     </vector>
    </apply>
    <apply>
     <times></times>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <ci>t</ci>
      <cn type="integer">2</cn>
     </apply>
     <apply>
      <minus></minus>
      <apply>
       <times></times>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <ci>L</ci>
        <apply>
         <times></times>
         <ci>x</ci>
         <ci>x</ci>
        </apply>
       </apply>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <ci>L</ci>
        <apply>
         <times></times>
         <ci>y</ci>
         <ci>y</ci>
        </apply>
       </apply>
      </apply>
      <apply>
       <csymbol cd="ambiguous">superscript</csymbol>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <ci>L</ci>
        <apply>
         <times></times>
         <ci>x</ci>
         <ci>y</ci>
        </apply>
       </apply>
       <cn type="integer">2</cn>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \operatorname{det}HL(x,y;t)=t^{2}(L_{xx}L_{yy}-L_{xy}^{2})
  </annotation>
 </semantics>
</math>

 where 

<math display="inline" id="Blob_detection:21">
 <semantics>
  <mrow>
   <mi>H</mi>
   <mi>L</mi>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <ci>H</ci>
    <ci>L</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   HL
  </annotation>
 </semantics>
</math>


 denotes the <a href="Hessian_matrix" title="wikilink">Hessian matrix</a> of 

<math display="inline" id="Blob_detection:22">
 <semantics>
  <mi>L</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>L</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   L
  </annotation>
 </semantics>
</math>

 and then detecting scale-space maxima of this operator one obtains another straightforward differential blob detector with automatic scale selection which also responds to saddles (Lindeberg 1994, 1998)</p>

<p>

<math display="block" id="Blob_detection:23">
 <semantics>
  <mrow>
   <mrow>
    <mo stretchy="false">(</mo>
    <mover accent="true">
     <mi>x</mi>
     <mo stretchy="false">^</mo>
    </mover>
    <mo>,</mo>
    <mover accent="true">
     <mi>y</mi>
     <mo stretchy="false">^</mo>
    </mover>
    <mo>;</mo>
    <mover accent="true">
     <mi>t</mi>
     <mo stretchy="false">^</mo>
    </mover>
    <mo stretchy="false">)</mo>
   </mrow>
   <mo>=</mo>
   <mrow>
    <msub>
     <mo>argmaxlocal</mo>
     <mrow>
      <mo stretchy="false">(</mo>
      <mi>x</mi>
      <mo>,</mo>
      <mi>y</mi>
      <mo>;</mo>
      <mi>t</mi>
      <mo stretchy="false">)</mo>
     </mrow>
    </msub>
    <mrow>
     <mo stretchy="false">(</mo>
     <mrow>
      <mrow>
       <mo>det</mo>
       <mrow>
        <mi>H</mi>
        <mi>L</mi>
       </mrow>
      </mrow>
      <mrow>
       <mo stretchy="false">(</mo>
       <mi>x</mi>
       <mo>,</mo>
       <mi>y</mi>
       <mo>;</mo>
       <mi>t</mi>
       <mo stretchy="false">)</mo>
      </mrow>
     </mrow>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <vector>
     <apply>
      <ci>normal-^</ci>
      <ci>x</ci>
     </apply>
     <apply>
      <ci>normal-^</ci>
      <ci>y</ci>
     </apply>
     <apply>
      <ci>normal-^</ci>
      <ci>t</ci>
     </apply>
    </vector>
    <apply>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>argmaxlocal</ci>
      <vector>
       <ci>x</ci>
       <ci>y</ci>
       <ci>t</ci>
      </vector>
     </apply>
     <apply>
      <times></times>
      <apply>
       <ci>det</ci>
       <apply>
        <times></times>
        <ci>H</ci>
        <ci>L</ci>
       </apply>
      </apply>
      <vector>
       <ci>x</ci>
       <ci>y</ci>
       <ci>t</ci>
      </vector>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   (\hat{x},\hat{y};\hat{t})=\operatorname{argmaxlocal}_{(x,y;t)}(\operatorname{%
det}HL(x,y;t))
  </annotation>
 </semantics>
</math>

. The blob points 

<math display="inline" id="Blob_detection:24">
 <semantics>
  <mrow>
   <mo stretchy="false">(</mo>
   <mover accent="true">
    <mi>x</mi>
    <mo stretchy="false">^</mo>
   </mover>
   <mo>,</mo>
   <mover accent="true">
    <mi>y</mi>
    <mo stretchy="false">^</mo>
   </mover>
   <mo stretchy="false">)</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <interval closure="open">
    <apply>
     <ci>normal-^</ci>
     <ci>x</ci>
    </apply>
    <apply>
     <ci>normal-^</ci>
     <ci>y</ci>
    </apply>
   </interval>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   (\hat{x},\hat{y})
  </annotation>
 </semantics>
</math>

 and scales 

<math display="inline" id="Blob_detection:25">
 <semantics>
  <mover accent="true">
   <mi>t</mi>
   <mo stretchy="false">^</mo>
  </mover>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <ci>normal-^</ci>
    <ci>t</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \hat{t}
  </annotation>
 </semantics>
</math>

 are also defined from an operational differential geometric definitions that leads to blob descriptors that are covariant with translations, rotations and rescalings in the image domain. In terms of scale selection, blobs defined from scale-space extrema of the determinant of the Hessian (DoH) also have slightly better scale selection properties under non-Euclidean affine transformations than the more commonly used Laplacian operator (Lindeberg 1994, 1998). In simplified form, the scale-normalized determinant of the Hessian computed from <a href="Haar_wavelet" title="wikilink">Haar wavelets</a> is used as the basic interest point operator in the <a class="uri" href="SURF" title="wikilink">SURF</a> descriptor (Bay et al. 2006) for image matching and object recognition.</p>

<p>A detailed analysis of the selection properties of the determinant of the Hessian operator and other closely scale-space interest point detectors is given in (Lindeberg 2013a).<a class="footnoteRef" href="#fn3" id="fnref3"><sup>3</sup></a> In (Lindeberg 2013b)<a class="footnoteRef" href="#fn4" id="fnref4"><sup>4</sup></a> it is shown that the determinant of the Hessian operator performs significantly better than the Laplacian operator or its difference-of-Gaussians approximation for image-based matching using local SIFT-like image descriptors.</p>
<h2 id="the-hybrid-laplacian-and-determinant-of-the-hessian-operator-hessian-laplace">The hybrid Laplacian and determinant of the Hessian operator (Hessian-Laplace)</h2>

<p>A hybrid operator between the Laplacian and the determinant of the Hessian blob detectors has also been proposed, where spatial selection is done by the determinant of the Hessian and scale selection is performed with the scale-normalized Laplacian (Mikolajczyk and Schmid 2004):</p>

<p>

<math display="block" id="Blob_detection:26">
 <semantics>
  <mrow>
   <mrow>
    <mo stretchy="false">(</mo>
    <mover accent="true">
     <mi>x</mi>
     <mo stretchy="false">^</mo>
    </mover>
    <mo>,</mo>
    <mover accent="true">
     <mi>y</mi>
     <mo stretchy="false">^</mo>
    </mover>
    <mo stretchy="false">)</mo>
   </mrow>
   <mo>=</mo>
   <mrow>
    <msub>
     <mo>argmaxlocal</mo>
     <mrow>
      <mo stretchy="false">(</mo>
      <mi>x</mi>
      <mo>,</mo>
      <mi>y</mi>
      <mo stretchy="false">)</mo>
     </mrow>
    </msub>
    <mrow>
     <mo stretchy="false">(</mo>
     <mrow>
      <mrow>
       <mo>det</mo>
       <mrow>
        <mi>H</mi>
        <mi>L</mi>
       </mrow>
      </mrow>
      <mrow>
       <mo stretchy="false">(</mo>
       <mi>x</mi>
       <mo>,</mo>
       <mi>y</mi>
       <mo>;</mo>
       <mi>t</mi>
       <mo stretchy="false">)</mo>
      </mrow>
     </mrow>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <interval closure="open">
     <apply>
      <ci>normal-^</ci>
      <ci>x</ci>
     </apply>
     <apply>
      <ci>normal-^</ci>
      <ci>y</ci>
     </apply>
    </interval>
    <apply>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>argmaxlocal</ci>
      <interval closure="open">
       <ci>x</ci>
       <ci>y</ci>
      </interval>
     </apply>
     <apply>
      <times></times>
      <apply>
       <ci>det</ci>
       <apply>
        <times></times>
        <ci>H</ci>
        <ci>L</ci>
       </apply>
      </apply>
      <vector>
       <ci>x</ci>
       <ci>y</ci>
       <ci>t</ci>
      </vector>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   (\hat{x},\hat{y})=\operatorname{argmaxlocal}_{(x,y)}(\operatorname{det}HL(x,y;%
t))
  </annotation>
 </semantics>
</math>

</p>

<p>

<math display="block" id="Blob_detection:27">
 <semantics>
  <mrow>
   <mover accent="true">
    <mi>t</mi>
    <mo stretchy="false">^</mo>
   </mover>
   <mo>=</mo>
   <mrow>
    <msub>
     <mo>argmaxminlocal</mo>
     <mi>t</mi>
    </msub>
    <mrow>
     <mo stretchy="false">(</mo>
     <mrow>
      <mrow>
       <msubsup>
        <mo>∇</mo>
        <mrow>
         <mi>n</mi>
         <mi>o</mi>
         <mi>r</mi>
         <mi>m</mi>
        </mrow>
        <mn>2</mn>
       </msubsup>
       <mi>L</mi>
      </mrow>
      <mrow>
       <mo stretchy="false">(</mo>
       <mover accent="true">
        <mi>x</mi>
        <mo stretchy="false">^</mo>
       </mover>
       <mo>,</mo>
       <mover accent="true">
        <mi>y</mi>
        <mo stretchy="false">^</mo>
       </mover>
       <mo>;</mo>
       <mi>t</mi>
       <mo stretchy="false">)</mo>
      </mrow>
     </mrow>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <ci>normal-^</ci>
     <ci>t</ci>
    </apply>
    <apply>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>argmaxminlocal</ci>
      <ci>t</ci>
     </apply>
     <apply>
      <times></times>
      <apply>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <apply>
         <csymbol cd="ambiguous">superscript</csymbol>
         <ci>normal-∇</ci>
         <cn type="integer">2</cn>
        </apply>
        <apply>
         <times></times>
         <ci>n</ci>
         <ci>o</ci>
         <ci>r</ci>
         <ci>m</ci>
        </apply>
       </apply>
       <ci>L</ci>
      </apply>
      <vector>
       <apply>
        <ci>normal-^</ci>
        <ci>x</ci>
       </apply>
       <apply>
        <ci>normal-^</ci>
        <ci>y</ci>
       </apply>
       <ci>t</ci>
      </vector>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \hat{t}=\operatorname{argmaxminlocal}_{t}(\nabla^{2}_{norm}L(\hat{x},\hat{y};t))
  </annotation>
 </semantics>
</math>

 This operator has been used for image matching, object recognition as well as texture analysis.</p>
<h2 id="affine-adapted-differential-blob-detectors">Affine-adapted differential blob detectors</h2>

<p>The blob descriptors obtained from these blob detectors with automatic scale selection are invariant to translations, rotations and uniform rescalings in the spatial domain. The images that constitute the input to a computer vision system are, however, also subject to perspective distortions. To obtain blob descriptors that are more robust to perspective transformations, a natural approach is to devise a blob detector that is <em>invariant to affine transformations</em>. In practice, affine invariant interest points can be obtained by applying <a href="affine_shape_adaptation" title="wikilink">affine shape adaptation</a> to a blob descriptor, where the shape of the smoothing kernel is iteratively warped to match the local image structure around the blob, or equivalently a local image patch is iteratively warped while the shape of the smoothing kernel remains rotationally symmetric (Lindeberg and Garding 1997; Baumberg 2000; Mikolajczyk and Schmid 2004, Lindeberg 2008/2009). In this way, we can define affine-adapted versions of the Laplacian/Difference of Gaussian operator, the determinant of the Hessian and the Hessian-Laplace operator (see also <a class="uri" href="Harris-Affine" title="wikilink">Harris-Affine</a> and <a class="uri" href="Hessian-Affine" title="wikilink">Hessian-Affine</a>).</p>
<h2 id="grey-level-blobs-grey-level-blob-trees-and-scale-space-blobs">Grey-level blobs, grey-level blob trees and scale-space blobs</h2>

<p>A natural approach to detect blobs is to associate a bright (dark) blob with each local maximum (minimum) in the intensity landscape. A main problem with such an approach, however, is that local extrema are very sensitive to noise. To address this problem, Lindeberg (1993, 1994) studied the problem of detecting local maxima with extent at multiple scales in <a href="scale_space" title="wikilink">scale space</a>. A region with spatial extent defined from a watershed analogy was associated with each local maximum, as well a local contrast defined from a so-called delimiting saddle point. A local extremum with extent defined in this way was referred to as a <em>grey-level blob</em>. Moreover, by proceeding with the watershed analogy beyond the delimiting saddle point, a <em>grey-level blob tree</em> was defined to capture the nested topological structure of level sets in the intensity landscape, in a way that is invariant to affine deformations in the image domain and monotone intensity transformations. By studying how these structures evolve with increasing scales, the notion of <em>scale-space blobs</em> was introduced. Beyond local contrast and extent, these scale-space blobs also measured how stable image structures are in scale-space, by measuring their <em>scale-space lifetime</em>.</p>

<p>It was proposed that regions of interest and scale descriptors obtained in this way, with associated scale levels defined from the scales at which normalized measures of blob strength assumed their maxima over scales could be used for guiding other early visual processing. An early prototype of simplified vision systems was developed where such regions of interest and scale descriptors were used for directing the focus-of-attention of an active vision system. While the specific technique that was used in these prototypes can be substantially improved with the current knowledge in computer vision, the overall general approach is still valid, for example in the way that local extrema over scales of the scale-normalized Laplacian operator are nowadays used for providing scale information to other visual processes.</p>
<h3 id="lindebergs-watershed-based-grey-level-blob-detection-algorithm">Lindeberg's watershed-based grey-level blob detection algorithm</h3>

<p>For the purpose of detecting <em>grey-level blobs</em> (local extrema with extent) from a watershed analogy, Lindeberg developed an algorithm based on <em>pre-sorting</em> the pixels, alternatively connected regions having the same intensity, in decreasing order of the intensity values. Then, comparisons were made between nearest neighbours of either pixels or connected regions.</p>

<p>For simplicity, let us consider the case of detecting bright grey-level blobs and let the notation "higher neighbour" stand for "neighbour pixel having a higher grey-level value". Then, at any stage in the algorithm (carried out in decreasing order of intensity values) is based on the following classification rules:</p>
<ol>
<li>If a region has no higher neighbour, then it is a local maximum and will be the seed of a blob.</li>
<li>Else, if it has at least one higher neighbour, which is background, then it cannot be part of any blob and must be background.</li>
<li>Else, if it has more than one higher neighbour and if those higher neighbours are parts of different blobs, then it cannot be a part of any blob, and must be background.</li>
<li>Else, it has one or more higher neighbours, which are all parts of the same blob. Then, it must also be a part of that blob.</li>
</ol>

<p>Compared to other watershed methods, the flooding in this algorithm stops once the intensity level falls below the intensity value of the so-called <em>delimiting saddle point</em> associated with the local maximum. However, it is rather straightforward to extend this approach to other types of watershed constructions. For example, by proceeding beyond the first delimiting saddle point a "grey-level blob tree" can be constructed. Moreover, the grey-level blob detection method was embedded in a <a href="scale_space_representation" title="wikilink">scale space representation</a> and performed at all levels of scale, resulting in a representation called the <em>scale-space primal sketch</em>.</p>

<p>This algorithm with its applications in computer vision is described in more detail in Lindeberg's thesis <a class="footnoteRef" href="#fn5" id="fnref5"><sup>5</sup></a> as well as the monograph on scale-space theory <a class="footnoteRef" href="#fn6" id="fnref6"><sup>6</sup></a> partially based on that work. Earlier presentations of this algorithm can also be found in.<a class="footnoteRef" href="#fn7" id="fnref7"><sup>7</sup></a><a class="footnoteRef" href="#fn8" id="fnref8"><sup>8</sup></a> More detailed treatments of applications of grey-level blob detection and the scale-space primal sketch to computer vision and medical image analysis are given in.<a class="footnoteRef" href="#fn9" id="fnref9"><sup>9</sup></a><a class="footnoteRef" href="#fn10" id="fnref10"><sup>10</sup></a><a class="footnoteRef" href="#fn11" id="fnref11"><sup>11</sup></a></p>
<h2 id="maximally-stable-extremum-regions-mser">Maximally stable extremum regions (MSER)</h2>

<p>Matas et al. (2002) were interested in defining image descriptors that are robust under <a href="3D_projection#Perspective_projection" title="wikilink">perspective transformations</a>. They studied level sets in the intensity landscape and measured how stable these were along the intensity dimension. Based on this idea, they defined a notion of <em>maximally stable extremum regions</em> and showed how these image descriptors can be used as image features for <a href="Computer_stereo_vision" title="wikilink">stereo matching</a>.</p>

<p>There are close relations between this notion and the above-mentioned notion of grey-level blob tree. The maximally stable extremum regions can be seen as making a specific subset of the grey-level blob tree explicit for further processing.</p>
<h2 id="see-also">See also</h2>
<ul>
<li><a href="Blob_extraction" title="wikilink">Blob extraction</a></li>
<li><a href="Corner_detection" title="wikilink">Corner detection</a></li>
<li><a href="Affine_shape_adaptation" title="wikilink">Affine shape adaptation</a></li>
<li><a href="Scale_space" title="wikilink">Scale space</a></li>
<li><a href="Ridge_detection" title="wikilink">Ridge detection</a></li>
<li><a href="Interest_point_detection" title="wikilink">Interest point detection</a></li>
<li><a href="Feature_detection_(computer_vision)" title="wikilink">Feature detection (computer vision)</a></li>
<li><a class="uri" href="Harris-Affine" title="wikilink">Harris-Affine</a></li>
<li><a class="uri" href="Hessian-Affine" title="wikilink">Hessian-Affine</a></li>
<li><a href="Principal_Curvature-Based_Region_Detector" title="wikilink">PCBR</a></li>
</ul>
<h2 id="references">References</h2>
<ul>
<li></li>
</ul>
<ul>
<li></li>
<li></li>
<li></li>
<li></li>
<li></li>
<li></li>
<li></li>
<li></li>
<li></li>
<li></li>
<li></li>
</ul>

<p>"</p>

<p><a href="Category:Feature_detection_(computer_vision)" title="wikilink">Category:Feature detection (computer vision)</a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1"><a href="http://www.dx.doi.org/10.1007/s10851-012-0378-3">Lindeberg, Tony (2013) "Scale Selection Properties of Generalized Scale-Space Interest Point Detectors", Journal of Mathematical Imaging and Vision, Volume 46, Issue 2, pages 177-210.</a><a href="#fnref1">↩</a></li>
<li id="fn2"><a href="http://www.dx.doi.org/10.1007/978-3-642-38267-3_30">Lindeberg (2013) "Image Matching Using Generalized Scale-Space Interest Points", Scale Space and Variational Methods in Computer Vision, Springer Lecture Notes in Computer Science Volume 7893, 2013, pp 355-367.</a><a href="#fnref2">↩</a></li>
<li id="fn3"></li>
<li id="fn4"></li>
<li id="fn5"><a href="http://www.csc.kth.se/~tony/abstracts/CVAP84.html">Lindeberg, T. (1991) <em>Discrete Scale-Space Theory and the Scale-Space Primal Sketch</em>, PhD thesis, Department of Numerical Analysis and Computing Science, Royal Institute of Technology, S-100 44 Stockholm, Sweden, May 1991. (ISSN 1101-2250. ISRN KTH NA/P--91/8--SE) (The grey-level blob detection algorithm is described in section 7.1)</a><a href="#fnref5">↩</a></li>
<li id="fn6"><a href="http://www.nada.kth.se/~tony/book.html">Lindeberg, Tony, <em>Scale-Space Theory in Computer Vision</em>, Kluwer Academic Publishers, 1994, ISBN 0-7923-9418-6</a><a href="#fnref6">↩</a></li>
<li id="fn7"><a href="http://ieeexplore.ieee.org/xpl/freeabs_all.jsp?arnumber=139563">T. Lindeberg and J.-O. Eklundh, "Scale detection and region extraction from a scale-space primal sketch", in <em>Proc. 3rd International Conference on Computer Vision</em>, (Osaka, Japan), pp. 416--426, Dec. 1990. (See Appendix A.1 for the basic definitions for the watershed-based grey-level blob detection algorithm.)</a><a href="#fnref7">↩</a></li>
<li id="fn8">T. Lindeberg and J.-O. Eklundh, "On the computation of a scale-space primal sketch", <em>Journal of Visual Communication and Image Representation</em>, vol. 2, pp. 55--78, Mar. 1991.<a href="#fnref8">↩</a></li>
<li id="fn9"><a href="http://www.nada.kth.se/~tony/abstracts/Lin92-IJCV.html">Lindeberg, T.: Detecting salient blob-like image structures and their scales with a scale-space primal sketch: A method for focus-of-attention, <em>International Journal of Computer Vision</em>, 11(3), 283--318, 1993.</a><a href="#fnref9">↩</a></li>
<li id="fn10"><a href="http://www.csc.kth.se/cvap/abstracts/cvap223.html">Lindeberg, T, Lidberg, Par and Roland, P. E..: "Analysis of Brain Activation Patterns Using a 3-D Scale-Space Primal Sketch", <em>Human Brain Mapping</em>, vol 7, no 3, pp 166--194, 1999.</a><a href="#fnref10">↩</a></li>
<li id="fn11"><a href="http://brainvisa.info/pdf/mangin-AImed03.pdf">Jean-Francois Mangin, Denis Rivière, Olivier Coulon, Cyril Poupon, Arnaud Cachia, Yann Cointepas, Jean-Baptiste Poline, Denis Le Bihan, Jean Régis, Dimitri Papadopoulos-Orfanos: "Coordinate-based versus structural approaches to brain image analysis". <em>Artificial Intelligence in Medicine</em> 30(2): 177-197 (2004)</a><a href="#fnref11">↩</a></li>
</ol>
</section>
</body>
</html>
