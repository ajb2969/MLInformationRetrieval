<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="1268">Ambisonics</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>Ambisonics</h1>
<hr/>

<p> <strong>Ambisonics</strong> is a <em>full-sphere</em> <a href="surround_sound" title="wikilink">surround sound</a> technique: in addition to the horizontal plane, it covers sound sources above and below the listener.<a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a></p>

<p>Unlike other multichannel surround formats, its transmission channels do not carry speaker signals. Instead, they contain a speaker-independent representation of a sound field called <em>B-format</em>, which is then <em>decoded</em> to the listener's speaker setup. This extra step allows the producer to think in terms of source directions rather than loudspeaker positions, and offers the listener a considerable degree of flexibility as to the layout and number of speakers used for playback.</p>

<p>Ambisonics was developed in the UK in the 1970s under the auspices of the British <a href="National_Research_Development_Corporation" title="wikilink">National Research Development Corporation</a>.</p>

<p>Despite its solid technical foundation and many advantages, Ambisonics has not been a commercial success, and survived only in niche applications and among recording enthusiasts.</p>

<p>With the easy availability of powerful digital signal processing (as opposed to the expensive and error-prone analog circuitry that had to be used during its early years) and the successful market introduction of home theatre surround sound systems since the 1990s, interest in Ambisonics among recording engineers, sound designers, composers, media companies, broadcasters and researchers has returned and continues to increase.</p>
<h2 id="introduction">Introduction</h2>

<p>Ambisonics can be understood as a three-dimensional extension of <a href="Microphone_practice#M.2FS_technique:_Mid.2FSide_stereophony" title="wikilink">M/S (mid/side) stereo</a>, adding additional difference channels for height and depth. The resulting signal set is called <em>B-format</em>. Its component channels are labelled 

<math display="inline" id="Ambisonics:0">
 <semantics>
  <mi>W</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>W</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   W
  </annotation>
 </semantics>
</math>

 for the sound pressure (the M in M/S), 

<math display="inline" id="Ambisonics:1">
 <semantics>
  <mi>X</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>X</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   X
  </annotation>
 </semantics>
</math>

 for the front-minus-back sound pressure gradient, 

<math display="inline" id="Ambisonics:2">
 <semantics>
  <mi>Y</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>Y</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   Y
  </annotation>
 </semantics>
</math>

 for left-minus-right (the S in M/S) and 

<math display="inline" id="Ambisonics:3">
 <semantics>
  <mi>Z</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>Z</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   Z
  </annotation>
 </semantics>
</math>


 for up-minus-down.<a class="footnoteRef" href="#fn2" id="fnref2"><sup>2</sup></a></p>

<p>The 

<math display="inline" id="Ambisonics:4">
 <semantics>
  <mi>W</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>W</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   W
  </annotation>
 </semantics>
</math>

 signal corresponds to an omnidirectional microphone, whereas 

<math display="inline" id="Ambisonics:5">
 <semantics>
  <mrow>
   <mi>X</mi>
   <mi>Y</mi>
   <mi>Z</mi>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <ci>X</ci>
    <ci>Y</ci>
    <ci>Z</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   XYZ
  </annotation>
 </semantics>
</math>

 are the components that would be picked up by figure-of-eight capsules oriented along the three spatial axes.</p>
<h3 id="panning-a-source">Panning a source</h3>

<p> A simple Ambisonic panner (or <em>encoder</em>) takes a source signal 

<math display="inline" id="Ambisonics:6">
 <semantics>
  <mi>S</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>S</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   S
  </annotation>
 </semantics>
</math>

 and two parameters, the horizontal angle 

<math display="inline" id="Ambisonics:7">
 <semantics>
  <mi>θ</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>θ</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \theta
  </annotation>
 </semantics>
</math>

 and the elevation angle 

<math display="inline" id="Ambisonics:8">
 <semantics>
  <mi>ϕ</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>ϕ</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \phi
  </annotation>
 </semantics>
</math>


. It positions the source at the desired angle by distributing the signal over the Ambisonic components with different gains:</p>

<p>

<math display="block" id="Ambisonics:9">
 <semantics>
  <mrow>
   <mi>W</mi>
   <mo>=</mo>
   <mrow>
    <mi>S</mi>
    <mo>⋅</mo>
    <mfrac>
     <mn>1</mn>
     <msqrt>
      <mn>2</mn>
     </msqrt>
    </mfrac>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <ci>W</ci>
    <apply>
     <ci>normal-⋅</ci>
     <ci>S</ci>
     <apply>
      <divide></divide>
      <cn type="integer">1</cn>
      <apply>
       <root></root>
       <cn type="integer">2</cn>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   W=S\cdot\frac{1}{\sqrt{2}}
  </annotation>
 </semantics>
</math>

</p>

<p>

<math display="block" id="Ambisonics:10">
 <semantics>
  <mrow>
   <mi>X</mi>
   <mo>=</mo>
   <mrow>
    <mrow>
     <mi>S</mi>
     <mo>⋅</mo>
     <mrow>
      <mi>cos</mi>
      <mi>θ</mi>
     </mrow>
    </mrow>
    <mrow>
     <mi>cos</mi>
     <mi>ϕ</mi>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <ci>X</ci>
    <apply>
     <times></times>
     <apply>
      <ci>normal-⋅</ci>
      <ci>S</ci>
      <apply>
       <cos></cos>
       <ci>θ</ci>
      </apply>
     </apply>
     <apply>
      <cos></cos>
      <ci>ϕ</ci>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   X=S\cdot\cos\theta\cos\phi
  </annotation>
 </semantics>
</math>

</p>

<p>

<math display="block" id="Ambisonics:11">
 <semantics>
  <mrow>
   <mi>Y</mi>
   <mo>=</mo>
   <mrow>
    <mrow>
     <mi>S</mi>
     <mo>⋅</mo>
     <mrow>
      <mi>sin</mi>
      <mi>θ</mi>
     </mrow>
    </mrow>
    <mrow>
     <mi>cos</mi>
     <mi>ϕ</mi>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <ci>Y</ci>
    <apply>
     <times></times>
     <apply>
      <ci>normal-⋅</ci>
      <ci>S</ci>
      <apply>
       <sin></sin>
       <ci>θ</ci>
      </apply>
     </apply>
     <apply>
      <cos></cos>
      <ci>ϕ</ci>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   Y=S\cdot\sin\theta\cos\phi
  </annotation>
 </semantics>
</math>

</p>

<p>

<math display="block" id="Ambisonics:12">
 <semantics>
  <mrow>
   <mi>Z</mi>
   <mo>=</mo>
   <mrow>
    <mi>S</mi>
    <mo>⋅</mo>
    <mrow>
     <mi>sin</mi>
     <mi>ϕ</mi>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <ci>Z</ci>
    <apply>
     <ci>normal-⋅</ci>
     <ci>S</ci>
     <apply>
      <sin></sin>
      <ci>ϕ</ci>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   Z=S\cdot\sin\phi
  </annotation>
 </semantics>
</math>

</p>

<p>Being omnidirectional, the 

<math display="inline" id="Ambisonics:13">
 <semantics>
  <mi>W</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>W</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   W
  </annotation>
 </semantics>
</math>


 channel always gets the same constant input signal, regardless of the angles. So that is has more-or-less the same average energy as the other channels, W is attenuated by about 3 dB (precisely, divided by the square root of two).<a class="footnoteRef" href="#fn3" id="fnref3"><sup>3</sup></a> The terms for 

<math display="inline" id="Ambisonics:14">
 <semantics>
  <mrow>
   <mi>X</mi>
   <mi>Y</mi>
   <mi>Z</mi>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <ci>X</ci>
    <ci>Y</ci>
    <ci>Z</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   XYZ
  </annotation>
 </semantics>
</math>

 actually produce the polar patterns of figure-of-eight microphones (see illustration on the right, second row). We take their value at 

<math display="inline" id="Ambisonics:15">
 <semantics>
  <mi>θ</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>θ</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \theta
  </annotation>
 </semantics>
</math>

 and 

<math display="inline" id="Ambisonics:16">
 <semantics>
  <mi>ϕ</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>ϕ</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \phi
  </annotation>
 </semantics>
</math>

, and multiply the result with the input signal. The result is that the input ends up in all components exactly as loud as the corresponding microphone would have picked it up.</p>
<h3 id="virtual-microphones">Virtual microphones</h3>

<p> The B-format components can be combined to derive <em>virtual <a href="microphone" title="wikilink">microphones</a></em> with any first-order polar pattern (omnidirectional, cardioid, hypercardioid, figure-of-eight or anything in between) pointing in any direction. Several such microphones with different parameters can be derived at the same time, to create coincident stereo pairs (such as a <a href="Blumlein_Pair" title="wikilink">Blumlein</a>) or surround arrays.</p>
<table>
<thead>
<tr class="header">
<th style="text-align: left;">
<p>

<math display="inline" id="Ambisonics:17">
 <semantics>
  <mi>p</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>p</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   p
  </annotation>
 </semantics>
</math>

</p></th>
<th style="text-align: left;">
<p>Pattern</p></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">
<p>

<math display="inline" id="Ambisonics:18">
 <semantics>
  <mn>0</mn>
  <annotation-xml encoding="MathML-Content">
   <cn type="integer">0</cn>
  </annotation-xml>
 </semantics>
</math>


</p></td>
<td style="text-align: left;">
<p>Figure-of-eight</p></td>
</tr>
<tr class="even">
<td style="text-align: left;">
<p>

<math display="inline" id="Ambisonics:19">
 <semantics>
  <mrow>
   <mo stretchy="false">[</mo>
   <mn>0</mn>
   <mo>,</mo>
   <mn>0.5</mn>
   <mo stretchy="false">]</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <interval closure="closed">
    <cn type="integer">0</cn>
    <cn type="float">0.5</cn>
   </interval>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   [0,0.5]
  </annotation>
 </semantics>
</math>

</p></td>
<td style="text-align: left;">
<p>Hyper- and Supercardioids</p></td>
</tr>
<tr class="odd">
<td style="text-align: left;">
<p>

<math display="inline" id="Ambisonics:20">
 <semantics>
  <mn>0.5</mn>
  <annotation-xml encoding="MathML-Content">
   <cn type="float">0.5</cn>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   0.5
  </annotation>
 </semantics>
</math>

</p></td>
<td style="text-align: left;">
<p>Cardioid</p></td>
</tr>
<tr class="even">
<td style="text-align: left;">
<p>

<math display="inline" id="Ambisonics:21">
 <semantics>
  <mrow>
   <mo stretchy="false">[</mo>
   <mn>0.5</mn>
   <mo>,</mo>
   <mn>1.0</mn>
   <mo stretchy="false">]</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <interval closure="closed">
    <cn type="float">0.5</cn>
    <cn type="float">1.0</cn>
   </interval>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   [0.5,1.0]
  </annotation>
 </semantics>
</math>

</p></td>
<td style="text-align: left;">
<p>Wide cardioids</p></td>
</tr>
<tr class="odd">
<td style="text-align: left;">
<p>

<math display="inline" id="Ambisonics:22">
 <semantics>
  <mn>1.0</mn>
  <annotation-xml encoding="MathML-Content">
   <cn type="float">1.0</cn>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   1.0
  </annotation>
 </semantics>
</math>

</p></td>
<td style="text-align: left;">
<p>Omnidirectional</p></td>
</tr>
</tbody>
</table>

<p>A horizontal virtual microphone at horizontal angle 

<math display="inline" id="Ambisonics:23">
 <semantics>
  <mi mathvariant="normal">Θ</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>normal-Θ</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \Theta
  </annotation>
 </semantics>
</math>


 with pattern 

<math display="inline" id="Ambisonics:24">
 <semantics>
  <mrow>
   <mn>0</mn>
   <mo>≤</mo>
   <mi>p</mi>
   <mo>≤</mo>
   <mn>1</mn>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <and></and>
    <apply>
     <leq></leq>
     <cn type="integer">0</cn>
     <ci>p</ci>
    </apply>
    <apply>
     <leq></leq>
     <share href="#.cmml">
     </share>
     <cn type="integer">1</cn>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   0\leq p\leq 1
  </annotation>
 </semantics>
</math>

 is given by</p>

<p>

<math display="block" id="Ambisonics:25">
 <semantics>
  <mrow>
   <mrow>
    <mi>M</mi>
    <mrow>
     <mo stretchy="false">(</mo>
     <mi mathvariant="normal">Θ</mi>
     <mo>,</mo>
     <mi>p</mi>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
   <mo>=</mo>
   <mrow>
    <mrow>
     <mi>p</mi>
     <msqrt>
      <mn>2</mn>
     </msqrt>
     <mi>W</mi>
    </mrow>
    <mo>+</mo>
    <mrow>
     <mrow>
      <mo stretchy="false">(</mo>
      <mrow>
       <mn>1</mn>
       <mo>-</mo>
       <mi>p</mi>
      </mrow>
      <mo stretchy="false">)</mo>
     </mrow>
     <mrow>
      <mo stretchy="false">(</mo>
      <mrow>
       <mrow>
        <mi>cos</mi>
        <mrow>
         <mi mathvariant="normal">Θ</mi>
         <mi>X</mi>
        </mrow>
       </mrow>
       <mo>+</mo>
       <mrow>
        <mi>sin</mi>
        <mrow>
         <mi mathvariant="normal">Θ</mi>
         <mi>Y</mi>
        </mrow>
       </mrow>
      </mrow>
      <mo stretchy="false">)</mo>
     </mrow>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <times></times>
     <ci>M</ci>
     <interval closure="open">
      <ci>normal-Θ</ci>
      <ci>p</ci>
     </interval>
    </apply>
    <apply>
     <plus></plus>
     <apply>
      <times></times>
      <ci>p</ci>
      <apply>
       <root></root>
       <cn type="integer">2</cn>
      </apply>
      <ci>W</ci>
     </apply>
     <apply>
      <times></times>
      <apply>
       <minus></minus>
       <cn type="integer">1</cn>
       <ci>p</ci>
      </apply>
      <apply>
       <plus></plus>
       <apply>
        <cos></cos>
        <apply>
         <times></times>
         <ci>normal-Θ</ci>
         <ci>X</ci>
        </apply>
       </apply>
       <apply>
        <sin></sin>
        <apply>
         <times></times>
         <ci>normal-Θ</ci>
         <ci>Y</ci>
        </apply>
       </apply>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   M(\Theta,p)=p\sqrt{2}W+(1-p)(\cos\Theta X+\sin\Theta Y)
  </annotation>
 </semantics>
</math>

.</p>

<p>This virtual mic is <em>free-field normalised</em>, which means it has a constant gain of one for on-axis sounds. The illustration on the left shows some exampled created with this formula.</p>

<p>Virtual microphones can be manipulated in post-production: desired sounds can be picked out, unwanted ones suppressed, and the balance between direct and reverberant sound can be fine-tuned during mixing. </p>
<h3 id="decoding">Decoding</h3>

<p> A basic Ambisonic <em>decoder</em> is very similar to a set of virtual microphones. For perfectly regular layouts (but only there!), a simplified decoder can be generated by pointing a virtual cardioid microphone in the direction of each speaker. Here is a square:</p>

<p>

<math display="block" id="Ambisonics:26">
 <semantics>
  <mrow>
   <mrow>
    <mi>L</mi>
    <mi>F</mi>
   </mrow>
   <mo>=</mo>
   <mrow>
    <mrow>
     <mo stretchy="false">(</mo>
     <mrow>
      <mrow>
       <mn>2</mn>
       <mi>W</mi>
      </mrow>
      <mo>+</mo>
      <mi>X</mi>
      <mo>+</mo>
      <mi>Y</mi>
     </mrow>
     <mo stretchy="false">)</mo>
    </mrow>
    <msqrt>
     <mn>8</mn>
    </msqrt>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <times></times>
     <ci>L</ci>
     <ci>F</ci>
    </apply>
    <apply>
     <times></times>
     <apply>
      <plus></plus>
      <apply>
       <times></times>
       <cn type="integer">2</cn>
       <ci>W</ci>
      </apply>
      <ci>X</ci>
      <ci>Y</ci>
     </apply>
     <apply>
      <root></root>
      <cn type="integer">8</cn>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   LF=(2W+X+Y)\sqrt{8}
  </annotation>
 </semantics>
</math>

</p>

<p>

<math display="block" id="Ambisonics:27">
 <semantics>
  <mrow>
   <mrow>
    <mi>L</mi>
    <mi>B</mi>
   </mrow>
   <mo>=</mo>
   <mrow>
    <mrow>
     <mo stretchy="false">(</mo>
     <mrow>
      <mrow>
       <mrow>
        <mn>2</mn>
        <mi>W</mi>
       </mrow>
       <mo>-</mo>
       <mi>X</mi>
      </mrow>
      <mo>+</mo>
      <mi>Y</mi>
     </mrow>
     <mo stretchy="false">)</mo>
    </mrow>
    <msqrt>
     <mn>8</mn>
    </msqrt>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <times></times>
     <ci>L</ci>
     <ci>B</ci>
    </apply>
    <apply>
     <times></times>
     <apply>
      <plus></plus>
      <apply>
       <minus></minus>
       <apply>
        <times></times>
        <cn type="integer">2</cn>
        <ci>W</ci>
       </apply>
       <ci>X</ci>
      </apply>
      <ci>Y</ci>
     </apply>
     <apply>
      <root></root>
      <cn type="integer">8</cn>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   LB=(2W-X+Y)\sqrt{8}
  </annotation>
 </semantics>
</math>

</p>

<p>

<math display="block" id="Ambisonics:28">
 <semantics>
  <mrow>
   <mrow>
    <mi>R</mi>
    <mi>B</mi>
   </mrow>
   <mo>=</mo>
   <mrow>
    <mrow>
     <mo stretchy="false">(</mo>
     <mrow>
      <mrow>
       <mn>2</mn>
       <mi>W</mi>
      </mrow>
      <mo>-</mo>
      <mi>X</mi>
      <mo>-</mo>
      <mi>Y</mi>
     </mrow>
     <mo stretchy="false">)</mo>
    </mrow>
    <msqrt>
     <mn>8</mn>
    </msqrt>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <times></times>
     <ci>R</ci>
     <ci>B</ci>
    </apply>
    <apply>
     <times></times>
     <apply>
      <minus></minus>
      <apply>
       <times></times>
       <cn type="integer">2</cn>
       <ci>W</ci>
      </apply>
      <ci>X</ci>
      <ci>Y</ci>
     </apply>
     <apply>
      <root></root>
      <cn type="integer">8</cn>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   RB=(2W-X-Y)\sqrt{8}
  </annotation>
 </semantics>
</math>

</p>

<p>

<math display="block" id="Ambisonics:29">
 <semantics>
  <mrow>
   <mrow>
    <mi>R</mi>
    <mi>F</mi>
   </mrow>
   <mo>=</mo>
   <mrow>
    <mrow>
     <mo stretchy="false">(</mo>
     <mrow>
      <mrow>
       <mrow>
        <mn>2</mn>
        <mi>W</mi>
       </mrow>
       <mo>+</mo>
       <mi>X</mi>
      </mrow>
      <mo>-</mo>
      <mi>Y</mi>
     </mrow>
     <mo stretchy="false">)</mo>
    </mrow>
    <msqrt>
     <mn>8</mn>
    </msqrt>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <times></times>
     <ci>R</ci>
     <ci>F</ci>
    </apply>
    <apply>
     <times></times>
     <apply>
      <minus></minus>
      <apply>
       <plus></plus>
       <apply>
        <times></times>
        <cn type="integer">2</cn>
        <ci>W</ci>
       </apply>
       <ci>X</ci>
      </apply>
      <ci>Y</ci>
     </apply>
     <apply>
      <root></root>
      <cn type="integer">8</cn>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   RF=(2W+X-Y)\sqrt{8}
  </annotation>
 </semantics>
</math>

 The signs of the 

<math display="inline" id="Ambisonics:30">
 <semantics>
  <mi>X</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>X</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   X
  </annotation>
 </semantics>
</math>

 and 

<math display="inline" id="Ambisonics:31">
 <semantics>
  <mi>Y</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>Y</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   Y
  </annotation>
 </semantics>
</math>

 components are the important part, the rest are gain factors. The 

<math display="inline" id="Ambisonics:32">
 <semantics>
  <mi>Z</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>Z</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   Z
  </annotation>
 </semantics>
</math>

 component is discarded, because it is not possible to reproduce height cues with just four loudspeakers in one plane.</p>

<p>Please do not implement this example – in practice, a real Ambisonic decoder requires a number of psycho-acoustic optimisations to work properly.<a class="footnoteRef" href="#fn4" id="fnref4"><sup>4</sup></a></p>
<h3 id="higher-order-ambisonics">Higher-order Ambisonics</h3>

<p>The spatial resolution of first-order Ambisonics as described above is quite low. In practice, that translates to slightly blurry sources, but also to a comparably small usable listening area or <em>sweet spot</em>. The resolution can be increased and the sweet spot enlarged by adding groups of more selective directional components to the B-format. These no longer correspond to conventional microphone polar patterns, but rather look like clover leaves. The resulting signal set is then called <em>Second-</em>, <em>Third-</em>, or collectively, <em>Higher-order Ambisonics</em>.</p>

<p>For a given order 

<math display="inline" id="Ambisonics:33">
 <semantics>
  <mi mathvariant="normal">ℓ</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>normal-ℓ</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \ell
  </annotation>
 </semantics>
</math>


, full-sphere systems require 

<math display="inline" id="Ambisonics:34">
 <semantics>
  <msup>
   <mrow>
    <mo stretchy="false">(</mo>
    <mrow>
     <mi mathvariant="normal">ℓ</mi>
     <mo>+</mo>
     <mn>1</mn>
    </mrow>
    <mo stretchy="false">)</mo>
   </mrow>
   <mn>2</mn>
  </msup>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">superscript</csymbol>
    <apply>
     <plus></plus>
     <ci>normal-ℓ</ci>
     <cn type="integer">1</cn>
    </apply>
    <cn type="integer">2</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   (\ell+1)^{2}
  </annotation>
 </semantics>
</math>

 signal components, and 

<math display="inline" id="Ambisonics:35">
 <semantics>
  <mrow>
   <mrow>
    <mn>2</mn>
    <mi mathvariant="normal">ℓ</mi>
   </mrow>
   <mo>+</mo>
   <mn>1</mn>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <plus></plus>
    <apply>
     <times></times>
     <cn type="integer">2</cn>
     <ci>normal-ℓ</ci>
    </apply>
    <cn type="integer">1</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   2\ell+1
  </annotation>
 </semantics>
</math>

 components are needed for horizontal-only reproduction.</p>

<p>There are several different format conventions for higher-order Ambisonics, for details see <a href="Ambisonic_data_exchange_formats" title="wikilink">Ambisonic data exchange formats</a>.</p>
<h3 id="comparison-to-other-surround-formats">Comparison to other surround formats</h3>

<p>Ambisonics differs from other surround formats in a number of aspects:</p>
<ul>
<li>It is <a href="Isotropy" title="wikilink"><em>isotropic</em></a>: sounds from any direction are treated equally, as opposed to assuming that the main sources of sound are frontal and that rear channels are only for ambience or special effects.</li>
<li>All speakers contribute to any one sound in any direction, as opposed to conventional pan-potted (pair-wise mixing) techniques which use only two adjacent speakers. This gives better localisation, particularly to the sides and rear.<a class="footnoteRef" href="#fn5" id="fnref5"><sup>5</sup></a><a class="footnoteRef" href="#fn6" id="fnref6"><sup>6</sup></a></li>
<li>The stability and imaging of the reproduced soundfield vary less with listener position than with most other surround systems. The soundfield can even be appreciated by listeners <em>outside</em> the speaker array, although with reduced localisation performance.<a class="footnoteRef" href="#fn7" id="fnref7"><sup>7</sup></a></li>
<li>It requires only three channels for basic horizontal surround, and four channels for a full-sphere soundfield. Basic full-sphere replay requires a minimum of six loudspeakers (a minimum of four for horizontal).</li>
<li>The Ambisonic signal is decoupled from the playback system: loudspeaker placement is flexible (within reasonable limits), and the same program material can be decoded for varying numbers of loudspeakers. Moreover, a with-height mix can be played back on horizontal-only, stereo or even mono systems without losing content entirely (it will be folded to the horizontal plane and to the frontal quadrant, respectively). This allows producers to embrace with-height production without worrying about loss of information.</li>
<li>Ambisonics can be scaled to any desired spatial resolution at the cost of additional transmission channels and more speakers for playback. Higher-order material remains downwards compatible and can be played back at lower spatial resolution without requiring a special downmix.</li>
<li>The core technology of Ambisonics is free of patents, and a complete tool chain for production and listening is available as <a href="free_software" title="wikilink">free software</a> for all major <a href="operating_system" title="wikilink">operating systems</a>.</li>
</ul>

<p>On the downside, Ambisonics is</p>
<ul>
<li>not supported by any major record label or media company;</li>
<li>not widely known, since it has never been marketed well;</li>
<li>conceptually difficult for people to grasp, as opposed to the conventional <em>"one channel,one speaker"</em> paradigm;</li>
<li>more complicated for the consumer to set up, because of the decoding stage;</li>
<li>prone to phasing artifacts when the listener moves or turns, since any one virtual source will be reproduced by several speakers with strong <em>correlation</em> (a situation which is usually avoided in N.1 production).</li>
</ul>
<h2 id="theoretical-foundation">Theoretical foundation</h2>
<h3 id="soundfield-analysis-encoding">Soundfield analysis (encoding)</h3>

<p>The B-format signals comprise a truncated <a href="spherical_harmonic" title="wikilink">spherical harmonic</a> decomposition of the sound field. They correspond to the <a href="Sound#Sound_pressure" title="wikilink">sound pressure</a> 

<math display="inline" id="Ambisonics:36">
 <semantics>
  <mi>W</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>W</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   W
  </annotation>
 </semantics>
</math>

, and the three components of the pressure gradient 

<math display="inline" id="Ambisonics:37">
 <semantics>
  <mrow>
   <mi>X</mi>
   <mi>Y</mi>
   <mi>Z</mi>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <ci>X</ci>
    <ci>Y</ci>
    <ci>Z</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   XYZ
  </annotation>
 </semantics>
</math>

 (not to be confused with the related <a href="particle_velocity" title="wikilink">particle velocity</a>) at a point in space. Together, these approximate the sound field on a sphere around the microphone; formally the first-order truncation of the <a href="multipole_expansion" title="wikilink">multipole expansion</a>. 

<math display="inline" id="Ambisonics:38">
 <semantics>
  <mi>W</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>W</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   W
  </annotation>
 </semantics>
</math>


 (the mono signal) is the zero-order information, corresponding to a constant function on the sphere, while 

<math display="inline" id="Ambisonics:39">
 <semantics>
  <mrow>
   <mi>X</mi>
   <mi>Y</mi>
   <mi>Z</mi>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <ci>X</ci>
    <ci>Y</ci>
    <ci>Z</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   XYZ
  </annotation>
 </semantics>
</math>

 are the first-order terms (the dipoles or figures-of-eight). This first-order truncation is only an approximation of the overall sound field.</p>

<p>The <em>higher orders</em> correspond to further terms of the multipole expansion of a function on the sphere in terms of spherical harmonics. In practice, higher orders require more speakers for playback, but increase the spatial resolution and enlarge the area where the sound field is reproduced perfectly (up to an upper boundary frequency).</p>

<p>The radius 

<math display="inline" id="Ambisonics:40">
 <semantics>
  <mi>r</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>r</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   r
  </annotation>
 </semantics>
</math>

 of this area for Ambisonic order 

<math display="inline" id="Ambisonics:41">
 <semantics>
  <mi mathvariant="normal">ℓ</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>normal-ℓ</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \ell
  </annotation>
 </semantics>
</math>

 and frequency 

<math display="inline" id="Ambisonics:42">
 <semantics>
  <mi>f</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>f</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   f
  </annotation>
 </semantics>
</math>

 is given by</p>

<p>

<math display="block" id="Ambisonics:43">
 <semantics>
  <mrow>
   <mi>r</mi>
   <mo>≈</mo>
   <mfrac>
    <mrow>
     <mi mathvariant="normal">ℓ</mi>
     <mi>c</mi>
    </mrow>
    <mrow>
     <mn>2</mn>
     <mi>π</mi>
     <mi>f</mi>
    </mrow>
   </mfrac>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <approx></approx>
    <ci>r</ci>
    <apply>
     <divide></divide>
     <apply>
      <times></times>
      <ci>normal-ℓ</ci>
      <ci>c</ci>
     </apply>
     <apply>
      <times></times>
      <cn type="integer">2</cn>
      <ci>π</ci>
      <ci>f</ci>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   r\approx\frac{\ell c}{2\pi f}
  </annotation>
 </semantics>
</math>

,<a class="footnoteRef" href="#fn8" id="fnref8"><sup>8</sup></a> where 

<math display="inline" id="Ambisonics:44">
 <semantics>
  <mi>c</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>c</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   c
  </annotation>
 </semantics>
</math>

 denotes the speed of sound.</p>

<p>This area becomes smaller than a human head above 600 Hz for first order or 1800 Hz for third-order. Accurate reproduction in a head-sized volume up to 20 kHz would require an order of 32 or more than 1000 loudspeakers.</p>

<p>At those frequencies and listening positions where perfect soundfield reconstruction is no longer possible, Ambisonic reproduction has to focus on delivering correct directional cues to allow for good localisation even in the presence reconstruction errors.</p>
<h3 id="psychoacoustics">Psychoacoustics</h3>

<p>The human hearing apparatus has very keen localisation on the horizontal plane (as fine as 2° source separation in some experiments). Two predominant cues, for different frequency ranges, can be identified:</p>
<h4 id="low-frequency-localisation">Low frequency localisation</h4>

<p>At low frequencies, where the wavelength is large compared to the human head, an incoming sound <a href="Diffraction" title="wikilink">diffracts</a> around it, so that there is virtually no acoustic shadow and hence no level difference between the ears. In this range, the only available information is the phase relationship between the two ear signals, called <em>interaural time difference</em>, or <em>ITD</em>. Evaluating this time difference allows for precise localisation within a <em>cone of confusion</em>: the angle of incidence is unambiguous, but the ITD is the same for sounds from the front or from the back. As long as the sound is not totally unknown to the subject, the confusion can usually be resolved by perceiving the timbral front-back variations caused by the ear flaps (or <em>pinnae</em>).</p>
<h4 id="high-frequency-localisation">High-frequency localisation</h4>

<p>As the wavelength approaches twice the size of the head, phase relationships become ambiguous, since it is no longer clear whether the phase difference between the ears corresponds to one, two, or even more periods as the frequency goes up. Fortunately, the head will create a significant acoustic shadow in this range, which causes a slight difference in level between the ears. This is called the <em>interaural level difference</em>, or <em>ILD</em> (the same cone of confusion applies). Combined, these two mechanisms provide localisation over the entire hearing range.</p>
<h4 id="itd-and-ild-reproduction-in-ambisonics">ITD and ILD reproduction in Ambisonics</h4>

<p>Gerzon has shown that the quality of localisation cues in the reproduced sound field corresponds to two objective metrics: the length of the particle velocity vector 

<math display="inline" id="Ambisonics:45">
 <semantics>
  <mover accent="true">
   <msub>
    <mi>r</mi>
    <mi>V</mi>
   </msub>
   <mo stretchy="false">→</mo>
  </mover>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <ci>normal-→</ci>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>r</ci>
     <ci>V</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \vec{r_{V}}
  </annotation>
 </semantics>
</math>

 for the ITD, and the length of the energy vector 

<math display="inline" id="Ambisonics:46">
 <semantics>
  <mover accent="true">
   <msub>
    <mi>r</mi>
    <mi>E</mi>
   </msub>
   <mo stretchy="false">→</mo>
  </mover>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <ci>normal-→</ci>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>r</ci>
     <ci>E</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \vec{r_{E}}
  </annotation>
 </semantics>
</math>

 for the ILD. Gerzon and Barton (1992) define a decoder for horizontal surround to be <em>Ambisonic</em> if</p>
<ul>
<li>the directions of 

<math display="inline" id="Ambisonics:47">
 <semantics>
  <mover accent="true">
   <msub>
    <mi>r</mi>
    <mi>V</mi>
   </msub>
   <mo stretchy="false">→</mo>
  </mover>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <ci>normal-→</ci>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>r</ci>
     <ci>V</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \vec{r_{V}}
  </annotation>
 </semantics>
</math>

 and 

<math display="inline" id="Ambisonics:48">
 <semantics>
  <mover accent="true">
   <msub>
    <mi>r</mi>
    <mi>E</mi>
   </msub>
   <mo stretchy="false">→</mo>
  </mover>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <ci>normal-→</ci>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>r</ci>
     <ci>E</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \vec{r_{E}}
  </annotation>
 </semantics>
</math>


 agree up to at least 4 kHz,</li>
<li>at frequencies below about 400 Hz, 

<math display="inline" id="Ambisonics:49">
 <semantics>
  <mrow>
   <mrow>
    <mo>∥</mo>
    <mover accent="true">
     <msub>
      <mi>r</mi>
      <mi>V</mi>
     </msub>
     <mo stretchy="false">→</mo>
    </mover>
    <mo>∥</mo>
   </mrow>
   <mo>=</mo>
   <mn>1</mn>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <csymbol cd="latexml">norm</csymbol>
     <apply>
      <ci>normal-→</ci>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>r</ci>
       <ci>V</ci>
      </apply>
     </apply>
    </apply>
    <cn type="integer">1</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \|\vec{r_{V}}\|=1
  </annotation>
 </semantics>
</math>

 for all azimuth angles, and</li>
<li>at frequencies from about 700 Hz to 4 kHz, the magnitude of 

<math display="inline" id="Ambisonics:50">
 <semantics>
  <mover accent="true">
   <msub>
    <mi>r</mi>
    <mi>E</mi>
   </msub>
   <mo stretchy="false">→</mo>
  </mover>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <ci>normal-→</ci>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>r</ci>
     <ci>E</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \vec{r_{E}}
  </annotation>
 </semantics>
</math>

 is <em>"substantially maximised across as large a part of the 360° sound stage as possible"</em>.<a class="footnoteRef" href="#fn9" id="fnref9"><sup>9</sup></a></li>
</ul>

<p>In practice, satisfactory results are achieved at moderate orders even for very large listening areas.<a class="footnoteRef" href="#fn10" id="fnref10"><sup>10</sup></a><a class="footnoteRef" href="#fn11" id="fnref11"><sup>11</sup></a></p>
<h3 id="soundfield-synthesis-decoding">Soundfield synthesis (decoding)</h3>

<p>In principle, the <a class="uri" href="loudspeaker" title="wikilink">loudspeaker</a> signals are derived by using a <a href="linear_combination" title="wikilink">linear combination</a> of the Ambisonic component signals, where each signal is dependent on the actual position of the speaker in relation to the center of an imaginary sphere the surface of which passes through all available speakers. In practice, slightly irregular distances of the speakers may be compensated with <a href="Delay_(audio_effect)#Straight_delay" title="wikilink">delay</a>.</p>

<p>True Ambisonic decoding however requires spatial equalization of the signals to account for the differences in the high- and low-frequency <a href="sound_localization" title="wikilink">sound localization</a> mechanisms in human hearing.<a class="footnoteRef" href="#fn12" id="fnref12"><sup>12</sup></a> A further refinement accounts for the distance of the listener from the loudspeakers (<em>near-field compensation</em>).<a class="footnoteRef" href="#fn13" id="fnref13"><sup>13</sup></a> </p>
<h2 id="compatibility-with-existing-distribution-channels">Compatibility with existing distribution channels</h2>

<p>Ambisonic decoders are not currently being marketed to end users in any significant way, and no native Ambisonic recordings are commercially available. Hence, content that has been produced in Ambisonics must be made available to consumers in stereo or discrete multichannel formats.</p>
<h3 id="stereo">Stereo</h3>

<p>Ambisonic content can be folded down to stereo automatically, without requiring a dedicated downmix. The most straightforward approach is to sample the B-format with a <em>virtual stereo microphone</em>. The result is equivalent to a coincident stereo recording. Imaging will depend on the microphone geometry, but usually rear sources will be reproduced more softly and diffuse. Vertical information (from the 

<math display="inline" id="Ambisonics:51">
 <semantics>
  <mi>Z</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>Z</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   Z
  </annotation>
 </semantics>
</math>

 channel) is omitted.</p>

<p>Alternatively, the B-format can be matrix-encoded into <em>UHJ format</em>, which is suitable for direct playback on stereo systems. As before, the vertical information will be discarded, but in addition to left-right reproduction, UHJ tries to retain some of the horizontal surround information by translating sources in the back into out-of-phase signals. This gives the listener some sense of rear localisation.</p>

<p>Two-channel UHJ can also be decoded back into horizontal Ambisonics (with some loss of accuracy), if an Ambisonic playback system is available. Lossless UHJ up to four channels (including height information) exists but has never seen wide use. In all UHJ schemes, the first two channels are conventional left and right speaker feeds.</p>
<h3 id="multichannel-formats">Multichannel formats</h3>

<p>Likewise, it is possible to pre-decode Ambisonic material to arbitrary speaker layouts, such as <a href="Quadraphonics" title="wikilink">Quad</a>, <a href="5.1_surround_sound" title="wikilink">5.1</a>, <a href="7.1_surround_sound" title="wikilink">7.1</a>, <a href="Auro_11.1" title="wikilink">Auro 11.1</a>, or even <a href="22.2_surround_sound" title="wikilink">22.2</a>, again without manual intervention. The LFE channel is either omitted, or a special mix is created manually. Pre-decoding to 5.1 media has been known as <em>G-Format</em><a class="footnoteRef" href="#fn14" id="fnref14"><sup>14</sup></a> during the early days of DVD audio, although the term is not in common use anymore.</p>

<p>The obvious advantage of pre-decoding is that any surround listener can be able to experience Ambisonics; no special hardware is required beyond that found in a common home theatre system. The main disadvantage is that the flexibility of rendering a single, standard Ambisonic signal to any target speaker array is lost: the signal is assumes a specific "standard" layout and anyone listening with a different array may experience a degradation of localisation accuracy.</p>

<p>Target layouts from 5.1 upwards usually surpass the spatial resolution of first-order Ambisonics, at least in the frontal quadrant. For optimal resolution, to avoid excessive crosstalk, and to steer around irregularities of the target layout, pre-decodings for such targets should be derived from source material in Higher-order Ambisonics.<a class="footnoteRef" href="#fn15" id="fnref15"><sup>15</sup></a></p>
<h2 id="production-workflow">Production workflow</h2>

<p>Ambisonic content can be created in two basic ways: by recording a sound with a suitable first- or higher-order microphone, or by taking separate monophonic sources and panning them to the desired positions. Content can also be manipulated while it is in B-format.</p>
<h3 id="ambisonic-microphones">Ambisonic microphones</h3>
<h4 id="native-b-format-arrays">Native B-format arrays</h4>

<p> Since the components of first-order Ambisonics correspond to physical microphone pickup patterns, it is entirely practical to record B-format directly, with a collection of coincident microphones: an omnidirectional capsule, one forward-facing and one left-facing figure-of-eight, yielding the 

<math display="inline" id="Ambisonics:52">
 <semantics>
  <mi>W</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>W</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   W
  </annotation>
 </semantics>
</math>

, 

<math display="inline" id="Ambisonics:53">
 <semantics>
  <mi>X</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>X</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   X
  </annotation>
 </semantics>
</math>


 and 

<math display="inline" id="Ambisonics:54">
 <semantics>
  <mi>Y</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>Y</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   Y
  </annotation>
 </semantics>
</math>

 components.<a class="footnoteRef" href="#fn16" id="fnref16"><sup>16</sup></a><a class="footnoteRef" href="#fn17" id="fnref17"><sup>17</sup></a> This is referred to as a <em>native</em> or <em>Nimbus/Halliday</em> microphone array, after its designer Dr Jonathan Halliday at <a href="Nimbus_Records" title="wikilink">Nimbus Records</a>, where it is used to record their extensive and continuing series of Ambisonic releases.</p>

<p>The primary difficulty inherent in this approach is that high-frequency localisation and clarity relies on the diaphragms approaching true coincidence. By stacking the capsules vertically, perfect coincidence for horizontal sources is obtained. However, sound from above or below will suffer from subtle comb filtering effects in the highest frequencies.</p>

<p>Native arrays are most commonly used for horizontal-only surround, because of increasing positional errors and shading effects when adding a fourth microphone.</p>
<h4 id="the-tetrahedral-microphone">The tetrahedral microphone</h4>

<p>Since it is impossible to build a perfectly coincident microphone array, the next-best approach is to minimize and distribute the positional error as uniformly as possible. This can be achieved by arranging four cardioid or sub-cardioid capsules in a tetrahedron and equalising for uniform diffuse-field response.<a class="footnoteRef" href="#fn18" id="fnref18"><sup>18</sup></a> The capsule signals are then converted to B-format with a matrix operation.  Outside Ambisonics, tetrahedral microphones have become popular with location recording engineers working in stereo or 5.1 for their flexibility in post-production; here, the B-format is only used as an intermediate to derive <a href="#Virtual_microphones" title="wikilink">virtual microphones</a>.</p>
<h4 id="higher-order-microphones">Higher order microphones</h4>

<p>Above first-order, it is no longer possible to obtain Ambisonic components directly with single microphone capsules. Instead, higher-order difference signals are derived from several spatially distributed (usually omnidirectional) capsules using very sophisticated digital signal processing.<a class="footnoteRef" href="#fn19" id="fnref19"><sup>19</sup></a></p>

<p>Due to the aggressive equalisation necessary, the timbral and noise performance of higher-order arrays is not currently comparable to traditional high-quality recording microphones, and the resulting B-format is increasingly band-limited towards higher orders, raising issues of up- and downwards compatibility.</p>

<p>A recent paper by Peter Craven et al.<a class="footnoteRef" href="#fn20" id="fnref20"><sup>20</sup></a> (subsequently patented) describes the use of bi-directional capsules for higher order microphones to reduce the extremity of the equalisation involved. No microphones have yet been made using this idea.</p>
<h3 id="ambisonic-panning">Ambisonic panning</h3>

<p>The most straightforward way to produce Ambisonic mixes of arbitrarily high order is to take monophonic sources and position them with an Ambisonic encoder.</p>

<p>A full-sphere encoder usually has two parameters, azimuth (or horizon) and elevation angle. The encoder will distribute the source signal to the Ambisonic components such that, when decoded, the source will appear at the desired location. More sophisticated panners will additionally provide a radius parameter that will take care of distance-dependent attenuation and bass boost due to near-field effect.</p>

<p>Hardware panning units and mixers for first-order Ambisonics have been available since the 1980s<a class="footnoteRef" href="#fn21" id="fnref21"><sup>21</sup></a><a class="footnoteRef" href="#fn22" id="fnref22"><sup>22</sup></a><a class="footnoteRef" href="#fn23" id="fnref23"><sup>23</sup></a> and have been used commercially. Today, panning plugins and other related software tools are available for all major digital audio workstations, often as <a href="free_software" title="wikilink">free software</a>. However, due to arbitrary bus width restrictions, few professional DAWs support orders higher than second. Notable exceptions are <a class="uri" href="REAPER" title="wikilink">REAPER</a> and <a href="Ardour_(software)" title="wikilink">Ardour</a>.</p>
<h3 id="ambisonic-manipulation">Ambisonic manipulation</h3>

<p>First order B-format can be manipulated in various ways to change the contents of an auditory scene. Well known manipulations include "rotation" and "dominance" (moving sources towards or away from a particular direction).<a class="footnoteRef" href="#fn24" id="fnref24"><sup>24</sup></a><a class="footnoteRef" href="#fn25" id="fnref25"><sup>25</sup></a></p>

<p>Additionally, linear time-invariant <a href="signal_processing" title="wikilink">signal processing</a> such as <a href="Equalization_(audio)" title="wikilink">equalization</a> can be applied to B-format without disrupting sound directions, as long as it applied to all component channels equally.</p>

<p>More recent developments in Higher Order Ambisonics enable a wide range of manipulations including rotation, reflection, movement, 3D <a class="uri" href="reverb" title="wikilink">reverb</a>, upmixing from legacy formats such as 5.1 or first order, visualization and directionally-dependent masking and equalization.</p>
<h3 id="data-exchange">Data exchange</h3>

<p>Transmitting Ambisonic B-format between devices and to end-users requires a standardized exchange format. While <em>traditional first-order B-format</em> is well-defined and universally understood, there are numerous conflicting conventions for Higher-order Ambisonics, differing both in channel order and weighting, which might need to be supported for some time. The most widespread is <em>Furse-Malham higher order format</em> in the <code>.amb</code> container based on Microsoft's WAVE-EX file format.<a class="footnoteRef" href="#fn26" id="fnref26"><sup>26</sup></a> It scales up to third order and has a file size limitation of 4GB.</p>

<p>Future implementations and productions might want to consider the AmbiX<a class="footnoteRef" href="#fn27" id="fnref27"><sup>27</sup></a> proposal, which adopts the <code>.caf</code> file format and does away with the 4GB limit. It scales to arbitrarily high orders. </p>
<h2 id="history-of-ambisonics">History of Ambisonics</h2>

<p>Ambisonics was invented by <a href="Michael_Gerzon" title="wikilink">Michael Gerzon</a> of the <a href="Mathematical_Institute" title="wikilink">Mathematical Institute, Oxford</a>, who – with Professor <a href="Peter_Fellgett" title="wikilink">Peter Fellgett</a><a class="footnoteRef" href="#fn28" id="fnref28"><sup>28</sup></a> of the <a href="University_of_Reading" title="wikilink">University of Reading</a>, David Brown, John Wright and John Hayes of the now defunct IMF Electronics,<a class="footnoteRef" href="#fn29" id="fnref29"><sup>29</sup></a> and building on the work of other researchers – developed the theoretical and practical aspects of the system in the early 1970s.</p>
<h2 id="current-development">Current development</h2>
<h3 id="research">Research</h3>

<p>Recent conferences dedicated to or including Ambisonics or spherical harmonic analysis illustrate the current research interest:</p>
<ul>
<li><a href="http://ambisonics.iem.at/symposium2009">Ambisonics Symposium 2009</a> at IEM, Graz, Austria, 2009.</li>
<li><a href="http://ambisonics10.ircam.fr/drupal/index.html">2nd International Symposium on Ambisonics and Spherical Acoustics</a> at IRCAM, Paris, France, 2010</li>
<li><a href="http://ambisonics.iem.at/proceedings-of-the-ambisonics-symposium-2011">Ambisonics Symposium 2011</a> at Vis Center, Lexington(KY), USA, 2011</li>
<li>[<a class="uri" href="http://www.tonmeister.de/index.php?p=veranstaltungen/archiv/icsa2011/programm&amp;sl">http://www.tonmeister.de/index.php?p=veranstaltungen/archiv/icsa2011/programm&amp;sl;</a>;=en International Conference on Spatial Audio] at Hochschule für Musik Detmold, Germany, 2011</li>
<li><a href="http://www.aes-uk.org/uk-conference/25th-conf-spatial-audio-in-todays-3d-world/">25th AES UK Conference/4th International Symposium on Amisonics and Spherical Acoustics</a>, University of York, UK</li>
<li><a href="http://www.aes.org/conferences/52/">52nd AES Conference on Sound Field Control - Engineering and Perception</a>, University of Surrey, Guildford, UK, 2013.</li>
<li><a href="https://www.auralization.tu-berlin.de/">EAA Joint Symposium on Auralization and Ambisonics</a>, TU Berlin, Germany, 2014</li>
<li><a href="http://www.tonmeister.de/index.php?p=veranstaltungen/icsa2014">International Conference on Spatial Audio</a> at Fraunhofer IIS, Erlangen, Germany, 2014</li>
</ul>

<p>An increasing number of institutions world-wide are maintaining <a href="List_of_permanent_Ambisonic_playback_systems" title="wikilink">permanent Ambisonic playback systems</a> for research, production, and concert use.</p>
<h3 id="corporate-interest">Corporate interest</h3>

<p>A number of companies are currently conducting research in Ambisonics:</p>
<ul>
<li><a class="uri" href="BBC" title="wikilink">BBC</a><a class="footnoteRef" href="#fn30" id="fnref30"><sup>30</sup></a><a class="footnoteRef" href="#fn31" id="fnref31"><sup>31</sup></a><a class="footnoteRef" href="#fn32" id="fnref32"><sup>32</sup></a></li>
<li><a class="uri" href="Technicolor" title="wikilink">Technicolor</a> Research and Innovation/Thomson Licensing<a class="footnoteRef" href="#fn33" id="fnref33"><sup>33</sup></a><a class="footnoteRef" href="#fn34" id="fnref34"><sup>34</sup></a></li>
</ul>

<p><a href="Dolby_Laboratories" title="wikilink">Dolby Laboratories</a> have expressed "interest" in Ambisonics by acquiring (and liquidating) Barcelona-based Ambisonics specialist <a href="imm_sound" title="wikilink">imm sound</a> prior to launching <a href="Dolby_Atmos" title="wikilink">Dolby Atmos</a>,<a class="footnoteRef" href="#fn35" id="fnref35"><sup>35</sup></a> which, although its precise workings are undisclosed, does implement decoupling between source direction and actual loudspeaker positions. Atmos takes a fundamentally different approach in that it does not attempt to transmit a sound field; it transmits discrete premixes or stems (i.e., raw streams of sound data) along with metadata about what location and direction they should appear to be coming from. The stems are then decoded, mixed, and rendered in real time using whatever loudspeakers are available at the playback location.</p>
<h3 id="use-in-gaming">Use in gaming</h3>

<p>Higher-order Ambisonics has found a niche market in video games developed by <a class="uri" href="Codemasters" title="wikilink">Codemasters</a>. Their first game to use an Ambisonic audio engine was <a href="Colin_McRae:_DiRT" title="wikilink">Colin McRae: DiRT</a>, however, this only used Ambisonics on the <a href="PlayStation_3" title="wikilink">PlayStation 3</a> platform.<a class="footnoteRef" href="#fn36" id="fnref36"><sup>36</sup></a> Their game <a href="Race_Driver:_GRID" title="wikilink">Race Driver: GRID</a> extended the use of Ambisonics to the <a href="Xbox_360" title="wikilink">Xbox 360</a> platform,<a class="footnoteRef" href="#fn37" id="fnref37"><sup>37</sup></a> and <a href="Colin_McRae:_DiRT_2" title="wikilink">Colin McRae: DiRT 2</a> uses Ambisonics on all platforms including the PC.<a class="footnoteRef" href="#fn38" id="fnref38"><sup>38</sup></a></p>

<p>The recent games from Codemasters, <a href="F1_2010_(video_game)" title="wikilink">F1 2010</a>, <a href="Dirt_3" title="wikilink">Dirt 3</a>,<a class="footnoteRef" href="#fn39" id="fnref39"><sup>39</sup></a> <a href="F1_2011_(video_game)" title="wikilink">F1 2011</a><a class="footnoteRef" href="#fn40" id="fnref40"><sup>40</sup></a> and <a href="Dirt:_Showdown" title="wikilink">Dirt: Showdown</a>,<a class="footnoteRef" href="#fn41" id="fnref41"><sup>41</sup></a> use fourth-order Ambisonics on faster PCs,<a class="footnoteRef" href="#fn42" id="fnref42"><sup>42</sup></a> rendered by <a href="Blue_Ripple_Sound" title="wikilink">Blue Ripple Sound</a>'s <a class="uri" href="Rapture3D" title="wikilink">Rapture3D</a> <a class="uri" href="OpenAL" title="wikilink">OpenAL</a> driver.</p>
<h2 id="patents-and-trademarks">Patents and Trademarks</h2>

<p>Most of the patents covering Ambisonic developments have now expired (including those covering the <a href="Soundfield_microphone" title="wikilink">Soundfield microphone</a>) and, as a result, the basic technology is available for anyone to implement. Exceptions to this include Dr Geoffrey Barton's <a class="uri" href="Trifield" title="wikilink">Trifield</a> technology, which is a three-speaker stereo rendering system based on Ambisonic theory (), and so-called "Vienna" decoders, based on Gerzon and Barton's Vienna 1992 AES paper, which are intended for decoding to irregular speaker arrays ().</p>

<p>The "pool" of patents comprising Ambisonics technology was originally assembled by the UK Government's National Research &amp; Development Corporation (NRDC), which existed until the late 1970s to develop and promote British inventions and license them to commercial manufacturers – ideally to a single licensee. The system was ultimately licensed to <a href="Nimbus_Records" title="wikilink">Nimbus Records</a> (now owned by Wyastone Estate Ltd).</p>

<p>The "interlocking circles" Ambisonic logo (UK trademarks <a href="http://www.ipo.gov.uk/tmcase/Results/1/UK00001113276">UK00001113276</a> and <a href="http://www.ipo.gov.uk/tmcase/Results/1/UK00001113277">UK00001113277</a>), and the text marks "AMBISONIC" and "A M B I S O N" (UK trademarks <a href="http://www.ipo.gov.uk/tmcase/Results/1/UK00001500177">UK00001500177</a> and <a href="http://www.ipo.gov.uk/tmcase/Results/1/UK00001112259">UK00001112259</a>), formerly owned by Wyastone Estate Ltd., have expired as of 2010.</p>
<h2 id="see-also">See also</h2>
<ul>
<li><a href="Ambisonic_reproduction_systems" title="wikilink">Ambisonic reproduction systems</a></li>
<li><a href="Ambisonic_decoding" title="wikilink">Ambisonic decoding</a></li>
<li><a href="Ambisonic_UHJ_Format" title="wikilink">Ambisonic UHJ Format</a></li>
<li><a href="List_of_Ambisonic_Software" title="wikilink">List of Ambisonic Software</a></li>
<li><a href="List_of_Ambisonic_Hardware" title="wikilink">List of Ambisonic Hardware</a></li>
<li><a href="List_of_permanent_Ambisonic_playback_systems" title="wikilink">List of permanent Ambisonic playback systems</a></li>
<li><a href="List_of_Ambisonic_Source_Texts" title="wikilink">List of Ambisonic Source Texts</a></li>
<li><a href="Nimbus_Records" title="wikilink">Nimbus Records</a></li>
<li><a href="Soundfield_microphone" title="wikilink">Soundfield microphone</a></li>
</ul>
<h2 id="notes">Notes</h2>
<h2 id="references">References</h2>
<h2 id="external-links">External links</h2>
<ul>
<li><a href="http://www.ambisonic.net/">Ambisonic.net</a> website</li>
<li><a href="http://www.ambisonia.com/">Ambisonia</a>, a repository of Ambisonic recordings and compositions</li>
<li><a href="http://ambisonic.info/">Ambisonic.info</a>, website of Ambisonic field recordist Paul Hodges</li>
</ul>
<ul>
<li><a href="http://pcfarina.eng.unipr.it/Ambisonics.htm">Ambisonics resources</a> at the University of Parma</li>
<li><a href="http://www.york.ac.uk/inst/mustech/3d_audio/">Ambisonic resources</a> at the University of York</li>
<li><a href="http://www.blueripplesound.com/hoa-introduction">Higher Order Ambisonic Technical Notes</a> at Blue Ripple Sound</li>
</ul>

<p>"</p>

<p><a href="Category:Ambisonics" title="wikilink"> </a> <a href="Category:Surround_sound" title="wikilink">Category:Surround sound</a> <a href="Category:Sound_technology" title="wikilink">Category:Sound technology</a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1">Michael A. Gerzon, <em>Periphony: With-Height Sound Reproduction</em>. Journal of the Audio Engineering Society, 1973, 21(1):2–10.<a href="#fnref1">↩</a></li>
<li id="fn2">The traditional B-format notation is used in this introductory paragraph, since it is assumed that the reader may have come across it already. For higher-order Ambisonics, use of the <a href="Ambisonic_data_exchange_formats" title="wikilink">ACN notation</a> is recommended.<a href="#fnref2">↩</a></li>
<li id="fn3"><a href="#fnref3">↩</a></li>
<li id="fn4">Eric Benjamin, Richard Lee, and Aaron Heller, <a href="http://www.ai.sri.com/ajh/ambisonics/BLaH3.pdf"><em>Is My Decoder Ambisonic?</em></a>, 125th AES Convention, San Francisco 2008<a href="#fnref4">↩</a></li>
<li id="fn5"><a href="#fnref5">↩</a></li>
<li id="fn6"><a href="#fnref6">↩</a></li>
<li id="fn7"><a href="#fnref7">↩</a></li>
<li id="fn8">Darren B Ward and Thushara D Abhayapala, <em><a href="http://www-sigproc.eng.cam.ac.uk/research/reading%2520group/material/00943347.pdf">Reproduction of a Plane-Wave Sound Field Using an Array of Loudspeakers</a></em>, IEEE Transactions on Speech and Audio Processing Vol.9 No.6, Sept 2001<a href="#fnref8">↩</a></li>
<li id="fn9">Michael A Gerzon, Geoffrey J Barton, "Ambisonic Decoders for HDTV", 92nd AES Convention, Vienna 1992. <a class="uri" href="http://www.aes.org/e-lib/browse.cfm?elib=6788">http://www.aes.org/e-lib/browse.cfm?elib=6788</a><a href="#fnref9">↩</a></li>
<li id="fn10"></li>
<li id="fn11">Jörn Nettingsmeier and David Dohrmann, <a href="http://stackingdwarves.net/public_stuff/linux_audio/ambisonic_symposium_2011/AmbiSym2011-Nettingsmeier-Dohrmann_Large-scale_HOA_Systems.pdf"><em>Preliminary studies on large-scale higher-order Ambisonic sound reinforcement systems</em></a>, Ambisonics Symposium 2011, Lexington (KY) 2011<a href="#fnref11">↩</a></li>
<li id="fn12">Eric Benjamin, Richard Lee, and Aaron Heller: <a href="http://www.ai.sri.com/ajh/ambisonics/BLaH1.pdf">Localization in Horizontal-Only Ambisonic Systems</a>, 121st AES Convention, San Francisco 2006<a href="#fnref12">↩</a></li>
<li id="fn13">Jérôme Daniel, <a href="http://gyronymo.free.fr/audio3D/publications/AES23%20NFC%20HOA.pdf"><em>Spatial Sound Encoding Including Near Field Effect: Introducing Distance Coding Filters and a Viable, New Ambisonic Format</em></a>, 23rd AES Conference, Copenhagen 2003<a href="#fnref13">↩</a></li>
<li id="fn14">Richard Elen, <a href="http://www.ambisonic.net/gformat.html"><em>Ambisonics for the New Millennium</em></a>, September 1998.<a href="#fnref14">↩</a></li>
<li id="fn15">Bruce Wiggins, <a href="http://www.brucewiggins.co.uk/wp-content/plugins/download-monitor/download.php?id=3"><em>The Generation of Panning Laws for Irregular Speaker Arrays Using Heuristic Methods</em></a>. 31st AES Conference, London 2007<a href="#fnref15">↩</a></li>
<li id="fn16">E. M. Benjamin and T. Chen, “The Native B-Format Microphone,” AES 119th Convention, New York, 2005, Preprint no. 6621. <a class="uri" href="http://www.aes.org/e-lib/browse.cfm?elib=13348">http://www.aes.org/e-lib/browse.cfm?elib=13348</a><a href="#fnref16">↩</a></li>
<li id="fn17">[1] E. M. Benjamin and T. Chen, “The Native B-Format Microphone: Part II,” AES 120th Convention, Paris, 2006, Preprint no. 6640. <a class="uri" href="http://www.aes.org/e-lib/browse.cfm?elib=13444">http://www.aes.org/e-lib/browse.cfm?elib=13444</a><a href="#fnref17">↩</a></li>
<li id="fn18">Michael A. Gerzon, <em>The Design of Precisely Coincident Microphone Arrays for Stereo and Surround Sound</em>, 50th AES Convention, London 1975, <a class="uri" href="http://www.aes.org/e-lib/browse.cfm?elib=2466">http://www.aes.org/e-lib/browse.cfm?elib=2466</a><a href="#fnref18">↩</a></li>
<li id="fn19">Peter Plessas, <a href="http://plessas.mur.at/rnd/da/Thesis_Plessas.pdf"><em>Rigid Sphere Microphone Arrays for Spatial Recording and Holography</em></a>, Diploma thesis in Electrical Engineering - Audio Engineering, Graz 2009<a href="#fnref19">↩</a></li>
<li id="fn20">P G Craven, M J Law, and C Travis, <a href="http://ambisonics.iem.at/symposium2009/proceedings/ambisym09-craventravis-tangentialsphmic.pdf/at_download/file"><em>Microphone arrays using tangential velocity sensors</em></a>, Ambisonics Symposium, Graz 2009<a href="#fnref20">↩</a></li>
<li id="fn21">Michael A Gerzon and Geoffrey J Barton, <em>Ambisonic Surround-Sound Mixing for Multitrack Studios</em>, AES Preprint C1009, 2nd International Conference: The Art and Technology of Recording May 1984. <a class="uri" href="http://www.aes.org/e-lib/browse.cfm?elib=11654">http://www.aes.org/e-lib/browse.cfm?elib=11654</a><a href="#fnref21">↩</a></li>
<li id="fn22">Richard Elen, <a href="http://www.ambisonic.net/ambimix.html"><em>Ambisonic mixing – an introduction</em></a>, Studio Sound, September 1983<a href="#fnref22">↩</a></li>
<li id="fn23">Nigel Branwell, <a href="http://www.ambisonic.net/branwell_arb.html"><em>Ambisonic Surround-Sound Technology for Recording and Broadcast</em></a>, Recording Engineer/Producer, December 1983<a href="#fnref23">↩</a></li>
<li id="fn24"></li>
<li id="fn25">Dave G. Malham, <a href="http://www.york.ac.uk/inst/mustech/3d_audio/ambis2.htm"><em>Spatial Heading Mechanisms and Sound Reproduction</em></a> 1998, retrieved 2014-01-24<a href="#fnref25">↩</a></li>
<li id="fn26">Richard Dobson <a href="http://people.bath.ac.uk/masrwd/bformat.html"><em>The AMB Ambisonic File Format</em></a><a href="#fnref26">↩</a></li>
<li id="fn27">Christian Nachbar, Franz Zotter, Etienne Deleflie, and Alois Sontacchi: <a href="http://iem.kug.ac.at/fileadmin/media/iem/projects/2011/ambisonics11_nachbar_zotter_sontacchi_deleflie.pdf"><em>AmbiX - A Suggested Ambisonics Format</em></a> Ambisonics Symposium 2011, Lexington (KY) 2011<a href="#fnref27">↩</a></li>
<li id="fn28">Peter Fellgett, <em>Ambisonics. Part One: General System Description</em>, Studio Sound, August 1975, 1:20–22,40.<a href="#fnref28">↩</a></li>
<li id="fn29"><a href="#fnref29">↩</a></li>
<li id="fn30">Chris Baume, Anthony Churnside, <a href="http://www.bbc.co.uk/rd/publications/whitepaper221"><em>Upping the Auntie: A Broadcaster's Take on Ambisonics</em></a>, BBC R&amp;D; Publications, 2012<a href="#fnref30">↩</a></li>
<li id="fn31">Darius Satongar, Chris Dunn, Yiu Lam, and Francis Li <a href="http://www.bbc.co.uk/rd/publications/whitepaper261"><em>Localisation Performance of Higher-Order Ambisonics for Off-Centre Listening</em>, BBC R&amp;D; Publications, 2013</a><a href="#fnref31">↩</a></li>
<li id="fn32">Paul Power, Chris Dunn, W. Davies, and J. Hirst, <a href="http://www.bbc.co.uk/rd/publications/whitepaper261"><em>Localisation of Elevated Sources in Higher-order Ambisonics</em></a>, BBC R&amp;D; Publications, 2013<a href="#fnref32">↩</a></li>
<li id="fn33">Johann-Markus Batke and Florian Keiler, <a href="http://ambisonics10.ircam.fr/drupal/files/proceedings/presentations/O14_47.pdf"><em>Using VBAP-derived Panning Functions for 3D Ambisonics Decoding</em></a> 2nd International Symposium on Ambisonics and Spherical Acoustics, Paris 2010<a href="#fnref33">↩</a></li>
<li id="fn34">Florian Keiler, Sven Kordon, Johannes Boehm, Holger Kropp, and Johann-Markus Batke, <a href="http://www.google.com/patents/EP2450880A1"><em>Data structure for Higher Order Ambisonics audio data</em></a>, European Patent Application EP 2450880 A1, 2012<a href="#fnref34">↩</a></li>
<li id="fn35"><a href="#fnref35">↩</a></li>
<li id="fn36"><a href="#fnref36">↩</a></li>
<li id="fn37"><a href="#fnref37">↩</a></li>
<li id="fn38"><a href="#fnref38">↩</a></li>
<li id="fn39"><a href="#fnref39">↩</a></li>
<li id="fn40"><a href="#fnref40">↩</a></li>
<li id="fn41"><a href="#fnref41">↩</a></li>
<li id="fn42"><a href="#fnref42">↩</a></li>
</ol>
</section>
</body>
</html>
