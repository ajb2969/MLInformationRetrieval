<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title offset="635">Log sum inequality</title>
   <script type="text/javascript"
      src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js">
    </script>
</head>
<body>
<h1>Log sum inequality</h1>
<hr/>
<p>__NOTOC__ In mathematics, the <strong>log sum inequality</strong> is an <a href="inequality_(mathematics)" title="wikilink">inequality</a> which is useful for proving several theorems in <a href="information_theory" title="wikilink">information theory</a>.</p>
<h2 id="statement">Statement</h2>
<p>Let <span class="LaTeX">$a_1,\ldots,a_n$</span> and <span class="LaTeX">$b_1,\ldots,b_n$</span> be nonnegative numbers. Denote the sum of all <span class="LaTeX">$a_i\;$</span>s by <span class="LaTeX">$a$</span> and the sum of all <span class="LaTeX">$b_i\;$</span>s by <span class="LaTeX">$b$</span>. The log sum inequality states that</p>
<p><span class="LaTeX">$$\sum_{i=1}^n a_i\log\frac{a_i}{b_i}\geq a\log\frac{a}{b},$$</span></p>
<p>with equality if and only if <span class="LaTeX">$\frac{a_i}{b_i}$</span> are equal for all <span class="LaTeX">$i$</span>.</p>
<h2 id="proof">Proof</h2>
<p>Notice that after setting <span class="LaTeX">$f(x)=x\log x$</span> we have</p>
<p><span class="LaTeX">$$\begin{align}
\sum_{i=1}^n a_i\log\frac{a_i}{b_i} & {} = \sum_{i=1}^n b_i f\left(\frac{a_i}{b_i}\right)
 = b\sum_{i=1}^n \frac{b_i}{b} f\left(\frac{a_i}{b_i}\right) \\
& {} \geq b f\left(\sum_{i=1}^n \frac{b_i}{b}\frac{a_i}{b_i}\right) = b f\left(\frac{1}{b}\sum_{i=1}^n a_i\right)
= b f\left(\frac{a}{b}\right) \\
& {} = a\log\frac{a}{b},
\end{align}$$</span> where the inequality follows from <a href="Jensen's_inequality" title="wikilink">Jensen's inequality</a> since <span class="LaTeX">$\frac{b_i}{b}\geq 0$</span>, <span class="LaTeX">$\sum_i\frac{b_i}{b}= 1$</span>, and <span class="LaTeX">$f$</span> is convex.</p>
<h2 id="applications">Applications</h2>
<p>The log sum inequality can be used to prove several inequalities in information theory such as <a href="Gibbs'_inequality" title="wikilink">Gibbs' inequality</a> or the convexity of <a href="KL-divergence" title="wikilink">Kullback-Leibler divergence</a>.</p>
<p>For example to prove Gibbs' inequality it is enough to substitute <span class="LaTeX">$p_i\;$</span>s for <span class="LaTeX">$a_i\;$</span>s, and <span class="LaTeX">$q_i\;$</span>s for <span class="LaTeX">$b_i\;$</span>s to get</p>
<p><span class="LaTeX">$$D_{\mathrm{KL}}(P\|Q) \equiv \sum_{i=1}^n p_i \log_2 \frac{p_i}{q_i} \geq 1\log\frac{1}{1} = 0.$$</span></p>
<h2 id="generalizations">Generalizations</h2>
<p>The inequality remains valid for <span class="LaTeX">$n=\infty$</span> provided that <span class="LaTeX">$a<\infty$</span> and <span class="LaTeX">$b<\infty$</span>. The proof above holds for any function <span class="LaTeX">$g$</span> such that <span class="LaTeX">$f(x)=xg(x)$</span> is convex, such as all continuous non-decreasing functions. Generalizations to convex functions other than the logarithm is given in Csisz√°r, 2004.</p>
<h2 id="references">References</h2>
<ul>
<li>T.S. Han, K. Kobayashi, <em>Mathematics of information and coding.</em> American Mathematical Society, 2001. ISBN 0-8218-0534-7.</li>
<li>Information Theory course materials, Utah State University <a href="http://ocw.usu.edu/Electrical_and_Computer_Engineering/Information_Theory/lecture3.pdf">1</a>. Retrieved on 2009-06-14.</li>
<li></li>
</ul>
<p>"</p>
<p><a class="uri" href="Category:Inequalities" title="wikilink">Category:Inequalities</a> <a href="Category:Information_theory" title="wikilink">Category:Information theory</a> <a href="Category:Articles_containing_proofs" title="wikilink">Category:Articles containing proofs</a></p>
</body>
</html>
