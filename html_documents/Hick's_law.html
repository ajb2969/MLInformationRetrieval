<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="573">Hick's law</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>Hick's law</h1>
<hr/>

<p><strong>Hick's law</strong>, or the <strong>Hick–Hyman Law</strong>, named after British and American psychologists <a href="W._E._Hick" title="wikilink">William Edmund Hick</a> and <a href="Ray_Hyman" title="wikilink">Ray Hyman</a>, describes the <a href="reaction_time" title="wikilink">time</a> it takes for a person to make a decision as a result of the possible choices he or she has: increasing the number of choices will increase the decision time <a href="logarithm" title="wikilink">logarithmically</a>. The Hick–Hyman law assesses cognitive information capacity in choice reaction experiments. The amount of time taken to process a certain amount of bits in the Hick–Hyman law is known as the <em>rate of gain of information</em>.</p>

<p>Hick's law is sometimes cited to justify <a href="menu_(computing)" title="wikilink">menu</a> design decisions. For example, to find a given word (e.g. the name of a command) in a randomly ordered word list (e.g. a menu), scanning of each word in the list is required, consuming linear time, so Hick's law does not apply. However, if the list is alphabetical and the user knows the name of the command, he or she may be able to use a subdividing strategy that works in logarithmic time.<a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a></p>
<h2 id="background">Background</h2>

<p>In 1868, the relationship between having multiple <a href="stimulus_(psychology)" title="wikilink">stimuli</a> and the choice reaction time was reported by <a href="Franciscus_Donders" title="wikilink">Franciscus Donders</a>. In 1885, J. Merkel discovered the response time is longer when a stimulus belongs to a larger set of stimuli. Psychologists began to see similarities between this phenomenon and the <a href="Information_Theory" title="wikilink">Information Theory</a>.</p>

<p>Hick first began experimenting with this theory in 1951. His first experiment involved 10 lamps with corresponding <a href="Morse_Code" title="wikilink">Morse Code</a> keys. The lamps would light at random every five seconds. The choice reaction time was recorded with the number of choices ranging from 2–10 lamps.</p>

<p>Hick performed a second experiment using the same task, while keeping the number of alternatives at 10. The participant performed the task the first two times with the instruction to perform the task as accurately as possible. For the last task, the participant was asked to perform the task as quickly as possible.</p>

<p>While Hick was stating that the relationship between reaction time and the number of choices was logarithmic, Hyman wanted to better understand the relationship between the reaction time and the mean number of choices. In Hyman’s experiment, he had eight different lights arranged in a 6x6 matrix. Each of these different lights was given a name, so the participant was timed in the time it took to say the name of the light after it was lit. Further experiments changed the number of each different type of light. Hyman was responsible for determining a <a href="linear_relation" title="wikilink">linear relation</a> between reaction time and the information transmitted.</p>
<h2 id="law">Law</h2>

<p>Given <em>n</em> equally probable choices, the average reaction time <em>T</em> required to choose among the choices is approximately:</p>

<p>

<math display="block" id="Hick's_law:0">
 <semantics>
  <mrow>
   <mi>T</mi>
   <mo>=</mo>
   <mrow>
    <mi>b</mi>
    <mo>⋅</mo>
    <mrow>
     <msub>
      <mi>log</mi>
      <mn>2</mn>
     </msub>
     <mrow>
      <mo stretchy="false">(</mo>
      <mrow>
       <mi>n</mi>
       <mo>+</mo>
       <mn>1</mn>
      </mrow>
      <mo stretchy="false">)</mo>
     </mrow>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <ci>T</ci>
    <apply>
     <ci>normal-⋅</ci>
     <ci>b</ci>
     <apply>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <log></log>
       <cn type="integer">2</cn>
      </apply>
      <apply>
       <plus></plus>
       <ci>n</ci>
       <cn type="integer">1</cn>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   T=b\cdot\log_{2}(n+1)
  </annotation>
 </semantics>
</math>

</p>

<p>where <em>b</em> is a constant that can be determined empirically by fitting a line to measured data. The <a class="uri" href="logarithm" title="wikilink">logarithm</a> expresses depth of "choice tree" hierarchy – log<sub>2</sub> indicates <a href="binary_search" title="wikilink">binary search</a> was performed. Addition of 1 to <em>n</em> takes into account the "uncertainty about whether to respond or not, as well as about which response to make."<a class="footnoteRef" href="#fn2" id="fnref2"><sup>2</sup></a></p>

<p>In the case of choices with unequal probabilities, the law can be generalized as:</p>

<p>

<math display="block" id="Hick's_law:1">
 <semantics>
  <mrow>
   <mi>T</mi>
   <mo>=</mo>
   <mrow>
    <mi>b</mi>
    <mi>H</mi>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <ci>T</ci>
    <apply>
     <times></times>
     <ci>b</ci>
     <ci>H</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   T=bH
  </annotation>
 </semantics>
</math>

</p>

<p>where <em>H</em> is the <a href="information_theory" title="wikilink">information-theoretic</a> entropy of the decision, defined as:</p>

<p>

<math display="block" id="Hick's_law:2">
 <semantics>
  <mrow>
   <mi>H</mi>
   <mo>=</mo>
   <mrow>
    <munderover>
     <mo largeop="true" movablelimits="false" symmetric="true">∑</mo>
     <mi>i</mi>
     <mi>n</mi>
    </munderover>
    <mrow>
     <msub>
      <mi>p</mi>
      <mi>i</mi>
     </msub>
     <mrow>
      <msub>
       <mi>log</mi>
       <mn>2</mn>
      </msub>
      <mrow>
       <mo stretchy="false">(</mo>
       <mrow>
        <mrow>
         <mn>1</mn>
         <mo>/</mo>
         <msub>
          <mi>p</mi>
          <mi>i</mi>
         </msub>
        </mrow>
        <mo>+</mo>
        <mn>1</mn>
       </mrow>
       <mo stretchy="false">)</mo>
      </mrow>
     </mrow>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <ci>H</ci>
    <apply>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <sum></sum>
       <ci>i</ci>
      </apply>
      <ci>n</ci>
     </apply>
     <apply>
      <times></times>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>p</ci>
       <ci>i</ci>
      </apply>
      <apply>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <log></log>
        <cn type="integer">2</cn>
       </apply>
       <apply>
        <plus></plus>
        <apply>
         <divide></divide>
         <cn type="integer">1</cn>
         <apply>
          <csymbol cd="ambiguous">subscript</csymbol>
          <ci>p</ci>
          <ci>i</ci>
         </apply>
        </apply>
        <cn type="integer">1</cn>
       </apply>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   H=\sum_{i}^{n}p_{i}\log_{2}(1/p_{i}+1)
  </annotation>
 </semantics>
</math>

</p>

<p>where <em>p<sub>i</sub></em> refers to the probability of the <em>i</em>th alternative yielding the information-theoretic entropy.</p>

<p>Hick's law is similar in form to <a href="Fitts's_law" title="wikilink">Fitts's law</a>. Hick's law has a logarithmic form because people subdivide the total collection of choices into categories, eliminating about half of the remaining choices at each step, rather than considering each and every choice one-by-one, which would require linear time.</p>
<h3 id="relation-to-iq">Relation to IQ</h3>

<p> E. Roth (1964) demonstrated a correlation between IQ and information processing speed, which is the <a href="Multiplicative_inverse" title="wikilink">reciprocal</a> of the slope of the function:<a class="footnoteRef" href="#fn3" id="fnref3"><sup>3</sup></a></p>

<p>

<math display="block" id="Hick's_law:3">
 <semantics>
  <mrow>
   <mtext>Reaction Time</mtext>
   <mo>=</mo>
   <mrow>
    <mtext>Movement Time</mtext>
    <mo>+</mo>
    <mfrac>
     <mrow>
      <msub>
       <mi>log</mi>
       <mn>2</mn>
      </msub>
      <mrow>
       <mo stretchy="false">(</mo>
       <mi>n</mi>
       <mo stretchy="false">)</mo>
      </mrow>
     </mrow>
     <mtext>Processing Speed</mtext>
    </mfrac>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <mtext>Reaction Time</mtext>
    <apply>
     <plus></plus>
     <mtext>Movement Time</mtext>
     <apply>
      <divide></divide>
      <apply>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <log></log>
        <cn type="integer">2</cn>
       </apply>
       <ci>n</ci>
      </apply>
      <mtext>Processing Speed</mtext>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \text{Reaction Time}=\text{Movement Time}+\frac{\log_{2}(n)}{\text{Processing %
Speed}}
  </annotation>
 </semantics>
</math>

</p>

<p>where <em>n</em> is the number of choices. The time it takes to come to a decision is:</p>

<p>

<math display="block" id="Hick's_law:4">
 <semantics>
  <mrow>
   <mtext>Processing Speed</mtext>
   <mo>⋅</mo>
   <mrow>
    <msub>
     <mi>log</mi>
     <mn>2</mn>
    </msub>
    <mrow>
     <mo stretchy="false">(</mo>
     <mi>n</mi>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <ci>normal-⋅</ci>
    <mtext>Processing Speed</mtext>
    <apply>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <log></log>
      <cn type="integer">2</cn>
     </apply>
     <ci>n</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \text{Processing Speed}\cdot\log_{2}(n)
  </annotation>
 </semantics>
</math>

</p>
<h2 id="stimulusresponse-compatibility">Stimulus–response compatibility</h2>

<p>The stimulus–response compatibility is known to also affect the choice <a href="reaction_time" title="wikilink">reaction time</a> for the Hick–Hyman Law. This means that the response should be similar to the stimulus itself (such as turning a steering wheel to turn the wheels of the car). The action the user performs is similar to the response the driver receives from the car.</p>
<h2 id="see-also">See also</h2>
<ul>
<li><a href="Power_Law_of_Practice" title="wikilink">Power Law of Practice</a></li>
<li><em><a href="The_Paradox_of_Choice" title="wikilink">The Paradox of Choice</a></em></li>
</ul>
<h2 id="notes">Notes</h2>
<h2 id="references">References</h2>
<ul>
<li></li>
<li></li>
<li></li>
<li></li>
<li></li>
<li></li>
<li></li>
</ul>
<h2 id="external-links">External links</h2>
<ul>
<li><a href="http://www.usabilityfirst.com/glossary/hicks-law/">Usability Glossary: Hick's Law</a></li>
</ul>

<p>"</p>

<p><a href="Category:Experimental_psychology" title="wikilink">Category:Experimental psychology</a> <a href="Category:Human–computer_interaction" title="wikilink">Category:Human–computer interaction</a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1"><a href="#fnref1">↩</a></li>
<li id="fn2"><a href="#fnref2">↩</a></li>
<li id="fn3"><a href="#fnref3">↩</a></li>
</ol>
</section>
</body>
</html>
