<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="507">Monte Carlo tree search</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>Monte Carlo tree search</h1>
<hr/>

<p>In <a href="computer_science" title="wikilink">computer science</a>, <strong>Monte Carlo tree search</strong> (<strong>MCTS</strong>) is a <a href="heuristic_(computer_science)" title="wikilink">heuristic</a> <a href="search_algorithm" title="wikilink">search algorithm</a> of making decisions in some <a href="decision_process" title="wikilink">decision processes</a>, most notably employed in game playing. The leading example of its use is in contemporary <a href="computer_Go" title="wikilink">computer Go</a> programs,<a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a> but it is also used in other board games, as well as real-time video games and non-deterministic games such as poker (see <a href="#History" title="wikilink">history</a> section).</p>
<h2 id="principle-of-operation">Principle of operation</h2>

<p>MCTS concentrates on analysing the most promising moves, basing the expansion of the <a href="search_tree" title="wikilink">search tree</a> on <a href="Monte_Carlo_method" title="wikilink">random sampling</a> of the search space. MCTS in games is based on many <em>playouts</em>. In each playout, the games are played-out to the very end by selecting moves at random. The final game result of each playout is then used to weight the nodes in the game tree so that better nodes are more likely to be chosen in future playouts.</p>

<p>The most primitive way of using playouts is playing the same number of them after each legal move of the current player and choosing the move, after which the most playouts ended up in the player's victory.<a class="footnoteRef" href="#fn2" id="fnref2"><sup>2</sup></a> The efficiency of this method—called <em>Pure Monte Carlo Game Search</em>—often increases when, as time goes on, more playouts are assigned to the moves that have frequently resulted in the player's victory (in previous playouts). Full MCTS consists in employing this principle recursively on many depths of the game tree. Each round of MCTS consists of four steps:<a class="footnoteRef" href="#fn3" id="fnref3"><sup>3</sup></a></p>
<ul>
<li><em>Selection</em>: starting from root 

<math display="inline" id="Monte_Carlo_tree_search:0">
 <semantics>
  <mi>R</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>R</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   R
  </annotation>
 </semantics>
</math>

, select successive child nodes down to a leaf node 

<math display="inline" id="Monte_Carlo_tree_search:1">
 <semantics>
  <mi>L</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>L</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   L
  </annotation>
 </semantics>
</math>

. The section below says more about a way of choosing child nodes that lets the game tree expand towards most promising moves, which is the essence of MCTS.</li>
<li><em>Expansion</em>: unless 

<math display="inline" id="Monte_Carlo_tree_search:2">
 <semantics>
  <mi>L</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>L</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   L
  </annotation>
 </semantics>
</math>

 ends the game, either create one or more child nodes of it and choose from them node 

<math display="inline" id="Monte_Carlo_tree_search:3">
 <semantics>
  <mi>C</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>C</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   C
  </annotation>
 </semantics>
</math>


.</li>
<li><em>Simulation</em>: play a random playout from node 

<math display="inline" id="Monte_Carlo_tree_search:4">
 <semantics>
  <mi>C</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>C</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   C
  </annotation>
 </semantics>
</math>

.</li>
<li><em>Backpropagation</em>: using the result of the playout, update information in the nodes on the path from 

<math display="inline" id="Monte_Carlo_tree_search:5">
 <semantics>
  <mi>C</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>C</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   C
  </annotation>
 </semantics>
</math>

 to 

<math display="inline" id="Monte_Carlo_tree_search:6">
 <semantics>
  <mi>R</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>R</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   R
  </annotation>
 </semantics>
</math>

.</li>
</ul>

<p>Sample steps of one round are shown in the figure below. Each tree node stores the number of won/played playouts. </p>

<p>Note that the updating of the number of wins in each node during backpropagation should be from the point of view of the player who made the move that resulted in that node <a class="footnoteRef" href="#fn4" id="fnref4"><sup>4</sup></a> (this is not accurately reflected in the sample image above). This ensures that during selection, each player chooses to expand towards the most promising moves for that player, which mirrors the maximizing behavior of each player in reality.</p>

<p>Such rounds are repeated as long as the time allotted to a move is not up. Then, one of moves from the root of the tree is chosen but it is the move with the most simulations made rather than the move with the highest average win rate.</p>
<h2 id="pure-monte-carlo-game-search">Pure Monte Carlo game search</h2>

<p>This basic procedure can be applied in all games which have only positions with finitely many moves, and which allow only for games of finite length. In a position all feasible moves are determined, for each one <em>k</em> random games are played to the very end, and the cumulative scores are recorded. The move with the best score is chosen. Ties are broken by fair coin flips. Pure Monte Carlo Game Search results in strong play in several games with random elements, for instance in <a href="EinStein_würfelt_nicht!" title="wikilink">EinStein würfelt nicht!</a>. It converges to optimal play (as <em>k</em> tends to infinity) in board filling games with random turn order, for instance in <a href="Hex_(board_game)" title="wikilink">Hex</a> with random turn order.</p>
<h2 id="exploration-and-exploitation">Exploration and exploitation</h2>

<p>The main difficulty in selecting child nodes is maintaining some balance between the <em>exploitation</em> of deep variants after moves with high average win rate and the <em>exploration</em> of moves with few simulations. The first formula for balancing exploitation and exploration in games, called UCT (<em>Upper Confidence Bound</em> 1 <em>applied to trees</em>), was introduced by L. Kocsis and Cs. Szepesvári<a class="footnoteRef" href="#fn5" id="fnref5"><sup>5</sup></a> basing on the UCB1 formula derived by Auer, Cesa-Bianchi, and Fischer.<a class="footnoteRef" href="#fn6" id="fnref6"><sup>6</sup></a> Kocsis and Szepesvári recommend to choose in each node of the game tree the move, for which the expression 

<math display="inline" id="Monte_Carlo_tree_search:7">
 <semantics>
  <mrow>
   <mfrac>
    <msub>
     <mi>w</mi>
     <mi>i</mi>
    </msub>
    <msub>
     <mi>n</mi>
     <mi>i</mi>
    </msub>
   </mfrac>
   <mo>+</mo>
   <mrow>
    <mi>c</mi>
    <msqrt>
     <mfrac>
      <mrow>
       <mi>ln</mi>
       <mi>t</mi>
      </mrow>
      <msub>
       <mi>n</mi>
       <mi>i</mi>
      </msub>
     </mfrac>
    </msqrt>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <plus></plus>
    <apply>
     <divide></divide>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>w</ci>
      <ci>i</ci>
     </apply>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>n</ci>
      <ci>i</ci>
     </apply>
    </apply>
    <apply>
     <times></times>
     <ci>c</ci>
     <apply>
      <root></root>
      <apply>
       <divide></divide>
       <apply>
        <ln></ln>
        <ci>t</ci>
       </apply>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <ci>n</ci>
        <ci>i</ci>
       </apply>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \frac{w_{i}}{n_{i}}+c\sqrt{\frac{\ln t}{n_{i}}}
  </annotation>
 </semantics>
</math>

 has the highest value. In this formula:</p>
<ul>
<li>

<math display="inline" id="Monte_Carlo_tree_search:8">
 <semantics>
  <msub>
   <mi>w</mi>
   <mi>i</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>w</ci>
    <ci>i</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   w_{i}
  </annotation>
 </semantics>
</math>


 stands for the number of wins after the 

<math display="inline" id="Monte_Carlo_tree_search:9">
 <semantics>
  <mi>i</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>i</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   i
  </annotation>
 </semantics>
</math>

th move;</li>
<li>

<math display="inline" id="Monte_Carlo_tree_search:10">
 <semantics>
  <msub>
   <mi>n</mi>
   <mi>i</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>n</ci>
    <ci>i</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   n_{i}
  </annotation>
 </semantics>
</math>

 stands for the number of simulations after the 

<math display="inline" id="Monte_Carlo_tree_search:11">
 <semantics>
  <mi>i</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>i</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   i
  </annotation>
 </semantics>
</math>

th move;</li>
<li>

<math display="inline" id="Monte_Carlo_tree_search:12">
 <semantics>
  <mi>c</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>c</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   c
  </annotation>
 </semantics>
</math>

 is the exploration parameter—theoretically equal to 

<math display="inline" id="Monte_Carlo_tree_search:13">
 <semantics>
  <msqrt>
   <mn>2</mn>
  </msqrt>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <root></root>
    <cn type="integer">2</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \sqrt{2}
  </annotation>
 </semantics>
</math>


; in practice usually chosen empirically;</li>
<li>

<math display="inline" id="Monte_Carlo_tree_search:14">
 <semantics>
  <mi>t</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>t</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   t
  </annotation>
 </semantics>
</math>

 stands for the total number of simulations, equal to the sum of all 

<math display="inline" id="Monte_Carlo_tree_search:15">
 <semantics>
  <msub>
   <mi>n</mi>
   <mi>i</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>n</ci>
    <ci>i</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   n_{i}
  </annotation>
 </semantics>
</math>

.</li>
</ul>

<p>The first component of the formula above corresponds to exploitation; it is high for moves with high average win ratio. The second component corresponds to exploration; it is high for moves with few simulations.</p>

<p>Most contemporary implementations of MCTS are based on some variant of UCT.</p>
<h2 id="advantages-and-disadvantages">Advantages and disadvantages</h2>

<p>Although it has been proven that the evaluation of moves in MCTS converges to the <a class="uri" href="minimax" title="wikilink">minimax</a> evaluation,<a class="footnoteRef" href="#fn7" id="fnref7"><sup>7</sup></a> the basic version of MCTS can converge to it after enormous time. Besides this disadvantage (partially cancelled by the improvements described below), MCTS has some advantages compared to <a href="alpha–beta_pruning" title="wikilink">alpha–beta pruning</a> and similar algorithms.</p>

<p>Unlike them, MCTS works without an explicit <a href="evaluation_function" title="wikilink">evaluation function</a>. It is enough to implement game mechanics, i.e. the generating of allowed moves in a given position and the game-end conditions. Thanks to this, MCTS can be applied in games without a developed theory or even in <a href="general_game_playing" title="wikilink">general game playing</a>.</p>

<p>The game tree in MCTS grows asymmetrically: the method concentrates on searching its more promising parts. Thanks to this, it achieves better results than classical algorithms in games with a high <a href="branching_factor" title="wikilink">branching factor</a>.</p>

<p>Moreover, MCTS can be interrupted at <a href="Anytime_algorithm" title="wikilink">any time</a>, yielding the move it considers the most promising.</p>
<h2 id="improvements">Improvements</h2>

<p>Various modifications of the basic MCTS method have been proposed, with the aim of shortening the time to find good moves. They can be divided into improvements based on expert knowledge and into domain-independent improvements.</p>

<p>MCTS can use either <em>light</em> or <em>heavy</em> playouts. Light playouts consist of random moves. In heavy playouts various heuristics influence the choice of moves.<a class="footnoteRef" href="#fn8" id="fnref8"><sup>8</sup></a> The heuristics can be based on the results of previous playouts (e.g. the Last Good Reply heuristic<a class="footnoteRef" href="#fn9" id="fnref9"><sup>9</sup></a>) or on expert knowledge of a given game. For instance, in many go-playing programs, certain stone patterns on a part of the board influence the probability of moving into that part.<a class="footnoteRef" href="#fn10" id="fnref10"><sup>10</sup></a> Paradoxically, not always playing stronger in simulations makes an MCTS program play stronger overall.<a class="footnoteRef" href="#fn11" id="fnref11"><sup>11</sup></a></p>
<figure><b>(Figure)</b>
<figcaption>Patterns of <em>hane</em> (surrounding opponent stones) used in playouts by the MoGo program. It is advantageous both for black and for white to put a stone on the middle square, except the rightmost pattern where it is advantageous for black only.<a class="footnoteRef" href="#fn12" id="fnref12"><sup>12</sup></a></figcaption>
</figure>

<p>Domain-specific knowledge can also be used while building the game tree, to help the exploitation of some variants. One of such methods consists in assigning nonzero <em>priors</em> to the numbers of won and played simulations when creating a child node. Such artificially raised or lowered average win rate causes the node to be chosen more or less frequently, respectively, in the selection step.<a class="footnoteRef" href="#fn13" id="fnref13"><sup>13</sup></a> A related method, called <em>progressive bias</em>, consists in adding to the UCB1 formula a 

<math display="inline" id="Monte_Carlo_tree_search:16">
 <semantics>
  <mfrac>
   <msub>
    <mi>b</mi>
    <mi>i</mi>
   </msub>
   <msub>
    <mi>n</mi>
    <mi>i</mi>
   </msub>
  </mfrac>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <divide></divide>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>b</ci>
     <ci>i</ci>
    </apply>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>n</ci>
     <ci>i</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \frac{b_{i}}{n_{i}}
  </annotation>
 </semantics>
</math>

 element, where 

<math display="inline" id="Monte_Carlo_tree_search:17">
 <semantics>
  <msub>
   <mi>b</mi>
   <mi>i</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>b</ci>
    <ci>i</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   b_{i}
  </annotation>
 </semantics>
</math>

 is a heuristic score of the 

<math display="inline" id="Monte_Carlo_tree_search:18">
 <semantics>
  <mi>i</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>i</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   i
  </annotation>
 </semantics>
</math>


th move.<a class="footnoteRef" href="#fn14" id="fnref14"><sup>14</sup></a></p>

<p>The basic MCTS collects enough information to find the most promising moves after many rounds. Before that, it chooses more or less random moves. This initial phase can be significantly shortened in a certain class of games thanks to RAVE (<em>Rapid Action Value Estimation</em>).<a class="footnoteRef" href="#fn15" id="fnref15"><sup>15</sup></a> The games in question are those where permutations of a sequence of moves lead to the same position, especially board games where a move consists in putting a piece or a stone on the board. In such games, the value of a move is often only slightly influenced by moves played elsewhere.</p>

<p>In RAVE, for a given game tree node 

<math display="inline" id="Monte_Carlo_tree_search:19">
 <semantics>
  <mi>N</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>N</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   N
  </annotation>
 </semantics>
</math>

, its child nodes 

<math display="inline" id="Monte_Carlo_tree_search:20">
 <semantics>
  <msub>
   <mi>C</mi>
   <mi>i</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>C</ci>
    <ci>i</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   C_{i}
  </annotation>
 </semantics>
</math>

 store besides the statistics of wins in playouts started in node 

<math display="inline" id="Monte_Carlo_tree_search:21">
 <semantics>
  <mi>N</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>N</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   N
  </annotation>
 </semantics>
</math>

 also the statistics of wins in all playouts started in node 

<math display="inline" id="Monte_Carlo_tree_search:22">
 <semantics>
  <mi>N</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>N</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   N
  </annotation>
 </semantics>
</math>

 and below it, if they contain move 

<math display="inline" id="Monte_Carlo_tree_search:23">
 <semantics>
  <mi>i</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>i</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   i
  </annotation>
 </semantics>
</math>


 (also when the move was played in the tree, between node 

<math display="inline" id="Monte_Carlo_tree_search:24">
 <semantics>
  <mi>N</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>N</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   N
  </annotation>
 </semantics>
</math>

 and a playout). This way, the contents of tree nodes are influenced not only by moves played immediately in a given position but also by the same moves played later.</p>
<figure><b>(Figure)</b>
<figcaption>RAVE on the example of tic-tac-toe. In red nodes, the RAVE statistics will be updated after the b1-a2-b3 simulation.</figcaption>
</figure>

<p>When using RAVE, the selection step selects the node, for which the modified UCB1 formula 

<math display="inline" id="Monte_Carlo_tree_search:25">
 <semantics>
  <mrow>
   <mrow>
    <mrow>
     <mo stretchy="false">(</mo>
     <mrow>
      <mn>1</mn>
      <mo>-</mo>
      <mrow>
       <mi>β</mi>
       <mrow>
        <mo stretchy="false">(</mo>
        <msub>
         <mi>n</mi>
         <mi>i</mi>
        </msub>
        <mo>,</mo>
        <msub>
         <mover accent="true">
          <mi>n</mi>
          <mo stretchy="false">~</mo>
         </mover>
         <mi>i</mi>
        </msub>
        <mo stretchy="false">)</mo>
       </mrow>
      </mrow>
     </mrow>
     <mo stretchy="false">)</mo>
    </mrow>
    <mfrac>
     <msub>
      <mi>w</mi>
      <mi>i</mi>
     </msub>
     <msub>
      <mi>n</mi>
      <mi>i</mi>
     </msub>
    </mfrac>
   </mrow>
   <mo>+</mo>
   <mrow>
    <mi>β</mi>
    <mrow>
     <mo stretchy="false">(</mo>
     <msub>
      <mi>n</mi>
      <mi>i</mi>
     </msub>
     <mo>,</mo>
     <msub>
      <mover accent="true">
       <mi>n</mi>
       <mo stretchy="false">~</mo>
      </mover>
      <mi>i</mi>
     </msub>
     <mo stretchy="false">)</mo>
    </mrow>
    <mfrac>
     <msub>
      <mover accent="true">
       <mi>w</mi>
       <mo stretchy="false">~</mo>
      </mover>
      <mi>i</mi>
     </msub>
     <msub>
      <mover accent="true">
       <mi>n</mi>
       <mo stretchy="false">~</mo>
      </mover>
      <mi>i</mi>
     </msub>
    </mfrac>
   </mrow>
   <mo>+</mo>
   <mrow>
    <mi>c</mi>
    <msqrt>
     <mfrac>
      <mrow>
       <mi>ln</mi>
       <mi>t</mi>
      </mrow>
      <msub>
       <mi>n</mi>
       <mi>i</mi>
      </msub>
     </mfrac>
    </msqrt>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <plus></plus>
    <apply>
     <times></times>
     <apply>
      <minus></minus>
      <cn type="integer">1</cn>
      <apply>
       <times></times>
       <ci>β</ci>
       <interval closure="open">
        <apply>
         <csymbol cd="ambiguous">subscript</csymbol>
         <ci>n</ci>
         <ci>i</ci>
        </apply>
        <apply>
         <csymbol cd="ambiguous">subscript</csymbol>
         <apply>
          <ci>normal-~</ci>
          <ci>n</ci>
         </apply>
         <ci>i</ci>
        </apply>
       </interval>
      </apply>
     </apply>
     <apply>
      <divide></divide>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>w</ci>
       <ci>i</ci>
      </apply>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>n</ci>
       <ci>i</ci>
      </apply>
     </apply>
    </apply>
    <apply>
     <times></times>
     <ci>β</ci>
     <interval closure="open">
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>n</ci>
       <ci>i</ci>
      </apply>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <apply>
        <ci>normal-~</ci>
        <ci>n</ci>
       </apply>
       <ci>i</ci>
      </apply>
     </interval>
     <apply>
      <divide></divide>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <apply>
        <ci>normal-~</ci>
        <ci>w</ci>
       </apply>
       <ci>i</ci>
      </apply>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <apply>
        <ci>normal-~</ci>
        <ci>n</ci>
       </apply>
       <ci>i</ci>
      </apply>
     </apply>
    </apply>
    <apply>
     <times></times>
     <ci>c</ci>
     <apply>
      <root></root>
      <apply>
       <divide></divide>
       <apply>
        <ln></ln>
        <ci>t</ci>
       </apply>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <ci>n</ci>
        <ci>i</ci>
       </apply>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   (1-\beta(n_{i},\tilde{n}_{i}))\frac{w_{i}}{n_{i}}+\beta(n_{i},\tilde{n}_{i})%
\frac{\tilde{w}_{i}}{\tilde{n}_{i}}+c\sqrt{\frac{\ln t}{n_{i}}}
  </annotation>
 </semantics>
</math>

 has the highest value. In this formula, 

<math display="inline" id="Monte_Carlo_tree_search:26">
 <semantics>
  <msub>
   <mover accent="true">
    <mi>w</mi>
    <mo stretchy="false">~</mo>
   </mover>
   <mi>i</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <apply>
     <ci>normal-~</ci>
     <ci>w</ci>
    </apply>
    <ci>i</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \tilde{w}_{i}
  </annotation>
 </semantics>
</math>

 and 

<math display="inline" id="Monte_Carlo_tree_search:27">
 <semantics>
  <msub>
   <mover accent="true">
    <mi>n</mi>
    <mo stretchy="false">~</mo>
   </mover>
   <mi>i</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <apply>
     <ci>normal-~</ci>
     <ci>n</ci>
    </apply>
    <ci>i</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \tilde{n}_{i}
  </annotation>
 </semantics>
</math>

 stand for the number of won playouts containing move 

<math display="inline" id="Monte_Carlo_tree_search:28">
 <semantics>
  <mi>i</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>i</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   i
  </annotation>
 </semantics>
</math>


 and the number of all playouts containing move 

<math display="inline" id="Monte_Carlo_tree_search:29">
 <semantics>
  <mi>i</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>i</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   i
  </annotation>
 </semantics>
</math>

, and the 

<math display="inline" id="Monte_Carlo_tree_search:30">
 <semantics>
  <mrow>
   <mi>β</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <msub>
     <mi>n</mi>
     <mi>i</mi>
    </msub>
    <mo>,</mo>
    <msub>
     <mover accent="true">
      <mi>n</mi>
      <mo stretchy="false">~</mo>
     </mover>
     <mi>i</mi>
    </msub>
    <mo stretchy="false">)</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <ci>β</ci>
    <interval closure="open">
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>n</ci>
      <ci>i</ci>
     </apply>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <apply>
       <ci>normal-~</ci>
       <ci>n</ci>
      </apply>
      <ci>i</ci>
     </apply>
    </interval>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \beta(n_{i},\tilde{n}_{i})
  </annotation>
 </semantics>
</math>

 function should be close to one and to zero for relatively small and relatively big 

<math display="inline" id="Monte_Carlo_tree_search:31">
 <semantics>
  <msub>
   <mi>n</mi>
   <mi>i</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>n</ci>
    <ci>i</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   n_{i}
  </annotation>
 </semantics>
</math>

 and 

<math display="inline" id="Monte_Carlo_tree_search:32">
 <semantics>
  <msub>
   <mover accent="true">
    <mi>n</mi>
    <mo stretchy="false">~</mo>
   </mover>
   <mi>i</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <apply>
     <ci>normal-~</ci>
     <ci>n</ci>
    </apply>
    <ci>i</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \tilde{n}_{i}
  </annotation>
 </semantics>
</math>

, respectively. One of many formulas for 

<math display="inline" id="Monte_Carlo_tree_search:33">
 <semantics>
  <mrow>
   <mi>β</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <msub>
     <mi>n</mi>
     <mi>i</mi>
    </msub>
    <mo>,</mo>
    <msub>
     <mover accent="true">
      <mi>n</mi>
      <mo stretchy="false">~</mo>
     </mover>
     <mi>i</mi>
    </msub>
    <mo stretchy="false">)</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <ci>β</ci>
    <interval closure="open">
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>n</ci>
      <ci>i</ci>
     </apply>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <apply>
       <ci>normal-~</ci>
       <ci>n</ci>
      </apply>
      <ci>i</ci>
     </apply>
    </interval>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \beta(n_{i},\tilde{n}_{i})
  </annotation>
 </semantics>
</math>


, proposed by D. Silver,<a class="footnoteRef" href="#fn16" id="fnref16"><sup>16</sup></a> says that in balanced positions one can take 

<math display="inline" id="Monte_Carlo_tree_search:34">
 <semantics>
  <mrow>
   <mrow>
    <mi>β</mi>
    <mrow>
     <mo stretchy="false">(</mo>
     <msub>
      <mi>n</mi>
      <mi>i</mi>
     </msub>
     <mo>,</mo>
     <msub>
      <mover accent="true">
       <mi>n</mi>
       <mo stretchy="false">~</mo>
      </mover>
      <mi>i</mi>
     </msub>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
   <mo>=</mo>
   <mfrac>
    <msub>
     <mover accent="true">
      <mi>n</mi>
      <mo stretchy="false">~</mo>
     </mover>
     <mi>i</mi>
    </msub>
    <mrow>
     <msub>
      <mi>n</mi>
      <mi>i</mi>
     </msub>
     <mo>+</mo>
     <msub>
      <mover accent="true">
       <mi>n</mi>
       <mo stretchy="false">~</mo>
      </mover>
      <mi>i</mi>
     </msub>
     <mo>+</mo>
     <mrow>
      <mn>4</mn>
      <msup>
       <mi>b</mi>
       <mn>2</mn>
      </msup>
      <msub>
       <mi>n</mi>
       <mi>i</mi>
      </msub>
      <msub>
       <mover accent="true">
        <mi>n</mi>
        <mo stretchy="false">~</mo>
       </mover>
       <mi>i</mi>
      </msub>
     </mrow>
    </mrow>
   </mfrac>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <times></times>
     <ci>β</ci>
     <interval closure="open">
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>n</ci>
       <ci>i</ci>
      </apply>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <apply>
        <ci>normal-~</ci>
        <ci>n</ci>
       </apply>
       <ci>i</ci>
      </apply>
     </interval>
    </apply>
    <apply>
     <divide></divide>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <apply>
       <ci>normal-~</ci>
       <ci>n</ci>
      </apply>
      <ci>i</ci>
     </apply>
     <apply>
      <plus></plus>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>n</ci>
       <ci>i</ci>
      </apply>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <apply>
        <ci>normal-~</ci>
        <ci>n</ci>
       </apply>
       <ci>i</ci>
      </apply>
      <apply>
       <times></times>
       <cn type="integer">4</cn>
       <apply>
        <csymbol cd="ambiguous">superscript</csymbol>
        <ci>b</ci>
        <cn type="integer">2</cn>
       </apply>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <ci>n</ci>
        <ci>i</ci>
       </apply>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <apply>
         <ci>normal-~</ci>
         <ci>n</ci>
        </apply>
        <ci>i</ci>
       </apply>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \beta(n_{i},\tilde{n}_{i})=\frac{\tilde{n}_{i}}{n_{i}+\tilde{n}_{i}+4b^{2}n_{i%
}\tilde{n}_{i}}
  </annotation>
 </semantics>
</math>

, where 

<math display="inline" id="Monte_Carlo_tree_search:35">
 <semantics>
  <mi>b</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>b</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   b
  </annotation>
 </semantics>
</math>

 is an empirically chosen constant.</p>

<p>Heuristics used in MCTS often depend on many parameters. There are methods of automatic tuning the values of these parameters to maximize the win rate.<a class="footnoteRef" href="#fn17" id="fnref17"><sup>17</sup></a></p>

<p>MCTS can be concurrently executed by many <a href="thread_(computing)" title="wikilink">threads</a> or <a href="process_(computing)" title="wikilink">processes</a>. There are several fundamentally different methods of its <a href="parallel_computing" title="wikilink">parallel</a> execution:<a class="footnoteRef" href="#fn18" id="fnref18"><sup>18</sup></a></p>
<ul>
<li><em>Leaf parallelization</em>, i.e. parallel execution of many playouts from one leaf of the game tree.</li>
<li><em>Root parallelization</em>, i.e. building independent game trees in parallel and making the move basing on the root-level branches of all these trees.</li>
<li><em>Tree parallelization</em>, i.e. parallel building of the same game tree, protecting data from simultaneous writes either with one, global <a class="uri" href="mutex" title="wikilink">mutex</a>, with more mutexes, or with <a href="non-blocking_algorithm" title="wikilink">non-blocking synchronization</a>.<a class="footnoteRef" href="#fn19" id="fnref19"><sup>19</sup></a></li>
</ul>
<h2 id="history">History</h2>

<p>The <a href="Monte_Carlo_method" title="wikilink">Monte Carlo method</a>, based on random sampling, dates back to the 1940s. Bruce Abramson explored the idea in his 1987 PhD thesis and said it "is shown to be precise, accurate, easily estimable, efficiently calculable, and domain-independent."<a class="footnoteRef" href="#fn20" id="fnref20"><sup>20</sup></a> He experimented in-depth with <a class="uri" href="Tic-tac-toe" title="wikilink">Tic-tac-toe</a> and then with machine generated evaluation functions for <a href="Reversi" title="wikilink">Othello</a> and <a class="uri" href="Chess" title="wikilink">Chess</a>. In 1992, B. Brügmann employed it for the first time in a go-playing program,<a class="footnoteRef" href="#fn21" id="fnref21"><sup>21</sup></a> but his idea was not taken seriously. In 2006, called the year of the Monte Carlo revolution in Go,<a class="footnoteRef" href="#fn22" id="fnref22"><sup>22</sup></a> R. Coulom described the application of the Monte Carlo method to game-tree search and coined the name Monte Carlo tree search,<a class="footnoteRef" href="#fn23" id="fnref23"><sup>23</sup></a> L. Kocsis and Cs. Szepesvári developed the UCT algorithm,<a class="footnoteRef" href="#fn24" id="fnref24"><sup>24</sup></a> and S. Gelly et al. implemented UCT in their program MoGo.<a class="footnoteRef" href="#fn25" id="fnref25"><sup>25</sup></a> In 2008, MoGo achieved <a href="dan_(rank)" title="wikilink">dan</a> (master) level in 9×9 go,<a class="footnoteRef" href="#fn26" id="fnref26"><sup>26</sup></a> and the Fuego program began to win with strong amateur players in 9×9 go.<a class="footnoteRef" href="#fn27" id="fnref27"><sup>27</sup></a> In January 2012, the Zen program won 3:1 a 19×19 go match with John Tromp, a 2 dan player.<a class="footnoteRef" href="#fn28" id="fnref28"><sup>28</sup></a></p>
<figure><b>(Figure)</b>
<figcaption>The rating of best go-playing programs on the KGS server since 2007. Since 2006, all the best programs use MCTS.<a class="footnoteRef" href="#fn29" id="fnref29"><sup>29</sup></a></figcaption>
</figure>

<p>MCTS has also been used in programs that play other <a href="board_game" title="wikilink">board games</a> (for example <a href="Hex_(board_game)" title="wikilink">Hex</a>,<a class="footnoteRef" href="#fn30" id="fnref30"><sup>30</sup></a> <a class="uri" href="Havannah" title="wikilink">Havannah</a>,<a class="footnoteRef" href="#fn31" id="fnref31"><sup>31</sup></a> <a href="Game_of_the_Amazons" title="wikilink">Game of the Amazons</a>,<a class="footnoteRef" href="#fn32" id="fnref32"><sup>32</sup></a> and <a class="uri" href="Arimaa" title="wikilink">Arimaa</a><a class="footnoteRef" href="#fn33" id="fnref33"><sup>33</sup></a>), real-time video games (for instance <a href="Ms._Pac-Man" title="wikilink">Ms. Pac-Man</a><a class="footnoteRef" href="#fn34" id="fnref34"><sup>34</sup></a><a class="footnoteRef" href="#fn35" id="fnref35"><sup>35</sup></a> and <a href="Total_War:_Rome_II" title="wikilink">Total War: Rome II</a><a class="footnoteRef" href="#fn36" id="fnref36"><sup>36</sup></a>), and nondeterministic games (such as <a href="skat_(card_game)" title="wikilink">skat</a>,<a class="footnoteRef" href="#fn37" id="fnref37"><sup>37</sup></a> <a class="uri" href="poker" title="wikilink">poker</a>,<a class="footnoteRef" href="#fn38" id="fnref38"><sup>38</sup></a> <a href="Magic:_The_Gathering" title="wikilink">Magic: The Gathering</a>,<a class="footnoteRef" href="#fn39" id="fnref39"><sup>39</sup></a> or <a href="Settlers_of_Catan" title="wikilink">Settlers of Catan</a><a class="footnoteRef" href="#fn40" id="fnref40"><sup>40</sup></a>).</p>
<h2 id="references">References</h2>
<h2 id="bibliography">Bibliography</h2>
<ul>
<li></li>
</ul>

<p>"</p>

<p><a href="Category:Combinatorial_game_theory" title="wikilink">Category:Combinatorial game theory</a> <a href="Category:Heuristic_algorithms" title="wikilink">Category:Heuristic algorithms</a> <a href="Category:Monte_Carlo_methods" title="wikilink">Category:Monte Carlo methods</a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1"><a href="#fnref1">↩</a></li>
<li id="fn2"><a href="#fnref2">↩</a></li>
<li id="fn3"><a href="#fnref3">↩</a></li>
<li id="fn4"><a class="uri" href="http://mcts.ai/code/python.html">http://mcts.ai/code/python.html</a><a href="#fnref4">↩</a></li>
<li id="fn5"><a href="#fnref5">↩</a></li>
<li id="fn6"><a href="#fnref6">↩</a></li>
<li id="fn7"><a href="#fnref7">↩</a></li>
<li id="fn8">Swiechowski, M.; Mandziuk, J., "Self-Adaptation of Playing Strategies in General Game Playing" (2010), <em>IEEE Transactions on Computational Intelligence and AI in Games</em>, doi: 10.1109/TCIAIG.2013.2275163, <a class="uri" href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp</a>=&amp;arnumber;=6571225&amp;isnumber;=4804729<a href="#fnref8">↩</a></li>
<li id="fn9"><a href="#fnref9">↩</a></li>
<li id="fn10"><a href="#fnref10">↩</a></li>
<li id="fn11"><a href="#fnref11">↩</a></li>
<li id="fn12"></li>
<li id="fn13"><a href="#fnref13">↩</a></li>
<li id="fn14"></li>
<li id="fn15"></li>
<li id="fn16"><a href="#fnref16">↩</a></li>
<li id="fn17"><a href="#fnref17">↩</a></li>
<li id="fn18"><a href="#fnref18">↩</a></li>
<li id="fn19"><a href="#fnref19">↩</a></li>
<li id="fn20"><a href="#fnref20">↩</a></li>
<li id="fn21"></li>
<li id="fn22"><a href="#fnref22">↩</a></li>
<li id="fn23"><a href="#fnref23">↩</a></li>
<li id="fn24"></li>
<li id="fn25"></li>
<li id="fn26"><a href="#fnref26">↩</a></li>
<li id="fn27"><a href="#fnref27">↩</a></li>
<li id="fn28"><a href="#fnref28">↩</a></li>
<li id="fn29"><a href="#fnref29">↩</a></li>
<li id="fn30"><a href="#fnref30">↩</a></li>
<li id="fn31"><a href="#fnref31">↩</a></li>
<li id="fn32"><a href="#fnref32">↩</a></li>
<li id="fn33"><a href="#fnref33">↩</a></li>
<li id="fn34"><a href="#fnref34">↩</a></li>
<li id="fn35"><a href="#fnref35">↩</a></li>
<li id="fn36"><a href="#fnref36">↩</a></li>
<li id="fn37"><a href="#fnref37">↩</a></li>
<li id="fn38"><a href="#fnref38">↩</a></li>
<li id="fn39"><a href="#fnref39">↩</a></li>
<li id="fn40"><a href="#fnref40">↩</a></li>
</ol>
</section>
</body>
</html>
