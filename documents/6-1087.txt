   Generalized inverse Gaussian distribution      Generalized inverse Gaussian distribution   {2 K_p(\sqrt{ab})} x^{(p-1)} e^{-(ax + b/x)/2}|  cdf        =|  mean       =        b     K   p  +  1     (    a  b    )       a     K  p    (    a  b    )            b    subscript  K    p  1        a  b         a    subscript  K  p       a  b       \frac{\sqrt{b}\ K_{p+1}(\sqrt{ab})}{\sqrt{a}\ K_{p}(\sqrt{ab})}    |  median     =|  mode       =       (   p  -  1   )   +      (   p  -  1   )   2   +   a  b      a          p  1        superscript    p  1   2     a  b      a    \frac{(p-1)+\sqrt{(p-1)^{2}+ab}}{a}    |  variance   =      (   b  a   )    [      K   p  +  2     (    a  b    )      K  p    (    a  b    )     -    (     K   p  +  1     (    a  b    )      K  p    (    a  b    )     )   2    ]         b  a    delimited-[]         subscript  K    p  2        a  b        subscript  K  p       a  b       superscript       subscript  K    p  1        a  b        subscript  K  p       a  b      2       \left(\frac{b}{a}\right)\left[\frac{K_{p+2}(\sqrt{ab})}{K_{p}(\sqrt{ab})}-%
 \left(\frac{K_{p+1}(\sqrt{ab})}{K_{p}(\sqrt{ab})}\right)^{2}\right]    |  skewness   =|  kurtosis   =|  entropy    =|  mgf        =       (   a   a  -   2  t     )    p  2       K  p    (    b   (   a  -   2  t    )     )      K  p    (    a  b    )          superscript    a    a    2  t       p  2         subscript  K  p       b    a    2  t          subscript  K  p       a  b        \left(\frac{a}{a-2t}\right)^{\frac{p}{2}}\frac{K_{p}(\sqrt{b(a-2t)})}{K_{p}(%
 \sqrt{ab})}    |  char       =       (   a   a  -   2  i  t     )    p  2       K  p    (    b   (   a  -   2  i  t    )     )      K  p    (    a  b    )          superscript    a    a    2  i  t       p  2         subscript  K  p       b    a    2  i  t          subscript  K  p       a  b        \left(\frac{a}{a-2it}\right)^{\frac{p}{2}}\frac{K_{p}(\sqrt{b(a-2it)})}{K_{p}(%
 \sqrt{ab})}    |  }}  In probability theory and statistics , the generalized inverse Gaussian distribution ( GIG ) is a three-parameter family of continuous probability distributions with probability density function         f   (  x  )    =      (   a  /  b   )    p  /  2     2   K  p    (    a  b    )      x   (   p  -  1   )     e   -    (    a  x   +   b  /  x    )   /  2       ,   x  >  0    ,     formulae-sequence      f  x        superscript    a  b     p  2      2   subscript  K  p       a  b       superscript  x    p  1     superscript  e          a  x     b  x    2         x  0     f(x)=\frac{(a/b)^{p/2}}{2K_{p}(\sqrt{ab})}x^{(p-1)}e^{-(ax+b/x)/2},\qquad x>0,     where K p is a modified Bessel function of the second kind, a > 0, b > 0 and p a real parameter. It is used extensively in geostatistics , statistical linguistics, finance, etc. This distribution was first proposed by Étienne Halphen. 1 2 3 It was rediscovered and popularised by Ole Barndorff-Nielsen , who called it the generalized inverse Gaussian distribution. It is also known as the Sichel distribution , after Herbert Sichel . 4 Its statistical properties are discussed in Bent Jørgensen's lecture notes. 5  Properties  Summation  Barndorff-Nielsen and Halgreen proved that the GIG distribution has Infinite divisibility 6  Entropy  The entropy of the generalized inverse Gaussian distribution is given as       H   (   f   (  x  )    )    =       1  2    log   (   b  a   )     +   log   (   2   K  p    (    a  b    )    )     -    (   p  -  1   )      [    d   d  ν     K  ν    (    a  b    )    ]    ν  =  p      K  p    (    a  b    )       +      a  b     2   K  p    (    a  b    )      (     K   p  +  1     (    a  b    )    +    K   p  -  1     (    a  b    )     )           H    f  x              1  2       b  a         2   subscript  K  p       a  b           p  1      subscript   delimited-[]      d    d  ν     subscript  K  ν       a  b        ν  p       subscript  K  p       a  b                a  b      2   subscript  K  p       a  b           subscript  K    p  1        a  b        subscript  K    p  1        a  b          H(f(x))=\frac{1}{2}\log\left(\frac{b}{a}\right)+\log\left(2K_{p}\left(\sqrt{ab%
 }\right)\right)-(p-1)\frac{\left[\frac{d}{d\nu}K_{\nu}\left(\sqrt{ab}\right)%
 \right]_{\nu=p}}{K_{p}\left(\sqrt{ab}\right)}+\frac{\sqrt{ab}}{2K_{p}\left(%
 \sqrt{ab}\right)}\left(K_{p+1}\left(\sqrt{ab}\right)+K_{p-1}\left(\sqrt{ab}%
 \right)\right)     where     [    d   d  ν     K  ν    (    a  b    )    ]    ν  =  p      subscript   delimited-[]      d    d  ν     subscript  K  ν       a  b        ν  p     \left[\frac{d}{d\nu}K_{\nu}\left(\sqrt{ab}\right)\right]_{\nu=p}   is a derivative of the modified Bessel function of the second kind with respect to the order   ν   ν   \nu   evaluated at    ν  =  p      ν  p    \nu=p     Differential equation  The pdf of the generalized inverse Gaussian distribution is a solution to the following differential equation :      {         f   (  x  )    (    x   (     a  x   -   2  p    +  2   )    -  b   )    +   2   x  2    f  ′    (  x  )     =  0   ,         f   (  1  )    =     e    1  2    (    -  a   -  b   )       (   a  b   )    p  /  2      2   K  p    (    a  b    )         }             f  x      x        a  x     2  p    2    b      2   superscript  x  2    superscript  f  normal-′   x    0         f  1        superscript  e      1  2       a   b      superscript    a  b     p  2       2   subscript  K  p       a  b           \left\{\begin{array}[]{l}f(x)(x(ax-2p+2)-b)+2x^{2}f^{\prime}(x)=0,\\
 f(1)=\frac{e^{\frac{1}{2}(-a-b)}\left(\frac{a}{b}\right)^{p/2}}{2K_{p}\left(%
 \sqrt{ab}\right)}\end{array}\right\}     Related distributions  Special cases  The inverse Gaussian and gamma distributions are special cases of the generalized inverse Gaussian distribution for p = -1/2 and b = 0, respectively. 7 Specifically, an inverse Gaussian distribution of the form       f   (  x  ;  μ  ,  λ  )    =     [   λ   2  π   x  3     ]    1  /  2     exp    -   λ    (   x  -  μ   )   2      2   μ  2   x            f   x  μ  λ       superscript   delimited-[]    λ    2  π   superscript  x  3        1  2            λ   superscript    x  μ   2       2   superscript  μ  2   x        f(x;\mu,\lambda)=\left[\frac{\lambda}{2\pi x^{3}}\right]^{1/2}\exp{\frac{-%
 \lambda(x-\mu)^{2}}{2\mu^{2}x}}   is a GIG with    a  =   λ  /   μ  2        a    λ   superscript  μ  2      a=\lambda/\mu^{2}   ,    b  =  λ      b  λ    b=\lambda   , and    p  =   -   1  /  2        p      1  2      p=-1/2   . A Gamma distribution of the form       g   (  x  ;  α  ,  β  )    =    β  α    1   Γ   (  α  )      x   α  -  1     e   -   β  x            g   x  α  β       superscript  β  α     1    normal-Γ  α     superscript  x    α  1     superscript  e      β  x        g(x;\alpha,\beta)=\beta^{\alpha}\frac{1}{\Gamma(\alpha)}x^{\alpha-1}e^{-\beta x}   is a GIG with    a  =   2  β       a    2  β     a=2\beta   ,    b  =  0      b  0    b=0   , and    p  =  α      p  α    p=\alpha   .  Other special cases include the inverse-gamma distribution , for a =0, and the hyperbolic distribution , for p =0. 8  Conjugate prior for Gaussian  The GIG distribution is conjugate to the normal distribution when serving as the mixing distribution in a normal variance-mean mixture . 9 10 Let the prior distribution for some hidden variable, say   z   z   z   , be GIG:      P   (  z  |  a  ,  b  ,  p  )   =  GIG   (  z  |  a  ,  b  ,  p  )      fragments  P   fragments  normal-(  z  normal-|  a  normal-,  b  normal-,  p  normal-)    GIG   fragments  normal-(  z  normal-|  a  normal-,  b  normal-,  p  normal-)     P(z|a,b,p)=\text{GIG}(z|a,b,p)   and let there be   T   T   T   observed data points,    X  =    x  1   ,  …  ,   x  T        X    subscript  x  1   normal-…   subscript  x  T      X=x_{1},\ldots,x_{T}   , with normal likelihood function, conditioned on   z   z   z   :      P   (  X  |  z  ,  α  ,  β  )   =   ∏   i  =  1   T   N   (   x  i   |  α  +  β  z  ,  z  )      fragments  P   fragments  normal-(  X  normal-|  z  normal-,  α  normal-,  β  normal-)     superscript   subscript  product    i  1    T   N   fragments  normal-(   subscript  x  i   normal-|  α   β  z  normal-,  z  normal-)     P(X|z,\alpha,\beta)=\prod_{i=1}^{T}N(x_{i}|\alpha+\beta z,z)   where    N   (  x  |  μ  ,  v  )      fragments  N   fragments  normal-(  x  normal-|  μ  normal-,  v  normal-)     N(x|\mu,v)   is the normal distribution, with mean   μ   μ   \mu   and variance   v   v   v   . Then the posterior for   z   z   z   , given the data is also GIG:      P   (  z  |  X  ,  a  ,  b  ,  p  ,  α  ,  β  )   =  GIG   (  z  |  p  -    T  2    ,  a  +  T   β  2   ,  b  +  S  )      fragments  P   fragments  normal-(  z  normal-|  X  normal-,  a  normal-,  b  normal-,  p  normal-,  α  normal-,  β  normal-)    GIG   fragments  normal-(  z  normal-|  p     T  2   normal-,  a   T   superscript  β  2   normal-,  b   S  normal-)     P(z|X,a,b,p,\alpha,\beta)=\text{GIG}(z|p-\tfrac{T}{2},a+T\beta^{2},b+S)   where    S  =    ∑   i  =  1   T     (    x  i   -  α   )   2        S    superscript   subscript     i  1    T    superscript     subscript  x  i   α   2      \textstyle S=\sum_{i=1}^{T}(x_{i}-\alpha)^{2}   . Due to the conjugacy, these details can be derived without solving integrals, by noting that      P   (  z  |  X  ,  a  ,  b  ,  p  ,  α  ,  β  )   ∝  P   (  z  |  a  ,  b  ,  p  )   P   (  X  |  z  ,  α  ,  β  )      fragments  P   fragments  normal-(  z  normal-|  X  normal-,  a  normal-,  b  normal-,  p  normal-,  α  normal-,  β  normal-)   proportional-to  P   fragments  normal-(  z  normal-|  a  normal-,  b  normal-,  p  normal-)   P   fragments  normal-(  X  normal-|  z  normal-,  α  normal-,  β  normal-)     P(z|X,a,b,p,\alpha,\beta)\propto P(z|a,b,p)P(X|z,\alpha,\beta)   . Omitting all factors independent of   z   z   z   , the right-hand-side can be simplified to give an un-normalized GIG distribution, from which the posterior parameters can be identified.  Notes  References  See also   Inverse Gaussian distribution  Gamma distribution   "  Category:Continuous distributions  Category:Exponential family distributions  Category:Probability distributions     ↩  ↩  Étienne Halphen was the uncle of the mathematician Georges Henri Halphen . ↩  Sichel, H.S., Statistical valuation of diamondiferous deposits, Journal of the South African Institute of Mining and Metallurgy 1973 ↩  ↩  O. Barndorff-Nielsen and Christian Halgreen, Infinite Divisibility of the Hyperbolic and Generalized Inverse Gaussian Distributions, Zeitschrift für Wahrscheinlichkeitstheorie und verwandte Gebiete 1977 ↩    Dimitris Karlis, "An EM type algorithm for maximum likelihood estimation of the normal–inverse Gaussian distribution", Statistics & Probability Letters 57 (2002) 43–52. ↩  Barndorf-Nielsen, O.E., 1997. Normal Inverse Gaussian Distributions and stochastic volatility modelling . Scand. J. Statist. 24, 1–13. ↩     