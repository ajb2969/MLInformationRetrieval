<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="1468">Matrix regularization</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>Matrix regularization</h1>
<hr/>

<p>In the field of <a href="statistical_learning_theory" title="wikilink">statistical learning theory</a>, <strong>matrix regularization</strong> generalizes notions of vector regularization to cases where the object to be learned is a matrix. The purpose of regularization is to enforce conditions, for example sparsity or smoothness, that can produce stable predictive functions. For example, in the more common vector framework, <a href="Tikhonov_regularization" title="wikilink">Tikhonov regularization</a> optimizes over</p>

<p>

<math display="block" id="Matrix_regularization:0">
 <semantics>
  <mrow>
   <mrow>
    <munder>
     <mi>min</mi>
     <mi>x</mi>
    </munder>
    <msup>
     <mrow>
      <mo>∥</mo>
      <mrow>
       <mrow>
        <mi>A</mi>
        <mi>x</mi>
       </mrow>
       <mo>-</mo>
       <mi>y</mi>
      </mrow>
      <mo>∥</mo>
     </mrow>
     <mn>2</mn>
    </msup>
   </mrow>
   <mo>+</mo>
   <mrow>
    <mi>λ</mi>
    <msup>
     <mrow>
      <mo>∥</mo>
      <mi>x</mi>
      <mo>∥</mo>
     </mrow>
     <mn>2</mn>
    </msup>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <plus></plus>
    <apply>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <min></min>
      <ci>x</ci>
     </apply>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <apply>
       <csymbol cd="latexml">norm</csymbol>
       <apply>
        <minus></minus>
        <apply>
         <times></times>
         <ci>A</ci>
         <ci>x</ci>
        </apply>
        <ci>y</ci>
       </apply>
      </apply>
      <cn type="integer">2</cn>
     </apply>
    </apply>
    <apply>
     <times></times>
     <ci>λ</ci>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <apply>
       <csymbol cd="latexml">norm</csymbol>
       <ci>x</ci>
      </apply>
      <cn type="integer">2</cn>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \min_{x}\|Ax-y\|^{2}+\lambda\|x\|^{2}
  </annotation>
 </semantics>
</math>

</p>

<p>to find a vector, 

<math display="inline" id="Matrix_regularization:1">
 <semantics>
  <mi>x</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>x</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   x
  </annotation>
 </semantics>
</math>

, that is a stable solution to the regression problem. When the system is described by a matrix rather than a vector, this problem can be written as</p>

<p>

<math display="block" id="Matrix_regularization:2">
 <semantics>
  <mrow>
   <mrow>
    <munder>
     <mi>min</mi>
     <mi>X</mi>
    </munder>
    <msup>
     <mrow>
      <mo>∥</mo>
      <mrow>
       <mrow>
        <mi>A</mi>
        <mi>X</mi>
       </mrow>
       <mo>-</mo>
       <mi>Y</mi>
      </mrow>
      <mo>∥</mo>
     </mrow>
     <mn>2</mn>
    </msup>
   </mrow>
   <mo>+</mo>
   <mrow>
    <mi>λ</mi>
    <msup>
     <mrow>
      <mo>∥</mo>
      <mi>X</mi>
      <mo>∥</mo>
     </mrow>
     <mn>2</mn>
    </msup>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <plus></plus>
    <apply>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <min></min>
      <ci>X</ci>
     </apply>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <apply>
       <csymbol cd="latexml">norm</csymbol>
       <apply>
        <minus></minus>
        <apply>
         <times></times>
         <ci>A</ci>
         <ci>X</ci>
        </apply>
        <ci>Y</ci>
       </apply>
      </apply>
      <cn type="integer">2</cn>
     </apply>
    </apply>
    <apply>
     <times></times>
     <ci>λ</ci>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <apply>
       <csymbol cd="latexml">norm</csymbol>
       <ci>X</ci>
      </apply>
      <cn type="integer">2</cn>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \min_{X}\|AX-Y\|^{2}+\lambda\|X\|^{2}
  </annotation>
 </semantics>
</math>

</p>

<p>where the vector norm enforcing a regularization penalty on 

<math display="inline" id="Matrix_regularization:3">
 <semantics>
  <mi>x</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>x</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   x
  </annotation>
 </semantics>
</math>

 has been extended to a matrix norm on 

<math display="inline" id="Matrix_regularization:4">
 <semantics>
  <mi>X</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>X</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   X
  </annotation>
 </semantics>
</math>

.</p>

<p>Matrix Regularization has applications in <a href="matrix_completion" title="wikilink">matrix completion</a>, <a href="multivariate_regression" title="wikilink">multivariate regression</a>, and multi-task learning. Ideas of feature and group selection can also be extended to matrices, and these can be generalized to the nonparametric case of <a href="multiple_kernel_learning" title="wikilink">multiple kernel learning</a>.</p>
<h2 id="basic-definition">Basic definition</h2>

<p>Consider a matrix 

<math display="inline" id="Matrix_regularization:5">
 <semantics>
  <mi>W</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>W</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   W
  </annotation>
 </semantics>
</math>

 to be learned from a set of examples, 

<math display="inline" id="Matrix_regularization:6">
 <semantics>
  <mrow>
   <mi>S</mi>
   <mo>=</mo>
   <mrow>
    <mo stretchy="false">(</mo>
    <msubsup>
     <mi>X</mi>
     <mi>i</mi>
     <mi>t</mi>
    </msubsup>
    <mo>,</mo>
    <msubsup>
     <mi>y</mi>
     <mi>i</mi>
     <mi>t</mi>
    </msubsup>
    <mo stretchy="false">)</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <ci>S</ci>
    <interval closure="open">
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>X</ci>
       <ci>i</ci>
      </apply>
      <ci>t</ci>
     </apply>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>y</ci>
       <ci>i</ci>
      </apply>
      <ci>t</ci>
     </apply>
    </interval>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   S=(X_{i}^{t},y_{i}^{t})
  </annotation>
 </semantics>
</math>

, where 

<math display="inline" id="Matrix_regularization:7">
 <semantics>
  <mi>i</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>i</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   i
  </annotation>
 </semantics>
</math>

 goes from 

<math display="inline" id="Matrix_regularization:8">
 <semantics>
  <mn>1</mn>
  <annotation-xml encoding="MathML-Content">
   <cn type="integer">1</cn>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   1
  </annotation>
 </semantics>
</math>

 to 

<math display="inline" id="Matrix_regularization:9">
 <semantics>
  <mi>n</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>n</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   n
  </annotation>
 </semantics>
</math>

, and 

<math display="inline" id="Matrix_regularization:10">
 <semantics>
  <mi>t</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>t</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   t
  </annotation>
 </semantics>
</math>

 goes from 

<math display="inline" id="Matrix_regularization:11">
 <semantics>
  <mn>1</mn>
  <annotation-xml encoding="MathML-Content">
   <cn type="integer">1</cn>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   1
  </annotation>
 </semantics>
</math>

 to 

<math display="inline" id="Matrix_regularization:12">
 <semantics>
  <mi>T</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>T</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   T
  </annotation>
 </semantics>
</math>

. Let each input matrix 

<math display="inline" id="Matrix_regularization:13">
 <semantics>
  <msub>
   <mi>X</mi>
   <mi>i</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>X</ci>
    <ci>i</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   X_{i}
  </annotation>
 </semantics>
</math>

 be 

<math display="inline" id="Matrix_regularization:14">
 <semantics>
  <mrow>
   <mi></mi>
   <mo>∈</mo>
   <msup>
    <mi>ℝ</mi>
    <mrow>
     <mi>D</mi>
     <mi>T</mi>
    </mrow>
   </msup>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <in></in>
    <csymbol cd="latexml">absent</csymbol>
    <apply>
     <csymbol cd="ambiguous">superscript</csymbol>
     <ci>ℝ</ci>
     <apply>
      <times></times>
      <ci>D</ci>
      <ci>T</ci>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \in\mathbb{R}^{DT}
  </annotation>
 </semantics>
</math>

, and let 

<math display="inline" id="Matrix_regularization:15">
 <semantics>
  <mi>W</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>W</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   W
  </annotation>
 </semantics>
</math>

 be of size 

<math display="inline" id="Matrix_regularization:16">
 <semantics>
  <mrow>
   <mi>D</mi>
   <mo>×</mo>
   <mi>T</mi>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <ci>D</ci>
    <ci>T</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   D\times T
  </annotation>
 </semantics>
</math>

. A general model for the output 

<math display="inline" id="Matrix_regularization:17">
 <semantics>
  <mi>y</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>y</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   y
  </annotation>
 </semantics>
</math>

 can be posed as</p>

<p>

<math display="block" id="Matrix_regularization:18">
 <semantics>
  <mrow>
   <msubsup>
    <mi>y</mi>
    <mi>i</mi>
    <mi>t</mi>
   </msubsup>
   <mo>=</mo>
   <msub>
    <mrow>
     <mo stretchy="false">⟨</mo>
     <mi>W</mi>
     <mo>,</mo>
     <msubsup>
      <mi>X</mi>
      <mi>i</mi>
      <mi>t</mi>
     </msubsup>
     <mo stretchy="false">⟩</mo>
    </mrow>
    <mi>F</mi>
   </msub>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <csymbol cd="ambiguous">superscript</csymbol>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>y</ci>
      <ci>i</ci>
     </apply>
     <ci>t</ci>
    </apply>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <list>
      <ci>W</ci>
      <apply>
       <csymbol cd="ambiguous">superscript</csymbol>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <ci>X</ci>
        <ci>i</ci>
       </apply>
       <ci>t</ci>
      </apply>
     </list>
     <ci>F</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   y_{i}^{t}=\langle W,X_{i}^{t}\rangle_{F}
  </annotation>
 </semantics>
</math>

</p>

<p>where the inner product is the <a href="Frobenius_inner_product" title="wikilink">Frobenius inner product</a>. For different applications the matrices 

<math display="inline" id="Matrix_regularization:19">
 <semantics>
  <msub>
   <mi>X</mi>
   <mi>i</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>X</ci>
    <ci>i</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   X_{i}
  </annotation>
 </semantics>
</math>

 will have different forms,<a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a> but for each of these the optimization problem to infer 

<math display="inline" id="Matrix_regularization:20">
 <semantics>
  <mi>W</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>W</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   W
  </annotation>
 </semantics>
</math>

 can be written as</p>

<p>

<math display="block" id="Matrix_regularization:21">
 <semantics>
  <mrow>
   <mrow>
    <mrow>
     <munder>
      <mi>min</mi>
      <mrow>
       <mi>W</mi>
       <mo>∈</mo>
       <mi class="ltx_font_mathcaligraphic">ℋ</mi>
      </mrow>
     </munder>
     <mi>E</mi>
    </mrow>
    <mrow>
     <mo stretchy="false">(</mo>
     <mi>W</mi>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
   <mo>+</mo>
   <mrow>
    <mi>R</mi>
    <mrow>
     <mo stretchy="false">(</mo>
     <mi>W</mi>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <plus></plus>
    <apply>
     <times></times>
     <apply>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <min></min>
       <apply>
        <in></in>
        <ci>W</ci>
        <ci>ℋ</ci>
       </apply>
      </apply>
      <ci>E</ci>
     </apply>
     <ci>W</ci>
    </apply>
    <apply>
     <times></times>
     <ci>R</ci>
     <ci>W</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \min_{W\in\mathcal{H}}E(W)+R(W)
  </annotation>
 </semantics>
</math>

</p>

<p>where 

<math display="inline" id="Matrix_regularization:22">
 <semantics>
  <mi>E</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>E</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   E
  </annotation>
 </semantics>
</math>

 defines the empirical error for a given 

<math display="inline" id="Matrix_regularization:23">
 <semantics>
  <mi>W</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>W</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   W
  </annotation>
 </semantics>
</math>

, and 

<math display="inline" id="Matrix_regularization:24">
 <semantics>
  <mrow>
   <mi>R</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <mi>W</mi>
    <mo stretchy="false">)</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <ci>R</ci>
    <ci>W</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   R(W)
  </annotation>
 </semantics>
</math>

 is a matrix regularization penalty. The function 

<math display="inline" id="Matrix_regularization:25">
 <semantics>
  <mrow>
   <mi>R</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <mi>W</mi>
    <mo stretchy="false">)</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <ci>R</ci>
    <ci>W</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   R(W)
  </annotation>
 </semantics>
</math>

 is typically chosen to be convex, and is often selected to enforce sparsity (using 

<math display="inline" id="Matrix_regularization:26">
 <semantics>
  <msup>
   <mi mathvariant="normal">ℓ</mi>
   <mn>1</mn>
  </msup>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">superscript</csymbol>
    <ci>normal-ℓ</ci>
    <cn type="integer">1</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \ell^{1}
  </annotation>
 </semantics>
</math>

-norms) and/or smoothness (using 

<math display="inline" id="Matrix_regularization:27">
 <semantics>
  <msup>
   <mi mathvariant="normal">ℓ</mi>
   <mn>2</mn>
  </msup>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">superscript</csymbol>
    <ci>normal-ℓ</ci>
    <cn type="integer">2</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \ell^{2}
  </annotation>
 </semantics>
</math>

-norms). Finally, 

<math display="inline" id="Matrix_regularization:28">
 <semantics>
  <mi>W</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>W</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   W
  </annotation>
 </semantics>
</math>

 is in the space of matrices, 

<math display="inline" id="Matrix_regularization:29">
 <semantics>
  <mi class="ltx_font_mathcaligraphic">ℋ</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>ℋ</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \mathcal{H}
  </annotation>
 </semantics>
</math>

, with Forbenius inner product,.</p>
<h2 id="general-applications">General applications</h2>
<h3 id="matrix-completion">Matrix completion</h3>

<p>In the problem of <a href="matrix_completion" title="wikilink">matrix completion</a>, the matrix 

<math display="inline" id="Matrix_regularization:30">
 <semantics>
  <msubsup>
   <mi>X</mi>
   <mi>i</mi>
   <mi>t</mi>
  </msubsup>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">superscript</csymbol>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>X</ci>
     <ci>i</ci>
    </apply>
    <ci>t</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   X_{i}^{t}
  </annotation>
 </semantics>
</math>

 takes the form</p>

<p>

<math display="block" id="Matrix_regularization:31">
 <semantics>
  <mrow>
   <msubsup>
    <mi>X</mi>
    <mi>i</mi>
    <mi>t</mi>
   </msubsup>
   <mo>=</mo>
   <mrow>
    <msub>
     <mi>e</mi>
     <mi>t</mi>
    </msub>
    <mo>⊗</mo>
    <msubsup>
     <mi>e</mi>
     <mi>i</mi>
     <mo>′</mo>
    </msubsup>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <csymbol cd="ambiguous">superscript</csymbol>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>X</ci>
      <ci>i</ci>
     </apply>
     <ci>t</ci>
    </apply>
    <apply>
     <csymbol cd="latexml">tensor-product</csymbol>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>e</ci>
      <ci>t</ci>
     </apply>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>e</ci>
       <ci>i</ci>
      </apply>
      <ci>normal-′</ci>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   X_{i}^{t}=e_{t}\otimes e_{i}^{\prime}
  </annotation>
 </semantics>
</math>

</p>

<p>where 

<math display="inline" id="Matrix_regularization:32">
 <semantics>
  <msub>
   <mrow>
    <mo stretchy="false">(</mo>
    <msub>
     <mi>e</mi>
     <mi>t</mi>
    </msub>
    <mo stretchy="false">)</mo>
   </mrow>
   <mi>t</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>e</ci>
     <ci>t</ci>
    </apply>
    <ci>t</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   (e_{t})_{t}
  </annotation>
 </semantics>
</math>

 and 

<math display="inline" id="Matrix_regularization:33">
 <semantics>
  <msub>
   <mrow>
    <mo stretchy="false">(</mo>
    <msubsup>
     <mi>e</mi>
     <mi>i</mi>
     <mo>′</mo>
    </msubsup>
    <mo stretchy="false">)</mo>
   </mrow>
   <mi>i</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <apply>
     <csymbol cd="ambiguous">superscript</csymbol>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>e</ci>
      <ci>i</ci>
     </apply>
     <ci>normal-′</ci>
    </apply>
    <ci>i</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   (e_{i}^{\prime})_{i}
  </annotation>
 </semantics>
</math>

 are the canonical basis in 

<math display="inline" id="Matrix_regularization:34">
 <semantics>
  <msup>
   <mi>ℝ</mi>
   <mi>T</mi>
  </msup>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">superscript</csymbol>
    <ci>ℝ</ci>
    <ci>T</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \mathbb{R}^{T}
  </annotation>
 </semantics>
</math>

 and 

<math display="inline" id="Matrix_regularization:35">
 <semantics>
  <msup>
   <mi>ℝ</mi>
   <mi>D</mi>
  </msup>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">superscript</csymbol>
    <ci>ℝ</ci>
    <ci>D</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \mathbb{R}^{D}
  </annotation>
 </semantics>
</math>

. In this case the role of the Frobenius inner product is to select individual elements, 

<math display="inline" id="Matrix_regularization:36">
 <semantics>
  <msubsup>
   <mi>w</mi>
   <mi>i</mi>
   <mi>t</mi>
  </msubsup>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">superscript</csymbol>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>w</ci>
     <ci>i</ci>
    </apply>
    <ci>t</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   w_{i}^{t}
  </annotation>
 </semantics>
</math>

, from the matrix 

<math display="inline" id="Matrix_regularization:37">
 <semantics>
  <mi>W</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>W</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   W
  </annotation>
 </semantics>
</math>

. Thus, the output, 

<math display="inline" id="Matrix_regularization:38">
 <semantics>
  <mi>y</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>y</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   y
  </annotation>
 </semantics>
</math>

, is a sampling of entries from the matrix 

<math display="inline" id="Matrix_regularization:39">
 <semantics>
  <mi>W</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>W</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   W
  </annotation>
 </semantics>
</math>

.</p>

<p>The problem of reconstructing 

<math display="inline" id="Matrix_regularization:40">
 <semantics>
  <mi>W</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>W</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   W
  </annotation>
 </semantics>
</math>

 from a small set of sampled entries is possible only under certain restrictions on the matrix, and these restrictions can be enforced by a regularization function. For example, it might be assumed that 

<math display="inline" id="Matrix_regularization:41">
 <semantics>
  <mi>W</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>W</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   W
  </annotation>
 </semantics>
</math>

 is low-rank, in which case the regularization penalty can take the form of a nuclear norm.<a class="footnoteRef" href="#fn2" id="fnref2"><sup>2</sup></a></p>

<p>

<math display="block" id="Matrix_regularization:42">
 <semantics>
  <mrow>
   <mrow>
    <mi>R</mi>
    <mrow>
     <mo stretchy="false">(</mo>
     <mi>W</mi>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
   <mo>=</mo>
   <mrow>
    <mi>λ</mi>
    <msub>
     <mrow>
      <mo>∥</mo>
      <mi>W</mi>
      <mo>∥</mo>
     </mrow>
     <mo>*</mo>
    </msub>
   </mrow>
   <mo>=</mo>
   <mrow>
    <mi>λ</mi>
    <mrow>
     <mo largeop="true" movablelimits="false" symmetric="true">∑</mo>
     <mrow>
      <mo stretchy="false">|</mo>
      <msub>
       <mi>σ</mi>
       <mi>i</mi>
      </msub>
      <mo stretchy="false">|</mo>
     </mrow>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <and></and>
    <apply>
     <eq></eq>
     <apply>
      <times></times>
      <ci>R</ci>
      <ci>W</ci>
     </apply>
     <apply>
      <times></times>
      <ci>λ</ci>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <apply>
        <csymbol cd="latexml">norm</csymbol>
        <ci>W</ci>
       </apply>
       <times></times>
      </apply>
     </apply>
    </apply>
    <apply>
     <eq></eq>
     <share href="#.cmml">
     </share>
     <apply>
      <times></times>
      <ci>λ</ci>
      <apply>
       <sum></sum>
       <apply>
        <abs></abs>
        <apply>
         <csymbol cd="ambiguous">subscript</csymbol>
         <ci>σ</ci>
         <ci>i</ci>
        </apply>
       </apply>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   R(W)=\lambda\|W\|_{*}=\lambda\sum|\sigma_{i}|
  </annotation>
 </semantics>
</math>

</p>

<p>where 

<math display="inline" id="Matrix_regularization:43">
 <semantics>
  <msub>
   <mi>σ</mi>
   <mi>i</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>σ</ci>
    <ci>i</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \sigma_{i}
  </annotation>
 </semantics>
</math>

, with 

<math display="inline" id="Matrix_regularization:44">
 <semantics>
  <mi>i</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>i</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   i
  </annotation>
 </semantics>
</math>

 from 

<math display="inline" id="Matrix_regularization:45">
 <semantics>
  <mn>1</mn>
  <annotation-xml encoding="MathML-Content">
   <cn type="integer">1</cn>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   1
  </annotation>
 </semantics>
</math>

 to 

<math display="inline" id="Matrix_regularization:46">
 <semantics>
  <mrow>
   <mrow>
    <mi>min</mi>
    <mi>D</mi>
   </mrow>
   <mo>,</mo>
   <mi>T</mi>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <list>
    <apply>
     <min></min>
     <ci>D</ci>
    </apply>
    <ci>T</ci>
   </list>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \min D,T
  </annotation>
 </semantics>
</math>

, are the singular values of 

<math display="inline" id="Matrix_regularization:47">
 <semantics>
  <mi>W</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>W</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   W
  </annotation>
 </semantics>
</math>

.</p>
<h3 id="multivariate-regression">Multivariate regression</h3>

<p>Models used in <a href="multivariate_regression" title="wikilink">multivariate regression</a> are parameterized by a matrix of coefficients. In the Frobenius inner product above, each matrix 

<math display="inline" id="Matrix_regularization:48">
 <semantics>
  <mi>X</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>X</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   X
  </annotation>
 </semantics>
</math>

 is</p>

<p>

<math display="block" id="Matrix_regularization:49">
 <semantics>
  <mrow>
   <msubsup>
    <mi>X</mi>
    <mi>i</mi>
    <mi>t</mi>
   </msubsup>
   <mo>=</mo>
   <mrow>
    <msub>
     <mi>e</mi>
     <mi>t</mi>
    </msub>
    <mo>⊗</mo>
    <mpadded width="+1.7pt">
     <msub>
      <mi>x</mi>
      <mi>i</mi>
     </msub>
    </mpadded>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <csymbol cd="ambiguous">superscript</csymbol>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>X</ci>
      <ci>i</ci>
     </apply>
     <ci>t</ci>
    </apply>
    <apply>
     <csymbol cd="latexml">tensor-product</csymbol>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>e</ci>
      <ci>t</ci>
     </apply>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>x</ci>
      <ci>i</ci>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   X_{i}^{t}=e_{t}\otimes x_{i}\,
  </annotation>
 </semantics>
</math>

</p>

<p>such that the output of the inner product is the dot product of one row of the input with one column of the coefficient matrix. The familiar form of such models is</p>

<p>

<math display="block" id="Matrix_regularization:50">
 <semantics>
  <mrow>
   <mi>Y</mi>
   <mo>=</mo>
   <mrow>
    <mrow>
     <mi>X</mi>
     <mi>W</mi>
    </mrow>
    <mo>+</mo>
    <mpadded width="+1.7pt">
     <mi>b</mi>
    </mpadded>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <ci>Y</ci>
    <apply>
     <plus></plus>
     <apply>
      <times></times>
      <ci>X</ci>
      <ci>W</ci>
     </apply>
     <ci>b</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   Y=XW+b\,
  </annotation>
 </semantics>
</math>

</p>

<p>Many of the vector norms used in single variable regression can be extended to the multivariate case. One example is the squared Frobenius norm, which can be viewed as an 

<math display="inline" id="Matrix_regularization:51">
 <semantics>
  <msup>
   <mi mathvariant="normal">ℓ</mi>
   <mn>2</mn>
  </msup>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">superscript</csymbol>
    <ci>normal-ℓ</ci>
    <cn type="integer">2</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \ell^{2}
  </annotation>
 </semantics>
</math>

-norm acting either entrywise, or on the singular values of the matrix:</p>

<p>

<math display="block" id="Matrix_regularization:52">
 <semantics>
  <mrow>
   <mrow>
    <mrow>
     <mi>R</mi>
     <mrow>
      <mo stretchy="false">(</mo>
      <mi>W</mi>
      <mo stretchy="false">)</mo>
     </mrow>
    </mrow>
    <mo>=</mo>
    <mrow>
     <mi>λ</mi>
     <msubsup>
      <mrow>
       <mo>∥</mo>
       <mi>W</mi>
       <mo>∥</mo>
      </mrow>
      <mi>F</mi>
      <mn>2</mn>
     </msubsup>
    </mrow>
    <mo>=</mo>
    <mrow>
     <mi>λ</mi>
     <mrow>
      <mo largeop="true" movablelimits="false" symmetric="true">∑</mo>
      <mrow>
       <mo largeop="true" movablelimits="false" symmetric="true">∑</mo>
       <msup>
        <mrow>
         <mo stretchy="false">|</mo>
         <msub>
          <mi>w</mi>
          <mrow>
           <mi>i</mi>
           <mi>j</mi>
          </mrow>
         </msub>
         <mo stretchy="false">|</mo>
        </mrow>
        <mn>2</mn>
       </msup>
      </mrow>
     </mrow>
    </mrow>
    <mo>=</mo>
    <mrow>
     <mi>λ</mi>
     <mrow>
      <mo>Tr</mo>
      <mrow>
       <mo stretchy="false">(</mo>
       <mrow>
        <msup>
         <mi>W</mi>
         <mo>*</mo>
        </msup>
        <mi>W</mi>
       </mrow>
       <mo stretchy="false">)</mo>
      </mrow>
     </mrow>
    </mrow>
    <mo>=</mo>
    <mrow>
     <mi>λ</mi>
     <mrow>
      <mo largeop="true" movablelimits="false" symmetric="true">∑</mo>
      <msubsup>
       <mi>σ</mi>
       <mi>i</mi>
       <mn>2</mn>
      </msubsup>
     </mrow>
    </mrow>
   </mrow>
   <mo>.</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <and></and>
    <apply>
     <eq></eq>
     <apply>
      <times></times>
      <ci>R</ci>
      <ci>W</ci>
     </apply>
     <apply>
      <times></times>
      <ci>λ</ci>
      <apply>
       <csymbol cd="ambiguous">superscript</csymbol>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <apply>
         <csymbol cd="latexml">norm</csymbol>
         <ci>W</ci>
        </apply>
        <ci>F</ci>
       </apply>
       <cn type="integer">2</cn>
      </apply>
     </apply>
    </apply>
    <apply>
     <eq></eq>
     <share href="#.cmml">
     </share>
     <apply>
      <times></times>
      <ci>λ</ci>
      <apply>
       <sum></sum>
       <apply>
        <sum></sum>
        <apply>
         <csymbol cd="ambiguous">superscript</csymbol>
         <apply>
          <abs></abs>
          <apply>
           <csymbol cd="ambiguous">subscript</csymbol>
           <ci>w</ci>
           <apply>
            <times></times>
            <ci>i</ci>
            <ci>j</ci>
           </apply>
          </apply>
         </apply>
         <cn type="integer">2</cn>
        </apply>
       </apply>
      </apply>
     </apply>
    </apply>
    <apply>
     <eq></eq>
     <share href="#.cmml">
     </share>
     <apply>
      <times></times>
      <ci>λ</ci>
      <apply>
       <ci>Tr</ci>
       <apply>
        <times></times>
        <apply>
         <csymbol cd="ambiguous">superscript</csymbol>
         <ci>W</ci>
         <times></times>
        </apply>
        <ci>W</ci>
       </apply>
      </apply>
     </apply>
    </apply>
    <apply>
     <eq></eq>
     <share href="#.cmml">
     </share>
     <apply>
      <times></times>
      <ci>λ</ci>
      <apply>
       <sum></sum>
       <apply>
        <csymbol cd="ambiguous">superscript</csymbol>
        <apply>
         <csymbol cd="ambiguous">subscript</csymbol>
         <ci>σ</ci>
         <ci>i</ci>
        </apply>
        <cn type="integer">2</cn>
       </apply>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   R(W)=\lambda\|W\|_{F}^{2}=\lambda\sum\sum|w_{ij}|^{2}=\lambda\operatorname{Tr}%
(W^{*}W)=\lambda\sum\sigma_{i}^{2}.
  </annotation>
 </semantics>
</math>

</p>

<p>In the multivariate case the effect of regularizing with the Frobenius norm is the same as the vector case; very complex models will have larger norms, and, thus, will be penalized more.</p>
<h3 id="multi-task-learning">Multi-task learning</h3>

<p>The setup for multi-task learning is almost the same as the setup for multivariate regression. The primary difference is that the input variables are also indexed by task (columns of 

<math display="inline" id="Matrix_regularization:53">
 <semantics>
  <mi>Y</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>Y</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   Y
  </annotation>
 </semantics>
</math>

). The representation with the Frobenius inner product is then</p>

<p>

<math display="block" id="Matrix_regularization:54">
 <semantics>
  <mrow>
   <mrow>
    <msubsup>
     <mi>X</mi>
     <mi>i</mi>
     <mi>t</mi>
    </msubsup>
    <mo>=</mo>
    <mrow>
     <msub>
      <mi>e</mi>
      <mi>t</mi>
     </msub>
     <mo>⊗</mo>
     <msubsup>
      <mi>x</mi>
      <mi>i</mi>
      <mi>t</mi>
     </msubsup>
    </mrow>
   </mrow>
   <mo>.</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <csymbol cd="ambiguous">superscript</csymbol>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>X</ci>
      <ci>i</ci>
     </apply>
     <ci>t</ci>
    </apply>
    <apply>
     <csymbol cd="latexml">tensor-product</csymbol>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>e</ci>
      <ci>t</ci>
     </apply>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>x</ci>
       <ci>i</ci>
      </apply>
      <ci>t</ci>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   X_{i}^{t}=e_{t}\otimes x_{i}^{t}.
  </annotation>
 </semantics>
</math>

</p>

<p>The role of matrix regularization in this setting can be the same as in multivariate regression, but matrix norms can also be used to couple learning problems across tasks. In particular, note that for the optimization problem</p>

<p>

<math display="block" id="Matrix_regularization:55">
 <semantics>
  <mrow>
   <mrow>
    <munder>
     <mi>min</mi>
     <mi>W</mi>
    </munder>
    <msubsup>
     <mrow>
      <mo>∥</mo>
      <mrow>
       <mrow>
        <mi>X</mi>
        <mi>W</mi>
       </mrow>
       <mo>-</mo>
       <mi>Y</mi>
      </mrow>
      <mo>∥</mo>
     </mrow>
     <mn>2</mn>
     <mn>2</mn>
    </msubsup>
   </mrow>
   <mo>+</mo>
   <mrow>
    <mi>λ</mi>
    <msubsup>
     <mrow>
      <mo>∥</mo>
      <mi>W</mi>
      <mo>∥</mo>
     </mrow>
     <mn>2</mn>
     <mn>2</mn>
    </msubsup>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <plus></plus>
    <apply>
     <times></times>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <min></min>
      <ci>W</ci>
     </apply>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <apply>
        <csymbol cd="latexml">norm</csymbol>
        <apply>
         <minus></minus>
         <apply>
          <times></times>
          <ci>X</ci>
          <ci>W</ci>
         </apply>
         <ci>Y</ci>
        </apply>
       </apply>
       <cn type="integer">2</cn>
      </apply>
      <cn type="integer">2</cn>
     </apply>
    </apply>
    <apply>
     <times></times>
     <ci>λ</ci>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <apply>
        <csymbol cd="latexml">norm</csymbol>
        <ci>W</ci>
       </apply>
       <cn type="integer">2</cn>
      </apply>
      <cn type="integer">2</cn>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \min_{W}\|XW-Y\|_{2}^{2}+\lambda\|W\|_{2}^{2}
  </annotation>
 </semantics>
</math>

</p>

<p>the solutions corresponding to each column of 

<math display="inline" id="Matrix_regularization:56">
 <semantics>
  <mi>Y</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>Y</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   Y
  </annotation>
 </semantics>
</math>

 are decoupled. That is, the same solution can be found by solving the joint problem, or by solving an isolated regression problem for each column. The problems can be coupled by adding an additional regulatization penalty on the covariance of solutions</p>

<p>

<math display="block" id="Matrix_regularization:57">
 <semantics>
  <mrow>
   <mrow>
    <munder>
     <mi>min</mi>
     <mrow>
      <mi>W</mi>
      <mo>,</mo>
      <mi mathvariant="normal">Ω</mi>
     </mrow>
    </munder>
    <msubsup>
     <mrow>
      <mo>∥</mo>
      <mrow>
       <mrow>
        <mi>X</mi>
        <mi>W</mi>
       </mrow>
       <mo>-</mo>
       <mi>Y</mi>
      </mrow>
      <mo>∥</mo>
     </mrow>
     <mn>2</mn>
     <mn>2</mn>
    </msubsup>
   </mrow>
   <mo>+</mo>
   <mrow>
    <msub>
     <mi>λ</mi>
     <mn>1</mn>
    </msub>
    <msubsup>
     <mrow>
      <mo>∥</mo>
      <mi>W</mi>
      <mo>∥</mo>
     </mrow>
     <mn>2</mn>
     <mn>2</mn>
    </msubsup>
   </mrow>
   <mo>+</mo>
   <mrow>
    <msub>
     <mi>λ</mi>
     <mn>2</mn>
    </msub>
    <mrow>
     <mo>Tr</mo>
     <mrow>
      <mo stretchy="false">(</mo>
      <mrow>
       <msup>
        <mi>W</mi>
        <mi>T</mi>
       </msup>
       <msup>
        <mi mathvariant="normal">Ω</mi>
        <mrow>
         <mo>-</mo>
         <mn>1</mn>
        </mrow>
       </msup>
       <mi>W</mi>
      </mrow>
      <mo stretchy="false">)</mo>
     </mrow>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <plus></plus>
    <apply>
     <times></times>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <min></min>
      <list>
       <ci>W</ci>
       <ci>normal-Ω</ci>
      </list>
     </apply>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <apply>
        <csymbol cd="latexml">norm</csymbol>
        <apply>
         <minus></minus>
         <apply>
          <times></times>
          <ci>X</ci>
          <ci>W</ci>
         </apply>
         <ci>Y</ci>
        </apply>
       </apply>
       <cn type="integer">2</cn>
      </apply>
      <cn type="integer">2</cn>
     </apply>
    </apply>
    <apply>
     <times></times>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>λ</ci>
      <cn type="integer">1</cn>
     </apply>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <apply>
        <csymbol cd="latexml">norm</csymbol>
        <ci>W</ci>
       </apply>
       <cn type="integer">2</cn>
      </apply>
      <cn type="integer">2</cn>
     </apply>
    </apply>
    <apply>
     <times></times>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>λ</ci>
      <cn type="integer">2</cn>
     </apply>
     <apply>
      <ci>Tr</ci>
      <apply>
       <times></times>
       <apply>
        <csymbol cd="ambiguous">superscript</csymbol>
        <ci>W</ci>
        <ci>T</ci>
       </apply>
       <apply>
        <csymbol cd="ambiguous">superscript</csymbol>
        <ci>normal-Ω</ci>
        <apply>
         <minus></minus>
         <cn type="integer">1</cn>
        </apply>
       </apply>
       <ci>W</ci>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \min_{W,\Omega}\|XW-Y\|_{2}^{2}+\lambda_{1}\|W\|_{2}^{2}+\lambda_{2}%
\operatorname{Tr}(W^{T}\Omega^{-1}W)
  </annotation>
 </semantics>
</math>

</p>

<p>where 

<math display="inline" id="Matrix_regularization:58">
 <semantics>
  <mi mathvariant="normal">Ω</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>normal-Ω</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \Omega
  </annotation>
 </semantics>
</math>

 models the relationship between tasks. This scheme can be used to both enforce similarity of solutions across tasks, and to learn the specific structure of task similarity by alternating between optimizations of 

<math display="inline" id="Matrix_regularization:59">
 <semantics>
  <mi>W</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>W</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   W
  </annotation>
 </semantics>
</math>

 and 

<math display="inline" id="Matrix_regularization:60">
 <semantics>
  <mi mathvariant="normal">Ω</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>normal-Ω</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \Omega
  </annotation>
 </semantics>
</math>

.<a class="footnoteRef" href="#fn3" id="fnref3"><sup>3</sup></a> When the relationship between tasks is known to lie on a graph, the <a href="Laplacian_matrix" title="wikilink">Laplacian matrix</a> of the graph can be used to couple the learning problems.</p>
<h2 id="spectral-regularization">Spectral regularization</h2>

<p><a href="Regularization_by_spectral_filtering" title="wikilink">Regularization by spectral filtering</a> has been used to find stable solutions to problems such as those discussed above by addressing ill-posed matrix inversions (see for example <a href="Regularization_by_spectral_filtering#Filter_function_for_Tikhonov_regularization" title="wikilink">Filter function for Tikhonov regularization</a>). In many cases the regularization function acts on the input (or kernel) to ensure a bounded inverse by eliminating small singular values, but it can also be useful to have spectral norms that act on the matrix that is to be learned.</p>

<p>There are a number of matrix norms that act on the singular values of the matrix. Frequently used examples include the <a href="Schatten_norm" title="wikilink">Schatten p-norms</a>, with <em>p</em> = 1 or 2. For example, matrix regularization with a Schatten 1-norm, also called the nuclear norm, can be used to enforce sparsity in the spectrum of a matrix. This has been used in the context of matrix completion when the matrix in question is believed to have a restricted rank.<a class="footnoteRef" href="#fn4" id="fnref4"><sup>4</sup></a> In this case the optimization problem becomes:</p>

<p>

<math display="block" id="Matrix_regularization:61">
 <semantics>
  <mrow>
   <mi>min</mi>
   <msub>
    <mrow>
     <mo>∥</mo>
     <mi>W</mi>
     <mo>∥</mo>
    </mrow>
    <mo>*</mo>
   </msub>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <min></min>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <apply>
      <csymbol cd="latexml">norm</csymbol>
      <ci>W</ci>
     </apply>
     <times></times>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \min\|W\|_{*}
  </annotation>
 </semantics>
</math>

 subject to 

<math display="inline" id="Matrix_regularization:62">
 <semantics>
  <mrow>
   <mrow>
    <msub>
     <mi>W</mi>
     <mrow>
      <mi>i</mi>
      <mo>,</mo>
      <mi>j</mi>
     </mrow>
    </msub>
    <mo>=</mo>
    <msub>
     <mi>Y</mi>
     <mrow>
      <mi>i</mi>
      <mi>j</mi>
     </mrow>
    </msub>
   </mrow>
   <mo>.</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>W</ci>
     <list>
      <ci>i</ci>
      <ci>j</ci>
     </list>
    </apply>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>Y</ci>
     <apply>
      <times></times>
      <ci>i</ci>
      <ci>j</ci>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   W_{i,j}=Y_{ij}.
  </annotation>
 </semantics>
</math>

</p>

<p>Spectral Regularization is also used to enforce a reduced rank coefficient matrix in multivariate regression.<a class="footnoteRef" href="#fn5" id="fnref5"><sup>5</sup></a> In this setting, a reduced rank coefficient matrix can be found by keeping just the top 

<math display="inline" id="Matrix_regularization:63">
 <semantics>
  <mi>n</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>n</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   n
  </annotation>
 </semantics>
</math>

 singular values, but this can be extended to keep any reduced set of singular values and vectors.</p>
<h2 id="structured-sparsity">Structured sparsity</h2>

<p>Sparse optimization has become the focus of much research interest as a way to find solutions that depend on a small number of variables (see e.g. the <a href="Least_squares#Lasso_method" title="wikilink">Lasso method</a>). In principle, entry-wise sparsity can be enforced by penalizing the entry-wise 

<math display="inline" id="Matrix_regularization:64">
 <semantics>
  <msup>
   <mi mathvariant="normal">ℓ</mi>
   <mn>0</mn>
  </msup>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">superscript</csymbol>
    <ci>normal-ℓ</ci>
    <cn type="integer">0</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \ell^{0}
  </annotation>
 </semantics>
</math>

-norm of the matrix, but the 

<math display="inline" id="Matrix_regularization:65">
 <semantics>
  <msup>
   <mi mathvariant="normal">ℓ</mi>
   <mn>0</mn>
  </msup>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">superscript</csymbol>
    <ci>normal-ℓ</ci>
    <cn type="integer">0</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \ell^{0}
  </annotation>
 </semantics>
</math>

-norm is not convex. In practice this can be implemented by convex relaxation to the 

<math display="inline" id="Matrix_regularization:66">
 <semantics>
  <msup>
   <mi mathvariant="normal">ℓ</mi>
   <mn>1</mn>
  </msup>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">superscript</csymbol>
    <ci>normal-ℓ</ci>
    <cn type="integer">1</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \ell^{1}
  </annotation>
 </semantics>
</math>

-norm. While entry-wise regularization with an 

<math display="inline" id="Matrix_regularization:67">
 <semantics>
  <msup>
   <mi mathvariant="normal">ℓ</mi>
   <mn>1</mn>
  </msup>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">superscript</csymbol>
    <ci>normal-ℓ</ci>
    <cn type="integer">1</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \ell^{1}
  </annotation>
 </semantics>
</math>

-norm will find solutions with a small number of nonzero elements, applying an 

<math display="inline" id="Matrix_regularization:68">
 <semantics>
  <msup>
   <mi mathvariant="normal">ℓ</mi>
   <mn>1</mn>
  </msup>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">superscript</csymbol>
    <ci>normal-ℓ</ci>
    <cn type="integer">1</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \ell^{1}
  </annotation>
 </semantics>
</math>

-norm to different groups of variables can enforce structure in the sparsity of solutions.<a class="footnoteRef" href="#fn6" id="fnref6"><sup>6</sup></a></p>

<p>The most straightforward example of structured sparsity uses the 

<math display="inline" id="Matrix_regularization:69">
 <semantics>
  <msub>
   <mi mathvariant="normal">ℓ</mi>
   <mrow>
    <mi>p</mi>
    <mo>,</mo>
    <mi>q</mi>
   </mrow>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>normal-ℓ</ci>
    <list>
     <ci>p</ci>
     <ci>q</ci>
    </list>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \ell_{p,q}
  </annotation>
 </semantics>
</math>

 norm with 

<math display="inline" id="Matrix_regularization:70">
 <semantics>
  <mrow>
   <mi>p</mi>
   <mo>=</mo>
   <mn>2</mn>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <ci>p</ci>
    <cn type="integer">2</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   p=2
  </annotation>
 </semantics>
</math>

 and 

<math display="inline" id="Matrix_regularization:71">
 <semantics>
  <mrow>
   <mi>q</mi>
   <mo>=</mo>
   <mn>1</mn>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <ci>q</ci>
    <cn type="integer">1</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   q=1
  </annotation>
 </semantics>
</math>

:</p>

<p>

<math display="block" id="Matrix_regularization:72">
 <semantics>
  <mrow>
   <mrow>
    <msub>
     <mrow>
      <mo>∥</mo>
      <mi>W</mi>
      <mo>∥</mo>
     </mrow>
     <mrow>
      <mn>2</mn>
      <mo>,</mo>
      <mn>1</mn>
     </mrow>
    </msub>
    <mo>=</mo>
    <mrow>
     <mo largeop="true" movablelimits="false" symmetric="true">∑</mo>
     <msub>
      <mrow>
       <mo>∥</mo>
       <msub>
        <mi>w</mi>
        <mi>i</mi>
       </msub>
       <mo>∥</mo>
      </mrow>
      <mn>2</mn>
     </msub>
    </mrow>
   </mrow>
   <mo>.</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <apply>
      <csymbol cd="latexml">norm</csymbol>
      <ci>W</ci>
     </apply>
     <list>
      <cn type="integer">2</cn>
      <cn type="integer">1</cn>
     </list>
    </apply>
    <apply>
     <sum></sum>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <apply>
       <csymbol cd="latexml">norm</csymbol>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <ci>w</ci>
        <ci>i</ci>
       </apply>
      </apply>
      <cn type="integer">2</cn>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \|W\|_{2,1}=\sum\|w_{i}\|_{2}.
  </annotation>
 </semantics>
</math>

</p>

<p>For example, the 

<math display="inline" id="Matrix_regularization:73">
 <semantics>
  <msub>
   <mi mathvariant="normal">ℓ</mi>
   <mrow>
    <mn>2</mn>
    <mo>,</mo>
    <mn>1</mn>
   </mrow>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>normal-ℓ</ci>
    <list>
     <cn type="integer">2</cn>
     <cn type="integer">1</cn>
    </list>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \ell_{2,1}
  </annotation>
 </semantics>
</math>

 norm is used in multi-task learning to group features across tasks, such that all the elements in a given row of the coefficient matrix can be forced to zero as a group.<a class="footnoteRef" href="#fn7" id="fnref7"><sup>7</sup></a> The grouping effect is achieved by taking the 

<math display="inline" id="Matrix_regularization:74">
 <semantics>
  <msup>
   <mi mathvariant="normal">ℓ</mi>
   <mn>2</mn>
  </msup>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">superscript</csymbol>
    <ci>normal-ℓ</ci>
    <cn type="integer">2</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \ell^{2}
  </annotation>
 </semantics>
</math>

-norm of each row, and then taking the total penalty to be the sum of these row-wise norms. This regularization results in rows that will tend to be all zeros, or dense. The same type of regularization can be used to enforce sparsity column-wise by taking the 

<math display="inline" id="Matrix_regularization:75">
 <semantics>
  <msup>
   <mi mathvariant="normal">ℓ</mi>
   <mn>2</mn>
  </msup>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">superscript</csymbol>
    <ci>normal-ℓ</ci>
    <cn type="integer">2</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \ell^{2}
  </annotation>
 </semantics>
</math>

-norms of each column.</p>

<p>More generally, the 

<math display="inline" id="Matrix_regularization:76">
 <semantics>
  <msub>
   <mi mathvariant="normal">ℓ</mi>
   <mrow>
    <mn>2</mn>
    <mo>,</mo>
    <mn>1</mn>
   </mrow>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>normal-ℓ</ci>
    <list>
     <cn type="integer">2</cn>
     <cn type="integer">1</cn>
    </list>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \ell_{2,1}
  </annotation>
 </semantics>
</math>

 norm can be applied to arbitrary groups of variables:</p>

<p>

<math display="block" id="Matrix_regularization:77">
 <semantics>
  <mrow>
   <mrow>
    <mi>R</mi>
    <mrow>
     <mo stretchy="false">(</mo>
     <mi>W</mi>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
   <mo>=</mo>
   <mrow>
    <mi>λ</mi>
    <mrow>
     <munderover>
      <mo largeop="true" movablelimits="false" symmetric="true">∑</mo>
      <mi>g</mi>
      <mi>G</mi>
     </munderover>
     <msqrt>
      <mrow>
       <munderover>
        <mo largeop="true" movablelimits="false" symmetric="true">∑</mo>
        <mi>j</mi>
        <mrow>
         <mo stretchy="false">|</mo>
         <msub>
          <mi>G</mi>
          <mi>g</mi>
         </msub>
         <mo stretchy="false">|</mo>
        </mrow>
       </munderover>
       <msup>
        <mrow>
         <mo stretchy="false">|</mo>
         <msubsup>
          <mi>w</mi>
          <mi>g</mi>
          <mi>j</mi>
         </msubsup>
         <mo stretchy="false">|</mo>
        </mrow>
        <mn>2</mn>
       </msup>
      </mrow>
     </msqrt>
    </mrow>
   </mrow>
   <mo>=</mo>
   <mrow>
    <mi>λ</mi>
    <mrow>
     <munderover>
      <mo largeop="true" movablelimits="false" symmetric="true">∑</mo>
      <mi>g</mi>
      <mi>G</mi>
     </munderover>
     <msub>
      <mrow>
       <mo>∥</mo>
       <msub>
        <mi>w</mi>
        <mi>g</mi>
       </msub>
       <mo>∥</mo>
      </mrow>
      <mi>g</mi>
     </msub>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <and></and>
    <apply>
     <eq></eq>
     <apply>
      <times></times>
      <ci>R</ci>
      <ci>W</ci>
     </apply>
     <apply>
      <times></times>
      <ci>λ</ci>
      <apply>
       <apply>
        <csymbol cd="ambiguous">superscript</csymbol>
        <apply>
         <csymbol cd="ambiguous">subscript</csymbol>
         <sum></sum>
         <ci>g</ci>
        </apply>
        <ci>G</ci>
       </apply>
       <apply>
        <root></root>
        <apply>
         <apply>
          <csymbol cd="ambiguous">superscript</csymbol>
          <apply>
           <csymbol cd="ambiguous">subscript</csymbol>
           <sum></sum>
           <ci>j</ci>
          </apply>
          <apply>
           <abs></abs>
           <apply>
            <csymbol cd="ambiguous">subscript</csymbol>
            <ci>G</ci>
            <ci>g</ci>
           </apply>
          </apply>
         </apply>
         <apply>
          <csymbol cd="ambiguous">superscript</csymbol>
          <apply>
           <abs></abs>
           <apply>
            <csymbol cd="ambiguous">superscript</csymbol>
            <apply>
             <csymbol cd="ambiguous">subscript</csymbol>
             <ci>w</ci>
             <ci>g</ci>
            </apply>
            <ci>j</ci>
           </apply>
          </apply>
          <cn type="integer">2</cn>
         </apply>
        </apply>
       </apply>
      </apply>
     </apply>
    </apply>
    <apply>
     <eq></eq>
     <share href="#.cmml">
     </share>
     <apply>
      <times></times>
      <ci>λ</ci>
      <apply>
       <apply>
        <csymbol cd="ambiguous">superscript</csymbol>
        <apply>
         <csymbol cd="ambiguous">subscript</csymbol>
         <sum></sum>
         <ci>g</ci>
        </apply>
        <ci>G</ci>
       </apply>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <apply>
         <csymbol cd="latexml">norm</csymbol>
         <apply>
          <csymbol cd="ambiguous">subscript</csymbol>
          <ci>w</ci>
          <ci>g</ci>
         </apply>
        </apply>
        <ci>g</ci>
       </apply>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   R(W)=\lambda\sum_{g}^{G}\sqrt{\sum_{j}^{|G_{g}|}|w_{g}^{j}|^{2}}=\lambda\sum_{%
g}^{G}\|w_{g}\|_{g}
  </annotation>
 </semantics>
</math>

</p>

<p>where the index 

<math display="inline" id="Matrix_regularization:78">
 <semantics>
  <mi>g</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>g</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   g
  </annotation>
 </semantics>
</math>

 is across groups of variables, and 

<math display="inline" id="Matrix_regularization:79">
 <semantics>
  <mrow>
   <mo stretchy="false">|</mo>
   <msub>
    <mi>G</mi>
    <mi>g</mi>
   </msub>
   <mo stretchy="false">|</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <abs></abs>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>G</ci>
     <ci>g</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   |G_{g}|
  </annotation>
 </semantics>
</math>

 indicates the cardinality of group 

<math display="inline" id="Matrix_regularization:80">
 <semantics>
  <mi>g</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>g</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   g
  </annotation>
 </semantics>
</math>

.</p>

<p>Algorithms for solving these group sparsity problems extend the more well-known Lasso and group Lasso methods by allowing overlapping groups, for example, and have been implemented via <a href="matching_pursuit" title="wikilink">matching pursuit</a>:<a class="footnoteRef" href="#fn8" id="fnref8"><sup>8</sup></a> and <a href="proximal_gradient_method" title="wikilink">proximal gradient methods</a>.<a class="footnoteRef" href="#fn9" id="fnref9"><sup>9</sup></a> By writing the proximal gradient with respect to a given coefficient, 

<math display="inline" id="Matrix_regularization:81">
 <semantics>
  <msubsup>
   <mi>w</mi>
   <mi>g</mi>
   <mi>i</mi>
  </msubsup>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">superscript</csymbol>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>w</ci>
     <ci>g</ci>
    </apply>
    <ci>i</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   w_{g}^{i}
  </annotation>
 </semantics>
</math>

, it can be seen that this norm enforces a group-wise soft threshold<a class="footnoteRef" href="#fn10" id="fnref10"><sup>10</sup></a></p>

<p>

<math display="block" id="Matrix_regularization:82">
 <semantics>
  <mrow>
   <msub>
    <mo>prox</mo>
    <mrow>
     <mi>λ</mi>
     <mo>,</mo>
     <msub>
      <mi>R</mi>
      <mi>g</mi>
     </msub>
    </mrow>
   </msub>
   <msup>
    <mrow>
     <mo stretchy="false">(</mo>
     <msub>
      <mi>w</mi>
      <mi>g</mi>
     </msub>
     <mo stretchy="false">)</mo>
    </mrow>
    <mi>i</mi>
   </msup>
   <mo>=</mo>
   <mrow>
    <mo>(</mo>
    <msubsup>
     <mi>w</mi>
     <mi>g</mi>
     <mi>i</mi>
    </msubsup>
    <mo>-</mo>
    <mi>λ</mi>
    <mfrac>
     <msubsup>
      <mi>w</mi>
      <mi>g</mi>
      <mi>i</mi>
     </msubsup>
     <msub>
      <mrow>
       <mo>∥</mo>
       <msub>
        <mi>w</mi>
        <mi>g</mi>
       </msub>
       <mo>∥</mo>
      </mrow>
      <mi>g</mi>
     </msub>
    </mfrac>
    <mo>)</mo>
   </mrow>
   <msub>
    <mn>𝟏</mn>
    <mrow>
     <msub>
      <mrow>
       <mo>∥</mo>
       <msub>
        <mi>w</mi>
        <mi>g</mi>
       </msub>
       <mo>∥</mo>
      </mrow>
      <mi>g</mi>
     </msub>
     <mo>≥</mo>
     <mi>λ</mi>
    </mrow>
   </msub>
   <mo>.</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <cerror>
    <csymbol cd="ambiguous">fragments</csymbol>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>prox</ci>
     <list>
      <ci>λ</ci>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>R</ci>
       <ci>g</ci>
      </apply>
     </list>
    </apply>
    <apply>
     <csymbol cd="ambiguous">superscript</csymbol>
     <cerror>
      <csymbol cd="ambiguous">fragments</csymbol>
      <ci>normal-(</ci>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>w</ci>
       <ci>g</ci>
      </apply>
      <ci>normal-)</ci>
     </cerror>
     <ci>i</ci>
    </apply>
    <eq></eq>
    <cerror>
     <csymbol cd="ambiguous">fragments</csymbol>
     <ci>normal-(</ci>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>w</ci>
       <ci>g</ci>
      </apply>
      <ci>i</ci>
     </apply>
     <minus></minus>
     <csymbol cd="unknown">λ</csymbol>
     <apply>
      <divide></divide>
      <apply>
       <csymbol cd="ambiguous">superscript</csymbol>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <ci>w</ci>
        <ci>g</ci>
       </apply>
       <ci>i</ci>
      </apply>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <apply>
        <csymbol cd="latexml">norm</csymbol>
        <apply>
         <csymbol cd="ambiguous">subscript</csymbol>
         <ci>w</ci>
         <ci>g</ci>
        </apply>
       </apply>
       <ci>g</ci>
      </apply>
     </apply>
     <ci>normal-)</ci>
    </cerror>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <cn type="integer">1</cn>
     <apply>
      <geq></geq>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <apply>
        <csymbol cd="latexml">norm</csymbol>
        <apply>
         <csymbol cd="ambiguous">subscript</csymbol>
         <ci>w</ci>
         <ci>g</ci>
        </apply>
       </apply>
       <ci>g</ci>
      </apply>
      <ci>λ</ci>
     </apply>
    </apply>
    <ci>normal-.</ci>
   </cerror>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \operatorname{prox}_{\lambda,R_{g}}(w_{g})^{i}=\left(w_{g}^{i}-\lambda\frac{w_%
{g}^{i}}{\|w_{g}\|_{g}}\right)\mathbf{1}_{\|w_{g}\|_{g}\geq\lambda}.
  </annotation>
 </semantics>
</math>

</p>

<p>where 

<math display="inline" id="Matrix_regularization:83">
 <semantics>
  <msub>
   <mn>𝟏</mn>
   <mrow>
    <msub>
     <mrow>
      <mo>∥</mo>
      <msub>
       <mi>w</mi>
       <mi>g</mi>
      </msub>
      <mo>∥</mo>
     </mrow>
     <mi>g</mi>
    </msub>
    <mo>≥</mo>
    <mi>λ</mi>
   </mrow>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <cn type="integer">1</cn>
    <apply>
     <geq></geq>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <apply>
       <csymbol cd="latexml">norm</csymbol>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <ci>w</ci>
        <ci>g</ci>
       </apply>
      </apply>
      <ci>g</ci>
     </apply>
     <ci>λ</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \mathbf{1}_{\|w_{g}\|_{g}\geq\lambda}
  </annotation>
 </semantics>
</math>

 is the indicator function for group norms 

<math display="inline" id="Matrix_regularization:84">
 <semantics>
  <mrow>
   <mi></mi>
   <mo>≥</mo>
   <mi>λ</mi>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <geq></geq>
    <csymbol cd="latexml">absent</csymbol>
    <ci>λ</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \geq\lambda
  </annotation>
 </semantics>
</math>

.</p>

<p>Thus, using 

<math display="inline" id="Matrix_regularization:85">
 <semantics>
  <msub>
   <mi mathvariant="normal">ℓ</mi>
   <mrow>
    <mn>2</mn>
    <mo>,</mo>
    <mn>1</mn>
   </mrow>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>normal-ℓ</ci>
    <list>
     <cn type="integer">2</cn>
     <cn type="integer">1</cn>
    </list>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \ell_{2,1}
  </annotation>
 </semantics>
</math>

 norms it is straightforward to enforce structure in the sparsity of a matrix either row-wise, column-wise, or in arbitrary blocks. By enforcing group norms on blocks in multivariate or multi-task regression, for example, it is possible to find groups of input and output variables, such that defined subsets of output variables (columns in the matrix 

<math display="inline" id="Matrix_regularization:86">
 <semantics>
  <mi>Y</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>Y</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   Y
  </annotation>
 </semantics>
</math>

) will depend on the same sparse set of input variables.</p>
<h2 id="multiple-kernel-selection">Multiple kernel selection</h2>

<p>The ideas of structured sparsity and feature selection can be extended to the nonparametric case of <a href="multiple_kernel_learning" title="wikilink">multiple kernel learning</a>.<a class="footnoteRef" href="#fn11" id="fnref11"><sup>11</sup></a> This can be useful when there are multiple types of input data (color and texture, for example) with different appropriate kernels for each, or when the appropriate kernel is unknown. If there are two kernels, for example, with feature maps 

<math display="inline" id="Matrix_regularization:87">
 <semantics>
  <mi>A</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>A</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   A
  </annotation>
 </semantics>
</math>

 and 

<math display="inline" id="Matrix_regularization:88">
 <semantics>
  <mi>B</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>B</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   B
  </annotation>
 </semantics>
</math>

 that lie in corresponding <a href="reproducing_kernel_Hilbert_space" title="wikilink">reproducing kernel Hilbert spaces</a> 

<math display="inline" id="Matrix_regularization:89">
 <semantics>
  <mrow>
   <msub>
    <mi class="ltx_font_mathcaligraphic">ℋ</mi>
    <mi class="ltx_font_mathcaligraphic">𝒜</mi>
   </msub>
   <mo>,</mo>
   <msub>
    <mi class="ltx_font_mathcaligraphic">ℋ</mi>
    <mi class="ltx_font_mathcaligraphic">ℬ</mi>
   </msub>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <list>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>ℋ</ci>
     <ci>𝒜</ci>
    </apply>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>ℋ</ci>
     <ci>ℬ</ci>
    </apply>
   </list>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \mathcal{H_{A}},\mathcal{H_{B}}
  </annotation>
 </semantics>
</math>

, then a larger space, 

<math display="inline" id="Matrix_regularization:90">
 <semantics>
  <msub>
   <mi class="ltx_font_mathcaligraphic">ℋ</mi>
   <mi class="ltx_font_mathcaligraphic">𝒟</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>ℋ</ci>
    <ci>𝒟</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \mathcal{H_{D}}
  </annotation>
 </semantics>
</math>

, can be created as the sum of two spaces:</p>

<p>

<math display="block" id="Matrix_regularization:91">
 <semantics>
  <mrow>
   <msub>
    <mi class="ltx_font_mathcaligraphic">ℋ</mi>
    <mi class="ltx_font_mathcaligraphic">𝒟</mi>
   </msub>
   <mo>:</mo>
   <mrow>
    <mrow>
     <mi>f</mi>
     <mo>=</mo>
     <mrow>
      <mi>h</mi>
      <mo>+</mo>
      <msup>
       <mi>h</mi>
       <mo>′</mo>
      </msup>
     </mrow>
    </mrow>
    <mo>;</mo>
    <mrow>
     <mrow>
      <mi>h</mi>
      <mo>∈</mo>
      <msub>
       <mi class="ltx_font_mathcaligraphic">ℋ</mi>
       <mi class="ltx_font_mathcaligraphic">𝒜</mi>
      </msub>
     </mrow>
     <mo>,</mo>
     <mrow>
      <msup>
       <mi>h</mi>
       <mo>′</mo>
      </msup>
      <mo>∈</mo>
      <msub>
       <mi class="ltx_font_mathcaligraphic">ℋ</mi>
       <mi class="ltx_font_mathcaligraphic">ℬ</mi>
      </msub>
     </mrow>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <ci>normal-:</ci>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>ℋ</ci>
     <ci>𝒟</ci>
    </apply>
    <apply>
     <csymbol cd="ambiguous">formulae-sequence</csymbol>
     <apply>
      <eq></eq>
      <ci>f</ci>
      <apply>
       <plus></plus>
       <ci>h</ci>
       <apply>
        <csymbol cd="ambiguous">superscript</csymbol>
        <ci>h</ci>
        <ci>normal-′</ci>
       </apply>
      </apply>
     </apply>
     <apply>
      <csymbol cd="ambiguous">formulae-sequence</csymbol>
      <apply>
       <in></in>
       <ci>h</ci>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <ci>ℋ</ci>
        <ci>𝒜</ci>
       </apply>
      </apply>
      <apply>
       <in></in>
       <apply>
        <csymbol cd="ambiguous">superscript</csymbol>
        <ci>h</ci>
        <ci>normal-′</ci>
       </apply>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <ci>ℋ</ci>
        <ci>ℬ</ci>
       </apply>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \mathcal{H_{D}}:f=h+h^{\prime};h\in\mathcal{H_{A}},h^{\prime}\in\mathcal{H_{B}}
  </annotation>
 </semantics>
</math>

</p>

<p>assuming linear independence in 

<math display="inline" id="Matrix_regularization:92">
 <semantics>
  <mi>A</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>A</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   A
  </annotation>
 </semantics>
</math>

 and 

<math display="inline" id="Matrix_regularization:93">
 <semantics>
  <mi>B</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>B</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   B
  </annotation>
 </semantics>
</math>

. In this case the 

<math display="inline" id="Matrix_regularization:94">
 <semantics>
  <msub>
   <mi mathvariant="normal">ℓ</mi>
   <mrow>
    <mn>2</mn>
    <mo>,</mo>
    <mn>1</mn>
   </mrow>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>normal-ℓ</ci>
    <list>
     <cn type="integer">2</cn>
     <cn type="integer">1</cn>
    </list>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \ell_{2,1}
  </annotation>
 </semantics>
</math>

-norm is again the sum of norms:</p>

<p>

<math display="block" id="Matrix_regularization:95">
 <semantics>
  <mrow>
   <msub>
    <mrow>
     <mo>∥</mo>
     <mi>f</mi>
     <mo>∥</mo>
    </mrow>
    <mrow>
     <msub>
      <mi class="ltx_font_mathcaligraphic">ℋ</mi>
      <mi class="ltx_font_mathcaligraphic">𝒟</mi>
     </msub>
     <mo>,</mo>
     <mn>1</mn>
    </mrow>
   </msub>
   <mo>=</mo>
   <mrow>
    <msub>
     <mrow>
      <mo>∥</mo>
      <mi>h</mi>
      <mo>∥</mo>
     </mrow>
     <msub>
      <mi class="ltx_font_mathcaligraphic">ℋ</mi>
      <mi class="ltx_font_mathcaligraphic">𝒜</mi>
     </msub>
    </msub>
    <mo>+</mo>
    <msub>
     <mrow>
      <mo>∥</mo>
      <msup>
       <mi>h</mi>
       <mo>′</mo>
      </msup>
      <mo>∥</mo>
     </mrow>
     <msub>
      <mi class="ltx_font_mathcaligraphic">ℋ</mi>
      <mi class="ltx_font_mathcaligraphic">ℬ</mi>
     </msub>
    </msub>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <apply>
      <csymbol cd="latexml">norm</csymbol>
      <ci>f</ci>
     </apply>
     <list>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>ℋ</ci>
       <ci>𝒟</ci>
      </apply>
      <cn type="integer">1</cn>
     </list>
    </apply>
    <apply>
     <plus></plus>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <apply>
       <csymbol cd="latexml">norm</csymbol>
       <ci>h</ci>
      </apply>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>ℋ</ci>
       <ci>𝒜</ci>
      </apply>
     </apply>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <apply>
       <csymbol cd="latexml">norm</csymbol>
       <apply>
        <csymbol cd="ambiguous">superscript</csymbol>
        <ci>h</ci>
        <ci>normal-′</ci>
       </apply>
      </apply>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>ℋ</ci>
       <ci>ℬ</ci>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \|f\|_{\mathcal{H_{D}},1}=\|h\|_{\mathcal{H_{A}}}+\|h^{\prime}\|_{\mathcal{H_{%
B}}}
  </annotation>
 </semantics>
</math>

</p>

<p>Thus, by choosing a matrix regularization function as this type of norm, it is possible to find a solution that is sparse in terms of which kernels are used, but dense in the coefficient of each used kernel. Multiple kernel learning can also be used as a form of nonlinear variable selection, or as a model aggregation technique (e.g. by taking the sum of squared norms and relaxing sparsity constraints). For example, each kernel can be taken to be the Gaussian kernel with a different width.</p>
<h2 id="references">References</h2>

<p>"</p>

<p><a class="uri" href="Category:Matrices" title="wikilink">Category:Matrices</a> <a class="uri" href="Category:Vectors" title="wikilink">Category:Vectors</a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1">Lorenzo Rosasco, Tomaso Poggio, "A Regularization Tour of Machine Learning — MIT-9.520 Lectures Notes" Manuscript, Dec. 2014.<a href="#fnref1">↩</a></li>
<li id="fn2">Exact Matrix Completion via Convex Optimization by Candès, Emmanuel J. and Recht, Benjamin (2009) in Foundations of Computational Mathematics, 9 (6). pp. 717–772. ISSN 1615-3375<a href="#fnref2">↩</a></li>
<li id="fn3">Zhang and Yeung. A Convex Formulation for Learning Task Relationships in Multi-Task Learning. Proceedings of the Twenty-Sixth Conference on Uncertainty in Artificial Intelligence (UAI2010)<a href="#fnref3">↩</a></li>
<li id="fn4"></li>
<li id="fn5">Alan Izenman. Reduced Rank Regression for the Multivariate Linear Model. Journal of Multivariate Analysis 5,248-264(1975)<a href="#fnref5">↩</a></li>
<li id="fn6">Kakade, Shalev-Shwartz and Tewari. Regularization Techniques for Learning with Matrices. Journal of Machine Learning Research 13 (2012) 1865-1890.<a href="#fnref6">↩</a></li>
<li id="fn7">A. Argyriou, T. Evgeniou, and M. Pontil. Convex multi-task feature learning. Machine Learning, 73(3):243–272, 2008.<a href="#fnref7">↩</a></li>
<li id="fn8">Huang, Zhang, and Metaxas. Learning with Structured Sparsity. Journal of Machine Learning Research 12 (2011) 3371-3412.<a href="#fnref8">↩</a></li>
<li id="fn9">Chen et. al. Smoothing Proximal Gradient Method for General Structured Sparse Regression. The Annals of Applied Statistics, 2012, Vol. 6, No. 2, 719–752 DOI: 10.1214/11-AOAS514<a href="#fnref9">↩</a></li>
<li id="fn10"></li>
<li id="fn11">Sonnenburg, Ratsch, Schafer AND Scholkopf. Large Scale Multiple Kernel Learning. Journal of Machine Learning Research 7 (2006) 1531–1565.<a href="#fnref11">↩</a></li>
</ol>
</section>
</body>
</html>
