   Bernstein inequalities (probability theory)      Bernstein inequalities (probability theory)   In probability theory , Bernstein inequalities give bounds on the probability that the sum of random variables deviates from its mean. In the simplest case, let X 1 ,Â ..., X n be independent Bernoulli random variables taking values +1 and âˆ’1 with probabilityÂ 1/2 (this distribution is also known as the Rademacher distribution ), then for every positive   Îµ   Îµ   \varepsilon   ,      ğ   (  |   1  n    âˆ‘   i  =  1   n    X  i   |  >  Îµ  )   â‰¤  2  exp   (  -    n   Îµ  2     2   (   1  +   Îµ  3    )     )   .     fragments  P   fragments  normal-(  normal-|    1  n    superscript   subscript     i  1    n    subscript  X  i   normal-|   Îµ  normal-)    2    fragments  normal-(       n   superscript  Îµ  2      2    1    Îµ  3      normal-)   normal-.    \mathbf{P}\left(\left|\frac{1}{n}\sum_{i=1}^{n}X_{i}\right|>\varepsilon\right)%
 \leq 2\exp\left(-\frac{n\varepsilon^{2}}{2(1+\frac{\varepsilon}{3})}\right).     Bernstein inequalities were proved and published by Sergei Bernstein in the 1920s and 1930s. 1 2 3 4 Later, these inequalities were rediscovered several times in various forms. Thus, special cases of the Bernstein inequalities are also known as the Chernoff bound , Hoeffding's inequality and Azuma's inequality .  Some of the inequalities  1. Let X 1 ,Â ..., X n be independent zero-mean random variables. Suppose that | X  i |Â â‰¤ M almost surely, for all i . Then, for all positive t ,      ğ   (   âˆ‘   i  =  1   n    X  i   >  t  )   â‰¤  exp   (  -     1  2    t  2      âˆ‘   ğ„   [   X  j  2   ]     +    1  3   M  t     )   .     fragments  P   fragments  normal-(   superscript   subscript     i  1    n    subscript  X  i    t  normal-)      fragments  normal-(         1  2    superscript  t  2          ğ„   delimited-[]   superscript   subscript  X  j   2          1  3   M  t     normal-)   normal-.    \mathbf{P}\left(\sum_{i=1}^{n}X_{i}>t\right)\leq\exp\left(-\frac{\tfrac{1}{2}t%
 ^{2}}{\sum\mathbf{E}\left[X_{j}^{2}\right]+\tfrac{1}{3}Mt}\right).     2. Let X 1 , ..., X n be independent random variables. Suppose that for some positive real L and every integer k >Â 1,       ğ„   [   |   X  i  k   |   ]    â‰¤     1  2    ğ„   [   X  i  2   ]    L   k  -  2     k  !          ğ„   delimited-[]     superscript   subscript  X  i   k          1  2   ğ„   delimited-[]   superscript   subscript  X  i   2     superscript  L    k  2      k      \mathbf{E}\left[|X_{i}^{k}|\right]\leq\tfrac{1}{2}\mathbf{E}\left[X_{i}^{2}%
 \right]L^{k-2}k!     Then      ğ   (   âˆ‘   i  =  1   n    X  i   â‰¥  2  t    âˆ‘   ğ„   [   X  i  2   ]      )   <  exp   (  -   t  2   )   ,  for  0  <  t  â‰¤    1   2  L       âˆ‘   ğ„   [   X  j  2   ]      .     fragments  P   fragments  normal-(   superscript   subscript     i  1    n    subscript  X  i    2  t        ğ„   delimited-[]   superscript   subscript  X  i   2       normal-)      fragments  normal-(    superscript  t  2   normal-)   normal-,  for  0   t     1    2  L          ğ„   delimited-[]   superscript   subscript  X  j   2       normal-.    \mathbf{P}\left(\sum_{i=1}^{n}X_{i}\geq 2t\sqrt{\sum\mathbf{E}\left[X_{i}^{2}%
 \right]}\right)<\exp(-t^{2}),\qquad\text{for }0     3. Let X 1 , ..., X n be independent random variables. Suppose that       ğ„   [   |   X  i  k   |   ]    â‰¤     k  !    4  !      (   L  5   )    k  -  4           ğ„   delimited-[]     superscript   subscript  X  i   k            k     4     superscript    L  5     k  4       \mathbf{E}\left[|X_{i}^{k}|\right]\leq\frac{k!}{4!}\left(\frac{L}{5}\right)^{k%
 -4}     for all integer k >Â 3. Denote        A  k   =   âˆ‘   ğ„   [   X  i  k   ]      .       subscript  A  k       ğ„   delimited-[]   superscript   subscript  X  i   k        A_{k}=\sum\mathbf{E}\left[X_{i}^{k}\right].     Then,      ğ   (  |   âˆ‘   j  =  1   n    X  j   -     A  3    t  2     3   A  2     |  â‰¥     2   A  2      t   [  1  +     A  4    t  2     6   A  2  2     ]   )   <  2  exp   (  -   t  2   )   ,  for  0  <  t  â‰¤    5    2   A  2       4  L    .     fragments  P   fragments  normal-(  normal-|   superscript   subscript     j  1    n    subscript  X  j         subscript  A  3    superscript  t  2      3   subscript  A  2     normal-|       2   subscript  A  2     t   fragments  normal-[  1        subscript  A  4    superscript  t  2      6   superscript   subscript  A  2   2     normal-]   normal-)    2    fragments  normal-(    superscript  t  2   normal-)   normal-,  for  0   t       5      2   subscript  A  2        4  L    normal-.    \mathbf{P}\left(\left|\sum_{j=1}^{n}X_{j}-\frac{A_{3}t^{2}}{3A_{2}}\right|\geq%
 \sqrt{2A_{2}}\,t\left[1+\frac{A_{4}t^{2}}{6A_{2}^{2}}\right]\right)<2\exp(-t^{%
 2}),\qquad\text{for }0     4. Bernstein also proved generalizations of the inequalities above to weakly dependent random variables. For example, inequality (2) can be extended as follows. Let X 1 ,Â ..., X n be possibly non-independent random variables. Suppose that for all integer i >Â 0,      ğ„   [   X  i   |   X  1   ,  â€¦  ,   X   i  -  1    ]      fragments  E   fragments  normal-[   subscript  X  i   normal-|   subscript  X  1   normal-,  normal-â€¦  normal-,   subscript  X    i  1    normal-]     \displaystyle\mathbf{E}\left[X_{i}|X_{1},\dots,X_{i-1}\right]     Then      ğ   (   âˆ‘   i  =  1   n    X  i   â‰¥  2  t     âˆ‘   i  =  1   n     R  i   ğ„   [   X  i  2   ]      )   <  exp   (  -   t  2   )   ,  for  0  <  t  â‰¤    1   2  L        âˆ‘   i  =  1   n     R  i   ğ„   [   X  i  2   ]      .     fragments  P   fragments  normal-(   superscript   subscript     i  1    n    subscript  X  i    2  t      superscript   subscript     i  1    n      subscript  R  i   ğ„   delimited-[]   superscript   subscript  X  i   2       normal-)      fragments  normal-(    superscript  t  2   normal-)   normal-,  for  0   t     1    2  L        superscript   subscript     i  1    n      subscript  R  i   ğ„   delimited-[]   superscript   subscript  X  i   2       normal-.    \mathbf{P}\left(\sum_{i=1}^{n}X_{i}\geq 2t\sqrt{\sum_{i=1}^{n}R_{i}\mathbf{E}%
 \left[X_{i}^{2}\right]}\right)<\exp(-t^{2}),\qquad\text{for }0   More general results for martingales can be found in Fan et al. (2012). 5  Proofs  The proofs are based on an application of Markov's inequality to the random variable       exp   (   Î»    âˆ‘   j  =  1   n    X  j     )    ,        Î»    superscript   subscript     j  1    n    subscript  X  j       \exp\left(\lambda\sum_{j=1}^{n}X_{j}\right),     for a suitable choice of the parameter Î» > 0.  See also   McDiarmid's inequality  Markov inequality  Dvoretzkyâ€“Kieferâ€“Wolfowitz inequality  Hoeffding's inequality  Chebyshev's inequality  Azuma's inequality  Bennett's inequality  Concentration inequality   References  (according to: S.N.Bernstein, Collected Works, Nauka, 1964)  A modern translation of some of these results can also be found in   "  Category:Probability theory  Category:Probabilistic inequalities     S.N.Bernstein, "On a modification of Chebyshevâ€™s inequality and of the error formula of Laplace" vol. 4, #5 (original publication: Ann. Sci. Inst. Sav. Ukraine, Sect. Math. 1, 1924) â†©  â†©  S.N.Bernstein, "Theory of Probability" (Russian), Moscow, 1927 â†©  J.V.Uspensky, "Introduction to Mathematical Probability", McGraw-Hill Book Company, 1937 â†©  â†©     