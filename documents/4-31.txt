   Laplace's method      Laplace's method   See also: Additive smoothing (Laplace smoothing) a method of smoothing of a statistical estimator  In mathematics , Laplace's method , named after Pierre-Simon Laplace , is a technique used to approximate integrals of the form        ∫  a  b       e   M  f   (  x  )      d  x       superscript   subscript   a   b      superscript  e    M  f  x    d  x     \int_{a}^{b}\!e^{Mf(x)}\,dx     where ƒ ( x ) is some twice- differentiable  function , M is a large number, and the integral endpoints a and b could possibly be infinite. This technique was originally presented in Laplace (1774, pp. 366–367).  The idea of Laplace's method  (Figure)  The function e Mƒ ( x ) , in blue, is shown on top for M = 0.5, and at the bottom for M = 3. Here, ƒ ( x ) = sin x / x , with a global maximum at x 0 = 0. It is seen that as M grows larger, the approximation of this function by a Gaussian function (shown in red) is getting better. This observation underlies Laplace's method.   Assume that the function ƒ ( x ) has a unique global maximum at x 0 . Then, the value ƒ ( x 0 ) will be larger than other values ƒ ( x ). If we multiply this function by a large number M , the ratio between Mƒ ( x 0 ) and Mƒ ( x ) will stay the same (since Mƒ ( x 0 )/ Mƒ ( x ) = ƒ ( x 0 )/ ƒ ( x )), but it will grow exponentially in the function (see figure)       e   M  f   (  x  )     .     superscript  e    M  f  x     e^{Mf(x)}.\,     Thus, significant contributions to the integral of this function will come only from points x in a neighborhood of x 0 , which can then be estimated.  General theory of Laplace's method  To state and motivate the method, we need several assumptions. We will assume that x 0 is not an endpoint of the interval of integration, that the values ƒ ( x ) cannot be very close to ƒ ( x 0 ) unless x is close to x 0 , and that the second derivative      f  ′′    (   x  0   )    <  0         superscript  f  ′′    subscript  x  0    0    f^{\prime\prime}(x_{0})<0   .  We can expand ƒ ( x ) around x 0 by Taylor's theorem ,       f   (  x  )    =    f   (   x  0   )    +    f  ′    (   x  0   )    (   x  -   x  0    )    +    1  2    f  ′′    (   x  0   )     (   x  -   x  0    )   2    +  R         f  x       f   subscript  x  0       superscript  f  normal-′    subscript  x  0     x   subscript  x  0         1  2    superscript  f  ′′    subscript  x  0    superscript    x   subscript  x  0    2    R     f(x)=f(x_{0})+f^{\prime}(x_{0})(x-x_{0})+\frac{1}{2}f^{\prime\prime}(x_{0})(x-%
 x_{0})^{2}+R      where     R  =   O   (    (   x  -   x  0    )   3   )     .      R    O   superscript    x   subscript  x  0    3      R=O\left((x-x_{0})^{3}\right).      Since ƒ has a global maximum at x 0 , and since x 0 is not an endpoint, it is a stationary point , so the derivative of ƒ vanishes at x 0 . Therefore, the function ƒ ( x ) may be approximated to quadratic order       f   (  x  )    ≈    f   (   x  0   )    -    1  2    |    f  ′′    (   x  0   )    |     (   x  -   x  0    )   2           f  x       f   subscript  x  0        1  2        superscript  f  ′′    subscript  x  0      superscript    x   subscript  x  0    2       f(x)\approx f(x_{0})-\frac{1}{2}|f^{\prime\prime}(x_{0})|(x-x_{0})^{2}     for x close to x 0 (recall that the second derivative is negative at the global maximum ƒ ( x 0 )). The assumptions made ensure the accuracy of the approximation         ∫  a  b       e   M  f   (  x  )      d  x    ≈    e   M  f   (   x  0   )       ∫  a  b      e   -    M   |    f  ′′    (   x  0   )    |     (   x  -   x  0    )   2    /  2      d  x           superscript   subscript   a   b      superscript  e    M  f  x    d  x       superscript  e    M  f   subscript  x  0       superscript   subscript   a   b      superscript  e        M       superscript  f  ′′    subscript  x  0      superscript    x   subscript  x  0    2    2     d  x       \int_{a}^{b}\!e^{Mf(x)}\,dx\approx e^{Mf(x_{0})}\int_{a}^{b}e^{-M|f^{\prime%
 \prime}(x_{0})|(x-x_{0})^{2}/2}\,dx     (see the picture on the right). This latter integral is a Gaussian integral if the limits of integration go from −∞ to +∞ (which can be assumed because the exponential decays very fast away from x 0 ), and thus it can be calculated. We find          ∫  a  b       e   M  f   (  x  )      d  x    ≈      2  π    M   |    f  ′′    (   x  0   )    |       e   M  f   (   x  0   )     as  M   →  ∞   .          superscript   subscript   a   b      superscript  e    M  f  x    d  x            2  π     M       superscript  f  ′′    subscript  x  0         superscript  e    M  f   subscript  x  0     as  M     normal-→        \int_{a}^{b}\!e^{Mf(x)}\,dx\approx\sqrt{\frac{2\pi}{M|f^{\prime\prime}(x_{0})|%
 }}e^{Mf(x_{0})}\text{ as }M\to\infty.\,     A generalization of this method and extension to arbitrary precision is provided by Fog (2008).  Formal statement and proof:  Assume that    f   (  x  )       f  x    f(x)   is a twice differentiable function on    [  a  ,  b  ]     a  b    [a,b]   with     x  0   ∈   [  a  ,  b  ]        subscript  x  0    a  b     x_{0}\in[a,b]   the unique point such that     f   (   x  0   )    =     max   [  a  ,  b  ]    f    (  x  )          f   subscript  x  0        subscript    a  b    f   x     f(x_{0})=\max_{[a,b]}f(x)   . Assume additionally that      f  ′′    (   x  0   )    <  0         superscript  f  ′′    subscript  x  0    0    f^{\prime\prime}(x_{0})<0   .  Then,        lim   n  →   +  ∞      (     ∫  a  b      e   n  f   (  x  )      d  x     (    e   n  f   (   x  0   )        2  π    n   (   -    f  ′′    (   x  0   )     )       )    )    =  1        subscript    normal-→  n            superscript   subscript   a   b      superscript  e    n  f  x    d  x       superscript  e    n  f   subscript  x  0           2  π     n       superscript  f  ′′    subscript  x  0           1    \lim_{n\to+\infty}\left(\frac{\int_{a}^{b}e^{nf(x)}\,dx}{\left(e^{nf(x_{0})}%
 \sqrt{\frac{2\pi}{n(-f^{\prime\prime}(x_{0}))}}\right)}\right)=1    Lower bound :  Let    ε  >  0      ε  0    \varepsilon>0   . Then by the continuity of    f  ′′     superscript  f  ′′    f^{\prime\prime}   there exists    δ  >  0      δ  0    \delta>0   such that if     |    x  0   -  c   |   <  δ           subscript  x  0   c    δ    |x_{0}-c|<\delta   then       f  ′′    (  c  )    ≥     f  ′′    (   x  0   )    -  ε    .         superscript  f  ′′   c        superscript  f  ′′    subscript  x  0    ε     f^{\prime\prime}(c)\geq f^{\prime\prime}(x_{0})-\varepsilon.   . By Taylor's Theorem , for any    x  ∈   (    x  0   -  δ   ,    x  0   +  δ   )       x      subscript  x  0   δ      subscript  x  0   δ      x\in(x_{0}-\delta,x_{0}+\delta)   ,     f   (  x  )    ≥    f   (   x  0   )    +    1  2    (     f  ′′    (   x  0   )    -  ε   )     (   x  -   x  0    )   2           f  x       f   subscript  x  0        1  2        superscript  f  ′′    subscript  x  0    ε    superscript    x   subscript  x  0    2       f(x)\geq f(x_{0})+\frac{1}{2}(f^{\prime\prime}(x_{0})-\varepsilon)(x-x_{0})^{2}   .  Then we have the following lower bound:        ∫  a  b      e   n  f   (  x  )      d  x    ≥    ∫    x  0   -  δ     x  0   +  δ       e   n  f   (  x  )      d  x    ≥    e   n  f   (   x  0   )       ∫    x  0   -  δ     x  0   +  δ       e    n  2    (     f  ′′    (   x  0   )    -  ε   )     (   x  -   x  0    )   2      d  x     =    e   n  f   (   x  0   )       1   n   (    -    f  ′′    (   x  0   )     +  ε   )        ∫   -   δ    n   (    -    f  ′′    (   x  0   )     +  ε   )        δ    n   (    -    f  ′′    (   x  0   )     +  ε   )          e   -    1  2    y  2       d  y             superscript   subscript   a   b      superscript  e    n  f  x    d  x      superscript   subscript      subscript  x  0   δ       subscript  x  0   δ       superscript  e    n  f  x    d  x            superscript  e    n  f   subscript  x  0       superscript   subscript      subscript  x  0   δ       subscript  x  0   δ       superscript  e      n  2        superscript  f  ′′    subscript  x  0    ε    superscript    x   subscript  x  0    2     d  x             superscript  e    n  f   subscript  x  0         1    n         superscript  f  ′′    subscript  x  0     ε        superscript   subscript       δ      n         superscript  f  ′′    subscript  x  0     ε          δ      n         superscript  f  ′′    subscript  x  0     ε          superscript  e        1  2    superscript  y  2      d  y        \int_{a}^{b}e^{nf(x)}\,dx\geq\int_{x_{0}-\delta}^{x_{0}+\delta}e^{nf(x)}\,dx%
 \geq e^{nf(x_{0})}\int_{x_{0}-\delta}^{x_{0}+\delta}e^{\frac{n}{2}(f^{\prime%
 \prime}(x_{0})-\varepsilon)(x-x_{0})^{2}}\,dx=e^{nf(x_{0})}\sqrt{\frac{1}{n(-f%
 ^{\prime\prime}(x_{0})+\varepsilon)}}\int_{-\delta\sqrt{n(-f^{\prime\prime}(x_%
 {0})+\varepsilon)}}^{\delta\sqrt{n(-f^{\prime\prime}(x_{0})+\varepsilon)}}e^{-%
 \frac{1}{2}y^{2}}\,dy     where the last equality was obtained by a change of variables    y  =     n   (    -    f  ′′    (   x  0   )     +  ε   )      (   x  -   x  0    )        y        n         superscript  f  ′′    subscript  x  0     ε       x   subscript  x  0       y=\sqrt{n(-f^{\prime\prime}(x_{0})+\varepsilon)}(x-x_{0})   . Remember that      f  ′′    (   x  0   )    <  0         superscript  f  ′′    subscript  x  0    0    f^{\prime\prime}(x_{0})<0   so that is why we can take the square root of its negation.  If we divide both sides of the above inequality by     e   n  f   (   x  0   )        2  π    n   (   -    f  ′′    (   x  0   )     )           superscript  e    n  f   subscript  x  0           2  π     n       superscript  f  ′′    subscript  x  0          e^{nf(x_{0})}\sqrt{\frac{2\pi}{n(-f^{\prime\prime}(x_{0}))}}   and take the limit we get:        lim   n  →   +  ∞      (     ∫  a  b      e   n  f   (  x  )      d  x     (    e   n  f   (   x  0   )        2  π    n   (   -    f  ′′    (   x  0   )     )       )    )    ≥    lim   n  →   +  ∞       1    2  π       ∫   -   δ    n   (    -    f  ′′    (   x  0   )     +  ε   )        δ    n   (    -    f  ′′    (   x  0   )     +  ε   )          e   -    1  2    y  2       d  y     -    f  ′′    (   x  0   )       -    f  ′′    (   x  0   )     +  ε         =     -    f  ′′    (   x  0   )       -    f  ′′    (   x  0   )     +  ε             subscript    normal-→  n            superscript   subscript   a   b      superscript  e    n  f  x    d  x       superscript  e    n  f   subscript  x  0           2  π     n       superscript  f  ′′    subscript  x  0             subscript    normal-→  n            1      2  π       superscript   subscript       δ      n         superscript  f  ′′    subscript  x  0     ε          δ      n         superscript  f  ′′    subscript  x  0     ε          superscript  e        1  2    superscript  y  2      d  y           superscript  f  ′′    subscript  x  0            superscript  f  ′′    subscript  x  0     ε                       superscript  f  ′′    subscript  x  0            superscript  f  ′′    subscript  x  0     ε        \lim_{n\to+\infty}\left(\frac{\int_{a}^{b}e^{nf(x)}\,dx}{\left(e^{nf(x_{0})}%
 \sqrt{\frac{2\pi}{n(-f^{\prime\prime}(x_{0}))}}\right)}\right)\geq\lim_{n\to+%
 \infty}\frac{1}{\sqrt{2\pi}}\int_{-\delta\sqrt{n(-f^{\prime\prime}(x_{0})+%
 \varepsilon)}}^{\delta\sqrt{n(-f^{\prime\prime}(x_{0})+\varepsilon)}}e^{-\frac%
 {1}{2}y^{2}}\,dy\sqrt{\frac{-f^{\prime\prime}(x_{0})}{-f^{\prime\prime}(x_{0})%
 +\varepsilon}}=\sqrt{\frac{-f^{\prime\prime}(x_{0})}{-f^{\prime\prime}(x_{0})+%
 \varepsilon}}     since this is true for arbitrary   ε   ε   \varepsilon   we get the lower bound:        lim   n  →   +  ∞      (     ∫  a  b      e   n  f   (  x  )      d  x     (    e   n  f   (   x  0   )        2  π    n   (   -    f  ′′    (   x  0   )     )       )    )    ≥  1        subscript    normal-→  n            superscript   subscript   a   b      superscript  e    n  f  x    d  x       superscript  e    n  f   subscript  x  0           2  π     n       superscript  f  ′′    subscript  x  0           1    \lim_{n\to+\infty}\left(\frac{\int_{a}^{b}e^{nf(x)}\,dx}{\left(e^{nf(x_{0})}%
 \sqrt{\frac{2\pi}{n(-f^{\prime\prime}(x_{0}))}}\right)}\right)\geq 1     Note that this proof works also when    a  =   -  ∞       a        a=-\infty   or    b  =  ∞      b     b=\infty   (or both).  Upper bound :  The proof of the upper bound is similar to the proof of the lower bound but there are a few inconveniences. Again we start by picking an    ε  >  0      ε  0    \varepsilon>0   but in order for the proof to work we need   ε   ε   \varepsilon   small enough so that       f  ′′    (   x  0   )    +  ε   <  0           superscript  f  ′′    subscript  x  0    ε   0    f^{\prime\prime}(x_{0})+\varepsilon<0   . Then, as above, by continuity of    f  ′′     superscript  f  ′′    f^{\prime\prime}   and Taylor's Theorem we can find    δ  >  0      δ  0    \delta>0   so that if     |   x  -   x  0    |   <  δ          x   subscript  x  0     δ    |x-x_{0}|<\delta   , then     f   (  x  )    ≤    f   (   x  0   )    +    1  2    (     f  ′′    (   x  0   )    +  ε   )     (   x  -   x  0    )   2           f  x       f   subscript  x  0        1  2        superscript  f  ′′    subscript  x  0    ε    superscript    x   subscript  x  0    2       f(x)\leq f(x_{0})+\frac{1}{2}(f^{\prime\prime}(x_{0})+\varepsilon)(x-x_{0})^{2}   . Lastly, by our assumptions (assuming    a  ,  b     a  b    a,b   are finite) there exists an    η  >  0      η  0    \eta>0   such that if     |   x  -   x  0    |   ≥  δ          x   subscript  x  0     δ    |x-x_{0}|\geq\delta   , then     f   (  x  )    ≤    f   (   x  0   )    -  η         f  x       f   subscript  x  0    η     f(x)\leq f(x_{0})-\eta   .  Then we can calculate the following upper bound:        ∫  a  b      e   n  f   (  x  )      d  x    ≤     ∫  a    x  0   -  δ       e   n  f   (  x  )      d  x    +    ∫    x  0   -  δ     x  0   +  δ       e   n  f   (  x  )      d  x    +    ∫    x  0   +  δ   b      e   n  f   (  x  )      d  x     ≤     (   b  -  a   )    e   n   (    f   (   x  0   )    -  η   )      +    ∫    x  0   -  δ     x  0   +  δ       e   n  f   (  x  )      d  x             superscript   subscript   a   b      superscript  e    n  f  x    d  x        superscript   subscript   a      subscript  x  0   δ       superscript  e    n  f  x    d  x      superscript   subscript      subscript  x  0   δ       subscript  x  0   δ       superscript  e    n  f  x    d  x      superscript   subscript      subscript  x  0   δ    b      superscript  e    n  f  x    d  x                b  a    superscript  e    n      f   subscript  x  0    η        superscript   subscript      subscript  x  0   δ       subscript  x  0   δ       superscript  e    n  f  x    d  x        \int_{a}^{b}e^{nf(x)}\,dx\leq\int_{a}^{x_{0}-\delta}e^{nf(x)}\,dx+\int_{x_{0}-%
 \delta}^{x_{0}+\delta}e^{nf(x)}\,dx+\int_{x_{0}+\delta}^{b}e^{nf(x)}\,dx\leq(b%
 -a)e^{n(f(x_{0})-\eta)}+\int_{x_{0}-\delta}^{x_{0}+\delta}e^{nf(x)}\,dx          ≤     (   b  -  a   )    e   n   (    f   (   x  0   )    -  η   )      +    e   n  f   (   x  0   )       ∫    x  0   -  δ     x  0   +  δ       e    n  2    (     f  ′′    (   x  0   )    +  ε   )     (   x  -   x  0    )   2      d  x      ≤     (   b  -  a   )    e   n   (    f   (   x  0   )    -  η   )      +    e   n  f   (   x  0   )       ∫   -  ∞    +  ∞       e    n  2    (     f  ′′    (   x  0   )    +  ε   )     (   x  -   x  0    )   2      d  x            absent        b  a    superscript  e    n      f   subscript  x  0    η         superscript  e    n  f   subscript  x  0       superscript   subscript      subscript  x  0   δ       subscript  x  0   δ       superscript  e      n  2        superscript  f  ′′    subscript  x  0    ε    superscript    x   subscript  x  0    2     d  x                 b  a    superscript  e    n      f   subscript  x  0    η         superscript  e    n  f   subscript  x  0       superscript   subscript                superscript  e      n  2        superscript  f  ′′    subscript  x  0    ε    superscript    x   subscript  x  0    2     d  x         \leq(b-a)e^{n(f(x_{0})-\eta)}+e^{nf(x_{0})}\int_{x_{0}-\delta}^{x_{0}+\delta}e%
 ^{\frac{n}{2}(f^{\prime\prime}(x_{0})+\varepsilon)(x-x_{0})^{2}}\,dx\leq(b-a)e%
 ^{n(f(x_{0})-\eta)}+e^{nf(x_{0})}\int_{-\infty}^{+\infty}e^{\frac{n}{2}(f^{%
 \prime\prime}(x_{0})+\varepsilon)(x-x_{0})^{2}}\,dx          ≤     (   b  -  a   )    e   n   (    f   (   x  0   )    -  η   )      +    e   n  f   (   x  0   )        2  π    n   (    -    f  ′′    (   x  0   )     -  ε   )            absent        b  a    superscript  e    n      f   subscript  x  0    η         superscript  e    n  f   subscript  x  0           2  π     n         superscript  f  ′′    subscript  x  0     ε          \leq(b-a)e^{n(f(x_{0})-\eta)}+e^{nf(x_{0})}\sqrt{\frac{2\pi}{n(-f^{\prime%
 \prime}(x_{0})-\varepsilon)}}     If we divide both sides of the above inequality by     e   n  f   (   x  0   )        2  π    n   (   -    f  ′′    (   x  0   )     )           superscript  e    n  f   subscript  x  0           2  π     n       superscript  f  ′′    subscript  x  0          e^{nf(x_{0})}\sqrt{\frac{2\pi}{n(-f^{\prime\prime}(x_{0}))}}   and take the limit we get:        lim   n  →   +  ∞      (     ∫  a  b      e   n  f   (  x  )      d  x     (    e   n  f   (   x  0   )        2  π    n   (   -    f  ′′    (   x  0   )     )       )    )    ≤    lim   n  →   +  ∞      (     (   b  -  a   )    e   -   η  n        n   (   -    f  ′′    (   x  0   )     )     2  π      +     -    f  ′′    (   x  0   )       -    f  ′′    (   x  0   )     -  ε      )    =     -    f  ′′    (   x  0   )       -    f  ′′    (   x  0   )     -  ε             subscript    normal-→  n            superscript   subscript   a   b      superscript  e    n  f  x    d  x       superscript  e    n  f   subscript  x  0           2  π     n       superscript  f  ′′    subscript  x  0             subscript    normal-→  n              b  a    superscript  e      η  n           n       superscript  f  ′′    subscript  x  0        2  π               superscript  f  ′′    subscript  x  0            superscript  f  ′′    subscript  x  0     ε                     superscript  f  ′′    subscript  x  0            superscript  f  ′′    subscript  x  0     ε        \lim_{n\to+\infty}\left(\frac{\int_{a}^{b}e^{nf(x)}\,dx}{\left(e^{nf(x_{0})}%
 \sqrt{\frac{2\pi}{n(-f^{\prime\prime}(x_{0}))}}\right)}\right)\leq\lim_{n\to+%
 \infty}\left((b-a)e^{-\eta n}\sqrt{\frac{n(-f^{\prime\prime}(x_{0}))}{2\pi}}+%
 \sqrt{\frac{-f^{\prime\prime}(x_{0})}{-f^{\prime\prime}(x_{0})-\varepsilon}}%
 \right)=\sqrt{\frac{-f^{\prime\prime}(x_{0})}{-f^{\prime\prime}(x_{0})-%
 \varepsilon}}     Since   ε   ε   \varepsilon   is arbitrary we get the upper bound:        lim   n  →   +  ∞      (     ∫  a  b      e   n  f   (  x  )      d  x     (    e   n  f   (   x  0   )        2  π    n   (   -    f  ′′    (   x  0   )     )       )    )    ≤  1        subscript    normal-→  n            superscript   subscript   a   b      superscript  e    n  f  x    d  x       superscript  e    n  f   subscript  x  0           2  π     n       superscript  f  ′′    subscript  x  0           1    \lim_{n\to+\infty}\left(\frac{\int_{a}^{b}e^{nf(x)}\,dx}{\left(e^{nf(x_{0})}%
 \sqrt{\frac{2\pi}{n(-f^{\prime\prime}(x_{0}))}}\right)}\right)\leq 1     And combining this with the lower bound gives the result.  Note that the above proof obviously fails when    a  =   -  ∞       a        a=-\infty   or    b  =  ∞      b     b=\infty   (or both). To deal with these cases, we need some extra assumptions. A sufficient (not necessary) assumption is that for    n  =  1      n  1    n=1   , the integral     ∫  a  b      e   n  f   (  x  )      d  x       superscript   subscript   a   b      superscript  e    n  f  x    d  x     \int_{a}^{b}e^{nf(x)}\,dx   is finite, and that the number   η   η   \eta   as above exists (note that this must be an assumption in the case when the interval    [  a  ,  b  ]     a  b    [a,b]   is infinite). The proof proceeds otherwise as above, but the integrals        ∫  a    x  0   -  δ       e   n  f   (  x  )      d  x    +    ∫    x  0   +  δ   b      e   n  f   (  x  )      d  x          superscript   subscript   a      subscript  x  0   δ       superscript  e    n  f  x    d  x      superscript   subscript      subscript  x  0   δ    b      superscript  e    n  f  x    d  x      \int_{a}^{x_{0}-\delta}e^{nf(x)}\,dx+\int_{x_{0}+\delta}^{b}e^{nf(x)}\,dx     must be approximated by         ∫  a    x  0   -  δ       e   n  f   (  x  )      d  x    +    ∫    x  0   +  δ   b      e   n  f   (  x  )      d  x     ≤    ∫  a  b     e   f   (  x  )       e    (   n  -  1   )    (    f   (   x  0   )    -  η   )      d  x    =    e    (   n  -  1   )    (    f   (   x  0   )    -  η   )       ∫  a  b      e   f   (  x  )      d  x               superscript   subscript   a      subscript  x  0   δ       superscript  e    n  f  x    d  x      superscript   subscript      subscript  x  0   δ    b      superscript  e    n  f  x    d  x       superscript   subscript   a   b      superscript  e    f  x     superscript  e      n  1       f   subscript  x  0    η     d  x            superscript  e      n  1       f   subscript  x  0    η       superscript   subscript   a   b      superscript  e    f  x    d  x        \int_{a}^{x_{0}-\delta}e^{nf(x)}\,dx+\int_{x_{0}+\delta}^{b}e^{nf(x)}\,dx\leq%
 \int_{a}^{b}e^{f(x)}e^{(n-1)(f(x_{0})-\eta)}\,dx=e^{(n-1)(f(x_{0})-\eta)}\int_%
 {a}^{b}e^{f(x)}\,dx     instead of     (   b  -  a   )    e   n   (    f   (   x  0   )    -  η   )           b  a    superscript  e    n      f   subscript  x  0    η       (b-a)e^{n(f(x_{0})-\eta)}   as above, so that when we divide by     e   n  f   (   x  0   )        2  π    n   (   -    f  ′′    (   x  0   )     )           superscript  e    n  f   subscript  x  0           2  π     n       superscript  f  ′′    subscript  x  0          e^{nf(x_{0})}\sqrt{\frac{2\pi}{n(-f^{\prime\prime}(x_{0}))}}   , we get for this term         e    (   n  -  1   )    (    f   (   x  0   )    -  η   )       ∫  a  b      e   f   (  x  )      d  x       e   n  f   (   x  0   )        2  π    n   (   -    f  ′′    (   x  0   )     )        =    e   -    (   n  -  1   )   η      n    e   -   f   (   x  0   )        ∫  a  b      e   f   (  x  )      d  x     -    f  ′′    (   x  0   )      2  π                 superscript  e      n  1       f   subscript  x  0    η       superscript   subscript   a   b      superscript  e    f  x    d  x        superscript  e    n  f   subscript  x  0           2  π     n       superscript  f  ′′    subscript  x  0             superscript  e        n  1   η       n    superscript  e      f   subscript  x  0        superscript   subscript   a   b      superscript  e    f  x    d  x           superscript  f  ′′    subscript  x  0       2  π          \frac{e^{(n-1)(f(x_{0})-\eta)}\int_{a}^{b}e^{f(x)}\,dx}{e^{nf(x_{0})}\sqrt{%
 \frac{2\pi}{n(-f^{\prime\prime}(x_{0}))}}}=e^{-(n-1)\eta}\sqrt{n}e^{-f(x_{0})}%
 \int_{a}^{b}e^{f(x)}\,dx\sqrt{\frac{-f^{\prime\prime}(x_{0})}{2\pi}}     whose limit as    n  →  ∞     normal-→  n     n\rightarrow\infty   is   0   0    . The rest of the proof (the analysis of the interesting term) proceeds as above.  The given condition in the infinite interval case is, as said above, sufficient but not necessary. However, the condition is fulfilled in many, if not in most, applications: the condition simply says that the integral we are studying must be well-defined (not infinite) and that the maximum of the function at    x  0     subscript  x  0    x_{0}   must be a "true" maximum (the number    η  >  0      η  0    \eta>0   must exist). There is no need to demand that the integral is finite for    n  =  1      n  1    n=1   but it is enough to demand that the integral is finite for some    n  =  N      n  N    n=N   .  This method relies on 4 basic concepts such as   1. Relative error    First of all, we need to have an understanding about the so-called “approximation” in this method is related to the relative error instead of the absolute error . Therefore, if we set      s  =     2  π    M   |    f  ′′    (   x  0   )    |          s        2  π     M       superscript  f  ′′    subscript  x  0          s=\sqrt{\frac{2\pi}{M\left|f^{\prime\prime}(x_{0})\right|}}     , this integration can be written as         ∫  a  b        e   M  f   (  x  )      d  x       superscript   subscript   a   b      superscript  e    M  f  x    d  x     \displaystyle\int_{a}^{b}\!e^{Mf(x)}\,dx     , where   s   s   s   is a small number when   M   M   M   is a large number obviously and the relative error will be       |     ∫    (   a  -   x  0    )   /  s     (   b  -   x  0    )   /  s      e   M   (    f   (    s  y   +   x  0    )    -   f   (   x  0   )     )     d  y    -  1   |   .          superscript   subscript       a   subscript  x  0    s        b   subscript  x  0    s       superscript  e    M      f      s  y    subscript  x  0       f   subscript  x  0       d  y    1     \left|\int_{(a-x_{0})/s}^{(b-x_{0})/s}e^{M(f(sy+x_{0})-f(x_{0}))}dy-1\right|.     Now, let us separate this integration into two parts    y  ∈   [   -   D  y    ,   D  y   ]       y      subscript  D  y     subscript  D  y      y\in[-D_{y},D_{y}]   region and the rest part.   2. function    e   M   (    f   (    s  y   +   x  0    )    -   f   (   x  0   )     )       superscript  e    M      f      s  y    subscript  x  0       f   subscript  x  0        e^{M\left(f(sy+x_{0})-f(x_{0})\right)}   will tend to    e   -   π   y  2        superscript  e      π   superscript  y  2       e^{-\pi y^{2}}   around the stationary point when   M   M   M   is large enough    Let’s look at the Taylor expansion of    M   (    f   (  x  )    -   f   (   x  0   )     )       M      f  x     f   subscript  x  0       M\left(f(x)-f(x_{0})\right)   around x 0 and translate x to y because we do the comparison in y-space, we will get      M   (    f   (  x  )    -   f   (   x  0   )     )       M      f  x     f   subscript  x  0       \displaystyle M\left(f(x)-f(x_{0})\right)     Note that      f  ′    (   x  0   )    =  0         superscript  f  normal-′    subscript  x  0    0    f^{\prime}(x_{0})=0   because    x  0     subscript  x  0    x_{0}   is a stationary point. From this equation you will find that the terms higher than second derivative in this Taylor expansion is suppressed as the order of    1   M       1    M     \frac{1}{\sqrt{M}}   so that    exp   (   M   (    f   (  x  )    -   f   (   x  0   )     )    )         M      f  x     f   subscript  x  0        \exp\left(M\left(f(x)-f(x_{0})\right)\right)   will get closer to the Gaussian function as shown in figure. Besides,        ∫   -  ∞   ∞     e   -   π   y  2      d  y    =  1.        superscript   subscript             superscript  e      π   superscript  y  2      d  y    1.    \int_{-\infty}^{\infty}e^{-\pi y^{2}}dy=1.     (Figure)  The figure of    e   M   [    f   (    s  y   +   x  0    )    -   f   (   x  0   )     ]       superscript  e    M   delimited-[]      f      s  y    subscript  x  0       f   subscript  x  0         e^{M[f(sy+x_{0})-f(x_{0})]}   with   M   M   M   equals 1, 2 and 3, and the red line is the curve of function    e   -   π   y  2        superscript  e      π   superscript  y  2       e^{-\pi y^{2}}   .    3. The bigger   M   M   M   is, the smaller range of   x   x   x   is related    Because we do the comparison in y-space,   y   y   y   is fixed in    y  ∈   [   -   D  y    ,   D  y   ]       y      subscript  D  y     subscript  D  y      y\in[-D_{y},D_{y}]   which will cause    x  ∈   [   -   s   D  y     ,   s   D  y    ]       x       s   subscript  D  y       s   subscript  D  y       x\in[-sD_{y},sD_{y}]   ; however,   s   s   s   is inversely proportional to    M      M    \sqrt{M}   , the chosen region of   x   x   x   will be smaller when   M   M   M   is increased.   4. If the integration used by Laplace’s method is converged, the contribution of the region which is not around the stationary point    x  0     subscript  x  0    x_{0}   of the integration of its relative error will tend to zero when   M   M   M   is increased.    Relying on the 3rd concept, even if we choose a very large D y , sD y will finally be a very small number when   M   M   M   is increased to a huge number. Then, how can we guarantee the integration of the rest part will tend to 0 when   M   M   M   is large enough?  The basic idea is trying to find a function    m   (  x  )       m  x    m(x)   which will     m   (  x  )    ≥   f   (  x  )          m  x     f  x     m(x)\geq f(x)   and the integration of    e   M  m   (  x  )       superscript  e    M  m  x     e^{Mm(x)}   will tend to zero when   M   M   M   is increased. Because the exponential function of    M  m   (  x  )       M  m  x    Mm(x)   will be always larger than zero as long as    m   (  x  )       m  x    m(x)   is a real number, and this exponential function is proportional to    m   (  x  )       m  x    m(x)   , the integration of    e   M  f   (  x  )       superscript  e    M  f  x     e^{Mf(x)}   will tend to zero. For simplicity, let me choose    m   (  x  )       m  x    m(x)   as a tangent through the point    x  =   s   D  y        x    s   subscript  D  y      x=sD_{y}   as shown in the figure:  (Figure)      m   (  x  )       m  x    m(x)   is denoted by the two tangent lines passing through    x  =    ±   s   D  y     +   x  0        x     plus-or-minus    s   subscript  D  y      subscript  x  0      x=\pm sD_{y}+x_{0}   . When    s   D  y       s   subscript  D  y     sD_{y}   gets smaller, the cover region will be larger.   If the interval of the integration of this method is finite, we will find that no matter    f   (  x  )       f  x    f(x)   is continue in the rest region, it will be always smaller than    m   (  x  )       m  x    m(x)   shown above when   M   M   M   is large enough. By the way, it will be proved later that the integration of    e   M  m   (  x  )       superscript  e    M  m  x     e^{Mm(x)}   will tend to zero when   M   M   M   is large enough.  If the interval of the integration of this method is infinite,    m   (  x  )       m  x    m(x)   and    f   (  x  )       f  x    f(x)   might always cross to each other. If so, we cannot guarantee that the integration of    e   M  f   (  x  )       superscript  e    M  f  x     e^{Mf(x)}   will tend to zero finally. For example, in the case of     f   (  x  )    =    s  i  n   (  x  )    x         f  x       s  i  n  x   x     f(x)=\frac{sin(x)}{x}   ,     ∫  0  ∞     e   M  f   (  x  )     d  x       subscript   superscript     0      superscript  e    M  f  x    d  x     \int^{\infty}_{0}e^{Mf(x)}dx   will be always diverged. Therefore, we need to require that     ∫  d  ∞     e   M  f   (  x  )     d  x       subscript   superscript     d      superscript  e    M  f  x    d  x     \int^{\infty}_{d}e^{Mf(x)}dx   can converge for the infinite interval case. If so, this integration will tend to zero when   d   d   d   is large enough and we can choose this   d   d   d   as the cross of    m   (  x  )       m  x    m(x)   and    f   (  x  )       f  x    f(x)   .  You might ask that why not choose     ∫  d  ∞     e   f   (  x  )     d  x       subscript   superscript     d      superscript  e    f  x    d  x     \int^{\infty}_{d}e^{f(x)}dx   as a convergent integration? Let me use an example to show you the reason. Suppose the rest part of    f   (  x  )       f  x    f(x)   is    -   ln  x         x     -\ln x   , then     e   f   (  x  )     =   1  x        superscript  e    f  x      1  x     e^{f(x)}=\frac{1}{x}   and its integration will diverge; however, when    M  =  2      M  2    M=2   ,the integration of     e   M  f   (  x  )     =   1   x  2         superscript  e    M  f  x      1   superscript  x  2      e^{Mf(x)}=\frac{1}{x^{2}}   converges. So, the integrations of some functions will diverge when   M   M   M   is not a large number, but they will converge when   M   M   M   is large enough.  Based on these four concepts, we can derive the relative error of this Laplace's method.  Other formulations  Laplace's approximation is sometimes written as         ∫  a  b     h   (  x  )     e   M  g   (  x  )      d  x    ≈      2  π    M   |    g  ′′    (   x  0   )    |      h   (   x  0   )    e   M  g   (   x  0   )     as  M   →   ∞           superscript   subscript   a   b     h  x   superscript  e    M  g  x    d  x            2  π     M       superscript  g  ′′    subscript  x  0        h   subscript  x  0    superscript  e    M  g   subscript  x  0     as  M     normal-→        \int_{a}^{b}\!h(x)e^{Mg(x)}\,dx\approx\sqrt{\frac{2\pi}{M|g^{\prime\prime}(x_{%
 0})|}}h(x_{0})e^{Mg(x_{0})}\text{ as }M\to\infty\,     where   h   h   h   is positive.  Importantly, the accuracy of the approximation depends on the variable of integration, that is, on what stays in    g   (  x  )       g  x    g(x)   and what goes into    h   (  x  )       h  x    h(x)   . 1 First of all, let me set the global maximum is located at     x  0   =  0       subscript  x  0   0    x_{0}=0   which can simplify the derivation and does not lost any important information; therefore, all the derivation inside this sub-section is under this assumption. Besides, what we want is the relative error    |  R  |      R    \left|R\right|   as shown below          ∫  a  b     h   (  x  )     e   M  g   (  x  )      d  x    =   h   (  0  )    e   M  g   (  0  )     s      ∫   a  /  s    b  /  s       h   (  x  )     h   (  0  )      e   M   [    g   (   s  y   )    -   g   (  0  )     ]     d  y    ⏟    1  +  R      ,        superscript   subscript   a   b     h  x   superscript  e    M  g  x    d  x      h  0   superscript  e    M  g  0    s   subscript   normal-⏟    superscript   subscript     a  s      b  s          h  x     h  0     superscript  e    M   delimited-[]      g    s  y      g  0       d  y       1  R       \int_{a}^{b}\!h(x)e^{Mg(x)}\,dx=h(0)e^{Mg(0)}s\underbrace{\int_{a/s}^{b/s}%
 \frac{h(x)}{h(0)}e^{M\left[g(sy)-g(0)\right]}dy}_{1+R},     where    s  ≡     2  π    M   |    g  ′′    (  0  )    |          s        2  π     M       superscript  g  ′′   0         s\equiv\sqrt{\frac{2\pi}{M\left|g^{\prime\prime}(0)\right|}}   . So, if we let    A  ≡     h   (   s  y   )     h   (  0  )      e   M   [    g   (   s  y   )    -   g   (  0  )     ]          A        h    s  y      h  0     superscript  e    M   delimited-[]      g    s  y      g  0          A\equiv\frac{h(sy)}{h(0)}e^{M\left[g(sy)-g(0)\right]}   and     A  0   ≡   e   -   π   y  2           subscript  A  0    superscript  e      π   superscript  y  2        A_{0}\equiv e^{-\pi y^{2}}   , we can get       |  R  |   =   |     ∫   a  /  s    b  /  s      A   d  y    -    ∫   -  ∞   ∞      A  0    d  y     |         R         superscript   subscript     a  s      b  s      A  d  y      superscript   subscript             subscript  A  0   d  y        \left|R\right|=\left|\int_{a/s}^{b/s}A\,dy-\int_{-\infty}^{\infty}A_{0}\,dy\right|     since      ∫   -  ∞   ∞      A  0    d  y    =  1        superscript   subscript             subscript  A  0   d  y    1    \int_{-\infty}^{\infty}A_{0}\,dy=1   . Now, let us find its upper bound.  Owing to     |   A  +  B   |   ≤    |  A  |   +   |  B  |            A  B        A     B      \left|A+B\right|\leq|A|+|B|   , we can separate this integration into 5 parts with 3 different types (a), (b) and (c), respectively. Therefore,       |  R  |   <      |    ∫   D  y   ∞     A  0   d  y    |   ⏟    (   a  1   )    +     |    ∫   D  y    b  /  s     A  d  y    |   ⏟    (   b  1   )    +     |    ∫   -   D  y     D  y      (   A  -   A  0    )   d  y    |   ⏟    (  c  )    +     |    ∫   a  /  s    -   D  y      A  d  y    |   ⏟    (   b  2   )    +     |    ∫   -  ∞    -   D  y       A  0   d  y    |   ⏟    (   a  2   )           R      subscript   normal-⏟      superscript   subscript    subscript  D  y         subscript  A  0   d  y       subscript  a  1     subscript   normal-⏟      superscript   subscript    subscript  D  y      b  s      A  d  y       subscript  b  1     subscript   normal-⏟      superscript   subscript      subscript  D  y      subscript  D  y        A   subscript  A  0    d  y      c    subscript   normal-⏟      superscript   subscript     a  s       subscript  D  y       A  d  y       subscript  b  2     subscript   normal-⏟      superscript   subscript           subscript  D  y        subscript  A  0   d  y       subscript  a  2       |R|<\underbrace{\left|\int_{D_{y}}^{\infty}A_{0}dy\right|}_{(a_{1})}+%
 \underbrace{\left|\int_{D_{y}}^{b/s}Ady\right|}_{(b_{1})}+\underbrace{\left|%
 \int_{-D_{y}}^{D_{y}}\left(A-A_{0}\right)dy\right|}_{(c)}+\underbrace{\left|%
 \int_{a/s}^{-D_{y}}Ady\right|}_{(b_{2})}+\underbrace{\left|\int_{-\infty}^{-D_%
 {y}}A_{0}dy\right|}_{(a_{2})}     where    (   a  1   )     subscript  a  1    (a_{1})   and    (   a  2   )     subscript  a  2    (a_{2})   are similar, let us just calculate    (   a  1   )     subscript  a  1    (a_{1})   , and    (   b  1   )     subscript  b  1    (b_{1})   and    (   b  2   )     subscript  b  2    (b_{2})   are similar, too, I’ll just calculate    (   b  1   )     subscript  b  1    (b_{1})   .  For    (   a  1   )     subscript  a  1    (a_{1})   , after the translation of    z  ≡   π   y  2        z    π   superscript  y  2      z\equiv\pi y^{2}   , we can get        (   a  1   )   =   |    1   2   π       ∫   π   D  y  2    ∞     e   -  z     z   -   1  /  2     d  z     |   <    e   -   π   D  y  2       2  π   D  y      .         subscript  a  1         1    2    π       superscript   subscript     π   superscript   subscript  D  y   2          superscript  e    z     superscript  z      1  2     d  z              superscript  e      π   superscript   subscript  D  y   2        2  π   subscript  D  y        (a_{1})=\left|\frac{1}{2\sqrt{\pi}}\int_{\pi D_{y}^{2}}^{\infty}e^{-z}z^{-1/2}%
 dz\right|<\frac{e^{-\pi D_{y}^{2}}}{2\pi D_{y}}.     This means that as long as    D  y     subscript  D  y    D_{y}   is large enough, it will tend to zero.  For    (   b  1   )     subscript  b  1    (b_{1})   , we can get       (   b  1   )   ≤   |    ∫   D  y    b  /  s       [    h   (   s  y   )     h   (  0  )     ]   max    e   M  m   (   s  y   )     d  y    |        subscript  b  1       superscript   subscript    subscript  D  y      b  s       subscript   delimited-[]      h    s  y      h  0     max    superscript  e    M  m    s  y     d  y       (b_{1})\leq\left|\int_{D_{y}}^{b/s}\left[\frac{h(sy)}{h(0)}\right]_{\text{max}%
 }e^{Mm(sy)}dy\right|     where       m   (  x  )    ≥      1  M    ln    h   (  x  )     h   (  0  )       +   g   (  x  )     -   g   (  0  )    as   x    ∈   [   s   D  y    ,  b  ]           m  x           1  M         h  x     h  0        g  x      g  0  as  x            s   subscript  D  y    b      m(x)\geq\frac{1}{M}\ln{\frac{h(x)}{h(0)}}+g(x)-g(0)\,\,\text{as}\,\,x\in[sD_{y%
 },b]     and    h   (  x  )       h  x    h(x)   should have the same sign of    h   (  0  )       h  0    h(0)   during this region. Let us choose    m   (  x  )       m  x    m(x)   as the tangent across the point at    x  =   s   D  y        x    s   subscript  D  y      x=sD_{y}   , i.e.     m   (   s  y   )    =     g   (   s   D  y    )    -   g   (  0  )     +    g  ′    (   s   D  y    )    (    s  y   -   s   D  y     )           m    s  y          g    s   subscript  D  y       g  0       superscript  g  normal-′     s   subscript  D  y        s  y     s   subscript  D  y         m(sy)=g(sD_{y})-g(0)+g^{\prime}(sD_{y})\left(sy-sD_{y}\right)   which is shown in the figure  (Figure)      m   (  x  )       m  x    m(x)   is the tangent lines across the point at    x  =   s   D  y        x    s   subscript  D  y      x=sD_{y}   .   From this figure you can find that when   s   s   s   or    D  y     subscript  D  y    D_{y}   gets smaller, the region satisfies the above inequality will get larger. Therefore, if we want to find a suitable    m   (  x  )       m  x    m(x)   to cover the whole    f   (  x  )       f  x    f(x)   during the interval of    (   b  1   )     subscript  b  1    (b_{1})   ,    D  y     subscript  D  y    D_{y}   will have an upper limit. Besides, because the integration of    e   -   α  x       superscript  e      α  x      e^{-\alpha x}   is simple, let me use it to estimate the relative error contributed by this    (   b  1   )     subscript  b  1    (b_{1})   .  Based on Taylor expansion, we can get      M   [    g   (   s   D  y    )    -   g   (  0  )     ]       M   delimited-[]      g    s   subscript  D  y       g  0       \displaystyle M\left[g(sD_{y})-g(0)\right]     and      M  s   g  ′    (   s   D  y    )       M  s   superscript  g  normal-′     s   subscript  D  y      \displaystyle Msg^{\prime}(sD_{y})     and then substitute them back into the calculation of    (   b  1   )     subscript  b  1    (b_{1})   ; however, you can find that the remainders of these two expansions are both inversely proportional to the square root of   M   M   M   , let me drop them out to beautify the calculation. Keeping them is better, but it will make the formula uglier.      (   b  1   )     subscript  b  1    \displaystyle(b_{1})     Therefore, it will tend to zero when    D  y     subscript  D  y    D_{y}   gets larger, but don't forget that the upper bound of    D  y     subscript  D  y    D_{y}   should be considered during this calculation.  About the integration near    x  =  0      x  0    x=0   , we can also use Taylor's Theorem to calculate it. When      h  ′    (  0  )    ≠  0         superscript  h  normal-′   0   0    h^{\prime}(0)\neq 0         (  c  )    c   \displaystyle(c)     and you can find that it is inversely proportional to the square root of   M   M   M   . In fact,    (  c  )    c   (c)   will have the same behave when    h   (  x  )       h  x    h(x)   is a constant.  Conclusively, the integration near the stationary point will get smaller when    M      M    \sqrt{M}   gets larger, and the rest parts will tend to zero as long as    D  y     subscript  D  y    D_{y}   is large enough; however, we need to remember that    D  y     subscript  D  y    D_{y}   has an upper limit which is decided by whether the function    m   (  x  )       m  x    m(x)   is always larger than     g   (  x  )    -   g   (  0  )          g  x     g  0     g(x)-g(0)   during this rest region. However, as long as we can find one    m   (  x  )       m  x    m(x)   satisfies this condition, the upper bound of    D  y     subscript  D  y    D_{y}   can be chosen as directly proportional to    M      M    \sqrt{M}   since    m   (  x  )       m  x    m(x)   is a tangent across the point of     g   (  x  )    -   g   (  0  )          g  x     g  0     g(x)-g(0)   at    x  =   s   D  y        x    s   subscript  D  y      x=sD_{y}   . So, the bigger   M   M   M   is, the bigger    D  y     subscript  D  y    D_{y}   can be.  In the multivariate case where   𝐱   𝐱   \mathbf{x}   is a   d   d   d   -dimensional vector and    f   (  𝐱  )       f  𝐱    f(\mathbf{x})   is a scalar function of   𝐱   𝐱   \mathbf{x}   , Laplace's approximation is usually written as:       ∫     e   M  f   (  𝐱  )      d  𝐱    ≈     (    2  π   M   )    d  /  2      |   -   H   (  f  )    (   𝐱  0   )     |    -   1  /  2      e   M  f   (   𝐱  0   )     as  M   →   ∞              superscript  e    M  f  𝐱    d  𝐱       superscript      2  π   M     d  2     superscript        H  f   subscript  𝐱  0          1  2      superscript  e    M  f   subscript  𝐱  0     as  M     normal-→        \int e^{Mf(\mathbf{x})}\,d\mathbf{x}\approx\left(\frac{2\pi}{M}\right)^{d/2}|-%
 H(f)(\mathbf{x}_{0})|^{-1/2}e^{Mf(\mathbf{x}_{0})}\text{ as }M\to\infty\,     where    H   (  f  )    (   𝐱  0   )       H  f   subscript  𝐱  0     H(f)(\mathbf{x}_{0})   is the Hessian matrix of   f   f   f   evaluated at    𝐱  0     subscript  𝐱  0    \mathbf{x}_{0}   and where    |  ⋅  |     fragments  normal-|  normal-⋅  normal-|    |\cdot|   denotes matrix determinant . Analogously to the univariate case, the Hessian is required to be negative definite . 2  By the way, although   𝐱   𝐱   \mathbf{x}   denotes a   d   d   d   -dimensional vector, the term    d  𝐱      d  𝐱    d\mathbf{x}   denotes an Infinitesimal volume here, i.e.     d  𝐱   :=   d   x  1   d   x  2   ⋯  d   x  d       assign    d  𝐱     d   subscript  x  1   d   subscript  x  2   normal-⋯  d   subscript  x  d      d\mathbf{x}:=dx_{1}dx_{2}\cdots dx_{d}   .  Laplace's method extension: Steepest descent  In extensions of Laplace's method, complex analysis , and in particular Cauchy's integral formula , is used to find a contour of steepest descent for an (asymptotically with large M ) equivalent integral, expressed as a line integral . In particular, if no point x 0 where the derivative of ƒ vanishes exists on the real line, it may be necessary to deform the integration contour to an optimal one, where the above analysis will be possible. Again the main idea is to reduce, at least asymptotically, the calculation of the given integral to that of a simpler integral that can be explicitly evaluated. See the book of Erdelyi (1956) for a simple discussion (where the method is termed steepest descents ).  The appropriate formulation for the complex z -plane is          ∫  a  b       e   M  f   (  z  )      d  z    ≈      2  π    -   M   f  ′′    (   z  0   )        e   M  f   (   z  0   )     as  M   →  ∞   .          superscript   subscript   a   b      superscript  e    M  f  z    d  z            2  π       M   superscript  f  ′′    subscript  z  0        superscript  e    M  f   subscript  z  0     as  M     normal-→        \int_{a}^{b}\!e^{Mf(z)}\,dz\approx\sqrt{\frac{2\pi}{-Mf^{\prime\prime}(z_{0})}%
 }e^{Mf(z_{0})}\text{ as }M\to\infty.\,   for a path passing through the saddle point at z 0 . Note the explicit appearance of a minus sign to indicate the direction of the second derivative: one must not take the modulus. Also note that if the integrand is meromorphic , one may have to add residues corresponding to poles traversed while deforming the contour (see for example section 3 of Okounkov's paper Symmetric functions and random partitions ).  Further generalizations  An extension of the steepest descent method is the so-called nonlinear stationary phase/steepest descent method . Here, instead of integrals, one needs to evaluate asymptotically solutions of Riemann–Hilbert factorization problems.  Given a contour C in the complex sphere , a function ƒ defined on that contour and a special point, say infinity, one seeks a function M holomorphic away from the contour C , with prescribed jump across C , and with a given normalization at infinity. If ƒ and hence M are matrices rather than scalars this is a problem that in general does not admit an explicit solution.  An asymptotic evaluation is then possible along the lines of the linear stationary phase/steepest descent method. The idea is to reduce asymptotically the solution of the given Riemann–Hilbert problem to that of a simpler, explicitly solvable, Riemann–Hilbert problem. Cauchy's theorem is used to justify deformations of the jump contour.  The nonlinear stationary phase was introduced by Deift and Zhou in 1993, based on earlier work of Its. A (properly speaking) nonlinear steepest descent method was introduced by Kamvissis, K. McLaughlin and P. Miller in 2003, based on previous work of Lax, Levermore, Deift, Venakides and Zhou.  The nonlinear stationary phase/steepest descent method has applications to the theory of soliton equations and integrable models , random matrices and combinatorics .  Complex integrals  For complex integrals in the form:       1   2  π  i      ∫   c  -   i  ∞     c  +   i  ∞      g   (  s  )     e   s  t     d  s          1    2  π  i      superscript   subscript     c    i        c    i        g  s   superscript  e    s  t    d  s      \frac{1}{2\pi i}\int_{c-i\infty}^{c+i\infty}g(s)e^{st}\,ds     with t >> 1, we make the substitution t = iu and the change of variable s = c + ix to get the Laplace bilateral transform:        1   2  π      ∫   -  ∞   ∞    g   (   c  +   i  x    )    e   -   u  x       e   i  c  u     d  x     .        1    2  π      superscript   subscript            g    c    i  x     superscript  e      u  x      superscript  e    i  c  u    d  x      \frac{1}{2\pi}\int_{-\infty}^{\infty}g(c+ix)e^{-ux}e^{icu}\,dx.     We then split g ( c + ix ) in its real and complex part, after which we recover u = t / i . This is useful for inverse Laplace transforms , the Perron formula and complex integration.  Example 1: Stirling's approximation  Laplace's method can be used to derive Stirling's approximation       N  !   ≈     2  π  N     N  N     e   -  N            N         2  π  N     superscript  N  N    superscript  e    N       N!\approx\sqrt{2\pi N}N^{N}e^{-N}\,   for a large integer  N .  From the definition of the Gamma function , we have        N  !   =   Γ   (   N  +  1   )    =    ∫  0  ∞     e   -  x      x  N    d  x     .          N     normal-Γ    N  1           superscript   subscript   0        superscript  e    x     superscript  x  N   d  x       N!=\Gamma(N+1)=\int_{0}^{\infty}e^{-x}x^{N}\,dx.     Now we change variables, letting        x  =   N   z        x    N  z     x=Nz\,        so that          d  x   =    N   d  z    .        d  x     N  d  z     dx=N\,dz.        Plug these values back in to obtain      N  !      N    \displaystyle N!     This integral has the form necessary for Laplace's method with       f   (  z  )    =    ln  z   -  z         f  z       z   z     f\left(z\right)=\ln{z}-z   which is twice-differentiable:         f  ′    (  z  )    =    1  z   -  1    ,         superscript  f  normal-′   z       1  z   1     f^{\prime}(z)=\frac{1}{z}-1,\,            f  ′′    (  z  )    =   -   1   z  2      .         superscript  f  ′′   z       1   superscript  z  2       f^{\prime\prime}(z)=-\frac{1}{z^{2}}.\,   The maximum of ƒ ( z ) lies at z 0 = 1, and the second derivative of ƒ ( z ) has the value −1 at this point. Therefore, we obtain        N  !   ≈    N   N  +  1       2  π   N     e   -  N     =     2  π  N     N  N    e   -  N      .          N      superscript  N    N  1          2  π   N     superscript  e    N                2  π  N     superscript  N  N    superscript  e    N        N!\approx N^{N+1}\sqrt{\frac{2\pi}{N}}e^{-N}=\sqrt{2\pi N}N^{N}e^{-N}.\,     Example 2: parameter estimation and probabilistic inference  reviews Laplace's method results ( univariate and multivariate ) and presents a detailed example showing the method used in parameter estimation and probabilistic  inference under a Bayesian perspective. Laplace's method is applied to a meta-analysis problem from the medical domain, involving experimental data , and compared to other techniques.  See also   Method of stationary phase  Large deviations theory  Laplace principle (large deviations theory)   Notes  References    .   .   .   .   .  Laplace, P. S. (1774). Memoir on the probability of causes of events. Mémoires de Mathématique et de Physique, Tome Sixième. (English translation by S. M. Stigler 1986. Statist. Sci., 1(19):364–378).   "  Category:Asymptotic analysis  Category:Perturbation theory     ↩  ↩     