<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="1264">Deep learning</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>Deep learning</h1>
<hr/>

<p><strong>Deep learning</strong> (<em>deep machine learning</em>, or <em>deep structured learning</em>, or <em>hierarchical learning</em>, or sometimes <em>DL</em>) is a branch of <a href="machine_learning" title="wikilink">machine learning</a> based on a set of <a href="algorithm" title="wikilink">algorithms</a> that attempt to model high-level abstractions in data by using model architectures, with complex structures or otherwise, composed of multiple non-<a href="linear_transformation" title="wikilink">linear transformations</a>.<a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a><a class="footnoteRef" href="#fn2" id="fnref2"><sup>2</sup></a><a class="footnoteRef" href="#fn3" id="fnref3"><sup>3</sup></a><a class="footnoteRef" href="#fn4" id="fnref4"><sup>4</sup></a></p>

<p>Deep learning is part of a broader family of <a href="machine_learning" title="wikilink">machine learning</a> methods based on <a href="learning_representation" title="wikilink">learning representations</a> of data. An observation (e.g., an image) can be represented in many ways such as a <a href="Vector_space" title="wikilink">vector</a> of intensity values per pixel, or in a more abstract way as a set of edges, regions of particular shape, <a href="Scale-invariant_feature_transform" title="wikilink">etc.</a>. Some representations make it easier to learn tasks (e.g., face recognition or facial expression recognition<a class="footnoteRef" href="#fn5" id="fnref5"><sup>5</sup></a>) from examples. One of the promises of deep learning is replacing handcrafted <a href="Feature_(machine_learning)" title="wikilink">features</a> with efficient algorithms for <a href="Unsupervised_learning" title="wikilink">unsupervised</a> or <a href="Semi-supervised_learning" title="wikilink">semi-supervised</a> <a href="feature_learning" title="wikilink">feature learning</a> and hierarchical <a href="feature_extraction" title="wikilink">feature extraction</a>.<a class="footnoteRef" href="#fn6" id="fnref6"><sup>6</sup></a></p>

<p>Research in this area attempts to make better representations and create models to learn these representations from large-scale unlabeled data. Some of the representations are inspired by advances in <a class="uri" href="neuroscience" title="wikilink">neuroscience</a> and are loosely based on interpretation of information processing and communication patterns in a <a href="nervous_system" title="wikilink">nervous system</a>, such as <a href="neural_coding" title="wikilink">neural coding</a> which attempts to define a relationship between the stimulus and the neuronal responses and the relationship among the electrical activity of the neurons in the <a class="uri" href="brain" title="wikilink">brain</a>.<a class="footnoteRef" href="#fn7" id="fnref7"><sup>7</sup></a></p>

<p>Various deep learning architectures such as <a href="#Deep_neural_networks" title="wikilink">deep neural networks</a>, <a href="convolutional_neural_network" title="wikilink">convolutional deep neural networks</a>, <a href="deep_belief_network" title="wikilink">deep belief networks</a> and <a href="recurrent_neural_network" title="wikilink">recurrent neural networks</a> have been applied to fields like <a href="computer_vision" title="wikilink">computer vision</a>, <a href="automatic_speech_recognition" title="wikilink">automatic speech recognition</a>, <a href="natural_language_processing" title="wikilink">natural language processing</a>, audio recognition and <a class="uri" href="bioinformatics" title="wikilink">bioinformatics</a> where they have been shown to produce state-of-the-art results on various tasks.</p>

<p>Alternatively, <em>deep learning</em> has been characterized as a <a class="uri" href="buzzword" title="wikilink">buzzword</a>, or a rebranding of <a href="neural_network" title="wikilink">neural networks</a>.<a class="footnoteRef" href="#fn8" id="fnref8"><sup>8</sup></a><a class="footnoteRef" href="#fn9" id="fnref9"><sup>9</sup></a></p>
<h2 id="introduction">Introduction</h2>
<h3 id="definitions">Definitions</h3>

<p>There are a number of ways that the field of deep learning has been characterized. Deep learning is a class of <a href="machine_learning" title="wikilink">machine learning</a> <a href="algorithm" title="wikilink">algorithms</a> that<a class="footnoteRef" href="#fn10" id="fnref10"><sup>10</sup></a></p>
<ul>
<li>use a cascade of many layers of <a href="Nonlinear_filter" title="wikilink">nonlinear processing</a> units for <a href="feature_extraction" title="wikilink">feature extraction</a> and transformation. Each successive layer uses the output from the previous layer as input. The algorithms may be <a href="Supervised_learning" title="wikilink">supervised</a> or <a href="Unsupervised_learning" title="wikilink">unsupervised</a> and applications include pattern analysis (unsupervised) and classification (supervised).</li>
<li>are based on the (unsupervised) learning of multiple levels of features or representations of the data. Higher level features are derived from lower level features to form a hierarchical representation.</li>
<li>are part of the broader machine learning field of learning representations of data.</li>
<li>learn multiple levels of representations that correspond to different levels of abstraction; the levels form a hierarchy of concepts.</li>
</ul>

<p>These definitions have in common (1) multiple layers of nonlinear processing units and (2) the supervised or unsupervised learning of feature representations in each layer, with the layers forming a hierarchy from low-level to high-level features.<a class="footnoteRef" href="#fn11" id="fnref11"><sup>11</sup></a> The composition of a layer of nonlinear processing units used in a deep learning algorithm depends on the problem to be solved. Layers that have been used in deep learning include hidden layers of an <a href="artificial_neural_network" title="wikilink">artificial neural network</a> and sets of complicated <a href="propositional_formula" title="wikilink">propositional formulas</a>.<a class="footnoteRef" href="#fn12" id="fnref12"><sup>12</sup></a> They may also include latent variables organized layer-wise in deep generative models such as the nodes in Deep Belief Networks and Deep Boltzmann Machines.</p>

<p>Deep learning algorithms are contrasted with shallow learning algorithms by the number of parameterized transformations a signal encounters as it propagates from the input layer to the output layer, where a parameterized transformation is a processing unit that has trainable parameters, such as weights and thresholds.<a class="footnoteRef" href="#fn13" id="fnref13"><sup>13</sup></a> A chain of transformations from input to output is a <em>credit assignment path</em> (CAP). CAPs describe potentially causal connections between input and output and may vary in length. For a feedforward neural network, the depth of the CAPs, and thus the depth of the network, is the number of hidden layers plus one (the output layer is also parameterized). For <a href="recurrent_neural_network" title="wikilink">recurrent neural networks</a>, in which a signal may propagate through a layer more than once, the CAP is potentially unlimited in length. There is no universally agreed upon threshold of depth dividing shallow learning from deep learning, but most researchers in the field agree that deep learning has multiple nonlinear layers (CAP &gt; 2) and Schmidhuber considers CAP &gt; 10 to be very deep learning.<a class="footnoteRef" href="#fn14" id="fnref14"><sup>14</sup></a></p>
<h3 id="fundamental-concepts">Fundamental concepts</h3>

<p>Deep learning algorithms are based on distributed representations. The underlying assumption behind distributed representations is that observed data is generated by the interactions of many different factors on different levels. Deep learning adds the assumption that these factors are organized into multiple levels, corresponding to different levels of abstraction or composition. Varying numbers of layers and layer sizes can be used to provide different amounts of abstraction.<a class="footnoteRef" href="#fn15" id="fnref15"><sup>15</sup></a></p>

<p>Deep learning algorithms in particular exploit this idea of hierarchical explanatory factors. Different concepts are learned from other concepts, with the more abstract, higher level concepts being learned from the lower level ones. These architectures are often constructed with a <a href="greedy_algorithm" title="wikilink">greedy</a> layer-by-layer method that models this idea. Deep learning helps to disentangle these abstractions and pick out which features are useful for learning.<a class="footnoteRef" href="#fn16" id="fnref16"><sup>16</sup></a></p>

<p>For supervised learning tasks where label information is readily available in training, deep learning promotes a principle which is very different than traditional methods of machine learning. That is, rather than focusing on <a href="feature_engineering" title="wikilink">feature engineering</a> which is often labor-intensive and varies from one task to another, deep learning methods are focused on end-to-end learning based on raw features. In other words, deep learning moves away from feature engineering to a maximal extent possible. To accomplish end-to-end optimization starting with raw features and ending in labels, layered structures are often necessary. From this perspective, we can regard the use of layered structures to derive intermediate representations in deep learning as a natural consequence of raw-feature-based end-to-end learning.<a class="footnoteRef" href="#fn17" id="fnref17"><sup>17</sup></a> Understanding the connection between the above two aspects of deep learning is important to appreciate its use in several application areas, all involving supervised learning tasks (e.g., supervised speech and image recognition), as to be discussed in a later part of this article.</p>

<p>Many deep learning algorithms are framed as unsupervised learning problems. Because of this, these algorithms can make use of the unlabeled data that supervised algorithms cannot. Unlabeled data is usually more abundant than labeled data, making this an important benefit of these algorithms. The deep belief network is an example of a deep structure that can be trained in an unsupervised manner.<a class="footnoteRef" href="#fn18" id="fnref18"><sup>18</sup></a></p>
<h2 id="history">History</h2>

<p>Deep learning architectures, specifically those built from <a href="artificial_neural_networks" title="wikilink">artificial neural networks</a> (ANN), date back at least to the <a class="uri" href="Neocognitron" title="wikilink">Neocognitron</a> introduced by <a href="Kunihiko_Fukushima" title="wikilink">Kunihiko Fukushima</a> in 1980.<a class="footnoteRef" href="#fn19" id="fnref19"><sup>19</sup></a> The ANNs themselves date back even further. In 1989, <a href="Yann_LeCun" title="wikilink">Yann LeCun</a> et al. were able to apply the standard <a class="uri" href="backpropagation" title="wikilink">backpropagation</a> algorithm, which had been around since 1974,<a class="footnoteRef" href="#fn20" id="fnref20"><sup>20</sup></a> to a deep neural network with the purpose of recognizing handwritten <a href="ZIP_code" title="wikilink">ZIP codes</a> on mail. Despite the success of applying the algorithm, the time to train the network on this dataset was approximately 3 days, making it impractical for general use.<a class="footnoteRef" href="#fn21" id="fnref21"><sup>21</sup></a> Many factors contribute to the slow speed, one being due to the so-called <a href="vanishing_gradient_problem" title="wikilink">vanishing gradient problem</a> analyzed in 1991 by <a href="Sepp_Hochreiter" title="wikilink">Sepp Hochreiter</a>.<a class="footnoteRef" href="#fn22" id="fnref22"><sup>22</sup></a><a class="footnoteRef" href="#fn23" id="fnref23"><sup>23</sup></a></p>

<p>While such neural networks by 1991 were used for recognizing isolated 2-D hand-written digits, 3-D object recognition by 1991 used a 3-D model-based approach – matching 2-D images with a handcrafted 3-D object model. Juyang Weng <em>et al.</em>. proposed that a human brain does not use a monolithic 3-D object model and in 1992 they published Cresceptron,<a class="footnoteRef" href="#fn24" id="fnref24"><sup>24</sup></a><a class="footnoteRef" href="#fn25" id="fnref25"><sup>25</sup></a><a class="footnoteRef" href="#fn26" id="fnref26"><sup>26</sup></a> a method for performing 3-D object recognition directly from cluttered scenes. Cresceptron is a cascade of many layers similar to <a class="uri" href="Neocognitron" title="wikilink">Neocognitron</a>. But unlike <a class="uri" href="Neocognitron" title="wikilink">Neocognitron</a> which required the human programmer to hand-merge features, Cresceptron fully <em>automatically</em> learned an open number of unsupervised features in each layer of the cascade where each feature is represented by a convolution kernel. In addition, Cresceptron also segmented each learned object from a cluttered scene through back-analysis through the network. Max-pooling, now often adopted by deep neural networks (e.g., ImageNet tests), was first used in Cresceptron to reduce the position resolution by a factor of (2x2) to 1 through the cascade for better generalization. Because of a great lack of understanding how the brain autonomously wire its biological networks and the computational cost by ANNs then, simpler models that use task-specific handcrafted features such as <a href="Gabor_filter" title="wikilink">Gabor filter</a> and <a href="support_vector_machine" title="wikilink">support vector machines</a> (SVMs) were of popular choice of the field in the 1990s and 2000s.</p>

<p>In the long history of speech recognition, both shallow form and deep form (e.g., recurrent nets) of artificial neural networks had been explored for many years.<a class="footnoteRef" href="#fn27" id="fnref27"><sup>27</sup></a><a class="footnoteRef" href="#fn28" id="fnref28"><sup>28</sup></a><a class="footnoteRef" href="#fn29" id="fnref29"><sup>29</sup></a> But these methods never won over the non-uniform internal-handcrafting <a href="Mixture_model" title="wikilink">Gaussian mixture model</a>/<a href="Hidden_Markov_model" title="wikilink">Hidden Markov model</a> (GMM-HMM) technology based on generative models of speech trained discriminatively.<a class="footnoteRef" href="#fn30" id="fnref30"><sup>30</sup></a> A number of key difficulties had been methodologically analyzed, including gradient diminishing and weak temporal correlation structure in the neural predictive models.<a class="footnoteRef" href="#fn31" id="fnref31"><sup>31</sup></a><a class="footnoteRef" href="#fn32" id="fnref32"><sup>32</sup></a> All these difficulties were in addition to the lack of big training data and big computing power in these early days. Most speech recognition researchers who understood such barriers hence subsequently moved away from neural nets to pursue generative modeling approaches until the recent resurgence of deep learning that has overcome all these difficulties. Hinton et al. and Deng et al. reviewed part of this recent history about how their collaboration with each other and then with cross-group colleagues ignited the renaissance of neural networks and initiated deep learning research and applications in speech recognition.<a class="footnoteRef" href="#fn33" id="fnref33"><sup>33</sup></a><a class="footnoteRef" href="#fn34" id="fnref34"><sup>34</sup></a><a class="footnoteRef" href="#fn35" id="fnref35"><sup>35</sup></a><a class="footnoteRef" href="#fn36" id="fnref36"><sup>36</sup></a></p>

<p>The term "deep learning" gained traction in the mid-2000s after a publication by <a href="Geoffrey_Hinton" title="wikilink">Geoffrey Hinton</a> and Ruslan Salakhutdinov showed how a many-layered <a href="feedforward_neural_network" title="wikilink">feedforward neural network</a> could be effectively pre-trained one layer at a time, treating each layer in turn as an <a href="unsupervised_learning" title="wikilink">unsupervised</a> <a href="restricted_Boltzmann_machine" title="wikilink">restricted Boltzmann machine</a>, then using <a href="supervised_learning" title="wikilink">supervised</a> <a class="uri" href="backpropagation" title="wikilink">backpropagation</a> for fine-tuning.<a class="footnoteRef" href="#fn37" id="fnref37"><sup>37</sup></a> In 1992, Schmidhuber had already implemented a very similar idea for the more general case of unsupervised deep hierarchies of <a href="recurrent_neural_network" title="wikilink">recurrent neural networks</a>, and also experimentally shown its benefits for speeding up supervised learning <a class="footnoteRef" href="#fn38" id="fnref38"><sup>38</sup></a><a class="footnoteRef" href="#fn39" id="fnref39"><sup>39</sup></a></p>

<p>Since the resurgence of deep learning, it has become part of many state-of-the-art systems in different disciplines, particularly that of computer vision and <a href="automatic_speech_recognition" title="wikilink">automatic speech recognition</a> (ASR). Results on commonly used evaluation sets such as <a class="uri" href="TIMIT" title="wikilink">TIMIT</a> (ASR) and <a href="MNIST_database" title="wikilink">MNIST</a> (<a href="image_classification" title="wikilink">image classification</a>) as well as a range of large vocabulary speech recognition tasks are constantly being improved with new applications of deep learning.<a class="footnoteRef" href="#fn40" id="fnref40"><sup>40</sup></a><a class="footnoteRef" href="#fn41" id="fnref41"><sup>41</sup></a><a class="footnoteRef" href="#fn42" id="fnref42"><sup>42</sup></a> Currently, it has been shown that deep learning architectures in the form of <a href="convolutional_neural_network" title="wikilink">convolutional neural networks</a> have been nearly best performing;<a class="footnoteRef" href="#fn43" id="fnref43"><sup>43</sup></a><a class="footnoteRef" href="#fn44" id="fnref44"><sup>44</sup></a> however, these are more widely used in computer vision than in ASR.</p>

<p>The real impact of deep learning in industry started in large-scale speech recognition around 2010. In late 2009, Geoff Hinton was invited by Li Deng to work with him and colleagues at Microsoft Research in Redmond to apply deep learning to speech recognition. They co-organized the 2009 NIPS Workshop on Deep Learning for Speech Recognition. The workshop was motivated by the limitations of deep generative models of speech, and the possibility that the big-compute, big-data era warranted a serious try of the deep neural net (DNN) approach. It was then (incorrectly) believed that pre-training of DNNs using generative models of deep belief net (DBN) would be the cure for the main difficulties of neural nets encountered during 1990's.<a class="footnoteRef" href="#fn45" id="fnref45"><sup>45</sup></a> However, soon after the research along this direction started at Microsoft Research, it was discovered that when large amounts of training data are used and especially when DNNs are designed correspondingly with large, context-dependent output layers, dramatic error reduction occurred over the then-state-of-the-art GMM-HMM and more advanced generative model-based speech recognition systems without the need for generative DBN pre-training, the finding verified subsequently by several other major speech recognition research groups <a class="footnoteRef" href="#fn46" id="fnref46"><sup>46</sup></a><a class="footnoteRef" href="#fn47" id="fnref47"><sup>47</sup></a> Further, the nature of recognition errors produced by the two types of systems was found to be characteristically different,<a class="footnoteRef" href="#fn48" id="fnref48"><sup>48</sup></a><a class="footnoteRef" href="#fn49" id="fnref49"><sup>49</sup></a> offering technical insights into how to artfully integrate deep learning into the existing highly efficient, run-time speech decoding system deployed by all major players in speech recognition industry. The history of this significant development in deep learning has been described and analyzed in recent books.<a class="footnoteRef" href="#fn50" id="fnref50"><sup>50</sup></a><a class="footnoteRef" href="#fn51" id="fnref51"><sup>51</sup></a></p>

<p>Advances in hardware have also been an important enabling factor for the renewed interest of deep learning. In particular, powerful <a href="graphics_processing_unit" title="wikilink">graphics processing units</a> (GPUs) are highly suited for the kind of number crunching, matrix/vector math involved in machine learning. GPUs have been shown to speed up training algorithms by orders of magnitude, bringing running times of weeks back to days.<a class="footnoteRef" href="#fn52" id="fnref52"><sup>52</sup></a><a class="footnoteRef" href="#fn53" id="fnref53"><sup>53</sup></a></p>
<h2 id="deep-learning-in-artificial-neural-networks">Deep learning in artificial neural networks</h2>

<p>Some of the most successful deep learning methods involve artificial <a href="neural_network" title="wikilink">neural networks</a>. Artificial neural networks are inspired by the 1959 biological model proposed by <a href="Nobel_laureate" title="wikilink">Nobel laureates</a> <a href="David_H._Hubel" title="wikilink">David H. Hubel</a> &amp; <a href="Torsten_Wiesel" title="wikilink">Torsten Wiesel</a>, who found two types of cells in the <a href="primary_visual_cortex" title="wikilink">primary visual cortex</a>: <a href="simple_cell" title="wikilink">simple cells</a> and <a href="complex_cell" title="wikilink">complex cells</a>. Many artificial neural networks can be viewed as cascading models <a class="footnoteRef" href="#fn54" id="fnref54"><sup>54</sup></a><a class="footnoteRef" href="#fn55" id="fnref55"><sup>55</sup></a><a class="footnoteRef" href="#fn56" id="fnref56"><sup>56</sup></a><a class="footnoteRef" href="#fn57" id="fnref57"><sup>57</sup></a> of cell types inspired by these biological observations.</p>

<p>Fukushima's Neocognitron introduced <a href="convolution" title="wikilink">convolutional</a> neural networks partially trained by <a href="unsupervised_learning" title="wikilink">unsupervised learning</a> while humans directed features in the neural plane. <a href="Yann_LeCun" title="wikilink">Yann LeCun</a> et al. (1989) applied supervised <a class="uri" href="backpropagation" title="wikilink">backpropagation</a> to such architectures.<a class="footnoteRef" href="#fn58" id="fnref58"><sup>58</sup></a> Weng et al. (1992) published <a href="convolution" title="wikilink">convolutional</a> neural networks Cresceptron<a class="footnoteRef" href="#fn59" id="fnref59"><sup>59</sup></a><a class="footnoteRef" href="#fn60" id="fnref60"><sup>60</sup></a><a class="footnoteRef" href="#fn61" id="fnref61"><sup>61</sup></a> for 3-D object recognition from images of cluttered scenes and segmentation of such objects from images.</p>

<p>An obvious need for recognizing general 3-D objects is least shift invariance and tolerance to deformation. Max-pooling appeared to be first proposed by Cresceptron<a class="footnoteRef" href="#fn62" id="fnref62"><sup>62</sup></a><a class="footnoteRef" href="#fn63" id="fnref63"><sup>63</sup></a> to enable the network to tolerate small-to-large deformation in a hierarchical way while using convolution. Max-pooling helps, but still does not fully guarantee, shift-invariance at the pixel level.<a class="footnoteRef" href="#fn64" id="fnref64"><sup>64</sup></a></p>

<p>With the advent of the <a class="uri" href="back-propagation" title="wikilink">back-propagation</a> algorithm in the 1970s, many researchers tried to train supervised deep <a href="artificial_neural_network" title="wikilink">artificial neural networks</a> from scratch, initially with little success. <a href="Sepp_Hochreiter" title="wikilink">Sepp Hochreiter</a>'s diploma thesis of 1991<a class="footnoteRef" href="#fn65" id="fnref65"><sup>65</sup></a><a class="footnoteRef" href="#fn66" id="fnref66"><sup>66</sup></a> formally identified the reason for this failure in the "vanishing gradient problem," which not only affects many-layered feedforward networks, but also <a href="recurrent_neural_network" title="wikilink">recurrent neural networks</a>. The latter are trained by unfolding them into very deep feedforward networks, where a new layer is created for each time step of an input sequence processed by the network. As errors propagate from layer to layer, they shrink exponentially with the number of layers.</p>

<p>To overcome this problem, several methods were proposed. One is <a href="Jürgen_Schmidhuber" title="wikilink">Jürgen Schmidhuber</a>'s multi-level hierarchy of networks (1992) pre-trained one level at a time through unsupervised learning, fine-tuned through <a class="uri" href="backpropagation" title="wikilink">backpropagation</a>.<a class="footnoteRef" href="#fn67" id="fnref67"><sup>67</sup></a> Here each level learns a compressed representation of the observations that is fed to the next level.</p>

<p>Another method is the <a href="long_short_term_memory" title="wikilink">long short term memory</a> (LSTM) network of 1997 by <a href="Sepp_Hochreiter" title="wikilink">Hochreiter</a> &amp; <a href="Jürgen_Schmidhuber" title="wikilink">Schmidhuber</a>.<a class="footnoteRef" href="#fn68" id="fnref68"><sup>68</sup></a> In 2009, deep multidimensional LSTM networks won three ICDAR 2009 competitions in connected handwriting recognition, without any prior knowledge about the three different languages to be learned.<a class="footnoteRef" href="#fn69" id="fnref69"><sup>69</sup></a><a class="footnoteRef" href="#fn70" id="fnref70"><sup>70</sup></a></p>

<p>Sven Behnke relied only on the sign of the gradient (<a class="uri" href="Rprop" title="wikilink">Rprop</a>) when training his Neural Abstraction Pyramid<a class="footnoteRef" href="#fn71" id="fnref71"><sup>71</sup></a> to solve problems like image reconstruction and face localization.</p>

<p>Other methods also use unsupervised pre-training to structure a neural network, making it first learn generally useful <a href="feature_detector" title="wikilink">feature detectors</a>. Then the network is trained further by supervised <a class="uri" href="back-propagation" title="wikilink">back-propagation</a> to classify labeled data. The deep model of Hinton et al. (2006) involves learning the distribution of a high level representation using successive layers of binary or real-valued <a href="latent_variable" title="wikilink">latent variables</a>. It uses a <a href="restricted_Boltzmann_machine" title="wikilink">restricted Boltzmann machine</a> (Smolensky, 1986<a class="footnoteRef" href="#fn72" id="fnref72"><sup>72</sup></a>) to model each new layer of higher level features. Each new layer guarantees an increase on the <a href="Lower_bound" title="wikilink">lower-bound</a> of the <a href="log_likelihood" title="wikilink">log likelihood</a> of the data, thus improving the model, if trained properly. Once sufficiently many layers have been learned the deep architecture may be used as a <a href="generative_model" title="wikilink">generative model</a> by reproducing the data when sampling down the model (an "ancestral pass") from the top level feature activations.<a class="footnoteRef" href="#fn73" id="fnref73"><sup>73</sup></a> Hinton reports that his models are effective feature extractors over high-dimensional, structured data.<a class="footnoteRef" href="#fn74" id="fnref74"><sup>74</sup></a></p>

<p>The <a href="Google_Brain" title="wikilink">Google Brain</a> team led by <a href="Andrew_Ng" title="wikilink">Andrew Ng</a> and <a href="Jeff_Dean_(computer_scientist)" title="wikilink">Jeff Dean</a> created a neural network that learned to recognize higher-level concepts, such as cats, only from watching unlabeled images taken from <a class="uri" href="YouTube" title="wikilink">YouTube</a> videos.<a class="footnoteRef" href="#fn75" id="fnref75"><sup>75</sup></a> <a class="footnoteRef" href="#fn76" id="fnref76"><sup>76</sup></a></p>

<p>Other methods rely on the sheer processing power of modern computers, in particular, <a href="GPU" title="wikilink">GPUs</a>. In 2010 it was shown by Dan Ciresan and colleagues<a class="footnoteRef" href="#fn77" id="fnref77"><sup>77</sup></a> in <a href="Jürgen_Schmidhuber" title="wikilink">Jürgen Schmidhuber</a>'s group at the Swiss AI Lab <a class="uri" href="IDSIA" title="wikilink">IDSIA</a> that despite the above-mentioned "vanishing gradient problem," the superior processing power of GPUs makes plain <a class="uri" href="back-propagation" title="wikilink">back-propagation</a> feasible for deep feedforward neural networks with many layers. The method outperformed all other machine learning techniques on the old, famous MNIST handwritten digits problem of <a href="Yann_LeCun" title="wikilink">Yann LeCun</a> and colleagues at <a class="uri" href="NYU" title="wikilink">NYU</a>.</p>

<p>At about the same time, in late 2009, deep learning made inroad into speech recognition, as marked by the NIPS Workshop on Deep Learning for Speech Recognition. Intensive collaborative work between Microsoft Research and University of Toronto researchers had demonstrated by mid 2010 in Redmond that deep neural networks interfaced with a hidden Markov model with context-dependent states that define the neural network output layer can drastically reduce errors in large vocabulary speech recognition tasks such as voice search. The same deep neural net model was shown to scale up to Switchboard tasks about one year later at Microsoft Research Asia.</p>

<p>As of 2011, the state of the art in deep learning feedforward networks alternates convolutional layers and max-pooling layers,<a class="footnoteRef" href="#fn78" id="fnref78"><sup>78</sup></a><a class="footnoteRef" href="#fn79" id="fnref79"><sup>79</sup></a> topped by several pure classification layers. Training is usually done without any unsupervised pre-training. Since 2011, GPU-based implementations<a class="footnoteRef" href="#fn80" id="fnref80"><sup>80</sup></a> of this approach won many pattern recognition contests, including the IJCNN 2011 Traffic Sign Recognition Competition,<a class="footnoteRef" href="#fn81" id="fnref81"><sup>81</sup></a> the ISBI 2012 Segmentation of neuronal structures in EM stacks challenge,<a class="footnoteRef" href="#fn82" id="fnref82"><sup>82</sup></a> and others.</p>

<p>Such supervised deep learning methods also were the first artificial pattern recognizers to achieve human-competitive performance on certain tasks.<a class="footnoteRef" href="#fn83" id="fnref83"><sup>83</sup></a></p>

<p>To break the barriers of weak AI represented by deep learning, it is necessary to go beyond the deep learning architectures because biological brains use both shallow and deep circuits as reported by brain anatomy<a class="footnoteRef" href="#fn84" id="fnref84"><sup>84</sup></a> in order to deal with the wide variety of invariance that the brain displays. Weng<a class="footnoteRef" href="#fn85" id="fnref85"><sup>85</sup></a> argued that the brain self-wires largely according to signal statistics and, therefore, a serial cascade cannot catch all major statistical dependencies. Fully guaranteed shift invariance for ANNs to deal with small and large natural objects in large cluttered scenes became true when the invariance went beyond shift, to extend to all ANN-learned concepts, such as location, type (object class label), scale, lighting, in the Developmental Networks (DNs)<a class="footnoteRef" href="#fn86" id="fnref86"><sup>86</sup></a> whose embodiments are Where-What Networks, WWN-1 (2008)<a class="footnoteRef" href="#fn87" id="fnref87"><sup>87</sup></a> through WWN-7 (2013).<a class="footnoteRef" href="#fn88" id="fnref88"><sup>88</sup></a></p>
<h2 id="deep-learning-architectures">Deep learning architectures</h2>

<p>There are huge number of different variants of deep architectures; however, most of them are branched from some original parent architectures. It is not always possible to compare the performance of multiple architectures all together, since they are not all implemented on the same data set. Deep learning is a fast-growing field so new architectures, variants, or algorithms may appear every few weeks.</p>
<h3 id="deep-neural-networks">Deep neural networks</h3>

<p>A deep neural network (DNN) is an <a href="artificial_neural_network" title="wikilink">artificial neural network</a> with multiple hidden layers of units between the input and output layers.<a class="footnoteRef" href="#fn89" id="fnref89"><sup>89</sup></a><a class="footnoteRef" href="#fn90" id="fnref90"><sup>90</sup></a> Similar to shallow ANNs, DNNs can model complex non-linear relationships. DNN architectures, e.g., for <a href="object_detection" title="wikilink">object detection</a> and <a href="Natural_language_processing" title="wikilink">parsing</a> generate compositional models where the object is expressed as layered composition of image primitives.<a class="footnoteRef" href="#fn91" id="fnref91"><sup>91</sup></a> The extra layers enable composition of features from lower layers, giving the potential of modeling complex data with fewer units than a similarly performing shallow network.<a class="footnoteRef" href="#fn92" id="fnref92"><sup>92</sup></a></p>

<p>DNNs are typically designed as <a href="feedforward_neural_network" title="wikilink">feedforward</a> networks, but recent research has successfully applied the deep learning architecture to <a href="recurrent_neural_network" title="wikilink">recurrent neural networks</a> for applications such as <a href="language_model" title="wikilink">language modeling</a>.<a class="footnoteRef" href="#fn93" id="fnref93"><sup>93</sup></a> <a href="convolutional_neural_network" title="wikilink">Convolutional deep neural networks</a> (CNNs) are used in computer vision where their success is well-documented.<a class="footnoteRef" href="#fn94" id="fnref94"><sup>94</sup></a> More recently, CNNs have been applied to <a href="acoustic_model" title="wikilink">acoustic modeling</a> for automatic speech recognition (ASR), where they have shown success over previous models.<a class="footnoteRef" href="#fn95" id="fnref95"><sup>95</sup></a> For simplicity, a look at training DNNs is given here.</p>

<p>A DNN can be <a href="discriminative_model" title="wikilink">discriminatively</a> trained with the standard <a class="uri" href="backpropagation" title="wikilink">backpropagation</a> algorithm. The weight updates can be done via <a href="stochastic_gradient_descent" title="wikilink">stochastic gradient descent</a> using the following equation:</p>

<p>
<math display="block" id="Deep_learning:0">
<semantics>
<mrow>
<mrow>
<msub>
<mi>w</mi>
<mrow>
<mi>i</mi>
<mi>j</mi>
</mrow>
</msub>
<mrow>
<mo stretchy="false">(</mo>
<mrow>
<mi>t</mi>
<mo>+</mo>
<mn>1</mn>
</mrow>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
<mo>=</mo>
<mrow>
<mrow>
<msub>
<mi>w</mi>
<mrow>
<mi>i</mi>
<mi>j</mi>
</mrow>
</msub>
<mrow>
<mo stretchy="false">(</mo>
<mi>t</mi>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
<mo>+</mo>
<mrow>
<mi>η</mi>
<mfrac>
<mrow>
<mo>∂</mo>
<mi>C</mi>
</mrow>
<mrow>
<mo>∂</mo>
<msub>
<mi>w</mi>
<mrow>
<mi>i</mi>
<mi>j</mi>
</mrow>
</msub>
</mrow>
</mfrac>
</mrow>
</mrow>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<eq></eq>
<apply>
<times></times>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>w</ci>
<apply>
<times></times>
<ci>i</ci>
<ci>j</ci>
</apply>
</apply>
<apply>
<plus></plus>
<ci>t</ci>
<cn type="integer">1</cn>
</apply>
</apply>
<apply>
<plus></plus>
<apply>
<times></times>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>w</ci>
<apply>
<times></times>
<ci>i</ci>
<ci>j</ci>
</apply>
</apply>
<ci>t</ci>
</apply>
<apply>
<times></times>
<ci>η</ci>
<apply>
<divide></divide>
<apply>
<partialdiff></partialdiff>
<ci>C</ci>
</apply>
<apply>
<partialdiff></partialdiff>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>w</ci>
<apply>
<times></times>
<ci>i</ci>
<ci>j</ci>
</apply>
</apply>
</apply>
</apply>
</apply>
</apply>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   w_{ij}(t+1)=w_{ij}(t)+\eta\frac{\partial C}{\partial w_{ij}}
  </annotation>
</semantics>
</math>
</p>

<p>Here, 

<math display="inline" id="Deep_learning:1">
<semantics>
<mi>η</mi>
<annotation-xml encoding="MathML-Content">
<ci>η</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   \eta
  </annotation>
</semantics>
</math>

 is the learning rate, and 

<math display="inline" id="Deep_learning:2">
<semantics>
<mi>C</mi>
<annotation-xml encoding="MathML-Content">
<ci>C</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   C
  </annotation>
</semantics>
</math>

 is the <a href="loss_function" title="wikilink">cost function</a>. The choice of the cost function depends on factors such as the learning type (supervised, unsupervised, <a href="Reinforcement_learning" title="wikilink">reinforcement</a>, etc.) and the <a href="activation_function" title="wikilink">activation function</a>. For example, when performing supervised learning on a <a href="multiclass_classification" title="wikilink">multiclass classification</a> problem, common choices for the activation function and cost function are the <a href="softmax_activation_function" title="wikilink">softmax</a> function and <a href="cross_entropy" title="wikilink">cross entropy</a> function, respectively. The softmax function is defined as 

<math display="inline" id="Deep_learning:3">
<semantics>
<mrow>
<msub>
<mi>p</mi>
<mi>j</mi>
</msub>
<mo>=</mo>
<mfrac>
<mrow>
<mi>exp</mi>
<mrow>
<mo stretchy="false">(</mo>
<msub>
<mi>x</mi>
<mi>j</mi>
</msub>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
<mrow>
<mstyle displaystyle="false">
<msub>
<mo largeop="true" symmetric="true">∑</mo>
<mi>k</mi>
</msub>
</mstyle>
<mrow>
<mi>exp</mi>
<mrow>
<mo stretchy="false">(</mo>
<msub>
<mi>x</mi>
<mi>k</mi>
</msub>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
</mrow>
</mfrac>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<eq></eq>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>p</ci>
<ci>j</ci>
</apply>
<apply>
<divide></divide>
<apply>
<exp></exp>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>x</ci>
<ci>j</ci>
</apply>
</apply>
<apply>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<sum></sum>
<ci>k</ci>
</apply>
<apply>
<exp></exp>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>x</ci>
<ci>k</ci>
</apply>
</apply>
</apply>
</apply>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   p_{j}=\frac{\exp(x_{j})}{\sum_{k}\exp(x_{k})}
  </annotation>
</semantics>
</math>

 where 

<math display="inline" id="Deep_learning:4">
<semantics>
<msub>
<mi>p</mi>
<mi>j</mi>
</msub>
<annotation-xml encoding="MathML-Content">
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>p</ci>
<ci>j</ci>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   p_{j}
  </annotation>
</semantics>
</math>

 represents the class probability and 

<math display="inline" id="Deep_learning:5">
<semantics>
<msub>
<mi>x</mi>
<mi>j</mi>
</msub>
<annotation-xml encoding="MathML-Content">
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>x</ci>
<ci>j</ci>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   x_{j}
  </annotation>
</semantics>
</math>

 and 

<math display="inline" id="Deep_learning:6">
<semantics>
<msub>
<mi>x</mi>
<mi>k</mi>
</msub>
<annotation-xml encoding="MathML-Content">
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>x</ci>
<ci>k</ci>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   x_{k}
  </annotation>
</semantics>
</math>

 represent the total input to units 

<math display="inline" id="Deep_learning:7">
<semantics>
<mi>j</mi>
<annotation-xml encoding="MathML-Content">
<ci>j</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   j
  </annotation>
</semantics>
</math>

 and 

<math display="inline" id="Deep_learning:8">
<semantics>
<mi>k</mi>
<annotation-xml encoding="MathML-Content">
<ci>k</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   k
  </annotation>
</semantics>
</math>

 respectively. Cross entropy is defined as 

<math display="inline" id="Deep_learning:9">
<semantics>
<mrow>
<mi>C</mi>
<mo>=</mo>
<mrow>
<mo>-</mo>
<mrow>
<msub>
<mo largeop="true" symmetric="true">∑</mo>
<mi>j</mi>
</msub>
<mrow>
<msub>
<mi>d</mi>
<mi>j</mi>
</msub>
<mrow>
<mi>log</mi>
<mrow>
<mo stretchy="false">(</mo>
<msub>
<mi>p</mi>
<mi>j</mi>
</msub>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
</mrow>
</mrow>
</mrow>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<eq></eq>
<ci>C</ci>
<apply>
<minus></minus>
<apply>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<sum></sum>
<ci>j</ci>
</apply>
<apply>
<times></times>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>d</ci>
<ci>j</ci>
</apply>
<apply>
<log></log>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>p</ci>
<ci>j</ci>
</apply>
</apply>
</apply>
</apply>
</apply>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   C=-\sum_{j}d_{j}\log(p_{j})
  </annotation>
</semantics>
</math>

 where 

<math display="inline" id="Deep_learning:10">
<semantics>
<msub>
<mi>d</mi>
<mi>j</mi>
</msub>
<annotation-xml encoding="MathML-Content">
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>d</ci>
<ci>j</ci>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   d_{j}
  </annotation>
</semantics>
</math>

 represents the target probability for output unit 

<math display="inline" id="Deep_learning:11">
<semantics>
<mi>j</mi>
<annotation-xml encoding="MathML-Content">
<ci>j</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   j
  </annotation>
</semantics>
</math>

 and 

<math display="inline" id="Deep_learning:12">
<semantics>
<msub>
<mi>p</mi>
<mi>j</mi>
</msub>
<annotation-xml encoding="MathML-Content">
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>p</ci>
<ci>j</ci>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   p_{j}
  </annotation>
</semantics>
</math>

 is the probability output for 

<math display="inline" id="Deep_learning:13">
<semantics>
<mi>j</mi>
<annotation-xml encoding="MathML-Content">
<ci>j</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   j
  </annotation>
</semantics>
</math>

 after applying the activation function.<a class="footnoteRef" href="#fn96" id="fnref96"><sup>96</sup></a></p>
<h3 id="issues-with-deep-neural-networks">Issues with deep neural networks</h3>

<p>As with ANNs, many issues can arise with DNNs if they are naively trained. Two common issues are <a class="uri" href="overfitting" title="wikilink">overfitting</a> and computation time.</p>

<p>DNNs are prone to overfitting because of the added layers of abstraction, which allow them to model rare dependencies in the training data. <a href="Regularization_(mathematics)" title="wikilink">Regularization</a> methods such as <a href="weight_decay" title="wikilink">weight decay</a> (

<math display="inline" id="Deep_learning:14">
<semantics>
<msub>
<mi mathvariant="normal">ℓ</mi>
<mn>2</mn>
</msub>
<annotation-xml encoding="MathML-Content">
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>normal-ℓ</ci>
<cn type="integer">2</cn>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   \ell_{2}
  </annotation>
</semantics>
</math>

-regularization) or <a href="sparse_matrix" title="wikilink">sparsity</a> (

<math display="inline" id="Deep_learning:15">
<semantics>
<msub>
<mi mathvariant="normal">ℓ</mi>
<mn>1</mn>
</msub>
<annotation-xml encoding="MathML-Content">
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>normal-ℓ</ci>
<cn type="integer">1</cn>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   \ell_{1}
  </annotation>
</semantics>
</math>

-regularization) can be applied during training to help combat overfitting.<a class="footnoteRef" href="#fn97" id="fnref97"><sup>97</sup></a> A more recent regularization method applied to DNNs is <em>dropout</em> regularization. In dropout, some number of units are randomly omitted from the hidden layers during training. This helps to break the rare dependencies that can occur in the training data <a class="footnoteRef" href="#fn98" id="fnref98"><sup>98</sup></a></p>

<p>Backpropagation and <a href="gradient_descent" title="wikilink">gradient descent</a> have been the preferred method for training these structures due to the ease of implementation and their tendency to converge to better <a href="Local_optimum" title="wikilink">local optima</a> in comparison with other training methods. However, these methods can be computationally expensive, especially when being used to train DNNs. There are many training parameters to be considered with a DNN, such as the size (number of layers and number of units per layer), the learning rate and initial weights. <a href="Hyperparameter_optimization#Grid_search" title="wikilink">Sweeping through the parameter space</a> for optimal parameters may not be feasible due to the cost in time and computational resources. Various 'tricks' such as using mini-batching (computing the gradient on several training examples at once rather than individual examples) <a class="footnoteRef" href="#fn99" id="fnref99"><sup>99</sup></a> have been shown to speed up computation. The large processing throughput of GPUs has produced significant speedups in training, due to the matrix and vector computations required being well suited for GPUs.<a class="footnoteRef" href="#fn100" id="fnref100"><sup>100</sup></a> Radical alternatives to backprop such as <a href="Extreme_Learning_Machines" title="wikilink">Extreme Learning Machines</a>,<a class="footnoteRef" href="#fn101" id="fnref101"><sup>101</sup></a> "No-prop" networks <a class="footnoteRef" href="#fn102" id="fnref102"><sup>102</sup></a> and <a href="Weightless_neural_networks" title="wikilink">Weightless neural networks</a> <a class="footnoteRef" href="#fn103" id="fnref103"><sup>103</sup></a> are gaining attention.</p>
<h3 id="deep-belief-networks">Deep belief networks</h3>
<figure><b>(Figure)</b>
<figcaption> A <a href="restricted_Boltzmann_machine" title="wikilink">restricted Boltzmann machine</a> (RBM) with fully connected visible and hidden units. Note there are no hidden-hidden or visible-visible connections.</figcaption>
</figure>

<p>A deep belief network (DBN) is a probabilistic, <a href="generative_model" title="wikilink">generative model</a> made up of multiple layers of hidden units. It can be looked at as a <a href="Function_composition" title="wikilink">composition</a> of simple learning modules that make up each layer.<a class="footnoteRef" href="#fn104" id="fnref104"><sup>104</sup></a></p>

<p>A DBN can be used for generatively pre-training a DNN by using the learned weights as the initial weights. Backpropagation or other discriminative algorithms can then be applied for fine-tuning of these weights. This is particularly helpful in situations where limited training data is available, as poorly initialized weights can have significant impact on the performance of the final model. These pre-trained weights are in a region of the weight space that is closer to the optimal weights (as compared to just random initialization). This allows for both improved modeling capability and faster convergence of the fine-tuning phase.<a class="footnoteRef" href="#fn105" id="fnref105"><sup>105</sup></a></p>

<p>A DBN can be efficiently trained in an unsupervised, layer-by-layer manner where the layers are typically made of <a href="restricted_Boltzmann_machine" title="wikilink">restricted Boltzmann machines</a> (RBM). A description of training a DBN via RBMs is provided below. An RBM is an <a href="undirected_graph" title="wikilink">undirected</a>, generative energy-based model with an input layer and single hidden layer. Connections only exist between the visible units of the input layer and the hidden units of the hidden layer; there are no visible-visible or hidden-hidden connections.</p>

<p>The training method for RBMs was initially proposed by Geoffrey Hinton for use with training "Product of Expert" models and is known as <a href="contrastive_divergence" title="wikilink">contrastive divergence</a> (CD).<a class="footnoteRef" href="#fn106" id="fnref106"><sup>106</sup></a> CD provides an approximation to the <a href="maximum_likelihood" title="wikilink">maximum likelihood</a> method that would ideally be applied for learning the weights of the RBM.<a class="footnoteRef" href="#fn107" id="fnref107"><sup>107</sup></a><a class="footnoteRef" href="#fn108" id="fnref108"><sup>108</sup></a></p>

<p>In training a single RBM, weight updates are performed with <a href="gradient_descent" title="wikilink">gradient ascent</a> via the following equation

<math display="block" id="Deep_learning:16">
<semantics>
<mrow>
<mrow>
<mi mathvariant="normal">Δ</mi>
<msub>
<mi>w</mi>
<mrow>
<mi>i</mi>
<mi>j</mi>
</mrow>
</msub>
<mrow>
<mo stretchy="false">(</mo>
<mrow>
<mi>t</mi>
<mo>+</mo>
<mn>1</mn>
</mrow>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
<mo>=</mo>
<mrow>
<mrow>
<msub>
<mi>w</mi>
<mrow>
<mi>i</mi>
<mi>j</mi>
</mrow>
</msub>
<mrow>
<mo stretchy="false">(</mo>
<mi>t</mi>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
<mo>+</mo>
<mrow>
<mi>η</mi>
<mfrac>
<mrow>
<mrow>
<mo>∂</mo>
<mi>log</mi>
</mrow>
<mrow>
<mo stretchy="false">(</mo>
<mrow>
<mi>p</mi>
<mrow>
<mo stretchy="false">(</mo>
<mi>v</mi>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
<mrow>
<mo>∂</mo>
<msub>
<mi>w</mi>
<mrow>
<mi>i</mi>
<mi>j</mi>
</mrow>
</msub>
</mrow>
</mfrac>
</mrow>
</mrow>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<eq></eq>
<apply>
<times></times>
<ci>normal-Δ</ci>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>w</ci>
<apply>
<times></times>
<ci>i</ci>
<ci>j</ci>
</apply>
</apply>
<apply>
<plus></plus>
<ci>t</ci>
<cn type="integer">1</cn>
</apply>
</apply>
<apply>
<plus></plus>
<apply>
<times></times>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>w</ci>
<apply>
<times></times>
<ci>i</ci>
<ci>j</ci>
</apply>
</apply>
<ci>t</ci>
</apply>
<apply>
<times></times>
<ci>η</ci>
<apply>
<divide></divide>
<apply>
<apply>
<partialdiff></partialdiff>
<log></log>
</apply>
<apply>
<times></times>
<ci>p</ci>
<ci>v</ci>
</apply>
</apply>
<apply>
<partialdiff></partialdiff>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>w</ci>
<apply>
<times></times>
<ci>i</ci>
<ci>j</ci>
</apply>
</apply>
</apply>
</apply>
</apply>
</apply>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   \Delta w_{ij}(t+1)=w_{ij}(t)+\eta\frac{\partial\log(p(v))}{\partial w_{ij}}
  </annotation>
</semantics>
</math>

. Here, 

<math display="inline" id="Deep_learning:17">
<semantics>
<mrow>
<mi>p</mi>
<mrow>
<mo stretchy="false">(</mo>
<mi>v</mi>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<times></times>
<ci>p</ci>
<ci>v</ci>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   p(v)
  </annotation>
</semantics>
</math>

 is the probability of a visible vector, which is given by 

<math display="inline" id="Deep_learning:18">
<semantics>
<mrow>
<mrow>
<mi>p</mi>
<mrow>
<mo stretchy="false">(</mo>
<mi>v</mi>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
<mo>=</mo>
<mrow>
<mfrac>
<mn>1</mn>
<mi>Z</mi>
</mfrac>
<mrow>
<msub>
<mo largeop="true" symmetric="true">∑</mo>
<mi>h</mi>
</msub>
<msup>
<mi>e</mi>
<mrow>
<mo>-</mo>
<mrow>
<mi>E</mi>
<mrow>
<mo stretchy="false">(</mo>
<mi>v</mi>
<mo>,</mo>
<mi>h</mi>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
</mrow>
</msup>
</mrow>
</mrow>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<eq></eq>
<apply>
<times></times>
<ci>p</ci>
<ci>v</ci>
</apply>
<apply>
<times></times>
<apply>
<divide></divide>
<cn type="integer">1</cn>
<ci>Z</ci>
</apply>
<apply>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<sum></sum>
<ci>h</ci>
</apply>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<ci>e</ci>
<apply>
<minus></minus>
<apply>
<times></times>
<ci>E</ci>
<interval closure="open">
<ci>v</ci>
<ci>h</ci>
</interval>
</apply>
</apply>
</apply>
</apply>
</apply>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   p(v)=\frac{1}{Z}\sum_{h}e^{-E(v,h)}
  </annotation>
</semantics>
</math>

. 

<math display="inline" id="Deep_learning:19">
<semantics>
<mi>Z</mi>
<annotation-xml encoding="MathML-Content">
<ci>Z</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   Z
  </annotation>
</semantics>
</math>

 is the partition function (used for normalizing) and 

<math display="inline" id="Deep_learning:20">
<semantics>
<mrow>
<mi>E</mi>
<mrow>
<mo stretchy="false">(</mo>
<mi>v</mi>
<mo>,</mo>
<mi>h</mi>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<times></times>
<ci>E</ci>
<interval closure="open">
<ci>v</ci>
<ci>h</ci>
</interval>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   E(v,h)
  </annotation>
</semantics>
</math>

 is the energy function assigned to the state of the network. A lower energy indicates the network is in a more "desirable" configuration. The gradient 

<math display="inline" id="Deep_learning:21">
<semantics>
<mfrac>
<mrow>
<mrow>
<mo>∂</mo>
<mi>log</mi>
</mrow>
<mrow>
<mo stretchy="false">(</mo>
<mrow>
<mi>p</mi>
<mrow>
<mo stretchy="false">(</mo>
<mi>v</mi>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
<mrow>
<mo>∂</mo>
<msub>
<mi>w</mi>
<mrow>
<mi>i</mi>
<mi>j</mi>
</mrow>
</msub>
</mrow>
</mfrac>
<annotation-xml encoding="MathML-Content">
<apply>
<divide></divide>
<apply>
<apply>
<partialdiff></partialdiff>
<log></log>
</apply>
<apply>
<times></times>
<ci>p</ci>
<ci>v</ci>
</apply>
</apply>
<apply>
<partialdiff></partialdiff>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>w</ci>
<apply>
<times></times>
<ci>i</ci>
<ci>j</ci>
</apply>
</apply>
</apply>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   \frac{\partial\log(p(v))}{\partial w_{ij}}
  </annotation>
</semantics>
</math>

 has the simple form 

<math display="inline" id="Deep_learning:22">
<semantics>
<mrow>
<msub>
<mrow>
<mo stretchy="false">⟨</mo>
<mrow>
<msub>
<mi>v</mi>
<mi>i</mi>
</msub>
<msub>
<mi>h</mi>
<mi>j</mi>
</msub>
</mrow>
<mo stretchy="false">⟩</mo>
</mrow>
<mtext>data</mtext>
</msub>
<mo>-</mo>
<msub>
<mrow>
<mo stretchy="false">⟨</mo>
<mrow>
<msub>
<mi>v</mi>
<mi>i</mi>
</msub>
<msub>
<mi>h</mi>
<mi>j</mi>
</msub>
</mrow>
<mo stretchy="false">⟩</mo>
</mrow>
<mtext>model</mtext>
</msub>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<minus></minus>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<apply>
<csymbol cd="latexml">delimited-⟨⟩</csymbol>
<apply>
<times></times>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>v</ci>
<ci>i</ci>
</apply>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>h</ci>
<ci>j</ci>
</apply>
</apply>
</apply>
<mtext>data</mtext>
</apply>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<apply>
<csymbol cd="latexml">delimited-⟨⟩</csymbol>
<apply>
<times></times>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>v</ci>
<ci>i</ci>
</apply>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>h</ci>
<ci>j</ci>
</apply>
</apply>
</apply>
<mtext>model</mtext>
</apply>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   \langle v_{i}h_{j}\rangle_{\text{data}}-\langle v_{i}h_{j}\rangle_{\text{model}}
  </annotation>
</semantics>
</math>

 where 

<math display="inline" id="Deep_learning:23">
<semantics>
<msub>
<mrow>
<mo stretchy="false">⟨</mo>
<mi mathvariant="normal">⋯</mi>
<mo stretchy="false">⟩</mo>
</mrow>
<mi>p</mi>
</msub>
<annotation-xml encoding="MathML-Content">
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<apply>
<csymbol cd="latexml">delimited-⟨⟩</csymbol>
<ci>normal-⋯</ci>
</apply>
<ci>p</ci>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   \langle\cdots\rangle_{p}
  </annotation>
</semantics>
</math>

 represent averages with respect to distribution 

<math display="inline" id="Deep_learning:24">
<semantics>
<mi>p</mi>
<annotation-xml encoding="MathML-Content">
<ci>p</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   p
  </annotation>
</semantics>
</math>

. The issue arises in sampling 

<math display="inline" id="Deep_learning:25">
<semantics>
<msub>
<mrow>
<mo stretchy="false">⟨</mo>
<mrow>
<msub>
<mi>v</mi>
<mi>i</mi>
</msub>
<msub>
<mi>h</mi>
<mi>j</mi>
</msub>
</mrow>
<mo stretchy="false">⟩</mo>
</mrow>
<mtext>model</mtext>
</msub>
<annotation-xml encoding="MathML-Content">
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<apply>
<csymbol cd="latexml">delimited-⟨⟩</csymbol>
<apply>
<times></times>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>v</ci>
<ci>i</ci>
</apply>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>h</ci>
<ci>j</ci>
</apply>
</apply>
</apply>
<mtext>model</mtext>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   \langle v_{i}h_{j}\rangle_{\text{model}}
  </annotation>
</semantics>
</math>

 as this requires running alternating <a href="Gibbs_sampling" title="wikilink">Gibbs sampling</a> for a long time. CD replaces this step by running alternating Gibbs sampling for 

<math display="inline" id="Deep_learning:26">
<semantics>
<mi>n</mi>
<annotation-xml encoding="MathML-Content">
<ci>n</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   n
  </annotation>
</semantics>
</math>

 steps (values of 

<math display="inline" id="Deep_learning:27">
<semantics>
<mrow>
<mi>n</mi>
<mo>=</mo>
<mn>1</mn>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<eq></eq>
<ci>n</ci>
<cn type="integer">1</cn>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   n=1
  </annotation>
</semantics>
</math>

 have empirically been shown to perform well). After 

<math display="inline" id="Deep_learning:28">
<semantics>
<mi>n</mi>
<annotation-xml encoding="MathML-Content">
<ci>n</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   n
  </annotation>
</semantics>
</math>

 steps, the data is sampled and that sample is used in place of 

<math display="inline" id="Deep_learning:29">
<semantics>
<msub>
<mrow>
<mo stretchy="false">⟨</mo>
<mrow>
<msub>
<mi>v</mi>
<mi>i</mi>
</msub>
<msub>
<mi>h</mi>
<mi>j</mi>
</msub>
</mrow>
<mo stretchy="false">⟩</mo>
</mrow>
<mtext>model</mtext>
</msub>
<annotation-xml encoding="MathML-Content">
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<apply>
<csymbol cd="latexml">delimited-⟨⟩</csymbol>
<apply>
<times></times>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>v</ci>
<ci>i</ci>
</apply>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>h</ci>
<ci>j</ci>
</apply>
</apply>
</apply>
<mtext>model</mtext>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   \langle v_{i}h_{j}\rangle_{\text{model}}
  </annotation>
</semantics>
</math>

. The CD procedure works as follows:<a class="footnoteRef" href="#fn109" id="fnref109"><sup>109</sup></a></p>
<ol>
<li>Initialize the visible units to a training vector.</li>
<li>Update the hidden units in parallel given the visible units

<math display="block" id="Deep_learning:30">
<semantics>
<mrow>
<mi>p</mi>
<mrow>
<mo stretchy="false">(</mo>
<msub>
<mi>h</mi>
<mi>j</mi>
</msub>
<mo>=</mo>
<mn>1</mn>
<mo>∣</mo>
<mtext>𝐕</mtext>
<mo stretchy="false">)</mo>
</mrow>
<mo>=</mo>
<mi>σ</mi>
<mrow>
<mo stretchy="false">(</mo>
<msub>
<mi>b</mi>
<mi>j</mi>
</msub>
<mo>+</mo>
<munder>
<mo largeop="true" movablelimits="false" symmetric="true">∑</mo>
<mi>i</mi>
</munder>
<msub>
<mi>v</mi>
<mi>i</mi>
</msub>
<msub>
<mi>w</mi>
<mrow>
<mi>i</mi>
<mi>j</mi>
</mrow>
</msub>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
<annotation-xml encoding="MathML-Content">
<cerror>
<csymbol cd="ambiguous">fragments</csymbol>
<csymbol cd="unknown">p</csymbol>
<cerror>
<csymbol cd="ambiguous">fragments</csymbol>
<ci>normal-(</ci>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>h</ci>
<ci>j</ci>
</apply>
<eq></eq>
<cn type="integer">1</cn>
<ci>normal-∣</ci>
<mtext>V</mtext>
<ci>normal-)</ci>
</cerror>
<eq></eq>
<csymbol cd="unknown">σ</csymbol>
<cerror>
<csymbol cd="ambiguous">fragments</csymbol>
<ci>normal-(</ci>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>b</ci>
<ci>j</ci>
</apply>
<plus></plus>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<sum></sum>
<ci>i</ci>
</apply>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>v</ci>
<ci>i</ci>
</apply>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>w</ci>
<apply>
<times></times>
<ci>i</ci>
<ci>j</ci>
</apply>
</apply>
<ci>normal-)</ci>
</cerror>
</cerror>
</annotation-xml>
<annotation encoding="application/x-tex">
   p(h_{j}=1\mid\textbf{V})=\sigma(b_{j}+\sum_{i}v_{i}w_{ij})
  </annotation>
</semantics>
</math>

. 

<math display="inline" id="Deep_learning:31">
<semantics>
<mi>σ</mi>
<annotation-xml encoding="MathML-Content">
<ci>σ</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   \sigma
  </annotation>
</semantics>
</math>

 represents the sigmoid function and 

<math display="inline" id="Deep_learning:32">
<semantics>
<msub>
<mi>b</mi>
<mi>j</mi>
</msub>
<annotation-xml encoding="MathML-Content">
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>b</ci>
<ci>j</ci>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   b_{j}
  </annotation>
</semantics>
</math>

 is the bias of 

<math display="inline" id="Deep_learning:33">
<semantics>
<msub>
<mi>h</mi>
<mi>j</mi>
</msub>
<annotation-xml encoding="MathML-Content">
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>h</ci>
<ci>j</ci>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   h_{j}
  </annotation>
</semantics>
</math>

.</li>
<li>Update the visible units in parallel given the hidden units

<math display="block" id="Deep_learning:34">
<semantics>
<mrow>
<mi>p</mi>
<mrow>
<mo stretchy="false">(</mo>
<msub>
<mi>v</mi>
<mi>i</mi>
</msub>
<mo>=</mo>
<mn>1</mn>
<mo>∣</mo>
<mtext>𝐇</mtext>
<mo stretchy="false">)</mo>
</mrow>
<mo>=</mo>
<mi>σ</mi>
<mrow>
<mo stretchy="false">(</mo>
<msub>
<mi>a</mi>
<mi>i</mi>
</msub>
<mo>+</mo>
<munder>
<mo largeop="true" movablelimits="false" symmetric="true">∑</mo>
<mi>j</mi>
</munder>
<msub>
<mi>h</mi>
<mi>j</mi>
</msub>
<msub>
<mi>w</mi>
<mrow>
<mi>i</mi>
<mi>j</mi>
</mrow>
</msub>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
<annotation-xml encoding="MathML-Content">
<cerror>
<csymbol cd="ambiguous">fragments</csymbol>
<csymbol cd="unknown">p</csymbol>
<cerror>
<csymbol cd="ambiguous">fragments</csymbol>
<ci>normal-(</ci>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>v</ci>
<ci>i</ci>
</apply>
<eq></eq>
<cn type="integer">1</cn>
<ci>normal-∣</ci>
<mtext>H</mtext>
<ci>normal-)</ci>
</cerror>
<eq></eq>
<csymbol cd="unknown">σ</csymbol>
<cerror>
<csymbol cd="ambiguous">fragments</csymbol>
<ci>normal-(</ci>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>a</ci>
<ci>i</ci>
</apply>
<plus></plus>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<sum></sum>
<ci>j</ci>
</apply>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>h</ci>
<ci>j</ci>
</apply>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>w</ci>
<apply>
<times></times>
<ci>i</ci>
<ci>j</ci>
</apply>
</apply>
<ci>normal-)</ci>
</cerror>
</cerror>
</annotation-xml>
<annotation encoding="application/x-tex">
   p(v_{i}=1\mid\textbf{H})=\sigma(a_{i}+\sum_{j}h_{j}w_{ij})
  </annotation>
</semantics>
</math>

. 

<math display="inline" id="Deep_learning:35">
<semantics>
<msub>
<mi>a</mi>
<mi>i</mi>
</msub>
<annotation-xml encoding="MathML-Content">
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>a</ci>
<ci>i</ci>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   a_{i}
  </annotation>
</semantics>
</math>

 is the bias of 

<math display="inline" id="Deep_learning:36">
<semantics>
<msub>
<mi>v</mi>
<mi>i</mi>
</msub>
<annotation-xml encoding="MathML-Content">
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>v</ci>
<ci>i</ci>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   v_{i}
  </annotation>
</semantics>
</math>

. This is called the "reconstruction" step.</li>
<li>Reupdate the hidden units in parallel given the reconstructed visible units using the same equation as in step 2.</li>
<li>Perform the weight update

<math display="block" id="Deep_learning:37">
<semantics>
<mrow>
<mrow>
<mi mathvariant="normal">Δ</mi>
<msub>
<mi>w</mi>
<mrow>
<mi>i</mi>
<mi>j</mi>
</mrow>
</msub>
</mrow>
<mo>∝</mo>
<mrow>
<msub>
<mrow>
<mo stretchy="false">⟨</mo>
<mrow>
<msub>
<mi>v</mi>
<mi>i</mi>
</msub>
<msub>
<mi>h</mi>
<mi>j</mi>
</msub>
</mrow>
<mo stretchy="false">⟩</mo>
</mrow>
<mtext>data</mtext>
</msub>
<mo>-</mo>
<msub>
<mrow>
<mo stretchy="false">⟨</mo>
<mrow>
<msub>
<mi>v</mi>
<mi>i</mi>
</msub>
<msub>
<mi>h</mi>
<mi>j</mi>
</msub>
</mrow>
<mo stretchy="false">⟩</mo>
</mrow>
<mtext>reconstruction</mtext>
</msub>
</mrow>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<csymbol cd="latexml">proportional-to</csymbol>
<apply>
<times></times>
<ci>normal-Δ</ci>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>w</ci>
<apply>
<times></times>
<ci>i</ci>
<ci>j</ci>
</apply>
</apply>
</apply>
<apply>
<minus></minus>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<apply>
<csymbol cd="latexml">delimited-⟨⟩</csymbol>
<apply>
<times></times>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>v</ci>
<ci>i</ci>
</apply>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>h</ci>
<ci>j</ci>
</apply>
</apply>
</apply>
<mtext>data</mtext>
</apply>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<apply>
<csymbol cd="latexml">delimited-⟨⟩</csymbol>
<apply>
<times></times>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>v</ci>
<ci>i</ci>
</apply>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>h</ci>
<ci>j</ci>
</apply>
</apply>
</apply>
<mtext>reconstruction</mtext>
</apply>
</apply>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   \Delta w_{ij}\propto\langle v_{i}h_{j}\rangle_{\text{data}}-\langle v_{i}h_{j}%
\rangle_{\text{reconstruction}}
  </annotation>
</semantics>
</math>

.</li>
</ol>

<p>Once an RBM is trained, another RBM can be "stacked" atop of it to create a multilayer model. Each time another RBM is stacked, the input visible layer is initialized to a training vector and values for the units in the already-trained RBM layers are assigned using the current weights and biases. The final layer of the already-trained layers is used as input to the new RBM. The new RBM is then trained with the procedure above, and then this whole process can be repeated until some desired stopping criterion is met.<a class="footnoteRef" href="#fn110" id="fnref110"><sup>110</sup></a></p>

<p>Despite the approximation of CD to maximum likelihood being very crude (CD has been shown to not follow the gradient of any function), empirical results have shown it to be an effective method for use with training deep architectures.<a class="footnoteRef" href="#fn111" id="fnref111"><sup>111</sup></a></p>
<h3 id="convolutional-neural-networks">Convolutional neural networks</h3>

<p>A CNN is composed of one or more <a href="convolution" title="wikilink">convolutional</a> layers with fully connected layers (matching those in typical artificial neural networks) on top. It also uses tied weights and pooling layers. This architecture allows CNNs to take advantage of the 2D structure of input data. In comparison with other deep architectures, convolutional neural networks are starting to show superior results in both image and speech applications. They can also be trained with standard backpropagation. CNNs are easier to train than other regular, deep, feed-forward neural networks and have many fewer parameters to estimate, making them a highly attractive architecture to use.<a class="footnoteRef" href="#fn112" id="fnref112"><sup>112</sup></a> Examples of applications in Computer Vision include <a class="uri" href="DeepDream" title="wikilink">DeepDream</a>.<a class="footnoteRef" href="#fn113" id="fnref113"><sup>113</sup></a></p>
<h3 id="convolutional-deep-belief-networks">Convolutional Deep Belief Networks</h3>

<p>A recent achievement in deep learning is from the use of convolutional deep belief networks (CDBN). A CDBN is very similar to normal <a href="Convolutional_neural_network" title="wikilink">Convolutional neural network</a> in terms of its structure. Therefore, like CNNs they are also able to exploit the 2D structure of images combined with the advantage gained by pre-training in <a href="Deep_belief_network" title="wikilink">Deep belief network</a>. They provide a generic structure which can be used in many image and signal processing tasks and can be trained in a way similar to that for Deep Belief Networks. Recently, many benchmark results on standard image datasets like CIFAR <a class="footnoteRef" href="#fn114" id="fnref114"><sup>114</sup></a> have been obtained using CDBNs.<a class="footnoteRef" href="#fn115" id="fnref115"><sup>115</sup></a></p>
<h3 id="deep-boltzmann-machines">Deep Boltzmann Machines</h3>

<p>A <em>Deep Boltzmann Machine</em> (DBM) is a type of binary pairwise <a href="Markov_random_field" title="wikilink">Markov random field</a> (<a href="Graph_(mathematics)#Undirected_graph" title="wikilink">undirected</a> probabilistic <a href="graphical_model" title="wikilink">graphical models</a>) with multiple layers of <a href="Latent_variable" title="wikilink">hidden</a> <a href="random_variables" title="wikilink">random variables</a>. It is a network of symmetrically coupled stochastic <a href="Binary_variables" title="wikilink">binary units</a>. It comprises a set of visible units 

<math display="inline" id="Deep_learning:38">
<semantics>
<mrow>
<mi>𝝂</mi>
<mo>∈</mo>
<msup>
<mrow>
<mo stretchy="false">{</mo>
<mn>0</mn>
<mo>,</mo>
<mn>1</mn>
<mo stretchy="false">}</mo>
</mrow>
<mi>D</mi>
</msup>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<in></in>
<ci>𝝂</ci>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<set>
<cn type="integer">0</cn>
<cn type="integer">1</cn>
</set>
<ci>D</ci>
</apply>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   \boldsymbol{\nu}\in\{0,1\}^{D}
  </annotation>
</semantics>
</math>

, and a series of layers of hidden units 

<math display="inline" id="Deep_learning:39">
<semantics>
<mrow>
<mrow>
<msup>
<mi>𝒉</mi>
<mrow>
<mo stretchy="false">(</mo>
<mn>1</mn>
<mo stretchy="false">)</mo>
</mrow>
</msup>
<mo>∈</mo>
<msup>
<mrow>
<mo stretchy="false">{</mo>
<mn>0</mn>
<mo>,</mo>
<mn>1</mn>
<mo stretchy="false">}</mo>
</mrow>
<msub>
<mi>F</mi>
<mn>1</mn>
</msub>
</msup>
</mrow>
<mo>,</mo>
<mrow>
<mrow>
<msup>
<mi>𝒉</mi>
<mrow>
<mo stretchy="false">(</mo>
<mn>2</mn>
<mo stretchy="false">)</mo>
</mrow>
</msup>
<mo>∈</mo>
<mrow>
<msup>
<mrow>
<mo stretchy="false">{</mo>
<mn>0</mn>
<mo>,</mo>
<mn>1</mn>
<mo stretchy="false">}</mo>
</mrow>
<msub>
<mi>F</mi>
<mn>2</mn>
</msub>
</msup>
<mo>,</mo>
<mi mathvariant="normal">…</mi>
</mrow>
</mrow>
<mo>,</mo>
<mrow>
<msup>
<mi>𝒉</mi>
<mrow>
<mo stretchy="false">(</mo>
<mi>L</mi>
<mo stretchy="false">)</mo>
</mrow>
</msup>
<mo>∈</mo>
<msup>
<mrow>
<mo stretchy="false">{</mo>
<mn>0</mn>
<mo>,</mo>
<mn>1</mn>
<mo stretchy="false">}</mo>
</mrow>
<msub>
<mi>F</mi>
<mi>L</mi>
</msub>
</msup>
</mrow>
</mrow>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<csymbol cd="ambiguous">formulae-sequence</csymbol>
<apply>
<in></in>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<ci>𝒉</ci>
<cn type="integer">1</cn>
</apply>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<set>
<cn type="integer">0</cn>
<cn type="integer">1</cn>
</set>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>F</ci>
<cn type="integer">1</cn>
</apply>
</apply>
</apply>
<apply>
<csymbol cd="ambiguous">formulae-sequence</csymbol>
<apply>
<in></in>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<ci>𝒉</ci>
<cn type="integer">2</cn>
</apply>
<list>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<set>
<cn type="integer">0</cn>
<cn type="integer">1</cn>
</set>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>F</ci>
<cn type="integer">2</cn>
</apply>
</apply>
<ci>normal-…</ci>
</list>
</apply>
<apply>
<in></in>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<ci>𝒉</ci>
<ci>L</ci>
</apply>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<set>
<cn type="integer">0</cn>
<cn type="integer">1</cn>
</set>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>F</ci>
<ci>L</ci>
</apply>
</apply>
</apply>
</apply>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   \boldsymbol{h}^{(1)}\in\{0,1\}^{F_{1}},\boldsymbol{h}^{(2)}\in\{0,1\}^{F_{2}},%
\ldots,\boldsymbol{h}^{(L)}\in\{0,1\}^{F_{L}}
  </annotation>
</semantics>
</math>

. There is no connection between the units of the same layer (like <a href="Restricted_Boltzmann_machine" title="wikilink">RBM</a>). For the , we can write the probability which is assigned to vector 

<math display="inline" id="Deep_learning:40">
<semantics>
<mi>ν</mi>
<annotation-xml encoding="MathML-Content">
<ci>ν</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   \nu
  </annotation>
</semantics>
</math>

 as:</p>

<p>
<math display="inline" id="Deep_learning:41">
<semantics>
<mrow>
<mrow>
<mrow>
<mi>p</mi>
<mrow>
<mo stretchy="false">(</mo>
<mi>𝝂</mi>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
<mo>=</mo>
<mrow>
<mfrac>
<mn>1</mn>
<mi>Z</mi>
</mfrac>
<mrow>
<msub>
<mo largeop="true" symmetric="true">∑</mo>
<mi>h</mi>
</msub>
<msup>
<mi>e</mi>
<mrow>
<mrow>
<mstyle displaystyle="false">
<msub>
<mo largeop="true" symmetric="true">∑</mo>
<mrow>
<mi>i</mi>
<mi>j</mi>
</mrow>
</msub>
</mstyle>
<mrow>
<msubsup>
<mi>W</mi>
<mrow>
<mi>i</mi>
<mi>j</mi>
</mrow>
<mrow>
<mo stretchy="false">(</mo>
<mn>1</mn>
<mo stretchy="false">)</mo>
</mrow>
</msubsup>
<msub>
<mi>ν</mi>
<mi>i</mi>
</msub>
<msubsup>
<mi>h</mi>
<mi>j</mi>
<mrow>
<mo stretchy="false">(</mo>
<mn>1</mn>
<mo stretchy="false">)</mo>
</mrow>
</msubsup>
</mrow>
</mrow>
<mo>+</mo>
<mrow>
<mstyle displaystyle="false">
<msub>
<mo largeop="true" symmetric="true">∑</mo>
<mrow>
<mi>j</mi>
<mi>l</mi>
</mrow>
</msub>
</mstyle>
<mrow>
<msubsup>
<mi>W</mi>
<mrow>
<mi>j</mi>
<mi>l</mi>
</mrow>
<mrow>
<mo stretchy="false">(</mo>
<mn>2</mn>
<mo stretchy="false">)</mo>
</mrow>
</msubsup>
<msubsup>
<mi>h</mi>
<mi>j</mi>
<mrow>
<mo stretchy="false">(</mo>
<mn>1</mn>
<mo stretchy="false">)</mo>
</mrow>
</msubsup>
<msubsup>
<mi>h</mi>
<mi>l</mi>
<mrow>
<mo stretchy="false">(</mo>
<mn>2</mn>
<mo stretchy="false">)</mo>
</mrow>
</msubsup>
</mrow>
</mrow>
<mo>+</mo>
<mrow>
<mstyle displaystyle="false">
<msub>
<mo largeop="true" symmetric="true">∑</mo>
<mrow>
<mi>l</mi>
<mi>m</mi>
</mrow>
</msub>
</mstyle>
<mrow>
<msubsup>
<mi>W</mi>
<mrow>
<mi>l</mi>
<mi>m</mi>
</mrow>
<mrow>
<mo stretchy="false">(</mo>
<mn>3</mn>
<mo stretchy="false">)</mo>
</mrow>
</msubsup>
<msubsup>
<mi>h</mi>
<mi>l</mi>
<mrow>
<mo stretchy="false">(</mo>
<mn>2</mn>
<mo stretchy="false">)</mo>
</mrow>
</msubsup>
<msubsup>
<mi>h</mi>
<mi>m</mi>
<mrow>
<mo stretchy="false">(</mo>
<mn>3</mn>
<mo stretchy="false">)</mo>
</mrow>
</msubsup>
</mrow>
</mrow>
</mrow>
</msup>
</mrow>
</mrow>
</mrow>
<mo>,</mo>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<eq></eq>
<apply>
<times></times>
<ci>p</ci>
<ci>𝝂</ci>
</apply>
<apply>
<times></times>
<apply>
<divide></divide>
<cn type="integer">1</cn>
<ci>Z</ci>
</apply>
<apply>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<sum></sum>
<ci>h</ci>
</apply>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<ci>e</ci>
<apply>
<plus></plus>
<apply>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<sum></sum>
<apply>
<times></times>
<ci>i</ci>
<ci>j</ci>
</apply>
</apply>
<apply>
<times></times>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>W</ci>
<apply>
<times></times>
<ci>i</ci>
<ci>j</ci>
</apply>
</apply>
<cn type="integer">1</cn>
</apply>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>ν</ci>
<ci>i</ci>
</apply>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>h</ci>
<ci>j</ci>
</apply>
<cn type="integer">1</cn>
</apply>
</apply>
</apply>
<apply>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<sum></sum>
<apply>
<times></times>
<ci>j</ci>
<ci>l</ci>
</apply>
</apply>
<apply>
<times></times>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>W</ci>
<apply>
<times></times>
<ci>j</ci>
<ci>l</ci>
</apply>
</apply>
<cn type="integer">2</cn>
</apply>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>h</ci>
<ci>j</ci>
</apply>
<cn type="integer">1</cn>
</apply>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>h</ci>
<ci>l</ci>
</apply>
<cn type="integer">2</cn>
</apply>
</apply>
</apply>
<apply>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<sum></sum>
<apply>
<times></times>
<ci>l</ci>
<ci>m</ci>
</apply>
</apply>
<apply>
<times></times>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>W</ci>
<apply>
<times></times>
<ci>l</ci>
<ci>m</ci>
</apply>
</apply>
<cn type="integer">3</cn>
</apply>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>h</ci>
<ci>l</ci>
</apply>
<cn type="integer">2</cn>
</apply>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>h</ci>
<ci>m</ci>
</apply>
<cn type="integer">3</cn>
</apply>
</apply>
</apply>
</apply>
</apply>
</apply>
</apply>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   p(\boldsymbol{\nu})=\frac{1}{Z}\sum_{h}e^{\sum_{ij}W_{ij}^{(1)}\nu_{i}h_{j}^{(%
1)}+\sum_{jl}W_{jl}^{(2)}h_{j}^{(1)}h_{l}^{(2)}+\sum_{lm}W_{lm}^{(3)}h_{l}^{(2%
)}h_{m}^{(3)}},
  </annotation>
</semantics>
</math>
</p>

<p>where 

<math display="inline" id="Deep_learning:42">
<semantics>
<mrow>
<mi>𝒉</mi>
<mo>=</mo>
<mrow>
<mo stretchy="false">{</mo>
<msup>
<mi>𝒉</mi>
<mrow>
<mo stretchy="false">(</mo>
<mn>1</mn>
<mo stretchy="false">)</mo>
</mrow>
</msup>
<mo>,</mo>
<msup>
<mi>𝒉</mi>
<mrow>
<mo stretchy="false">(</mo>
<mn>2</mn>
<mo stretchy="false">)</mo>
</mrow>
</msup>
<mo>,</mo>
<msup>
<mi>𝒉</mi>
<mrow>
<mo stretchy="false">(</mo>
<mn>3</mn>
<mo stretchy="false">)</mo>
</mrow>
</msup>
<mo stretchy="false">}</mo>
</mrow>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<eq></eq>
<ci>𝒉</ci>
<set>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<ci>𝒉</ci>
<cn type="integer">1</cn>
</apply>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<ci>𝒉</ci>
<cn type="integer">2</cn>
</apply>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<ci>𝒉</ci>
<cn type="integer">3</cn>
</apply>
</set>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   \boldsymbol{h}=\{\boldsymbol{h}^{(1)},\boldsymbol{h}^{(2)},\boldsymbol{h}^{(3)}\}
  </annotation>
</semantics>
</math>

 are the set of hidden units, and 

<math display="inline" id="Deep_learning:43">
<semantics>
<mrow>
<mi>θ</mi>
<mo>=</mo>
<mrow>
<mo stretchy="false">{</mo>
<msup>
<mi>𝑾</mi>
<mrow>
<mo stretchy="false">(</mo>
<mn>1</mn>
<mo stretchy="false">)</mo>
</mrow>
</msup>
<mo>,</mo>
<msup>
<mi>𝑾</mi>
<mrow>
<mo stretchy="false">(</mo>
<mn>2</mn>
<mo stretchy="false">)</mo>
</mrow>
</msup>
<mo>,</mo>
<msup>
<mi>𝑾</mi>
<mrow>
<mo stretchy="false">(</mo>
<mn>3</mn>
<mo stretchy="false">)</mo>
</mrow>
</msup>
<mo stretchy="false">}</mo>
</mrow>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<eq></eq>
<ci>θ</ci>
<set>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<ci>𝑾</ci>
<cn type="integer">1</cn>
</apply>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<ci>𝑾</ci>
<cn type="integer">2</cn>
</apply>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<ci>𝑾</ci>
<cn type="integer">3</cn>
</apply>
</set>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   \theta=\{\boldsymbol{W}^{(1)},\boldsymbol{W}^{(2)},\boldsymbol{W}^{(3)}\}
  </annotation>
</semantics>
</math>

 are the model parameters, representing visible-hidden and hidden-hidden <em>symmetric interaction</em>, since they are undirected links. As it is clear by setting 

<math display="inline" id="Deep_learning:44">
<semantics>
<mrow>
<msup>
<mi>𝑾</mi>
<mrow>
<mo stretchy="false">(</mo>
<mn>2</mn>
<mo stretchy="false">)</mo>
</mrow>
</msup>
<mo>=</mo>
<mn>0</mn>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<eq></eq>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<ci>𝑾</ci>
<cn type="integer">2</cn>
</apply>
<cn type="integer">0</cn>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   \boldsymbol{W}^{(2)}=0
  </annotation>
</semantics>
</math>

 and 

<math display="inline" id="Deep_learning:45">
<semantics>
<mrow>
<msup>
<mi>𝑾</mi>
<mrow>
<mo stretchy="false">(</mo>
<mn>3</mn>
<mo stretchy="false">)</mo>
</mrow>
</msup>
<mo>=</mo>
<mn>0</mn>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<eq></eq>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<ci>𝑾</ci>
<cn type="integer">3</cn>
</apply>
<cn type="integer">0</cn>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   \boldsymbol{W}^{(3)}=0
  </annotation>
</semantics>
</math>

 the network becomes the well-known <a href="Restricted_Boltzmann_machine" title="wikilink">Restricted Boltzmann machine</a>.<a class="footnoteRef" href="#fn116" id="fnref116"><sup>116</sup></a></p>

<p>There are several reasons which motivate us to take advantage of deep Boltzmann machine architectures. Like <a href="Deep_belief_network" title="wikilink">DBNs</a>, they benefit from the ability of learning complex and abstract internal representations of the input in tasks such as <a href="Object_recognition" title="wikilink">object</a> or <a href="speech_recognition" title="wikilink">speech recognition</a>, with the use of <em>limited number</em> of <em>labeled</em> data to fine-tune the representations built based on a large <em>supply</em> of <em>unlabeled</em> sensory input data. However, unlike  and <em>deep convolutional</em> neural networks, they adopt the <a class="uri" href="inference" title="wikilink">inference</a> and training procedure in both directions, bottom-up and top-down pass, which enable the  to better unveil the representations of the ambiguous and complex input structures,<a class="footnoteRef" href="#fn117" id="fnref117"><sup>117</sup></a> .<a class="footnoteRef" href="#fn118" id="fnref118"><sup>118</sup></a></p>

<p>Since the <em>exact maximum likelihood</em> learning is intractable for the , we may perform the <em>approximate maximum likelihood</em> learning. There is another possibility, to use <em>mean-field</em> inference to estimate data-dependent expectations, incorporation with a <em><a href="Markov_chain_Monte_Carlo" title="wikilink">Markov chain Monte Carlo</a></em> <em>(MCMC)</em> based stochastic approximation technique to approximate the expected <em>sufficient statistics</em> of the model.<a class="footnoteRef" href="#fn119" id="fnref119"><sup>119</sup></a></p>

<p>We can see the difference between  and . In , the top two layers form a <a href="restricted_Boltzmann_machine" title="wikilink">restricted Boltzmann machine</a> which is an undirected <a href="graphical_model" title="wikilink">graphical model</a>, but the lower layers form a directed generative model.</p>

<p>Apart from all the advantages of  discussed so far, they have a crucial disadvantage which limits the performance and functionality of this kind of architecture. The approximate inference, which is based on mean-field method, is about 25 to 50 times slower than a single bottom-up pass in . This time consuming task make the joint optimization, quite impractical for large data sets, and seriously restricts the use of  in tasks such as feature representations (the mean-field inference have to be performed for each new test input).<a class="footnoteRef" href="#fn120" id="fnref120"><sup>120</sup></a></p>
<h3 id="stacked-denoising-auto-encoders">Stacked (Denoising) Auto-Encoders</h3>

<p>The auto encoder idea is motivated by the concept of <em>good</em> representation. For instance for the case of <a href="Linear_classifier" title="wikilink">classifier</a> it is possible to define that a <em>good representation is one that will yield a better performing classifier</em>.</p>

<p>An <em>encoder</em> is referred to a deterministic mapping 

<math display="inline" id="Deep_learning:46">
<semantics>
<msub>
<mi>f</mi>
<mi>θ</mi>
</msub>
<annotation-xml encoding="MathML-Content">
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>f</ci>
<ci>θ</ci>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   f_{\theta}
  </annotation>
</semantics>
</math>

 that transforms an input vector<strong>'' x</strong>'' into hidden representation <strong><em>y</em></strong>, where 

<math display="inline" id="Deep_learning:47">
<semantics>
<mrow>
<mi>θ</mi>
<mo>=</mo>
<mrow>
<mo stretchy="false">{</mo>
<mi>𝑾</mi>
<mo>,</mo>
<mi>b</mi>
<mo stretchy="false">}</mo>
</mrow>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<eq></eq>
<ci>θ</ci>
<set>
<ci>𝑾</ci>
<ci>b</ci>
</set>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   \theta=\{\boldsymbol{W},b\}
  </annotation>
</semantics>
</math>

, 

<math display="inline" id="Deep_learning:48">
<semantics>
<mi>𝑾</mi>
<annotation-xml encoding="MathML-Content">
<ci>𝑾</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   \boldsymbol{W}
  </annotation>
</semantics>
</math>

 is the weight matrix and <strong>b</strong> is an offset vector (bias). On the contrary a <em>decoder</em> maps back the hidden representation <strong>y</strong> to the reconstructed input <em>'</em>z <em>'</em> via 

<math display="inline" id="Deep_learning:49">
<semantics>
<msub>
<mi>g</mi>
<mi>θ</mi>
</msub>
<annotation-xml encoding="MathML-Content">
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>g</ci>
<ci>θ</ci>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   g_{\theta}
  </annotation>
</semantics>
</math>

. The whole process of auto encoding is to compare this reconstructed input to the original and try to minimize this error to make the reconstructed value as close as possible to the original.</p>

<p>In <em>stacked denoising auto encoders</em>, the partially corrupted output is cleaned (<em>denoised</em>). This fact has been introduced in <a class="footnoteRef" href="#fn121" id="fnref121"><sup>121</sup></a> with a specific approach to <em>good</em> representation, a <em>good representation is one that can be obtained <a href="Robustness_(computer_science)" title="wikilink">robustly</a> from a corrupted input and that will be useful for recovering the corresponding clean input.</em> Implicit in this definition are the ideas of</p>
<ul>
<li>The higher level representations are relatively stable and robust to the corruption of the input;</li>
<li>It is required to extract features that are useful for representation of the input distribution.</li>
</ul>

<p>The algorithm consists of multiple steps; starts by a <a href="stochastic_mapping" title="wikilink">stochastic mapping</a> of 

<math display="inline" id="Deep_learning:50">
<semantics>
<mi>𝒙</mi>
<annotation-xml encoding="MathML-Content">
<ci>𝒙</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   \boldsymbol{x}
  </annotation>
</semantics>
</math>

 to 

<math display="inline" id="Deep_learning:51">
<semantics>
<mover accent="true">
<mi>𝒙</mi>
<mo stretchy="false">~</mo>
</mover>
<annotation-xml encoding="MathML-Content">
<apply>
<ci>normal-~</ci>
<ci>𝒙</ci>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   \tilde{\boldsymbol{x}}
  </annotation>
</semantics>
</math>

 through 

<math display="inline" id="Deep_learning:52">
<semantics>
<mrow>
<msub>
<mi>q</mi>
<mi>D</mi>
</msub>
<mrow>
<mo stretchy="false">(</mo>
<mover accent="true">
<mi>𝒙</mi>
<mo stretchy="false">~</mo>
</mover>
<mo stretchy="false">|</mo>
<mi>𝒙</mi>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
<annotation-xml encoding="MathML-Content">
<cerror>
<csymbol cd="ambiguous">fragments</csymbol>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>q</ci>
<ci>D</ci>
</apply>
<cerror>
<csymbol cd="ambiguous">fragments</csymbol>
<ci>normal-(</ci>
<apply>
<ci>normal-~</ci>
<ci>𝒙</ci>
</apply>
<ci>normal-|</ci>
<csymbol cd="unknown">x</csymbol>
<ci>normal-)</ci>
</cerror>
</cerror>
</annotation-xml>
<annotation encoding="application/x-tex">
   q_{D}(\tilde{\boldsymbol{x}}|\boldsymbol{x})
  </annotation>
</semantics>
</math>

, this is the corrupting step. Then the corrupted input 

<math display="inline" id="Deep_learning:53">
<semantics>
<mover accent="true">
<mi>𝒙</mi>
<mo stretchy="false">~</mo>
</mover>
<annotation-xml encoding="MathML-Content">
<apply>
<ci>normal-~</ci>
<ci>𝒙</ci>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   \tilde{\boldsymbol{x}}
  </annotation>
</semantics>
</math>

 passes through a basic auto encoder process and is mapped to a hidden representation 

<math display="inline" id="Deep_learning:54">
<semantics>
<mrow>
<mi>𝒚</mi>
<mo>=</mo>
<mrow>
<msub>
<mi>f</mi>
<mi>θ</mi>
</msub>
<mrow>
<mo stretchy="false">(</mo>
<mover accent="true">
<mi>𝒙</mi>
<mo stretchy="false">~</mo>
</mover>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
<mo>=</mo>
<mrow>
<mi>s</mi>
<mrow>
<mo stretchy="false">(</mo>
<mrow>
<mrow>
<mi>𝑾</mi>
<mover accent="true">
<mi>𝒙</mi>
<mo stretchy="false">~</mo>
</mover>
</mrow>
<mo>+</mo>
<mi>b</mi>
</mrow>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<and></and>
<apply>
<eq></eq>
<ci>𝒚</ci>
<apply>
<times></times>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>f</ci>
<ci>θ</ci>
</apply>
<apply>
<ci>normal-~</ci>
<ci>𝒙</ci>
</apply>
</apply>
</apply>
<apply>
<eq></eq>
<share href="#.cmml">
</share>
<apply>
<times></times>
<ci>s</ci>
<apply>
<plus></plus>
<apply>
<times></times>
<ci>𝑾</ci>
<apply>
<ci>normal-~</ci>
<ci>𝒙</ci>
</apply>
</apply>
<ci>b</ci>
</apply>
</apply>
</apply>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   \boldsymbol{y}=f_{\theta}(\tilde{\boldsymbol{x}})=s(\boldsymbol{W}\tilde{%
\boldsymbol{x}}+b)
  </annotation>
</semantics>
</math>

. From this hidden representation we can reconstruct 

<math display="inline" id="Deep_learning:55">
<semantics>
<mrow>
<mi>𝒛</mi>
<mo>=</mo>
<mrow>
<msub>
<mi>g</mi>
<mi>θ</mi>
</msub>
<mrow>
<mo stretchy="false">(</mo>
<mi>𝒚</mi>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<eq></eq>
<ci>𝒛</ci>
<apply>
<times></times>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>g</ci>
<ci>θ</ci>
</apply>
<ci>𝒚</ci>
</apply>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   \boldsymbol{z}=g_{\theta}(\boldsymbol{y})
  </annotation>
</semantics>
</math>

. In the last stage a <a href="minimization_algorithm" title="wikilink">minimization algorithm</a> is done in order to have a <strong><em>z</em></strong> as close as possible to uncorrupted input 

<math display="inline" id="Deep_learning:56">
<semantics>
<mi>𝒙</mi>
<annotation-xml encoding="MathML-Content">
<ci>𝒙</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   \boldsymbol{x}
  </annotation>
</semantics>
</math>

. The reconstruction error 

<math display="inline" id="Deep_learning:57">
<semantics>
<mrow>
<msub>
<mi>L</mi>
<mi>H</mi>
</msub>
<mrow>
<mo stretchy="false">(</mo>
<mi>𝒙</mi>
<mo>,</mo>
<mi>𝒛</mi>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<times></times>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>L</ci>
<ci>H</ci>
</apply>
<interval closure="open">
<ci>𝒙</ci>
<ci>𝒛</ci>
</interval>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   L_{H}(\boldsymbol{x},\boldsymbol{z})
  </annotation>
</semantics>
</math>

 might be either the <a class="uri" href="cross-entropy" title="wikilink">cross-entropy</a> loss with an affine-sigmoid decoder, or the squared error loss with an affine decoder.<a class="footnoteRef" href="#fn122" id="fnref122"><sup>122</sup></a></p>

<p>In order to make a deep architecture, auto encoders stack one on top of another. Once the encoding function 

<math display="inline" id="Deep_learning:58">
<semantics>
<msub>
<mi>f</mi>
<mi>θ</mi>
</msub>
<annotation-xml encoding="MathML-Content">
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>f</ci>
<ci>θ</ci>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   f_{\theta}
  </annotation>
</semantics>
</math>

 of the first denoising auto encoder is learned and used to uncorrupt the input (corrupted input), we can train the second level.<a class="footnoteRef" href="#fn123" id="fnref123"><sup>123</sup></a></p>

<p>Once the stacked auto encoder is trained, its output might be used as the input to a <a href="supervised_learning" title="wikilink">supervised learning</a> algorithm such as <a href="support_vector_machine" title="wikilink">support vector machine</a> classifier or a multiclass <a href="logistic_regression" title="wikilink">logistic regression</a>.<a class="footnoteRef" href="#fn124" id="fnref124"><sup>124</sup></a></p>
<h3 id="deep-stacking-networks">Deep stacking networks</h3>

<p>One of the deep architectures recently introduced in<a class="footnoteRef" href="#fn125" id="fnref125"><sup>125</sup></a> which is based on building hierarchies with blocks of simplified <a href="neural_network" title="wikilink">neural network</a> modules, is called <em>deep convex network</em>. They are called "convex" because of the formulation of the weights learning problem, which is a <a href="convex_optimization_problem" title="wikilink">convex optimization problem</a> with a <a href="Closed-form_expression" title="wikilink">closed-form solution</a>. The network is also called the <em>deep stacking network (DSN)</em>,<a class="footnoteRef" href="#fn126" id="fnref126"><sup>126</sup></a> emphasizing on this fact that a similar mechanism as the <em>stacked generalization</em> is used.<a class="footnoteRef" href="#fn127" id="fnref127"><sup>127</sup></a></p>

<p>The  blocks, each consisting of a simple, easy-to-learn module, are stacked to form the overall deep network. It can be trained block-wise in a <a href="Supervised_learning" title="wikilink">supervised</a> fashion without the need for <a class="uri" href="back-propagation" title="wikilink">back-propagation</a> for the entire blocks.<a class="footnoteRef" href="#fn128" id="fnref128"><sup>128</sup></a></p>

<p>As designed in <a class="footnoteRef" href="#fn129" id="fnref129"><sup>129</sup></a> each block consists of a simplified <a href="Multilayer_perceptron" title="wikilink">MLP</a> with a single hidden layer. It comprises a weight matrix <strong><em>U</em></strong> as the connection between the logistic <a href="Sigmoid_function" title="wikilink">sigmoidal</a> <a href="Artificial_neuron" title="wikilink">units</a> of the hidden layer <strong><em>h</em></strong> to the linear output layer <strong><em>y</em></strong>, and a weight matrix <strong><em>W</em></strong> which connects each input of the blocks to their respective hidden layers. If we assume that the target vectors <strong><em>t</em></strong> be arranged to form the columns of <strong><em>T</em></strong> (the target matrix), let the input data vectors <strong><em>x</em></strong> be arranged to form the columns of <strong><em>X</em></strong>, let 

<math display="inline" id="Deep_learning:59">
<semantics>
<mrow>
<mi>𝑯</mi>
<mo>=</mo>
<mrow>
<mi>σ</mi>
<mrow>
<mo stretchy="false">(</mo>
<mrow>
<msup>
<mi>𝑾</mi>
<mi>T</mi>
</msup>
<mi>𝑿</mi>
</mrow>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<eq></eq>
<ci>𝑯</ci>
<apply>
<times></times>
<ci>σ</ci>
<apply>
<times></times>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<ci>𝑾</ci>
<ci>T</ci>
</apply>
<ci>𝑿</ci>
</apply>
</apply>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   \boldsymbol{H}=\sigma(\boldsymbol{W}^{T}\boldsymbol{X})
  </annotation>
</semantics>
</math>

 denote the matrix of hidden units, and assume the lower-layer weights <strong><em>W</em></strong> are known (training layer-by-layer). The function performs the element-wise logistic sigmoid operation. Then learning the upper-layer weight matrix <strong><em>U</em></strong> given other weights in the network can be formulated as a convex optimization problem:</p>

<p>
<math display="block" id="Deep_learning:60">
<semantics>
<mrow>
<mrow>
<mrow>
<munder>
<mi>min</mi>
<msup>
<mi>U</mi>
<mi>T</mi>
</msup>
</munder>
<mi>f</mi>
</mrow>
<mo>=</mo>
<msubsup>
<mrow>
<mo fence="true">||</mo>
<mrow>
<mrow>
<msup>
<mi>𝑼</mi>
<mi>T</mi>
</msup>
<mi>𝑯</mi>
</mrow>
<mo>-</mo>
<mi>𝑻</mi>
</mrow>
<mo fence="true">||</mo>
</mrow>
<mi>F</mi>
<mn>2</mn>
</msubsup>
</mrow>
<mo>,</mo>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<eq></eq>
<apply>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<min></min>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<ci>U</ci>
<ci>T</ci>
</apply>
</apply>
<ci>f</ci>
</apply>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<apply>
<csymbol cd="latexml">norm</csymbol>
<apply>
<minus></minus>
<apply>
<times></times>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<ci>𝑼</ci>
<ci>T</ci>
</apply>
<ci>𝑯</ci>
</apply>
<ci>𝑻</ci>
</apply>
</apply>
<cn type="integer">2</cn>
</apply>
<ci>F</ci>
</apply>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   \min_{U^{T}}f=||\boldsymbol{U}^{T}\boldsymbol{H}-\boldsymbol{T}||^{2}_{F},
  </annotation>
</semantics>
</math>
</p>

<p>which has a closed-form solution. The input to the first block <strong><em>X</em></strong> only contains the original data, however in the upper blocks in addition to this original (raw) data there is a copy of the lower-block(s) output <em>y</em>.</p>

<p>In each block an estimate of the same final label class <em>y</em> is produced, then this estimated label concatenated with original input to form the <em>expanded input</em> for the upper block. In contrast with other deep architectures, such as <a href="Deep_belief_network" title="wikilink">DBNs</a>, the goal is not to discover the transformed <a href="Feature_(machine_learning)" title="wikilink">feature</a> representation. Regarding the structure of the hierarchy of this kind of architecture, it makes the parallel training straightforward as the problem is naturally a batch-mode optimization one. In purely <a href="Discriminative_model" title="wikilink">discriminative tasks</a>  performance is better than the conventional <a href="Deep_belief_network" title="wikilink">DBN</a>.<a class="footnoteRef" href="#fn130" id="fnref130"><sup>130</sup></a></p>
<h3 id="tensor-deep-stacking-networks-t-dsn">Tensor Deep Stacking Networks (T-DSN)</h3>

<p>This architecture is an extension of the . It improves the  in two important ways, using the higher order information by means of <a class="uri" href="covariance" title="wikilink">covariance</a> statistics and transforming the <a href="Convex_optimization" title="wikilink">non-convex problem</a> of the lower-layer to a convex sub-problem of the upper-layer.<a class="footnoteRef" href="#fn131" id="fnref131"><sup>131</sup></a></p>

<p>Unlike the , the covariance statistics of the data is employed using a <a href="bilinear_map" title="wikilink">bilinear mapping</a> from two distinct sets of hidden units in the same layer to predictions via a third-order <a class="uri" href="tensor" title="wikilink">tensor</a>.</p>

<p>The scalability and parallelization are the two important factors in the learning algorithms which are not considered seriously in the conventional .<a class="footnoteRef" href="#fn132" id="fnref132"><sup>132</sup></a><a class="footnoteRef" href="#fn133" id="fnref133"><sup>133</sup></a><a class="footnoteRef" href="#fn134" id="fnref134"><sup>134</sup></a> All the learning process for the  (and  as well) is done on a batch-mode basis so as to make the parallelization possible on a <a href="Computer_cluster" title="wikilink">cluster</a> of <a class="uri" href="CPU" title="wikilink">CPU</a> or <a class="uri" href="GPU" title="wikilink">GPU</a> nodes.<a class="footnoteRef" href="#fn135" id="fnref135"><sup>135</sup></a><a class="footnoteRef" href="#fn136" id="fnref136"><sup>136</sup></a> Parallelization gives the opportunity to scale up the design to larger (deeper) architectures and data sets.</p>

<p>The basic architecture is suitable for diverse tasks such as <a href="Statistical_classification" title="wikilink">classification</a> and <a href="regression_analysis" title="wikilink">regression</a>.</p>
<h3 id="spike-and-slab-rbms-ssrbms">Spike-and-Slab RBMs (ssRBMs)</h3>

<p>The need for real-valued inputs which are employed in Gaussian <a href="Restricted_Boltzmann_machine" title="wikilink">RBMs</a> (GRBMs), motivates scientists seeking new methods. One of these methods is the <em>spike and slab</em> <a href="Restricted_Boltzmann_machine" title="wikilink">RBM</a> (<em>ss</em><a href="Restricted_Boltzmann_machine" title="wikilink">RBMs</a>), which models continuous-valued inputs with strictly <a href="Binary_variable" title="wikilink">binary</a> <a href="latent_variable" title="wikilink">latent variables</a>.<a class="footnoteRef" href="#fn137" id="fnref137"><sup>137</sup></a></p>

<p>Similar to basic <a href="Restricted_Boltzmann_machine" title="wikilink">RBMs</a> and its variants, the spike and slab <a href="Restricted_Boltzmann_machine" title="wikilink">RBM</a> is a <a href="bipartite_graph" title="wikilink">bipartite graph</a>. Like G<a href="Restricted_Boltzmann_machine" title="wikilink">RBM</a>, the visible units (input) are real-valued. The difference arises in the hidden layer, where each hidden unit come along with a binary spike variable and real-valued slab variable. These terms (spike and slab) come from the statistics literature,<a class="footnoteRef" href="#fn138" id="fnref138"><sup>138</sup></a> and refer to a prior including a mixture of two components. One is a discrete probability mass at zero called spike, and the other is a density over continuous domain.<a class="footnoteRef" href="#fn139" id="fnref139"><sup>139</sup></a><a class="footnoteRef" href="#fn140" id="fnref140"><sup>140</sup></a></p>

<p>There is also an extension of the ss<a href="Restricted_Boltzmann_machine" title="wikilink">RBM</a> model, which is called µ-ss<a href="Restricted_Boltzmann_machine" title="wikilink">RBM</a>. This variant provides extra modeling capacity to the architecture using additional terms in the <a href="energy_function" title="wikilink">energy function</a>. One of these terms enable model to form a <a href="Conditional_probability_distribution" title="wikilink">conditional distribution</a> of the spike variables by means of marginalizing out the slab variables given an observation.</p>
<h3 id="compound-hierarchical-deep-models">Compound Hierarchical-Deep Models</h3>

<p>The class architectures called <em>compound HD models</em>, where HD stands for <em>Hierarchical-Deep</em> are structured as a composition of non-parametric <a href="Bayesian_network" title="wikilink">Bayesian models</a> with deep networks. The <a href="Feature_(machine_learning)" title="wikilink">features</a>, learned by deep architectures such as <a href="Deep_belief_network" title="wikilink">DBNs</a>,<a class="footnoteRef" href="#fn141" id="fnref141"><sup>141</sup></a> <a href="Deep_Boltzmann_Machines" title="wikilink">DBMs</a>,<a class="footnoteRef" href="#fn142" id="fnref142"><sup>142</sup></a> deep auto encoders,<a class="footnoteRef" href="#fn143" id="fnref143"><sup>143</sup></a> convolutional variants,<a class="footnoteRef" href="#fn144" id="fnref144"><sup>144</sup></a><a class="footnoteRef" href="#fn145" id="fnref145"><sup>145</sup></a> ssRBMs,<a class="footnoteRef" href="#fn146" id="fnref146"><sup>146</sup></a> deep coding network,<a class="footnoteRef" href="#fn147" id="fnref147"><sup>147</sup></a> DBNs with sparse feature learning,<a class="footnoteRef" href="#fn148" id="fnref148"><sup>148</sup></a> recursive neural networks,<a class="footnoteRef" href="#fn149" id="fnref149"><sup>149</sup></a> conditional DBNs,<a class="footnoteRef" href="#fn150" id="fnref150"><sup>150</sup></a> denoising auto encoders,<a class="footnoteRef" href="#fn151" id="fnref151"><sup>151</sup></a> are able to provide better representation for more rapid and accurate classification tasks with high-dimensional <a href="Training_set" title="wikilink">training data sets</a>. However, they are not quite powerful in learning novel classes with few examples, themselves. In these architectures, all units through the network are involved in the representation of the input (<em>distributed representations</em>), and they have to be adjusted together (high <a href="degree_of_freedom" title="wikilink">degree of freedom</a>). However, if we limit the degree of freedom, we make it easier for the model to learn new classes out of few training samples (less parameters to learn). <em>Hierarchical Bayesian (HB)</em> models, provide learning from few examples, for example <a class="footnoteRef" href="#fn152" id="fnref152"><sup>152</sup></a><a class="footnoteRef" href="#fn153" id="fnref153"><sup>153</sup></a><a class="footnoteRef" href="#fn154" id="fnref154"><sup>154</sup></a><a class="footnoteRef" href="#fn155" id="fnref155"><sup>155</sup></a><a class="footnoteRef" href="#fn156" id="fnref156"><sup>156</sup></a> for <a href="computer_vision" title="wikilink">computer vision</a>, <a class="uri" href="statistics" title="wikilink">statistics</a>, and <a href="cognitive_science" title="wikilink">cognitive science</a>.</p>

<p>Compound HD architectures try to integrate both characteristics of HB and deep networks. The compound HDP-DBM architecture, a <em>hierarchical Dirichlet process (HDP)</em> as a hierarchical model, incorporated with DBM architecture. It is a full <a href="generative_model" title="wikilink">generative model</a>, generalized from abstract concepts flowing through the layers of the model, which is able to synthesize new examples in novel classes that look <em>reasonably natural</em>. Note that all the levels are learned jointly by maximizing a joint <a href="Log_probability" title="wikilink">log-probability</a> score.<a class="footnoteRef" href="#fn157" id="fnref157"><sup>157</sup></a></p>

<p>Consider a DBM with three hidden layers, the probability of a visible input 

<math display="inline" id="Deep_learning:61">
<semantics>
<mi>𝝂</mi>
<annotation-xml encoding="MathML-Content">
<ci>𝝂</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   \boldsymbol{\nu}
  </annotation>
</semantics>
</math>

 is:</p>

<p>
<math display="inline" id="Deep_learning:62">
<semantics>
<mrow>
<mrow>
<mrow>
<mi>p</mi>
<mrow>
<mo stretchy="false">(</mo>
<mi>𝝂</mi>
<mo>,</mo>
<mi>ψ</mi>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
<mo>=</mo>
<mrow>
<mfrac>
<mn>1</mn>
<mi>Z</mi>
</mfrac>
<mrow>
<msub>
<mo largeop="true" symmetric="true">∑</mo>
<mi>h</mi>
</msub>
<msup>
<mi>e</mi>
<mrow>
<mrow>
<mstyle displaystyle="false">
<msub>
<mo largeop="true" symmetric="true">∑</mo>
<mrow>
<mi>i</mi>
<mi>j</mi>
</mrow>
</msub>
</mstyle>
<mrow>
<msubsup>
<mi>W</mi>
<mrow>
<mi>i</mi>
<mi>j</mi>
</mrow>
<mrow>
<mo stretchy="false">(</mo>
<mn>1</mn>
<mo stretchy="false">)</mo>
</mrow>
</msubsup>
<msub>
<mi>ν</mi>
<mi>i</mi>
</msub>
<msubsup>
<mi>h</mi>
<mi>j</mi>
<mn>1</mn>
</msubsup>
</mrow>
</mrow>
<mo>+</mo>
<mrow>
<mstyle displaystyle="false">
<msub>
<mo largeop="true" symmetric="true">∑</mo>
<mrow>
<mi>j</mi>
<mi>l</mi>
</mrow>
</msub>
</mstyle>
<mrow>
<msubsup>
<mi>W</mi>
<mrow>
<mi>j</mi>
<mi>l</mi>
</mrow>
<mrow>
<mo stretchy="false">(</mo>
<mn>2</mn>
<mo stretchy="false">)</mo>
</mrow>
</msubsup>
<msubsup>
<mi>h</mi>
<mi>j</mi>
<mn>1</mn>
</msubsup>
<msubsup>
<mi>h</mi>
<mi>l</mi>
<mn>2</mn>
</msubsup>
</mrow>
</mrow>
<mo>+</mo>
<mrow>
<mstyle displaystyle="false">
<msub>
<mo largeop="true" symmetric="true">∑</mo>
<mrow>
<mi>l</mi>
<mi>m</mi>
</mrow>
</msub>
</mstyle>
<mrow>
<msubsup>
<mi>W</mi>
<mrow>
<mi>l</mi>
<mi>m</mi>
</mrow>
<mrow>
<mo stretchy="false">(</mo>
<mn>3</mn>
<mo stretchy="false">)</mo>
</mrow>
</msubsup>
<msubsup>
<mi>h</mi>
<mi>l</mi>
<mn>2</mn>
</msubsup>
<msubsup>
<mi>h</mi>
<mi>m</mi>
<mn>3</mn>
</msubsup>
</mrow>
</mrow>
</mrow>
</msup>
</mrow>
</mrow>
</mrow>
<mo>,</mo>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<eq></eq>
<apply>
<times></times>
<ci>p</ci>
<interval closure="open">
<ci>𝝂</ci>
<ci>ψ</ci>
</interval>
</apply>
<apply>
<times></times>
<apply>
<divide></divide>
<cn type="integer">1</cn>
<ci>Z</ci>
</apply>
<apply>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<sum></sum>
<ci>h</ci>
</apply>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<ci>e</ci>
<apply>
<plus></plus>
<apply>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<sum></sum>
<apply>
<times></times>
<ci>i</ci>
<ci>j</ci>
</apply>
</apply>
<apply>
<times></times>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>W</ci>
<apply>
<times></times>
<ci>i</ci>
<ci>j</ci>
</apply>
</apply>
<cn type="integer">1</cn>
</apply>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>ν</ci>
<ci>i</ci>
</apply>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>h</ci>
<ci>j</ci>
</apply>
<cn type="integer">1</cn>
</apply>
</apply>
</apply>
<apply>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<sum></sum>
<apply>
<times></times>
<ci>j</ci>
<ci>l</ci>
</apply>
</apply>
<apply>
<times></times>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>W</ci>
<apply>
<times></times>
<ci>j</ci>
<ci>l</ci>
</apply>
</apply>
<cn type="integer">2</cn>
</apply>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>h</ci>
<ci>j</ci>
</apply>
<cn type="integer">1</cn>
</apply>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>h</ci>
<ci>l</ci>
</apply>
<cn type="integer">2</cn>
</apply>
</apply>
</apply>
<apply>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<sum></sum>
<apply>
<times></times>
<ci>l</ci>
<ci>m</ci>
</apply>
</apply>
<apply>
<times></times>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>W</ci>
<apply>
<times></times>
<ci>l</ci>
<ci>m</ci>
</apply>
</apply>
<cn type="integer">3</cn>
</apply>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>h</ci>
<ci>l</ci>
</apply>
<cn type="integer">2</cn>
</apply>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>h</ci>
<ci>m</ci>
</apply>
<cn type="integer">3</cn>
</apply>
</apply>
</apply>
</apply>
</apply>
</apply>
</apply>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   p(\boldsymbol{\nu},\psi)=\frac{1}{Z}\sum_{h}e^{\sum_{ij}W_{ij}^{(1)}\nu_{i}h_{%
j}^{1}+\sum_{jl}W_{jl}^{(2)}h_{j}^{1}h_{l}^{2}+\sum_{lm}W_{lm}^{(3)}h_{l}^{2}h%
_{m}^{3}},
  </annotation>
</semantics>
</math>
</p>

<p>where 

<math display="inline" id="Deep_learning:63">
<semantics>
<mrow>
<mi>𝒉</mi>
<mo>=</mo>
<mrow>
<mo stretchy="false">{</mo>
<msup>
<mi>𝒉</mi>
<mrow>
<mo stretchy="false">(</mo>
<mn>1</mn>
<mo stretchy="false">)</mo>
</mrow>
</msup>
<mo>,</mo>
<msup>
<mi>𝒉</mi>
<mrow>
<mo stretchy="false">(</mo>
<mn>2</mn>
<mo stretchy="false">)</mo>
</mrow>
</msup>
<mo>,</mo>
<msup>
<mi>𝒉</mi>
<mrow>
<mo stretchy="false">(</mo>
<mn>3</mn>
<mo stretchy="false">)</mo>
</mrow>
</msup>
<mo stretchy="false">}</mo>
</mrow>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<eq></eq>
<ci>𝒉</ci>
<set>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<ci>𝒉</ci>
<cn type="integer">1</cn>
</apply>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<ci>𝒉</ci>
<cn type="integer">2</cn>
</apply>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<ci>𝒉</ci>
<cn type="integer">3</cn>
</apply>
</set>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   \boldsymbol{h}=\{\boldsymbol{h}^{(1)},\boldsymbol{h}^{(2)},\boldsymbol{h}^{(3)}\}
  </annotation>
</semantics>
</math>

 are the set of hidden units, and 

<math display="inline" id="Deep_learning:64">
<semantics>
<mrow>
<mi>ψ</mi>
<mo>=</mo>
<mrow>
<mo stretchy="false">{</mo>
<msup>
<mi>𝑾</mi>
<mrow>
<mo stretchy="false">(</mo>
<mn>1</mn>
<mo stretchy="false">)</mo>
</mrow>
</msup>
<mo>,</mo>
<msup>
<mi>𝑾</mi>
<mrow>
<mo stretchy="false">(</mo>
<mn>2</mn>
<mo stretchy="false">)</mo>
</mrow>
</msup>
<mo>,</mo>
<msup>
<mi>𝑾</mi>
<mrow>
<mo stretchy="false">(</mo>
<mn>3</mn>
<mo stretchy="false">)</mo>
</mrow>
</msup>
<mo stretchy="false">}</mo>
</mrow>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<eq></eq>
<ci>ψ</ci>
<set>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<ci>𝑾</ci>
<cn type="integer">1</cn>
</apply>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<ci>𝑾</ci>
<cn type="integer">2</cn>
</apply>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<ci>𝑾</ci>
<cn type="integer">3</cn>
</apply>
</set>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   \psi=\{\boldsymbol{W}^{(1)},\boldsymbol{W}^{(2)},\boldsymbol{W}^{(3)}\}
  </annotation>
</semantics>
</math>

 are the model parameters, representing visible-hidden and hidden-hidden symmetric interaction terms.</p>

<p>After a DBM model has been learned, we have an undirected model that defines the joint distribution 

<math display="inline" id="Deep_learning:65">
<semantics>
<mrow>
<mi>P</mi>
<mrow>
<mo stretchy="false">(</mo>
<mi>ν</mi>
<mo>,</mo>
<msup>
<mi>h</mi>
<mn>1</mn>
</msup>
<mo>,</mo>
<msup>
<mi>h</mi>
<mn>2</mn>
</msup>
<mo>,</mo>
<msup>
<mi>h</mi>
<mn>3</mn>
</msup>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<times></times>
<ci>P</ci>
<vector>
<ci>ν</ci>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<ci>h</ci>
<cn type="integer">1</cn>
</apply>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<ci>h</ci>
<cn type="integer">2</cn>
</apply>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<ci>h</ci>
<cn type="integer">3</cn>
</apply>
</vector>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   P(\nu,h^{1},h^{2},h^{3})
  </annotation>
</semantics>
</math>

. One way to express what has been learned is the <a href="Discriminative_model" title="wikilink">conditional model</a>
<math display="inline" id="Deep_learning:66">
<semantics>
<mrow>
<mi>P</mi>
<mrow>
<mo stretchy="false">(</mo>
<mi>ν</mi>
<mo>,</mo>
<msup>
<mi>h</mi>
<mn>1</mn>
</msup>
<mo>,</mo>
<msup>
<mi>h</mi>
<mn>2</mn>
</msup>
<mo stretchy="false">|</mo>
<msup>
<mi>h</mi>
<mn>3</mn>
</msup>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
<annotation-xml encoding="MathML-Content">
<cerror>
<csymbol cd="ambiguous">fragments</csymbol>
<csymbol cd="unknown">P</csymbol>
<cerror>
<csymbol cd="ambiguous">fragments</csymbol>
<ci>normal-(</ci>
<csymbol cd="unknown">ν</csymbol>
<ci>normal-,</ci>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<ci>h</ci>
<cn type="integer">1</cn>
</apply>
<ci>normal-,</ci>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<ci>h</ci>
<cn type="integer">2</cn>
</apply>
<ci>normal-|</ci>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<ci>h</ci>
<cn type="integer">3</cn>
</apply>
<ci>normal-)</ci>
</cerror>
</cerror>
</annotation-xml>
<annotation encoding="application/x-tex">
   P(\nu,h^{1},h^{2}|h^{3})
  </annotation>
</semantics>
</math>

 and a prior term 

<math display="inline" id="Deep_learning:67">
<semantics>
<mrow>
<mi>P</mi>
<mrow>
<mo stretchy="false">(</mo>
<msup>
<mi>h</mi>
<mn>3</mn>
</msup>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<times></times>
<ci>P</ci>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<ci>h</ci>
<cn type="integer">3</cn>
</apply>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   P(h^{3})
  </annotation>
</semantics>
</math>

.</p>

<p>The part 

<math display="inline" id="Deep_learning:68">
<semantics>
<mrow>
<mi>P</mi>
<mrow>
<mo stretchy="false">(</mo>
<mi>ν</mi>
<mo>,</mo>
<msup>
<mi>h</mi>
<mn>1</mn>
</msup>
<mo>,</mo>
<msup>
<mi>h</mi>
<mn>2</mn>
</msup>
<mo stretchy="false">|</mo>
<msup>
<mi>h</mi>
<mn>3</mn>
</msup>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
<annotation-xml encoding="MathML-Content">
<cerror>
<csymbol cd="ambiguous">fragments</csymbol>
<csymbol cd="unknown">P</csymbol>
<cerror>
<csymbol cd="ambiguous">fragments</csymbol>
<ci>normal-(</ci>
<csymbol cd="unknown">ν</csymbol>
<ci>normal-,</ci>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<ci>h</ci>
<cn type="integer">1</cn>
</apply>
<ci>normal-,</ci>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<ci>h</ci>
<cn type="integer">2</cn>
</apply>
<ci>normal-|</ci>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<ci>h</ci>
<cn type="integer">3</cn>
</apply>
<ci>normal-)</ci>
</cerror>
</cerror>
</annotation-xml>
<annotation encoding="application/x-tex">
   P(\nu,h^{1},h^{2}|h^{3})
  </annotation>
</semantics>
</math>

, represents a <em>conditional</em> DBM model, which can be viewed as a two-layer DBM but with bias terms given by the states of 

<math display="inline" id="Deep_learning:69">
<semantics>
<msup>
<mi>h</mi>
<mn>3</mn>
</msup>
<annotation-xml encoding="MathML-Content">
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<ci>h</ci>
<cn type="integer">3</cn>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   h^{3}
  </annotation>
</semantics>
</math>

:</p>

<p>
<math display="inline" id="Deep_learning:70">
<semantics>
<mrow>
<mi>P</mi>
<mrow>
<mo stretchy="false">(</mo>
<mi>ν</mi>
<mo>,</mo>
<msup>
<mi>h</mi>
<mn>1</mn>
</msup>
<mo>,</mo>
<msup>
<mi>h</mi>
<mn>2</mn>
</msup>
<mo stretchy="false">|</mo>
<msup>
<mi>h</mi>
<mn>3</mn>
</msup>
<mo stretchy="false">)</mo>
</mrow>
<mo>=</mo>
<mfrac>
<mn>1</mn>
<mrow>
<mi>Z</mi>
<mrow>
<mo stretchy="false">(</mo>
<mi>ψ</mi>
<mo>,</mo>
<msup>
<mi>h</mi>
<mn>3</mn>
</msup>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
</mfrac>
<msup>
<mi>e</mi>
<mrow>
<mrow>
<mstyle displaystyle="false">
<msub>
<mo largeop="true" symmetric="true">∑</mo>
<mrow>
<mi>i</mi>
<mi>j</mi>
</mrow>
</msub>
</mstyle>
<mrow>
<msubsup>
<mi>W</mi>
<mrow>
<mi>i</mi>
<mi>j</mi>
</mrow>
<mrow>
<mo stretchy="false">(</mo>
<mn>1</mn>
<mo stretchy="false">)</mo>
</mrow>
</msubsup>
<msub>
<mi>ν</mi>
<mi>i</mi>
</msub>
<msubsup>
<mi>h</mi>
<mi>j</mi>
<mn>1</mn>
</msubsup>
</mrow>
</mrow>
<mo>+</mo>
<mrow>
<mstyle displaystyle="false">
<msub>
<mo largeop="true" symmetric="true">∑</mo>
<mrow>
<mi>j</mi>
<mi>l</mi>
</mrow>
</msub>
</mstyle>
<mrow>
<msubsup>
<mi>W</mi>
<mrow>
<mi>j</mi>
<mi>l</mi>
</mrow>
<mrow>
<mo stretchy="false">(</mo>
<mn>2</mn>
<mo stretchy="false">)</mo>
</mrow>
</msubsup>
<msubsup>
<mi>h</mi>
<mi>j</mi>
<mn>1</mn>
</msubsup>
<msubsup>
<mi>h</mi>
<mi>l</mi>
<mn>2</mn>
</msubsup>
</mrow>
</mrow>
<mo>+</mo>
<mrow>
<mstyle displaystyle="false">
<msub>
<mo largeop="true" symmetric="true">∑</mo>
<mrow>
<mi>l</mi>
<mi>m</mi>
</mrow>
</msub>
</mstyle>
<mrow>
<msubsup>
<mi>W</mi>
<mrow>
<mi>l</mi>
<mi>m</mi>
</mrow>
<mrow>
<mo stretchy="false">(</mo>
<mn>3</mn>
<mo stretchy="false">)</mo>
</mrow>
</msubsup>
<msubsup>
<mi>h</mi>
<mi>l</mi>
<mn>2</mn>
</msubsup>
<msubsup>
<mi>h</mi>
<mi>m</mi>
<mn>3</mn>
</msubsup>
</mrow>
</mrow>
</mrow>
</msup>
<mo>.</mo>
</mrow>
<annotation-xml encoding="MathML-Content">
<cerror>
<csymbol cd="ambiguous">fragments</csymbol>
<csymbol cd="unknown">P</csymbol>
<cerror>
<csymbol cd="ambiguous">fragments</csymbol>
<ci>normal-(</ci>
<csymbol cd="unknown">ν</csymbol>
<ci>normal-,</ci>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<ci>h</ci>
<cn type="integer">1</cn>
</apply>
<ci>normal-,</ci>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<ci>h</ci>
<cn type="integer">2</cn>
</apply>
<ci>normal-|</ci>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<ci>h</ci>
<cn type="integer">3</cn>
</apply>
<ci>normal-)</ci>
</cerror>
<eq></eq>
<apply>
<divide></divide>
<cn type="integer">1</cn>
<apply>
<times></times>
<ci>Z</ci>
<interval closure="open">
<ci>ψ</ci>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<ci>h</ci>
<cn type="integer">3</cn>
</apply>
</interval>
</apply>
</apply>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<ci>e</ci>
<apply>
<plus></plus>
<apply>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<sum></sum>
<apply>
<times></times>
<ci>i</ci>
<ci>j</ci>
</apply>
</apply>
<apply>
<times></times>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>W</ci>
<apply>
<times></times>
<ci>i</ci>
<ci>j</ci>
</apply>
</apply>
<cn type="integer">1</cn>
</apply>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>ν</ci>
<ci>i</ci>
</apply>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>h</ci>
<ci>j</ci>
</apply>
<cn type="integer">1</cn>
</apply>
</apply>
</apply>
<apply>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<sum></sum>
<apply>
<times></times>
<ci>j</ci>
<ci>l</ci>
</apply>
</apply>
<apply>
<times></times>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>W</ci>
<apply>
<times></times>
<ci>j</ci>
<ci>l</ci>
</apply>
</apply>
<cn type="integer">2</cn>
</apply>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>h</ci>
<ci>j</ci>
</apply>
<cn type="integer">1</cn>
</apply>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>h</ci>
<ci>l</ci>
</apply>
<cn type="integer">2</cn>
</apply>
</apply>
</apply>
<apply>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<sum></sum>
<apply>
<times></times>
<ci>l</ci>
<ci>m</ci>
</apply>
</apply>
<apply>
<times></times>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>W</ci>
<apply>
<times></times>
<ci>l</ci>
<ci>m</ci>
</apply>
</apply>
<cn type="integer">3</cn>
</apply>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>h</ci>
<ci>l</ci>
</apply>
<cn type="integer">2</cn>
</apply>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>h</ci>
<ci>m</ci>
</apply>
<cn type="integer">3</cn>
</apply>
</apply>
</apply>
</apply>
</apply>
<ci>normal-.</ci>
</cerror>
</annotation-xml>
<annotation encoding="application/x-tex">
   P(\nu,h^{1},h^{2}|h^{3})=\frac{1}{Z(\psi,h^{3})}e^{\sum_{ij}W_{ij}^{(1)}\nu_{i%
}h_{j}^{1}+\sum_{jl}W_{jl}^{(2)}h_{j}^{1}h_{l}^{2}+\sum_{lm}W_{lm}^{(3)}h_{l}^%
{2}h_{m}^{3}}.
  </annotation>
</semantics>
</math>
</p>
<h3 id="deep-coding-networks">Deep Coding Networks</h3>

<p>There are several advantages to having a model which can <em>actively</em> update itself to the context in data. One of these methods arises from the idea to have a model which is able to adjust its prior knowledge dynamically according to the context of the data. Deep coding network (DPCN) is a <a href="Predictive_modelling" title="wikilink">predictive</a> coding scheme where top-down information is used to empirically adjust the priors needed for the bottom-up <a href="Inference" title="wikilink">inference procedure</a> by means of a deep locally connected <a href="generative_model" title="wikilink">generative model</a>. This is based on extracting sparse <a href="Feature_(machine_learning)" title="wikilink">features</a> out of time-varying observations using a linear dynamical model. Then, a pooling strategy is employed in order to learn invariant feature representations. Similar to other deep architectures, these blocks are the building elements of a deeper architecture where greedy layer-wise <a href="unsupervised_learning" title="wikilink">unsupervised learning</a> are used. Note that the layers constitute a kind of <a href="Markov_chain" title="wikilink">Markov chain</a> such that the states at any layer are only dependent on the succeeding and preceding layers.</p>

<p>Deep predictive coding network (DPCN)<a class="footnoteRef" href="#fn158" id="fnref158"><sup>158</sup></a> predicts the representation of the layer, by means of a top-down approach using the information in upper layer and also temporal dependencies from the previous states, it is called</p>

<p>It is also possible to extend the DPCN to form a <a href="Convolutional_neural_network" title="wikilink">convolutional network</a>.<a class="footnoteRef" href="#fn159" id="fnref159"><sup>159</sup></a></p>
<h3 id="multilayer-kernel-machine">Multilayer Kernel Machine</h3>

<p>The <em>Multilayer Kernel Machine (MKM)</em> as introduced in <a class="footnoteRef" href="#fn160" id="fnref160"><sup>160</sup></a> is a way of learning highly nonlinear functions with the iterative applications of weakly nonlinear kernels. They use the <em>kernel principal component analysis (KPCA)</em>, in,<a class="footnoteRef" href="#fn161" id="fnref161"><sup>161</sup></a> as method for <a href="Unsupervised_learning" title="wikilink">unsupervised</a> greedy layer-wise pre-training step of the deep learning architecture.</p>

<p>Layer 

<math display="inline" id="Deep_learning:71">
<semantics>
<mrow>
<mi>l</mi>
<mo>+</mo>
<mn>1</mn>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<plus></plus>
<ci>l</ci>
<cn type="integer">1</cn>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   l+1
  </annotation>
</semantics>
</math>

-th learns the representation of the previous layer 

<math display="inline" id="Deep_learning:72">
<semantics>
<mi>l</mi>
<annotation-xml encoding="MathML-Content">
<ci>l</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   l
  </annotation>
</semantics>
</math>

, extracting the 

<math display="inline" id="Deep_learning:73">
<semantics>
<msub>
<mi>n</mi>
<mi>l</mi>
</msub>
<annotation-xml encoding="MathML-Content">
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>n</ci>
<ci>l</ci>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   n_{l}
  </annotation>
</semantics>
</math>
<a href="Principal_component_analysis" title="wikilink">principal component</a> (PC) of the projection layer 

<math display="inline" id="Deep_learning:74">
<semantics>
<mi>l</mi>
<annotation-xml encoding="MathML-Content">
<ci>l</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   l
  </annotation>
</semantics>
</math>

 output in the feature domain induced by the kernel. For the sake of <a href="dimensionality_reduction" title="wikilink">dimensionality reduction</a> of the updated representation in each layer, a <a href="Supervised_learning" title="wikilink">supervised strategy</a> is proposed to select the best informative features among the ones extracted by KPCA. The process is:</p>
<ul>
<li>ranking the 

<math display="inline" id="Deep_learning:75">
<semantics>
<msub>
<mi>n</mi>
<mi>l</mi>
</msub>
<annotation-xml encoding="MathML-Content">
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>n</ci>
<ci>l</ci>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   n_{l}
  </annotation>
</semantics>
</math>

 features according to their <a href="mutual_information" title="wikilink">mutual information</a> with the class labels;</li>
<li>for different values of <em>K</em> and 

<math display="inline" id="Deep_learning:76">
<semantics>
<mrow>
<msub>
<mi>m</mi>
<mi>l</mi>
</msub>
<mo>∈</mo>
<mrow>
<mo stretchy="false">{</mo>
<mn>1</mn>
<mo>,</mo>
<mi mathvariant="normal">…</mi>
<mo>,</mo>
<msub>
<mi>n</mi>
<mi>l</mi>
</msub>
<mo stretchy="false">}</mo>
</mrow>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<in></in>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>m</ci>
<ci>l</ci>
</apply>
<set>
<cn type="integer">1</cn>
<ci>normal-…</ci>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>n</ci>
<ci>l</ci>
</apply>
</set>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   m_{l}\in\{1,\ldots,n_{l}\}
  </annotation>
</semantics>
</math>

, compute the classification error rate of a <em>K-nearest neighbor (K-NN)</em> classifier using only the 

<math display="inline" id="Deep_learning:77">
<semantics>
<msub>
<mi>m</mi>
<mi>l</mi>
</msub>
<annotation-xml encoding="MathML-Content">
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>m</ci>
<ci>l</ci>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   m_{l}
  </annotation>
</semantics>
</math>

 most informative features on a <a href="validation_set" title="wikilink">validation set</a>;</li>
<li>the value of 

<math display="inline" id="Deep_learning:78">
<semantics>
<msub>
<mi>m</mi>
<mi>l</mi>
</msub>
<annotation-xml encoding="MathML-Content">
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>m</ci>
<ci>l</ci>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   m_{l}
  </annotation>
</semantics>
</math>

 with which the classifier has reached the lowest error rate determines the number of features to retain.</li>
</ul>

<p>There are some drawbacks in using the KPCA method as the building cells of an MKM.</p>

<p>Another, more straightforward method of integrating kernel machine into the deep learning architecture was developed by Microsoft researchers for spoken language understanding applications.<a class="footnoteRef" href="#fn162" id="fnref162"><sup>162</sup></a> The main idea is to use a kernel machine to approximate a shallow neural net with an infinite number of hidden units, and then to use the stacking technique to splice the output of the kernel machine and the raw input in building the next, higher level of the kernel machine. The number of the levels in this kernel version of the deep convex network is a hyper-parameter of the overall system determined by cross validation.</p>
<h3 id="deep-q-networks">Deep Q-Networks</h3>

<p>This is the latest class of deep learning models targeted for reinforcement learning, published in February 2015 in Nature<a class="footnoteRef" href="#fn163" id="fnref163"><sup>163</sup></a> The application discussed in this paper is limited to ATARI gaming, but the implications for other potential applications are profound.</p>
<h3 id="memory-networks">Memory networks</h3>

<p>Integrating external memory component with <a href="artificial_neural_networks" title="wikilink">artificial neural networks</a> has a long history dating back to early research in <a href="distributed_representations" title="wikilink">distributed representations</a> <a class="footnoteRef" href="#fn164" id="fnref164"><sup>164</sup></a> and <a href="self-organizing_map" title="wikilink">self-organizing maps</a>. E.g. in <a href="sparse_distributed_memory" title="wikilink">sparse distributed memory</a> or <a href="Hierarchical_temporal_memory" title="wikilink">HTM</a> the patterns encoded by neural networks are used as memory addresses for <em>content-addressable memory</em>, with "neurons" essentially serving as address <a href="encoder" title="wikilink">encoders</a> and <a href="decoder" title="wikilink">decoders</a>.</p>

<p>In the 1990s and 2000s, there was a lot of related work with differentiable long-term memories. For example:</p>
<ul>
<li>Differentiable push and pop actions for alternative memory networks called <em>neural stack machines</em><ref></ref></li>
</ul>

<p>S. Das, C.L. Giles, G.Z. Sun, "Learning Context Free Grammars: Limitations of a Recurrent Neural Network with an External Stack Memory," Proc. 14th Annual Conf. of the Cog. Sci. Soc., p. 79, 1992.<a class="footnoteRef" href="#fn165" id="fnref165"><sup>165</sup></a></p>
<ul>
<li>Memory networks where the control network's external differentiable storage is in the fast weights of another network <a class="footnoteRef" href="#fn166" id="fnref166"><sup>166</sup></a></li>
</ul>
<ul>
<li>The <a href="Long_short_term_memory" title="wikilink">LSTM</a> <em>"forget gates"</em> <a class="footnoteRef" href="#fn167" id="fnref167"><sup>167</sup></a></li>
</ul>
<ul>
<li>Self-referential <a href="Recurrent_neural_network" title="wikilink">RNNs</a> with special output units for addressing and rapidly manipulating each of the RNN's own weights in differentiable fashion (so the external storage is actually internal) <a class="footnoteRef" href="#fn168" id="fnref168"><sup>168</sup></a><a class="footnoteRef" href="#fn169" id="fnref169"><sup>169</sup></a></li>
</ul>

<p>More recently deep learning was shown to be useful in <a href="semantic_hashing" title="wikilink">semantic hashing</a><a class="footnoteRef" href="#fn170" id="fnref170"><sup>170</sup></a> where a deep <a href="graphical_model" title="wikilink">graphical model</a> the word-count vectors<a class="footnoteRef" href="#fn171" id="fnref171"><sup>171</sup></a> obtained from a large set of documents. Documents are mapped to memory addresses in such a way that semantically similar documents are located at nearby addresses. Documents similar to a query document can then be found by simply accessing all the addresses that differ by only a few bits from the address of the query document.</p>

<p><a href="Neural_Turing_Machines" title="wikilink">Neural Turing Machines</a><a class="footnoteRef" href="#fn172" id="fnref172"><sup>172</sup></a> developed by <a href="Google_DeepMind" title="wikilink">Google DeepMind</a> extend the capabilities of deep neural networks by coupling them to external memory resources, which they can interact with by attentional processes. The combined system is analogous to a <a href="Turing_Machine" title="wikilink">Turing Machine</a> but is differentiable end-to-end, allowing it to be efficiently trained with <a href="gradient_descent" title="wikilink">gradient descent</a>. Preliminary results demonstrate that Neural Turing Machines can infer simple algorithms such as copying, sorting, and associative recall from input and output examples.</p>

<p><a href="Memory_Networks" title="wikilink">Memory Networks</a><a class="footnoteRef" href="#fn173" id="fnref173"><sup>173</sup></a> is another extension to neural networks incorporating <a href="long-term_memory" title="wikilink">long-term memory</a> which was developed by <a class="uri" href="Facebook" title="wikilink">Facebook</a> research. The long-term memory can be read and written to, with the goal of using it for prediction. These models have been applied in the context of <a href="question_answering" title="wikilink">question answering</a> (QA) where the long-term memory effectively acts as a (dynamic) knowledge base, and the output is a textual response.</p>
<h2 id="applications">Applications</h2>
<h3 id="automatic-speech-recognition">Automatic speech recognition</h3>

<p>The results shown in the table below are for automatic speech recognition on the popular <a class="uri" href="TIMIT" title="wikilink">TIMIT</a> data set. This is a common data set used for initial evaluations of deep learning architectures. The entire set contains 630 speakers from eight major <a href="dialect" title="wikilink">dialects</a> of <a href="American_English" title="wikilink">American English</a>, with each speaker reading 10 different sentences.<a class="footnoteRef" href="#fn174" id="fnref174"><sup>174</sup></a> Its small size allows many different configurations to be tried effectively with it. More importantly, the TIMIT task concerns phone-sequence recognition, which, unlike word-sequence recognition, permits very weak "language models" and thus the weaknesses in acoustic modeling aspects of speech recognition can be more easily analyzed. It was such analysis on TIMIT contrasting the GMM (and other generative models of speech) vs. DNN models carried out by Li Deng and collaborators around 2009-2010 that stimulated early industrial investment on deep learning technology for speech recognition from small to large scales,<a class="footnoteRef" href="#fn175" id="fnref175"><sup>175</sup></a><a class="footnoteRef" href="#fn176" id="fnref176"><sup>176</sup></a> eventually leading to pervasive and dominant uses of deep learning in speech recognition industry. That analysis was carried out with comparable performance (less than 1.5% in error rate) between discriminative DNNs and generative models. The error rates presented below, including these early results and measured as percent phone error rates (PER), have been summarized over a time span of the past 20 years:</p>
<table>
<thead>
<tr class="header">
<th style="text-align: left;">

<p>Method</p></th>
<th style="text-align: left;">

<p>PER (%)</p></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">

<p>Randomly Initialized RNN</p></td>
<td style="text-align: left;">

<p>26.1</p></td>
</tr>
<tr class="even">
<td style="text-align: left;">

<p>Bayesian Triphone GMM-HMM</p></td>
<td style="text-align: left;">

<p>25.6</p></td>
</tr>
<tr class="odd">
<td style="text-align: left;">

<p>Hidden Trajectory (Generative) Model</p></td>
<td style="text-align: left;">

<p>24.8</p></td>
</tr>
<tr class="even">
<td style="text-align: left;">

<p>Monophone Randomly Initialized DNN</p></td>
<td style="text-align: left;">

<p>23.4</p></td>
</tr>
<tr class="odd">
<td style="text-align: left;">

<p>Monophone DBN-DNN</p></td>
<td style="text-align: left;">

<p>22.4</p></td>
</tr>
<tr class="even">
<td style="text-align: left;">

<p>Triphone GMM-HMM with BMMI Training</p></td>
<td style="text-align: left;">

<p>21.7</p></td>
</tr>
<tr class="odd">
<td style="text-align: left;">

<p>Monophone DBN-DNN on fbank</p></td>
<td style="text-align: left;">

<p>20.7</p></td>
</tr>
<tr class="even">
<td style="text-align: left;">

<p>Convolutional DNN<a class="footnoteRef" href="#fn177" id="fnref177"><sup>177</sup></a></p></td>
<td style="text-align: left;">

<p>20.0</p></td>
</tr>
<tr class="odd">
<td style="text-align: left;">

<p>Convolutional DNN w. Heterogeneous Pooling</p></td>
<td style="text-align: left;">

<p>18.7</p></td>
</tr>
<tr class="even">
<td style="text-align: left;">

<p>Ensemble DNN/CNN/RNN <a class="footnoteRef" href="#fn178" id="fnref178"><sup>178</sup></a></p></td>
<td style="text-align: left;">

<p>18.2</p></td>
</tr>
<tr class="odd">
<td style="text-align: left;">

<p>Bidirectional LSTM</p></td>
<td style="text-align: left;">

<p>17.9</p></td>
</tr>
</tbody>
</table>

<p>Extension of the success of deep learning from TIMIT to large vocabulary speech recognition occurred in 2010 by industrial researchers, where large output layers of the DNN based on context dependent HMM states constructed by decision trees were adopted.<a class="footnoteRef" href="#fn179" id="fnref179"><sup>179</sup></a><a class="footnoteRef" href="#fn180" id="fnref180"><sup>180</sup></a> See comprehensive reviews of this development and of the state of the art as of October 2014 in the recent Springer book from Microsoft Research.<a class="footnoteRef" href="#fn181" id="fnref181"><sup>181</sup></a> See also the related background of automatic speech recognition and the impact of various machine learning paradigms including notably deep learning in a recent overview article.<a class="footnoteRef" href="#fn182" id="fnref182"><sup>182</sup></a></p>

<p>One fundamental principle of deep learning is to do away with hand-crafted <a href="feature_engineering" title="wikilink">feature engineering</a> and to use raw features. This principle was first explored successfully in the architecture of deep autoencoder on the "raw" spectrogram or linear filter-bank features,<a class="footnoteRef" href="#fn183" id="fnref183"><sup>183</sup></a> showing its superiority over the Mel-Cepstral features which contain a few stages of fixed transformation from spectrograms. The true "raw" features of speech, waveforms, have more recently been shown to produce excellent larger-scale speech recognition results.<a class="footnoteRef" href="#fn184" id="fnref184"><sup>184</sup></a></p>

<p>Since the initial successful debut of DNNs for speech recognition around 2009-2011, there has been huge progress made. This progress (as well as future directions) has been summarized into the following eight major areas:<a class="footnoteRef" href="#fn185" id="fnref185"><sup>185</sup></a><a class="footnoteRef" href="#fn186" id="fnref186"><sup>186</sup></a><a class="footnoteRef" href="#fn187" id="fnref187"><sup>187</sup></a> 1) Scaling up/out and speedup DNN training and decoding; 2) Sequence discriminative training of DNNs; 3) Feature processing by deep models with solid understanding of the underlying mechanisms; 4) Adaptation of DNNs and of related deep models; 5) Multi-task and transfer learning by DNNs and related deep models; 6) Convolution neural networks and how to design them to best exploit domain knowledge of speech; 7) Recurrent neural network and its rich LSTM variants; 8) Other types of deep models including tensor-based models and integrated deep generative/discriminative models.</p>

<p>Large-scale automatic speech recognition is the first and the most convincing successful case of deep learning in the recent history, embraced by both industry and academic across the board. Between 2010 and 2014, the two major conferences on signal processing and speech recognition, IEEE-ICASSP and Interspeech, have seen near exponential growth in the numbers of accepted papers in their respective annual conference papers on the topic of deep learning for speech recognition. More importantly, all major commercial speech recognition systems (e.g., Microsoft Cortana, Xbox, Skype Translator, Google Now, Apple Siri, Baidu and iFlyTek voice search, and a range of Nuance speech products, etc.) nowadays are based on deep learning methods.<a class="footnoteRef" href="#fn188" id="fnref188"><sup>188</sup></a><a class="footnoteRef" href="#fn189" id="fnref189"><sup>189</sup></a><a class="footnoteRef" href="#fn190" id="fnref190"><sup>190</sup></a> See also the recent media interview with the CTO of Nuance Communications.<a class="footnoteRef" href="#fn191" id="fnref191"><sup>191</sup></a></p>

<p>The wide-spreading success in speech recognition achieved by 2011 was followed shortly by large-scale image recognition described next.</p>
<h3 id="image-recognition">Image recognition</h3>

<p>A common evaluation set for image classification is the <a href="MNIST_database" title="wikilink">MNIST database</a> data set. MNIST is composed of handwritten digits and includes 60000 training examples and 10000 test examples. Similar to TIMIT, its small size allows multiple configurations to be tested. A comprehensive list of results on this set can be found in.<a class="footnoteRef" href="#fn192" id="fnref192"><sup>192</sup></a> The current best result on MNIST is an error rate of 0.23%, achieved by Ciresan et al. in 2012.<a class="footnoteRef" href="#fn193" id="fnref193"><sup>193</sup></a></p>

<p>The real impact of deep learning in image or object recognition, one major branch of computer vision, was felt in the fall of 2012 after the team of Geoff Hinton and his students won the large-scale ImageNet competition by a significant margin over the then-state-of-the-art shallow machine learning methods. The technology is based on 20-year-old deep convolutional nets, but with much larger scale on a much larger task, since it had been learned that deep learning works quite well on large-scale speech recognition. In 2013 and 2014, the error rate on the ImageNet task using deep learning was further reduced at a rapid pace, following a similar trend in large-scale speech recognition.</p>

<p>As in the ambitious moves from automatic speech recognition toward automatic speech translation and understanding, image classification has recently been extended to the more ambitious and challenging task of automatic image captioning, in which deep learning is the essential underlying technology. <a class="footnoteRef" href="#fn194" id="fnref194"><sup>194</sup></a> <a class="footnoteRef" href="#fn195" id="fnref195"><sup>195</sup></a> <a class="footnoteRef" href="#fn196" id="fnref196"><sup>196</sup></a> <a class="footnoteRef" href="#fn197" id="fnref197"><sup>197</sup></a></p>

<p>One example application is a car computer said to be trained with deep learning, which may be able to let cars interpret 360° camera views.<a class="footnoteRef" href="#fn198" id="fnref198"><sup>198</sup></a></p>
<h3 id="natural-language-processing">Natural language processing</h3>

<p>Neural networks have been used for implementing <a href="language_model" title="wikilink">language models</a> since the early 2000s.<a class="footnoteRef" href="#fn199" id="fnref199"><sup>199</sup></a> Key techniques in this field are <a href="negative_sampling" title="wikilink">negative sampling</a><a class="footnoteRef" href="#fn200" id="fnref200"><sup>200</sup></a> and <a href="word_embedding" title="wikilink">word embedding</a>. A word embedding, such as <em>word2vec</em>, can be thought of as a representational layer in a deep learning architecture transforming an atomic word into a positional representation of the word relative to other words in the dataset; the position is represented as a point in a <a href="vector_space" title="wikilink">vector space</a>. Using a word embedding as an input layer to a recursive neural network (RNN) allows for the training of the network to parse sentences and phrases using an effective <em>compositional vector grammar</em>. A compositional vector grammar can be thought of as <a href="probabilistic_context_free_grammar" title="wikilink">probabilistic context free grammar</a> (PCFG) implemented by a recursive neural network.<a class="footnoteRef" href="#fn201" id="fnref201"><sup>201</sup></a> Recursive autoencoders built atop word embeddings have been trained to assess sentence similarity and detect paraphrasing.<a class="footnoteRef" href="#fn202" id="fnref202"><sup>202</sup></a> Deep neural architectures have achieved state-of-the-art results in many tasks in natural language processing, such as <a href="Statistical_parsing" title="wikilink">constituency parsing</a>,<a class="footnoteRef" href="#fn203" id="fnref203"><sup>203</sup></a> <a href="sentiment_analysis" title="wikilink">sentiment analysis</a>,<a class="footnoteRef" href="#fn204" id="fnref204"><sup>204</sup></a> information retrieval,<a class="footnoteRef" href="#fn205" id="fnref205"><sup>205</sup></a> <a class="footnoteRef" href="#fn206" id="fnref206"><sup>206</sup></a> machine translation, <a class="footnoteRef" href="#fn207" id="fnref207"><sup>207</sup></a> <a class="footnoteRef" href="#fn208" id="fnref208"><sup>208</sup></a> contextual entity linking, <a class="footnoteRef" href="#fn209" id="fnref209"><sup>209</sup></a> and other areas of NLP. <a class="footnoteRef" href="#fn210" id="fnref210"><sup>210</sup></a></p>
<h3 id="drug-discovery-and-toxicology">Drug discovery and toxicology</h3>

<p>The <a href="pharmaceutical_industry" title="wikilink">pharmaceutical industry</a> faces the problem that a large percentage of candidate drugs fail to reach the market. These failures of <a href="chemical_compounds" title="wikilink">chemical compounds</a> are caused by insufficient efficacy on the <a href="Biological_target" title="wikilink">biomolecular target</a> (on-target effect), undetected and undesired interactions with other <a class="uri" href="biomolecules" title="wikilink">biomolecules</a> (off-target effects), or unanticipated <a href="cytotoxicity" title="wikilink">toxic effects</a>.<a class="footnoteRef" href="#fn211" id="fnref211"><sup>211</sup></a><a class="footnoteRef" href="#fn212" id="fnref212"><sup>212</sup></a> In 2012 a team led by George Dahl won the "Merck Molecular Activity Challenge" using multi-task deep neural networks to predict the biomolecular target of a compound.<a class="footnoteRef" href="#fn213" id="fnref213"><sup>213</sup></a><a class="footnoteRef" href="#fn214" id="fnref214"><sup>214</sup></a> In 2014 Sepp Hochreiter's group used Deep Learning to detect off-target and <a href="cytotoxicity" title="wikilink">toxic effects</a> of environmental chemicals in nutrients, household products and drugs and won the "Tox21 Data Challenge" of <a class="uri" href="NIH" title="wikilink">NIH</a>, <a class="uri" href="FDA" title="wikilink">FDA</a> and <a href="National_Center_for_Advancing_Translational_Sciences" title="wikilink">NCATS</a>.<a class="footnoteRef" href="#fn215" id="fnref215"><sup>215</sup></a><a class="footnoteRef" href="#fn216" id="fnref216"><sup>216</sup></a> These impressive successes show Deep Learning may be superior to other <a href="virtual_screening" title="wikilink">virtual screening</a> methods.<a class="footnoteRef" href="#fn217" id="fnref217"><sup>217</sup></a><a class="footnoteRef" href="#fn218" id="fnref218"><sup>218</sup></a> Researchers from <a class="uri" href="Google" title="wikilink">Google</a> and <a href="Stanford_University" title="wikilink">Stanford</a> enhanced Deep Learning for drug discovery by combining data from a variety of sources.<a class="footnoteRef" href="#fn219" id="fnref219"><sup>219</sup></a></p>
<h3 id="customer-relationship-management">Customer relationship management</h3>

<p>Recently success has been reported with application of deep reinforcement learning in direct marketing settings, illustrating suitability of the method for <a href="Customer_relationship_management" title="wikilink">CRM</a> automation. A neural network was used to approximate the value of possible direct marketing actions over the customer state space, defined in terms of <a href="RFM_(customer_value)" title="wikilink">RFM</a> variables. The estimated value function was shown to have a natural interpretation as <a href="Customer_lifetime_value" title="wikilink">CLV</a> (customer lifetime value).<a class="footnoteRef" href="#fn220" id="fnref220"><sup>220</sup></a></p>
<h2 id="deep-learning-in-the-human-brain">Deep learning in the human brain</h2>

<p>Computational deep learning is closely related to a class of theories of <a href="brain_development" title="wikilink">brain development</a> (specifically, neocortical development) proposed by <a href="cognitive_neuroscientist" title="wikilink">cognitive neuroscientists</a> in the early 1990s.<a class="footnoteRef" href="#fn221" id="fnref221"><sup>221</sup></a> An approachable summary of this work is Elman, et al.'s 1996 book "Rethinking Innateness" <a class="footnoteRef" href="#fn222" id="fnref222"><sup>222</sup></a> (see also: Shrager and Johnson;<a class="footnoteRef" href="#fn223" id="fnref223"><sup>223</sup></a> Quartz and Sejnowski <a class="footnoteRef" href="#fn224" id="fnref224"><sup>224</sup></a>). As these developmental theories were also instantiated in computational models, they are technical predecessors of purely computationally-motivated deep learning models. These developmental models share the interesting property that various proposed learning dynamics in the brain (e.g., a wave of <a href="nerve_growth_factor" title="wikilink">nerve growth factor</a>) conspire to support the <a class="uri" href="self-organization" title="wikilink">self-organization</a> of just the sort of inter-related neural networks utilized in the later, purely computational deep learning models; and such computational neural networks seem analogous to a view of the brain's neocortex as a hierarchy of filters in which each layer captures some of the information in the operating environment, and then passes the remainder, as well as modified base signal, to other layers further up the hierarchy. This process yields a self-organizing stack of <a href="transducer" title="wikilink">transducers</a>, well-tuned to their operating environment. As described in The <a href="New_York_Times" title="wikilink">New York Times</a> in 1995: "...the infant's brain seems to organize itself under the influence of waves of so-called trophic-factors ... different regions of the brain become connected sequentially, with one layer of tissue maturing before another and so on until the whole brain is mature." <a class="footnoteRef" href="#fn225" id="fnref225"><sup>225</sup></a></p>

<p>The importance of deep learning with respect to the evolution and development of human <a class="uri" href="cognition" title="wikilink">cognition</a> did not escape the attention of these researchers. One aspect of human development that distinguishes us from our nearest primate neighbors may be changes in the timing of development.<a class="footnoteRef" href="#fn226" id="fnref226"><sup>226</sup></a> Among <a href="primate" title="wikilink">primates</a>, the human brain remains relatively plastic until late in the post-natal period, whereas the brains of our closest relatives are more completely formed by birth. Thus, humans have greater access to the complex experiences afforded by being out in the world during the most formative period of brain development. This may enable us to "tune in" to rapidly changing features of the environment that other animals, more constrained by evolutionary structuring of their brains, are unable to take account of. To the extent that these changes are reflected in similar timing changes in hypothesized wave of cortical development, they may also lead to changes in the extraction of information from the stimulus environment during the early self-organization of the brain. Of course, along with this flexibility comes an extended period of immaturity, during which we are dependent upon our caretakers and our community for both support and training. The theory of deep learning therefore sees the coevolution of culture and cognition as a fundamental condition of human evolution.<a class="footnoteRef" href="#fn227" id="fnref227"><sup>227</sup></a></p>
<h2 id="commercial-activities">Commercial activities</h2>

<p>Deep learning is often presented as a step towards realising <a href="Artificial_general_intelligence" title="wikilink">strong AI</a><a class="footnoteRef" href="#fn228" id="fnref228"><sup>228</sup></a> and thus many organizations have become interested in its use for particular applications. Most recently, in December 2013, <a class="uri" href="Facebook" title="wikilink">Facebook</a> announced that it hired <a href="Yann_LeCun" title="wikilink">Yann LeCun</a> to head its new <a href="artificial_intelligence" title="wikilink">artificial intelligence</a> (AI) lab that will have operations in California, London, and New York. The AI lab will be used for developing deep learning techniques that will help Facebook do tasks such as <a href="Automatic_image_annotation" title="wikilink">automatically tagging uploaded pictures</a> with the names of the people in them.<a class="footnoteRef" href="#fn229" id="fnref229"><sup>229</sup></a></p>

<p>In March 2013, <a href="Geoffrey_Hinton" title="wikilink">Geoffrey Hinton</a> and two of his graduate students, Alex Krizhevsky and Ilya Sutskever, were hired by <a class="uri" href="Google" title="wikilink">Google</a>. Their work will be focused on both improving existing machine learning products at Google and also help deal with the growing amount of data Google has. Google also purchased Hinton's company, DNNresearch.</p>

<p>In 2014 Google also acquired <a href="DeepMind_Technologies" title="wikilink">DeepMind Technologies</a>, a British start-up that developed a system capable of learning how to play <a class="uri" href="Atari" title="wikilink">Atari</a> video games using only raw pixels as data input.</p>

<p>Also in 2014, Microsoft established The Deep Learning Technology Center in its MSR division, amassing deep learning experts for application-focused activities.</p>

<p>And <a class="uri" href="Baidu" title="wikilink">Baidu</a> hired <a href="Andrew_Ng" title="wikilink">Andrew Ng</a> to head their new Silicon Valley based research lab focusing on deep learning.</p>
<h2 id="criticism-and-comment">Criticism and comment</h2>

<p>Given the far-reaching implications of artificial intelligence coupled with the realization that deep learning is emerging as one of its most powerful techniques, the subject is understandably attracting both criticism and comment, and in some cases from outside the field of computer science itself.</p>

<p>A main criticism of deep learning concerns the lack of theory surrounding many of the methods. Most of the learning in deep architectures is just some form of <a href="gradient_descent" title="wikilink">gradient descent</a>. While gradient descent has been understood for a while now, the theory surrounding other algorithms, such as contrastive divergence is less clear (i.e., Does it converge? If so, how fast? What is it approximating?). Deep learning methods are often looked at as a black box, with most confirmations done empirically, rather than theoretically.</p>

<p>Others point out that deep learning should be looked at as a step towards realizing strong AI, not as an all-encompassing solution. Despite the power of deep learning methods, they still lack much of the functionality needed for realizing this goal entirely. Research psychologist <a href="Gary_Marcus" title="wikilink">Gary Marcus</a> has noted that:</p>

<p>"Realistically, deep learning is only part of the larger challenge of building intelligent machines. Such techniques lack ways of representing <a href="causality" title="wikilink">causal relationships</a> (...) have no obvious ways of performing <a href="inference" title="wikilink">logical inferences</a>, and they are also still a long way from integrating abstract knowledge, such as information about what objects are, what they are for, and how they are typically used. The most powerful A.I. systems, like <a href="Watson_(computer)" title="wikilink">Watson</a> (...) use techniques like deep learning as just one element in a very complicated ensemble of techniques, ranging from the statistical technique of <a href="Bayesian_inference" title="wikilink">Bayesian inference</a> to <a href="deductive_reasoning" title="wikilink">deductive reasoning</a>." <a class="footnoteRef" href="#fn230" id="fnref230"><sup>230</sup></a></p>

<p>To the extent that such a viewpoint implies, without intending to, that deep learning will ultimately constitute nothing more than the primitive discriminatory levels of a comprehensive future machine intelligence, a recent pair of speculations regarding art and artificial intelligence<a class="footnoteRef" href="#fn231" id="fnref231"><sup>231</sup></a> offers an alternative and more expansive outlook. The first such speculation is that it might be possible to train a machine vision stack to perform the sophisticated task of discriminating between "old master" and amateur figure drawings; and the second is that such a sensitivity might in fact represent the rudiments of a non-trivial machine empathy. It is suggested, moreover, that such an eventuality would be in line with both anthropology, which identifies a concern with aesthetics as a key element of <a href="behavioral_modernity" title="wikilink">behavioral modernity</a>, and also with a current school of thought which suspects that the allied phenomenon of <a class="uri" href="consciousness" title="wikilink">consciousness</a>, formerly thought of as a purely high-order phenomenon, may in fact have roots deep within the structure of the universe itself.</p>

<p>In further reference to the idea that a significant degree of artistic sensitivity might inhere within relatively low levels, whether biological or digital, of the cognitive hierarchy, there has recently been published a series of graphic representations of the internal states of deep (20-30 layers) neural networks attempting to discern within essentially random data the images on which they have been trained,<a class="footnoteRef" href="#fn232" id="fnref232"><sup>232</sup></a> and these, based on the remarkable level of public attention which this work has captured, demonstrate a striking visual appeal, with the original research notice having received well in excess of one thousand comments, and <a href="The_Guardian" title="wikilink">The Guardian</a> coverage<a class="footnoteRef" href="#fn233" id="fnref233"><sup>233</sup></a> having achieved the status of most frequently accessed article on that newspaper's web site.</p>

<p>Some currently popular and successful deep learning architectures display certain problematical behaviors<a class="footnoteRef" href="#fn234" id="fnref234"><sup>234</sup></a> (e.g. confidently classifying random data as belonging to a familiar category of nonrandom images;<a class="footnoteRef" href="#fn235" id="fnref235"><sup>235</sup></a> and misclassifying miniscule perturbations of correctly classified images <a class="footnoteRef" href="#fn236" id="fnref236"><sup>236</sup></a>). The creator of <a class="uri" href="OpenCog" title="wikilink">OpenCog</a>, <a href="Ben_Goertzel" title="wikilink">Ben Goertzel</a> hypothesized <a class="footnoteRef" href="#fn237" id="fnref237"><sup>237</sup></a> that these behaviors are tied with limitations in the internal representations learned by these architectures, and that these same limitations would inhibit integration of these architectures into heterogeneous multi-component <a href="Artificial_general_intelligence" title="wikilink">AGI</a> architectures. It is suggested that these issues can be worked around by developing deep learning architectures that internally form states homologous to image-grammar <a class="footnoteRef" href="#fn238" id="fnref238"><sup>238</sup></a> decompositions of observed entities and events.<a class="footnoteRef" href="#fn239" id="fnref239"><sup>239</sup></a> Learning a <a class="uri" href="grammar" title="wikilink">grammar</a> (visual or linguistic) from training data would be equivalent to restricting the system to <a href="commonsense_reasoning" title="wikilink">commonsense reasoning</a> which operates on concepts in terms of <a href="Production_(computer_science)" title="wikilink">production rules</a> of the grammar, and is a basic goal of both human language acquisition <a class="footnoteRef" href="#fn240" id="fnref240"><sup>240</sup></a> and A.I. (Also see <a href="Grammar_induction" title="wikilink">Grammar induction</a> <a class="footnoteRef" href="#fn241" id="fnref241"><sup>241</sup></a>)</p>
<h2 id="deep-learning-software-libraries">Deep learning software libraries</h2>
<ul>
<li><a href="Torch_(machine_learning)" title="wikilink">Torch</a> - An open source software library for machine learning based on the Lua programming language.</li>
<li><a href="Theano_(software)" title="wikilink">Theano</a> - An open source machine learning library for Python.</li>
<li><a class="uri" href="H2O.ai" title="wikilink">H2O.ai</a> - An open source machine learning platform written in Java with a parallel architecture.</li>
<li><a class="uri" href="Deeplearning4j" title="wikilink">Deeplearning4j</a> - An open source deep learning library written for Java. It provides parallelization with CPUs and GPUs.</li>
<li><a class="uri" href="OpenNN" title="wikilink">OpenNN</a> - An open source C++ library which implements deep neural networks and provides parallelization with CPUs.</li>
<li>NVIDIA cuDNN - A GPU-accelerated library of primitives for deep neural networks.</li>
<li>DeepLearnToolbox - A <a class="uri" href="Matlab" title="wikilink">Matlab</a>/<a href="GNU_Octave" title="wikilink">Octave</a> toolbox for deep learning.</li>
<li>convnetjs - A <a class="uri" href="Javascript" title="wikilink">Javascript</a> library for training deep learning models. It contains online demos.</li>
<li><a class="uri" href="Gensim" title="wikilink">Gensim</a> - A toolkit for natural language processing implemented in the Python programming language.</li>
<li>Caffe - A deep learning framework .</li>
<li>Apache SINGA<a class="footnoteRef" href="#fn242" id="fnref242"><sup>242</sup></a> - A deep learning platform developed for scalability, usability and extensibility.</li>
<li>RNNLM - RNN language model open source</li>
<li>RNNLMPara - Parallel RNN language model trainer open source</li>
</ul>
<h2 id="see-also">See also</h2>
<ul>
<li><a href="Sparse_coding" title="wikilink">Sparse coding</a></li>
<li><a href="Compressed_Sensing" title="wikilink">Compressed Sensing</a></li>
<li><a class="uri" href="Connectionism" title="wikilink">Connectionism</a></li>
<li><a href="Self-organizing_map" title="wikilink">Self-organizing map</a></li>
<li><a href="Applications_of_artificial_intelligence" title="wikilink">Applications of artificial intelligence</a></li>
<li><a href="List_of_artificial_intelligence_projects" title="wikilink">List of artificial intelligence projects</a></li>
<li><a href="Reservoir_computing" title="wikilink">Reservoir computing</a></li>
<li><a href="Liquid_state_machine" title="wikilink">Liquid state machine</a></li>
<li><a href="Echo_state_network" title="wikilink">Echo state network</a></li>
</ul>
<h2 id="references">References</h2>

<p>"</p>

<p><a href="Category:Machine_learning" title="wikilink">Category:Machine learning</a> <a href="Category:Artificial_neural_networks" title="wikilink">Category:Artificial neural networks</a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1">L. Deng and D. Yu (2014) "Deep Learning: Methods and Applications" <a class="uri" href="http://research.microsoft.com/pubs/209355/DeepLearning-NowPublishing-Vol7-SIG-039.pdf">http://research.microsoft.com/pubs/209355/DeepLearning-NowPublishing-Vol7-SIG-039.pdf</a><a href="#fnref1">↩</a></li>
<li id="fn2"><a href="#fnref2">↩</a></li>
<li id="fn3">Y. Bengio, A. Courville, and P. Vincent., "Representation Learning: A Review and New Perspectives," <em>IEEE Trans. PAMI, special issue Learning Deep Architectures</em>, 2013<a href="#fnref3">↩</a></li>
<li id="fn4">J. Schmidhuber, "Deep Learning in Neural Networks: An Overview" <a class="uri" href="http://arxiv.org/abs/1404.7828">http://arxiv.org/abs/1404.7828</a>, 2014<a href="#fnref4">↩</a></li>
<li id="fn5"><a href="#fnref5">↩</a></li>
<li id="fn6">Song, Hyun Ah, and Soo-Young Lee. "Hierarchical Representation Using NMF." Neural Information Processing. Springer Berlin Heidelberg, 2013.<a href="#fnref6">↩</a></li>
<li id="fn7">Olshausen, Bruno A. "Emergence of simple-cell receptive field properties by learning a sparse code for natural images." Nature 381.6583 (1996): 607-609.<a href="#fnref7">↩</a></li>
<li id="fn8"> Ca. 7:45.<a href="#fnref8">↩</a></li>
<li id="fn9"><a href="#fnref9">↩</a></li>
<li id="fn10"></li>
<li id="fn11"></li>
<li id="fn12"></li>
<li id="fn13"></li>
<li id="fn14"></li>
<li id="fn15"></li>
<li id="fn16"></li>
<li id="fn17"></li>
<li id="fn18"></li>
<li id="fn19"><a href="#fnref19">↩</a></li>
<li id="fn20">P. Werbos., "Beyond Regression: New Tools for Prediction and Analysis in the Behavioral Sciences," <em>PhD thesis, Harvard University</em>, 1974.<a href="#fnref20">↩</a></li>
<li id="fn21">LeCun <em>et al.</em>, "Backpropagation Applied to Handwritten Zip Code Recognition," <em>Neural Computation</em>, 1, pp. 541–551, 1989.<a href="#fnref21">↩</a></li>
<li id="fn22">S. Hochreiter., "<a href="http://people.idsia.ch/~juergen/SeppHochreiter1991ThesisAdvisorSchmidhuber.pdf">Untersuchungen zu dynamischen neuronalen Netzen</a>," <em>Diploma thesis. Institut f. Informatik, Technische Univ. Munich. Advisor: J. Schmidhuber</em>, 1991.<a href="#fnref22">↩</a></li>
<li id="fn23">S. Hochreiter <em>et al.</em>, "Gradient flow in recurrent nets: the difficulty of learning long-term dependencies," <em>In S. C. Kremer and J. F. Kolen, editors, A Field Guide to Dynamical Recurrent Neural Networks. IEEE Press</em>, 2001.<a href="#fnref23">↩</a></li>
<li id="fn24">J. Weng, N. Ahuja and T. S. Huang, "<a href="http://www.cse.msu.edu/~weng/research/CresceptronIJCNN1992.pdf">Cresceptron: a self-organizing neural network which grows adaptively</a>," <em>Proc. International Joint Conference on Neural Networks</em>, Baltimore, Maryland, vol I, pp. 576-581, June, 1992.<a href="#fnref24">↩</a></li>
<li id="fn25">J. Weng, N. Ahuja and T. S. Huang, "<a href="http://www.cse.msu.edu/~weng/research/CresceptronICCV1993.pdf">Learning recognition and segmentation of 3-D objects from 2-D images</a>," <em>Proc. 4th International Conf. Computer Vision</em>, Berlin, Germany, pp. 121-128, May, 1993.<a href="#fnref25">↩</a></li>
<li id="fn26">J. Weng, N. Ahuja and T. S. Huang, "<a href="http://www.cse.msu.edu/~weng/research/CresceptronIJCV.pdf">Learning recognition and segmentation using the Cresceptron</a>," <em>International Journal of Computer Vision</em>, vol. 25, no. 2, pp. 105-139, Nov. 1997.<a href="#fnref26">↩</a></li>
<li id="fn27">Morgan, Bourlard, Renals, Cohen, Franco (1993) "Hybrid neural network/hidden Markov model systems for continuous speech recognition. ICASSP/IJPRAI"<a href="#fnref27">↩</a></li>
<li id="fn28">T. Robinson. (1992) A real-time recurrent error propagation network word recognition system, ICASSP.<a href="#fnref28">↩</a></li>
<li id="fn29">Waibel, Hanazawa, Hinton, Shikano, Lang. (1989) "Phoneme recognition using time-delay neural networks. IEEE Transactions on Acoustics, Speech and Signal Processing."<a href="#fnref29">↩</a></li>
<li id="fn30"><a href="#fnref30">↩</a></li>
<li id="fn31">Y. Bengio (1991). "Artificial Neural Networks and their Application to Speech/Sequence Recognition," Ph.D. thesis, McGill University, Canada.<a href="#fnref31">↩</a></li>
<li id="fn32"><a href="#fnref32">↩</a></li>
<li id="fn33"></li>
<li id="fn34"><a href="#fnref34">↩</a></li>
<li id="fn35">Keynote talk: Recent Developments in Deep Neural Networks. ICASSP, 2013 (by Geoff Hinton).<a href="#fnref35">↩</a></li>
<li id="fn36">Keynote talk: "Achievements and Challenges of Deep Learning - From Speech Analysis and Recognition To Language and Multimodal Processing," Interspeech, September 2014.<a href="#fnref36">↩</a></li>
<li id="fn37">G. E. Hinton., "Learning multiple layers of representation," <em>Trends in Cognitive Sciences</em>, 11, pp. 428–434, 2007.<a href="#fnref37">↩</a></li>
<li id="fn38">J. Schmidhuber., "Learning complex, extended sequences using the principle of history compression," <em>Neural Computation</em>, 4, pp. 234–242, 1992.<a href="#fnref38">↩</a></li>
<li id="fn39">J. Schmidhuber., "My First Deep Learning System of 1991 + Deep Learning Timeline 1962–2013."<a href="#fnref39">↩</a></li>
<li id="fn40"></li>
<li id="fn41"><a class="uri" href="http://research.microsoft.com/apps/pubs/default.aspx?id=189004">http://research.microsoft.com/apps/pubs/default.aspx?id=189004</a><a href="#fnref41">↩</a></li>
<li id="fn42">L. Deng et al. Recent Advances in Deep Learning for Speech Research at Microsoft, ICASSP, 2013.<a href="#fnref42">↩</a></li>
<li id="fn43">L. Deng, O. Abdel-Hamid, and D. Yu, A deep convolutional neural network using heterogeneous pooling for trading acoustic invariance with phonetic confusion, ICASSP, 2013.<a href="#fnref43">↩</a></li>
<li id="fn44"></li>
<li id="fn45"></li>
<li id="fn46"><a href="#fnref46">↩</a></li>
<li id="fn47">D. Yu, L. Deng, G. Li, and F. Seide (2011). "Discriminative pretraining of deep neural networks," U.S. Patent Filing.<a href="#fnref47">↩</a></li>
<li id="fn48"></li>
<li id="fn49"></li>
<li id="fn50"></li>
<li id="fn51"><a href="#fnref51">↩</a></li>
<li id="fn52">D. C. Ciresan <em>et al.</em>, "Deep Big Simple Neural Nets for Handwritten Digit Recognition," <em>Neural Computation</em>, 22, pp. 3207–3220, 2010.<a href="#fnref52">↩</a></li>
<li id="fn53">R. Raina, A. Madhavan, A. Ng., "Large-scale Deep Unsupervised Learning using Graphics Processors," <em>Proc. 26th Int. Conf. on Machine Learning</em>, 2009.<a href="#fnref53">↩</a></li>
<li id="fn54"></li>
<li id="fn55"></li>
<li id="fn56"></li>
<li id="fn57"><a href="#fnref57">↩</a></li>
<li id="fn58">Y. LeCun, B. Boser, J. S. Denker, D. Henderson, R. E. Howard, W. Hubbard, L. D. Jackel. 1989 <em>Backpropagation Applied to Handwritten Zip Code Recognition.</em> Neural Computation, 1(4):541–551.<a href="#fnref58">↩</a></li>
<li id="fn59"></li>
<li id="fn60"></li>
<li id="fn61"></li>
<li id="fn62"></li>
<li id="fn63"></li>
<li id="fn64"></li>
<li id="fn65"><a href="Sepp_Hochreiter" title="wikilink">S. Hochreiter</a>. Untersuchungen zu dynamischen neuronalen Netzen. Diploma thesis, Institut f. Informatik, Technische Univ. Munich, 1991. Advisor: <a href="Jürgen_Schmidhuber" title="wikilink">J. Schmidhuber</a><a href="#fnref65">↩</a></li>
<li id="fn66"><a href="Sepp_Hochreiter" title="wikilink">S. Hochreiter</a>, Y. Bengio, P. Frasconi, and <a href="Jürgen_Schmidhuber" title="wikilink">J. Schmidhuber</a>. Gradient flow in recurrent nets: the difficulty of learning long-term dependencies. In S. C. Kremer and J. F. Kolen, editors, A Field Guide to Dynamical Recurrent Neural Networks. IEEE Press, 2001.<a href="#fnref66">↩</a></li>
<li id="fn67"></li>
<li id="fn68"><a href="Sepp_Hochreiter" title="wikilink">Hochreiter, Sepp</a>; and <a href="Jürgen_Schmidhuber" title="wikilink">Schmidhuber, Jürgen</a>; <em>Long Short-Term Memory</em>, Neural Computation, 9(8):1735–1780, 1997<a href="#fnref68">↩</a></li>
<li id="fn69">Graves, Alex; and Schmidhuber, Jürgen; <em>Offline Handwriting Recognition with Multidimensional Recurrent Neural Networks</em>, in Bengio, Yoshua; Schuurmans, Dale; Lafferty, John; Williams, Chris K. I.; and Culotta, Aron (eds.), <em>Advances in Neural Information Processing Systems 22 (NIPS'22), December 7th–10th, 2009, Vancouver, BC</em>, Neural Information Processing Systems (NIPS) Foundation, 2009, pp. 545–552<a href="#fnref69">↩</a></li>
<li id="fn70"><a href="#fnref70">↩</a></li>
<li id="fn71"><a href="#fnref71">↩</a></li>
<li id="fn72"><a href="#fnref72">↩</a></li>
<li id="fn73"><a href="#fnref73">↩</a></li>
<li id="fn74"><a href="#fnref74">↩</a></li>
<li id="fn75"><a href="#fnref75">↩</a></li>
<li id="fn76"><a href="#fnref76">↩</a></li>
<li id="fn77"></li>
<li id="fn78">D. C. Ciresan, U. Meier, J. Masci, L. M. Gambardella, J. Schmidhuber. Flexible, High Performance Convolutional Neural Networks for Image Classification. International Joint Conference on Artificial Intelligence (IJCAI-2011, Barcelona), 2011.<a href="#fnref78">↩</a></li>
<li id="fn79"><a href="#fnref79">↩</a></li>
<li id="fn80"></li>
<li id="fn81">D. C. Ciresan, U. Meier, J. Masci, J. Schmidhuber. Multi-Column Deep Neural Network for Traffic Sign Classification. Neural Networks, 2012.<a href="#fnref81">↩</a></li>
<li id="fn82">D. Ciresan, A. Giusti, L. Gambardella, J. Schmidhuber. Deep Neural Networks Segment Neuronal Membranes in Electron Microscopy Images. In Advances in Neural Information Processing Systems (NIPS 2012), Lake Tahoe, 2012.<a href="#fnref82">↩</a></li>
<li id="fn83">D. C. Ciresan, U. Meier, J. Schmidhuber. Multi-column Deep Neural Networks for Image Classification. IEEE Conf. on Computer Vision and Pattern Recognition CVPR 2012.<a href="#fnref83">↩</a></li>
<li id="fn84">D. J. Felleman and D. C. Van Essen, "<a href="http://cercor.oxfordjournals.org/content/1/1/1.1.full.pdf+html">Distributed hierarchical processing in the primate cerebral cortex</a>," <em>Cerebral Cortex</em>, 1, pp. 1-47, 1991.<a href="#fnref84">↩</a></li>
<li id="fn85">J. Weng, "<a href="http://www.amazon.com/Natural-Artificial-Intelligence-Introduction-Computational/dp/0985875720">Natural and Artificial Intelligence: Introduction to Computational Brain-Mind</a>," BMI Press, ISBN 978-0985875725, 2012.<a href="#fnref85">↩</a></li>
<li id="fn86">J. Weng, "<a href="http://www.cse.msu.edu/~weng/research/WhyPass-Weng-NI-2011.pdf">Why Have We Passed `Neural Networks Do not Abstract Well'?</a>," <em>Natural Intelligence: the INNS Magazine</em>, vol. 1, no.1, pp. 13-22, 2011.<a href="#fnref86">↩</a></li>
<li id="fn87">Z. Ji, J. Weng, and D. Prokhorov, "<a href="http://www.cse.msu.edu/~weng/research/ICDL08_0077.pdf">Where-What Network 1: Where and What Assist Each Other Through Top-down Connections</a>," <em>Proc. 7th International Conference on Development and Learning (ICDL'08)</em>, Monterey, CA, Aug. 9-12, pp. 1-6, 2008.<a href="#fnref87">↩</a></li>
<li id="fn88">X. Wu, G. Guo, and J. Weng, "<a href="http://www.cse.msu.edu/~weng/research/WWN7-Wu-ICBM-2013.pdf">Skull-closed Autonomous Development: WWN-7 Dealing with Scales</a>," <em>Proc. International Conference on Brain-Mind</em>, July 27–28, East Lansing, Michigan, pp. +1-9, 2013.<a href="#fnref88">↩</a></li>
<li id="fn89"></li>
<li id="fn90"></li>
<li id="fn91">Szegedy, Christian, Alexander Toshev, and Dumitru Erhan. "Deep neural networks for object detection." Advances in Neural Information Processing Systems. 2013.<a href="#fnref91">↩</a></li>
<li id="fn92"></li>
<li id="fn93">T. Mikolov <em>et al.</em>, "Recurrent neural network based language model," <em>Interspeech</em>, 2010.<a href="#fnref93">↩</a></li>
<li id="fn94"><a href="#fnref94">↩</a></li>
<li id="fn95">T. Sainath <em>et al.</em>, "Convolutional neural networks for LVCSR," <em>ICASSP</em>, 2013.<a href="#fnref95">↩</a></li>
<li id="fn96">G. E. Hinton <em>et al.</em>., "Deep Neural Networks for Acoustic Modeling in Speech Recognition: The shared views of four research groups," <em>IEEE Signal Processing Magazine</em>, pp. 82–97, November 2012.<a href="#fnref96">↩</a></li>
<li id="fn97">Y. Bengio <em>et al.</em>., "Advances in optimizing recurrent networks," <em>ICASSP</em>, 2013.<a href="#fnref97">↩</a></li>
<li id="fn98">G. Dahl <em>et al.</em>., "Improving DNNs for LVCSR using rectified linear units and dropout," <em>ICASSP</em>, 2013.<a href="#fnref98">↩</a></li>
<li id="fn99">G. E. Hinton., "A Practical Guide to Training Restricted Boltzmann Machines," <em>Tech. Rep. UTML TR 2010-003, Dept. CS., Univ. of Toronto</em>, 2010.<a href="#fnref99">↩</a></li>
<li id="fn100"></li>
<li id="fn101">Huang, Guang-Bin, Qin-Yu Zhu, and Chee-Kheong Siew. "Extreme learning machine: theory and applications." Neurocomputing 70.1 (2006): 489-501.<a href="#fnref101">↩</a></li>
<li id="fn102">Widrow, Bernard, et al. "The no-prop algorithm: A new learning algorithm for multilayer neural networks." Neural Networks 37 (2013): 182-188.<a href="#fnref102">↩</a></li>
<li id="fn103">Aleksander, Igor, et al. "A brief introduction to Weightless Neural Systems." ESANN. 2009.<a href="#fnref103">↩</a></li>
<li id="fn104"><a href="#fnref104">↩</a></li>
<li id="fn105">H. Larochelle <em>et al.</em>., "An empirical evaluation of deep architectures on problems with many factors of variation," <em>in Proc. 24th Int. Conf. Machine Learning</em>, pp. 473–480, 2007.<a href="#fnref105">↩</a></li>
<li id="fn106">G. E. Hinton., "Training Product of Experts by Minimizing Contrastive Divergence," <em>Neural Computation</em>, 14, pp. 1771–1800, 2002.<a href="#fnref106">↩</a></li>
<li id="fn107"></li>
<li id="fn108">A. Fischer and C. Igel. <a href="http://image.diku.dk/igel/paper/TRBMAI.pdf">Training Restricted Boltzmann Machines: An Introduction</a>. Pattern Recognition 47, pp. 25-39, 2014<a href="#fnref108">↩</a></li>
<li id="fn109"></li>
<li id="fn110"></li>
<li id="fn111"></li>
<li id="fn112"><a class="uri" href="http://ufldl.stanford.edu/tutorial/index.php/Convolutional_Neural_Network">http://ufldl.stanford.edu/tutorial/index.php/Convolutional_Neural_Network</a><a href="#fnref112">↩</a></li>
<li id="fn113"><a href="#fnref113">↩</a></li>
<li id="fn114"><a href="http://www.cs.toronto.edu/~kriz/conv-cifar10-aug2010.pdf">1</a><a href="#fnref114">↩</a></li>
<li id="fn115">[<a class="uri" href="http://delivery.acm.org/10.1145/1560000/1553453/p609-lee.pdf?ip=103.246.106.9&amp;id">http://delivery.acm.org/10.1145/1560000/1553453/p609-lee.pdf?ip=103.246.106.9&amp;id;</a>;=1553453&amp;acc;=ACTIVE%20SERVICE&amp;key;=045416EF4DDA69D9.6454B2DFDB9CC807.4D4702B0C3E38B35.4D4702B0C3E38B35&amp;CFID;=314860032&amp;CFTOKEN;=99308732&amp;__acm__=1396880972_5c56c52aa4ab95e2d971f2d2a80e3eb9]<a href="#fnref115">↩</a></li>
<li id="fn116"><a href="#fnref116">↩</a></li>
<li id="fn117"><a href="#fnref117">↩</a></li>
<li id="fn118"><a href="#fnref118">↩</a></li>
<li id="fn119"></li>
<li id="fn120"><a href="#fnref120">↩</a></li>
<li id="fn121"><a href="#fnref121">↩</a></li>
<li id="fn122"></li>
<li id="fn123"></li>
<li id="fn124"></li>
<li id="fn125"><a href="#fnref125">↩</a></li>
<li id="fn126"><a href="#fnref126">↩</a></li>
<li id="fn127"><a href="#fnref127">↩</a></li>
<li id="fn128"><a href="#fnref128">↩</a></li>
<li id="fn129"></li>
<li id="fn130"></li>
<li id="fn131"><a href="#fnref131">↩</a></li>
<li id="fn132"><a href="#fnref132">↩</a></li>
<li id="fn133"><a href="#fnref133">↩</a></li>
<li id="fn134"><a href="#fnref134">↩</a></li>
<li id="fn135"></li>
<li id="fn136"></li>
<li id="fn137"><a href="#fnref137">↩</a></li>
<li id="fn138"><a href="#fnref138">↩</a></li>
<li id="fn139"><a href="#fnref139">↩</a></li>
<li id="fn140"></li>
<li id="fn141"></li>
<li id="fn142"></li>
<li id="fn143"><a href="#fnref143">↩</a></li>
<li id="fn144"><a href="#fnref144">↩</a></li>
<li id="fn145"><a href="#fnref145">↩</a></li>
<li id="fn146"></li>
<li id="fn147"><a href="#fnref147">↩</a></li>
<li id="fn148"><a href="#fnref148">↩</a></li>
<li id="fn149"><a href="#fnref149">↩</a></li>
<li id="fn150"><a href="#fnref150">↩</a></li>
<li id="fn151"><a href="#fnref151">↩</a></li>
<li id="fn152"><a href="#fnref152">↩</a></li>
<li id="fn153"><a href="#fnref153">↩</a></li>
<li id="fn154"><a href="#fnref154">↩</a></li>
<li id="fn155"><a href="#fnref155">↩</a></li>
<li id="fn156"><a href="#fnref156">↩</a></li>
<li id="fn157"><a href="#fnref157">↩</a></li>
<li id="fn158"><a href="#fnref158">↩</a></li>
<li id="fn159"></li>
<li id="fn160"><a href="#fnref160">↩</a></li>
<li id="fn161"><a href="#fnref161">↩</a></li>
<li id="fn162">L. Deng, G. Tur, X. He, and D. Hakkani-Tur. "Use of Kernel Deep Convex Networks and End-To-End Learning for Spoken Language Understanding," <em>Proc. IEEE Workshop on Spoken Language Technologies</em>, 2012<a href="#fnref162">↩</a></li>
<li id="fn163"><a href="#fnref163">↩</a></li>
<li id="fn164">Hinton, Geoffrey E. "Distributed representations." (1984)<a href="#fnref164">↩</a></li>
<li id="fn165">Mozer, M. C., &amp; Das, S. (1993). A connectionist symbol manipulator that discovers the structure of context-free languages. NIPS 5 (pp. 863-870).<a href="#fnref165">↩</a></li>
<li id="fn166">J. Schmidhuber. Learning to control fast-weight memories: An alternative to recurrent nets. Neural Computation, 4(1):131-139, 1992<a href="#fnref166">↩</a></li>
<li id="fn167">F. Gers, N. Schraudolph, J. Schmidhuber. Learning precise timing with LSTM recurrent networks. JMLR 3:115-143, 2002.<a href="#fnref167">↩</a></li>
<li id="fn168">J. Schmidhuber. An introspective network that can learn to run its own weight change algorithm. In Proc. of the Intl. Conf. on Artificial Neural Networks, Brighton, pages 191-195. IEE, 1993.<a href="#fnref168">↩</a></li>
<li id="fn169">Hochreiter, Sepp; Younger, A. Steven; Conwell, Peter R. (2001). "Learning to Learn Using Gradient Descent". ICANN 2001, 2130: 87–94.<a href="#fnref169">↩</a></li>
<li id="fn170">Salakhutdinov, Ruslan, and Geoffrey Hinton. "Semantic hashing." International Journal of Approximate Reasoning 50.7 (2009): 969-978.<a href="#fnref170">↩</a></li>
<li id="fn171">Le, Quoc V., and Tomas Mikolov. "Distributed representations of sentences and documents." arXiv preprint arXiv:1405.4053 (2014).<a href="#fnref171">↩</a></li>
<li id="fn172">Graves, Alex, Greg Wayne, and Ivo Danihelka. "Neural Turing Machines." arXiv preprint arXiv:1410.5401 (2014).<a href="#fnref172">↩</a></li>
<li id="fn173">Weston, Jason, Sumit Chopra, and Antoine Bordes. "Memory networks." arXiv preprint arXiv:1410.3916 (2014).<a href="#fnref173">↩</a></li>
<li id="fn174"><em>TIMIT Acoustic-Phonetic Continuous Speech Corpus</em> Linguistic Data Consortium, Philadelphia.<a href="#fnref174">↩</a></li>
<li id="fn175"></li>
<li id="fn176">NIPS Workshop: Deep Learning for Speech Recognition and Related Applications, Whistler, BC, Canada, Dec. 2009 (Organizers: Li Deng, Geoff Hinton, D. Yu).<a href="#fnref176">↩</a></li>
<li id="fn177"><a href="#fnref177">↩</a></li>
<li id="fn178"><a href="#fnref178">↩</a></li>
<li id="fn179"><a href="#fnref179">↩</a></li>
<li id="fn180">Deng L., Li, J., Huang, J., Yao, K., Yu, D., Seide, F. et al. Recent Advances in Deep Learning for Speech Research at Microsoft. ICASSP, 2013.<a href="#fnref180">↩</a></li>
<li id="fn181"></li>
<li id="fn182"><a href="#fnref182">↩</a></li>
<li id="fn183">L. Deng, M. Seltzer, D. Yu, A. Acero, A. Mohamed, and G. Hinton (2010) Binary Coding of Speech Spectrograms Using a Deep Auto-encoder. Interspeech.<a href="#fnref183">↩</a></li>
<li id="fn184">Z. Tuske, P. Golik, R. Schlüter and H. Ney (2014). Acoustic Modeling with Deep Neural Networks Using Raw Time Signal for LVCSR. Interspeech.<a href="#fnref184">↩</a></li>
<li id="fn185"></li>
<li id="fn186"></li>
<li id="fn187"></li>
<li id="fn188"></li>
<li id="fn189">McMillan, R. "How Skype Used AI to Build Its Amazing New Language Translator", Wire, Dec. 2014.<a href="#fnref189">↩</a></li>
<li id="fn190">Hannun et al. (2014) "Deep Speech: Scaling up end-to-end speech recognition", arXiv:1412.5567.<a href="#fnref190">↩</a></li>
<li id="fn191">Ron Schneiderman (2015) "Accuracy, Apps Advance Speech Recognition --- Interview with Vlad Sejnoha and Li Deng", IEEE Signal Processing Magazine, Jan, 2015.<a href="#fnref191">↩</a></li>
<li id="fn192"><a class="uri" href="http://yann.lecun.com/exdb/mnist/">http://yann.lecun.com/exdb/mnist/</a>.<a href="#fnref192">↩</a></li>
<li id="fn193">D. Ciresan, U. Meier, J. Schmidhuber., "Multi-column Deep Neural Networks for Image Classification," ''Technical Report No. IDSIA-04-12', 2012.<a href="#fnref193">↩</a></li>
<li id="fn194">Vinyals et al. (2014)."Show and Tell: A Neural Image Caption Generator," arXiv:1411.4555.<a href="#fnref194">↩</a></li>
<li id="fn195">Fang et al. (2014)."From Captions to Visual Concepts and Back," arXiv:1411.4952.<a href="#fnref195">↩</a></li>
<li id="fn196">Kiros et al. (2014)."Unifying Visual-Semantic Embeddings with Multimodal Neural Language Models," arXiv:1411.2539.<a href="#fnref196">↩</a></li>
<li id="fn197"><a href="#fnref197">↩</a></li>
<li id="fn198"><a href="http://www.technologyreview.com/news/533936/nvidia-demos-a-car-computer-trained-with-deep-learning/">Nvidia Demos a Car Computer Trained with "Deep Learning"</a> (2015-01-06), David Talbot, <em><a href="MIT_Technology_Review" title="wikilink">MIT Technology Review</a></em><a href="#fnref198">↩</a></li>
<li id="fn199">Y. Bengio, R. Ducharme, P. Vincent, C. Jauvin., "A Neural Probabilistic Language Model," ''Journal of Machine Learning Research 3 (2003) 1137–1155', 2003.<a href="#fnref199">↩</a></li>
<li id="fn200"><a href="#fnref200">↩</a></li>
<li id="fn201"><a href="#fnref201">↩</a></li>
<li id="fn202"></li>
<li id="fn203"><a href="#fnref203">↩</a></li>
<li id="fn204"><a href="#fnref204">↩</a></li>
<li id="fn205">Y. Shen, X. He, J. Gao, L. Deng, and G. Mesnil (2014) " A Latent Semantic Model with Convolutional-Pooling Structure for Information Retrieval," Proc. CIKM.<a href="#fnref205">↩</a></li>
<li id="fn206">P. Huang, X. He, J. Gao, L. Deng, A. Acero, and L. Heck (2013) "Learning Deep Structured Semantic Models for Web Search using Clickthrough Data," Proc. CIKM.<a href="#fnref206">↩</a></li>
<li id="fn207">I. Sutskever, O. Vinyals, Q. Le (2014) "Sequence to Sequence Learning with Neural Networks," Proc. NIPS.<a href="#fnref207">↩</a></li>
<li id="fn208">J. Gao, X. He, W. Yih, and L. Deng(2014) "Learning Continuous Phrase Representations for Translation Modeling," Proc. ACL.<a href="#fnref208">↩</a></li>
<li id="fn209">J. Gao, P. Pantel, M. Gamon, X. He, L. Deng (2014) "Modeling Interestingness with Deep Neural Networks," Proc. EMNLP.<a href="#fnref209">↩</a></li>
<li id="fn210">J. Gao, X. He, L. Deng (2014) "Deep Learning for Natural Language Processing: Theory and Practice (Tutorial)," CIKM.<a href="#fnref210">↩</a></li>
<li id="fn211"><a href="#fnref211">↩</a></li>
<li id="fn212"><a href="#fnref212">↩</a></li>
<li id="fn213">"Announcement of the winners of the Merck Molecular Activity Challenge" <a class="uri" href="https://www.kaggle.com/c/MerckActivity/details/winners">https://www.kaggle.com/c/MerckActivity/details/winners</a>.<a href="#fnref213">↩</a></li>
<li id="fn214">Dahl, G. E.; Jaitly, N.; &amp; Salakhutdinov, R. (2014) "Multi-task Neural Networks for QSAR Predictions," ArXiv, 2014.<a href="#fnref214">↩</a></li>
<li id="fn215">"Toxicology in the 21st century Data Challenge" <a class="uri" href="https://tripod.nih.gov/tox21/challenge/leaderboard.jsp">https://tripod.nih.gov/tox21/challenge/leaderboard.jsp</a><a href="#fnref215">↩</a></li>
<li id="fn216">"NCATS Announces Tox21 Data Challenge Winners" <a class="uri" href="http://www.ncats.nih.gov/news-and-events/features/tox21-challenge-winners.html">http://www.ncats.nih.gov/news-and-events/features/tox21-challenge-winners.html</a><a href="#fnref216">↩</a></li>
<li id="fn217">Unterthiner, T.; Mayr, A.; Klambauer, G.; Steijaert, M.; Ceulemans, H.; Wegner, J. K.; &amp; Hochreiter, S. (2014) <a href="http://www.bioinf.jku.at/publications/2014/NIPS2014a.pdf">"Deep Learning as an Opportunity in Virtual Screening"</a>. Workshop on Deep Learning and Representation Learning (NIPS2014).<a href="#fnref217">↩</a></li>
<li id="fn218">Unterthiner, T.; Mayr, A.; Klambauer, G.; &amp; Hochreiter, S. (2015) <a href="http://arxiv.org/pdf/1503.01445v1">"Toxicity Prediction using Deep Learning"</a>. ArXiv, 2015.<a href="#fnref218">↩</a></li>
<li id="fn219">Ramsundar, B.; Kearnes, S.; Riley, P.; Webster, D.; Konerding, D.;&amp; Pande, V. (2015) "Massively Multitask Networks for Drug Discovery". ArXiv, 2015.<a href="#fnref219">↩</a></li>
<li id="fn220">Tkachenko, Yegor. Autonomous CRM Control via CLV Approximation with Deep Reinforcement Learning in Discrete and Continuous Action Space. (April 8, 2015). arXiv.org: <a class="uri" href="http://arxiv.org/abs/1504.01840">http://arxiv.org/abs/1504.01840</a><a href="#fnref220">↩</a></li>
<li id="fn221"><a href="#fnref221">↩</a></li>
<li id="fn222">J. Elman, <em>et al.</em>, "Rethinking Innateness," 1996.<a href="#fnref222">↩</a></li>
<li id="fn223"><a href="#fnref223">↩</a></li>
<li id="fn224"><a href="#fnref224">↩</a></li>
<li id="fn225">S. Blakeslee., "In brain's early growth, timetable may be critical," <em>The New York Times, Science Section</em>, pp. B5–B6, 1995.<a href="#fnref225">↩</a></li>
<li id="fn226">{BUFILL} E. Bufill, J. Agusti, R. Blesa., "Human neoteny revisited: The case of synaptic plasticity," <em>American Journal of Human Biology</em>, 23 (6), pp. 729–739, 2011.<a href="#fnref226">↩</a></li>
<li id="fn227">J. Shrager and M. H. Johnson., "Timing in the development of cortical function: A computational approach," <em>In B. Julesz and I. Kovacs (Eds.), Maturational windows and adult cortical plasticity</em>, 1995.<a href="#fnref227">↩</a></li>
<li id="fn228">D. Hernandez., "The Man Behind the Google Brain: Andrew Ng and the Quest for the New AI," <em><a class="uri" href="http://www.wired.com/wiredenterprise/2013/05/neuro-artificial-intelligence/all/">http://www.wired.com/wiredenterprise/2013/05/neuro-artificial-intelligence/all/</a>. Wired</em>, 10 May 2013.<a href="#fnref228">↩</a></li>
<li id="fn229">C. Metz., "Facebook's 'Deep Learning' Guru Reveals the Future of AI," <em><a class="uri" href="http://www.wired.com/wiredenterprise/2013/12/facebook-yann-lecun-qa/">http://www.wired.com/wiredenterprise/2013/12/facebook-yann-lecun-qa/</a>. Wired</em>, 12 December 2013.<a href="#fnref229">↩</a></li>
<li id="fn230">G. Marcus., "Is "Deep Learning" a Revolution in Artificial Intelligence?" <em>The New Yorker</em>, 25 November 2012.<a href="#fnref230">↩</a></li>
<li id="fn231"><a href="#fnref231">↩</a></li>
<li id="fn232"><a href="#fnref232">↩</a></li>
<li id="fn233"><a href="#fnref233">↩</a></li>
<li id="fn234">Ben Goertzel. Are there Deep Reasons Underlying the Pathologies of Today’s Deep Learning Algorithms? (2015) Url: <a class="uri" href="http://goertzel.org/DeepLearning_v1.pdf">http://goertzel.org/DeepLearning_v1.pdf</a><a href="#fnref234">↩</a></li>
<li id="fn235">Nguyen, Anh, Jason Yosinski, and Jeff Clune. "Deep Neural Networks are Easily Fooled: High Confidence Predictions for Unrecognizable Images." arXiv preprint arXiv:1412.1897 (2014).<a href="#fnref235">↩</a></li>
<li id="fn236">Szegedy, Christian, et al. "Intriguing properties of neural networks." arXiv preprint arXiv:1312.6199 (2013).<a href="#fnref236">↩</a></li>
<li id="fn237"></li>
<li id="fn238"><a href="#fnref238">↩</a></li>
<li id="fn239"></li>
<li id="fn240">Miller, G. A., and N. Chomsky. "Pattern conception." Paper for Conference on pattern detection, University of Michigan. 1957.<a href="#fnref240">↩</a></li>
<li id="fn241">Jason Eisner, Deep Learning of Recursive Structure: Grammar Induction, <a class="uri" href="http://techtalks.tv/talks/deep-learning-of-recursive-structure-grammar-induction/58089/">http://techtalks.tv/talks/deep-learning-of-recursive-structure-grammar-induction/58089/</a><a href="#fnref241">↩</a></li>
<li id="fn242"><a href="http://singa.incubator.apache.org/"></a><a class="uri" href="http://singa.incubator.apache.org/">http://singa.incubator.apache.org/</a><a href="#fnref242">↩</a></li>
</ol>
</section>
</body>
</html>
