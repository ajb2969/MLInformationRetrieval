<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title offset="221">Wiener–Khinchin theorem</title>
   <script type="text/javascript"
      src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js">
    </script>
</head>
<body>
<h1>Wiener–Khinchin theorem</h1><hr/>
<p>In applied mathematics, the <strong>Wiener–Khinchin theorem</strong>, also known as the <strong>Wiener–Khintchine theorem</strong> and sometimes as the <strong>Wiener–Khinchin–Einstein theorem</strong> or the <strong>Khinchin–Kolmogorov theorem</strong>, states that the <a class="uri" href="autocorrelation" title="wikilink">autocorrelation</a> function of a <a href="wide-sense-stationary_random_process" title="wikilink">wide-sense-stationary random process</a> has a spectral decomposition given by the <a href="power_spectrum" title="wikilink">power spectrum</a> of that process.<a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a><a class="footnoteRef" href="#fn2" id="fnref2"><sup>2</sup></a><a class="footnoteRef" href="#fn3" id="fnref3"><sup>3</sup></a><a class="footnoteRef" href="#fn4" id="fnref4"><sup>4</sup></a><a class="footnoteRef" href="#fn5" id="fnref5"><sup>5</sup></a><a class="footnoteRef" href="#fn6" id="fnref6"><sup>6</sup></a><a class="footnoteRef" href="#fn7" id="fnref7"><sup>7</sup></a></p>
<h2 id="history">History</h2>
<p><a href="Norbert_Wiener" title="wikilink">Norbert Wiener</a> proved this <a class="uri" href="theorem" title="wikilink">theorem</a> for the case of a deterministic function in 1930;.<a class="footnoteRef" href="#fn8" id="fnref8"><sup>8</sup></a> <a href="Aleksandr_Khinchin" title="wikilink">Aleksandr Khinchin</a> later <a class="footnoteRef" href="#fn9" id="fnref9"><sup>9</sup></a> formulated an analogous result for stationary stochastic processes and published that probabilistic analogue in 1934.<a class="footnoteRef" href="#fn10" id="fnref10"><sup>10</sup></a> <a href="Albert_Einstein" title="wikilink">Albert Einstein</a> explained, without proofs, the idea in a brief two-page memo in 1914.<a class="footnoteRef" href="#fn11" id="fnref11"><sup>11</sup></a></p>
<h2 id="the-case-of-a-continuous-time-process">The case of a continuous-time process</h2>
<p>For continuous time, the Wiener–Khinchin theorem<a class="footnoteRef" href="#fn12" id="fnref12"><sup>12</sup></a><a class="footnoteRef" href="#fn13" id="fnref13"><sup>13</sup></a> says that if <span class="LaTeX">$x$</span> is a wide-sense stationary process such that its <a href="autocorrelation_function" title="wikilink">autocorrelation function</a> (sometimes called <a class="uri" href="autocovariance" title="wikilink">autocovariance</a>) defined in terms of statistical <a href="expected_value" title="wikilink">expected value</a> E, <span class="LaTeX">$r_{xx}(\tau) = \operatorname{E}\big[\, x(t)x^*(t-\tau) \, \big] \$</span> exists and is finite at every lag <span class="LaTeX">$\tau$</span>, then there exists a monotone function <span class="LaTeX">$F(f)$</span> in the frequency domain <span class="LaTeX">$-\infty < f < \infty$</span> such that</p>
<p><span class="LaTeX">$$r_{xx} (\tau) = \int_{-\infty}^\infty e^{2\pi i\tau f}  dF(f)$$</span></p>
<p>where the integral is a <a href="Stieltjes_integral" title="wikilink">Stieltjes integral</a>. This is a kind of spectral decomposition of the auto-correlation function. F is called the power spectral distribution function, and is a statistical distribution function. It is sometimes called the integrated spectrum.</p>
<p>(The asterisk denotes complex conjugate, and of course it can be omitted if the random process is real-valued.)</p>
<p>Note that the Fourier transform of <span class="LaTeX">$x(t)\,$</span> does not exist in general, because stationary random functions are not generally either <a href="square-integrable_function" title="wikilink">square integrable</a> or absolutely integrable. Nor is <span class="LaTeX">$r_{xx}$</span> assumed to be absolutely integrable, so it need not have a Fourier transform, either.</p>
<p>But if <span class="LaTeX">$F(f)$</span> is absolutely continuous, for example if the process is purely indeterministic, then <span class="LaTeX">$F$</span> is differentiable <a href="almost_everywhere" title="wikilink">almost everywhere</a>. In this case, one can define <span class="LaTeX">$S(f)$</span>, the power <a href="spectral_density" title="wikilink">spectral density</a> of <span class="LaTeX">$x(t)\,$</span>, by taking the averaged derivative of <span class="LaTeX">$F$</span>. Because the left and right derivatives of <span class="LaTeX">$F$</span> exist everywhere, we can put <span class="LaTeX">$S(f) = \frac12 (\lim_{\epsilon\downarrow 0} \frac1\epsilon (F(f+\epsilon)-F(f))+  \lim_{\epsilon\uparrow 0} \frac1\epsilon (F(f+\epsilon)-F(f)))$</span> everywhere,<a class="footnoteRef" href="#fn14" id="fnref14"><sup>14</sup></a> (obtaining that F is the integral of its averaged derivative<a class="footnoteRef" href="#fn15" id="fnref15"><sup>15</sup></a>), and the theorem simplifies to</p>
<p><span class="LaTeX">$$r_{xx} (\tau) = \int_{-\infty}^\infty S(f) e^{2\pi i\tau f} df.$$</span></p>
<p>If now one assumes that r and S satisfy the necessary conditions for Fourier inversion to be valid, the Wiener–Khinchin theorem takes the simple form of saying that r and S are a Fourier transform pair, and</p>
<p><span class="LaTeX">$$S(f) = \int_{-\infty}^\infty r_{xx} (\tau)  e^{-2\pi if\tau} d\tau.$$</span></p>
<h2 id="the-case-of-a-discrete-time-process">The case of a discrete-time process</h2>
<p>For the discrete-time case, the power spectral density of the function with discrete values <span class="LaTeX">$x[n]\,$</span> is</p>
<p><span class="LaTeX">$$S(f)=\sum_{k=-\infty}^\infty r_{xx}[k]e^{-i(2\pi f) k},$$</span></p>
<p>where</p>
<p><span class="LaTeX">$$r_{xx}[k] = \operatorname{E}\big[ \, x[n] x^*[n-k] \, \big] \$$</span></p>
<p>is the discrete autocorrelation function of <span class="LaTeX">$x[n]\,$</span>, provided this is absolutely integrable. Being a sampled and discrete-time sequence, the spectral density is periodic in the frequency domain. This is due to the problem of <a class="uri" href="aliasing" title="wikilink">aliasing</a>: the contribution of any frequency higher than the <a href="Nyquist_frequency" title="wikilink">Nyquist frequency</a> seems to be equal to that of its alias between 0 and 1. For this reason, the range of the function <span class="LaTeX">$S$</span> is usually restricted to lie between 0 and 1.</p>
<h2 id="application">Application</h2>
<p>The theorem is useful for analyzing <a href="LTI_system_theory" title="wikilink">linear time-invariant systems</a>, LTI systems, when the inputs and outputs are not square integrable, so their Fourier transforms do not exist. A corollary is that the Fourier transform of the autocorrelation function of the output of an LTI system is equal to the product of the Fourier transform of the autocorrelation function of the input of the system times the squared magnitude of the Fourier transform of the system impulse response.<a class="footnoteRef" href="#fn16" id="fnref16"><sup>16</sup></a> This works even when the Fourier transforms of the input and output signals do not exist because these signals are not square integrable, so the system inputs and outputs cannot be directly related by the Fourier transform of the impulse response.</p>
<p>Since the Fourier transform of the autocorrelation function of a signal is the power spectrum of the signal, this corollary is equivalent to saying that the power spectrum of the output is equal to the power spectrum of the input times the power <a href="transfer_function" title="wikilink">transfer function</a>.</p>
<p>This corollary is used in the parametric method for power spectrum estimation.</p>
<h2 id="discrepancies-in-terminology">Discrepancies in terminology</h2>
<p>In many textbooks and in much of the technical literature it is tacitly assumed that Fourier inversion of the <a class="uri" href="autocorrelation" title="wikilink">autocorrelation</a> function and the power spectral density is valid, and the Wiener–Khinchin theorem is stated, very simply, as if it said that the Fourier transform of the autocorrelation function was equal to the power <a href="spectral_density" title="wikilink">spectral density</a>, ignoring all questions of convergence.<a class="footnoteRef" href="#fn17" id="fnref17"><sup>17</sup></a> (Einstein is an example.) But the theorem (as stated here), was applied by <a href="Norbert_Wiener" title="wikilink">Norbert Wiener</a> and <a href="Aleksandr_Khinchin" title="wikilink">Aleksandr Khinchin</a> to the sample functions (signals) of <a href="wide-sense-stationary_random_process" title="wikilink">wide-sense-stationary random processes</a>, signals whose Fourier transforms do not exist. The whole point of Wiener's contribution was to make sense of the spectral decomposition of the autocorrelation function of a sample function of a <a href="wide-sense-stationary_random_process" title="wikilink">wide-sense-stationary random process</a> even when the integrals for the Fourier transform and Fourier inversion do not make sense.</p>
<p>Some authors refer to R as the autocovariance function. They then proceed to normalise it, by dividing by R(0), to obtain what they refer to as the autocorrelation function.</p>
<h2 id="references">References</h2>
<h2 id="further-reading">Further reading</h2>
<ul>
<li></li>
<li></li>
<li></li>
<li>
<p>(a classified document written for the Dept. of War in 1943).</p></li>
<li></li>
</ul>
<p>"</p>
<p><a href="Category:Theorems_in_Fourier_analysis" title="wikilink">Category:Theorems in Fourier analysis</a> <a href="Category:Signal_processing" title="wikilink">Category:Signal processing</a> <a href="Category:Probability_theorems" title="wikilink">Category:Probability theorems</a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1"><a href="#fnref1">↩</a></li>
<li id="fn2"><a href="#fnref2">↩</a></li>
<li id="fn3">Hannan, E.J., "Stationary Time Series", in: John Eatwell, Murray Milgate, and Peter Newman, editors, <em>The New Palgrave: A Dictionary of Economics. Time Series and Statistics</em>, Macmillan, London, 1990, p. 271.<a href="#fnref3">↩</a></li>
<li id="fn4"><a href="#fnref4">↩</a></li>
<li id="fn5"><a href="#fnref5">↩</a></li>
<li id="fn6"><a href="#fnref6">↩</a></li>
<li id="fn7"><a href="#fnref7">↩</a></li>
<li id="fn8"><a href="#fnref8">↩</a></li>
<li id="fn9">″Wiener's basic theory of 'generalised harmonic analysis' is in no way probabilistic, and the theorems apply to single well defined functions rather than to ensembles of functions.″ "A further development of these ideas occurs in the work of A. I. Khintchine (1894—1959) on stationary random processes (or stochastic processes)..." "...in contexts in which it is not important to distinguish the two aproaches the theory is often referred to as the Wiener—Khintchine theory."<a href="#fnref9">↩</a></li>
<li id="fn10"><a href="#fnref10">↩</a></li>
<li id="fn11"><a href="#fnref11">↩</a></li>
<li id="fn12"></li>
<li id="fn13">Hannan, E.J., "Stationary Time Series", in: John Eatwell, Murray Milgate, and Peter Newman, editors, <em>The New Palgrave: A Dictionary of Economics. Time Series and Statistics</em>, Macmillan, London, 1990, p. 271.<a href="#fnref13">↩</a></li>
<li id="fn14"><a href="#fnref14">↩</a></li>
<li id="fn15"><a href="#fnref15">↩</a></li>
<li id="fn16"><a href="#fnref16">↩</a></li>
<li id="fn17"><a href="#fnref17">↩</a></li>
</ol>
</section>
</body>
</html>
