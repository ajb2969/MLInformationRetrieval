   Statistical model      Statistical model   A statistical model embodies a set of assumptions concerning the generation of the observed data, and similar data from a larger population . A model represents, often in considerably idealized form, the data-generating process. The model assumptions describe a set of probability distributions , some of which are assumed to adequately approximate the distribution from which a particular data set is sampled .  A model is usually specified by mathematical equations that relate one or more random variables and possibly other non-random variables. As such, "a model is a formal representation of a theory" ( Herman Ad√®r quoting Kenneth Bollen ). 1  All statistical hypothesis tests and all statistical estimators are derived from statistical models. More generally, statistical models are part of the foundation of statistical inference .  Formal definition  In mathematical terms, a statistical model is usually thought of as a pair (    S  ,  ùí´     S  ùí´    S,\mathcal{P}   ), where   S   S   S   is the set of possible observations, i.e. the sample space , and   ùí´   ùí´   \mathcal{P}   is a set of probability distributions on   S   S   S   . 2  The intuition behind this definition is as follows. It is assumed that there is a "true" probability distribution that generates the observed data. We choose   ùí´   ùí´   \mathcal{P}   to represent a set (of distributions) which contains a distribution that adequately approximates the true distribution. Note that we do not require that   ùí´   ùí´   \mathcal{P}   contains the true distribution, and in practice that is rarely the case. Indeed, as Burnham & Anderson state, "A model is a simplification or approximation of reality and hence will not reflect all of reality" 3 ‚Äîwhence the saying " all models are wrong ".  The set   ùí´   ùí´   \mathcal{P}   is almost always parameterized    ùí´  =   {   P  Œ∏   :   Œ∏  ‚àà  Œò   }       ùí´   conditional-set   subscript  P  Œ∏     Œ∏  normal-Œò      \mathcal{P}=\{P_{\theta}:\theta\in\Theta\}   . The set   Œò   normal-Œò   \Theta   defines the parameters of the model. A parameterization is generally required to have distinct parameter values give rise to distinct distributions, i.e. to meet this condition     P   Œ∏  1    =   P   Œ∏  2    ‚áí   Œ∏  1   =   Œ∏  2          subscript  P   subscript  Œ∏  1     subscript  P   subscript  Œ∏  2      normal-‚áí     subscript  Œ∏  1         subscript  Œ∏  2      P_{\theta_{1}}=P_{\theta_{2}}\Rightarrow\theta_{1}=\theta_{2}   . A parameterization that meets the condition is said to be identifiable . 4  An example  Height and age are each probabilistically distributed over humans. They are stochastically related: when we know that a person is of age 10, this influences the chance of the person being 6 feet tall. We could formalize that relationship in a linear regression model with the following form: height i = b 0 + b 1 age i + Œµ i , where b 0 is the intercept, b 1 is a parameter that age is multiplied by to get a prediction of height, Œµ is the error term, and i identifies the person. This implies that height is predicted by age, with some error.  An admissible model must be consistent with all the data points. Thus, the straight line (height i = b 0 + b 1 age i ) is not a model of the data. The line cannot be a model, unless it exactly fits all the data points‚Äîi.e. all the data points lie perfectly on a straight line. The error term, Œµ i , must be included in the model, so that the model is consistent with all the data points.  To do statistical inference , we would first need to assume some probability distributions for the Œµ i . For instance, we might assume that the Œµ i distributions are i.i.d. Gaussian, with zero mean. In this instance, the model would have 3 parameters: b 0 , b 1 , and the variance of the Gaussian distribution.  We can formally specify the model in the form (    S  ,  ùí´     S  ùí´    S,\mathcal{P}   ) as follows. The sample space,   S   S   S   , of our model comprises the set of all possible pairs (age, height). Each possible value of   Œ∏   Œ∏   \theta   = ( b 0 , b 1 , œÉ 2 ) determines a distribution on   S   S   S   ; denote that distribution by    P  Œ∏     subscript  P  Œ∏    P_{\theta}   . If   Œò   normal-Œò   \Theta   is the set of all possible values of   Œ∏   Œ∏   \theta   , then    ùí´  =   {   P  Œ∏   :   Œ∏  ‚àà  Œò   }       ùí´   conditional-set   subscript  P  Œ∏     Œ∏  normal-Œò      \mathcal{P}=\{P_{\theta}:\theta\in\Theta\}   . (The parameterization is identifiable, and this is easy to check.)  In this example, the model is determined by (1) specifying   S   S   S   and (2) making some assumptions relevant to   ùí´   ùí´   \mathcal{P}   . There are two assumptions: that height can be approximated by a linear function of age; that errors in the approximation are distributed as i.i.d. Gaussian. The assumptions are sufficient to specify   ùí´   ùí´   \mathcal{P}   ‚Äîas they are required to do.  General remarks  A statistical model is a special type of mathematical model . What distinguishes a statistical model from other mathematical models is that a statistical model is non- deterministic . Thus, in a statistical model specified via mathematical equations, some of the variables do not have specific values, but instead have probability distributions; i.e. some of the variables are stochastic . In the example above, Œµ is a stochastic variable; without that variable, the model would be deterministic.  Statistical models are often used even when the physical process being modeled is deterministic. For instance, coin tossing is, in principle, a deterministic process; yet it is commonly modeled as stochastic (via a Bernoulli process ).  There are three purposes for a statistical model, according to Konishi¬†& Kitagawa. 5   Predictions  Extraction of information  Description of stochastic structures   Dimension of a model  Suppose that we have a statistical model (    S  ,  ùí´     S  ùí´    S,\mathcal{P}   ) with    ùí´  =   {   P  Œ∏   :   Œ∏  ‚àà  Œò   }       ùí´   conditional-set   subscript  P  Œ∏     Œ∏  normal-Œò      \mathcal{P}=\{P_{\theta}:\theta\in\Theta\}   . The model is said to be parametric if   Œò   normal-Œò   \Theta   has a finite dimension. In notation, we write that    Œò  ‚äÜ   ‚Ñù  d       normal-Œò   superscript  ‚Ñù  d     \Theta\subseteq\mathbb{R}^{d}   where d is a positive integer (   ‚Ñù   ‚Ñù   \mathbb{R}   denotes the real numbers ; other sets can be used, in principle). Here, d is called the dimension of the model.  As an example, if we assume that data arise from a univariate Gaussian distribution , then we are assuming that      ùí´  =   {     P   Œº  ,  œÉ     (  x  )    ‚â°    1     2  œÄ    œÉ     exp   (   -     (   x  -  Œº   )   2    2   œÉ  2      )      :    Œº  ‚àà  ‚Ñù   ,   œÉ  >  0    }       ùí´   conditional-set       subscript  P   Œº  œÉ    x       1        2  œÄ    œÉ           superscript    x  Œº   2     2   superscript  œÉ  2          formulae-sequence    Œº  ‚Ñù     œÉ  0       \mathcal{P}=\{P_{\mu,\sigma}(x)\equiv\frac{1}{\sqrt{2\pi}\sigma}\exp\left(-%
 \frac{(x-\mu)^{2}}{2\sigma^{2}}\right):\mu\in\mathbb{R},\sigma>0\}   . In this example, the dimension, d , equals 2.  As another example, suppose that the data consists of points ( x , y ) that we assume are distributed according to a straight line with i.i.d. Gaussian residuals (with zero mean). Then the dimension of the statistical model is 3: the intercept of the line, the slope of the line, and the variance of the distribution of the residuals. (Note that in geometry, a straight line has dimension 1.)  A statistical model is nonparametric if the parameter set   Œò   normal-Œò   \Theta   is infinite dimensional. A statistical model is semiparametric if it has both finite-dimensional and infinite-dimensional parameters. Formally, if d is the dimension of   Œò   normal-Œò   \Theta   and n is the number of samples, both semiparametric and nonparemtric models have    d  ‚Üí  ‚àû     normal-‚Üí  d     d\rightarrow\infty   as    n  ‚Üí  ‚àû     normal-‚Üí  n     n\rightarrow\infty   . If     d  /  n   ‚Üí  0     normal-‚Üí    d  n   0    d/n\rightarrow 0   as    n  ‚Üí  ‚àû     normal-‚Üí  n     n\rightarrow\infty   , then the model is semiparametric; otherwise, the model is nonparametric.  Parametric models are by far the most commonly-used statistical models. Regarding semiparametric and nonparametric models, Sir David Cox has said, "These typically involve fewer assumptions of structure and distributional form but usually contain strong assumptions about independencies". 6  Nested models  Two statistical models are nested if the first model can be transformed into the second model by imposing constraints on the parameters of the first model. For example, the set of all Gaussian distributions has, nested within it, the set of zero-mean Gaussian distributions: we constrain the mean in the set of all Gaussian distributions to get the zero-mean distributions.  In that example, the first model has a higher dimension than the second model (the zero-mean model has dimension 1). Such is usually, but not always, the case. As a different example, the set of positive-mean Gaussian distributions, which has dimension 2, is nested within the set of all Gaussian distributions.  Comparing models  It is assumed that there is a "true" probability distribution that generates the observed data. The main goal of model selection is to make statements about which elements of   ùí´   ùí´   \mathcal{P}   are most likely to adequately approximate the true distribution.  Models can be compared to each other. This can either be done when we have done an exploratory data analysis or a confirmatory data analysis . In an exploratory analysis, we formulate all models we can think of, and see which describes our data best. In a confirmatory analysis we check which of the models that we have described before the data was collected best fits the data, or test if our only model fits the data.  Common criteria for comparing models include R 2 , Bayes factor , and the likelihood-ratio test together with its generalization relative likelihood .  Konishi & Kitagawa state: "The majority of the problems in statistical inference can be considered to be problems related to statistical modeling. They are typically formulated as comparisons of several statistical models." 7 Relatedly, Sir David Cox has said, "How [the] translation from subject-matter problem to statistical model is done is often the most critical part of an analysis". 8  See also   Deterministic system  Econometric model  Graphical model  Identifiability  Regression analysis  Scientific modelling  Statistical inference  Statistical theory  Stochastic process  System identification   Notes  References    .   .   .   .   .   Further reading   Davison A.C. (2008), Statistical Models , Cambridge University Press .  Freedman D.A. (2009), Statistical Models , Cambridge University Press .  Helland I.S. (2010), Steps Towards a Unified Basis for Scientific Models and Methods , World Scientific .  Kroese D.P., Chan J.C.C. (2014), Statistical Modeling and Computation , Springer .  Stapleton J.H. (2007), Models for Probability and Statistical Inference , Wiley-Interscience .   "  Category:Mathematical modeling  Category:Scientific modeling  Category:Statistical models  Category:Statistical theory     ‚Ü©  ‚Ü©  ‚Ü©   ‚Ü©  ‚Ü©  ‚Ü©  ‚Ü©     