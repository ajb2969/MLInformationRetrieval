


Comonotonicity




Comonotonicity

In probability theory, comonotonicity mainly refers to the perfect positive dependence between the components of a random vector, essentially saying that they can be represented as increasing functions of a single random variable. In two dimensions it is also possible to consider perfect negative dependence, which is called countermonotonicity.
Comonotonicity is also related to the comonotonic additivity of the Choquet integral.1
The concept of comonotonicity has applications in financial risk management and actuarial science, see e.g.  and . In particular, the sum of the components  is the riskiest if the joint probability distribution of the random vector  is comonotonic.2 Furthermore, the -quantile of the sum equals of the sum of the -quantiles of its components, hence comonotonic random variables are quantile-additive.34
For extensions of comonotonicity, see  and .
Definitions
Comonotonicity of subsets of 
A subset  of  is called comonotonic5 (sometimes also nondecreasing6) if, for all  and  in  with  for some }, it follows that  for all }.
This means that  is a totally ordered set.
Comonotonicity of probability measures on 
Let  be a probability measure on the -dimensional Euclidean space  and let  denote its multivariate cumulative distribution function, that is



Furthermore, let  denote the cumulative distribution functions of the  one-dimensional marginal distributions of , that means



for every }. Then  is called comonotonic, if



Note that the probability measure  is comonotonic if and only if its support  is comonotonic according to the above definition.7
Comonotonicity of -valued random vectors
An -valued random vector  (X1, . . . , Xn)}} is called comonotonic, if its multivariate distribution (the pushforward measure) is comonotonic, this means



Properties
An -valued random vector  (X1, . . . , Xn)}} is comonotonic if and only if it can be represented as



where d}} stands for equality in distribution, on the right-hand side are the left-continuous generalized inverses8 of the cumulative distribution functions , and  is a uniformly distributed random variable on the unit interval. More generally, a random vector is comonotonic if and only if it agrees in distribution with a random vector where all components are non-decreasing functions (or all are non-increasing functions) of the same random variable.9
Upper bounds
Upper Fréchet–Hoeffding bound for cumulative distribution functions
Let  (X1, . . . , Xn)}} be an -valued random vector. Then, for every },



hence



with equality everywhere if and only if  is comonotonic.
Upper bound for the covariance
Let  be a bivariate random vector such that the expected values of ,  and the product  exist. Let  be a comonotonic bivariate random vector with the same one-dimensional marginal distributions as .10 Then it follows from Höffding's formula for the covariance11 and the upper Fréchet–Hoeffding bound that



and, correspondingly,



with equality if and only if  is comonotonic.12
Note that this result generalizes the rearrangement inequality and Chebyshev's sum inequality.
See also

Copula

Notes
Citations
References










"
Category:Theory of probability distributions Category:Statistical dependence Category:Covariance and correlation








See  for the case  2}}
See  for the case  2}}


 always exists, take for example , see section Properties above.






