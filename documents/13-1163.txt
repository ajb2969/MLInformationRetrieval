   Generalized chi-squared distribution      Generalized chi-squared distribution   In probability theory and statistics , the specific name generalized chi-squared distribution (also generalized chi-square distribution ) arises in relation to one particular family of variants of the chi-squared distribution . There are several other such variants for which the same term is sometimes used, or which clearly are generalizations of the chi-squared distribution, and which are treated elsewhere: some are special cases of the family discussed here, for example the noncentral chi-squared distribution and the gamma distribution , while the generalized gamma distribution is outside this family. The type of generalisation of the chi-squared distribution that is discussed here is of importance because it arises in the context of the distribution of statistical estimates in cases where the usual statistical theory does not hold. For example, if a predictive model is fitted by least squares but the model errors have either autocorrelation or heteroscedasticity , then a statistical analysis of alternative model structures can be undertaken by relating changes in the sum of squares to an asymptotically valid generalized chi-squared distribution. 1 More specifically, the distribution can be defined in terms of a quadratic form derived from a multivariate normal distribution .  Definition  One formulation of the generalized chi-squared distribution is as follows. 2 Let z have a multivariate normal distribution with zero mean and covariance matrix B , then the value of the quadratic form  X = z T Az, where A is a matrix, has a generalised chi-squared distribution with parameters A and B . Note that there is some redundancy in this formulation, as for any matrix C , the distribution with parameters C T AC and B is identical to the distribution with parameters A and CBC T . The most general form of generalized chi-squared distribution is obtained by extending the above consideration in two ways: firstly, to allow z to have a non-zero mean and, secondly, to include an additional linear combination of z in the definition of X .  Note that, in the above formulation, A and B need not be positive definite . However, the case where A is restricted to be at least positive semidefinite is an important one.  For the most general case, a reduction towards a common standard form can be made by using a representation of the following form: 3       X  =      (   z  +  a   )   T   A   (   z  +  a   )    +    c  T   z    =      (   x  +  b   )   T   D   (   x  +  b   )    +    d  T   x   +  e    ,        X       superscript    z  a   normal-T   A    z  a       superscript  c  normal-T   z              superscript    x  b   normal-T   D    x  b       superscript  d  normal-T   x   e      X=(z+a)^{\mathrm{T}}A(z+a)+c^{\mathrm{T}}z=(x+b)^{\mathrm{T}}D(x+b)+d^{\mathrm%
 {T}}x+e,     where D is a diagonal matrix and where x represents a vector of uncorrelated standard normal random variables. An alternative representation can be stated in the form: 4 5       X  =     ∑   i  =  1   r     λ  i    Y  i     +   f   Z  0      ,      X      superscript   subscript     i  1    r      subscript  λ  i    subscript  Y  i       f   subscript  Z  0       X=\sum_{i=1}^{r}\lambda_{i}Y_{i}+fZ_{0},   where the Y i represent random variables having (different) noncentral chi-squared distributions , where Z 0 has a standard normal distribution, and where all these random variables are independent. Some important special cases relating to this particular form either omit the additional standard normal term and/or have central rather than non-central chi-squared distributions for the components of the summation.  Practical implementation  Computer code for evaluating the cumulative distribution function of the generalized chi-squared distribution has been published, 6 7 but some preliminary manipulation of the parameters of the distribution is usually necessary.  Other applications  The following application arises in the context of Fourier analysis in signal processing , renewal theory in probability theory , and multi-antenna systems in wireless communication . The common factor of these areas is that the sum of exponentially distributed variables is of importance (or identically, the sum of squared magnitudes circular symmetric complex Gaussian variables).  If    Z  i     subscript  Z  i    Z_{i}   are k  independent , circular symmetric complex Gaussian random variables with mean 0 and variance     σ  i  2     superscript   subscript  σ  i   2    \sigma_{i}^{2}   , then the random variable       Q  ~   =    ∑   i  =  1   k     |   Z  i   |   2         normal-~  Q     superscript   subscript     i  1    k    superscript     subscript  Z  i    2      \tilde{Q}=\sum_{i=1}^{k}|Z_{i}|^{2}     has a generalized chi-squared distribution of a particular form. The difference from the standard chi-squared distribution is that    Z  i     subscript  Z  i    Z_{i}   are complex and can have different variances, and the difference from the more general generalized chi-squared distribution is that the relevant scaling matrix A is diagonal. If    μ  =   σ  i  2       μ   superscript   subscript  σ  i   2     \mu=\sigma_{i}^{2}   for all i , then    Q  ~     normal-~  Q    \tilde{Q}   , scaled down by    μ  /  2      μ  2    \mu/2   (i.e. multiplied by    2  /  μ      2  μ    2/\mu   ), has a chi-squared distribution ,     χ  2    (   2  k   )        superscript  χ  2     2  k     \chi^{2}(2k)   , also known as an Erlang distribution . If    σ  i  2     superscript   subscript  σ  i   2    \sigma_{i}^{2}   have distinct values for all i , then    Q  ~     normal-~  Q    \tilde{Q}   has the pdf 8        f   (  x  ;  k  ,   σ  1  2   ,  …  ,   σ  k  2   )    =    ∑   i  =  1   k     e   -   x   σ  i  2        σ  i  2     ∏    j  =  1   ,   j  ≠  i    k    (   1  -    σ  j  2    σ  i  2     )          for  x   ≥  0.      formulae-sequence      f   x  k   superscript   subscript  σ  1   2   normal-…   superscript   subscript  σ  k   2       superscript   subscript     i  1    k      superscript  e      x   superscript   subscript  σ  i   2         superscript   subscript  σ  i   2     superscript   subscript  product   formulae-sequence    j  1     j  i     k     1     superscript   subscript  σ  j   2    superscript   subscript  σ  i   2              for  x   0.     f(x;k,\sigma_{1}^{2},\ldots,\sigma_{k}^{2})=\sum_{i=1}^{k}\frac{e^{-\frac{x}{%
 \sigma_{i}^{2}}}}{\sigma_{i}^{2}\prod_{j=1,j\neq i}^{k}(1-\frac{\sigma_{j}^{2}%
 }{\sigma_{i}^{2}})}\quad\mbox{for }x\geq 0.     If there are sets of repeated variances among    σ  i  2     superscript   subscript  σ  i   2    \sigma_{i}^{2}   , assume that they are divided into M sets, each representing a certain variance value. Denote    𝐫  =   (   r  1   ,   r  2   ,  …  ,   r  M   )       𝐫    subscript  r  1    subscript  r  2   normal-…   subscript  r  M      \mathbf{r}=(r_{1},r_{2},\dots,r_{M})   to be the number of repetitions in each group. That is, the m th set contains    r  m     subscript  r  m    r_{m}   variables that have variance     σ  m  2   .     subscript   superscript  σ  2   m    \sigma^{2}_{m}.   It represents an arbitrary linear combination of independent    χ  2     superscript  χ  2    \chi^{2}   -distributed random variables with different degrees of freedom:         Q  ~   =    ∑   m  =  1   M     σ  m  2    Q  m      ,    Q  m   ∼    χ  2    (   2   r  m    )      .     formulae-sequence     normal-~  Q     superscript   subscript     m  1    M      subscript   superscript  σ  2   m    subscript  Q  m       similar-to   subscript  Q  m      superscript  χ  2     2   subscript  r  m        \tilde{Q}=\sum_{m=1}^{M}\sigma^{2}_{m}Q_{m},\quad Q_{m}\sim\chi^{2}(2r_{m})\,.     The pdf of    Q  ~     normal-~  Q    \tilde{Q}   is 9         f   (  x  ;  𝐫  ,   σ  1  2   ,   …   σ  M  2    )    =    ∏   m  =  1   M     1   σ  m   2   r  m        ∑   k  =  1   M     ∑   l  =  1    r  k       Ψ   k  ,  l  ,  𝐫      (    r  k   -  l   )   !      (   -  x   )     r  k   -  l     e   -   x   σ  k  2              , for  x   ≥  0    ,     formulae-sequence      f   x  𝐫   subscript   superscript  σ  2   1     normal-…   subscript   superscript  σ  2   M        superscript   subscript  product    m  1    M       1   subscript   superscript  σ    2   subscript  r  m     m      superscript   subscript     k  1    M     superscript   subscript     l  1     subscript  r  k         subscript  normal-Ψ   k  l  𝐫         subscript  r  k   l      superscript    x      subscript  r  k   l     superscript  e      x   subscript   superscript  σ  2   k                , for  x   0     f(x;\mathbf{r},\sigma^{2}_{1},\dots\sigma^{2}_{M})=\prod_{m=1}^{M}\frac{1}{%
 \sigma^{2r_{m}}_{m}}\sum_{k=1}^{M}\sum_{l=1}^{r_{k}}\frac{\Psi_{k,l,\mathbf{r}%
 }}{(r_{k}-l)!}(-x)^{r_{k}-l}e^{-\frac{x}{\sigma^{2}_{k}}}\quad\text{, for }x%
 \geq 0,     where        Ψ   k  ,  l  ,  𝐫    =     (   -  1   )     r  k   -  1      ∑   𝐢  ∈   Ω   k  ,  l        ∏   j  ≠  k      (         i  j   +   r  j    -  1        i  j       )     (     1   σ  j  2     -   1   σ  k  2     )    -   (    r  j   +   i  j    )          ,       subscript  normal-Ψ   k  l  𝐫       superscript    1      subscript  r  k   1      subscript     𝐢   subscript  normal-Ω   k  l        subscript  product    j  k             subscript  i  j    subscript  r  j    1      subscript  i  j      superscript      1   subscript   superscript  σ  2   j      1   subscript   superscript  σ  2   k          subscript  r  j    subscript  i  j            \Psi_{k,l,\mathbf{r}}=(-1)^{r_{k}-1}\sum_{\mathbf{i}\in\Omega_{k,l}}\prod_{j%
 \neq k}\Big(\!\!\!\begin{array}[]{c}i_{j}+r_{j}-1\\
 i_{j}\end{array}\!\!\!\Big)\Big(\frac{1}{\sigma^{2}_{j}}\!-\!\frac{1}{\sigma^{%
 2}_{k}}\Big)^{-(r_{j}+i_{j})},     with    𝐢  =    [   i  1   ,  …  ,   i  M   ]   T       𝐢   superscript    subscript  i  1   normal-…   subscript  i  M    T     \mathbf{i}=[i_{1},\ldots,i_{M}]^{T}   from the set    Ω   k  ,  l      subscript  normal-Ω   k  l     \Omega_{k,l}   of all partitions of    l  -  1      l  1    l-1   (with     i  k   =  0       subscript  i  k   0    i_{k}=0   ) defined as       Ω   k  ,  l    =   {   [   i  1   ,  …  ,   i  m   ]   ∈   ℤ  m   ;   ∑   j  =  1   M     i  j    =  l  -  1  ,   i  k   =  0  ,   i  j   ≥   0   , for all  j  }   .     fragments   subscript  normal-Ω   k  l      fragments  normal-{   fragments  normal-[   subscript  i  1   normal-,  normal-…  normal-,   subscript  i  m   normal-]     superscript  ℤ  m   normal-;   superscript   subscript     j  1    M    subscript  i  j    l   1  normal-,   subscript  i  k    0  normal-,   subscript  i  j    0  , for all  j  normal-}   normal-.    \Omega_{k,l}=\Big\{[i_{1},\ldots,i_{m}]\in\mathbb{Z}^{m};\sum_{j=1}^{M}i_{j}\!%
 =l-1,i_{k}=0,i_{j}\geq 0\,\,\text{, for all }j\Big\}.     See also   Degrees of freedom (statistics)#Alternative   References    External links   Davies, R.B.: Fortran and C source code for "Linear combination of chi-squared random variables"   "  Category:Continuous distributions  Category:Probability distributions     Jones, D.A. (1983) "Statistical analysis of empirical models fitted by optimisation", Biometrika , 70 (1), 67–88 ↩   Sheil, J., O'Muircheartaigh, I. (1977) "Algorithm AS106: The distribution of non-negative quadratic forms in normal variables", Applied Statistics , 26, 92–98 ↩  Davies, R.B. (1973) Numerical inversion of a characteristic function. Biometrika , 60 (2), 415–417 ↩  Davies, R,B. (1980) "Algorithm AS155: The distribution of a linear combination of χ 2 random variables", Applied Statistics , 29, 323–333 ↩    D. Hammarwall, M. Bengtsson, B. Ottersten (2008) "Acquiring Partial CSI for Spatially Selective Transmission by Instantaneous Channel Norm Feedback",'' IEEE Transactions on Signal Processing'', 56, 1188-1204 ↩  E. Björnson, D. Hammarwall, B. Ottersten (2009) "Exploiting Quantized Channel Norm Feedback through Conditional Statistics in Arbitrarily Correlated MIMO Systems" , IEEE Transactions on Signal Processing , 57, 4027-4041 ↩     