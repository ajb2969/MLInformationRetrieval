   Stationary phase approximation      Stationary phase approximation   In mathematics , the stationary phase approximation is a basic principle of asymptotic analysis , applying to oscillatory integrals       I   (  k  )    =   ∫   g   (  x  )     e   i  k  f   (  x  )      d  x          I  k       g  x   superscript  e    i  k  f  x    d  x      I(k)=\int g(x)e^{ikf(x)}\,dx     taken over n -dimensional space ℝ n where i is the imaginary unit . Here f and g are real-valued smooth functions . The role of g is to ensure convergence; that is, g is a test function . The large real parameter k is considered in the limit as .  This method originates from the 19th century, and is due to George Gabriel Stokes and Lord Kelvin . 1  Basics  The main idea of stationary phase methods relies on the cancellation of sinusoids with rapidly varying phase. If many sinusoids have the same phase and they are added together, they will add constructively. If, however, these same sinusoids have phases which change rapidly as the frequency changes, they will add incoherently, varying between constructive and destructive addition at different times.  An example  Consider a function       f   (  x  ,  t  )    =    1   2  π      ∫  ℝ    F   (  ω  )     e   i   [    k   (  ω  )   x   -   ω  t    ]      d  ω           f   x  t        1    2  π      subscript   ℝ     F  ω   superscript  e    i   delimited-[]      k  ω  x     ω  t       d  ω       f(x,t)=\frac{1}{2\pi}\int_{\mathbb{R}}F(\omega)e^{i[k(\omega)x-\omega t]}\,d\omega   .  The phase term in this function, , is stationary when       d   d  ω       (  k   (  ω  )   x  -  ω  t  )     =  0     fragments    d    d  ω     fragments  absent   fragments  normal-(  k   fragments  normal-(  ω  normal-)   x   ω  t  normal-)   absent    0    \frac{d}{d\omega}\mathopen{}\left(k(\omega)x-\omega t\right)\mathclose{}=0     or equivalently,        d  k    d  ω    =   t  x           d  k     d  ω      t  x     \frac{dk}{d\omega}=\frac{t}{x}   .  Solutions to this equation yield dominant frequencies ω 0 for some x and t . If we expand ϕ as a Taylor series about ω 0 and neglect terms of order higher than ,      ϕ  =    [    k   (   ω  0   )   x   -    ω  0   t    ]   +    1  2   x   k  ′′    (   ω  0   )     (   ω  -   ω  0    )   2    +  ⋯       ϕ     delimited-[]      k   subscript  ω  0   x      subscript  ω  0   t         1  2   x   superscript  k  ′′    subscript  ω  0    superscript    ω   subscript  ω  0    2    normal-⋯     \phi=\left[k(\omega_{0})x-\omega_{0}t\right]+\frac{1}{2}xk^{\prime\prime}(%
 \omega_{0})(\omega-\omega_{0})^{2}+\cdots     where k ″ denotes the second derivative of k . When x is relatively large, even a small difference will generate rapid oscillations within the integral, leading to cancellation. Therefore we can extend the limits of integration beyond the limit for a Taylor expansion. If we double the real contribution from the positive frequencies of the transform to account for the negative frequencies,       f   (  x  ,  t  )    ≈     1   2  π    ⋅  2    Re   {    e   i   [    k   (   ω  0   )   x   -    ω  0   t    ]      |   F   (   ω  0   )    |     ∫  ℝ      e    1  2   i  x   k  ′′    (   ω  0   )     (   ω  -   ω  0    )   2      d  ω     }           f   x  t       normal-⋅    1    2  π    2    Re     superscript  e    i   delimited-[]      k   subscript  ω  0   x      subscript  ω  0   t           F   subscript  ω  0       subscript   ℝ      superscript  e      1  2   i  x   superscript  k  ′′    subscript  ω  0    superscript    ω   subscript  ω  0    2     d  ω         f(x,t)\approx\frac{1}{2\pi}\cdot 2\operatorname{Re}\left\{e^{i\left[k(\omega_{%
 0})x-\omega_{0}t\right]}\left|F(\omega_{0})\right|\int_{\mathbb{R}}e^{\frac{1}%
 {2}ixk^{\prime\prime}(\omega_{0})(\omega-\omega_{0})^{2}}\,d\omega\right\}   .  This integrates to       f   (  x  ,  t  )    ≈     |   F   (   ω  0   )    |   π      2  π    x   |    k  ′′    (   ω  0   )    |       cos   [     k   (   ω  0   )   x   -    ω  0   t    ±   π  4    ]           f   x  t            F   subscript  ω  0     π         2  π     x       superscript  k  ′′    subscript  ω  0           plus-or-minus      k   subscript  ω  0   x      subscript  ω  0   t      π  4        f(x,t)\approx\frac{\left|F(\omega_{0})\right|}{\pi}\sqrt{\frac{2\pi}{x\left|k^%
 {\prime\prime}(\omega_{0})\right|}}\cos\left[k(\omega_{0})x-\omega_{0}t\pm%
 \frac{\pi}{4}\right]   .  Reduction steps  The first major general statement of the principle involved is that the asymptotic behaviour of I ( k ) depends only on the critical points of f . If by choice of g the integral is localised to a region of space where f has no critical point, the resulting integral tends to 0 as the frequency of oscillations is taken to infinity. See for example Riemann-Lebesgue lemma .  The second statement is that when f is a Morse function , so that the singular points of f are non-degenerate and isolated, then the question can be reduced to the case n = 1. In fact, then, a choice of g can be made to split the integral into cases with just one critical point P in each. At that point, because the Hessian determinant at P is by assumption not 0, the Morse lemma applies. By a change of co-ordinates f may be replaced by       (    x  1  2   +   x  2  2   +  ⋯  +   x  j  2    )   -   (    x   j  +  1   2   +   x   j  +  2   2   +  ⋯  +   x  n  2    )          superscript   subscript  x  1   2    superscript   subscript  x  2   2   normal-⋯   superscript   subscript  x  j   2       superscript   subscript  x    j  1    2    superscript   subscript  x    j  2    2   normal-⋯   superscript   subscript  x  n   2      (x_{1}^{2}+x_{2}^{2}+\cdots+x_{j}^{2})-(x_{j+1}^{2}+x_{j+2}^{2}+\cdots+x_{n}^{%
 2})   .  The value of j is given by the signature of the Hessian matrix of f at P . As for g , the essential case is that g is a product of bump functions of x i . Assuming now without loss of generality that P is the origin, take a smooth bump function h with value 1 on the interval  and quickly tending to 0 outside it. Take       g   (  x  )    =    ∏  i    h   (   x  i   )           g  x     subscript  product  i     h   subscript  x  i       g(x)=\prod_{i}h(x_{i})   ,  then Fubini's theorem reduces I ( k ) to a product of integrals over the real line like       J   (  k  )    =   ∫   h   (  x  )     e   i  k  f   (  x  )      d  x          J  k       h  x   superscript  e    i  k  f  x    d  x      J(k)=\int h(x)e^{ikf(x)}\,dx     with f ( x ) = ± x 2 . The case with the minus sign is the complex conjugate of the case with the plus sign, so there is essentially one required asymptotic estimate.  In this way asymptotics can be found for oscillatory integrals for Morse functions. The degenerate case requires further techniques. See for example Airy function .  One-dimensional case  The essential statement is this one:       ∫   -  1   1     e   i  k   x  2      d  x  =    π  k     e    i  π   /  4    +  𝒪     (   1  k   )        fragments   superscript   subscript     1    1    superscript  e    i  k   superscript  x  2     d  x       π  k     superscript  e      i  π   4     O   fragments  absent   fragments  normal-(    1  k   normal-)   absent     \int_{-1}^{1}e^{ikx^{2}}\,dx=\sqrt{\frac{\pi}{k}}e^{i\pi/4}+\mathcal{O}%
 \mathopen{}\left(\frac{1}{k}\right)\mathclose{}   .  In fact by contour integration it can be shown that the main term on the right hand side of the equation is the value of the integral on the left hand side, extended over the range . Therefore it is the question of estimating away the integral over, say, . 2  This is the model for all one-dimensional integrals I ( k ) with f having a single non-degenerate critical point at which f has second derivative > 0. In fact the model case has second derivative 2 at 0. In order to scale using k , observe that replacing k by  where c is constant is the same as scaling x by √ c . It follows that for general values of , the factor  becomes        2  π    k   f  ′′    (  0  )             2  π     k   superscript  f  ′′   0      \sqrt{\frac{2\pi}{kf^{\prime\prime}(0)}}   .  For  one uses the complex conjugate formula, as mentioned before.  See also   Method of steepest descent  Common integrals in quantum field theory   References   Bleistein, N. and Handelsman, R. (1975), Asymptotic Expansions of Integrals , Dover, New York.  Victor Guillemin and Shlomo Sternberg (1990), Geometric Asymptotics , (see Chapter 1).   .  Aki, Keiiti; & Richards, Paul G. (2002). "Quantitative Seismology" (2nd ed.), pp 255–256. University Science Books, ISBN 0-935702-96-2  Wong, R. (2001), Asymptotic Approximations of Integrals , Classics in Applied Mathematics, Vol. 34. Corrected reprint of the 1989 original. Society for Industrial and Applied Mathematics (SIAM), Philadelphia, PA. xviii+543 pages, ISBN 0-89871-497-4.   Notes  External links     "  Category:Mathematical analysis  Category:Perturbation theory     ↩  See for example Jean Dieudonné , Infinitesimal Calculus , p. 119. ↩     