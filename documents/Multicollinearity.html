<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="733">Multicollinearity</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>Multicollinearity</h1>
<hr>In [[statistics]], '''multicollinearity''' (also '''collinearity'
<p>'') is a phenomenon in which two or more predictor <a href="Variable_(mathematics)" title="wikilink">variables</a> in a <a href="multiple_regression" title="wikilink">multiple regression</a> model are highly <a href="Correlation_and_dependence" title="wikilink">correlated</a>, meaning that one can be linearly predicted from the others with a non-trivial degree of accuracy. In this situation the <a href="Regression_coefficient" title="wikilink">coefficient estimates</a> of the multiple regression may change erratically in response to small changes in the model or the data. Multicollinearity does not reduce the predictive power or reliability of the model as a whole, at least within the sample data set; it only affects calculations regarding <a href="Dependent_and_independent_variables#Use_in_statistics" title="wikilink">individual predictors</a>. That is, a multiple regression model with correlated predictors can indicate how well the entire bundle of predictors predicts the <a href="Dependent_variable#Use_in_statistics" title="wikilink">outcome variable</a>, but it may not give valid results about any individual predictor, or about which predictors are redundant with respect to others.</p>

<p>In case of perfect multicollinearity the predictor matrix is <a href="Singular_matrix" title="wikilink">singular</a> and therefore cannot be <a href="matrix_inversion" title="wikilink">inverted</a>. Under these circumstances, for a general linear model 

<math display="inline" id="Multicollinearity:0">
 <semantics>
  <mrow>
   <mi>y</mi>
   <mo>=</mo>
   <mrow>
    <mrow>
     <mi>X</mi>
     <mi>β</mi>
    </mrow>
    <mo>+</mo>
    <mi>ϵ</mi>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <ci>y</ci>
    <apply>
     <plus></plus>
     <apply>
      <times></times>
      <ci>X</ci>
      <ci>β</ci>
     </apply>
     <ci>ϵ</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   y=X\beta+\epsilon
  </annotation>
 </semantics>
</math>

, the <a href="Ordinary_least_squares" title="wikilink">ordinary least-squares</a> estimator 

<math display="inline" id="Multicollinearity:1">
 <semantics>
  <mrow>
   <msub>
    <mover accent="true">
     <mi>β</mi>
     <mo stretchy="false">^</mo>
    </mover>
    <mrow>
     <mi>O</mi>
     <mi>L</mi>
     <mi>S</mi>
    </mrow>
   </msub>
   <mo>=</mo>
   <mrow>
    <msup>
     <mrow>
      <mo stretchy="false">(</mo>
      <mrow>
       <msup>
        <mi>X</mi>
        <mo>′</mo>
       </msup>
       <mi>X</mi>
      </mrow>
      <mo stretchy="false">)</mo>
     </mrow>
     <mrow>
      <mo>-</mo>
      <mn>1</mn>
     </mrow>
    </msup>
    <msup>
     <mi>X</mi>
     <mo>′</mo>
    </msup>
    <mi>y</mi>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <apply>
      <ci>normal-^</ci>
      <ci>β</ci>
     </apply>
     <apply>
      <times></times>
      <ci>O</ci>
      <ci>L</ci>
      <ci>S</ci>
     </apply>
    </apply>
    <apply>
     <times></times>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <apply>
       <times></times>
       <apply>
        <csymbol cd="ambiguous">superscript</csymbol>
        <ci>X</ci>
        <ci>normal-′</ci>
       </apply>
       <ci>X</ci>
      </apply>
      <apply>
       <minus></minus>
       <cn type="integer">1</cn>
      </apply>
     </apply>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <ci>X</ci>
      <ci>normal-′</ci>
     </apply>
     <ci>y</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \hat{\beta}_{OLS}=(X^{\prime}X)^{-1}X^{\prime}y
  </annotation>
 </semantics>
</math>

 does not exist.</p>

<p>Note that in statements of the assumptions underlying regression analyses such as ordinary least squares, the phrase "no multicollinearity" is sometimes used to mean the absence of perfect multicollinearity, which is an exact (non-stochastic) linear relation among the <a href="Explanatory_variable#Independent_variable" title="wikilink">regressors</a>.</p>
<h2 id="definition">Definition</h2>

<p><strong>Collinearity</strong> is a linear association between <em>two</em> <a href="explanatory_variable" title="wikilink">explanatory variables</a>. Two variables are perfectly collinear if there is an exact linear relationship between them. For example, 

<math display="inline" id="Multicollinearity:2">
 <semantics>
  <msub>
   <mi>X</mi>
   <mn>1</mn>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>X</ci>
    <cn type="integer">1</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   X_{1}
  </annotation>
 </semantics>
</math>

 and 

<math display="inline" id="Multicollinearity:3">
 <semantics>
  <msub>
   <mi>X</mi>
   <mn>2</mn>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>X</ci>
    <cn type="integer">2</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   X_{2}
  </annotation>
 </semantics>
</math>


 are perfectly collinear if there exist parameters 

<math display="inline" id="Multicollinearity:4">
 <semantics>
  <msub>
   <mi>λ</mi>
   <mn>0</mn>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>λ</ci>
    <cn type="integer">0</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \lambda_{0}
  </annotation>
 </semantics>
</math>

 and 

<math display="inline" id="Multicollinearity:5">
 <semantics>
  <msub>
   <mi>λ</mi>
   <mn>1</mn>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>λ</ci>
    <cn type="integer">1</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \lambda_{1}
  </annotation>
 </semantics>
</math>

 such that, for all observations <em>i</em>, we have</p>

<p>

<math display="block" id="Multicollinearity:6">
 <semantics>
  <mrow>
   <mrow>
    <msub>
     <mi>X</mi>
     <mrow>
      <mn>2</mn>
      <mi>i</mi>
     </mrow>
    </msub>
    <mo>=</mo>
    <mrow>
     <msub>
      <mi>λ</mi>
      <mn>0</mn>
     </msub>
     <mo>+</mo>
     <mrow>
      <msub>
       <mi>λ</mi>
       <mn>1</mn>
      </msub>
      <msub>
       <mi>X</mi>
       <mrow>
        <mn>1</mn>
        <mi>i</mi>
       </mrow>
      </msub>
     </mrow>
    </mrow>
   </mrow>
   <mo>.</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>X</ci>
     <apply>
      <times></times>
      <cn type="integer">2</cn>
      <ci>i</ci>
     </apply>
    </apply>
    <apply>
     <plus></plus>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>λ</ci>
      <cn type="integer">0</cn>
     </apply>
     <apply>
      <times></times>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>λ</ci>
       <cn type="integer">1</cn>
      </apply>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>X</ci>
       <apply>
        <times></times>
        <cn type="integer">1</cn>
        <ci>i</ci>
       </apply>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   X_{2i}=\lambda_{0}+\lambda_{1}X_{1i}.
  </annotation>
 </semantics>
</math>

</p>

<p><strong>Multicollinearity</strong> refers to a situation in which two or more explanatory variables in a <a href="multiple_regression" title="wikilink">multiple regression</a> model are highly linearly related. We have perfect multicollinearity if, for example as in the equation above, the correlation between two independent variables is equal to 1 or -1. In practice, we rarely face perfect multicollinearity in a data set. More commonly, the issue of multicollinearity arises when there is an approximate linear relationship among two or more independent variables.</p>

<p>Mathematically, a set of variables is perfectly multicollinear if there exist one or more exact linear relationships among some of the variables. For example, we may have</p>

<p>

<math display="block" id="Multicollinearity:7">
 <semantics>
  <mrow>
   <mrow>
    <msub>
     <mi>λ</mi>
     <mn>0</mn>
    </msub>
    <mo>+</mo>
    <mrow>
     <msub>
      <mi>λ</mi>
      <mn>1</mn>
     </msub>
     <msub>
      <mi>X</mi>
      <mrow>
       <mn>1</mn>
       <mi>i</mi>
      </mrow>
     </msub>
    </mrow>
    <mo>+</mo>
    <mrow>
     <msub>
      <mi>λ</mi>
      <mn>2</mn>
     </msub>
     <msub>
      <mi>X</mi>
      <mrow>
       <mn>2</mn>
       <mi>i</mi>
      </mrow>
     </msub>
    </mrow>
    <mo>+</mo>
    <mi mathvariant="normal">⋯</mi>
    <mo>+</mo>
    <mrow>
     <msub>
      <mi>λ</mi>
      <mi>k</mi>
     </msub>
     <msub>
      <mi>X</mi>
      <mrow>
       <mi>k</mi>
       <mi>i</mi>
      </mrow>
     </msub>
    </mrow>
   </mrow>
   <mo>=</mo>
   <mn>0</mn>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <plus></plus>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>λ</ci>
      <cn type="integer">0</cn>
     </apply>
     <apply>
      <times></times>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>λ</ci>
       <cn type="integer">1</cn>
      </apply>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>X</ci>
       <apply>
        <times></times>
        <cn type="integer">1</cn>
        <ci>i</ci>
       </apply>
      </apply>
     </apply>
     <apply>
      <times></times>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>λ</ci>
       <cn type="integer">2</cn>
      </apply>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>X</ci>
       <apply>
        <times></times>
        <cn type="integer">2</cn>
        <ci>i</ci>
       </apply>
      </apply>
     </apply>
     <ci>normal-⋯</ci>
     <apply>
      <times></times>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>λ</ci>
       <ci>k</ci>
      </apply>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>X</ci>
       <apply>
        <times></times>
        <ci>k</ci>
        <ci>i</ci>
       </apply>
      </apply>
     </apply>
    </apply>
    <cn type="integer">0</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \lambda_{0}+\lambda_{1}X_{1i}+\lambda_{2}X_{2i}+\cdots+\lambda_{k}X_{ki}=0
  </annotation>
 </semantics>
</math>

</p>

<p>holding for all observations <em>i</em>, where 

<math display="inline" id="Multicollinearity:8">
 <semantics>
  <msub>
   <mi>λ</mi>
   <mi>j</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>λ</ci>
    <ci>j</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \lambda_{j}
  </annotation>
 </semantics>
</math>


 are constants and 

<math display="inline" id="Multicollinearity:9">
 <semantics>
  <msub>
   <mi>X</mi>
   <mrow>
    <mi>j</mi>
    <mi>i</mi>
   </mrow>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>X</ci>
    <apply>
     <times></times>
     <ci>j</ci>
     <ci>i</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   X_{ji}
  </annotation>
 </semantics>
</math>

 is the <em>i</em><sup>th</sup> observation on the <em>j</em><sup>th</sup> explanatory variable. We can explore one issue caused by multicollinearity by examining the process of attempting to obtain estimates for the parameters of the multiple regression equation</p>

<p>

<math display="block" id="Multicollinearity:10">
 <semantics>
  <mrow>
   <mrow>
    <msub>
     <mi>Y</mi>
     <mi>i</mi>
    </msub>
    <mo>=</mo>
    <mrow>
     <msub>
      <mi>β</mi>
      <mn>0</mn>
     </msub>
     <mo>+</mo>
     <mrow>
      <msub>
       <mi>β</mi>
       <mn>1</mn>
      </msub>
      <msub>
       <mi>X</mi>
       <mrow>
        <mn>1</mn>
        <mi>i</mi>
       </mrow>
      </msub>
     </mrow>
     <mo>+</mo>
     <mi mathvariant="normal">⋯</mi>
     <mo>+</mo>
     <mrow>
      <msub>
       <mi>β</mi>
       <mi>k</mi>
      </msub>
      <msub>
       <mi>X</mi>
       <mrow>
        <mi>k</mi>
        <mi>i</mi>
       </mrow>
      </msub>
     </mrow>
     <mo>+</mo>
     <msub>
      <mi>ε</mi>
      <mi>i</mi>
     </msub>
    </mrow>
   </mrow>
   <mo>.</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>Y</ci>
     <ci>i</ci>
    </apply>
    <apply>
     <plus></plus>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>β</ci>
      <cn type="integer">0</cn>
     </apply>
     <apply>
      <times></times>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>β</ci>
       <cn type="integer">1</cn>
      </apply>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>X</ci>
       <apply>
        <times></times>
        <cn type="integer">1</cn>
        <ci>i</ci>
       </apply>
      </apply>
     </apply>
     <ci>normal-⋯</ci>
     <apply>
      <times></times>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>β</ci>
       <ci>k</ci>
      </apply>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>X</ci>
       <apply>
        <times></times>
        <ci>k</ci>
        <ci>i</ci>
       </apply>
      </apply>
     </apply>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>ε</ci>
      <ci>i</ci>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   Y_{i}=\beta_{0}+\beta_{1}X_{1i}+\cdots+\beta_{k}X_{ki}+\varepsilon_{i}.
  </annotation>
 </semantics>
</math>

</p>

<p>The <a href="ordinary_least_squares" title="wikilink">ordinary least squares</a> estimates involve inverting the matrix</p>

<p>

<math display="block" id="Multicollinearity:11">
 <semantics>
  <mrow>
   <msup>
    <mi>X</mi>
    <mi>T</mi>
   </msup>
   <mi>X</mi>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <apply>
     <csymbol cd="ambiguous">superscript</csymbol>
     <ci>X</ci>
     <ci>T</ci>
    </apply>
    <ci>X</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   X^{T}X
  </annotation>
 </semantics>
</math>

</p>

<p>where</p>

<p>

<math display="block" id="Multicollinearity:12">
 <semantics>
  <mrow>
   <mrow>
    <mi>X</mi>
    <mo>=</mo>
    <mrow>
     <mo>[</mo>
     <mtable displaystyle="true">
      <mtr>
       <mtd columnalign="center">
        <mn>1</mn>
       </mtd>
       <mtd columnalign="center">
        <msub>
         <mi>X</mi>
         <mn>11</mn>
        </msub>
       </mtd>
       <mtd columnalign="center">
        <mi mathvariant="normal">⋯</mi>
       </mtd>
       <mtd columnalign="center">
        <msub>
         <mi>X</mi>
         <mrow>
          <mi>k</mi>
          <mn>1</mn>
         </mrow>
        </msub>
       </mtd>
      </mtr>
      <mtr>
       <mtd columnalign="center">
        <mi mathvariant="normal">⋮</mi>
       </mtd>
       <mtd columnalign="center">
        <mi mathvariant="normal">⋮</mi>
       </mtd>
       <mtd columnalign="center">
        <mi></mi>
       </mtd>
       <mtd columnalign="center">
        <mi mathvariant="normal">⋮</mi>
       </mtd>
      </mtr>
      <mtr>
       <mtd columnalign="center">
        <mn>1</mn>
       </mtd>
       <mtd columnalign="center">
        <msub>
         <mi>X</mi>
         <mrow>
          <mn>1</mn>
          <mi>N</mi>
         </mrow>
        </msub>
       </mtd>
       <mtd columnalign="center">
        <mi mathvariant="normal">⋯</mi>
       </mtd>
       <mtd columnalign="center">
        <msub>
         <mi>X</mi>
         <mrow>
          <mi>k</mi>
          <mi>N</mi>
         </mrow>
        </msub>
       </mtd>
      </mtr>
     </mtable>
     <mo>]</mo>
    </mrow>
   </mrow>
   <mo>.</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <ci>X</ci>
    <matrix>
     <matrixrow>
      <cn type="integer">1</cn>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>X</ci>
       <cn type="integer">11</cn>
      </apply>
      <ci>normal-⋯</ci>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>X</ci>
       <apply>
        <times></times>
        <ci>k</ci>
        <cn type="integer">1</cn>
       </apply>
      </apply>
     </matrixrow>
     <matrixrow>
      <ci>normal-⋮</ci>
      <ci>normal-⋮</ci>
      <csymbol cd="latexml">absent</csymbol>
      <ci>normal-⋮</ci>
     </matrixrow>
     <matrixrow>
      <cn type="integer">1</cn>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>X</ci>
       <apply>
        <times></times>
        <cn type="integer">1</cn>
        <ci>N</ci>
       </apply>
      </apply>
      <ci>normal-⋯</ci>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>X</ci>
       <apply>
        <times></times>
        <ci>k</ci>
        <ci>N</ci>
       </apply>
      </apply>
     </matrixrow>
    </matrix>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   X=\begin{bmatrix}\par
 1&X_{11}&\cdots&X_{k1}\\
\par
\vdots&\vdots&&\vdots\\
\par
 1&X_{1N}&\cdots&X_{kN}\par
\end{bmatrix}.
  </annotation>
 </semantics>
</math>

</p>

<p>If there is an exact linear relationship (perfect multicollinearity) among the independent variables, the <a href="Rank_(linear_algebra)" title="wikilink">rank</a> of X (and therefore of X<sup>T</sup>X) is less than k+1, and the matrix X<sup>T</sup>X will not be invertible.</p>

<p>Perfect multicollinearity is fairly common when working with raw datasets, which frequently contain redundant information. Once redundancies are identified and removed, however, nearly multicollinear variables often remain due to correlations inherent in the system being studied. In such a case, instead of the above equation holding, we have that equation in modified form with an error term 

<math display="inline" id="Multicollinearity:13">
 <semantics>
  <msub>
   <mi>v</mi>
   <mi>i</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>v</ci>
    <ci>i</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   v_{i}
  </annotation>
 </semantics>
</math>

:</p>

<p>

<math display="block" id="Multicollinearity:14">
 <semantics>
  <mrow>
   <mrow>
    <msub>
     <mi>λ</mi>
     <mn>0</mn>
    </msub>
    <mo>+</mo>
    <mrow>
     <msub>
      <mi>λ</mi>
      <mn>1</mn>
     </msub>
     <msub>
      <mi>X</mi>
      <mrow>
       <mn>1</mn>
       <mi>i</mi>
      </mrow>
     </msub>
    </mrow>
    <mo>+</mo>
    <mrow>
     <msub>
      <mi>λ</mi>
      <mn>2</mn>
     </msub>
     <msub>
      <mi>X</mi>
      <mrow>
       <mn>2</mn>
       <mi>i</mi>
      </mrow>
     </msub>
    </mrow>
    <mo>+</mo>
    <mi mathvariant="normal">⋯</mi>
    <mo>+</mo>
    <mrow>
     <msub>
      <mi>λ</mi>
      <mi>k</mi>
     </msub>
     <msub>
      <mi>X</mi>
      <mrow>
       <mi>k</mi>
       <mi>i</mi>
      </mrow>
     </msub>
    </mrow>
    <mo>+</mo>
    <msub>
     <mi>v</mi>
     <mi>i</mi>
    </msub>
   </mrow>
   <mo>=</mo>
   <mn>0.</mn>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <plus></plus>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>λ</ci>
      <cn type="integer">0</cn>
     </apply>
     <apply>
      <times></times>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>λ</ci>
       <cn type="integer">1</cn>
      </apply>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>X</ci>
       <apply>
        <times></times>
        <cn type="integer">1</cn>
        <ci>i</ci>
       </apply>
      </apply>
     </apply>
     <apply>
      <times></times>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>λ</ci>
       <cn type="integer">2</cn>
      </apply>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>X</ci>
       <apply>
        <times></times>
        <cn type="integer">2</cn>
        <ci>i</ci>
       </apply>
      </apply>
     </apply>
     <ci>normal-⋯</ci>
     <apply>
      <times></times>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>λ</ci>
       <ci>k</ci>
      </apply>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>X</ci>
       <apply>
        <times></times>
        <ci>k</ci>
        <ci>i</ci>
       </apply>
      </apply>
     </apply>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>v</ci>
      <ci>i</ci>
     </apply>
    </apply>
    <cn type="float">0.</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \lambda_{0}+\lambda_{1}X_{1i}+\lambda_{2}X_{2i}+\cdots+\lambda_{k}X_{ki}+v_{i}%
=0.
  </annotation>
 </semantics>
</math>

</p>

<p>In this case, there is no exact linear relationship among the variables, but the 

<math display="inline" id="Multicollinearity:15">
 <semantics>
  <msub>
   <mi>X</mi>
   <mi>j</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>X</ci>
    <ci>j</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   X_{j}
  </annotation>
 </semantics>
</math>

 variables are nearly perfectly multicollinear if the variance of 

<math display="inline" id="Multicollinearity:16">
 <semantics>
  <msub>
   <mi>v</mi>
   <mi>i</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>v</ci>
    <ci>i</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   v_{i}
  </annotation>
 </semantics>
</math>

 is small for some set of values for the 

<math display="inline" id="Multicollinearity:17">
 <semantics>
  <mi>λ</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>λ</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \lambda
  </annotation>
 </semantics>
</math>

's. In this case, the matrix X<sup>T</sup>X has an inverse, but is ill-conditioned so that a given computer algorithm may or may not be able to compute an approximate inverse, and if it does so the resulting computed inverse may be highly sensitive to slight variations in the data (due to magnified effects of rounding error) and so may be very inaccurate.</p>
<h2 id="detection-of-multicollinearity">Detection of multicollinearity</h2>

<p>Indicators that multicollinearity may be present in a model:</p>
<ol>
<li>Large changes in the estimated regression coefficients when a predictor variable is added or deleted</li>
<li>Insignificant regression coefficients for the affected variables in the multiple regression, but a rejection of the joint hypothesis that those coefficients are all zero (using an <a href="F-test" title="wikilink"><em>F</em>-test</a>)</li>
<li>If a multivariable regression finds an insignificant coefficient of a particular explanator, yet a <a href="simple_linear_regression" title="wikilink">simple linear regression</a> of the explained variable on this explanatory variable shows its coefficient to be significantly different from zero, this situation indicates multicollinearity in the multivariable regression.</li>
<li>Some authors have suggested a formal detection-tolerance or the <a href="variance_inflation_factor" title="wikilink">variance inflation factor</a> (VIF) for multicollinearity:<br/>


<math display="inline" id="Multicollinearity:18">
 <semantics>
  <mrow>
   <mrow>
    <mrow>
     <mi>tolerance</mi>
     <mo>=</mo>
     <mrow>
      <mn>1</mn>
      <mo>-</mo>
      <msubsup>
       <mi>R</mi>
       <mi>j</mi>
       <mn>2</mn>
      </msubsup>
     </mrow>
    </mrow>
    <mo rspace="12.5pt">,</mo>
    <mrow>
     <mi>VIF</mi>
     <mo>=</mo>
     <mfrac>
      <mn>1</mn>
      <mi>tolerance</mi>
     </mfrac>
    </mrow>
   </mrow>
   <mo>,</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">formulae-sequence</csymbol>
    <apply>
     <eq></eq>
     <ci>tolerance</ci>
     <apply>
      <minus></minus>
      <cn type="integer">1</cn>
      <apply>
       <csymbol cd="ambiguous">superscript</csymbol>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <ci>R</ci>
        <ci>j</ci>
       </apply>
       <cn type="integer">2</cn>
      </apply>
     </apply>
    </apply>
    <apply>
     <eq></eq>
     <ci>VIF</ci>
     <apply>
      <divide></divide>
      <cn type="integer">1</cn>
      <ci>tolerance</ci>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \mathrm{tolerance}=1-R_{j}^{2},\quad\mathrm{VIF}=\frac{1}{\mathrm{tolerance}},
  </annotation>
 </semantics>
</math>

<br/>
where 

<math display="inline" id="Multicollinearity:19">
 <semantics>
  <msubsup>
   <mi>R</mi>
   <mi>j</mi>
   <mn>2</mn>
  </msubsup>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">superscript</csymbol>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>R</ci>
     <ci>j</ci>
    </apply>
    <cn type="integer">2</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   R_{j}^{2}
  </annotation>
 </semantics>
</math>

 is the coefficient of determination of a regression of explanator <em>j</em> on all the other explanators. A tolerance of less than 0.20 or 0.10 and/or a VIF of 5 or 10 and above indicates a multicollinearity problem.<a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a></li>
<li><strong>Condition number test</strong>: The standard measure of <a href="Condition_number" title="wikilink">ill-conditioning</a> in a matrix is the condition index. It will indicate that the inversion of the matrix is numerically unstable with finite-precision numbers (standard computer floats and doubles). This indicates the potential sensitivity of the computed inverse to small changes in the original matrix. The Condition Number is computed by finding the square root of (the maximum eigenvalue divided by the minimum eigenvalue). If the Condition Number is above 30, the regression may have significant multicollinearity; multicollinearity exists if, in addition, two or more of the variables related to the high condition number have high proportions of variance explained. One advantage of this method is that it also shows which variables are causing the problem.<a class="footnoteRef" href="#fn2" id="fnref2"><sup>2</sup></a></li>
<li><strong>Farrar–Glauber test</strong>:<a class="footnoteRef" href="#fn3" id="fnref3"><sup>3</sup></a> If the variables are found to be orthogonal, there is no multicollinearity; if the variables are not orthogonal, then multicollinearity is present. C. Robert Wichers has argued that Farrar–Glauber partial correlation test is ineffective in that a given partial correlation may be compatible with different multicollinearity patterns.<a class="footnoteRef" href="#fn4" id="fnref4"><sup>4</sup></a> The Farrar–Glauber test has also been criticized by other researchers.<a class="footnoteRef" href="#fn5" id="fnref5"><sup>5</sup></a><a class="footnoteRef" href="#fn6" id="fnref6"><sup>6</sup></a></li>
<li><strong>Perturbing the data</strong>.<a class="footnoteRef" href="#fn7" id="fnref7"><sup>7</sup></a> Multicollinearity can be detected by adding random noise to the data and re-running the regression many times and seeing how much the coefficients change.</li>
<li>Construction of a correlation matrix among the explanatory variables will yield indications as to the likelihood that any given couplet of right-hand-side variables are creating multicollinearity problems. Correlation values (off-diagonal elements) of at least .4 are sometimes interpreted as indicating a multicollinearity problem. This procedure is, however, highly problematic and cannot be recommended. Intuitively, correlation describes a bivariate relationship, whereas collinearity is a multivariate phenomenon.</li>
</ol>
<h2 id="consequences-of-multicollinearity">Consequences of multicollinearity</h2>

<p>One consequence of a high degree of multicollinearity is that, even if the matrix X<sup>T</sup>X is invertible, a computer algorithm may be unsuccessful in obtaining an approximate inverse, and if it does obtain one it may be numerically inaccurate. But even in the presence of an accurate X<sup>T</sup>X matrix, the following consequences arise.</p>

<p>In the presence of multicollinearity, the estimate of one variable's impact on the dependent variable 

<math display="inline" id="Multicollinearity:20">
 <semantics>
  <mi>Y</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>Y</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   Y
  </annotation>
 </semantics>
</math>

 while controlling for the others tends to be less precise than if predictors were uncorrelated with one another. The usual interpretation of a regression coefficient is that it provides an estimate of the effect of a one unit change in an independent variable, 

<math display="inline" id="Multicollinearity:21">
 <semantics>
  <msub>
   <mi>X</mi>
   <mn>1</mn>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>X</ci>
    <cn type="integer">1</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   X_{1}
  </annotation>
 </semantics>
</math>

, holding the other variables constant. If 

<math display="inline" id="Multicollinearity:22">
 <semantics>
  <msub>
   <mi>X</mi>
   <mn>1</mn>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>X</ci>
    <cn type="integer">1</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   X_{1}
  </annotation>
 </semantics>
</math>

 is highly correlated with another independent variable, 

<math display="inline" id="Multicollinearity:23">
 <semantics>
  <msub>
   <mi>X</mi>
   <mn>2</mn>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>X</ci>
    <cn type="integer">2</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   X_{2}
  </annotation>
 </semantics>
</math>

, in the given data set, then we have a set of observations for which 

<math display="inline" id="Multicollinearity:24">
 <semantics>
  <msub>
   <mi>X</mi>
   <mn>1</mn>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>X</ci>
    <cn type="integer">1</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   X_{1}
  </annotation>
 </semantics>
</math>

 and 

<math display="inline" id="Multicollinearity:25">
 <semantics>
  <msub>
   <mi>X</mi>
   <mn>2</mn>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>X</ci>
    <cn type="integer">2</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   X_{2}
  </annotation>
 </semantics>
</math>

 have a particular linear stochastic relationship. We don't have a set of observations for which all changes in 

<math display="inline" id="Multicollinearity:26">
 <semantics>
  <msub>
   <mi>X</mi>
   <mn>1</mn>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>X</ci>
    <cn type="integer">1</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   X_{1}
  </annotation>
 </semantics>
</math>

 are independent of changes in 

<math display="inline" id="Multicollinearity:27">
 <semantics>
  <msub>
   <mi>X</mi>
   <mn>2</mn>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>X</ci>
    <cn type="integer">2</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   X_{2}
  </annotation>
 </semantics>
</math>

, so we have an imprecise estimate of the effect of independent changes in 

<math display="inline" id="Multicollinearity:28">
 <semantics>
  <msub>
   <mi>X</mi>
   <mn>1</mn>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>X</ci>
    <cn type="integer">1</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   X_{1}
  </annotation>
 </semantics>
</math>

.</p>

<p>In some sense, the collinear variables contain the same information about the dependent variable. If nominally "different" measures actually quantify the same phenomenon then they are redundant. Alternatively, if the variables are accorded different names and perhaps employ different numeric measurement scales but are highly correlated with each other, then they suffer from redundancy.</p>

<p>One of the features of multicollinearity is that the standard errors of the affected coefficients tend to be large. In that case, the test of the hypothesis that the coefficient is equal to zero may lead to a failure to reject a false null hypothesis of no effect of the explanator, a <a href="type_II_error" title="wikilink">type II error</a>.</p>

<p>Another issue with multicollinearity is that small changes to the input data can lead to large changes in the model, even resulting in changes of sign of parameter estimates.<a class="footnoteRef" href="#fn8" id="fnref8"><sup>8</sup></a></p>

<p>A principal danger of such data redundancy is that of <a class="uri" href="overfitting" title="wikilink">overfitting</a> in <a href="regression_analysis" title="wikilink">regression analysis</a> models. The best regression models are those in which the predictor variables each correlate highly with the dependent (outcome) variable but correlate at most only minimally with each other. Such a model is often called "low noise" and will be statistically robust (that is, it will predict reliably across numerous samples of variable sets drawn from the same statistical population).</p>

<p>So long as the underlying specification is correct, multicollinearity does not actually bias results; it just produces large <a href="Standard_error_(statistics)" title="wikilink">standard errors</a> in the related independent variables. More importantly, the usual use of regression is to take coefficients from the model and then apply them to other data. If the pattern of multicollinearity in the new data differs from that in the data that was fitted, such extrapolation may introduce large errors in the predictions.<a class="footnoteRef" href="#fn9" id="fnref9"><sup>9</sup></a></p>
<h2 id="remedies-for-multicollinearity">Remedies for multicollinearity</h2>
<ol>
<li>Make sure you have not fallen into the <a href="Dummy_variable_(statistics)" title="wikilink">dummy variable</a> trap; including a dummy variable for every category (e.g., summer, autumn, winter, and spring) and including a constant term in the regression together guarantee perfect multicollinearity.</li>
<li>Try seeing what happens if you use independent subsets of your data for estimation and apply those estimates to the whole data set. Theoretically you should obtain somewhat higher variance from the smaller datasets used for estimation, but the expectation of the coefficient values should be the same. Naturally, the observed coefficient values will vary, but look at how much they vary.</li>
<li>Leave the model as is, despite multicollinearity. The presence of multicollinearity doesn't affect the efficacy of extrapolating the fitted model to new data provided that the predictor variables follow the same pattern of multicollinearity in the new data as in the data on which the regression model is based.<a class="footnoteRef" href="#fn10" id="fnref10"><sup>10</sup></a></li>
<li>Drop one of the variables. An explanatory variable may be dropped to produce a model with significant coefficients. However, you lose information (because you've dropped a variable). Omission of a relevant variable results in biased coefficient estimates for the remaining explanatory variables that are correlated with the dropped variable.</li>
<li>Obtain more data, if possible. This is the preferred solution. More data can produce more precise parameter estimates (with lower standard errors), as seen from the formula in <a href="variance_inflation_factor" title="wikilink">variance inflation factor</a> for the variance of the estimate of a regression coefficient in terms of the sample size and the degree of multicollinearity.</li>
<li>Mean-center the predictor variables. Generating polynomial terms (i.e., for 

<math display="inline" id="Multicollinearity:29">
 <semantics>
  <msub>
   <mi>x</mi>
   <mn>1</mn>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>x</ci>
    <cn type="integer">1</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   x_{1}
  </annotation>
 </semantics>
</math>

, 

<math display="inline" id="Multicollinearity:30">
 <semantics>
  <msubsup>
   <mi>x</mi>
   <mn>1</mn>
   <mn>2</mn>
  </msubsup>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">superscript</csymbol>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>x</ci>
     <cn type="integer">1</cn>
    </apply>
    <cn type="integer">2</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   x_{1}^{2}
  </annotation>
 </semantics>
</math>

, 

<math display="inline" id="Multicollinearity:31">
 <semantics>
  <msubsup>
   <mi>x</mi>
   <mn>1</mn>
   <mn>3</mn>
  </msubsup>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">superscript</csymbol>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>x</ci>
     <cn type="integer">1</cn>
    </apply>
    <cn type="integer">3</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   x_{1}^{3}
  </annotation>
 </semantics>
</math>

, etc.) can cause some multicollinearity if the variable in question has a limited range (e.g., [2,4]). Mean-centering will eliminate this special kind of multicollinearity. However, in general, this has no effect. It can be useful in overcoming problems arising from rounding and other computational steps if a carefully designed computer program is not used.</li>
<li>Standardize your independent variables. This may help reduce a false flagging of a condition index above 30.</li>
<li>It has also been suggested that using the <a href="Shapley_value" title="wikilink">Shapley value</a>, a game theory tool, the model could account for the effects of multicollinearity. The Shapley value assigns a value for each predictor and assesses all possible combinations of importance.<a class="footnoteRef" href="#fn11" id="fnref11"><sup>11</sup></a></li>
<li><a href="Ridge_regression" title="wikilink">Ridge regression</a> or <a href="principal_component_regression" title="wikilink">principal component regression</a> or <a href="partial_least_squares_regression" title="wikilink">partial least squares regression</a> can be used.</li>
<li>If the correlated explanators are different lagged values of the same underlying explanator, then a <a href="distributed_lag" title="wikilink">distributed lag</a> technique can be used, imposing a general structure on the relative values of the coefficients to be estimated.</li>
</ol>

<p>Note that one technique that does not work in offsetting the effects of multicollinearity is <a href="orthogonality" title="wikilink">orthogonalizing</a> the explanatory variables (linearly transforming them so that the transformed variables are uncorrelated with each other): By the <a href="Frisch–Waugh–Lovell_theorem" title="wikilink">Frisch–Waugh–Lovell theorem</a>, using projection matrices to make the explanatory variables orthogonal to each other will lead to the same results as running the regression with all non-orthogonal explanators included.</p>
<h2 id="examples-of-contexts-in-which-multicollinearity-arises">Examples of contexts in which multicollinearity arises</h2>
<h3 id="survival-analysis">Survival analysis</h3>

<p>Multicollinearity may represent a serious issue in <a href="survival_analysis" title="wikilink">survival analysis</a>. The problem is that time-varying covariates may change their value over the time line of the study. A special procedure is recommended to assess the impact of multicollinearity on the results.<a class="footnoteRef" href="#fn12" id="fnref12"><sup>12</sup></a></p>
<h3 id="interest-rates-for-different-terms-to-maturity">Interest rates for different terms to maturity</h3>

<p>In various situations it might be hypothesized that multiple interest rates of various terms to maturity all influence some economic decision, such as the amount of money or some other financial asset to hold, or the amount of fixed investment spending to engage in. In this case, including these various interest rates will in general create a substantial multicollinearity problem because interest rates tend to move together. If in fact each of the interest rates has its own separate effect on the dependent variable, it can be extremely difficult to separate out their effects.</p>
<h2 id="extension">Extension</h2>

<p>The concept of <em>lateral collinearity</em> expands on the traditional view of multicollinearity, comprising also collinearity between explanatory and criteria (i.e., explained) variables, in the sense that they may be measuring almost the same thing as each other.<a class="footnoteRef" href="#fn13" id="fnref13"><sup>13</sup></a></p>
<h2 id="see-also">See also</h2>
<ul>
<li><a href="Linear_independence" title="wikilink">Linear independence</a></li>
</ul>
<h2 id="references">References</h2>
<h2 id="further-reading">Further reading</h2>
<ul>
<li></li>
<li></li>
<li></li>
<li></li>
<li></li>
</ul>
<h2 id="external-links">External links</h2>
<ul>
<li>

<p>by <a href="Mark_Thoma" title="wikilink">Mark Thoma</a></p></li>
<li><a href="http://jeff560.tripod.com/m.html">Earliest Uses: The entry on Multicollinearity has some historical information.</a></li>
</ul>

<p>"</p>

<p><a href="Category:Regression_analysis" title="wikilink">Category:Regression analysis</a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1"><a href="#fnref1">↩</a></li>
<li id="fn2"><a href="#fnref2">↩</a></li>
<li id="fn3"><a href="#fnref3">↩</a></li>
<li id="fn4"><a href="#fnref4">↩</a></li>
<li id="fn5"><a href="#fnref5">↩</a></li>
<li id="fn6"><a href="#fnref6">↩</a></li>
<li id="fn7">A package for <a href="R_(programming_language)" title="wikilink">R</a> is available: <a href="#fnref7">↩</a></li>
<li id="fn8"></li>
<li id="fn9"><a href="#fnref9">↩</a></li>
<li id="fn10"><a href="#fnref10">↩</a></li>
<li id="fn11"><a href="#fnref11">↩</a></li>
<li id="fn12">For a detailed discussion, see <a href="#fnref12">↩</a></li>
<li id="fn13"><a href="#fnref13">↩</a></li>
</ol>
</section>
</hr></body>
</html>
