   Contextual image classification      Contextual image classification   Contextual image classification , a topic of pattern recognition in computer vision , is an approach of classification based on contextual information in images. "Contextual" means this approach is focusing on the relationship of the nearby pixels, which is also called neighbourhood. The goal of this approach is to classify the images by using the contextual information.  Introduction  Similar as processing language , a single word may have multiple meanings unless the context is provided, and the patterns within the sentences are the only informative segments we care about. For images, the principle is same. Find out the patterns and associate proper meanings to them.  As the image illustrated below, if only a small portion of the image is shown, it is very difficult to tell what the image is about.  Even try another portion of the image, it is still difficult to classify the image.  However, if we increase the contextual of the image, then it makes more sense to recognize.  As the full images shows below, almost everyone can classify it easily.  During the procedure of segmentation , the methods which do not use the contextual information are sensitive to noise and variations, thus the result of segmentation will contain a great deal of misclassified regions, and often these regions are small (e.g., one pixel).  Compared to other techniques, this approach is robust to noise and substantial variations for it takes the continuity of the segments into account.  Several methods of this approach will be described below.  Applications  Functioning as a post-processing filter to a labelled image  This approach is very effective against small regions caused by noise. And these small regions are usually formed by few pixels or one pixel. The most probable label is assigned to these regions. However, there is a drawback of this method. The small regions also can be formed by correct regions rather than noise, and in this case the method is actually making the classification worse. This approach is widely used in remote sensing applications.  Improving the post-processing classification  This is a two-stage classification process:   For each pixel, label the pixel and form a new feature vector for it.  Use the new feature vector and combine the contextual information to assign the final label to the   Merging the pixels in earlier stages  Instead of using single pixels, the neighbour pixels can be merged into homogeneous regions benefiting from contextual information. And provide these regions to classifier.  Acquiring pixel feature from neighbourhood  The original spectral data can be enriched by adding the contextual information carried by the neighbour pixels, or even replaced in some occasions. This kind of pre-processing methods are widely used in textured image recognition. The typical approaches include mean values, variances, texture description, etc.  Combining spectral and spatial information  The classifier uses the grey level and pixel neighbourhood (contextual information) to assign labels to pixels. In such case the information is a combination of spectral and spatial information.  Powered by the Bayes minimum error classifier  Contextual classification of image data is based on the Bayes minimum error classifier (also known as a naive Bayes classifier ).  Present the pixel :   A pixel is denoted as    x  0     subscript  x  0    x_{0}   .  The neighbourhood of each pixel    x  0     subscript  x  0    x_{0}   is a vector and denoted as    N   (   x  0   )       N   subscript  x  0     N(x_{0})   .  The values in the neighbourhood vector is denoted as    f   (   x  i   )       f   subscript  x  i     f(x_{i})   .  Each pixel is presented by the vector          ξ  =   (   f   (   x  0   )    ,   f   (   x  1   )    ,  …  ,   f   (   x  k   )    )       ξ     f   subscript  x  0      f   subscript  x  1    normal-…    f   subscript  x  k       \xi=\left(f(x_{0}),f(x_{1}),\ldots,f(x_{k})\right)           x  i   ∈   N   (   x  0   )     ;   i  =   1  ,  …  ,  k       formulae-sequence     subscript  x  i     N   subscript  x  0       i   1  normal-…  k      x_{i}\in N(x_{0});\quad i=1,\ldots,k         The labels (classification) of pixels in the neighbourhood    N   (   x  0   )       N   subscript  x  0     N(x_{0})   are presented as a vector         η  =   (   θ  0   ,   θ  1   ,  …  ,   θ  k   )       η    subscript  θ  0    subscript  θ  1   normal-…   subscript  θ  k      \eta=\left(\theta_{0},\theta_{1},\ldots,\theta_{k}\right)          θ  i   ∈   {   ω  0   ,   ω  1   ,  …  ,   ω  k   }        subscript  θ  i     subscript  ω  0    subscript  ω  1   normal-…   subscript  ω  k      \theta_{i}\in\left\{\omega_{0},\omega_{1},\ldots,\omega_{k}\right\}         ω  s     subscript  ω  s    \omega_{s}   here denotes the assigned class.      A vector presents the labels in the neighbourhood    N   (   x  0   )       N   subscript  x  0     N(x_{0})   without the pixel    x  0     subscript  x  0    x_{0}             η  ^   =   (   θ  1   ,   θ  2   ,  …  ,   θ  k   )        normal-^  η     subscript  θ  1    subscript  θ  2   normal-…   subscript  θ  k      \hat{\eta}=\left(\theta_{1},\theta_{2},\ldots,\theta_{k}\right)        The neighbourhood : Size of the neighbourhood. There is no limitation of the size, but it is considered to be relatively small for each pixel    x  0     subscript  x  0    x_{0}   . A reasonable size of neighbourhood would be    3  ×  3      3  3    3\times 3   of 4- connectivity or 8-connectivity (    x  0     subscript  x  0    x_{0}   is marked as red and placed in the centre).  Image:Square_4_connectivity.svg| 4-connectivity neighbourhood,  Image:Square_8_connectivity.svg| 8-connectivity neighbourhood  The calculation :  Apply the minimum error classification on a pixel    x  0     subscript  x  0    x_{0}   , if the probability of a class    ω  r     subscript  ω  r    \omega_{r}   being presenting the pixel    x  0     subscript  x  0    x_{0}   is the highest among all, then assign    ω  r     subscript  ω  r    \omega_{r}   as its class.       θ  0   =   ω  r   if  P   (   ω  r   ∣  f   (   x  0   )   )   =   max   s  =   1  ,  2  ,  …  ,  R     P   (   ω  s   ∣  f   (   x  0   )   )      fragments   subscript  θ  0     subscript  ω  r    if   P   fragments  normal-(   subscript  ω  r   normal-∣  f   fragments  normal-(   subscript  x  0   normal-)   normal-)     subscript     s   1  2  normal-…  R     P   fragments  normal-(   subscript  ω  s   normal-∣  f   fragments  normal-(   subscript  x  0   normal-)   normal-)     \theta_{0}=\omega_{r}\quad\text{ if }\quad P(\omega_{r}\mid f(x_{0}))=\max_{s=%
 1,2,\ldots,R}P(\omega_{s}\mid f(x_{0}))     The contextual classification rule is described as below, it uses the feature vector    x  1     subscript  x  1    x_{1}   rather than    x  0     subscript  x  0    x_{0}   .       θ  0   =   ω  r   if  P   (   ω  r   ∣  ξ  )   =   max   s  =   1  ,  2  ,  …  ,  R     P   (   ω  s   ∣  ξ  )      fragments   subscript  θ  0     subscript  ω  r    if   P   fragments  normal-(   subscript  ω  r   normal-∣  ξ  normal-)     subscript     s   1  2  normal-…  R     P   fragments  normal-(   subscript  ω  s   normal-∣  ξ  normal-)     \theta_{0}=\omega_{r}\quad\text{ if }\quad P(\omega_{r}\mid\xi)=\max_{s=1,2,%
 \ldots,R}P(\omega_{s}\mid\xi)     Use the Bayes formula to calculate the posteriori probability    P   (   ω  s   ∣  ξ  )      fragments  P   fragments  normal-(   subscript  ω  s   normal-∣  ξ  normal-)     P(\omega_{s}\mid\xi)         P   (   ω  s   ∣  ξ  )   =    p   (  ξ  ∣   ω  s   )   P   (   ω  s   )     p   (  ξ  )        fragments  P   fragments  normal-(   subscript  ω  s   normal-∣  ξ  normal-)       fragments  p   fragments  normal-(  ξ  normal-∣   subscript  ω  s   normal-)   P   fragments  normal-(   subscript  ω  s   normal-)      p  ξ      P(\omega_{s}\mid\xi)=\frac{p(\xi\mid\omega_{s})P(\omega_{s})}{p\left(\xi\right)}     The amount of vectors is the same as the number of pixels in the image. For the classifier uses a vector corresponding to each pixel    x  i     subscript  x  i    x_{i}   , and the vector is generated from the pixel's neighbourhood.  The basic steps of contextual image classification :   Calculate the feature vector   ξ   ξ   \xi   for each pixel.  Calculate the parameters of probability distribution    p   (  ξ  ∣   ω  s   )      fragments  p   fragments  normal-(  ξ  normal-∣   subscript  ω  s   normal-)     p(\xi\mid\omega_{s})   and    P   (   ω  s   )       P   subscript  ω  s     P(\omega_{s})     Calculate the posterior probabilities    P   (   ω  r   ∣  ξ  )      fragments  P   fragments  normal-(   subscript  ω  r   normal-∣  ξ  normal-)     P(\omega_{r}\mid\xi)   and all labels    θ  0     subscript  θ  0    \theta_{0}   . Get the image classification result.   Algorithms  Template matching  The template matching is a "brute force" implementation of this approach. 1 The concept is first create a set of templates, and then look for small parts in the image match with a template.  This method is computationally high and inefficient. It keeps an entire templates list during the whole process and the number of combinations is extremely high. For a    m  ×  n      m  n    m\times n   pixel image, there could be a maximum of    2   m  ×  n      superscript  2    m  n     2^{m\times n}   combinations, which leads to high computation. This method is a top down method and often called table look-up or dictionary look-up .  Lower-order Markov chain  The Markov chain 2 also can be applied in pattern recognition. The pixels in an image can be recognised as a set of random variables, then use the lower order Markov chain to find the relationship among the pixels. The image is treated as a virtual line, and the method uses conditional probability.  Hilbert space-filling curves  The Hilbert curve runs in a unique pattern through the whole image, it traverses every pixel without visits any of them twice and keeps a continuous curve. It is fast and efficient.  Markov meshes  The lower-order Markov chain and Hilbert space-filling curves mentioned above are treating the image as a line structure. The Markov meshes however will take the two dimensional information into account.  Dependency tree  The dependency tree 3 is a method using tree dependency to approximate probability distributions.  References    External links   Advanced Vision homepage  The Use of Context in Pattern Recognition  Image Analysis and Understanding: contextual image classification   "  Category:Computer vision  Category:Applications of computer vision  Category:Image processing  Category:Artificial intelligence     G.T. Toussaint, "The Use of Context in Pattern Recognition," Pattern Recognition, vol. 10, 1977, pp. 189–204. ↩  K. Abend, T.J. Harley, and L.N. Kanal, "Classification of Binary Random Patterns," IEEE Transactions on Information Theory, vol. 11, no. 4, October 1965, pp. 538–544. ↩  C.K. Chow and C.N. Liu, "Approximating Discrete Probability Distributions with Dependence Trees," IEEE Transaction on Information Theory, vol.14, no. 3, May 1965, pp. 462–467. ↩     