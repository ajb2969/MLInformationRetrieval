<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="1298">Amortized analysis</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>Amortized analysis</h1>
<style>
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
<style>
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
  </style>
</body></html>
<body>
<hr/>

<p>In <a href="computer_science" title="wikilink">computer science</a>, <strong>amortized analysis</strong> is a method for <a href="Analysis_of_algorithms" title="wikilink">analyzing</a> a given algorithm's <a href="time_complexity" title="wikilink">time complexity</a>, or how much of a resource, especially time or memory in the context of computer programs, it takes to <a href="Execution_(computing)" title="wikilink">execute</a>. Unlike other analyses that focus on an algorithm's run time in a <a href="Best,_worst_and_average_case" title="wikilink">worst case scenario</a>, amortized analysis examines how an algorithm will perform in practice or on average.<a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a></p>

<p>While certain operations for a given algorithm may have a significant cost in resources, other operations may not be as costly. Amortized analysis considers both the costly and less costly operations together over the whole series of operations of the algorithm. This may include accounting for different types of input, length of the input, and other factors that affect its performance.<a class="footnoteRef" href="#fn2" id="fnref2"><sup>2</sup></a></p>
<h2 id="history">History</h2>

<p>Amortized analysis initially emerged from a method called aggregate analysis, which is now subsumed by amortized analysis. However, the technique was first formally introduced by <a href="Robert_Tarjan" title="wikilink">Robert Tarjan</a> in his 1985 paper <em>Amortized Computational Complexity</em>, which addressed the need for more useful form of analysis than the common probabilistic methods used. Amortization was initially used for very specific types of algorithms, particularly those involving <a href="binary_tree" title="wikilink">binary trees</a> and <a href="Union_(computer_science)" title="wikilink">union</a> operations. However, it is now ubiquitous and comes into play when analyzing many other algorithms as well.<a class="footnoteRef" href="#fn3" id="fnref3"><sup>3</sup></a></p>
<h2 id="method">Method</h2>

<p>The method requires knowledge of which series of operations are possible. This is most commonly the case with <a href="data_structure" title="wikilink">data structures</a>, which have <a href="state_(computer_science)" title="wikilink">state</a> that persists between operations. The basic idea is that a worst case operation can alter the state in such a way that the worst case cannot occur again for a long time, thus "amortizing" its cost.</p>

<p>There are generally three methods for performing amortized analysis: the aggregate method, the accounting method, and the potential method. All of these give the same answers, and their usage difference is primarily circumstantial and due to individual preference.<a class="footnoteRef" href="#fn4" id="fnref4"><sup>4</sup></a></p>
<ul>
<li>Aggregate analysis determines the upper bound <em>T</em>(<em>n</em>) on the total cost of a sequence of <em>n</em> operations, then calculates the amortized cost to be <em>T</em>(<em>n</em>) / <em>n</em>.<a class="footnoteRef" href="#fn5" id="fnref5"><sup>5</sup></a></li>
<li>The <a href="accounting_method" title="wikilink">accounting method</a> determines the individual cost of each operation, combining its immediate execution time and its influence on the running time of future operations. Usually, many short-running operations accumulate a "debt" of unfavorable state in small increments, while rare long-running operations decrease it drastically.<a class="footnoteRef" href="#fn6" id="fnref6"><sup>6</sup></a></li>
<li>The <a href="potential_method" title="wikilink">potential method</a> is like the accounting method, but overcharges operations early to compensate for undercharges later.<a class="footnoteRef" href="#fn7" id="fnref7"><sup>7</sup></a></li>
</ul>
<h2 id="examples">Examples</h2>
<h3 id="dynamic-array">Dynamic Array</h3>
<figure><b>(Figure)</b>
<figcaption><code>Amortized</code> <code>Analysis</code> <code>of</code> <code>the</code> <code>Push</code> <code>operation</code> <code>for</code> <code>a</code> <code>Dynamic</code> <code>Array</code></figcaption>
</figure>

<p>Consider a <a href="dynamic_array" title="wikilink">dynamic array</a> that grows in size as more elements are added to it such as an ArrayList in Java. If we started out with a dynamic array of size 4, it would take <a href="constant_time" title="wikilink">constant time</a> to push four elements onto it. Yet pushing a fifth element onto that array would take longer as the array would have to create a new array of double the current size (8), copy the old elements onto the new array, and then add the new element. The next three push operations would similarly take constant time, and then the subsequent addition would require another slow doubling of the array size.</p>

<p>In general if we consider an arbitrary number of pushes <em>n</em> to an array of size <em>n</em>, we notice that push operations take constant time except for the last one which takes <a href="Big_O_notation" title="wikilink">O(n)</a> time to perform the size doubling operation. Since there were <em>n</em> operations total we can take the average of this and find that for pushing elements onto the dynamic array takes 

<math display="block" id="Amortized_analysis:0">
 <semantics>
  <mrow>
   <mrow>
    <mi>O</mi>
    <mrow>
     <mo stretchy="false">(</mo>
     <mstyle displaystyle="false">
      <mfrac>
       <mi>n</mi>
       <mi>n</mi>
      </mfrac>
     </mstyle>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
   <mo>=</mo>
   <mrow>
    <mi>O</mi>
    <mrow>
     <mo stretchy="false">(</mo>
     <mn>1</mn>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <times></times>
     <ci>O</ci>
     <apply>
      <divide></divide>
      <ci>n</ci>
      <ci>n</ci>
     </apply>
    </apply>
    <apply>
     <times></times>
     <ci>O</ci>
     <cn type="integer">1</cn>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   O(\tfrac{n}{n})=O(1)
  </annotation>
 </semantics>
</math>

, constant time.<a class="footnoteRef" href="#fn8" id="fnref8"><sup>8</sup></a></p>
<h3 id="queue">Queue</h3>

<p>Let's look at a Ruby implementation of a Queue, a <a href="FIFO_(computing_and_electronics)" title="wikilink">FIFO data structure</a>:</p>
<div class="sourceCode"><pre class="sourceCode ruby"><code class="sourceCode ruby"><span class="kw">class</span> <span class="dt">Queue</span>
  <span class="kw">def</span> initialize
    <span class="ot">@input</span> = []
    <span class="ot">@output</span> = []
  <span class="kw">end</span>

  <span class="kw">def</span> enqueue(element)
    <span class="ot">@input</span> &lt;&lt; element
  <span class="kw">end</span>

  <span class="kw">def</span> dequeue
    <span class="kw">if</span> <span class="ot">@output</span>.empty?
      <span class="kw">while</span> <span class="ot">@input</span>.any?
        <span class="ot">@output</span> &lt;&lt; <span class="ot">@input</span>.pop
      <span class="kw">end</span>
    <span class="kw">end</span>

    <span class="ot">@output</span>.pop
  <span class="kw">end</span>
<span class="kw">end</span></code></pre></div>

<p>The amortized enqueue operation is always constant time because it just pushes an element onto the input array. This operation does not depend on the lengths of either input or output and so takes just constant time.</p>

<p>However the dequeue operation is more complicated. If the output array already has some elements in it, then it takes constant time to perform dequeue. Otherwise if output is empty, it will take O(n) time to add all the elements onto the output array from the input array, with <em>n</em> being the length of the input array. Now if we have just copied <em>n</em> elements from input, then we can perform <em>n</em> dequeue operations each taking constant time before we have to perform another costly operation of copying elements from input again. Therefore in practice the amortized run time of dequeue is O(1).<a class="footnoteRef" href="#fn9" id="fnref9"><sup>9</sup></a></p>
<h2 id="common-use">Common use</h2>
<ul>
<li>In common usage, an "amortized algorithm" is one that an amortized analysis has shown to perform well.</li>
<li><a href="Online_algorithm" title="wikilink">Online algorithms</a> commonly use amortized analysis.</li>
</ul>
<h2 id="references">References</h2>
<ul>
<li></li>
</ul>

<p>"</p>

<p><a href="Category:Analysis_of_algorithms" title="wikilink">Category:Analysis of algorithms</a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1"><a href="#fnref1">↩</a></li>
<li id="fn2"><a href="#fnref2">↩</a></li>
<li id="fn3"></li>
<li id="fn4"><a href="#fnref4">↩</a></li>
<li id="fn5"></li>
<li id="fn6"></li>
<li id="fn7"></li>
<li id="fn8"></li>
<li id="fn9"><a href="#fnref9">↩</a></li>
</ol>
</section>
</body>

