   De Finetti's theorem      De Finetti's theorem   In probability theory , de Finetti's theorem states that exchangeable observations are conditionally independent given some latent variable to which an epistemic probability  distribution would then be assigned. It is named in honor of Bruno de Finetti .  For the special case of an exchangeable sequence of Bernoulli random variables it states that such a sequence is a "mixture" of sequences of independent and identically distributed (i.i.d.) Bernoulli random variables. While the individual variables of the exchangeable sequence are not themselves i.i.d., only exchangeable, there is an underlying family of i.i.d. random variables.  Thus, while observations need not be i.i.d. for a sequence to be exchangeable, there are underlying, generally unobservable, quantities which are i.i.d. – exchangeable sequences are (not necessarily i.i.d.) mixtures of i.i.d. sequences.  Background  A Bayesian statistician often seeks the conditional probability distribution of a random quantity given the data. The concept of exchangeability was introduced by de Finetti. De Finetti's theorem explains a mathematical relationship between independence and exchangeability. 1  An infinite sequence       X  1   ,   X  2   ,   X  3   ,   …       subscript  X  1    subscript  X  2    subscript  X  3   normal-…    X_{1},X_{2},X_{3},\dots\!     of random variables is said to be exchangeable if for any finite cardinal number  n and any two finite sequences i 1 , ..., i n and j 1 , ..., j n (with each of the i s distinct, and each of the j s distinct), the two sequences       X   i  1    ,  …  ,    X   i  n    and   X   j  1     ,  …  ,    X   j  n         subscript  X   subscript  i  1    normal-…     subscript  X   subscript  i  n    and   subscript  X   subscript  j  1     normal-…   subscript  X   subscript  j  n      X_{i_{1}},\dots,X_{i_{n}}\text{ and }X_{j_{1}},\dots,X_{j_{n}}\!     both have the same joint probability distribution.  If an identically distributed sequence is independent , then the sequence is exchangeable; however, the converse is false --- there exist exchangeable random variables that are statistically dependent, for example the Polya urn model .  Statement of the theorem  A random variable  X has a Bernoulli distribution if Pr( X = 1) = p and Pr( X = 0) = 1 − p for some p ∈ (0, 1).  De Finetti's theorem states that the probability distribution of any infinite exchangeable sequence of Bernoulli random variables is a "mixture" of the probability distributions of independent and identically distributed sequences of Bernoulli random variables. "Mixture", in this sense, means a weighted average, but this need not mean a finite or countably infinite (i.e., discrete) weighted average: it can be an integral rather than a sum.  More precisely, suppose X 1 , X 2 , X 3 , ... is an infinite exchangeable sequence of Bernoulli-distributed random variables. Then there is some probability distribution m on the interval [0, 1] and some random variable Y such that   The probability distribution of Y is m , and  The conditional probability distribution of the whole sequence X 1 , X 2 , X 3 , ... given the value of Y is described by saying that  X 1 , X 2 , X 3 , ... are conditionally independent given Y , and  For any i ∈ {1, 2, 3, ...}, the conditional probability that X i = 1, given the value of Y , is Y .    Another way of stating the theorem  Suppose     X  1   ,   X  2   ,   X  3   ,  …      subscript  X  1    subscript  X  2    subscript  X  3   normal-…    X_{1},X_{2},X_{3},\ldots   is an infinite exchangeable sequence of Bernoulli random variables. Then     X  1   ,   X  2   ,   X  3   ,  …      subscript  X  1    subscript  X  2    subscript  X  3   normal-…    X_{1},X_{2},X_{3},\ldots   are conditionally independent and identically distributed given the exchangeable sigma-algebra (i.e., the sigma-algebra of events measurable with respect to     X  1   ,   X  2   ,  …      subscript  X  1    subscript  X  2   normal-…    X_{1},X_{2},\ldots   and invariant under finite permutations of the indices).  Example  Here is a concrete example. Suppose p = 2/3 with probability 1/2 and p = 9/10 with probability 1/2. Suppose the conditional distribution of the sequence       X  1   ,   X  2   ,   X  3   ,   …       subscript  X  1    subscript  X  2    subscript  X  3   normal-…    X_{1},X_{2},X_{3},\dots\!     given the event that p = 2/3, is described by saying that they are independent and identically distributed and X 1 = 1 with probability 2/3 and X 1 = 0 with probability 1 − (2/3). Further, the conditional distribution of the same sequence given the event that p = 9/10, is described by saying that they are independent and identically distributed and X 1 = 1 with probability 9/10 and X 1 = 0 with probability 1 − (9/10). The independence asserted here is conditional independence, i.e., the Bernoulli random variables in the sequence are conditionally independent given the event that p = 2/3, and are conditionally independent given the event that p = 9/10. But they are not unconditionally independent; they are positively correlated . In view of the strong law of large numbers , we can say that        lim   n  →  ∞       X  1   +  ⋯  +   X  n    n    =   {      2  /  3        with probability  1   /  2   ,        9  /  10       with probability  1   /  2.             subscript    normal-→  n          subscript  X  1   normal-⋯   subscript  X  n    n     cases    2  3       with probability  1   2     9  10       with probability  1   2.      \lim_{n\rightarrow\infty}\frac{X_{1}+\cdots+X_{n}}{n}=\begin{cases}2/3&\text{%
 with probability }1/2,\\
 9/10&\text{with probability }1/2.\end{cases}     Rather than concentrating probability 1/2 at each of two points between 0 and 1, the "mixing distribution" can be any probability distribution supported on the interval from 0 to 1; which one it is depends on the joint distribution of the infinite sequence of Bernoulli random variables.  The conclusion of the first version of the theorem above makes sense if the sequence of exchangeable Bernoulli random variables is finite, but the theorem is not generally true in that case. It is true if the sequence can be extended to an exchangeable sequence that is infinitely long. The simplest example of an exchangeable sequence of Bernoulli random variables that cannot be so extended is the one in which X 1 = 1 − X 2 and X 1 is either 0 or 1, each with probability 1/2. This sequence is exchangeable, but cannot be extended to an exchangeable sequence of length 3, let alone an infinitely long one.  Extensions  Versions of de Finetti's theorem for finitely exchangeable sequences, 2  3 and for Markov exchangeable sequences 4 have been proved by Diaconis and Freedman and by Kerns and Szekely. Two notions of partial exchangeability of arrays, known as separate and joint exchangeability lead to extensions of de Finetti's theorem for arrays by Aldous and Hoover. 5  The computable de Finetti theorem shows that if an exchangeable sequence of real random variables is given by a computer program, then a program which samples from the mixing measure can be automatically recovered. 6  In the setting of free probability , there is a noncommutative extension of de Finetti's theorem which characterizes noncommutative sequences invariant under quantum permutations. 7  Extensions of de Finetti's theorem to quantum states have been found to be useful in quantum information .  References    External links      What is so cool about De Finetti's representation theorem?   "  Category:Probability theorems  Category:Bayesian statistics  Category:Integral representations     See the Oxford lecture notes of Steffen Lauritzen http://www.stats.ox.ac.uk/~steffen/teaching/grad/definetti.pdf ↩  ↩  ↩  ↩  Persi Diaconis and Svante Janson (2008) "Graph Limits and Exchangeable Random Graphs" , Rendiconti di Matematica , Ser. VII 28(1), 33–61. ↩  Cameron Freer and Daniel Roy (2009) "Computable exchangeable sequences have computable de Finetti measures" , Proceedings of the 5th Conference on Computability in Europe: Mathematical Theory and Computational Practice , Lecture Notes In Computer Science, Vol. 5635, pp. 218–231. ↩  ↩     