   Local martingale      Local martingale   In mathematics , a local martingale is a type of stochastic process , satisfying the localized version of the martingale property. Every martingale is a local martingale; every bounded local martingale is a martingale; in particular, every local martingale that is bounded from below is a supermartingale, and every local martingale that is bounded from above is a submartingale; however, in general a local martingale is not a martingale, because its expectation can be distorted by large values of small probability. In particular, a driftless diffusion process is a local martingale, but not necessarily a martingale.  Local martingales are essential in stochastic analysis , see ItÅ calculus , semimartingale , Girsanov theorem .  Definition  Let (Î©, F , P ) be a probability space ; let F âˆ— =Â { F t | t â‰¥Â 0Â } be a filtration of F ; let XÂ :Â [0,Â +âˆ)Â Ã—Â Î©Â â†’ S be an F âˆ— - adapted stochastic process on set S . Then X is called an F âˆ— -local martingale if there exists a sequence of F âˆ— - stopping times  Ï„ k :Â Î©Â â†’Â [0,Â +âˆ) such that   the Ï„ k are almost surely  increasing : P [ Ï„ k  k +1]Â =Â 1;  the Ï„ k diverge almost surely: P [ Ï„ k â†’Â +âˆÂ as k â†’Â +âˆ]Â =Â 1;  the stopped process          X  t   Ï„  k    :=   X   min   {  t  ,   Ï„  k   }        assign   superscript   subscript  X  t    subscript  Ï„  k     subscript  X    t   subscript  Ï„  k       X_{t}^{\tau_{k}}:=X_{\min\{t,\tau_{k}\}}         is an F âˆ— -martingale for every k .   Examples  Example 1  Let W t be the Wiener process and T =Â min{ t : W t =Â âˆ’1Â } the time of first hit ofÂ âˆ’1. The stopped process  W min{ t , T } is a martingale; its expectation is 0 at all times, nevertheless its limit (as t â†’Â âˆ) is equal to âˆ’1 almost surely (a kind of gambler's ruin ). A time change leads to a process       X  t   =   {      W   min   (    t   1  -  t     ,  T  )          for  0   â‰¤  t  <  1   ,        -  1        for  1   â‰¤  t  <  âˆ   .            subscript  X  t    cases   subscript  W      t    1  t    T          for  0   t       1      1         for  1   t             \displaystyle X_{t}=\begin{cases}W_{\min(\tfrac{t}{1-t},T)}&\text{for }0\leq t%
 <1,\\
 -1&\text{for }1\leq t<\infty.\end{cases}     The process    X  t     subscript  X  t    X_{t}   is continuous almost surely; nevertheless, its expectation is discontinuous,       ğ”¼   X  t    =   {     0       for  0   â‰¤  t  <  1   ,        -  1        for  1   â‰¤  t  <  âˆ   .             ğ”¼   subscript  X  t     cases  0        for  0   t       1      1         for  1   t             \displaystyle\mathbb{E}X_{t}=\begin{cases}0&\text{for }0\leq t<1,\\
 -1&\text{for }1\leq t<\infty.\end{cases}     This process is not a martingale. However, it is a local martingale. A localizing sequence may be chosen as     Ï„  k   =   min   {   t  :    X  t   =  k    }         subscript  Ï„  k      normal-:  t     subscript  X  t   k       \tau_{k}=\min\{t:X_{t}=k\}   if there is such t , otherwise Ï„ k = k . This sequence diverges almost surely, since Ï„ k = k for all k large enough (namely, for all k that exceed the maximal value of the process X ). The process stopped at Ï„ k is a martingale. 1  Example 2  Let W t be the Wiener process and Æ’ a measurable function such that      ğ”¼   |   f   (   W  1   )    |    <  âˆ   .        ğ”¼      f   subscript  W  1         \mathbb{E}|f(W_{1})|<\infty.   Then the following process is a martingale:       X  t   =  ğ”¼   (  f   (   W  1   )   |   F  t   )   =   {       f   1  -  t     (   W  t   )         for  0   â‰¤  t  <  1   ,        f   (   W  1   )         for  1   â‰¤  t  <  âˆ   ;          fragments   subscript  X  t    E   fragments  normal-(  f   fragments  normal-(   subscript  W  1   normal-)   normal-|   subscript  F  t   normal-)     cases     subscript  f    1  t     subscript  W  t          for  0   t       1      f   subscript  W  1          for  1   t             \displaystyle X_{t}=\mathbb{E}(f(W_{1})|F_{t})=\begin{cases}f_{1-t}(W_{t})&%
 \text{for }0\leq t<1,\\
 f(W_{1})&\text{for }1\leq t<\infty;\end{cases}   here         f  s    (  x  )    =   ğ”¼  f   (   x  +   W  s    )    =   âˆ«   f   (   x  +  y   )    1    2  Ï€  s      e   -    y  2   /   (   2  s   )         .           subscript  f  s   x     ğ”¼  f    x   subscript  W  s              f    x  y     1      2  Ï€  s      superscript  normal-e       superscript  y  2     2  s           \displaystyle f_{s}(x)=\mathbb{E}f(x+W_{s})=\int f(x+y)\frac{1}{\sqrt{2\pi s}}%
 \mathrm{e}^{-y^{2}/(2s)}.   The Dirac delta function    Î´   Î´   \delta   (strictly speaking, not a function), being used in place of    f  ,    f   f,   leads to a process defined informally as     Y  t   =  ğ”¼   (  Î´   (   W  1   )   |   F  t   )      fragments   subscript  Y  t    E   fragments  normal-(  Î´   fragments  normal-(   subscript  W  1   normal-)   normal-|   subscript  F  t   normal-)     Y_{t}=\mathbb{E}(\delta(W_{1})|F_{t})   and formally as       Y  t   =   {       Î´   1  -  t     (   W  t   )         for  0   â‰¤  t  <  1   ,       0       for  1   â‰¤  t  <  âˆ   ,            subscript  Y  t    cases     subscript  Î´    1  t     subscript  W  t          for  0   t       1    0        for  1   t             \displaystyle Y_{t}=\begin{cases}\delta_{1-t}(W_{t})&\text{for }0\leq t<1,\\
 0&\text{for }1\leq t<\infty,\end{cases}   where         Î´  s    (  x  )    =    1    2  Ï€  s      e   -    x  2   /   (   2  s   )        .         subscript  Î´  s   x       1      2  Ï€  s      superscript  normal-e       superscript  x  2     2  s         \displaystyle\delta_{s}(x)=\frac{1}{\sqrt{2\pi s}}\mathrm{e}^{-x^{2}/(2s)}.   The process    Y  t     subscript  Y  t    Y_{t}   is continuous almost surely (since     W  1   â‰   0       subscript  W  1   0    W_{1}\neq 0   almost surely), nevertheless, its expectation is discontinuous,       ğ”¼   Y  t    =   {      1  /    2  Ï€          for  0   â‰¤  t  <  1   ,       0       for  1   â‰¤  t  <  âˆ   .             ğ”¼   subscript  Y  t     cases    1      2  Ï€           for  0   t       1    0        for  1   t             \displaystyle\mathbb{E}Y_{t}=\begin{cases}1/\sqrt{2\pi}&\text{for }0\leq t<1,%
 \\
 0&\text{for }1\leq t<\infty.\end{cases}   This process is not a martingale. However, it is a local martingale. A localizing sequence may be chosen as      Ï„  k   =   min   {   t  :    Y  t   =  k    }     .       subscript  Ï„  k      normal-:  t     subscript  Y  t   k       \tau_{k}=\min\{t:Y_{t}=k\}.     Example 3  Let    Z  t     subscript  Z  t    Z_{t}   be the complex-valued Wiener process , and        X  t   =   ln   |    Z  t   -  1   |     .       subscript  X  t          subscript  Z  t   1       \displaystyle X_{t}=\ln|Z_{t}-1|\,.   The process    X  t     subscript  X  t    X_{t}   is continuous almost surely (since    Z  t     subscript  Z  t    Z_{t}   does not hit 1, almost surely), and is a local martingale, since the function    u  â†¦   ln   |   u  -  1   |       maps-to  u        u  1       u\mapsto\ln|u-1|   is harmonic (on the complex plane without the point 1). A localizing sequence may be chosen as      Ï„  k   =   min   {   t  :    X  t   =   -  k     }     .       subscript  Ï„  k      normal-:  t     subscript  X  t     k        \tau_{k}=\min\{t:X_{t}=-k\}.   Nevertheless, the expectation of this process is non-constant; moreover,       ğ”¼   X  t    â†’  âˆ     normal-â†’    ğ”¼   subscript  X  t       \displaystyle\mathbb{E}X_{t}\to\infty   as     t  â†’  âˆ   ,     normal-â†’  t     t\to\infty,   which can be deduced from the fact that the mean value of    ln   |   u  -  1   |           u  1      \ln|u-1|   over the circle     |  u  |   =  r        u   r    |u|=r   tends to infinity as    r  â†’  âˆ     normal-â†’  r     r\to\infty   . (In fact, it is equal to    ln  r      r    \ln r   for r â‰¥ 1 but to 0 for r â‰¤ 1).  Martingales via local martingales  Let    M  t     subscript  M  t    M_{t}   be a local martingale. In order to prove that it is a martingale it is sufficient to prove that     M  t   Ï„  k    â†’   M  t      normal-â†’   superscript   subscript  M  t    subscript  Ï„  k     subscript  M  t     M_{t}^{\tau_{k}}\to M_{t}    in L 1 (as    k  â†’  âˆ     normal-â†’  k     k\to\infty   ) for every t , that is,      ğ”¼   |    M  t   Ï„  k    -   M  t    |    â†’  0   ;     normal-â†’    ğ”¼       superscript   subscript  M  t    subscript  Ï„  k     subscript  M  t      0    \mathbb{E}|M_{t}^{\tau_{k}}-M_{t}|\to 0;   here     M  t   Ï„  k    =   M   t  âˆ§   Ï„  k          superscript   subscript  M  t    subscript  Ï„  k     subscript  M    t   subscript  Ï„  k       M_{t}^{\tau_{k}}=M_{t\wedge\tau_{k}}   is the stopped process. The given relation     Ï„  k   â†’  âˆ     normal-â†’   subscript  Ï„  k      \tau_{k}\to\infty   implies that     M  t   Ï„  k    â†’   M  t      normal-â†’   superscript   subscript  M  t    subscript  Ï„  k     subscript  M  t     M_{t}^{\tau_{k}}\to M_{t}   almost surely. The dominated convergence theorem ensures the convergence in L 1 provided that        (  *  )    ğ”¼    sup  k    |   M  t   Ï„  k    |      <  âˆ          ğ”¼    subscript  supremum  k      superscript   subscript  M  t    subscript  Ï„  k           \textstyle(*)\quad\mathbb{E}\sup_{k}|M_{t}^{\tau_{k}}|<\infty   for every t . Thus, Condition (*) is sufficient for a local martingale    M  t     subscript  M  t    M_{t}   being a martingale. A stronger condition       (  *  *  )   ğ”¼   sup   s  âˆˆ   [  0  ,  t  ]     |   M  s   |  <  âˆ     fragments   fragments  normal-(    normal-)    E   subscript  supremum    s   0  t     normal-|   subscript  M  s   normal-|      \textstyle(**)\quad\mathbb{E}\sup_{s\in[0,t]}|M_{s}|<\infty   for every t is also sufficient.  Caution. The weaker condition        sup   s  âˆˆ   [  0  ,  t  ]      ğ”¼   |   M  s   |     <  âˆ        subscript  supremum    s   0  t       ğ”¼     subscript  M  s         \textstyle\sup_{s\in[0,t]}\mathbb{E}|M_{s}|<\infty   for every t is not sufficient. Moreover, the condition        sup   t  âˆˆ   [  0  ,  âˆ  )      ğ”¼   e   |   M  t   |      <  âˆ        subscript  supremum    t   0        ğ”¼   superscript  normal-e     subscript  M  t          \textstyle\sup_{t\in[0,\infty)}\mathbb{E}\mathrm{e}^{|M_{t}|}<\infty   is still not sufficient; for a counterexample see Example 3 above .  A special case:        M  t   =   f   (  t  ,   W  t   )     ,       subscript  M  t     f   t   subscript  W  t       \textstyle M_{t}=f(t,W_{t}),   where    W  t     subscript  W  t    W_{t}   is the Wiener process , and    f  :     [  0  ,  âˆ  )   Ã—  â„   â†’  â„      normal-:  f   normal-â†’     0    â„   â„     f:[0,\infty)\times\mathbb{R}\to\mathbb{R}   is twice continuously differentiable . The process    M  t     subscript  M  t    M_{t}   is a local martingale if and only if f satisfies the PDE        (    âˆ‚   âˆ‚  t    +    1  2     âˆ‚  2    âˆ‚   x  2       )   f   (  t  ,  x  )    =  0.               t        1  2      superscript   2      superscript  x  2       f   t  x    0.    \Big(\frac{\partial}{\partial t}+\frac{1}{2}\frac{\partial^{2}}{\partial x^{2}%
 }\Big)f(t,x)=0.   However, this PDE itself does not ensure that    M  t     subscript  M  t    M_{t}   is a martingale. In order to apply (**) the following condition on f is sufficient: for every    Îµ  >  0      Îµ  0    \varepsilon>0   and t there exists    C  =   C   (  Îµ  ,  t  )        C    C   Îµ  t      C=C(\varepsilon,t)   such that       |   f   (  s  ,  x  )    |   â‰¤   C   e   Îµ   x  2              f   s  x       C   superscript  normal-e    Îµ   superscript  x  2        \textstyle|f(s,x)|\leq C\mathrm{e}^{\varepsilon x^{2}}   for all    s  âˆˆ   [  0  ,  t  ]       s   0  t     s\in[0,t]   and     x  âˆˆ  â„   .      x  â„    x\in\mathbb{R}.     Technical details    References     "  Category:Martingale theory  Category:Stochastic processes     For the times before 1 it is a martingale since a stopped Brownian motion is. After the instant 1 it is constant. It remains to check it at the instant 1. By the bounded convergence theorem the expectation at 1 is the limit of the expectation at ( n -1)/ n (as n tends to infinity), and the latter does not depend on n . The same argument applies to the conditional expectation. â†©     