<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="1191">Relevance vector machine</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>Relevance vector machine</h1>
<hr/>

<p>In <a class="uri" href="mathematics" title="wikilink">mathematics</a>, a <strong>relevance vector machine (RVM)</strong> is a <a href="machine_learning" title="wikilink">machine learning</a> technique that uses <a href="Bayesian_inference" title="wikilink">Bayesian inference</a> to obtain <a href="Parsimony" title="wikilink">parsimonious</a> solutions for <a href="Regression_analysis" title="wikilink">regression</a> and <a href="probabilistic_classification" title="wikilink">probabilistic classification</a>.<a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a> The RVM has an identical functional form to the <a href="support_vector_machine" title="wikilink">support vector machine</a>, but provides probabilistic classification.</p>

<p>It is actually equivalent to a <a href="Gaussian_process" title="wikilink">Gaussian process</a> model with <a href="covariance_function" title="wikilink">covariance function</a>:</p>

<p>

<math display="block" id="Relevance_vector_machine:0">
 <semantics>
  <mrow>
   <mrow>
    <mi>k</mi>
    <mrow>
     <mo stretchy="false">(</mo>
     <mi>ğ±</mi>
     <mo>,</mo>
     <msup>
      <mi>ğ±</mi>
      <mo>â€²</mo>
     </msup>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
   <mo>=</mo>
   <mrow>
    <munderover>
     <mo largeop="true" movablelimits="false" symmetric="true">âˆ‘</mo>
     <mrow>
      <mi>j</mi>
      <mo>=</mo>
      <mn>1</mn>
     </mrow>
     <mi>N</mi>
    </munderover>
    <mrow>
     <mfrac>
      <mn>1</mn>
      <msub>
       <mi>Î±</mi>
       <mi>j</mi>
      </msub>
     </mfrac>
     <mi>Ï†</mi>
     <mrow>
      <mo stretchy="false">(</mo>
      <mi>ğ±</mi>
      <mo>,</mo>
      <msub>
       <mi>ğ±</mi>
       <mi>j</mi>
      </msub>
      <mo stretchy="false">)</mo>
     </mrow>
     <mi>Ï†</mi>
     <mrow>
      <mo stretchy="false">(</mo>
      <msup>
       <mi>ğ±</mi>
       <mo>â€²</mo>
      </msup>
      <mo>,</mo>
      <msub>
       <mi>ğ±</mi>
       <mi>j</mi>
      </msub>
      <mo stretchy="false">)</mo>
     </mrow>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <times></times>
     <ci>k</ci>
     <interval closure="open">
      <ci>ğ±</ci>
      <apply>
       <csymbol cd="ambiguous">superscript</csymbol>
       <ci>ğ±</ci>
       <ci>normal-â€²</ci>
      </apply>
     </interval>
    </apply>
    <apply>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <sum></sum>
       <apply>
        <eq></eq>
        <ci>j</ci>
        <cn type="integer">1</cn>
       </apply>
      </apply>
      <ci>N</ci>
     </apply>
     <apply>
      <times></times>
      <apply>
       <divide></divide>
       <cn type="integer">1</cn>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <ci>Î±</ci>
        <ci>j</ci>
       </apply>
      </apply>
      <ci>Ï†</ci>
      <interval closure="open">
       <ci>ğ±</ci>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <ci>ğ±</ci>
        <ci>j</ci>
       </apply>
      </interval>
      <ci>Ï†</ci>
      <interval closure="open">
       <apply>
        <csymbol cd="ambiguous">superscript</csymbol>
        <ci>ğ±</ci>
        <ci>normal-â€²</ci>
       </apply>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <ci>ğ±</ci>
        <ci>j</ci>
       </apply>
      </interval>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   k(\mathbf{x},\mathbf{x^{\prime}})=\sum_{j=1}^{N}\frac{1}{\alpha_{j}}\varphi(%
\mathbf{x},\mathbf{x}_{j})\varphi(\mathbf{x}^{\prime},\mathbf{x}_{j})
  </annotation>
 </semantics>
</math>

 where 

<math display="inline" id="Relevance_vector_machine:1">
 <semantics>
  <mi>Ï†</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>Ï†</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \varphi
  </annotation>
 </semantics>
</math>

 is the <a href="kernel_function" title="wikilink">kernel function</a> (usually Gaussian),

<math display="inline" id="Relevance_vector_machine:2">
 <semantics>
  <msub>
   <mi>Î±</mi>
   <mi>j</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>Î±</ci>
    <ci>j</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \alpha_{j}
  </annotation>
 </semantics>
</math>

's as the variances of the prior on the weight vector 

<math display="inline" id="Relevance_vector_machine:3">
 <semantics>
  <mrow>
   <mi>w</mi>
   <mo>âˆ¼</mo>
   <mrow>
    <mi>N</mi>
    <mrow>
     <mo stretchy="false">(</mo>
     <mn>0</mn>
     <mo>,</mo>
     <mrow>
      <msup>
       <mi>Î±</mi>
       <mrow>
        <mo>-</mo>
        <mn>1</mn>
       </mrow>
      </msup>
      <mi>I</mi>
     </mrow>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="latexml">similar-to</csymbol>
    <ci>w</ci>
    <apply>
     <times></times>
     <ci>N</ci>
     <interval closure="open">
      <cn type="integer">0</cn>
      <apply>
       <times></times>
       <apply>
        <csymbol cd="ambiguous">superscript</csymbol>
        <ci>Î±</ci>
        <apply>
         <minus></minus>
         <cn type="integer">1</cn>
        </apply>
       </apply>
       <ci>I</ci>
      </apply>
     </interval>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   w\sim N(0,\alpha^{-1}I)
  </annotation>
 </semantics>
</math>


 ,and 

<math display="inline" id="Relevance_vector_machine:4">
 <semantics>
  <mrow>
   <msub>
    <mi>ğ±</mi>
    <mn>1</mn>
   </msub>
   <mo>,</mo>
   <mi mathvariant="normal">â€¦</mi>
   <mo>,</mo>
   <msub>
    <mi>ğ±</mi>
    <mi>N</mi>
   </msub>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <list>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>ğ±</ci>
     <cn type="integer">1</cn>
    </apply>
    <ci>normal-â€¦</ci>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>ğ±</ci>
     <ci>N</ci>
    </apply>
   </list>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \mathbf{x}_{1},\ldots,\mathbf{x}_{N}
  </annotation>
 </semantics>
</math>

 are the input vectors of the <a href="training_set" title="wikilink">training set</a>.</p>

<p>Compared to that of <a href="support_vector_machine" title="wikilink">support vector machines</a> (SVM), the Bayesian formulation of the RVM avoids the set of free parameters of the SVM (that usually require cross-validation-based post-optimizations). However RVMs use an <a href="expectation_maximization" title="wikilink">expectation maximization</a> (EM)-like learning method and are therefore at risk of local minima. This is unlike the standard <a href="sequential_minimal_optimization" title="wikilink">sequential minimal optimization</a> (SMO)-based algorithms employed by <a href="Support_vector_machine" title="wikilink">SVMs</a>, which are guaranteed to find a global optimum (of the convex problem).</p>

<p>The relevance vector machine is <a href="Software_patents_under_United_States_patent_law" title="wikilink">patented in the United States</a> by <a class="uri" href="Microsoft" title="wikilink">Microsoft</a>.<a class="footnoteRef" href="#fn2" id="fnref2"><sup>2</sup></a></p>
<h2 id="see-also">See also</h2>
<ul>
<li><a href="Kernel_trick" title="wikilink">Kernel trick</a></li>
<li><a href="Platt_scaling" title="wikilink">Platt scaling</a>: turns an SVM into a probability model</li>
</ul>
<h2 id="references">References</h2>
<h2 id="software">Software</h2>
<ul>
<li><a href="http://dlib.net">dlib C++ Library</a></li>
<li><a href="http://www.terborg.net/research/kml/">The Kernel-Machine Library</a></li>
<li><a href="http://www.maths.bris.ac.uk/R/web/packages/rvmbinary/index.html">rvmbinary:R package for binary classification</a></li>
</ul>
<h2 id="external-links">External links</h2>
<ul>
<li><a href="http://www.relevancevector.com">Tipping's webpage on Sparse Bayesian Models and the RVM</a></li>
<li><a href="http://www.tristanfletcher.co.uk/RVM%20Explained.pdf">A Tutorial on RVM by Tristan Fletcher</a></li>
</ul>

<p>"</p>

<p><a href="Category:Classification_algorithms" title="wikilink">Category:Classification algorithms</a> <a href="Category:Kernel_methods_for_machine_learning" title="wikilink">Category:Kernel methods for machine learning</a> <a href="Category:Non-parametric_Bayesian_methods" title="wikilink">Category:Non-parametric Bayesian methods</a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1"><a href="#fnref1">â†©</a></li>
<li id="fn2"><a href="#fnref2">â†©</a></li>
</ol>
</section>
</body>
</html>
