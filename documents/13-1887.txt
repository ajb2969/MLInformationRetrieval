   Method of steepest descent      Method of steepest descent   In mathematics, the method of steepest descent or stationary phase method or saddle-point method is an extension of Laplace's method for approximating an integral, where one deforms a contour integral in the complex plane to pass near a stationary point ( saddle point ), in roughly the direction of steepest descent or stationary phase. The saddle-point approximation is used with integrals in the complex plane, whereas Laplaceâ€™s method is used with real integrals.  The integral to be estimated is often of the form       âˆ«  C    f   (  z  )    e   Î»  g   (  z  )     d  z       subscript   C     f  z   superscript  e    Î»  g  z    d  z     \int_{C}f(z)e^{\lambda g(z)}dz   where C is a contour and Î» is large. One version of the method of steepest descent deforms the contour of integration so that it passes through a zero of the derivative gâ€² ( z ) in such a way that on the contour g is (approximately) real and has a maximum at the zero.  The method of steepest descent was first published by , who used it to estimate Bessel functions and pointed out that it occurred in the unpublished note  about hypergeometric functions. The contour of steepest descent has a minimax property, see .  described some other unpublished notes of Riemann, where he used this method to derive the Riemann-Siegel formula .  A simple estimate 1  Let and . If       M  =    sup   x  âˆˆ  C     â„œ   (   S   (  x  )    )     <  âˆž   ,        M    subscript  supremum    x  C        S  x              M=\sup_{x\in C}\Re(S(x))<\infty,     where    â„œ   (  â‹…  )       normal-â‹…    \Re(\cdot)   denotes the real part, and there exists a positive real number such that         âˆ«  C     |   f   (  x  )    e    Î»  0   S   (  x  )      |   d  x    <  âˆž   ,        subscript   C         f  x   superscript  e     subscript  Î»  0   S  x      d  x       \int_{C}\left|f(x)e^{\lambda_{0}S(x)}\right|dx<\infty,     then the following estimate holds:         |    âˆ«  C    f   (  x  )    e   Î»  S   (  x  )     d  x    |   â©½   const  â‹…   e   Î»  M      ,     âˆ€  Î»   âˆˆ  â„   ,   Î»  â©¾   Î»  0      .     formulae-sequence        subscript   C     f  x   superscript  e    Î»  S  x    d  x      normal-â‹…  const   superscript  e    Î»  M       formulae-sequence     for-all  Î»   â„     Î»   subscript  Î»  0       \left|\int_{C}f(x)e^{\lambda S(x)}dx\right|\leqslant\text{const}\cdot e^{%
 \lambda M},\qquad\forall\lambda\in\mathbb{R},\quad\lambda\geqslant\lambda_{0}.       Proof of the simple estimate        |     âˆ«  C     f   (  x  )    e   Î»  S   (  x  )     d  x    |        subscript   C     f  x   superscript  e    Î»  S  x    d  x      \displaystyle\left|\int_{C}f(x)e^{\lambda S(x)}dx\right|       The case of a single non-degenerate saddle point  Basic notions and notation  Let   x   x   x   be a complex   n   n   n   -dimensional vector, and          S   x  x   â€²â€²    (  x  )    â‰¡   (      âˆ‚  2   S    (  x  )      âˆ‚   x  i     âˆ‚   x  j      )    ,    1  â©½  i   ,   j  â©½  n     ,     formulae-sequence       subscript   superscript  S  â€²â€²     x  x    x         superscript   2   S   x        subscript  x  i       subscript  x  j        formulae-sequence    1  i     j  n      S^{\prime\prime}_{xx}(x)\equiv\left(\frac{\partial^{2}S(x)}{\partial x_{i}%
 \partial x_{j}}\right),\qquad 1\leqslant i,\,j\leqslant n,     denote the Hessian matrix for a function    S   (  x  )       S  x    S(x)   . If       ð‹   (  x  )    =   (    Ï†  1    (  x  )    ,    Ï†  2    (  x  )    ,  â€¦  ,    Ï†  k    (  x  )    )         ð‹  x       subscript  Ï†  1   x      subscript  Ï†  2   x   normal-â€¦     subscript  Ï†  k   x      \boldsymbol{\varphi}(x)=(\varphi_{1}(x),\varphi_{2}(x),\ldots,\varphi_{k}(x))     is a vector function, then its Jacobian matrix is defined as           ð‹  x  â€²    (  x  )    â‰¡   (     âˆ‚   Ï†  i     (  x  )     âˆ‚   x  j     )    ,   1  â©½  i  â©½  k    ,   1  â©½  j  â©½  n    .     formulae-sequence   formulae-sequence       superscript   subscript  ð‹  x   normal-â€²   x          subscript  Ï†  i    x      subscript  x  j          1  i       k         1  j       n      \boldsymbol{\varphi}_{x}^{\prime}(x)\equiv\left(\frac{\partial\varphi_{i}(x)}{%
 \partial x_{j}}\right),\qquad 1\leqslant i\leqslant k,\quad 1\leqslant j%
 \leqslant n.     A non-degenerate saddle point , , of a holomorphic function    S   (  z  )       S  z    S(z)   is a point where the function reaches an extremum (i.e., 0}} ) and has a non-vanishing determinant of the Hessian (i.e.,     det    S   z  z   â€²â€²    (   z  0   )     â‰   0           subscript   superscript  S  â€²â€²     z  z     superscript  z  0     0    \det S^{\prime\prime}_{zz}(z^{0})\neq 0   ).  The following is the main tool for constructing the asymptotics of integrals in the case of a non-degenerate saddle point:  Complex Morse Lemma  The Morse lemma for real-valued functions generalizes as follows 2 for holomorphic functions : near a non-degenerate saddle point of a holomorphic function    S   (  z  )       S  z    S(z)   , there exist coordinates in terms of which is exactly quadratic. To make this precise, let   S   S   S   be a holomorphic function with domain , and let in   W   W   W   be a non-degenerate saddle point of   S   S   S   , that is, 0}} and     det    S   z  z   â€²â€²    (   z  0   )     â‰   0           subscript   superscript  S  â€²â€²     z  z     superscript  z  0     0    \det S^{\prime\prime}_{zz}(z^{0})\neq 0   . Then there exist neighborhoods    U  âŠ‚  W      U  normal-âŠ‚  W    UâŠ‚W   of and of    w  =  0      w  0    w=0   , and a bijective holomorphic function    Ï†  :   V  â†’  U      normal-:  Ï†    V  normal-â†’  U     \mathbf{Ï†}:Vâ†’U   with  z 0 }} such that      âˆ€  w  âˆˆ  V  :  S   (  ð‹   (  w  )   )   =  S   (   z  0   )   +   1  2    âˆ‘   j  =  1   n    Î¼  j    w  j  2   ,  det   ð‹  w  â€²    (  0  )   =  1  ,     fragments  for-all  w   V  normal-:  italic-  S   fragments  normal-(  Ï†   fragments  normal-(  w  normal-)   normal-)    S   fragments  normal-(   superscript  z  0   normal-)      1  2    superscript   subscript     j  1    n    subscript  Î¼  j    superscript   subscript  w  j   2   normal-,    superscript   subscript  ð‹  w   normal-â€²    fragments  normal-(  0  normal-)    1  normal-,    \forall w\in V:\qquad S(\boldsymbol{\varphi}(w))=S(z^{0})+\frac{1}{2}\sum_{j=1%
 }^{n}\mu_{j}w_{j}^{2},\quad\det\boldsymbol{\varphi}_{w}^{\prime}(0)=1,     Here, the are the eigenvalues of the matrix     S   z  z   â€²â€²    (   z  0   )        superscript   subscript  S    z  z    â€²â€²    superscript  z  0     S_{zz}^{\prime\prime}(z^{0})   .  (Figure)  An illustration of Complex Morse Lemma     Proof of Complex Morse Lemma    The following proof is a straightforward generalization of the proof of the real Morse Lemma , which can be found in. 3 We begin by demonstrating   Auxiliary Statement. Let be holomorphic in a neighborhood of the origin and     f   (  0  )    =  0        f  0   0    f(0)=0   . Then in some neighborhood, there exist functions such that       f   (  z  )    =    âˆ‘   i  =  1   n     z  i    g  i    (  z  )      ,        f  z     superscript   subscript     i  1    n      subscript  z  i    subscript  g  i   z      f(z)=\sum_{i=1}^{n}z_{i}g_{i}(z),      where each is holomorphic and        g  i    (  0  )    =        âˆ‚  f    (  z  )     âˆ‚   z  i      |    z  =  0     .         subscript  g  i   0    evaluated-at        f   z      subscript  z  i       z  0      g_{i}(0)=\left.\tfrac{\partial f(z)}{\partial z_{i}}\right|_{z=0}.         Proof of Auxiliary Statement    From the identity        f   (  z  )    =    âˆ«  0  1     d   d  t    f   (   t   z  1    ,  â‹¯  ,   t   z  n    )   d  t    =       âˆ‘   i  =  1   n     z  i     âˆ«  0  1      âˆ‚  f    (  z  )     âˆ‚   z  i        |    z  =   (   t   z  1    ,  â€¦  ,   t   z  n    )     d  t    ,          f  z     superscript   subscript   0   1       d    d  t    f     t   subscript  z  1    normal-â‹¯    t   subscript  z  n     d  t            evaluated-at    superscript   subscript     i  1    n      subscript  z  i     superscript   subscript   0   1         f   z      subscript  z  i          z     t   subscript  z  1    normal-â€¦    t   subscript  z  n       d  t      f(z)=\int_{0}^{1}\frac{d}{dt}f\left(tz_{1},\cdots,tz_{n}\right)dt=\sum_{i=1}^{%
 n}z_{i}\int_{0}^{1}\left.\frac{\partial f(z)}{\partial z_{i}}\right|_{z=(tz_{1%
 },\ldots,tz_{n})}dt,     we conclude that        g  i    (  z  )    =       âˆ«  0  1      âˆ‚  f    (  z  )     âˆ‚   z  i      |    z  =   (   t   z  1    ,  â€¦  ,   t   z  n    )     d  t          subscript  g  i   z      evaluated-at    superscript   subscript   0   1         f   z      subscript  z  i        z     t   subscript  z  1    normal-â€¦    t   subscript  z  n       d  t     g_{i}(z)=\int_{0}^{1}\left.\frac{\partial f(z)}{\partial z_{i}}\right|_{z=(tz_%
 {1},\ldots,tz_{n})}dt     and         g  i    (  0  )    =       âˆ‚  f    (  z  )     âˆ‚   z  i     |    z  =  0     .         subscript  g  i   0    evaluated-at        f   z      subscript  z  i       z  0      g_{i}(0)=\left.\frac{\partial f(z)}{\partial z_{i}}\right|_{z=0}.       Without loss of generality, we translate the origin to , such that 0}} and     S   (  0  )    =  0        S  0   0    S(0)=0   . Using the Auxiliary Statement, we have        S   (  z  )    =    âˆ‘   i  =  1   n     z  i    g  i    (  z  )      .        S  z     superscript   subscript     i  1    n      subscript  z  i    subscript  g  i   z      S(z)=\sum_{i=1}^{n}z_{i}g_{i}(z).   Since the origin is a saddle point,            âˆ‚  S    (  z  )     âˆ‚   z  i     |    z  =  0    =    g  i    (  0  )    =  0   ,         evaluated-at        S   z      subscript  z  i       z  0       subscript  g  i   0        0     \left.\frac{\partial S(z)}{\partial z_{i}}\right|_{z=0}=g_{i}(0)=0,   we can also apply the Auxiliary Statement to the functions and obtain        S   (  z  )    =    âˆ‘    i  ,  j   =  1   n     z  i    z  j    h   i  j     (  z  )      .        S  z     superscript   subscript      i  j   1    n      subscript  z  i    subscript  z  j    subscript  h    i  j    z      S(z)=\sum_{i,j=1}^{n}z_{i}z_{j}h_{ij}(z).      (1)   Recall that an arbitrary matrix   A   A   A   can be represented as a sum of symmetric and anti-symmetric matrices,         A   i  j    =    A   i  j    (  s  )    +   A   i  j    (  a  )      ,     A   i  j    (  s  )    =     1  2     (    A   i  j    +   A   j  i     )     ,    A   i  j    (  a  )    =     1  2     (    A   i  j    -   A   j  i     )       .     formulae-sequence     subscript  A    i  j       superscript   subscript  A    i  j    s    superscript   subscript  A    i  j    a      formulae-sequence     superscript   subscript  A    i  j    s       1  2      subscript  A    i  j     subscript  A    j  i          superscript   subscript  A    i  j    a       1  2      subscript  A    i  j     subscript  A    j  i          A_{ij}=A_{ij}^{(s)}+A_{ij}^{(a)},\qquad A_{ij}^{(s)}=\tfrac{1}{2}\left(A_{ij}+%
 A_{ji}\right),\qquad A_{ij}^{(a)}=\tfrac{1}{2}\left(A_{ij}-A_{ji}\right).   The contraction of any symmetric matrix B with an arbitrary matrix   A   A   A   is         âˆ‘   i  ,  j      B   i  j     A   i  j      =    âˆ‘   i  ,  j      B   i  j     A   i  j    (  s  )       ,        subscript    i  j       subscript  B    i  j     subscript  A    i  j        subscript    i  j       subscript  B    i  j     superscript   subscript  A    i  j    s       \sum_{i,j}B_{ij}A_{ij}=\sum_{i,j}B_{ij}A_{ij}^{(s)},      (2)   i.e., the anti-symmetric component of   A   A   A   does not contribute because        âˆ‘   i  ,  j      B   i  j     C   i  j      =    âˆ‘   i  ,  j      B   j  i     C   j  i      =   -    âˆ‘   i  ,  j      B   i  j     C   i  j       =  0.          subscript    i  j       subscript  B    i  j     subscript  C    i  j        subscript    i  j       subscript  B    j  i     subscript  C    j  i               subscript    i  j       subscript  B    i  j     subscript  C    i  j            0.     \sum_{i,j}B_{ij}C_{ij}=\sum_{i,j}B_{ji}C_{ji}=-\sum_{i,j}B_{ij}C_{ij}=0.   Thus, in equation (1) can be assumed to be symmetric with respect to the interchange of the indices   i   i   i   and   j   j   j   . Note that             âˆ‚  2   S    (  z  )      âˆ‚   z  i     âˆ‚   z  j      |    z  =  0    =   2   h   i  j     (  0  )     ;       evaluated-at        superscript   2   S   z        subscript  z  i       subscript  z  j        z  0      2   subscript  h    i  j    0     \left.\frac{\partial^{2}S(z)}{\partial z_{i}\partial z_{j}}\right|_{z=0}=2h_{%
 ij}(0);   hence, because the origin is a non-degenerate saddle point.  Let us show by induction that there are local coordinates ( u 1 , ... u n ), z {{=}} Ïˆ ( y ), 0 {{=}} Ïˆ (0)}} , such that        S   (   ð   (  u  )    )    =    âˆ‘   i  =  1   n    u  i  2     .        S    ð  u      superscript   subscript     i  1    n    superscript   subscript  u  i   2      S(\boldsymbol{\psi}(u))=\sum_{i=1}^{n}u_{i}^{2}.      (3)   First, assume that there exist local coordinates ( y 1 , ... y n ), z {{=}} Ï† ( y ), 0 {{=}} Ï† (0)}} , such that        S   (   Ï•   (  y  )    )    =    y  1  2   +  â‹¯  +   y   r  -  1   2   +    âˆ‘    i  ,  j   =  r   n     y  i    y  j    H   i  j     (  y  )       ,        S    bold-italic-Ï•  y       superscript   subscript  y  1   2   normal-â‹¯   superscript   subscript  y    r  1    2     superscript   subscript      i  j   r    n      subscript  y  i    subscript  y  j    subscript  H    i  j    y       S(\boldsymbol{\phi}(y))=y_{1}^{2}+\cdots+y_{r-1}^{2}+\sum_{i,j=r}^{n}y_{i}y_{j%
 }H_{ij}(y),      (4)   where is symmetric due to equation (2). By a linear change of the variables , we can assure that . From the chain rule , we have          âˆ‚  2   S    (   Ï•   (  y  )    )      âˆ‚   y  i     âˆ‚   y  j      =        âˆ‘    l  ,  k   =  1   n       âˆ‚  2   S    (  z  )      âˆ‚   z  k     âˆ‚   z  l       |    z  =   Ï•   (  y  )        âˆ‚   Ï•  k     âˆ‚   y  i       âˆ‚   Ï•  l     âˆ‚   y  j      +       âˆ‘   k  =  1   n      âˆ‚  S    (  z  )     âˆ‚   z  k      |    z  =   Ï•   (  y  )         âˆ‚  2    Ï•  k      âˆ‚   y  i     âˆ‚   y  j                  superscript   2   S     bold-italic-Ï•  y         subscript  y  i       subscript  y  j           evaluated-at    superscript   subscript      l  k   1    n         superscript   2   S   z        subscript  z  k       subscript  z  l         z    bold-italic-Ï•  y          subscript  Ï•  k       subscript  y  i          subscript  Ï•  l       subscript  y  j         evaluated-at    superscript   subscript     k  1    n         S   z      subscript  z  k        z    bold-italic-Ï•  y         superscript   2    subscript  Ï•  k         subscript  y  i       subscript  y  j          \frac{\partial^{2}S(\boldsymbol{\phi}(y))}{\partial y_{i}\partial y_{j}}=\sum_%
 {l,k=1}^{n}\left.\frac{\partial^{2}S(z)}{\partial z_{k}\partial z_{l}}\right|_%
 {z=\boldsymbol{\phi}(y)}\frac{\partial\phi_{k}}{\partial y_{i}}\frac{\partial%
 \phi_{l}}{\partial y_{j}}+\sum_{k=1}^{n}\left.\frac{\partial S(z)}{\partial z_%
 {k}}\right|_{z=\boldsymbol{\phi}(y)}\frac{\partial^{2}\phi_{k}}{\partial y_{i}%
 \partial y_{j}}     Therefore:          S   y  y   â€²â€²    (   Ï•   (  0  )    )    =    Ï•  y  â€²     (  0  )   T    S   z  z   â€²â€²    (  0  )    Ï•  y  â€²    (  0  )     ,    det    Ï•  y  â€²    (  0  )     â‰   0    ;     formulae-sequence       subscript   superscript  S  â€²â€²     y  y      bold-italic-Ï•  0       subscript   superscript  bold-italic-Ï•  normal-â€²   y    superscript  0  T    subscript   superscript  S  â€²â€²     z  z    0   subscript   superscript  bold-italic-Ï•  normal-â€²   y   0           subscript   superscript  bold-italic-Ï•  normal-â€²   y   0    0     S^{\prime\prime}_{yy}(\boldsymbol{\phi}(0))=\boldsymbol{\phi}^{\prime}_{y}(0)^%
 {T}S^{\prime\prime}_{zz}(0)\boldsymbol{\phi}^{\prime}_{y}(0),\qquad\det%
 \boldsymbol{\phi}^{\prime}_{y}(0)\neq 0;     whence,       0  â‰    det    S   y  y   â€²â€²    (   Ï•   (  0  )    )     =    2   r  -  1     det   (   2   H   i  j     (  0  )    )      .        0       subscript   superscript  S  â€²â€²     y  y      bold-italic-Ï•  0             superscript  2    r  1        2   subscript  H    i  j    0        0\neq\det S^{\prime\prime}_{yy}(\boldsymbol{\phi}(0))=2^{r-1}\det\left(2H_{ij}%
 (0)\right).     The matrix can be recast in the Jordan normal form :  LJL âˆ’1 }} , were   L   L   L   gives the desired non-singular linear transformation and the diagonal of   J   J   J   contains non-zero eigenvalues of . If then, due to continuity of , it must be also non-vanishing in some neighborhood of the origin. Having introduced       H  ~    i  j     (  y  )    =      H   i  j     (  y  )    /   H   r  r      (  y  )           subscript   normal-~  H     i  j    y          subscript  H    i  j    y    subscript  H    r  r     y     \tilde{H}_{ij}(y)=H_{ij}(y)/H_{rr}(y)   , we write       S   (   ð‹   (  y  )    )    =         S    ð‹  y    absent    \displaystyle S(\boldsymbol{\varphi}(y))=     Motivated by the last expression, we introduce new coordinates      z  =   Î·   (  x  )     ,   0  =   Î·   (  0  )      ,     formulae-sequence    z    Î·  x      0    Î·  0      z=\mathbf{Î·}(x),0=\mathbf{Î·}(0),            x  r   =      H   r  r     (  y  )      (    y  r   +    âˆ‘   j  =   r  +  1    n     y  j     H  ~    r  j     (  y  )      )     ,     x  j   =   y  j    ,    âˆ€  j   â‰   r     .     formulae-sequence     subscript  x  r          subscript  H    r  r    y       subscript  y  r     superscript   subscript     j    r  1     n      subscript  y  j    subscript   normal-~  H     r  j    y        formulae-sequence     subscript  x  j    subscript  y  j       for-all  j   r      x_{r}=\sqrt{H_{rr}(y)}\left(y_{r}+\sum_{j=r+1}^{n}y_{j}\tilde{H}_{rj}(y)\right%
 ),\qquad x_{j}=y_{j},\quad\forall j\neq r.     The change of the variables    y  â†”  x      y  normal-â†”  x    yâ†”x   is locally invertible since the corresponding Jacobian is non-zero,           âˆ‚   x  r     âˆ‚   y  k     |    y  =  0    =      H   r  r     (  0  )      [    Î´   r  ,  k    +    âˆ‘   j  =   r  +  1    n     Î´   j  ,  k      H  ~    j  r     (  0  )      ]     .       evaluated-at       subscript  x  r       subscript  y  k       y  0           subscript  H    r  r    0     delimited-[]     subscript  Î´   r  k      superscript   subscript     j    r  1     n      subscript  Î´   j  k     subscript   normal-~  H     j  r    0         \left.\frac{\partial x_{r}}{\partial y_{k}}\right|_{y=0}=\sqrt{H_{rr}(0)}\left%
 [\delta_{r,\,k}+\sum_{j=r+1}^{n}\delta_{j,\,k}\tilde{H}_{jr}(0)\right].     Therefore,        S   (   ðœ¼   (  x  )    )    =    x  1  2   +  â‹¯  +   x  r  2   +    âˆ‘    i  ,  j   =   r  +  1    n     x  i    x  j    W   i  j     (  x  )       .        S    ðœ¼  x       superscript   subscript  x  1   2   normal-â‹¯   superscript   subscript  x  r   2     superscript   subscript      i  j     r  1     n      subscript  x  i    subscript  x  j    subscript  W    i  j    x       S(\boldsymbol{\eta}(x))={x}_{1}^{2}+\cdots+{x}_{r}^{2}+\sum_{i,j=r+1}^{n}{x}_{%
 i}{x}_{j}W_{ij}(x).      (5)   Comparing equations (4) and (5), we conclude that equation (3) is verified. Denoting the eigenvalues of     S   z  z   â€²â€²    (  0  )        subscript   superscript  S  â€²â€²     z  z    0    S^{\prime\prime}_{zz}(0)   by , equation (3) can be rewritten as        S   (   ð‹   (  w  )    )    =    1  2     âˆ‘   j  =  1   n     Î¼  j    w  j  2       .        S    ð‹  w        1  2     superscript   subscript     j  1    n      subscript  Î¼  j    superscript   subscript  w  j   2        S(\boldsymbol{\varphi}(w))=\frac{1}{2}\sum_{j=1}^{n}\mu_{j}w_{j}^{2}.      (6)   Therefore,         S   w  w   â€²â€²    (   ð‹   (  0  )    )    =    ð‹  w  â€²     (  0  )   T    S   z  z   â€²â€²    (  0  )    ð‹  w  â€²    (  0  )     ,         subscript   superscript  S  â€²â€²     w  w      ð‹  0       subscript   superscript  ð‹  normal-â€²   w    superscript  0  T    subscript   superscript  S  â€²â€²     z  z    0   subscript   superscript  ð‹  normal-â€²   w   0     S^{\prime\prime}_{ww}(\boldsymbol{\varphi}(0))=\boldsymbol{\varphi}^{\prime}_{%
 w}(0)^{T}S^{\prime\prime}_{zz}(0)\boldsymbol{\varphi}^{\prime}_{w}(0),      (7)   From equation (6), it follows that     det    S   w  w   â€²â€²    (   ð‹   (  0  )    )     =    Î¼  1   â‹¯   Î¼  n             subscript   superscript  S  â€²â€²     w  w      ð‹  0        subscript  Î¼  1   normal-â‹¯   subscript  Î¼  n      \det S^{\prime\prime}_{ww}(\boldsymbol{\varphi}(0))=\mu_{1}\cdots\mu_{n}   . The Jordan normal form of     S   z  z   â€²â€²    (  0  )        subscript   superscript  S  â€²â€²     z  z    0    S^{\prime\prime}_{zz}(0)   reads      S   z  z   â€²â€²    (  0  )    =   P   J  z    P   -  1            subscript   superscript  S  â€²â€²     z  z    0     P   subscript  J  z    superscript  P    1       S^{\prime\prime}_{zz}(0)=PJ_{z}P^{-1}   , where is an upper diagonal matrix containing the eigenvalues and    d  e  t  P  â‰   0      d  e  t  P  normal-â‰   0    detPâ‰ 0   ; hence,     det    S   z  z   â€²â€²    (  0  )     =    Î¼  1   â‹¯   Î¼  n             subscript   superscript  S  â€²â€²     z  z    0       subscript  Î¼  1   normal-â‹¯   subscript  Î¼  n      \det S^{\prime\prime}_{zz}(0)=\mu_{1}\cdots\mu_{n}   . We obtain from equation (7)       det    S   w  w   â€²â€²    (   ð‹   (  0  )    )     =     [   det    ð‹  w  â€²    (  0  )     ]   2    det    S   z  z   â€²â€²    (  0  )      âŸ¹   det    ð‹  w  â€²    (  0  )     =   Â±  1.              subscript   superscript  S  â€²â€²     w  w      ð‹  0        superscript   delimited-[]       subscript   superscript  ð‹  normal-â€²   w   0     2        subscript   superscript  S  â€²â€²     z  z    0       normal-âŸ¹         subscript   superscript  ð‹  normal-â€²   w   0          plus-or-minus  1.      \det S^{\prime\prime}_{ww}(\boldsymbol{\varphi}(0))=\left[\det\boldsymbol{%
 \varphi}^{\prime}_{w}(0)\right]^{2}\det S^{\prime\prime}_{zz}(0)%
 \Longrightarrow\det\boldsymbol{\varphi}^{\prime}_{w}(0)=\pm 1.     If     det    ð‹  w  â€²    (  0  )     =   -  1            subscript   superscript  ð‹  normal-â€²   w   0      1     \det\boldsymbol{\varphi}^{\prime}_{w}(0)=-1   , then interchanging two variables assures that     det    ð‹  w  â€²    (  0  )     =   +  1            subscript   superscript  ð‹  normal-â€²   w   0      1     \det\boldsymbol{\varphi}^{\prime}_{w}(0)=+1   .    The asymptotic expansion in the case of a single non-degenerate saddle point  Assume       f   (  z  )       f  z    f(z)   and    S   (  z  )       S  z    S(z)   are holomorphic functions in an open , bounded , and simply connected set such that the Î© x âˆ© R n }} is connected ;      â„œ   (   S   (  z  )    )         S  z     \Re(S(z))   has a single maximum      max   z  âˆˆ   I  x      â„œ   (   S   (  z  )    )     =   â„œ   (   S   (   x  0   )    )          subscript     z   subscript  I  x         S  z         S   superscript  x  0       \max_{z\in I_{x}}\Re(S(z))=\Re(S(x^{0}))   for exactly one point ;  is a non-degenerate saddle point (i.e., 0}} and     det    S   x  x   â€²â€²    (   x  0   )     â‰   0           subscript   superscript  S  â€²â€²     x  x     superscript  x  0     0    \det S^{\prime\prime}_{xx}(x^{0})\neq 0   ).   Then, the following asymptotic holds         I   (  Î»  )    â‰¡    âˆ«   I  x     f   (  x  )    e   Î»  S   (  x  )     d  x    =     (    2  Ï€   Î»   )    n  2     e   Î»  S   (   x  0   )      (    f   (   x  0   )    +   O   (   Î»   -  1    )     )     âˆ   j  =  1   n     (   -   Î¼  j    )    -   1  2        ,   Î»  â†’  âˆž    ,     formulae-sequence        I  Î»     subscript    subscript  I  x      f  x   superscript  e    Î»  S  x    d  x            superscript      2  Ï€   Î»     n  2     superscript  e    Î»  S   superscript  x  0         f   superscript  x  0      O   superscript  Î»    1        superscript   subscript  product    j  1    n    superscript     subscript  Î¼  j        1  2          normal-â†’  Î»      I(\lambda)\equiv\int_{I_{x}}f(x)e^{\lambda S(x)}dx=\left(\frac{2\pi}{\lambda}%
 \right)^{\frac{n}{2}}e^{\lambda S(x^{0})}\left(f(x^{0})+O\left(\lambda^{-1}%
 \right)\right)\prod_{j=1}^{n}(-\mu_{j})^{-\frac{1}{2}},\qquad\lambda\to\infty,      (8)   where are eigenvalues of the Hessian      S   x  x   â€²â€²    (   x  0   )        subscript   superscript  S  â€²â€²     x  x     superscript  x  0     S^{\prime\prime}_{xx}(x^{0})   and     (   -   Î¼  j    )    -   1  2       superscript     subscript  Î¼  j        1  2      (-\mu_{j})^{-\frac{1}{2}}   are defined with arguments        |   arg    -   Î¼  j      |   <    Ï€  4     .               subscript  Î¼  j         Ï€  4     \left|\arg\sqrt{-\mu_{j}}\right|<\tfrac{\pi}{4}.      (9)   This statement is a special case of more general results presented in Fedoryuk (1987). 4    Derivation of equation (8)    (Figure)  An illustration to the derivation of equation (8)   First, we deform the contour into a new contour     I  x  â€²   âŠ‚   Î©  x        subscript   superscript  I  normal-â€²   x    subscript  normal-Î©  x     I^{\prime}_{x}\subset\Omega_{x}   passing through the saddle point and sharing the boundary with . This deformation does not change the value of the integral    I   (  Î»  )       I  Î»    I(Î»)   . We employ the Complex Morse Lemma to change the variables of integration. According to the lemma, the function    Ï†   (  w  )       Ï†  w    \mathbf{Ï†}(w)   maps a neighborhood onto a neighborhood containing the origin. The integral    I   (  Î»  )       I  Î»    I(Î»)   can be split into two:  I 0 ( Î» ) + I 1 ( Î» )}} , where is the integral over    U  âˆ©   I  x  â€²       U   subscript   superscript  I  normal-â€²   x     U\cap I^{\prime}_{x}   , while is over     I  x  â€²   âˆ–   (   U  âˆ©   I  x  â€²    )        subscript   superscript  I  normal-â€²   x     U   subscript   superscript  I  normal-â€²   x      I^{\prime}_{x}\setminus(U\cap I^{\prime}_{x})   (i.e., the remaining part of the contour ). Since the latter region does not contain the saddle point , the value of is exponentially smaller than as    Î»  â†’  âˆž      Î»  normal-â†’  normal-âˆž    Î»â†’âˆž   ; 5 thus, is ignored. Introducing the contour such that     U  âˆ©   I  x  â€²    =   ð‹   (   I  w   )          U   subscript   superscript  I  normal-â€²   x      ð‹   subscript  I  w      U\cap I^{\prime}_{x}=\boldsymbol{\varphi}(I_{w})   , we have         I  0    (  Î»  )    =    e   Î»  S   (   x  0   )       âˆ«   I  w     f   [   ð‹   (  w  )    ]    exp   (   Î»    âˆ‘   j  =  1   n       Î¼  j   2     w  j  2      )     |   det    ð‹  w  â€²    (  w  )     |   d  w      .         subscript  I  0   Î»      superscript  e    Î»  S   superscript  x  0       subscript    subscript  I  w      f   delimited-[]    ð‹  w        Î»    superscript   subscript     j  1    n        subscript  Î¼  j   2    superscript   subscript  w  j   2              superscript   subscript  ð‹  w   normal-â€²   w     d  w       I_{0}(\lambda)=e^{\lambda S(x^{0})}\int_{I_{w}}f[\boldsymbol{\varphi}(w)]\exp%
 \left(\lambda\sum_{j=1}^{n}\tfrac{\mu_{j}}{2}w_{j}^{2}\right)\left|\det%
 \boldsymbol{\varphi}_{w}^{\prime}(w)\right|dw.      (10)   Recalling that  Ï† (0)}} as well as     det    ð‹  w  â€²    (  0  )     =  1           superscript   subscript  ð‹  w   normal-â€²   0    1    \det\boldsymbol{\varphi}_{w}^{\prime}(0)=1   , we expand the pre-exponential function into a Taylor series and keep just the leading zero-order term         I  0    (  Î»  )    â‰ˆ   f   (   x  0   )    e   Î»  S   (   x  0   )       âˆ«   ð‘  n      exp   (   Î»    âˆ‘   j  =  1   n       Î¼  j   2     w  j  2      )    d  w     =   f   (   x  0   )    e   Î»  S   (   x  0   )       âˆ   j  =  1   n     âˆ«   -  âˆž   âˆž     e    1  2   Î»   Î¼  j    y  2     d  y       .           subscript  I  0   Î»     f   superscript  x  0    superscript  e    Î»  S   superscript  x  0       subscript    superscript  ð‘  n          Î»    superscript   subscript     j  1    n        subscript  Î¼  j   2    superscript   subscript  w  j   2       d  w            f   superscript  x  0    superscript  e    Î»  S   superscript  x  0       superscript   subscript  product    j  1    n     superscript   subscript             superscript  e      1  2   Î»   subscript  Î¼  j    superscript  y  2     d  y         I_{0}(\lambda)\approx f(x^{0})e^{\lambda S(x^{0})}\int_{\mathbf{R}^{n}}\exp%
 \left(\lambda\sum_{j=1}^{n}\tfrac{\mu_{j}}{2}w_{j}^{2}\right)dw=f(x^{0})e^{%
 \lambda S(x^{0})}\prod_{j=1}^{n}\int_{-\infty}^{\infty}e^{\frac{1}{2}\lambda%
 \mu_{j}y^{2}}dy.      (11)   Here, we have substituted the integration region by because both contain the origin, which is a saddle point, hence they are equal up to an exponentially small term. 6 The integrals in the r.h.s. of equation (11) can be expressed as        â„  j   =    âˆ«   -  âˆž   âˆž     e    1  2   Î»   Î¼  j    y  2     d  y    =   2    âˆ«  0  âˆž     e   -    1  2   Î»    (     -   Î¼  j     y   )   2      d  y     =   2    âˆ«  0  âˆž     e   -    1  2   Î»    |    -   Î¼  j     |   2    y  2    exp   (   2  i   arg    -   Î¼  j       )       d  y      .         subscript  â„  j     superscript   subscript             superscript  e      1  2   Î»   subscript  Î¼  j    superscript  y  2     d  y           2    superscript   subscript   0        superscript  e        1  2   Î»   superscript         subscript  Î¼  j     y   2      d  y            2    superscript   subscript   0        superscript  e        1  2   Î»   superscript         subscript  Î¼  j      2    superscript  y  2       2  i         subscript  Î¼  j           d  y        \mathcal{I}_{j}=\int_{-\infty}^{\infty}e^{\frac{1}{2}\lambda\mu_{j}y^{2}}dy=2%
 \int_{0}^{\infty}e^{-\frac{1}{2}\lambda\left(\sqrt{-\mu_{j}}y\right)^{2}}dy=2%
 \int_{0}^{\infty}e^{-\frac{1}{2}\lambda\left|\sqrt{-\mu_{j}}\right|^{2}y^{2}%
 \exp\left(2i\arg\sqrt{-\mu_{j}}\right)}dy.      (12)   From this representation, we conclude that condition (9) must be satisfied in order for the r.h.s. and l.h.s. of equation (12) to coincide. According to assumption 2,    â„œ   (    S   x  x   â€²â€²    (   x  0   )    )          superscript   subscript  S    x  x    â€²â€²    superscript  x  0      \Re\left(S_{xx}^{\prime\prime}(x^{0})\right)   is a negatively defined quadratic form (viz.,     â„œ   (   Î¼  j   )    <  0         subscript  Î¼  j    0    \Re(\mu_{j})<0   ) implying the existence of the integral    â„  j     subscript  â„  j    \mathcal{I}_{j}   , which is readily calculated        â„  j   =    2     -   Î¼  j      Î»       âˆ«  0  âˆž     e   -    Î¾  2   2     d  Î¾     =      2  Ï€   Î»      (   -   Î¼  j    )    -   1  2       .         subscript  â„  j       2         subscript  Î¼  j       Î»       superscript   subscript   0        superscript  e       superscript  Î¾  2   2     d  Î¾                  2  Ï€   Î»     superscript     subscript  Î¼  j        1  2         \mathcal{I}_{j}=\frac{2}{\sqrt{-\mu_{j}}\sqrt{\lambda}}\int_{0}^{\infty}e^{-%
 \frac{\xi^{2}}{2}}d\xi=\sqrt{\frac{2\pi}{\lambda}}(-\mu_{j})^{-\frac{1}{2}}.       Equation (8) can also be written as        I   (  Î»  )    =     (    2  Ï€   Î»   )    n  2     e   Î»  S   (   x  0   )       (   det   (   -    S   x  x   â€²â€²    (   x  0   )     )    )    -   1  2      (    f   (   x  0   )    +   O   (   Î»   -  1    )     )     ,        I  Î»      superscript      2  Ï€   Î»     n  2     superscript  e    Î»  S   superscript  x  0      superscript         superscript   subscript  S    x  x    â€²â€²    superscript  x  0          1  2         f   superscript  x  0      O   superscript  Î»    1         I(\lambda)=\left(\frac{2\pi}{\lambda}\right)^{\frac{n}{2}}e^{\lambda S(x^{0})}%
 \left(\det(-S_{xx}^{\prime\prime}(x^{0}))\right)^{-\frac{1}{2}}\left(f(x^{0})+%
 O\left(\lambda^{-1}\right)\right),      (13)   where the branch of       det   (   -    S   x  x   â€²â€²    (   x  0   )     )               superscript   subscript  S    x  x    â€²â€²    superscript  x  0        \sqrt{\det\left(-S_{xx}^{\prime\prime}(x^{0})\right)}     is selected as follows       (   det   (   -    S   x  x   â€²â€²    (   x  0   )     )    )    -   1  2       superscript         superscript   subscript  S    x  x    â€²â€²    superscript  x  0          1  2      \displaystyle\left(\det\left(-S_{xx}^{\prime\prime}(x^{0})\right)\right)^{-%
 \frac{1}{2}}     Consider important special cases:   If    S   (  x  )       S  x    S(x)   is real valued for real   x   x   x   and in (aka, the multidimensional Laplace method ), then 7          Ind   (   -    S   x  x   â€²â€²    (   x  0   )     )    =  0.        Ind       superscript   subscript  S    x  x    â€²â€²    superscript  x  0      0.    \text{Ind}\left(-S_{xx}^{\prime\prime}(x^{0})\right)=0.         If    S   (  x  )       S  x    S(x)   is purely imaginary for real   x   x   x   (i.e.,     â„œ   (   S   (  x  )    )    =  0          S  x    0    \Re(S(x))=0   for all   x   x   x   in ) and in (aka, the multidimensional stationary phase method ), 8 then 9           Ind   (   -    S   x  x   â€²â€²    (   x  0   )     )    =    Ï€  4   sign   S   x  x   â€²â€²    (   x  0   )     ,        Ind       superscript   subscript  S    x  x    â€²â€²    superscript  x  0          Ï€  4   sign   superscript   subscript  S    x  x    â€²â€²    subscript  x  0      \text{Ind}\left(-S_{xx}^{\prime\prime}(x^{0})\right)=\frac{\pi}{4}\text{sign }%
 S_{xx}^{\prime\prime}(x_{0}),         where    sign   S   x  x   â€²â€²    (   x  0   )       sign   superscript   subscript  S    x  x    â€²â€²    subscript  x  0     \text{sign }S_{xx}^{\prime\prime}(x_{0})   denotes the signature of matrix      S   x  x   â€²â€²    (   x  0   )        superscript   subscript  S    x  x    â€²â€²    subscript  x  0     S_{xx}^{\prime\prime}(x_{0})   , which equals to the number of negative eigenvalues minus the number of positive ones. It is noteworthy that in applications of the stationary phase method to the multidimensional WKB approximation in quantum mechanics (as well as in optics),    I  n  d      I  n  d    Ind   is related to the Maslov index see, e.g.,  and .   The case of multiple non-degenerate saddle points  If the function    S   (  x  )       S  x    S(x)   has multiple isolated non-degenerate saddle points, i.e.,          âˆ‡  S    (   x   (  k  )    )    =  0   ,     det    S   x  x   â€²â€²    (   x   (  k  )    )     â‰   0   ,    x   (  k  )    âˆˆ   Î©  x   (  k  )       ,     formulae-sequence       normal-âˆ‡  S    superscript  x  k    0    formulae-sequence         subscript   superscript  S  â€²â€²     x  x     superscript  x  k     0      superscript  x  k    superscript   subscript  normal-Î©  x   k       \nabla S\left(x^{(k)}\right)=0,\quad\det S^{\prime\prime}_{xx}\left(x^{(k)}%
 \right)\neq 0,\quad x^{(k)}\in\Omega_{x}^{(k)},     where       {   Î©  x   (  k  )    }    k  =  1   K     superscript   subscript    superscript   subscript  normal-Î©  x   k      k  1    K    \left\{\Omega_{x}^{(k)}\right\}_{k=1}^{K}     is an open cover of , then the calculation of the integral asymptotic is reduced to the case of a singe saddle point by employing the partition of unity . The partition of unity allows us to construct a set of continuous functions such that        âˆ‘   k  =  1   K      Ï  k    (  x  )        superscript   subscript     k  1    K      subscript  Ï  k   x     \displaystyle\sum_{k=1}^{K}\rho_{k}(x)     Whence,         âˆ«    I  x   âŠ‚   Î©  x      f   (  x  )    e   Î»  S   (  x  )     d  x    â‰¡    âˆ‘   k  =  1   K     âˆ«    I  x   âŠ‚   Î©  x       Ï  k    (  x  )   f   (  x  )    e   Î»  S   (  x  )     d  x      .        subscript      subscript  I  x    subscript  normal-Î©  x       f  x   superscript  e    Î»  S  x    d  x      superscript   subscript     k  1    K     subscript      subscript  I  x    subscript  normal-Î©  x        subscript  Ï  k   x  f  x   superscript  e    Î»  S  x    d  x       \int_{I_{x}\subset\Omega_{x}}f(x)e^{\lambda S(x)}dx\equiv\sum_{k=1}^{K}\int_{I%
 _{x}\subset\Omega_{x}}\rho_{k}(x)f(x)e^{\lambda S(x)}dx.     Therefore as    Î»  â†’  âˆž      Î»  normal-â†’  normal-âˆž    Î»â†’âˆž   we have:         âˆ‘   k  =  1   K     âˆ«   a neighborhood of   x   (  k  )       f   (  x  )    e   Î»  S   (  x  )     d  x     =     (    2  Ï€   Î»   )    n  2      âˆ‘   k  =  1   K     e   Î»  S   (   x   (  k  )    )       (   det   (   -    S   x  x   â€²â€²    (   x   (  k  )    )     )    )    -   1  2     f   (   x   (  k  )    )       ,        superscript   subscript     k  1    K     subscript     a neighborhood of   superscript  x  k       f  x   superscript  e    Î»  S  x    d  x        superscript      2  Ï€   Î»     n  2      superscript   subscript     k  1    K      superscript  e    Î»  S   superscript  x  k      superscript         superscript   subscript  S    x  x    â€²â€²    superscript  x  k          1  2     f   superscript  x  k        \sum_{k=1}^{K}\int_{\text{a neighborhood of }x^{(k)}}f(x)e^{\lambda S(x)}dx=%
 \left(\frac{2\pi}{\lambda}\right)^{\frac{n}{2}}\sum_{k=1}^{K}e^{\lambda S\left%
 (x^{(k)}\right)}\left(\det\left(-S_{xx}^{\prime\prime}\left(x^{(k)}\right)%
 \right)\right)^{-\frac{1}{2}}f\left(x^{(k)}\right),     where equation (13) was utilized at the last stage, and the pre-exponential function    f   (  x  )       f  x    f(x)   at least must be continuous.  The other cases  When 0}} and     det    S   z  z   â€²â€²    (   z  0   )     =  0           subscript   superscript  S  â€²â€²     z  z     superscript  z  0     0    \det S^{\prime\prime}_{zz}(z^{0})=0   , the point is called a degenerate saddle point of a function    S   (  z  )       S  z    S(z)   .  Calculating the asymptotic of       âˆ«   f   (  x  )    e   Î»  S   (  x  )     d  x    ,        f  x   superscript  e    Î»  S  x    d  x     \int f(x)e^{\lambda S(x)}dx,     when     Î»  â†’  âˆž   ,   f   (  x  )         Î»  normal-â†’  normal-âˆž     f  x     Î»â†’âˆž,f(x)   is continuous, and    S   (  z  )       S  z    S(z)   has a degenerate saddle point, is a very rich problem, whose solution heavily relies on the catastrophe theory . Here, the catastrophe theory replaces the Morse lemma , valid only in the non-degenerate case, to transform the function    S   (  z  )       S  z    S(z)   into one of the multitude of canonical representations. For further details see, e.g.,  and .  Integrals with degenerate saddle points naturally appear in many applications including optical caustics and the multidimensional WKB approximation in quantum mechanics.  The other cases such as, e.g.,    f   (  x  )       f  x    f(x)   and/or    S   (  x  )       S  x    S(x)   are discontinuous or when an extremum of    S   (  x  )       S  x    S(x)   lies at the integration region's boundary, require special care (see, e.g.,  and ).  Extensions and generalizations  An extension of the steepest descent method is the so-called nonlinear stationary phase/steepest descent method . Here, instead of integrals, one needs to evaluate asymptotically solutions of Riemannâ€“Hilbert factorization problems.  Given a contour C in the complex sphere , a function f defined on that contour and a special point, say infinity, one seeks a function M holomorphic away from the contour C , with prescribed jump across C , and with a given normalization at infinity. If f and hence M are matrices rather than scalars this is a problem that in general does not admit an explicit solution.  An asymptotic evaluation is then possible along the lines of the linear stationary phase/steepest descent method. The idea is to reduce asymptotically the solution of the given Riemannâ€“Hilbert problem to that of a simpler, explicitly solvable, Riemannâ€“Hilbert problem. Cauchy's theorem is used to justify deformations of the jump contour.  The nonlinear stationary phase was introduced by Deift and Zhou in 1993, based on earlier work of the Russian mathematician Alexander Its. A (properly speaking) nonlinear steepest descent method was introduced by Kamvissis, K. McLaughlin and P. Miller in 2003, based on previous work of Lax, Levermore, Deift, Venakides and Zhou. As in the linear case, steepest descent contours solve a min-max problem.  The nonlinear stationary phase/steepest descent method has applications to the theory of soliton equations and integrable models , random matrices and combinatorics .  See also  Pearcey integral  Notes  References     English translation in   .   .   .   [in Russian].   .   (Unpublished note, reproduced in Riemann's collected papers.)   Reprinted in Gesammelte Abhandlungen, Vol. 1. Berlin: Springer-Verlag, 1966.   .    .   "  Category:Asymptotic analysis  Category:Perturbation theory     A modified version of Lemma 2.1.1 on page 56 in . â†©  Lemma 3.3.2 on page 113 in â†©  , page 54; see also the comment on page 479 in . â†©  , pages 417-420. â†©  This conclusion follows from a comparison between the final asymptotic for , given by equation (8), and a simple estimate for the discarded integral . â†©  This is justified by comparing the integral asymptotic over [see equation (8)] with a simple estimate for the altered part. â†©  See equation (4.4.9) on page 125 in â†©  Rigorously speaking, this case cannot be inferred from equation (8) because the second assumption , utilized in the derivation, is violated. To include the discussed case of a purely imaginary phase function, condition (9) should be replaced by      |   arg    -   Î¼  j      |   â©½   Ï€  4    .               subscript  Î¼  j         Ï€  4     \left|\arg\sqrt{-\mu_{j}}\right|\leqslant\tfrac{\pi}{4}.    â†©  See equation (2.2.6') on page 186 in â†©     