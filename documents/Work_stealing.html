<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="1860">Work stealing</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>Work stealing</h1>
<hr/>

<p>In <a href="parallel_computing" title="wikilink">parallel computing</a>, <strong>work stealing</strong> is a <a href="Scheduling_(computing)" title="wikilink">scheduling</a> strategy for <a href="multithreading_(software)" title="wikilink">multithreaded</a> computer programs. It solves the problem of executing a <em>dynamically multithreaded</em> computation, one that can "spawn" new threads of execution, on a <em>statically multithreaded</em> computer, with a fixed number of <a href="processor_core" title="wikilink">processor cores</a>. It does so efficiently both in terms of execution time and memory usage.</p>

<p>In a work stealing scheduler, each processor in a computer system has a queue of work items (computational tasks, threads) to perform. Each work item consists of a series of instructions, to be executed sequentially, but in the course of its execution, a work item may also <em>spawn</em> new work items that can feasibly be executed in parallel with its other work. These new items are initially put on the queue of the processor executing the work item. When a processor runs out of work, it looks at the queues of other processors and "steals" their work items.</p>

<p>Work stealing contrasts with <em>work sharing</em>, another popular scheduling approach for dynamic multithreading, where each work item is scheduled onto a processor when it is spawned. Compared to this approach, work stealing reduces the amount of <a href="process_migration" title="wikilink">process migration</a> between processors, because no such migration occurs when all processors have work to do.<a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a></p>

<p>The idea of work stealing goes back to the implementation of the <a class="uri" href="Multilisp" title="wikilink">Multilisp</a> programming language and work on parallel <a href="functional_programming" title="wikilink">functional programming</a> languages in the 1980s.<a class="footnoteRef" href="#fn2" id="fnref2"><sup>2</sup></a> It is employed in the scheduler for the <a class="uri" href="Cilk" title="wikilink">Cilk</a> programming language,<a class="footnoteRef" href="#fn3" id="fnref3"><sup>3</sup></a> the <a href="Java_(programming_language)" title="wikilink">Java</a> fork/join framework,<a class="footnoteRef" href="#fn4" id="fnref4"><sup>4</sup></a> and the .NET <a href="Task_Parallel_Library" title="wikilink">Task Parallel Library</a>.<a class="footnoteRef" href="#fn5" id="fnref5"><sup>5</sup></a></p>
<h2 id="execution-model">Execution model</h2>

<p>Work stealing is designed for a "strict" <a href="fork–join_model" title="wikilink">fork–join model</a> of parallel computation, which means that a computation can be viewed as a <a href="directed_acyclic_graph" title="wikilink">directed acyclic graph</a> with a single source (start of computation) and a single sink (end of computation). Each node in this graph represents either a <em>fork</em> or a <em>join</em>. Forks produce multiple <em>logically parallel</em> computations, variously called "threads"<a class="footnoteRef" href="#fn6" id="fnref6"><sup>6</sup></a> or "strands".<a class="footnoteRef" href="#fn7" id="fnref7"><sup>7</sup></a> Edges represent serial computation.<a class="footnoteRef" href="#fn8" id="fnref8"><sup>8</sup></a><a class="footnoteRef" href="#fn9" id="fnref9"><sup>9</sup></a></p>

<p>As an example, consider the following trivial fork–join program in <a class="uri" href="Cilk" title="wikilink">Cilk</a>-like syntax:</p>

<p><strong><code>function</code></strong><code> f(a, b):</code><br/>
<code>    c ← </code><strong><code>fork</code></strong><code> g(a)</code><br/>
<code>    d ← h(b)</code><br/>
<code>    </code><strong><code>join</code></strong><br/>
<code>    return c + d</code><br/>
<br/>
<strong><code>function</code></strong><code> g(a):</code><br/>
<code>    return a × 2</code><br/>
<br/>
<strong><code>function</code></strong><code> h(a):</code><br/>
<code>    b ← </code><strong><code>fork</code></strong><code> g(a)</code><br/>
<code>    c ← a + 1</code><br/>
<code>    </code><strong><code>join</code></strong><br/>
<code>    return b + c</code></p>

<p>The function call <code>f(1, 2)</code> gives rise to the following computation graph:</p>
<figure><b>(Figure)</b>
<figcaption>Graph representation of a <a href=":w:en:fork–join_model" title="wikilink">fork–join</a> computation.</figcaption>
</figure>

<p>In the graph, when two edges leave a node, the computations represented by the edge labels are logically parallel: they may be performed either in parallel, or sequentially. The computation may only proceed past a <em>join</em> node when the computations represented by its incoming edges are complete. The work of a scheduler, now, is to assign the computations (edges) to processors in a way that makes the entire computation run to completion in the correct order (as constrained by the join nodes), preferably as fast as possible.</p>
<h2 id="algorithm">Algorithm</h2>

<p>The <a href="randomized_algorithm" title="wikilink">randomized</a> version of the work stealing algorithm presented by Blumofe and Leiserson maintains several threads of execution and schedules these onto 

<math display="inline" id="Work_stealing:0">
 <semantics>
  <mi>P</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>P</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   P
  </annotation>
 </semantics>
</math>

 processors. Each of the processors has a <a href="double-ended_queue" title="wikilink">double-ended queue</a> (deque) of threads. Call the ends of the deque "top" and "bottom".</p>

<p>Each processor that has a current thread to execute, executes the instructions in the thread one by one, until it encounters an instruction that causes one of four "special" behaviors:<a class="footnoteRef" href="#fn10" id="fnref10"><sup>10</sup></a></p>
<ul>
<li>A <em>spawn</em> instruction causes a new thread to be created. The current thread is placed at the bottom of the deque, and the processor starts executing the new thread.</li>
<li>A <em>stalling</em> instruction is one that temporarily halts execution of its thread. The processor pops a thread off the bottom of its deque and starts executing that thread. If its deque is empty, it starts work stealing, explained below.</li>
<li>An instruction may cause a thread to <em>die</em>. The behavior in this case is the same as for an instruction that stalls.</li>
<li>An instruction may <em>enable</em> another thread. The other thread is pushed onto the bottom of the deque, but the processor continues execution of its current thread.</li>
</ul>

<p>Initially, a computation consists of a single thread and is assigned to some processor, while the other processors start off idle. Any processor that becomes idle starts the actual process of work stealing, which means the following:</p>
<ul>
<li>it picks another processor uniformly at random;</li>
<li>if the other processor's deque is non-empty, it pops the top-most thread off the deque and starts executing that;</li>
<li>else, repeat.</li>
</ul>
<h3 id="child-stealing-vs.-continuation-stealing">Child stealing vs. continuation stealing</h3>

<p>Note that, in the rule for <em>spawn</em>, Blumofe and Leiserson suggest that the "parent" thread execute its new thread, as if performing a function call (in the C-like program , the function call to  completes before the call to  is performed). This is called "<a class="uri" href="continuation" title="wikilink">continuation</a> stealing", because the continuation of the function can be stolen while the spawned thread is executed, and is what is used by <a href="Cilk_Plus" title="wikilink">Cilk Plus</a>.<a class="footnoteRef" href="#fn11" id="fnref11"><sup>11</sup></a> It is not the only way to implement work stealing; the alternative strategy is called "child stealing" and is easier to implement as a <a href="software_library" title="wikilink">library</a>, without <a class="uri" href="compiler" title="wikilink">compiler</a> support.<a class="footnoteRef" href="#fn12" id="fnref12"><sup>12</sup></a> Child stealing is used by <a href="Threading_Building_Blocks" title="wikilink">Threading Building Blocks</a>, Microsoft's Task Parallel Library and <a class="uri" href="OpenMP" title="wikilink">OpenMP</a>, although the latter gives the programmer control over which strategy is used.<a class="footnoteRef" href="#fn13" id="fnref13"><sup>13</sup></a></p>
<h2 id="efficiency">Efficiency</h2>

<p>Several variants of work stealing have been proposed. The <a href="Randomized_algorithm" title="wikilink">randomized</a> variant due to Blumofe and Leiserson executes a parallel computation in <a href="expected_time" title="wikilink">expected time</a> 

<math display="inline" id="Work_stealing:1">
 <semantics>
  <mrow>
   <mrow>
    <msub>
     <mi>T</mi>
     <mn>1</mn>
    </msub>
    <mo>/</mo>
    <mi>P</mi>
   </mrow>
   <mo>+</mo>
   <mrow>
    <mi>O</mi>
    <mrow>
     <mo stretchy="false">(</mo>
     <msub>
      <mi>T</mi>
      <mi mathvariant="normal">∞</mi>
     </msub>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <plus></plus>
    <apply>
     <divide></divide>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>T</ci>
      <cn type="integer">1</cn>
     </apply>
     <ci>P</ci>
    </apply>
    <apply>
     <times></times>
     <ci>O</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>T</ci>
      <infinity></infinity>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   T_{1}/P+O(T_{\infty})
  </annotation>
 </semantics>
</math>

 on 

<math display="inline" id="Work_stealing:2">
 <semantics>
  <mi>P</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>P</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   P
  </annotation>
 </semantics>
</math>

 processors; here, 

<math display="inline" id="Work_stealing:3">
 <semantics>
  <msub>
   <mi>T</mi>
   <mn>1</mn>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>T</ci>
    <cn type="integer">1</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   T_{1}
  </annotation>
 </semantics>
</math>


 is the <em>work</em>, or the amount of time required to run the computation on a serial computer, and 

<math display="inline" id="Work_stealing:4">
 <semantics>
  <msub>
   <mi>T</mi>
   <mi mathvariant="normal">∞</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>T</ci>
    <infinity></infinity>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   T_{\infty}
  </annotation>
 </semantics>
</math>

 is the <em>span</em>, the amount of time required on an infinitely parallel machine.<a class="footnoteRef" href="#fn14" id="fnref14"><sup>14</sup></a> This means that, <a href="expected_value" title="wikilink">in expectation</a>, the time required is at most a constant factor times the theoretical minimum.<a class="footnoteRef" href="#fn15" id="fnref15"><sup>15</sup></a></p>
<h3 id="space-usage">Space usage</h3>

<p>A computation scheduled by the Blumofe–Leiserson version of work stealing uses 

<math display="inline" id="Work_stealing:5">
 <semantics>
  <mrow>
   <mi>O</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <mrow>
     <msub>
      <mi>S</mi>
      <mn>1</mn>
     </msub>
     <mi>P</mi>
    </mrow>
    <mo stretchy="false">)</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <ci>O</ci>
    <apply>
     <times></times>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>S</ci>
      <cn type="integer">1</cn>
     </apply>
     <ci>P</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   O(S_{1}P)
  </annotation>
 </semantics>
</math>

 <a href="call_stack" title="wikilink">stack space</a>, if 

<math display="inline" id="Work_stealing:6">
 <semantics>
  <msub>
   <mi>S</mi>
   <mn>1</mn>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>S</ci>
    <cn type="integer">1</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   S_{1}
  </annotation>
 </semantics>
</math>

 were the stack usage of the same computation on a single processor,<a class="footnoteRef" href="#fn16" id="fnref16"><sup>16</sup></a> fitting the authors' own earlier definition of space efficiency.<a class="footnoteRef" href="#fn17" id="fnref17"><sup>17</sup></a> This bound requires continuation stealing; in a child stealing scheduler, it does not hold.<a class="footnoteRef" href="#fn18" id="fnref18"><sup>18</sup></a></p>
<h2 id="multiprogramming-variant">Multiprogramming variant</h2>

<p>The work stealing algorithm as outlined earlier, and its analysis, assume a computing environment where a computation are scheduled onto dedicated processors. In a <a class="uri" href="multiprogramming" title="wikilink">multiprogramming</a> (multi-tasking) environment, other processes may be vying for the processors and an <a href="operating_system" title="wikilink">operating system</a> scheduler determines how much processor time each process gets. A variant of work stealing has been devised for this situation, which maps the lightweight threads maintained by work stealing onto a pool of worker threads managed by an operating system's scheduler. This variant executes a computation in expected time 

<math display="inline" id="Work_stealing:7">
 <semantics>
  <mrow>
   <mi>O</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <mrow>
     <mfrac>
      <msub>
       <mi>T</mi>
       <mn>1</mn>
      </msub>
      <msub>
       <mi>P</mi>
       <mi>avg</mi>
      </msub>
     </mfrac>
     <mo>+</mo>
     <mfrac>
      <mrow>
       <msub>
        <mi>T</mi>
        <mi mathvariant="normal">∞</mi>
       </msub>
       <mi>P</mi>
      </mrow>
      <msub>
       <mi>P</mi>
       <mi>avg</mi>
      </msub>
     </mfrac>
    </mrow>
    <mo stretchy="false">)</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <ci>O</ci>
    <apply>
     <plus></plus>
     <apply>
      <divide></divide>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>T</ci>
       <cn type="integer">1</cn>
      </apply>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>P</ci>
       <ci>avg</ci>
      </apply>
     </apply>
     <apply>
      <divide></divide>
      <apply>
       <times></times>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <ci>T</ci>
        <infinity></infinity>
       </apply>
       <ci>P</ci>
      </apply>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>P</ci>
       <ci>avg</ci>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   O(\frac{T_{1}}{P_{\mathrm{avg}}}+\frac{T_{\infty}P}{P_{\mathrm{avg}}})
  </annotation>
 </semantics>
</math>

, where 

<math display="inline" id="Work_stealing:8">
 <semantics>
  <msub>
   <mi>P</mi>
   <mi>avg</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>P</ci>
    <ci>avg</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   P_{\mathrm{avg}}
  </annotation>
 </semantics>
</math>


 is the average number of processors allocated to the computation by the OS scheduler over the computation's running time.<a class="footnoteRef" href="#fn19" id="fnref19"><sup>19</sup></a> The multiprogramming work-scheduler scheduler differs from the traditional version in two respects:</p>
<ul>
<li>Its queues are <a href="Non-blocking_algorithm" title="wikilink">non-blocking</a>. While on dedicated processors, access to the queues can be synchronized using <a href="Lock_(computer_science)" title="wikilink">locks</a>, this is not advisable in a multiprogramming environment since the operating system might <a href="Preemption_(computing)" title="wikilink">preempt</a> the worker thread holding the lock, blocking the progress of any other workers that try to access the same queue.</li>
<li>Before each attempt to steal work, a worker thread calls a "" system call that yields the processor on which it is scheduled to the OS, in order to prevent <a href="Starvation_(computer_science)" title="wikilink">starvation</a>.</li>
</ul>

<p>Attempts to improve on the multiprogramming work stealer have focused on <a href="Locality_of_reference" title="wikilink">cache locality</a> issues<a class="footnoteRef" href="#fn20" id="fnref20"><sup>20</sup></a> and improved queue data structures.</p>
<h2 id="notes">Notes</h2>
<h2 id="references">References</h2>

<p>"</p>

<p><a href="Category:Scheduling_(computing)" title="wikilink">Category:Scheduling (computing)</a> <a href="Category:Parallel_computing" title="wikilink">Category:Parallel computing</a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1"><a href="#fnref1">↩</a></li>
<li id="fn2"></li>
<li id="fn3"><a href="#fnref3">↩</a></li>
<li id="fn4"><a href="#fnref4">↩</a></li>
<li id="fn5"><a href="#fnref5">↩</a></li>
<li id="fn6"></li>
<li id="fn7"><a href="#fnref7">↩</a></li>
<li id="fn8"><a href="#fnref8">↩</a></li>
<li id="fn9">In the original presentation, serial computations were represented as nodes as well, and a directed edge represented the relation "is followed by".<a href="#fnref9">↩</a></li>
<li id="fn10"></li>
<li id="fn11"></li>
<li id="fn12"></li>
<li id="fn13"></li>
<li id="fn14">See <a href="analysis_of_PRAM_algorithms" title="wikilink">analysis of PRAM algorithms</a> for definitions.<a href="#fnref14">↩</a></li>
<li id="fn15"></li>
<li id="fn16"></li>
<li id="fn17"><a href="#fnref17">↩</a></li>
<li id="fn18"></li>
<li id="fn19"><a href="#fnref19">↩</a></li>
<li id="fn20"><a href="#fnref20">↩</a></li>
</ol>
</section>
</body>
</html>
