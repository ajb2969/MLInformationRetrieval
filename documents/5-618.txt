   Band matrix      Band matrix   In mathematics , particularly matrix theory , a band matrix is a sparse matrix whose non-zero entries are confined to a diagonal band , comprising the main diagonal and zero or more diagonals on either side.  Band matrix  Formally, consider an n × n matrix A =( a i,j ). If all matrix elements are zero outside a diagonally bordered band whose range is determined by constants k 1 and k 2 :       a   i  ,  j    =  0       subscript  a   i  j    0    a_{i,j}=0     then the quantities k 1 and k 2 are called the lower and upper  bandwidth , respectively. The bandwidth of the matrix is the maximum of k 1 and k 2 ; in other words, it is the number k such that     |   i  -  j   |   >  k          i  j    k    |i-j|>k   if    [      B  11      B  12     0    ⋯    ⋯    0       B  21      B  22      B  23     ⋱    ⋱    ⋮      0     B  32      B  33      B  34     ⋱    ⋮      ⋮    ⋱     B  43      B  44      B  45     0      ⋮    ⋱    ⋱     B  54      B  55      B  56       0    ⋯    ⋯    0     B  65      B  66      ]       subscript  B  11    subscript  B  12   0  normal-⋯  normal-⋯  0     subscript  B  21    subscript  B  22    subscript  B  23   normal-⋱  normal-⋱  normal-⋮    0   subscript  B  32    subscript  B  33    subscript  B  34   normal-⋱  normal-⋮    normal-⋮  normal-⋱   subscript  B  43    subscript  B  44    subscript  B  45   0    normal-⋮  normal-⋱  normal-⋱   subscript  B  54    subscript  B  55    subscript  B  56     0  normal-⋯  normal-⋯  0   subscript  B  65    subscript  B  66      \begin{bmatrix}B_{11}&B_{12}&0&\cdots&\cdots&0\\
 B_{21}&B_{22}&B_{23}&\ddots&\ddots&\vdots\\
 0&B_{32}&B_{33}&B_{34}&\ddots&\vdots\\
 \vdots&\ddots&B_{43}&B_{44}&B_{45}&0\\
 \vdots&\ddots&\ddots&B_{54}&B_{55}&B_{56}\\
 0&\cdots&\cdots&0&B_{65}&B_{66}\end{bmatrix}   .  A matrix is called a band matrix or banded matrix if its bandwidth is reasonably small.  A band matrix with k 1 = k 2 = 0 is a diagonal matrix ; a band matrix with k 1 = k 2 = 1 is a tridiagonal matrix ; when k 1 = k 2 = 2 one has a pentadiagonal matrix and so on. If one puts k 1 = 0, k 2 = n −1, one obtains the definition of an upper triangular matrix ; similarly, for k 1 = n −1, k 2 = 0 one obtains a lower triangular matrix.  Applications  In numerical analysis , matrices from finite element or finite difference problems are often banded. Such matrices can be viewed as descriptions of the coupling between the problem variables; the bandedness corresponds to the fact that variables are not coupled over arbitrarily large distances. Such matrices can be further divided - for instance, banded matrices exist where every element in the band is nonzero. These often arise when discretising one-dimensional problems.  Problems in higher dimensions also lead to banded matrices, in which case the band itself also tends to be sparse. For instance, a partial differential equation on a square domain (using central differences) will yield a matrix with a bandwidth equal to the square root of the matrix dimension, but inside the band only 5 diagonals are nonzero. Unfortunately, applying Gaussian elimination (or equivalently an LU decomposition ) to such a matrix results in the band being filled in by many non-zero elements.  Band storage  Band matrices are usually stored by storing the diagonals in the band; the rest is implicitly zero.  For example, a tridiagonal matrix has bandwidth 1. The 6-by-6 matrix       [     0     B  11      B  12        B  21      B  22      B  23        B  32      B  33      B  34        B  43      B  44      B  45        B  54      B  55      B  56        B  65      B  66     0     ]   .      0   subscript  B  11    subscript  B  12      subscript  B  21    subscript  B  22    subscript  B  23      subscript  B  32    subscript  B  33    subscript  B  34      subscript  B  43    subscript  B  44    subscript  B  45      subscript  B  54    subscript  B  55    subscript  B  56      subscript  B  65    subscript  B  66   0     \begin{bmatrix}0&B_{11}&B_{12}\\
 B_{21}&B_{22}&B_{23}\\
 B_{32}&B_{33}&B_{34}\\
 B_{43}&B_{44}&B_{45}\\
 B_{54}&B_{55}&B_{56}\\
 B_{65}&B_{66}&0\end{bmatrix}.   is stored as the 6-by-3 matrix       [      A  11      A  12      A  13     0    ⋯    0          A  22      A  23      A  24     ⋱    ⋮             A  33      A  34      A  35     0                A  44      A  45      A  46           s  y  m            A  55      A  56                       A  66      ]   .       subscript  A  11    subscript  A  12    subscript  A  13   0  normal-⋯  0    absent   subscript  A  22    subscript  A  23    subscript  A  24   normal-⋱  normal-⋮    absent  absent   subscript  A  33    subscript  A  34    subscript  A  35   0    absent  absent  absent   subscript  A  44    subscript  A  45    subscript  A  46     absent    s  y  m   absent  absent   subscript  A  55    subscript  A  56     absent  absent  absent  absent  absent   subscript  A  66      \begin{bmatrix}A_{11}&A_{12}&A_{13}&0&\cdots&0\\
 &A_{22}&A_{23}&A_{24}&\ddots&\vdots\\
 &&A_{33}&A_{34}&A_{35}&0\\
 &&&A_{44}&A_{45}&A_{46}\\
 &sym&&&A_{55}&A_{56}\\
 &&&&&A_{66}\end{bmatrix}.     A further saving is possible when the matrix is symmetric. For example, consider a symmetric 6-by-6 matrix with an upper bandwidth of 2:       [      A  11      A  12      A  13        A  22      A  23      A  24        A  33      A  34      A  35        A  44      A  45      A  46        A  55      A  56     0       A  66     0    0     ]   .       subscript  A  11    subscript  A  12    subscript  A  13      subscript  A  22    subscript  A  23    subscript  A  24      subscript  A  33    subscript  A  34    subscript  A  35      subscript  A  44    subscript  A  45    subscript  A  46      subscript  A  55    subscript  A  56   0     subscript  A  66   0  0     \begin{bmatrix}A_{11}&A_{12}&A_{13}\\
 A_{22}&A_{23}&A_{24}\\
 A_{33}&A_{34}&A_{35}\\
 A_{44}&A_{45}&A_{46}\\
 A_{55}&A_{56}&0\\
 A_{66}&0&0\end{bmatrix}.   This matrix is stored as the 6-by-3 matrix:  $$\begin{bmatrix}
  A_{11} & A_{12} & A_{13} \\
  A_{22} & A_{23} & A_{24} \\
  A_{33} & A_{34} & A_{35} \\
  A_{44} & A_{45} & A_{46} \\
  A_{55} & A_{56} & 0 \\
  A_{66} & 0 & 0
 \end{bmatrix}.$$  Band form of sparse matrices  From a computational point of view, working with band matrices is always preferential to working with similarly dimensioned square matrices. A band matrix can be likened in complexity to a rectangular matrix whose row dimension is equal to the bandwidth of the band matrix. Thus the work involved in performing operations such as multiplication falls significantly, often leading to huge savings in terms of calculation time and complexity .  As sparse matrices lend themselves to more efficient computation than dense matrices, as well as in more efficient utilization of computer storage, there has been much research focused on finding ways to minimise the bandwidth (or directly minimise the fill-in) by applying permutations to the matrix, or other such equivalence or similarity transformations.  The Cuthill–McKee algorithm can be used to reduce the bandwidth of a sparse symmetric matrix . There are, however, matrices for which the reverse Cuthill–McKee algorithm performs better. There are many other methods in use.  The problem of finding a representation of a matrix with minimal bandwidth by means of permutations of rows and columns is NP-hard .  Examples and special cases  The following are special cases of band matrices:   Diagonal matrices .  Tridiagonal matrices .  Pentadiagonal matrices .  Upper and lower triangular matrices .  Upper and lower Hessenberg matrices .  Block-diagonal matrices .  Shift matrices and shear matrices .  Matrices in Jordan normal form .  A skyline matrix , also called "variable band matrix" is a generalization of band matrix   The inverses of Lehmer matrices are constant tridiagonal matrices, and are thus band matrices.  See also   Graph bandwidth   Notes  References    .   .   .   .   .   External links   Information pertaining to LAPACK and band matrices  A tutorial on banded matrices and other sparse matrix formats   "  Category:Sparse matrices   