<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="1249">Action model learning</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>Action model learning</h1>
<hr/>

<p><strong>Action model learning</strong> (sometimes abbreviated <strong>action learning</strong>) is an area of <a href="machine_learning" title="wikilink">machine learning</a> concerned with creation and modification of <a href="software_agent" title="wikilink">software agent</a>'s knowledge about <em>effects</em> and <em>preconditions</em> of the <em>actions</em> that can be executed within its <em>environment</em>. This knowledge is usually represented in logic-based <a href="action_language" title="wikilink">action description language</a> and used as the input for <a href="automated_planning" title="wikilink">automated planners</a>.</p>

<p>Learning action models is important when goals change. When an agent acted for a while, it can use its accumulated knowledge about actions in the domain to make better decisions. Thus, learning action models differs from <a href="reinforcement_learning" title="wikilink">reinforcement learning</a>. It enables reasoning about actions instead of expensive trials in the world.<a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a>Action model learning is a form of <a href="inductive_reasoning" title="wikilink">inductive reasoning</a>, where new knowledge is generated based on agent's <em>observations</em>. It differs from standard <a href="supervised_learning" title="wikilink">supervised learning</a> in that correct input/output pairs are never presented, nor imprecise action models explicitly corrected.</p>

<p>Usual motivation for action model learning is the fact that manual specification of action models for planners is often a difficult, time consuming, and error-prone task (especially in complex environments).</p>
<h2 id="action-models">Action models</h2>

<p>Given a <a href="training_set" title="wikilink">training set</a> 

<math display="inline" id="Action_model_learning:0">
 <semantics>
  <mi>E</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>E</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   E
  </annotation>
 </semantics>
</math>

 consisting of examples 

<math display="inline" id="Action_model_learning:1">
 <semantics>
  <mrow>
   <mi>e</mi>
   <mo>=</mo>
   <mrow>
    <mo stretchy="false">(</mo>
    <mi>s</mi>
    <mo>,</mo>
    <mi>a</mi>
    <mo>,</mo>
    <msup>
     <mi>s</mi>
     <mo>′</mo>
    </msup>
    <mo stretchy="false">)</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <ci>e</ci>
    <vector>
     <ci>s</ci>
     <ci>a</ci>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <ci>s</ci>
      <ci>normal-′</ci>
     </apply>
    </vector>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   e=(s,a,s^{\prime})
  </annotation>
 </semantics>
</math>

, where 

<math display="inline" id="Action_model_learning:2">
 <semantics>
  <mrow>
   <mi>s</mi>
   <mo>,</mo>
   <msup>
    <mi>s</mi>
    <mo>′</mo>
   </msup>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <list>
    <ci>s</ci>
    <apply>
     <csymbol cd="ambiguous">superscript</csymbol>
     <ci>s</ci>
     <ci>normal-′</ci>
    </apply>
   </list>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   s,s^{\prime}
  </annotation>
 </semantics>
</math>

 are observations of a world state from two consecutive time steps 

<math display="inline" id="Action_model_learning:3">
 <semantics>
  <mrow>
   <mi>t</mi>
   <mo>,</mo>
   <msup>
    <mi>t</mi>
    <mo>′</mo>
   </msup>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <list>
    <ci>t</ci>
    <apply>
     <csymbol cd="ambiguous">superscript</csymbol>
     <ci>t</ci>
     <ci>normal-′</ci>
    </apply>
   </list>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   t,t^{\prime}
  </annotation>
 </semantics>
</math>

 and 

<math display="inline" id="Action_model_learning:4">
 <semantics>
  <mi>a</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>a</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   a
  </annotation>
 </semantics>
</math>

 is an <em>action instance</em> observed in time step 

<math display="inline" id="Action_model_learning:5">
 <semantics>
  <mi>t</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>t</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   t
  </annotation>
 </semantics>
</math>

, the goal of action model learning in general is to construct an <em>action model</em> 

<math display="inline" id="Action_model_learning:6">
 <semantics>
  <mrow>
   <mo stretchy="false">⟨</mo>
   <mi>D</mi>
   <mo>,</mo>
   <mi>P</mi>
   <mo stretchy="false">⟩</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <list>
    <ci>D</ci>
    <ci>P</ci>
   </list>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \langle D,P\rangle
  </annotation>
 </semantics>
</math>

, where 

<math display="inline" id="Action_model_learning:7">
 <semantics>
  <mi>D</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>D</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   D
  </annotation>
 </semantics>
</math>

 is a description of domain dynamics in action description formalism like <a class="uri" href="STRIPS" title="wikilink">STRIPS</a>, <a href="Architecture_description_language" title="wikilink">ADL</a> or <a class="uri" href="PDDL" title="wikilink">PDDL</a> and 

<math display="inline" id="Action_model_learning:8">
 <semantics>
  <mi>P</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>P</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   P
  </annotation>
 </semantics>
</math>

 is a probability function defined over the elements of 

<math display="inline" id="Action_model_learning:9">
 <semantics>
  <mi>D</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>D</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   D
  </annotation>
 </semantics>
</math>

. <a class="footnoteRef" href="#fn2" id="fnref2"><sup>2</sup></a> However, many state of the art <em>action learning methods</em> assume determinism and do not induce 

<math display="inline" id="Action_model_learning:10">
 <semantics>
  <mi>P</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>P</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   P
  </annotation>
 </semantics>
</math>

. In addition to determinism, individual methods differ in how they deal with other attributes of domain (e.g. partial observability or sensoric noise).</p>
<h2 id="action-learning-methods">Action learning methods</h2>
<h3 id="state-of-the-art">State of the art</h3>

<p>Recent action learning methods take various approaches and employ a wide variety of tools from different areas of <a href="artificial_intelligence" title="wikilink">artificial intelligence</a> and <a href="computational_logic" title="wikilink">computational logic</a>. As an example of a method based on propositional logic, we can mention SLAF (Simultaneous Learning and Filtering) algorithm,<a class="footnoteRef" href="#fn3" id="fnref3"><sup>3</sup></a> which uses agent's observations to construct a long propositional formula over time and subsequently interprets it using a <a href="SAT_solver" title="wikilink">satisfiability (SAT) solver</a>. Another technique, in which learning is converted into a satisfiability problem (weighted <a class="uri" href="MAX-SAT" title="wikilink">MAX-SAT</a> in this case) and SAT solvers are used, is implemented in ARMS (Action-Relation Modeling System).<a class="footnoteRef" href="#fn4" id="fnref4"><sup>4</sup></a> Two mutually similar, fully declarative approaches to action learning were based on logic programming paradigm <a href="Answer_Set_Programming" title="wikilink">Answer Set Programming</a> (ASP)<a class="footnoteRef" href="#fn5" id="fnref5"><sup>5</sup></a> and its extension, Reactive ASP.<a class="footnoteRef" href="#fn6" id="fnref6"><sup>6</sup></a> In another example, bottom-up <a href="inductive_logic_programming" title="wikilink">inductive logic programming</a> approach was employed.<a class="footnoteRef" href="#fn7" id="fnref7"><sup>7</sup></a> Several different solutions are not directly logic-based. For example, the action model learning using a <a href="perceptron_algorithm" title="wikilink">perceptron algorithm</a> <a class="footnoteRef" href="#fn8" id="fnref8"><sup>8</sup></a> or the multi level <a href="greedy_search" title="wikilink">greedy search</a> over the space of possible action models.<a class="footnoteRef" href="#fn9" id="fnref9"><sup>9</sup></a> In the older paper from 1992,<a class="footnoteRef" href="#fn10" id="fnref10"><sup>10</sup></a> the action model learning was studied as an extension of <a href="reinforcement_learning" title="wikilink">reinforcement learning</a>.</p>
<h3 id="literature">Literature</h3>

<p>Most action learning research papers are published in journals and conferences focused on <a href="artificial_intelligence" title="wikilink">artificial intelligence</a> in general (e.g. Journal of Artificial Intelligence Research (JAIR), Artificial Intelligence, Applied Artificial Intelligence (AAI) or AAAI conferences). Despite mutual relevance of the topics, action model learning is usually not addressed on <a href="Automated_planning_and_scheduling" title="wikilink">planning</a> conferences like ICAPS.</p>
<h2 id="see-also">See also</h2>
<ul>
<li><a href="Machine_learning" title="wikilink">Machine learning</a></li>
<li><a href="Automated_planning_and_scheduling" title="wikilink">Automated planning and scheduling</a></li>
<li><a href="Action_language" title="wikilink">Action language</a></li>
<li><a class="uri" href="STRIPS" title="wikilink">STRIPS</a></li>
<li><a class="uri" href="PDDL" title="wikilink">PDDL</a></li>
<li><a href="Architecture_description_language" title="wikilink">Architecture description language</a></li>
<li><a href="Inductive_reasoning" title="wikilink">Inductive reasoning</a></li>
<li><a href="Computational_logic" title="wikilink">Computational logic</a></li>
<li><a href="Knowledge_representation" title="wikilink">Knowledge representation</a></li>
</ul>
<h2 id="references">References</h2>

<p>"</p>

<p><a href="Category:Inductive_reasoning" title="wikilink">Category:Inductive reasoning</a> <a href="Category:Machine_learning" title="wikilink">Category:Machine learning</a> <a href="Category:Data_mining" title="wikilink">Category:Data mining</a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1"><a href="#fnref1">↩</a></li>
<li id="fn2"><a href="#fnref2">↩</a></li>
<li id="fn3"></li>
<li id="fn4"><a href="#fnref4">↩</a></li>
<li id="fn5"><a href="#fnref5">↩</a></li>
<li id="fn6"><a href="#fnref6">↩</a></li>
<li id="fn7"><a href="#fnref7">↩</a></li>
<li id="fn8"><a href="#fnref8">↩</a></li>
<li id="fn9"><a href="#fnref9">↩</a></li>
<li id="fn10"><a href="#fnref10">↩</a></li>
</ol>
</section>
</body>
</html>
