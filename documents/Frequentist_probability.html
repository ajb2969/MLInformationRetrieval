<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="384">Frequentist probability</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>Frequentist probability</h1>
<hr/>
<figure><b>(Figure)</b>
<figcaption>John Venn</figcaption>
</figure>

<p><strong>Frequentist probability</strong> or <strong>frequentism</strong> is a standard <a href="interpretation_of_probability" title="wikilink">interpretation of probability</a>; it defines an event's <a class="uri" href="probability" title="wikilink">probability</a> as the <a href="limit_of_a_sequence" title="wikilink">limit</a> of its relative <a class="uri" href="frequency" title="wikilink">frequency</a> in a large number of trials. This interpretation supports the statistical needs of experimental scientists and pollsters; probabilities can be found (in principle) by a repeatable objective process (and are thus ideally devoid of opinion). It does not support all needs; Gamblers typically require estimates of the odds without experiments.</p>

<p>The development of the frequentist account was motivated by the problems and paradoxes of the previously dominant viewpoint, the <a href="Classical_definition_of_probability" title="wikilink">classical interpretation</a>. In the classical interpretation, probability was defined in terms of the <a href="principle_of_indifference" title="wikilink">principle of indifference</a>, based on the natural symmetry of a problem, so, <em>e.g.</em> the probabilities of dice games arise from the natural symmetric 6-sidedness of the cube. This classical interpretation stumbled at any statistical problem that has no natural symmetry for reasoning.</p>
<h2 id="definition">Definition</h2>

<p>In the frequentist interpretation, probabilities are discussed only when dealing with well-defined <a href="experiment_(probability_theory)" title="wikilink">random experiments</a> (or random samples).<a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a> The <a href="Set_(mathematics)" title="wikilink">set</a> of all possible outcomes of a random experiment is called the <a href="sample_space" title="wikilink">sample space</a> of the experiment. An <a href="event_(probability_theory)" title="wikilink">event</a> is defined as a particular <a class="uri" href="subset" title="wikilink">subset</a> of the sample space to be considered. For any given event, only one of two possibilities may hold: it occurs or it does not. The <a href="relative_frequency" title="wikilink">relative frequency</a> of occurrence of an event, observed in a number of repetitions of the experiment, is a measure of the <strong>probability</strong> of that event. This is the core conception of probability in the frequentist interpretation.</p>

<p>Thus, if 

<math display="inline" id="Frequentist_probability:0">
 <semantics>
  <msub>
   <mi>n</mi>
   <mi>t</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>n</ci>
    <ci>t</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   n_{t}
  </annotation>
 </semantics>
</math>

 is the total number of trials and 

<math display="inline" id="Frequentist_probability:1">
 <semantics>
  <msub>
   <mi>n</mi>
   <mi>x</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>n</ci>
    <ci>x</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   n_{x}
  </annotation>
 </semantics>
</math>

 is the number of trials where the event 

<math display="inline" id="Frequentist_probability:2">
 <semantics>
  <mi>x</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>x</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   x
  </annotation>
 </semantics>
</math>

 occurred, the probability 

<math display="inline" id="Frequentist_probability:3">
 <semantics>
  <mrow>
   <mi>P</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <mi>x</mi>
    <mo stretchy="false">)</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <ci>P</ci>
    <ci>x</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   P(x)
  </annotation>
 </semantics>
</math>


 of the event occurring will be approximated by the relative frequency as follows:</p>

<p>

<math display="block" id="Frequentist_probability:4">
 <semantics>
  <mrow>
   <mrow>
    <mrow>
     <mi>P</mi>
     <mrow>
      <mo stretchy="false">(</mo>
      <mi>x</mi>
      <mo stretchy="false">)</mo>
     </mrow>
    </mrow>
    <mo>≈</mo>
    <mfrac>
     <msub>
      <mi>n</mi>
      <mi>x</mi>
     </msub>
     <msub>
      <mi>n</mi>
      <mi>t</mi>
     </msub>
    </mfrac>
   </mrow>
   <mo>.</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <approx></approx>
    <apply>
     <times></times>
     <ci>P</ci>
     <ci>x</ci>
    </apply>
    <apply>
     <divide></divide>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>n</ci>
      <ci>x</ci>
     </apply>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>n</ci>
      <ci>t</ci>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   P(x)\approx\frac{n_{x}}{n_{t}}.
  </annotation>
 </semantics>
</math>

</p>

<p>Clearly, as the number of trials is increased, one might expect the relative frequency to become a better approximation of a "true frequency".</p>

<p>A claim of the frequentist approach is that in the "long run," as the number of trials approaches infinity, the relative frequency will converge <em>exactly</em> to the true probability:<a class="footnoteRef" href="#fn2" id="fnref2"><sup>2</sup></a></p>

<p>

<math display="block" id="Frequentist_probability:5">
 <semantics>
  <mrow>
   <mrow>
    <mrow>
     <mi>P</mi>
     <mrow>
      <mo stretchy="false">(</mo>
      <mi>x</mi>
      <mo stretchy="false">)</mo>
     </mrow>
    </mrow>
    <mo>=</mo>
    <mrow>
     <munder>
      <mo movablelimits="false">lim</mo>
      <mrow>
       <msub>
        <mi>n</mi>
        <mi>t</mi>
       </msub>
       <mo>→</mo>
       <mi mathvariant="normal">∞</mi>
      </mrow>
     </munder>
     <mfrac>
      <msub>
       <mi>n</mi>
       <mi>x</mi>
      </msub>
      <msub>
       <mi>n</mi>
       <mi>t</mi>
      </msub>
     </mfrac>
    </mrow>
   </mrow>
   <mo>.</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <times></times>
     <ci>P</ci>
     <ci>x</ci>
    </apply>
    <apply>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <limit></limit>
      <apply>
       <ci>normal-→</ci>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <ci>n</ci>
        <ci>t</ci>
       </apply>
       <infinity></infinity>
      </apply>
     </apply>
     <apply>
      <divide></divide>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>n</ci>
       <ci>x</ci>
      </apply>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>n</ci>
       <ci>t</ci>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   P(x)=\lim_{n_{t}\rightarrow\infty}\frac{n_{x}}{n_{t}}.
  </annotation>
 </semantics>
</math>

</p>
<h2 id="scope">Scope</h2>

<p>The frequentist interpretation is a philosophical approach to the definition and use of probabilities; it is one of several such approaches. It does not claim to capture all connotations of the concept 'probable' in colloquial speech of natural languages.</p>

<p>As an interpretation, it is not in conflict with the mathematical axiomatization of probability theory; rather, it provides guidance for how to apply mathematical probability theory to real-world situations. It offers distinct guidance in the construction and design of practical experiments, especially when contrasted with the <a href="Bayesian_probability" title="wikilink">Bayesian interpretation</a>. As to whether this guidance is useful, or is apt to mis-interpretation, has been a source of controversy. Particularly when the frequency interpretation of probability is mistakenly assumed to be the only possible basis for <a href="frequentist_inference" title="wikilink">frequentist inference</a>. So, for example, a list of mis-interpretations of the meaning of <a class="uri" href="p-values" title="wikilink">p-values</a> accompanies the article on p-values; controversies are detailed in the article on <a href="Statistical_hypothesis_testing#Controversy" title="wikilink">statistical hypothesis testing</a>. The <a href="Jeffreys–Lindley_paradox" title="wikilink">Jeffreys–Lindley paradox</a> shows how different interpretations, applied to the same data set, can lead to different conclusions about the 'statistical significance' of a result.</p>

<p>As <a href="William_Feller" title="wikilink">William Feller</a> noted:<a class="footnoteRef" href="#fn3" id="fnref3"><sup>3</sup></a> </p>

<p>Feller's comment was criticism of Laplace, who published a solution to the sunrise problem using an alternative probability interpretation. Despite Laplace's explicit and immediate disclaimer in the source, based on expertise in astronomy as well as probability, two centuries of criticism have followed.</p>
<h2 id="history">History</h2>

<p>The frequentist view may have been foreshadowed by <a class="uri" href="Aristotle" title="wikilink">Aristotle</a>, in <em><a href="Rhetoric_(Aristotle)" title="wikilink">Rhetoric</a></em>,<a class="footnoteRef" href="#fn4" id="fnref4"><sup>4</sup></a> when he wrote:</p>

<p><mtpl></mtpl></p>

<p><a href="Siméon_Denis_Poisson" title="wikilink">Poisson</a> clearly distinguished between objective and subjective probabilities in 1837.<a class="footnoteRef" href="#fn5" id="fnref5"><sup>5</sup></a> Soon thereafter a flurry of nearly simultaneous publications by <a href="John_Stuart_Mill" title="wikilink">Mill</a>, <a href="Robert_Leslie_Ellis" title="wikilink">Ellis</a> ("On the Foundations of the Theory of Probabilities"<a class="footnoteRef" href="#fn6" id="fnref6"><sup>6</sup></a> and "Remarks on the Fundamental Principles of the Theory of Probabilities"<a class="footnoteRef" href="#fn7" id="fnref7"><sup>7</sup></a>), <a href="Antoine_Augustin_Cournot" title="wikilink">Cournot</a> (<em>Exposition de la théorie des chances et des probabilités</em>)<a class="footnoteRef" href="#fn8" id="fnref8"><sup>8</sup></a> and <a href="Jakob_Friedrich_Fries" title="wikilink">Fries</a> introduced the frequentist view. <a href="John_Venn" title="wikilink">Venn</a> provided a thorough exposition (<em>The Logic of Chance: An Essay on the Foundations and Province of the Theory of Probability</em> (published editions in 1866, 1876, 1888))<a class="footnoteRef" href="#fn9" id="fnref9"><sup>9</sup></a> two decades later. These were further supported by the publications of <a href="George_Boole" title="wikilink">Boole</a> and <a href="Joseph_Louis_François_Bertrand" title="wikilink">Bertrand</a>. By the end of the 19th century the frequentist interpretation was well established and perhaps dominant in the sciences.<a class="footnoteRef" href="#fn10" id="fnref10"><sup>10</sup></a> The following generation established the tools of classical inferential statistics (significance testing, hypothesis testing and confidence intervals) all based on frequentist probability.</p>

<p>Alternatively,<a class="footnoteRef" href="#fn11" id="fnref11"><sup>11</sup></a> <a href="Jacob_Bernoulli" title="wikilink">Jacob Bernoulli</a> (AKA James or Jacques) understood the concept of frequentist probability and published a critical proof (the weak law of large numbers) posthumously in <em>1713</em>. He is also credited with some appreciation for subjective probability (prior to and without Bayes theorem).<a class="footnoteRef" href="#fn12" id="fnref12"><sup>12</sup></a><a class="footnoteRef" href="#fn13" id="fnref13"><sup>13</sup></a> <a href="Carl_Friedrich_Gauss" title="wikilink">Gauss</a> and <a href="Pierre-Simon_Laplace" title="wikilink">Laplace</a> used frequentist (and other) probability in derivations of the least squares method a century later, a generation before Poisson.<a class="footnoteRef" href="#fn14" id="fnref14"><sup>14</sup></a> Laplace considered the probabilities of testimonies, tables of mortality, judgments of tribunals, etc. which are unlikely candidates for classical probability. In this view, Poisson's contribution was his sharp criticism of the alternative "inverse" (subjective, Bayesian) probability interpretation. Any criticism by Gauss and Laplace was muted and implicit. (Their later derivations did not use inverse probability.)</p>

<p>Major contributors to "classical" statistics in the early 20th century included <a href="Ronald_Aylmer_Fisher" title="wikilink">Fisher</a>, <a href="Jerzy_Neyman" title="wikilink">Neyman</a> and <a href="Egon_Pearson" title="wikilink">Pearson</a>. Fisher contributed to most of statistics and made significance testing the core of experimental science; Neyman formulated confidence intervals and contributed heavily to sampling theory; Neyman and Pearson paired in the creation of hypothesis testing. All valued objectivity, so the best interpretation of probability available to them was frequentist. All were suspicious of "inverse probability" (the available alternative) with prior probabilities chosen by the using the principle of indifference. Fisher said, "...the theory of inverse probability is founded upon an error, [referring to Bayes theorem] and must be wholly rejected." (from his Statistical Methods for Research Workers). While Neyman was a pure frequentist,<a class="footnoteRef" href="#fn15" id="fnref15"><sup>15</sup></a> Fisher's views of probability were unique; Both had nuanced view of probability. <a href="Richard_von_Mises" title="wikilink">von Mises</a> offered a combination of mathematical and philosophical support for frequentism in the era.<a class="footnoteRef" href="#fn16" id="fnref16"><sup>16</sup></a><a class="footnoteRef" href="#fn17" id="fnref17"><sup>17</sup></a></p>
<h2 id="etymology">Etymology</h2>

<p>According to the <em><a href="Oxford_English_Dictionary" title="wikilink">Oxford English Dictionary</a></em>, the term 'frequentist' was first used by <a href="Maurice_Kendall" title="wikilink">M. G. Kendall</a> in 1949, to contrast with <a href="Bayesian_probability" title="wikilink">Bayesians</a>, whom he called "non-frequentists".<a class="footnoteRef" href="#fn18" id="fnref18"><sup>18</sup></a><a class="footnoteRef" href="#fn19" id="fnref19"><sup>19</sup></a> He observed</p>
<dl>
<dd>3....we may broadly distinguish two main attitudes. One takes probability as 'a degree of rational belief', or some similar idea...the second defines probability in terms of frequencies of occurrence of events, or by relative proportions in 'populations' or 'collectives'; (p. 101)
</dd>
<dd>...
</dd>
<dd>12. It might be thought that the differences between the frequentists and the non-frequentists (if I may call them such) are largely due to the differences of the domains which they purport to cover. (p. 104)
</dd>
<dd>...
</dd>
<dd><em>I assert that this is not so</em> ... The essential distinction between the frequentists and the non-frequentists is, I think, that the former, in an effort to avoid anything savouring of matters of opinion, seek to define probability in terms of the objective properties of a population, real or hypothetical, whereas the latter do not. [emphasis in original]
</dd>
</dl>

<p>"The Frequency Theory of Probability" was used a generation earlier as a chapter title in Keynes (1921).<a class="footnoteRef" href="#fn20" id="fnref20"><sup>20</sup></a></p>

<p>The historical sequence: probability concepts were introduced and much of probability mathematics derived (prior to the 20th century), classical statistical inference methods were developed, the mathematical foundations of probability were solidified and current terminology was introduced (all in the 20th century). The primary historical sources in probability and statistics did not use the current terminology of classical, subjective (Bayesian) and frequentist probability.</p>
<h2 id="alternative-views">Alternative views</h2>

<p><a href="Probability_theory" title="wikilink">Probability theory</a> is a branch of mathematics. While its roots reach centuries into the past, it reached maturity with the axioms of <a href="Andrey_Kolmogorov" title="wikilink">Andrey Kolmogorov</a> in 1933. The theory focuses on the valid operations on probability values rather than on the initial assignment of values; the mathematics is largely independent of any interpretation of probability.</p>

<p>Applications and interpretations of <a class="uri" href="probability" title="wikilink">probability</a> are considered by philosophy, the sciences and statistics. All are interested in the extraction of knowledge from observations—<a href="inductive_reasoning" title="wikilink">inductive reasoning</a>. There are a variety of competing interpretations;<a class="footnoteRef" href="#fn21" id="fnref21"><sup>21</sup></a> All have problems. Major interpretations include classical probability, subjective probability and frequency interpretations.</p>
<ul>
<li><a href="Classical_definition_of_probability" title="wikilink">Classical probability</a> assigns probabilities based on physical idealized symmetry (dice, coins, cards). The classical definition is at risk of circularity; Probabilities are defined by assuming equality of probabilities.<a class="footnoteRef" href="#fn22" id="fnref22"><sup>22</sup></a> In the absence of symmetry the utility of the definition is limited.</li>
<li><a href="Bayesian_probability" title="wikilink">Subjective probability</a> (a family of competing interpretations) considers degrees of belief. All practical "subjective" probability interpretations are so constrained to rationality as to avoid most subjectivity. Real subjectivity is repellent to the sciences which strive for results independent of the observer and analyst. The historical roots of this concept extended to such non-numeric applications as legal evidence.</li>
<li>Frequency interpretations are empirical—they are defined by a ratio from an infinite series of trials. This is a very natural interpretation for scientific experiments. Mathematicians are dubious of the convergence properties of the non-mathematical series.<a class="footnoteRef" href="#fn23" id="fnref23"><sup>23</sup></a></li>
</ul>

<p>The frequentist interpretation does resolve difficulties with the classical interpretation, such as any problem where the natural symmetry of outcomes is not known. It does not address other issues, such as the <a href="dutch_book" title="wikilink">dutch book</a>. <a href="Propensity_probability" title="wikilink">Propensity probability</a> is an alternative physicalist approach.<a class="footnoteRef" href="#fn24" id="fnref24"><sup>24</sup></a></p>
<h2 id="notes">Notes</h2>
<h2 id="references">References</h2>
<ul>
<li>P W Bridgman, <em>The Logic of Modern Physics</em>, 1927</li>
<li>Alonzo Church, <em>The Concept of a Random Sequence</em>, 1940</li>
<li>Harald Cramér, <em>Mathematical Methods of Statistics</em>, 1946</li>
<li>William Feller, <em>An introduction to Probability Theory and its Applications</em>, 1957</li>
<li>P Martin-Löf, <em>On the Concept of a Random Sequence</em>, 1966</li>
<li>Richard von Mises, <em>Probability, Statistics, and Truth</em>, 1939 (German original 1928)</li>
<li>Jerzy Neyman, <em>First Course in Probability and Statistics</em>, 1950</li>
<li>Hans Reichenbach, <em>The Theory of Probability</em>, 1949 (German original 1935)</li>
<li>Bertrand Russell, <em>Human Knowledge</em>, 1948</li>
<li>

<p><a href="http://www.ma.utexas.edu/~friedman/freq.ps">PS</a></p></li>
</ul>

<p>"</p>

<p><a href="Category:Probability_interpretations" title="wikilink">Category:Probability interpretations</a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1"> Neyman's derivation of confidence intervals embraced the measure theoretic axioms of probability published by Kolmogorov a few years previously and referenced the subjective (Bayesian) probability definitions of Jeffreys published earlier in the decade. Neyman defined frequentist probability (under the name classical) and stated the need for randomness in the repeated samples or trials. He accepted in principle the possibility of multiple competing theories of probability while expressing several specific reservations about the existing alternative probability interpretation.<a href="#fnref1">↩</a></li>
<li id="fn2">von Mises, Richard (1939) <em>Probability, Statistics, and Truth</em> (in German) (English translation, 1981: Dover Publications; 2 Revised edition. ISBN 0486242145) (p.14)<a href="#fnref2">↩</a></li>
<li id="fn3"><a href="William_Feller" title="wikilink">William Feller</a> (1957), <em>An Introduction to Probability Theory and Its Applications, Vol. 1</em>, page 4<a href="#fnref3">↩</a></li>
<li id="fn4"><a href="John_Maynard_Keynes" title="wikilink">Keynes, John Maynard</a>; <em>A Treatise on Probability</em> (1921), Chapter VIII “The Frequency Theory of Probability”.<a href="#fnref4">↩</a></li>
<li id="fn5"><a href="#fnref5">↩</a></li>
<li id="fn6">Ellis, Robert Leslie (1843) “On the Foundations of the Theory of Probabilities”, <em>Transactions of the Cambridge Philosophical Society</em> vol 8<a href="#fnref6">↩</a></li>
<li id="fn7">Ellis, Robert Leslie (1854) “Remarks on the Fundamental Principles of the Theory of Probabilitiess”, <em>Transactions of the Cambridge Philosophical Society</em> vol 9<a href="#fnref7">↩</a></li>
<li id="fn8">Cournot, Antoine Augustin (1843) <em>Exposition de la théorie des chances et des probabilités</em>. L. Hachette, Paris. <a href="https://archive.org/details/expositiondelat00courgoog">archive.org</a><a href="#fnref8">↩</a></li>
<li id="fn9"></li>
<li id="fn10"></li>
<li id="fn11"><a href="#fnref11">↩</a></li>
<li id="fn12"><a href="#fnref12">↩</a></li>
<li id="fn13"> Bernoulli provided a classical example of drawing a large number of black and white pebbles from an urn (with replacement). The sample ratio allowed Bernoulli to infer the ratio in the urn, with tighter bounds as the number of samples increased. Historians can interpret the example as classical, frequentist or subjective probability. David says, "James has definitely started here the controversy on inverse probability..." Bernoulli wrote generations before Bayes, LaPlace and Gauss. The controversy continues.<a href="#fnref13">↩</a></li>
<li id="fn14"><a href="#fnref14">↩</a></li>
<li id="fn15"></li>
<li id="fn16"></li>
<li id="fn17"><em>The Frequency theory</em> Chapter 5; discussed in Donald Gilles, <em>Philosophical theories of probability</em> (2000), Psychology Press. ISBN 9780415182751 , p. 88.<a href="#fnref17">↩</a></li>
<li id="fn18"><a href="http://www.leidenuniv.nl/fsw/verduin/stathist/1stword.htm">Earliest Known Uses of Some of the Words of Probability &amp; Statistics</a><a href="#fnref18">↩</a></li>
<li id="fn19"><a href="#fnref19">↩</a></li>
<li id="fn20"></li>
<li id="fn21"><a href="#fnref21">↩</a></li>
<li id="fn22"><a href="#fnref22">↩</a></li>
<li id="fn23"></li>
<li id="fn24"></li>
</ol>
</section>
</body>
</html>
