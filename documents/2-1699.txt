


Inverse function theorem




Inverse function theorem

In mathematics, specifically differential calculus, the inverse function theorem gives sufficient conditions for a function to be invertible in a neighborhood of a point in its domain. The theorem also gives a formula for the derivative of the inverse function. In multivariable calculus, this theorem can be generalized to any continuously differentiable, vector-valued function whose Jacobian determinant is nonzero at a point in its domain. In this case, the theorem gives a formula for the Jacobian matrix of the inverse. There are also versions of the inverse function theorem for complex holomorphic functions, for differentiable maps between manifolds, for differentiable functions between Banach spaces, and so forth.
Statement of the theorem
For functions of a single variable, the theorem states that if 
 
 
 
  is a continuously differentiable function with nonzero derivative at the point 
 
 
 
 , then 
 
 
 
  is invertible in a neighborhood of 
 
 
 
 , the inverse is continuously differentiable, and


 
  where notationally the left side refers to the derivative of the inverse function evaluated at its value f(a). For functions of more than one variable, the theorem states that if the total derivative of a continuously differentiable function 
 
 
 
  defined from an open set of 
 
 
 
  into 
 
 
 
  is invertible at a point 
 
 
 
  (i.e., the Jacobian determinant of 
 
 
 
  at 
 
 
 
  is non-zero), then 
 
 
 
  is an invertible function near 
 
 
 
 . That is, an inverse function to 
 
 
 
  exists in some neighborhood of 
 
 
 
 . Moreover, the inverse function 
 
 
 
  is also continuously differentiable. In the infinite dimensional case it is required that the Fr√©chet derivative have a bounded inverse at 
 
 
 
 . Finally, the theorem says that


 
  where 
 
 
 
  denotes matrix inverse and 
 
 
 
  is the Jacobian matrix of the function 
 
 
 
  at the point 
 
 
 
 . This formula can also be derived from the chain rule. The chain rule states that for functions 
 
 
 
  and 
 
 
 
  which have total derivatives at 
 
 
 
  and 
 
 
 
  respectively,


 
  Letting 
 
 
 
  be 
 
 
 
  and 
 
 
 
  be 
 
 
 
 , 
 
 
 
  is the identity function, whose Jacobian matrix is also the identity. In this special case, the formula above can be solved for 
 
 
 
 . Note that the chain rule assumes the existence of total derivative of the inside function 
 
 
 
 , while the inverse function theorem proves that 
 
 
 
  has a total derivative at 
 
 
 
 . The existence of an inverse function to 
 
 
 
  is equivalent to saying that the system of 
 
 
 
  equations 
 
 
 
  can be solved for 
 
 
 
  in terms of 
 
 
 
  if we restrict 
 
 
 
  and 
 
 
 
  to small enough neighborhoods of 
 
 
 
  and 
 
 
 
 , respectively.
Example
Consider the vector-valued function

 
  from 
 
 
 
  to 
 
 
 
  defined by


 
  Then the Jacobian matrix is


 
  and the determinant is


 
  The determinant 
 
 
 
  is nonzero everywhere. By the theorem, for every point 
 
 
 
  in 
 
 
 
 , there exists a neighborhood about 
 
 
 
  over which 
 
 
 
  is invertible. Note that this is different than saying 
 
 
 
  is invertible over its entire image. In this example, 
 
 
 
  is not invertible because it is not injective (because 
 
 
 
 ).
Notes on methods of proof
As an important result, the inverse function theorem has been given numerous proofs. The proof most commonly seen in textbooks relies on the contraction mapping principle, also known as the Banach fixed point theorem. (This theorem can also be used as the key step in the proof of existence and uniqueness of solutions to ordinary differential equations.) Since this theorem applies in infinite-dimensional (Banach space) settings, it is the tool used in proving the infinite-dimensional version of the inverse function theorem (see "Generalizations", below). An alternate proof (which works only in finite dimensions) instead uses as the key tool the extreme value theorem for functions on a compact set.1 Yet another proof uses Newton's method, which has the advantage of providing an effective version of the theorem. That is, given specific bounds on the derivative of the function, an estimate of the size of the neighborhood on which the function is invertible can be obtained.2
Generalizations
Manifolds
The inverse function theorem can be generalized to differentiable maps between differentiable manifolds. In this context the theorem states that for a differentiable map 
 
 
 
 , if the differential of 
 
 
 
 ,


 
  is a linear isomorphism at a point 
 
 
 
  in 
 
 
 
  then there exists an open neighborhood 
 
 
 
  of 
 
 
 
  such that


 
  is a diffeomorphism. Note that this implies that 
 
 
 
  and 
 
 
 
  must have the same dimension at 
 
 
 
 . If the derivative of 
 
 
 
  is an isomorphism at all points 
 
 
 
  in 
 
 
 
  then the map 
 
 
 
  is a local diffeomorphism.
Banach spaces
The inverse function theorem can also be generalized to differentiable maps between Banach spaces. Let 
 
 
 
  and 
 
 
 
  be Banach spaces and 
 
 
 
  an open neighbourhood of the origin in 
 
 
 
 . Let 
 
 
 
  be continuously differentiable and assume that the derivative 
 
 
 
  of 
 
 
 
  at 0 is a bounded linear isomorphism of 
 
 
 
  onto 
 
 
 
 . Then there exists an open neighbourhood 
 
 
 
  of 
 
 
 
  in 
 
 
 
  and a continuously differentiable map 
 
 
 
  such that 
 
 
 
  for all 
 
 
 
  in 
 
 
 
 . Moreover, 
 
 
 
  is the only sufficiently small solution 
 
 
 
  of the equation 
 
 
 
 .
Banach manifolds
These two directions of generalization can be combined in the inverse function theorem for Banach manifolds.3
Constant rank theorem
The inverse function theorem (and the implicit function theorem) can be seen as a special case of the constant rank theorem, which states that a smooth map with constant rank near a point can be put in a particular normal form near that point.4 Specifically, if 
 
 
 
  has constant rank near a point 
 
 
 
 , then there are open neighborhoods 
 
 
 
  of 
 
 
 
  and 
 
 
 
  of 
 
 
 
  and there are diffeomorphisms 
 
 
 
  and 
 
 
 
  such that 
 
 
 
  and such that the derivative 
 
 
 
  is equal to 
 
 
 
 . That is, 
 
 
 
  "looks like" its derivative near 
 
 
 
 . Semicontinuity of the rank function implies that the set of points near which the derivative has constant rank is an open dense subset of the domain of the map. So the constant rank theorem applies "generically" across the domain.
When the derivative of 
 
 
 
  is injective (resp. surjective) at a point 
 
 
 
 , it is also injective (resp. surjective) in a neighborhood of 
 
 
 
 , and hence the rank of 
 
 
 
  is constant on that neighborhood, so the constant rank theorem applies.
Holomorphic Functions
If the Jacobian (in this context the matrix formed by the complex derivatives) of a holomorphic function 
 
 
 
 , defined from an open set 
 
 
 
  of 
 
 
 
  into 
 
 
 
  , is invertible at a point 
 
 
 
 , then 
 
 
 
  is an invertible function near 
 
 
 
 . This follows immediately from the theorem above. One can also show, that this inverse is again a holomorphic function.5
See also

Implicit function theorem

Notes
References







de:Satz von der impliziten Funktion#Satz von der Umkehrabbildung"
Category:Multivariable calculus Category:Differential topology Category:Inverse functions Category:Theorems in real analysis Category:Theorems in calculus



Michael Spivak, Calculus on Manifolds.
John H. Hubbard and Barbara Burke Hubbard, Vector Analysis, Linear Algebra, and Differential Forms: a unified approach, Matrix Editions, 2001.
, .
William M. Boothby, An Introduction to Differentiable Manifolds and Riemannian Geometry, Revised Second Edition, Academic Press, 2002, ISBN 0-12-116051-3.
K. Fritzsche, H. Grauert, [http://books.google.de/books?id=jSeRz36zXIMC&lpg;;=PP1&dq;=fritzsche%20grauert&hl;=de&pg;=PA33#v=onepage&q;&f;=false "From Holomorphic Functions to Complex Manifolds"], Springer-Verlag, (2002). Page 33.




