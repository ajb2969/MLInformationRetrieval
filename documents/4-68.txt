   Bisection method      Bisection method   (Figure)  A few steps of the bisection method applied over the starting range [a 1 ;b 1 ]. The bigger red dot is the root of the function.   The bisection method in mathematics is a root-finding method that repeatedly bisects an interval and then selects a subinterval in which a root must lie for further processing. It is a very simple and robust method, but it is also relatively slow. Because of this, it is often used to obtain a rough approximation to a solution which is then used as a starting point for more rapidly converging methods. 1 The method is also called the interval halving method, 2 the binary search method , 3 or the dichotomy method . 4  The method  The method is applicable for numerically solving the equation f ( x ) = 0 for the real variable x , where f is a continuous function defined on an interval [ a , b ] and where f ( a ) and f ( b ) have opposite signs. In this case a and b are said to bracket a root since, by the intermediate value theorem , the continuous function f must have at least one root in the interval ( a , b ).  At each step the method divides the interval in two by computing the midpoint c = ( a + b ) / 2 of the interval and the value of the function f ( c ) at that point. Unless c is itself a root (which is very unlikely, but possible) there are now only two possibilities: either f ( a ) and f ( c ) have opposite signs and bracket a root, or f ( c ) and f ( b ) have opposite signs and bracket a root. 5 The method selects the subinterval that is guaranteed to be a bracket as the new interval to be used in the next step. In this way an interval that contains a zero of f is reduced in width by 50% at each step. The process is continued until the interval is sufficiently small.  Explicitly, if f ( a ) and f ( c ) have opposite signs, then the method sets c as the new value for b , and if f ( b ) and f ( c ) have opposite signs then the method sets c as the new a . (If f ( c )=0 then c may be taken as the solution and the process stops.) In both cases, the new f ( a ) and f ( b ) have opposite signs, so the method is applicable to this smaller interval. 6  Iteration tasks  The input for the method is a continuous function f , an interval [ a , b ], and the function values f ( a ) and f ( b ). The function values are of opposite sign (there is at least one zero crossing within the interval). Each iteration performs these steps:   Calculate c , the midpoint of the interval, c = 0.5 * (''a ''+ b ).  Calculate the function value at the midpoint, f ( c ).  If convergence is satisfactory (that is, a - c is sufficiently small, or f ( c ) is sufficiently small), return c and stop iterating.  Examine the sign of f ( c ) and replace either ( a , f ( a )) or ( b , f ( b )) with ( c , f ( c )) so that there is a zero crossing within the new interval.   When implementing the method on a computer, there can be problems with finite precision, so there are often additional convergence tests or limits to the number of iterations. Although f is continuous, finite precision may preclude a function value ever being zero. For     f   (  x  )    =   x  −  π         f  x     x  normal-−  π     f(x)=x−π   , there will never be a finite representation of x that gives zero. Floating point representations also have limited precision, so at some point the midpoint of [ a , b ] will be either a or b .  Algorithm  The method may be written in pseudocode as follows: 7  INPUT: Function f , endpoint values a , b , tolerance TOL , maximum iterations NMAX  CONDITIONS: a  0 or f ( a ) > 0 and f ( b ) f(x) = x^3 - x - 2 \,.  First, two numbers   a   a   a   and   b   b   b   have to be found such that    f   (  a  )       f  a    f(a)   and    f   (  b  )       f  b    f(b)   have opposite signs. For the above function,    a  =  1      a  1    a=1   and    b  =  2      b  2    b=2   satisfy this criterion, as       f   (  1  )    =     (  1  )   3   -   (  1  )   -  2   =   -  2           f  1      superscript  1  3   1  2          2      f(1)=(1)^{3}-(1)-2=-2   and       f   (  2  )    =     (  2  )   3   -   (  2  )   -  2   =   +  4 .           f  2      superscript  2  3   2  2          4 .      f(2)=(2)^{3}-(2)-2=+4\,.   Because the function is continuous, there must be a root within the interval [1, 2].  In the first iteration, the end points of the interval which brackets the root are     a  1   =  1       subscript  a  1   1    a_{1}=1   and     b  1   =  2       subscript  b  1   2    b_{1}=2   , so the midpoint is       c  1   =    2  +  1   2   =  1.5         subscript  c  1       2  1   2        1.5     c_{1}=\frac{2+1}{2}=1.5   The function value at the midpoint is     f   (   c  1   )    =     (  1.5  )   3   -   (  1.5  )   -  2   =   -  0.125           f   subscript  c  1       superscript  1.5  3   1.5  2          0.125      f(c_{1})=(1.5)^{3}-(1.5)-2=-0.125   . Because    f   (   c  1   )       f   subscript  c  1     f(c_{1})   is negative,    a  =  1      a  1    a=1   is replaced with    a  =  1.5      a  1.5    a=1.5   for the next iteration to ensure that    f   (  a  )       f  a    f(a)   and    f   (  b  )       f  b    f(b)   have opposite signs. As this continues, the interval between   a   a   a   and   b   b   b   will become increasingly smaller, converging on the root of the function. See this happen in the table below.      Iteration       a  n     subscript  a  n    a_{n}          b  n     subscript  b  n    b_{n}          c  n     subscript  c  n    c_{n}          f   (   c  n   )       f   subscript  c  n     f(c_{n})          1   1   2   1.5   −0.125     2   1.5   2   1.75   1.6093750     3   1.5   1.75   1.625   0.6660156     4   1.5   1.625   1.5625   0.2521973     5   1.5   1.5625   1.5312500   0.0591125     6   1.5   1.5312500   1.5156250   −0.0340538     7   1.5156250   1.5312500   1.5234375   0.0122504     8   1.5156250   1.5234375   1.5195313   −0.0109712     9   1.5195313   1.5234375   1.5214844   0.0006222     10   1.5195313   1.5214844   1.5205078   −0.0051789     11   1.5205078   1.5214844   1.5209961   −0.0022794     12   1.5209961   1.5214844   1.5212402   −0.0008289     13   1.5212402   1.5214844   1.5213623   −0.0001034     14   1.5213623   1.5214844   1.5214233   0.0002594     15   1.5213623   1.5214233   1.5213928   0.0000780     After 13 iterations, it becomes apparent that there is a convergence to about 1.521: a root for the polynomial.  Analysis  The method is guaranteed to converge to a root of f if f is a continuous function on the interval [ a , b ] and f ( a ) and f ( b ) have opposite signs. The absolute error is halved at each step so the method converges linearly , which is comparatively slow.  Specifically, if c 1 = ( a + b )/2 is the midpoint of the initial interval, and c n is the midpoint of the interval in the n th step, then the difference between c n and a solution c is bounded by 8        |    c  n   -  c   |   ≤    |   b  -  a   |    2  n     .           subscript  c  n   c          b  a     superscript  2  n      |c_{n}-c|\leq\frac{|b-a|}{2^{n}}.   This formula can be used to determine in advance the number of iterations that the bisection method would need to converge to a root to within a certain tolerance. The number of iterations needed, n , to achieve a given error (or tolerance), ε, is given by:     n  =    log  2    (    ϵ  0   ϵ   )    =     log   ϵ  0    -   log  ϵ     log  2     ,        n    subscript   2      subscript  ϵ  0   ϵ                subscript  ϵ  0      ϵ      2       n=\log_{2}\left(\frac{\epsilon_{0}}{\epsilon}\right)=\frac{\log\epsilon_{0}-%
 \log\epsilon}{\log 2},     where      ϵ  0   =  initial bracket size  =   b  -  a    .         subscript  ϵ  0   initial bracket size         b  a      \epsilon_{0}=\text{initial bracket size}=b-a.     Therefore, the linear convergence is expressed by      ϵ   n  +  1    =   constant  ×   ϵ  n  m     ,   m  =  1.      formulae-sequence     subscript  ϵ    n  1      constant   superscript   subscript  ϵ  n   m       m  1.     \epsilon_{n+1}=\text{constant}\times\epsilon_{n}^{m},\ m=1.     See also   Secant method  Newton's method  Root-finding algorithm  Binary search algorithm  Lehmer–Schur algorithm , generalization of the bisection method in the complex plane  Nested intervals  Brent's method   References     Further reading      External links    Bisection Method Notes, PPT, Mathcad, Maple, Matlab, Mathematica from Holistic Numerical Methods Institute  Module for the Bisection Method by John H. Mathews   "  Category:Root-finding algorithms  Category:Articles with example pseudocode     ↩  http://siber.cankaya.edu.tr/NumericalComputations/ceng375/node32.html ↩  ↩  Encyclopedia of Mathematics ↩  If the function has the same sign at the endpoints of an interval, the endpoints may or may not bracket roots of the function. ↩  for section ↩  . This version recomputes the function values at each iteration rather than carrying them to the next iterations. ↩  , Theorem 2.1 ↩     