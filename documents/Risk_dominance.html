<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="495">Risk dominance</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>Risk dominance</h1>
<hr/>

<p><strong>Risk dominance</strong> and <strong>payoff dominance</strong> are two related refinements of the <a href="Nash_equilibrium" title="wikilink">Nash equilibrium</a> (NE) <a href="solution_concept" title="wikilink">solution concept</a> in <a href="game_theory" title="wikilink">game theory</a>, defined by <a href="John_Harsanyi" title="wikilink">John Harsanyi</a> and <a href="Reinhard_Selten" title="wikilink">Reinhard Selten</a>. A Nash equilibrium is considered <strong>payoff dominant</strong> if it is <a href="Pareto_efficiency" title="wikilink">Pareto superior</a> to all other Nash equilibria in the game. When faced with a choice among equilibria, all players would agree on the payoff dominant equilibrium since it offers to each player at least as much payoff as the other Nash equilibria. Conversely, a Nash equilibrium is considered <strong>risk dominant</strong> if it has the largest <a href="basin_of_attraction" title="wikilink">basin of attraction</a> (i.e. is less risky). This implies that the more uncertainty players have about the actions of the other player(s), the more likely they will choose the strategy corresponding to it.</p>

<p>The <a href="payoff_matrix" title="wikilink">payoff matrix</a> in Figure 1 provides a simple two-player, two-strategy example of a game with two pure Nash equilibria. The strategy pair (Hunt, Hunt) is payoff dominant since payoffs are higher for both players compared to the other pure NE, (Gather, Gather). On the other hand, (Gather, Gather) risk dominates (Hunt, Hunt) since if uncertainty exists about the other player's action, gathering will provide a higher expected payoff. The game in Figure 1 is a well-known game-theoretic dilemma called <a href="stag_hunt" title="wikilink">stag hunt</a>. The rationale behind it is that communal action (hunting) yields a higher return if all players combine their skills, but if it is unknown whether the other player helps in hunting, gathering might turn out to be the better individual strategy for food provision, since it does not depend on <a href="coordination_game" title="wikilink">coordinating</a> with the other player. In addition, gathering alone is preferred to gathering in competition with others. Like the <a href="Prisoner's_dilemma" title="wikilink">Prisoner's dilemma</a>, it provides a reason why <a href="collective_action" title="wikilink">collective action</a> might fail in the absence of <a href="credible_commitment" title="wikilink">credible commitments</a>.</p>
<center>
<table>
<tbody>
<tr class="odd">
<td style="text-align: left;">
<p>{{Payoff matrix | Name = Fig. 1: <a href="Stag_hunt" title="wikilink">Stag hunt</a> example</p></td>
<td style="text-align: left;">
<p>2L = Hunt | 2R = Gather | 1U = Hunt | UL = 5, 5 | UR = 0, 4 | 1D = Gather | DL = 4, 0 | DR = 2, 2 | float = none}}</p></td>
<td style="text-align: left;">
<p>{{Payoff matrix | Name = Fig. 2: Generic <a href="coordination_game" title="wikilink">coordination game</a></p></td>
<td style="text-align: left;">
<p>2L = H | 2R = G | 1U = H | UL = A, a | UR = C, b | 1D = G | DL = B, c | DR = D, d | float = none}}</p></td>
</tr>
</tbody>
</table>
</center>
<h2 id="formal-definition">Formal definition</h2>

<p>The game given in Figure 2 is a <a href="coordination_game" title="wikilink">coordination game</a> if the following payoff inequalities hold for player 1 (rows): A &gt; B, D &gt; C, and for player 2 (columns): a &gt; b, d &gt; c. The strategy pairs (H, H) and (G, G) are then the only <a href="pure_strategy" title="wikilink">pure</a> Nash equilibria. In addition there is a <a href="mixed_strategy" title="wikilink">mixed</a> Nash equilibrium where player 1 plays H with probability p = (d-c)/(a-b-c+d) and G with probability 1–p; player 2 plays H with probability q = (D-C)/(A-B-C+D) and G with probability 1–q.</p>

<p>Strategy pair (H, H) <strong>payoff dominates</strong> (G, G) if A ≥ D, a ≥ d, and at least one of the two is a strict inequality: A &gt; D or a &gt; d.</p>

<p>Strategy pair (G, G) <strong>risk dominates</strong> (H, H) if the product of the deviation losses is highest for (G, G) (Harsanyi and Selten, 1988, Lemma 5.4.4). In other words, if the following inequality holds: . If the inequality is strict then (G, G) strictly risk dominates (H, H).(That is, players have more incentive to deviate).</p>

<p>If the game is symmetric, so if A = a, B = b, etc., the inequality allows for a simple interpretation: We assume the players are unsure about which strategy the opponent will pick and assign probabilities for each strategy. If each player assigns probabilities ½ to H and G each, then (G, G) risk dominates (H, H) if the expected payoff from playing G exceeds the expected payoff from playing H: , or simply .</p>

<p>Another way to calculate the risk dominant equilibrium is to calculate the risk factor for all equilibria and to find the equilibrium with the smallest risk factor. To calculate the risk factor in our 2x2 game, consider the expected payoff to a player if they play H

<math display="block" id="Risk_dominance:0">
 <semantics>
  <mrow>
   <mrow>
    <mi>E</mi>
    <mrow>
     <mo stretchy="false">[</mo>
     <msub>
      <mi>π</mi>
      <mi>H</mi>
     </msub>
     <mo stretchy="false">]</mo>
    </mrow>
   </mrow>
   <mo>=</mo>
   <mrow>
    <mrow>
     <mi>p</mi>
     <mi>A</mi>
    </mrow>
    <mo>+</mo>
    <mrow>
     <mrow>
      <mo stretchy="false">(</mo>
      <mrow>
       <mn>1</mn>
       <mo>-</mo>
       <mi>p</mi>
      </mrow>
      <mo stretchy="false">)</mo>
     </mrow>
     <mi>C</mi>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <times></times>
     <ci>E</ci>
     <apply>
      <csymbol cd="latexml">delimited-[]</csymbol>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>π</ci>
       <ci>H</ci>
      </apply>
     </apply>
    </apply>
    <apply>
     <plus></plus>
     <apply>
      <times></times>
      <ci>p</ci>
      <ci>A</ci>
     </apply>
     <apply>
      <times></times>
      <apply>
       <minus></minus>
       <cn type="integer">1</cn>
       <ci>p</ci>
      </apply>
      <ci>C</ci>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   E[\pi_{H}]=pA+(1-p)C
  </annotation>
 </semantics>
</math>

 (where <em>p</em> is the probability that the other player will play H), and compare it to the expected payoff if they play G

<math display="block" id="Risk_dominance:1">
 <semantics>
  <mrow>
   <mrow>
    <mi>E</mi>
    <mrow>
     <mo stretchy="false">[</mo>
     <msub>
      <mi>π</mi>
      <mi>G</mi>
     </msub>
     <mo stretchy="false">]</mo>
    </mrow>
   </mrow>
   <mo>=</mo>
   <mrow>
    <mrow>
     <mi>p</mi>
     <mi>B</mi>
    </mrow>
    <mo>+</mo>
    <mrow>
     <mrow>
      <mo stretchy="false">(</mo>
      <mrow>
       <mn>1</mn>
       <mo>-</mo>
       <mi>p</mi>
      </mrow>
      <mo stretchy="false">)</mo>
     </mrow>
     <mi>D</mi>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <times></times>
     <ci>E</ci>
     <apply>
      <csymbol cd="latexml">delimited-[]</csymbol>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>π</ci>
       <ci>G</ci>
      </apply>
     </apply>
    </apply>
    <apply>
     <plus></plus>
     <apply>
      <times></times>
      <ci>p</ci>
      <ci>B</ci>
     </apply>
     <apply>
      <times></times>
      <apply>
       <minus></minus>
       <cn type="integer">1</cn>
       <ci>p</ci>
      </apply>
      <ci>D</ci>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   E[\pi_{G}]=pB+(1-p)D
  </annotation>
 </semantics>
</math>

. The value of <em>p</em> which makes these two expected values equal is the risk factor for the equilibrium (H, H), with 

<math display="inline" id="Risk_dominance:2">
 <semantics>
  <mrow>
   <mn>1</mn>
   <mo>-</mo>
   <mi>p</mi>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <minus></minus>
    <cn type="integer">1</cn>
    <ci>p</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   1-p
  </annotation>
 </semantics>
</math>

 the risk factor for playing (G, G). You can also calculate the risk factor for playing (G, G) by doing the same calculation, but setting <em>p</em> as the probability the other player will play G. An interpretation for <em>p</em> is it is the smallest probability that the opponent must play that strategy such that the person's own payoff from copying the opponent's strategy is greater than if the other strategy was played.</p>
<h2 id="equilibrium-selection">Equilibrium selection</h2>

<p>A number of evolutionary approaches have established that when played in a large population, players might fail to play the payoff dominant equilibrium strategy and instead end up in the payoff dominated, risk dominant equilibrium. Two separate evolutionary models both support the idea that the risk dominant equilibrium is more likely to occur. The first model, based on <a href="replicator_dynamics" title="wikilink">replicator dynamics</a>, predicts that a population is more likely to adopt the risk dominant equilibrium than the payoff dominant equilibrium. The second model, based on <a href="Best_response#Best_response_dynamics" title="wikilink">best response</a> <a href="strategy_revision" title="wikilink">strategy revision</a> and <a class="uri" href="mutation" title="wikilink">mutation</a>, predicts that the risk dominant state is the only <a href="stochastically_stable" title="wikilink">stochastically stable</a> equilibrium. Both models assume that multiple two-player games are played in a population of N players. The players are matched randomly with opponents, with each player having equal likelihoods of drawing any of the N−1 other players. The players start with a pure strategy, G or H, and play this strategy against their opponent. In replicator dynamics, the population game is repeated in sequential generations where subpopulations change based on the success of their chosen strategies. In best response, players update their strategies to improve expected payoffs in the subsequent generations. The recognition of Kandori, Mailath &amp; Rob (1993) and Young (1993) was that if the rule to update one's strategy allows for mutation, and the probability of mutation vanishes, i.e. asymptotically reaches zero over time, the likelihood that the risk dominant equilibrium is reached goes to one, even if it is payoff dominated.</p>
<h2 id="notes">Notes</h2>
<ul>
<li>

<p>A single Nash equilibrium is trivially payoff and risk dominant if it is the only NE in the game.</p></li>
<li>

<p>Similar distinctions between strict and weak exist for most definitions here, but are not denoted explicitly unless necessary.</p></li>
<li>

<p>Harsanyi and Selten (1988) propose that the payoff dominant equilibrium is the rational choice in the stag hunt game, however Harsanyi (1995) retracted this conclusion to take risk dominance as the relevant selection criterion.</p></li>
</ul>
<h2 id="references">References</h2>
<ul>
<li>Samuel Bowles: <em>Microeconomics: Behavior, Institutions, and Evolution</em>, Princeton University Press, pp. 45–46 (2004) ISBN 0-691-09163-3</li>
<li>Drew Fudenberg and David K. Levine: <em>The Theory of Learning in Games</em>, MIT Press, p. 27 (1999) ISBN 0-262-06194-5</li>
<li>John C. Harsanyi: "A New Theory of Equilibrium Selection for Games with Complete Information", <em>Games and Econonmic Behavior</em> 8, pp. 91–122 (1995)</li>
<li>John C. Harsanyi and Reinhard Selten: <em>A General Theory of Equilibrium Selection in Games</em>, MIT Press (1988) ISBN 0-262-08173-3</li>
<li>Michihiro Kandori, George J. Mailath &amp; <a href="Rafael_Rob" title="wikilink">Rafael Rob</a>: "Learning, Mutation, and Long-run Equilibria in Games", <em>Econometrica</em> 61, pp. 29–56 (1993) <a href="http://econpapers.repec.org/article/ecmemetrp/v_3A61_3Ay_3A1993_3Ai_3A1_3Ap_3A29-56.htm">Abstract</a></li>
<li>Roger B. Myerson: <em>Game Theory, Analysis of Conflict</em>, Harvard University Press, pp. 118–119 (1991) ISBN 0-674-34115-5</li>
<li><a href="Larry_Samuelson" title="wikilink">Larry Samuelson</a>: <em>Evolutionary Games and Equilibrium Selection</em>, MIT Press (1997) ISBN 0-262-19382-5</li>
<li>H. Peyton Young: "The Evolution of Conventions", <em>Econometrica</em>, 61, pp. 57–84 (1993) <a href="http://econpapers.repec.org/article/ecmemetrp/v_3a61_3ay_3a1993_3ai_3a1_3ap_3a57-84.htm">Abstract</a></li>
<li>H. Peyton Young: <em>Individual Strategy and Social Structure</em>, Princeton University Press (1998) ISBN 0-691-08687-7</li>
</ul>

<p>"</p>

<p><a href="Category:Game_theory" title="wikilink">Category:Game theory</a> <a href="Category:Evolutionary_game_theory" title="wikilink">Category:Evolutionary game theory</a></p>
</body>
</html>
