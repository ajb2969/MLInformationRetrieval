   Minkowski–Bouligand dimension      Minkowski–Bouligand dimension   thumb|450px|Estimating the box-counting dimension of the coast of Great Britain In fractal geometry , the Minkowski–Bouligand dimension , also known as Minkowski dimension or box-counting dimension , is a way of determining the fractal dimension of a set  S in a Euclidean space  R n , or more generally in a metric space ( X , d ).  To calculate this dimension for a fractal S , imagine this fractal lying on an evenly-spaced grid, and count how many boxes are required to cover the set. The box-counting dimension is calculated by seeing how this number changes as we make the grid finer by applying a box-counting algorithm.  Suppose that N ( ε ) is the number of boxes of side length ε required to cover the set. Then the box-counting dimension is defined as:  $$\dim_{\rm box}(S) := \lim_{\varepsilon \to 0} \frac {\log N(\varepsilon)}{\log (1/\varepsilon)}.$$  Roughly speaking, this means the dimension is the exponent d such that N (1/ n ) ≈ C n d , which is what one would expect in the trivial case where S is a smooth space (a manifold) of integer dimension d.  If the above limit does not exist, one may still take the limit superior and limit inferior , which respectively define the upper box dimension and lower box dimension . The upper box dimension is sometimes called the entropy dimension , Kolmogorov dimension , Kolmogorov capacity , limit capacity or upper Minkowski dimension , while the lower box dimension is also called the lower Minkowski dimension .  The upper and lower box dimensions are strongly related to the more popular Hausdorff dimension . Only in very special applications is it important to distinguish between the three (see below ). Yet another measure of fractal dimension is the correlation dimension .  Alternative definitions  thumb|350px|Examples of ball packing, ball covering, and box covering. It is possible to define the box dimensions using balls, with either the covering number or the packing number. The covering number $N_{\rm covering}(\varepsilon)$ is the minimal number of open balls of radius ε required to cover the fractal, or in other words, such that their union contains the fractal. We can also consider the intrinsic covering number $N'_{\rm covering}(\varepsilon)$ , which is defined the same way but with the additional requirement that the centers of the open balls lie inside the set S . The packing number $N_{\rm packing}(\varepsilon)$ is the maximal number of disjoint open balls of radius ε one can situate such that their centers would be inside the fractal. While N , N covering , N ' covering and N packing are not exactly identical, they are closely related, and give rise to identical definitions of the upper and lower box dimensions. This is easy to prove once the following inequalities are proven:  $$N_\text{packing}(\varepsilon) \leq N'_\text{covering}(\varepsilon) \leq N_\text{covering}(\varepsilon/2). \,$$  These, in turn, follow with a little effort from the triangle inequality .  The advantage of using balls rather than squares is that this definition generalizes to any metric space . In other words, the box definition is extrinsic — one assumes the fractal space S is contained in a Euclidean space , and defines boxes according to the external geometry of the containing space. However, the dimension of S should be intrinsic , independent of the environment into which S is placed, and the ball definition can be formulated intrinsically. One defines an internal ball as all points of S within a certain distance of a chosen center, and one counts such balls to get the dimension. (More precisely, the N covering definition is extrinsic, but the other two are intrinsic.)  The advantage of using boxes is that in many cases N ( ε ) may be easily calculated explicitly, and that for boxes the covering and packing numbers (defined in an equivalent way) are equal.  The logarithm of the packing and covering numbers are sometimes referred to as entropy numbers , and are somewhat analogous to the concepts of thermodynamic entropy and information-theoretic entropy , in that they measure the amount of "disorder" in the metric space or fractal at scale ε , and also measure how many bits or digits one would need to specify a point of the space to accuracy ε .  Another equivalent (extrinsic) definition for the box-counting dimension, is given by the formula:  $$\dim_\text{box}(S) = n - \lim_{r \to 0} \frac{\log \text{vol}(S_r)}{\log r},$$  where for each r > 0, the set $S_r$ is defined to be the r -neighborhood of S , i.e. the set of all points in $R^n$ which are at distance less than r from S (or equivalently, $S_r$ is the union of all the open balls of radius r which are centered at a point in S ).  Properties  Both box dimensions are finitely additive, i.e. if { A 1 , .... A n } is a finite collection of sets then  $$\dim (A_1 \cup \dotsb \cup A_n) = \max \{ \dim A_1 ,\dots, \dim A_n \}. \,$$  However, they are not countably additive, i.e. this equality does not hold for an infinite sequence of sets. For example, the box dimension of a single point is 0, but the box dimension of the collection of rational numbers in the interval [0, 1] has dimension 1. The Hausdorff measure by comparison, is countably additive.  An interesting property of the upper box dimension not shared with either the lower box dimension or the Hausdorff dimension is the connection to set addition. If A and B are two sets in a Euclidean space then A + B is formed by taking all the pairs of points a,b where a is from A and b is from B and adding a+b . One has  $$\dim_\text{upper box}(A+B)\leq \dim_\text{upper box}(A)+\dim_\text{upper box}(B).$$  Relations to the Hausdorff dimension  The box-counting dimension is one of a number of definitions for dimension that can be applied to fractals. For many well behaved fractals all these dimensions are equal; in particular, these dimensions coincide whenever the fractal satisfies the open set condition (OSC) . 1 For example, the Hausdorff dimension , lower box dimension, and upper box dimension of the Cantor set are all equal to log(2)/log(3). However, the definitions are not equivalent.  The box dimensions and the Hausdorff dimension are related by the inequality  $$\dim_{\operatorname{Haus}} \leq  \dim_{\operatorname{lower box}} \leq \dim_{\operatorname{upper box}}.$$  In general both inequalities may be strict . The upper box dimension may be bigger than the lower box dimension if the fractal has different behaviour in different scales. For example, examine the set of numbers in the interval [0,1] satisfying the condition   for any n , all the digits between the 2 2 n -th digit and the (2 2 n +1 − 1)th digit are zero   The digits in the "odd place-intervals", i.e. between digits 2 2 n +1 and 2 2 n +2 − 1 are not restricted and may take any value. This fractal has upper box dimension 2/3 and lower box dimension 1/3, a fact which may be easily verified by calculating N ( ε ) for $\varepsilon=10^{-2^n}$ and noting that their values behave differently for n even and odd.  More examples: The set of rational numbers $\mathbb{Q}$ , a countable set with $\dim_{\operatorname{Haus}} = 0$ , has $\dim_{\operatorname{box}} = 1$ because its closure, $\mathbb{R}$ , has dimension 1. In fact,  $$\dim_{\operatorname{box}}  \left\{0,1,\frac{1}{2}, \frac{1}{3}, \frac{1}{4}, \ldots\right\} = \frac{1}{2}.$$  These examples show that adding a countable set can change box-dimension, showing a kind of instability of this dimension.  See also   Correlation dimension  Packing dimension  Uncertainty exponent  Weyl–Berry conjecture  Lacunarity   References      External links   FrakOut!: an OSS application for calculating the fractal dimension of a shape using the box counting method (Does not automatically place the boxes for you).  FracLac: online user guide and software ImageJ and FracLac box counting plugin; free user-friendly open source software for digital image analysis in biology   "  Category:Fractals  Category:Dimension theory     ↩     