   Zipf–Mandelbrot law      Zipf–Mandelbrot law   |  cdf        =      H   k  ,  q  ,  s     H   N  ,  q  ,  s         subscript  H   k  q  s     subscript  H   N  q  s      \frac{H_{k,q,s}}{H_{N,q,s}}    |  mean       =       H   N  ,  q  ,   s  -  1      H   N  ,  q  ,  s     -  q         subscript  H   N  q    s  1      subscript  H   N  q  s     q    \frac{H_{N,q,s-1}}{H_{N,q,s}}-q    |  median     =|  mode       =     1    1   1\,    |  variance   =|  skewness   =|  kurtosis   =|  entropy    =       s   H   N  ,  q  ,  s       ∑   k  =  1   N     ln   (   k  +  q   )      (   k  +  q   )   s      +   ln   (   H   N  ,  q  ,  s    )            s   subscript  H   N  q  s       superscript   subscript     k  1    N         k  q     superscript    k  q   s         subscript  H   N  q  s       \frac{s}{H_{N,q,s}}\sum_{k=1}^{N}\frac{\ln(k+q)}{(k+q)^{s}}+\ln(H_{N,q,s})    |  mgf        =|  char       =|  }} In probability theory and statistics , the Zipf–Mandelbrot law is a discrete probability distribution . Also known as the Pareto -Zipf law, it is a power-law distribution on ranked data , named after the linguist  George Kingsley Zipf who suggested a simpler distribution called Zipf's law , and the mathematician Benoît Mandelbrot , who subsequently generalized it.  The probability mass function is given by:       f   (  k  ;  N  ,  q  ,  s  )    =    1  /    (   k  +  q   )   s     H   N  ,  q  ,  s           f   k  N  q  s        1   superscript    k  q   s     subscript  H   N  q  s       f(k;N,q,s)=\frac{1/(k+q)^{s}}{H_{N,q,s}}     where    H   N  ,  q  ,  s      subscript  H   N  q  s     H_{N,q,s}   is given by:       H   N  ,  q  ,  s    =    ∑   i  =  1   N    1    (   i  +  q   )   s          subscript  H   N  q  s      superscript   subscript     i  1    N     1   superscript    i  q   s       H_{N,q,s}=\sum_{i=1}^{N}\frac{1}{(i+q)^{s}}     which may be thought of as a generalization of a harmonic number . In the formula,   k   k   k   is the rank of the data, and   q   q   q   and   s   s   s   are parameters of the distribution. In the limit as   N   N   N   approaches infinity, this becomes the Hurwitz zeta function     ζ   (  s  ,  q  )       ζ   s  q     \zeta(s,q)   . For finite   N   N   N   and    q  =  0      q  0    q=0   the Zipf–Mandelbrot law becomes Zipf's law . For infinite   N   N   N   and    q  =  0      q  0    q=0   it becomes a Zeta distribution .  Applications  The distribution of words ranked by their frequency in a random text corpus is approximated by a power-law distribution, known as Zipf's law .  If one plots the frequency rank of words contained in a moderately sized corpus of text data versus the number of occurrences or actual frequencies, one obtains a power-law distribution, with exponent close to one (but see Powers, 1998 and Gelbukh & Sidorov, 2001). Zipf's law implicitly assumes a fixed vocabulary size, but the Harmonic series with s =1 does not converge, while the Zipf-Mandelbrot generalization with s >1 does. Furthermore, there is evidence that the closed class of functional words that define a language obeys a Zipf-Mandelbrot distribution with different parameters from the open classes of contentive words that vary by topic, field and register. 1  In ecological field studies, the relative abundance distribution (i.e. the graph of the number of species observed as a function of their abundance) is often found to conform to a Zipf–Mandelbrot law. 2  Within music, many metrics of measuring "pleasing" music conform to Zipf–Mandelbrot distributions. 3  Notes  References    Reprinted as        External links   Z. K. Silagadze: Citations and the Zipf-Mandelbrot's law  NIST: Zipf's law  W. Li's References on Zipf's law  Gelbukh & Sidorov, 2001: Zipf and Heaps Laws’ Coefficients Depend on Language   "  Category:Discrete distributions  Category:Power laws  Category:Computational linguistics  Category:Quantitative linguistics  Category:Probability distributions     ↩  ↩  ↩     