   Cramér–von Mises criterion      Cramér–von Mises criterion   In statistics the Cramér–von Mises criterion is a criterion used for judging the goodness of fit of a cumulative distribution function     F  *     superscript  F     F^{*}   compared to a given empirical distribution function     F  n     subscript  F  n    F_{n}   , or for comparing two empirical distributions. It is also used as a part of other algorithms, such as minimum distance estimation . It is defined as       ω  2   =    ∫   -  ∞   ∞       [     F  n    (  x  )    -    F  *    (  x  )     ]   2    d   F  *    (  x  )          superscript  ω  2     superscript   subscript             superscript   delimited-[]       subscript  F  n   x      superscript  F    x     2   normal-d   superscript  F    x      \omega^{2}=\int_{-\infty}^{\infty}[F_{n}(x)-F^{*}(x)]^{2}\,\mathrm{d}F^{*}(x)     In one-sample applications    F  *     superscript  F     F^{*}   is the theoretical distribution and    F  n     subscript  F  n    F_{n}   is the empirically observed distribution . Alternatively the two distributions can both be empirically estimated ones; this is called the two-sample case.  The criterion is named after Harald Cramér and Richard Edler von Mises who first proposed it in 1928–1930. 1  2 The generalization to two samples is due to Anderson . 3  The Cramér–von Mises test is an alternative to the Kolmogorov–Smirnov test .  Cramér–von Mises test (one sample)  Let     x  1   ,   x  2   ,  ⋯  ,   x  n       subscript  x  1    subscript  x  2   normal-⋯   subscript  x  n     x_{1},x_{2},\cdots,x_{n}   be the observed values, in increasing order. Then the statistic is 4 5       T  =   n   ω  2    =    1   12  n    +    ∑   i  =  1   n     [      2  i   -  1    2  n    -   F   (   x  i   )     ]   2      .        T    n   superscript  ω  2             1    12  n      superscript   subscript     i  1    n    superscript   delimited-[]          2  i   1     2  n      F   subscript  x  i      2        T=n\omega^{2}=\frac{1}{12n}+\sum_{i=1}^{n}\left[\frac{2i-1}{2n}-F(x_{i})\right%
 ]^{2}.     If this value is larger than the tabulated value, then the hypothesis that the data come from the distribution   F   F   F   can be rejected.  Watson test  A modified version of the Cramér–von Mises test is the Watson test 6 which uses the statistic U 2 , where 7        U  2   =   T  -   n    (    F  ¯   -    1  2     )   2      ,       superscript  U  2     T    n   superscript     normal-¯  F     1  2    2       U^{2}=T-n(\bar{F}-\tfrac{1}{2})^{2},     where        F  ¯   =    1  n    ∑   F   (   x  i   )       .       normal-¯  F       1  n       F   subscript  x  i        \bar{F}=\frac{1}{n}\sum F(x_{i}).     Cramér–von Mises test (two samples)  Let     x  1   ,   x  2   ,  ⋯  ,   x  N       subscript  x  1    subscript  x  2   normal-⋯   subscript  x  N     x_{1},x_{2},\cdots,x_{N}   and     y  1   ,   y  2   ,  ⋯  ,   y  M       subscript  y  1    subscript  y  2   normal-⋯   subscript  y  M     y_{1},y_{2},\cdots,y_{M}   be the observed values in the first and second sample respectively, in increasing order. Let     r  1   ,   r  2   ,  ⋯  ,   r  N       subscript  r  1    subscript  r  2   normal-⋯   subscript  r  N     r_{1},r_{2},\cdots,r_{N}   be the ranks of the x's in the combined sample, and let     s  1   ,   s  2   ,  ⋯  ,   s  M       subscript  s  1    subscript  s  2   normal-⋯   subscript  s  M     s_{1},s_{2},\cdots,s_{M}   be the ranks of the y's in the combined sample. Anderson 8 shows that      T  =   N   ω  2    =    U   N  M   (   N  +  M   )     -     4  M  N   -  1    6   (   M  +  N   )            T    N   superscript  ω  2             U    N  M    N  M           4  M  N   1     6    M  N         T=N\omega^{2}=\frac{U}{NM(N+M)}-\frac{4MN-1}{6(M+N)}     where U is defined as      U  =    N    ∑   i  =  1   N     (    r  i   -  i   )   2     +   M    ∑   j  =  1   M     (    s  j   -  j   )   2          U      N    superscript   subscript     i  1    N    superscript     subscript  r  i   i   2       M    superscript   subscript     j  1    M    superscript     subscript  s  j   j   2        U=N\sum_{i=1}^{N}(r_{i}-i)^{2}+M\sum_{j=1}^{M}(s_{j}-j)^{2}     If the value of T is larger than the tabulated values, 9 the hypothesis that the two samples come from the same distribution can be rejected. (Some books give critical values for U, which is more convenient, as it avoids the need to compute T via the expression above. The conclusion will be the same).  The above assumes there are no duplicates in the   x   x   x   ,   y   y   y   , and   r   r   r   sequences. So    x  i     subscript  x  i    x_{i}   is unique, and its rank is   i   i   i   in the sorted list     x  1   ,   …   x  N        subscript  x  1     normal-…   subscript  x  N      x_{1},...x_{N}   . If there are duplicates, and    x  i     subscript  x  i    x_{i}   through    x  j     subscript  x  j    x_{j}   are a run of identical values in the sorted list, then one common approach is the midrank 10 method: assign each duplicate a "rank" of     (   i  +  j   )   /  2        i  j   2    (i+j)/2   . In the above equations, in the expressions     (    r  i   -  i   )   2     superscript     subscript  r  i   i   2    (r_{i}-i)^{2}   and     (    s  j   -  j   )   2     superscript     subscript  s  j   j   2    (s_{j}-j)^{2}   , duplicates can modify all four variables    r  i     subscript  r  i    r_{i}   ,   i   i   i   ,    s  j     subscript  s  j    s_{j}   , and   j   j   j   .  References     Further reading     External links   C-vM Two Sample Test (Documentation for performing the test using R   "  Category:Statistical tests  Category:Statistical distance measures  Category:Non-parametric statistics  Category:Normality tests     H. Cramér, On the composition of elementary errors, Scandinavian Actuarial Journal 1928 ↩  R. E. von Mises, Wahrscheinlichkeit, Statistik und Wahrheit, Julius Springer 1928 ↩  ↩   Pearson, E.S. , Hartley, H.O. (1972) Biometrika Tables for Statisticians, Volume 2 , CUP. ISBN 0-521-06937-8 (page 118 and Table 54) ↩  Watson, G.S. (1961) "Goodness-Of-Fit Tests on a Circle", Biometrika , 48 (1/2), 109-114 ↩     Ruymgaart, F. H., (1980) "A unified approach to the asymptotic distribution theory of certain midrank statistics". In: Statistique non Parametrique Asymptotique , 1±18, J. P. Raoult (Ed.), Lecture Notes on Mathematics, No. 821, Springer, Berlin. ↩     