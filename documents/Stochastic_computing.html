<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="1268">Stochastic computing</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>Stochastic computing</h1>
<hr/>

<p><strong>Stochastic computing</strong> is a collection of techniques that represent continuous values by streams of random bits. Complex computations can then be computed by simple bit-wise operations on the streams.</p>

<p>Despite the similarity in their names, stochastic computing is distinct from the study of <a href="randomized_algorithm" title="wikilink">randomized algorithms</a>.</p>
<h2 id="motivation-and-a-simple-example">Motivation and a simple example</h2>

<p>Suppose that 

<math display="inline" id="Stochastic_computing:0">
 <semantics>
  <mrow>
   <mrow>
    <mi>p</mi>
    <mo>,</mo>
    <mi>q</mi>
   </mrow>
   <mo>∈</mo>
   <mrow>
    <mo stretchy="false">[</mo>
    <mn>0</mn>
    <mo>,</mo>
    <mn>1</mn>
    <mo stretchy="false">]</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <in></in>
    <list>
     <ci>p</ci>
     <ci>q</ci>
    </list>
    <interval closure="closed">
     <cn type="integer">0</cn>
     <cn type="integer">1</cn>
    </interval>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   p,q\in[0,1]
  </annotation>
 </semantics>
</math>

 is given, and we wish to compute 

<math display="inline" id="Stochastic_computing:1">
 <semantics>
  <mrow>
   <mi>p</mi>
   <mo>×</mo>
   <mi>q</mi>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <ci>p</ci>
    <ci>q</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   p\times q
  </annotation>
 </semantics>
</math>

. Stochastic computing performs this operation using probability instead of arithmetic.</p>

<p>Specifically, suppose that there are two random, independent bit streams called <em>stochastic number</em>s (i.e. <a href="Bernoulli_process" title="wikilink">Bernoulli processes</a>), where the probability of a one in the first stream is 

<math display="inline" id="Stochastic_computing:2">
 <semantics>
  <mi>p</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>p</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   p
  </annotation>
 </semantics>
</math>

, and the probability in the second stream is 

<math display="inline" id="Stochastic_computing:3">
 <semantics>
  <mi>q</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>q</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   q
  </annotation>
 </semantics>
</math>


. We can take the <a href="Logical_and#Applications_in_computer_programming" title="wikilink">logical AND</a> of the two streams.</p>
<table>
<thead>
<tr class="header">
<th style="text-align: left;">
<p>

<math display="inline" id="Stochastic_computing:4">
 <semantics>
  <msub>
   <mi>a</mi>
   <mi>i</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>a</ci>
    <ci>i</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   a_{i}
  </annotation>
 </semantics>
</math>

</p></th>
<th style="text-align: left;">
<p>1</p></th>
<th style="text-align: left;">
<p>0</p></th>
<th style="text-align: left;">
<p>1</p></th>
<th style="text-align: left;">
<p>1</p></th>
<th style="text-align: left;">
<p>0</p></th>
<th style="text-align: left;">
<p>1</p></th>
<th style="text-align: left;">
<p>...</p></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">
<p>

<math display="inline" id="Stochastic_computing:5">
 <semantics>
  <msub>
   <mi>b</mi>
   <mi>i</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>b</ci>
    <ci>i</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   b_{i}
  </annotation>
 </semantics>
</math>

</p></td>
<td style="text-align: left;">
<p>1</p></td>
<td style="text-align: left;">
<p>1</p></td>
<td style="text-align: left;">
<p>0</p></td>
<td style="text-align: left;">
<p>1</p></td>
<td style="text-align: left;">
<p>1</p></td>
<td style="text-align: left;">
<p>0</p></td>
<td style="text-align: left;">
<p>...</p></td>
</tr>
<tr class="even">
<td style="text-align: left;">
<p>

<math display="inline" id="Stochastic_computing:6">
 <semantics>
  <mrow>
   <msub>
    <mi>a</mi>
    <mi>i</mi>
   </msub>
   <mo>∧</mo>
   <msub>
    <mi>b</mi>
    <mi>i</mi>
   </msub>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <and></and>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>a</ci>
     <ci>i</ci>
    </apply>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>b</ci>
     <ci>i</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   a_{i}\land b_{i}
  </annotation>
 </semantics>
</math>

</p></td>
<td style="text-align: left;">
<p>1</p></td>
<td style="text-align: left;">
<p>0</p></td>
<td style="text-align: left;">
<p>0</p></td>
<td style="text-align: left;">
<p>1</p></td>
<td style="text-align: left;">
<p>0</p></td>
<td style="text-align: left;">
<p>0</p></td>
<td style="text-align: left;">
<p>...</p></td>
</tr>
</tbody>
</table>

<p>The probability of a one in the output stream is 

<math display="inline" id="Stochastic_computing:7">
 <semantics>
  <mrow>
   <mi>p</mi>
   <mi>q</mi>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <ci>p</ci>
    <ci>q</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   pq
  </annotation>
 </semantics>
</math>

. By observing enough output bits and measuring the frequency of ones, it is possible to estimate 

<math display="inline" id="Stochastic_computing:8">
 <semantics>
  <mrow>
   <mi>p</mi>
   <mi>q</mi>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <ci>p</ci>
    <ci>q</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   pq
  </annotation>
 </semantics>
</math>


 to arbitrary accuracy.</p>

<p>The operation above converts a fairly complicated computation (multiplication of 

<math display="inline" id="Stochastic_computing:9">
 <semantics>
  <mi>p</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>p</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   p
  </annotation>
 </semantics>
</math>

 and 

<math display="inline" id="Stochastic_computing:10">
 <semantics>
  <mi>q</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>q</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   q
  </annotation>
 </semantics>
</math>

) into a series of very simple operations (evaluation of 

<math display="inline" id="Stochastic_computing:11">
 <semantics>
  <mrow>
   <msub>
    <mi>a</mi>
    <mi>i</mi>
   </msub>
   <mo>∧</mo>
   <msub>
    <mi>b</mi>
    <mi>i</mi>
   </msub>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <and></and>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>a</ci>
     <ci>i</ci>
    </apply>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>b</ci>
     <ci>i</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   a_{i}\land b_{i}
  </annotation>
 </semantics>
</math>

) on random bits.</p>

<p>More generally speaking, stochastic computing represents numbers as streams of random bits and reconstructs numbers by calculating frequencies. The computations are performed on the streams and translate complicated operations on 

<math display="inline" id="Stochastic_computing:12">
 <semantics>
  <mi>p</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>p</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   p
  </annotation>
 </semantics>
</math>

 and 

<math display="inline" id="Stochastic_computing:13">
 <semantics>
  <mi>q</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>q</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   q
  </annotation>
 </semantics>
</math>


 into simple operations on their stream representations. (Because of the method of reconstruction, devices that perform these operations are sometimes called stochastic averaging processors.) In modern terms, stochastic computing can be viewed as an interpretation of calculations in probabilistic terms, which are then evaluated with a <a href="Gibbs_sampling" title="wikilink">Gibbs sampler</a>. It can also be interpreted as a hybrid <a href="Analog_computer" title="wikilink">analog</a>/<a href="Computer" title="wikilink">digital</a> computer.</p>
<h2 id="history">History</h2>
<figure><b>(Figure)</b>
<figcaption>The RASCEL stochastic computer, circa 1969</figcaption>
</figure>

<p>Stochastic computing was first introduced in a pioneering paper by <a href="John_von_Neumann" title="wikilink">John von Neumann</a> in 1953.<a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a> However, the theory could not be fully developed until advances in computing of the 1960s,<a class="footnoteRef" href="#fn2" id="fnref2"><sup>2</sup></a> <a class="footnoteRef" href="#fn3" id="fnref3"><sup>3</sup></a> mostly through a series of simultaneous and parallel efforts in the US<a class="footnoteRef" href="#fn4" id="fnref4"><sup>4</sup></a> and the UK.<a class="footnoteRef" href="#fn5" id="fnref5"><sup>5</sup></a> By the late 1960s, attention turned to the design of special-purpose hardware to perform stochastic computation. A host<a class="footnoteRef" href="#fn6" id="fnref6"><sup>6</sup></a> of these machines were constructed between 1969 and 1974; RASCEL<a class="footnoteRef" href="#fn7" id="fnref7"><sup>7</sup></a> is pictured in this article.</p>

<p>Despite the intense interest in the 1960s and 1970s, stochastic computing ultimately failed to compete with more traditional digital logic, for reasons outlined below. The first (and last) International Symposium on Stochastic Computing<a class="footnoteRef" href="#fn8" id="fnref8"><sup>8</sup></a> took place in 1978; active research in the area dwindled over the next few years.</p>

<p>Although stochastic computing declined as a general method of computing, it has shown promise in several applications. Research has traditionally focused on certain tasks in machine learning and control.<a class="footnoteRef" href="#fn9" id="fnref9"><sup>9</sup></a> <a class="footnoteRef" href="#fn10" id="fnref10"><sup>10</sup></a> Somewhat recently, interest has turned towards stochastic decoding, which applies stochastic computing to the decoding of error correcting codes.<a class="footnoteRef" href="#fn11" id="fnref11"><sup>11</sup></a> More recently, stochastic circuits have been successfully used in <a href="image_processing" title="wikilink">image processing</a> tasks such as <a href="edge_detection" title="wikilink">edge detection</a>. <a class="footnoteRef" href="#fn12" id="fnref12"><sup>12</sup></a></p>
<h2 id="strengths-and-weaknesses">Strengths and weaknesses</h2>

<p>Although stochastic computing was a historical failure, it may still remain relevant for solving certain problems. To understand when it remains relevant, it is useful to compare stochastic computing with more traditional methods of digital computing.</p>
<h3 id="strengths">Strengths</h3>

<p>Suppose we wish to multiply two numbers each with 

<math display="inline" id="Stochastic_computing:14">
 <semantics>
  <mi>n</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>n</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   n
  </annotation>
 </semantics>
</math>

 bits of precision. Using the typical <a href="Multiplication_algorithm#Long_multiplication" title="wikilink">long multiplication</a> method, we need to perform 

<math display="inline" id="Stochastic_computing:15">
 <semantics>
  <msup>
   <mi>n</mi>
   <mn>2</mn>
  </msup>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">superscript</csymbol>
    <ci>n</ci>
    <cn type="integer">2</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   n^{2}
  </annotation>
 </semantics>
</math>

 operations. With stochastic computing, we can AND together any number of bits and the expected value will always be correct. (However, with a small number of samples the variance will render the actual result highly inaccurate).</p>

<p>Moreover, the underlying operations in a digital multiplier are <a href="Adder_(electronics)#Full_adder" title="wikilink">full adders</a>, whereas a stochastic computer only requires an <a href="And_gate" title="wikilink">AND gate</a>. Additionally, a digital multiplier would naively require 

<math display="inline" id="Stochastic_computing:16">
 <semantics>
  <mrow>
   <mn>2</mn>
   <mi>n</mi>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <cn type="integer">2</cn>
    <ci>n</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   2n
  </annotation>
 </semantics>
</math>

 input wires, whereas a stochastic multiplier would only require 2 input wires. (If the digital multiplier serialized its output, however, it would also require only 2 input wires.)</p>

<p>Additionally, stochastic computing is robust against noise; if a few bits in a stream are flipped, those errors will have no significant impact on the solution.</p>

<p>Finally, stochastic computing provides an estimate of the solution that grows more accurate as we extend the bit stream. In particular, it provides a rough estimate very rapidly. This property is usually referred to as <em>progressive precision</em>, which suggests that the precision of stochastic numbers (bit streams) increases as computation proceeds. <a class="footnoteRef" href="#fn13" id="fnref13"><sup>13</sup></a> It is as if the <a href="most_significant_bit" title="wikilink">most significant bits</a> of the number arrive before its <a href="least_significant_bit" title="wikilink">least significant bits</a>; unlike the conventional <a href="Arithmetic_logic_unit" title="wikilink">arithmetic circuits</a> where the most significant bits usually arrive last. In some iterative systems the partial solutions obtained through progressive precision can provide faster feedback than through traditional computing methods, leading to faster convergence.</p>
<h3 id="weaknesses">Weaknesses</h3>

<p>Stochastic computing is, by its very nature, random. When we examine a random bit stream and try to reconstruct the underlying value, the effective precision can be measured by the variance of our sample. In the example above, the digital multiplier computes a number to 

<math display="inline" id="Stochastic_computing:17">
 <semantics>
  <mrow>
   <mn>2</mn>
   <mi>n</mi>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <cn type="integer">2</cn>
    <ci>n</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   2n
  </annotation>
 </semantics>
</math>

 bits of accuracy, so the precision is 

<math display="inline" id="Stochastic_computing:18">
 <semantics>
  <msup>
   <mn>2</mn>
   <mrow>
    <mo>-</mo>
    <mrow>
     <mn>2</mn>
     <mi>n</mi>
    </mrow>
   </mrow>
  </msup>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">superscript</csymbol>
    <cn type="integer">2</cn>
    <apply>
     <minus></minus>
     <apply>
      <times></times>
      <cn type="integer">2</cn>
      <ci>n</ci>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   2^{-2n}
  </annotation>
 </semantics>
</math>


. If we are using a random bit stream to estimate a number and want the standard deviation of our estimate of the solution to be at least 

<math display="inline" id="Stochastic_computing:19">
 <semantics>
  <msup>
   <mn>2</mn>
   <mrow>
    <mo>-</mo>
    <mrow>
     <mn>2</mn>
     <mi>n</mi>
    </mrow>
   </mrow>
  </msup>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">superscript</csymbol>
    <cn type="integer">2</cn>
    <apply>
     <minus></minus>
     <apply>
      <times></times>
      <cn type="integer">2</cn>
      <ci>n</ci>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   2^{-2n}
  </annotation>
 </semantics>
</math>

, we would need 

<math display="inline" id="Stochastic_computing:20">
 <semantics>
  <mrow>
   <mi>O</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <msup>
     <mn>2</mn>
     <mrow>
      <mn>4</mn>
      <mi>n</mi>
     </mrow>
    </msup>
    <mo stretchy="false">)</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <ci>O</ci>
    <apply>
     <csymbol cd="ambiguous">superscript</csymbol>
     <cn type="integer">2</cn>
     <apply>
      <times></times>
      <cn type="integer">4</cn>
      <ci>n</ci>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   O(2^{4n})
  </annotation>
 </semantics>
</math>

 samples. This represents an exponential increase in work. In certain applications, however, the progressive precision property of stochastic computing can be exploited to compensate this exponential loss.</p>

<p>Second, stochastic computing requires a method of generating random biased bit streams. In practice, these streams are generated with <a href="PRNG" title="wikilink">pseudo-random number generators</a>. Unfortunately, generating (pseudo-)random bits is fairly costly (compared to the expense of, e.g., a full adder). Therefore, the gate-level advantage of stochastic computing is typically lost.</p>

<p>Third, the analysis of stochastic computing assumes that the bit streams are independent (uncorrelated). If this assumption does not hold, stochastic computing can fail dramatically. For instance, if we try to compute 

<math display="inline" id="Stochastic_computing:21">
 <semantics>
  <msup>
   <mi>p</mi>
   <mn>2</mn>
  </msup>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">superscript</csymbol>
    <ci>p</ci>
    <cn type="integer">2</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   p^{2}
  </annotation>
 </semantics>
</math>

 by multiplying a bit stream for 

<math display="inline" id="Stochastic_computing:22">
 <semantics>
  <mi>p</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>p</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   p
  </annotation>
 </semantics>
</math>

 by itself, the process fails: since 

<math display="inline" id="Stochastic_computing:23">
 <semantics>
  <mrow>
   <mrow>
    <msub>
     <mi>a</mi>
     <mi>i</mi>
    </msub>
    <mo>∧</mo>
    <msub>
     <mi>a</mi>
     <mi>i</mi>
    </msub>
   </mrow>
   <mo>=</mo>
   <msub>
    <mi>a</mi>
    <mi>i</mi>
   </msub>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <and></and>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>a</ci>
      <ci>i</ci>
     </apply>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>a</ci>
      <ci>i</ci>
     </apply>
    </apply>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>a</ci>
     <ci>i</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   a_{i}\land a_{i}=a_{i}
  </annotation>
 </semantics>
</math>

, the stochastic computation would yield 

<math display="inline" id="Stochastic_computing:24">
 <semantics>
  <mrow>
   <mrow>
    <mi>p</mi>
    <mo>×</mo>
    <mi>p</mi>
   </mrow>
   <mo>=</mo>
   <mi>p</mi>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <times></times>
     <ci>p</ci>
     <ci>p</ci>
    </apply>
    <ci>p</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   p\times p=p
  </annotation>
 </semantics>
</math>

, which is not generally true (unless 

<math display="inline" id="Stochastic_computing:25">
 <semantics>
  <mrow>
   <mi>p</mi>
   <mo>=</mo>
   <mi></mi>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <ci>p</ci>
    <csymbol cd="latexml">absent</csymbol>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   p=
  </annotation>
 </semantics>
</math>

0 or 1). In systems with feedback, the problem of decorrelation can manifest in more complicated ways. Systems of stochastic processors are prone to <em>latching</em>, where feedback between different components can achieve a deadlocked state.<a class="footnoteRef" href="#fn14" id="fnref14"><sup>14</sup></a> A great deal of effort must be spent decorrelating the system to attempt to remediate latching.</p>

<p>Fourth, although some digital functions have very simple stochastic counterparts (such as the translation between multiplication and the AND gate), many do not. Trying to express these functions stochastically may cause various pathologies. For instance, stochastic decoding requires the computation of the function 

<math display="inline" id="Stochastic_computing:26">
 <semantics>
  <mrow>
   <mrow>
    <mi>f</mi>
    <mrow>
     <mo stretchy="false">(</mo>
     <mi>p</mi>
     <mo>,</mo>
     <mi>q</mi>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
   <mo>→</mo>
   <mrow>
    <mrow>
     <mi>p</mi>
     <mi>q</mi>
    </mrow>
    <mo>/</mo>
    <mrow>
     <mo stretchy="false">(</mo>
     <mrow>
      <mrow>
       <mi>p</mi>
       <mi>q</mi>
      </mrow>
      <mo>+</mo>
      <mrow>
       <mrow>
        <mo stretchy="false">(</mo>
        <mrow>
         <mn>1</mn>
         <mo>-</mo>
         <mi>p</mi>
        </mrow>
        <mo stretchy="false">)</mo>
       </mrow>
       <mrow>
        <mo stretchy="false">(</mo>
        <mrow>
         <mn>1</mn>
         <mo>-</mo>
         <mi>q</mi>
        </mrow>
        <mo stretchy="false">)</mo>
       </mrow>
      </mrow>
     </mrow>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <ci>normal-→</ci>
    <apply>
     <times></times>
     <ci>f</ci>
     <interval closure="open">
      <ci>p</ci>
      <ci>q</ci>
     </interval>
    </apply>
    <apply>
     <divide></divide>
     <apply>
      <times></times>
      <ci>p</ci>
      <ci>q</ci>
     </apply>
     <apply>
      <plus></plus>
      <apply>
       <times></times>
       <ci>p</ci>
       <ci>q</ci>
      </apply>
      <apply>
       <times></times>
       <apply>
        <minus></minus>
        <cn type="integer">1</cn>
        <ci>p</ci>
       </apply>
       <apply>
        <minus></minus>
        <cn type="integer">1</cn>
        <ci>q</ci>
       </apply>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   f(p,q)\rightarrow pq/(pq+(1-p)(1-q))
  </annotation>
 </semantics>
</math>

. There is no single bit operation that can compute this function; the usual solution involves producing correlated output bits, which, as we have seen above, can cause a host of problems. Still other functions (such as the averaging operator 

<math display="inline" id="Stochastic_computing:27">
 <semantics>
  <mrow>
   <mrow>
    <mi>f</mi>
    <mrow>
     <mo stretchy="false">(</mo>
     <mi>p</mi>
     <mo>,</mo>
     <mi>q</mi>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
   <mo>→</mo>
   <mrow>
    <mrow>
     <mo stretchy="false">(</mo>
     <mrow>
      <mi>p</mi>
      <mo>+</mo>
      <mi>q</mi>
     </mrow>
     <mo stretchy="false">)</mo>
    </mrow>
    <mo>/</mo>
    <mn>2</mn>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <ci>normal-→</ci>
    <apply>
     <times></times>
     <ci>f</ci>
     <interval closure="open">
      <ci>p</ci>
      <ci>q</ci>
     </interval>
    </apply>
    <apply>
     <divide></divide>
     <apply>
      <plus></plus>
      <ci>p</ci>
      <ci>q</ci>
     </apply>
     <cn type="integer">2</cn>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   f(p,q)\rightarrow(p+q)/2
  </annotation>
 </semantics>
</math>

) require stream decimation. Since decimation discards information, it leads to the problem of <em>attenuation</em>.</p>
<h2 id="stochastic-decoding">Stochastic decoding</h2>

<p>Although stochastic computing has a number of defects when considered as a method of general computation, there are certain applications that highlight its strengths. One notable case occurs in the decoding of certain error correcting codes.</p>

<p>In developments unrelated to stochastic computing, highly effective methods of decoding <a href="Low-density_parity-check_code" title="wikilink">LDPC codes</a> using the <a href="belief_propagation" title="wikilink">belief propagation</a> algorithm were developed. Belief propagation in this context involves iteratively reestimating certain parameters using two basic operations (essentially, a probabilistic XOR operation and an averaging operation).</p>

<p>In 2003, researchers realized that these two operations could be modeled very simply with stochastic computing.<a class="footnoteRef" href="#fn15" id="fnref15"><sup>15</sup></a> Moreover, since the belief propagation algorithm is iterative, stochastic computing provides partial solutions that may lead to faster convergence. Hardware implementations of stochastic decoders have been built on <a href="Field-programmable_gate_array" title="wikilink">FPGAs</a>. <a class="footnoteRef" href="#fn16" id="fnref16"><sup>16</sup></a> The proponents of these methods argue that the performance of stochastic decoding is competitive with digital alternatives.</p>
<h2 id="variants-of-stochastic-computing">Variants of stochastic computing</h2>

<p>There are a number of variants of the basic stochastic computing paradigm. Further information can be found in the referenced book by Mars and Poppelbaum.</p>

<p><em>Bundle Processing</em> involves sending a fixed number of bits instead of a stream. One of the advantages of this approach is that the precision is improved. To see why, suppose we transmit 

<math display="inline" id="Stochastic_computing:28">
 <semantics>
  <mi>s</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>s</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   s
  </annotation>
 </semantics>
</math>

 bits. In regular stochastic computing, we can represent a precision of roughly 

<math display="inline" id="Stochastic_computing:29">
 <semantics>
  <mrow>
   <mi>O</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <mrow>
     <mn>1</mn>
     <mo>/</mo>
     <msqrt>
      <mi>s</mi>
     </msqrt>
    </mrow>
    <mo stretchy="false">)</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <ci>O</ci>
    <apply>
     <divide></divide>
     <cn type="integer">1</cn>
     <apply>
      <root></root>
      <ci>s</ci>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   O(1/\sqrt{s})
  </annotation>
 </semantics>
</math>

 different values, because of the variance of the estimate. In bundle processing, we can represent a precision of 

<math display="inline" id="Stochastic_computing:30">
 <semantics>
  <mrow>
   <mn>1</mn>
   <mo>/</mo>
   <mi>s</mi>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <divide></divide>
    <cn type="integer">1</cn>
    <ci>s</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   1/s
  </annotation>
 </semantics>
</math>

. However, bundle processing retains the same robustness to error of regular stochastic processing.</p>

<p><em>Ergodic Processing</em> involves sending a stream of bundles, which captures the benefits of regular stochastic and bundle processing.</p>

<p><em>Burst Processing</em> encodes a number by a higher base increasing stream. For instance, we would encode 4.3 with ten decimal digits as</p>
<dl>
<dd><dl>
<dd>4444444555
</dd>
</dl>
</dd>
</dl>

<p>since the average value of the preceding stream is 4.3. This representation offers various advantages: there is no randomization since the numbers appear in increasing order, so the PRNG issues are avoided, but many of the advantages of stochastic computing are retained (such as partial estimates of the solution). Additionally, it retains the linear precision of bundle and ergodic processing.</p>
<h2 id="references">References</h2>
<h2 id="further-reading">Further reading</h2>
<ul>
<li></li>
</ul>
<ul>
<li></li>
</ul>

<p>"</p>

<p><a href="Category:History_of_computing_hardware" title="wikilink">Category:History of computing hardware</a> <a href="Category:Models_of_computation" title="wikilink">Category:Models of computation</a> <a href="Category:Stochastic_algorithms" title="wikilink">Category:Stochastic algorithms</a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1"><a href="#fnref1">↩</a></li>
<li id="fn2"><a href="#fnref2">↩</a></li>
<li id="fn3"><a href="#fnref3">↩</a></li>
<li id="fn4"><a href="#fnref4">↩</a></li>
<li id="fn5"><a href="#fnref5">↩</a></li>
<li id="fn6"><a href="#fnref6">↩</a></li>
<li id="fn7"><a href="#fnref7">↩</a></li>
<li id="fn8"><a href="#fnref8">↩</a></li>
<li id="fn9"><a href="#fnref9">↩</a></li>
<li id="fn10"><a href="#fnref10">↩</a></li>
<li id="fn11"><a href="#fnref11">↩</a></li>
<li id="fn12"><a href="#fnref12">↩</a></li>
<li id="fn13"><a href="#fnref13">↩</a></li>
<li id="fn14"><a href="#fnref14">↩</a></li>
<li id="fn15"><a href="#fnref15">↩</a></li>
<li id="fn16"><a href="#fnref16">↩</a></li>
</ol>
</section>
</body>
</html>
