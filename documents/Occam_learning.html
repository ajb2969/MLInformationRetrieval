<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="1447">Occam learning</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>Occam learning</h1>
<hr/>

<p>In <strong>Occam Learning</strong>, named after <a href="Occam’s_Razor#Science_and_the_scientific_method" title="wikilink">Occam's razor</a>, a <a href="probably_approximately_correct_learning" title="wikilink">probably approximately correct (PAC) learning</a> algorithm is evaluated based on its succinctness and performance on the training set, rather than directly on its predictive power on a test set. Occam learnability is equivalent to PAC learnability.</p>
<h2 id="definitions-of-occam-learning-and-succinctness">Definitions of Occam learning and succinctness</h2>

<p>The succinctness of a concept 

<math display="inline" id="Occam_learning:0">
 <semantics>
  <mi>c</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>c</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   c
  </annotation>
 </semantics>
</math>

 in <a href="concept_class" title="wikilink">concept class</a> 

<math display="inline" id="Occam_learning:1">
 <semantics>
  <mi>C</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>C</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   C
  </annotation>
 </semantics>
</math>

 can be expressed by the length 

<math display="inline" id="Occam_learning:2">
 <semantics>
  <mrow>
   <mi>s</mi>
   <mi>i</mi>
   <mi>z</mi>
   <mi>e</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <mi>c</mi>
    <mo stretchy="false">)</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <ci>s</ci>
    <ci>i</ci>
    <ci>z</ci>
    <ci>e</ci>
    <ci>c</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   size(c)
  </annotation>
 </semantics>
</math>

 of the shortest bit string that can represent 

<math display="inline" id="Occam_learning:3">
 <semantics>
  <mi>c</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>c</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   c
  </annotation>
 </semantics>
</math>

 in 

<math display="inline" id="Occam_learning:4">
 <semantics>
  <mi>C</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>C</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   C
  </annotation>
 </semantics>
</math>

. Occam learning connects the succinctness of a learning algorithm's output to its predictive power on unseen data.</p>

<p>Let 

<math display="inline" id="Occam_learning:5">
 <semantics>
  <mi>C</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>C</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   C
  </annotation>
 </semantics>
</math>

 and 

<math display="inline" id="Occam_learning:6">
 <semantics>
  <mi>H</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>H</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   H
  </annotation>
 </semantics>
</math>

 be concept classes containing target concepts and hypotheses respectively and let sample set 

<math display="inline" id="Occam_learning:7">
 <semantics>
  <mi>S</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>S</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   S
  </annotation>
 </semantics>
</math>

 contain 

<math display="inline" id="Occam_learning:8">
 <semantics>
  <mi>m</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>m</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   m
  </annotation>
 </semantics>
</math>

 samples each containing 

<math display="inline" id="Occam_learning:9">
 <semantics>
  <mi>n</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>n</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   n
  </annotation>
 </semantics>
</math>

 bits. Then, for constants 

<math display="inline" id="Occam_learning:10">
 <semantics>
  <mrow>
   <mi>α</mi>
   <mo>≥</mo>
   <mn>0</mn>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <geq></geq>
    <ci>α</ci>
    <cn type="integer">0</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \alpha\geq 0
  </annotation>
 </semantics>
</math>

 and 

<math display="inline" id="Occam_learning:11">
 <semantics>
  <mrow>
   <mn>0</mn>
   <mo>≤</mo>
   <mi>β</mi>
   <mo><</mo>
   <mn>1</mn>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <and></and>
    <apply>
     <leq></leq>
     <cn type="integer">0</cn>
     <ci>β</ci>
    </apply>
    <apply>
     <lt></lt>
     <share href="#.cmml">
     </share>
     <cn type="integer">1</cn>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   0\leq\beta<1
  </annotation>
 </semantics>
</math>

, a learning algorithm 

<math display="inline" id="Occam_learning:12">
 <semantics>
  <mi>L</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>L</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   L
  </annotation>
 </semantics>
</math>

 is an <strong>(α,β)-Occam algorithm</strong> for 

<math display="inline" id="Occam_learning:13">
 <semantics>
  <mi>C</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>C</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   C
  </annotation>
 </semantics>
</math>

 using 

<math display="inline" id="Occam_learning:14">
 <semantics>
  <mi>H</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>H</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   H
  </annotation>
 </semantics>
</math>

 if, given 

<math display="inline" id="Occam_learning:15">
 <semantics>
  <mi>S</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>S</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   S
  </annotation>
 </semantics>
</math>

 labeled according to 

<math display="inline" id="Occam_learning:16">
 <semantics>
  <mrow>
   <mi>c</mi>
   <mo>∈</mo>
   <mi>C</mi>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <in></in>
    <ci>c</ci>
    <ci>C</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   c\in C
  </annotation>
 </semantics>
</math>

, 

<math display="inline" id="Occam_learning:17">
 <semantics>
  <mi>L</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>L</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   L
  </annotation>
 </semantics>
</math>

 outputs a hypothesis 

<math display="inline" id="Occam_learning:18">
 <semantics>
  <mrow>
   <mi>h</mi>
   <mo>∈</mo>
   <mi>H</mi>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <in></in>
    <ci>h</ci>
    <ci>H</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   h\in H
  </annotation>
 </semantics>
</math>

 such that 

<math display="inline" id="Occam_learning:19">
 <semantics>
  <mi>h</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>h</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   h
  </annotation>
 </semantics>
</math>

 is consistent with 

<math display="inline" id="Occam_learning:20">
 <semantics>
  <mi>c</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>c</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   c
  </annotation>
 </semantics>
</math>

 on 

<math display="inline" id="Occam_learning:21">
 <semantics>
  <mi>S</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>S</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   S
  </annotation>
 </semantics>
</math>

 (that is, 

<math display="inline" id="Occam_learning:22">
 <semantics>
  <mrow>
   <mrow>
    <mrow>
     <mi>h</mi>
     <mrow>
      <mo stretchy="false">(</mo>
      <mi>x</mi>
      <mo stretchy="false">)</mo>
     </mrow>
    </mrow>
    <mo>=</mo>
    <mrow>
     <mi>c</mi>
     <mrow>
      <mo stretchy="false">(</mo>
      <mi>x</mi>
      <mo stretchy="false">)</mo>
     </mrow>
    </mrow>
   </mrow>
   <mo>,</mo>
   <mrow>
    <mrow>
     <mo>∀</mo>
     <mi>x</mi>
    </mrow>
    <mo>∈</mo>
    <mi>S</mi>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">formulae-sequence</csymbol>
    <apply>
     <eq></eq>
     <apply>
      <times></times>
      <ci>h</ci>
      <ci>x</ci>
     </apply>
     <apply>
      <times></times>
      <ci>c</ci>
      <ci>x</ci>
     </apply>
    </apply>
    <apply>
     <in></in>
     <apply>
      <csymbol cd="latexml">for-all</csymbol>
      <ci>x</ci>
     </apply>
     <ci>S</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   h(x)=c(x),\forall x\in S
  </annotation>
 </semantics>
</math>

) and 

<math display="inline" id="Occam_learning:23">
 <semantics>
  <mrow>
   <mrow>
    <mi>s</mi>
    <mi>i</mi>
    <mi>z</mi>
    <mi>e</mi>
    <mrow>
     <mo stretchy="false">(</mo>
     <mi>h</mi>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
   <mo>≤</mo>
   <mrow>
    <msup>
     <mrow>
      <mo stretchy="false">(</mo>
      <mrow>
       <mrow>
        <mi>n</mi>
        <mo>⋅</mo>
        <mi>s</mi>
       </mrow>
       <mi>i</mi>
       <mi>z</mi>
       <mi>e</mi>
       <mrow>
        <mo stretchy="false">(</mo>
        <mi>c</mi>
        <mo stretchy="false">)</mo>
       </mrow>
      </mrow>
      <mo stretchy="false">)</mo>
     </mrow>
     <mi>α</mi>
    </msup>
    <msup>
     <mi>m</mi>
     <mi>β</mi>
    </msup>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <leq></leq>
    <apply>
     <times></times>
     <ci>s</ci>
     <ci>i</ci>
     <ci>z</ci>
     <ci>e</ci>
     <ci>h</ci>
    </apply>
    <apply>
     <times></times>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <apply>
       <times></times>
       <apply>
        <ci>normal-⋅</ci>
        <ci>n</ci>
        <ci>s</ci>
       </apply>
       <ci>i</ci>
       <ci>z</ci>
       <ci>e</ci>
       <ci>c</ci>
      </apply>
      <ci>α</ci>
     </apply>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <ci>m</ci>
      <ci>β</ci>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   size(h)\leq(n\cdot size(c))^{\alpha}m^{\beta}
  </annotation>
 </semantics>
</math>

.<a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a><a class="footnoteRef" href="#fn2" id="fnref2"><sup>2</sup></a></p>

<p>Such an algorithm 

<math display="inline" id="Occam_learning:24">
 <semantics>
  <mi>L</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>L</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   L
  </annotation>
 </semantics>
</math>

 is called an efficient (α,β)-Occam algorithm if it runs in time polynomial in 

<math display="inline" id="Occam_learning:25">
 <semantics>
  <mi>n</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>n</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   n
  </annotation>
 </semantics>
</math>

, 

<math display="inline" id="Occam_learning:26">
 <semantics>
  <mi>m</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>m</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   m
  </annotation>
 </semantics>
</math>

, and 

<math display="inline" id="Occam_learning:27">
 <semantics>
  <mrow>
   <mi>s</mi>
   <mi>i</mi>
   <mi>z</mi>
   <mi>e</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <mi>c</mi>
    <mo stretchy="false">)</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <ci>s</ci>
    <ci>i</ci>
    <ci>z</ci>
    <ci>e</ci>
    <ci>c</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   size(c)
  </annotation>
 </semantics>
</math>

.</p>
<h2 id="equivalence-of-occam-and-pac-learning">Equivalence of Occam and PAC learning</h2>

<p>Any efficient Occam algorithm is also an efficient PAC learning algorithm. Specifically, an efficient (α,β)-Occam algorithm 

<math display="inline" id="Occam_learning:28">
 <semantics>
  <mi>L</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>L</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   L
  </annotation>
 </semantics>
</math>

 for 

<math display="inline" id="Occam_learning:29">
 <semantics>
  <mi>C</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>C</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   C
  </annotation>
 </semantics>
</math>

 using 

<math display="inline" id="Occam_learning:30">
 <semantics>
  <mi>H</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>H</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   H
  </annotation>
 </semantics>
</math>

, given 

<math display="inline" id="Occam_learning:31">
 <semantics>
  <mi>m</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>m</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   m
  </annotation>
 </semantics>
</math>

 samples of 

<math display="inline" id="Occam_learning:32">
 <semantics>
  <mi>n</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>n</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   n
  </annotation>
 </semantics>
</math>

 bits each, such that 

<math display="inline" id="Occam_learning:33">
 <semantics>
  <mrow>
   <mi>m</mi>
   <mo>≥</mo>
   <mrow>
    <mi>α</mi>
    <mrow>
     <mo>(</mo>
     <mrow>
      <mrow>
       <mfrac>
        <mn>1</mn>
        <mi>ϵ</mi>
       </mfrac>
       <mrow>
        <mi>log</mi>
        <mfrac>
         <mn>1</mn>
         <mi>δ</mi>
        </mfrac>
       </mrow>
      </mrow>
      <mo>+</mo>
      <msup>
       <mrow>
        <mo>(</mo>
        <mfrac>
         <mrow>
          <msup>
           <mrow>
            <mo stretchy="false">(</mo>
            <mi>n</mi>
            <mo>⋅</mo>
            <mi>s</mi>
            <mi>i</mi>
            <mi>z</mi>
            <mi>e</mi>
            <mrow>
             <mo stretchy="false">(</mo>
             <mi>c</mi>
             <mo stretchy="false">)</mo>
            </mrow>
            <mo stretchy="false">)</mo>
           </mrow>
           <mi>α</mi>
          </msup>
          <mo stretchy="false">)</mo>
         </mrow>
         <mi>ϵ</mi>
        </mfrac>
        <mo>)</mo>
       </mrow>
       <mfrac>
        <mn>1</mn>
        <mrow>
         <mn>1</mn>
         <mo>-</mo>
         <mi>β</mi>
        </mrow>
       </mfrac>
      </msup>
     </mrow>
     <mo>)</mo>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <geq></geq>
    <ci>m</ci>
    <apply>
     <times></times>
     <ci>α</ci>
     <apply>
      <plus></plus>
      <apply>
       <times></times>
       <apply>
        <divide></divide>
        <cn type="integer">1</cn>
        <ci>ϵ</ci>
       </apply>
       <apply>
        <log></log>
        <apply>
         <divide></divide>
         <cn type="integer">1</cn>
         <ci>δ</ci>
        </apply>
       </apply>
      </apply>
      <apply>
       <csymbol cd="ambiguous">superscript</csymbol>
       <apply>
        <divide></divide>
        <cerror>
         <csymbol cd="ambiguous">fragments</csymbol>
         <apply>
          <csymbol cd="ambiguous">superscript</csymbol>
          <cerror>
           <csymbol cd="ambiguous">fragments</csymbol>
           <ci>normal-(</ci>
           <csymbol cd="unknown">n</csymbol>
           <ci>normal-⋅</ci>
           <csymbol cd="unknown">s</csymbol>
           <csymbol cd="unknown">i</csymbol>
           <csymbol cd="unknown">z</csymbol>
           <csymbol cd="unknown">e</csymbol>
           <cerror>
            <csymbol cd="ambiguous">fragments</csymbol>
            <ci>normal-(</ci>
            <csymbol cd="unknown">c</csymbol>
            <ci>normal-)</ci>
           </cerror>
           <ci>normal-)</ci>
          </cerror>
          <ci>α</ci>
         </apply>
         <ci>normal-)</ci>
        </cerror>
        <ci>ϵ</ci>
       </apply>
       <apply>
        <divide></divide>
        <cn type="integer">1</cn>
        <apply>
         <minus></minus>
         <cn type="integer">1</cn>
         <ci>β</ci>
        </apply>
       </apply>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   m\geq\alpha\left(\frac{1}{\epsilon}\log\frac{1}{\delta}+\left(\frac{(n\cdot
size%
(c))^{\alpha})}{\epsilon}\right)^{\frac{1}{1-\beta}}\right)
  </annotation>
 </semantics>
</math>

 will return 

<math display="inline" id="Occam_learning:34">
 <semantics>
  <mrow>
   <mi>h</mi>
   <mo>∈</mo>
   <mi>H</mi>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <in></in>
    <ci>h</ci>
    <ci>H</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   h\in H
  </annotation>
 </semantics>
</math>

 such that 

<math display="inline" id="Occam_learning:35">
 <semantics>
  <mrow>
   <mrow>
    <mi>e</mi>
    <mi>r</mi>
    <mi>r</mi>
    <mi>o</mi>
    <mi>r</mi>
    <mrow>
     <mo stretchy="false">(</mo>
     <mi>h</mi>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
   <mo>≤</mo>
   <mi>ϵ</mi>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <leq></leq>
    <apply>
     <times></times>
     <ci>e</ci>
     <ci>r</ci>
     <ci>r</ci>
     <ci>o</ci>
     <ci>r</ci>
     <ci>h</ci>
    </apply>
    <ci>ϵ</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   error(h)\leq\epsilon
  </annotation>
 </semantics>
</math>

 with probability at least 

<math display="inline" id="Occam_learning:36">
 <semantics>
  <mrow>
   <mn>1</mn>
   <mo>-</mo>
   <mi>δ</mi>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <minus></minus>
    <cn type="integer">1</cn>
    <ci>δ</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   1-\delta
  </annotation>
 </semantics>
</math>

. More generally, there exists a constant 

<math display="inline" id="Occam_learning:37">
 <semantics>
  <mrow>
   <mi>b</mi>
   <mo>></mo>
   <mn>0</mn>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <gt></gt>
    <ci>b</ci>
    <cn type="integer">0</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   b>0
  </annotation>
 </semantics>
</math>

 such that given 

<math display="inline" id="Occam_learning:38">
 <semantics>
  <mrow>
   <mi>m</mi>
   <mo>≥</mo>
   <mrow>
    <mfrac>
     <mn>1</mn>
     <mrow>
      <mi>b</mi>
      <mi>ϵ</mi>
     </mrow>
    </mfrac>
    <mrow>
     <mo>(</mo>
     <mrow>
      <mrow>
       <mi>log</mi>
       <mrow>
        <mo stretchy="false">|</mo>
        <mi>H</mi>
        <mo stretchy="false">|</mo>
       </mrow>
      </mrow>
      <mo>+</mo>
      <mrow>
       <mi>log</mi>
       <mfrac>
        <mn>1</mn>
        <mi>δ</mi>
       </mfrac>
      </mrow>
     </mrow>
     <mo>)</mo>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <geq></geq>
    <ci>m</ci>
    <apply>
     <times></times>
     <apply>
      <divide></divide>
      <cn type="integer">1</cn>
      <apply>
       <times></times>
       <ci>b</ci>
       <ci>ϵ</ci>
      </apply>
     </apply>
     <apply>
      <plus></plus>
      <apply>
       <log></log>
       <apply>
        <abs></abs>
        <ci>H</ci>
       </apply>
      </apply>
      <apply>
       <log></log>
       <apply>
        <divide></divide>
        <cn type="integer">1</cn>
        <ci>δ</ci>
       </apply>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   m\geq\frac{1}{b\epsilon}\left(\log|H|+\log\frac{1}{\delta}\right)
  </annotation>
 </semantics>
</math>

 examples 

<math display="inline" id="Occam_learning:39">
 <semantics>
  <mi>L</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>L</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   L
  </annotation>
 </semantics>
</math>

 will output 

<math display="inline" id="Occam_learning:40">
 <semantics>
  <mrow>
   <mi>h</mi>
   <mo>∈</mo>
   <mi>H</mi>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <in></in>
    <ci>h</ci>
    <ci>H</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   h\in H
  </annotation>
 </semantics>
</math>

 such that 

<math display="inline" id="Occam_learning:41">
 <semantics>
  <mrow>
   <mrow>
    <mi>e</mi>
    <mi>r</mi>
    <mi>r</mi>
    <mi>o</mi>
    <mi>r</mi>
    <mrow>
     <mo stretchy="false">(</mo>
     <mi>h</mi>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
   <mo>≤</mo>
   <mi>ϵ</mi>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <leq></leq>
    <apply>
     <times></times>
     <ci>e</ci>
     <ci>r</ci>
     <ci>r</ci>
     <ci>o</ci>
     <ci>r</ci>
     <ci>h</ci>
    </apply>
    <ci>ϵ</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   error(h)\leq\epsilon
  </annotation>
 </semantics>
</math>

 with probability at least 

<math display="inline" id="Occam_learning:42">
 <semantics>
  <mrow>
   <mn>1</mn>
   <mo>-</mo>
   <mi>δ</mi>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <minus></minus>
    <cn type="integer">1</cn>
    <ci>δ</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   1-\delta
  </annotation>
 </semantics>
</math>

.<a class="footnoteRef" href="#fn3" id="fnref3"><sup>3</sup></a></p>

<p>Any PAC learning algorithm is also an Occam algorithm.<a class="footnoteRef" href="#fn4" id="fnref4"><sup>4</sup></a></p>
<h2 id="improving-sample-complexity-for-common-problems">Improving sample complexity for common problems</h2>

<p>Though Occam and PAC learnability are equivalent, the Occam framework can be used to produce tighter bounds on the sample complexity of classical problems including conjunctions,<a class="footnoteRef" href="#fn5" id="fnref5"><sup>5</sup></a> conjunctions with few relevant variables,<a class="footnoteRef" href="#fn6" id="fnref6"><sup>6</sup></a> and decision lists.<a class="footnoteRef" href="#fn7" id="fnref7"><sup>7</sup></a></p>
<h2 id="extensions">Extensions</h2>

<p>Occam algorithms have also been shown to be successful for PAC learning in the presence of errors,<a class="footnoteRef" href="#fn8" id="fnref8"><sup>8</sup></a><a class="footnoteRef" href="#fn9" id="fnref9"><sup>9</sup></a> probabilistic concepts,<a class="footnoteRef" href="#fn10" id="fnref10"><sup>10</sup></a> function learning<a class="footnoteRef" href="#fn11" id="fnref11"><sup>11</sup></a> and Markovian non-independent examples.<a class="footnoteRef" href="#fn12" id="fnref12"><sup>12</sup></a></p>
<h2 id="see-also">See also</h2>
<ul>
<li><a href="Structural_Risk_Minimization" title="wikilink">Structural Risk Minimization</a></li>
<li><a href="Computational_learning_theory" title="wikilink">Computational learning theory</a></li>
</ul>
<h2 id="references">References</h2>

<p>"</p>

<p><a href="Category:Theoretical_computer_science" title="wikilink">Category:Theoretical computer science</a> <a href="Category:Computational_learning_theory" title="wikilink">Category:Computational learning theory</a> <a href="Category:Machine_learning" title="wikilink">Category:Machine learning</a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1">Kearns, M. J., &amp; Vazirani, U. V. (1994). An introduction to computational learning theory, chapter 2. MIT press.<a href="#fnref1">↩</a></li>
<li id="fn2">Blumer, A., Ehrenfeucht, A., Haussler, D., &amp; Warmuth, M. K. (1987). <em><a href="http://www.cse.buffalo.edu/~hungngo/classes/2008/694/papers/occam.pdf">Occam's razor</a></em>. Information processing letters, 24(6), 377-380.<a href="#fnref2">↩</a></li>
<li id="fn3"></li>
<li id="fn4">Board, R., &amp; Pitt, L. (1990, April). On the necessity of Occam algorithms. In Proceedings of the twenty-second annual ACM symposium on Theory of computing (pp. 54-63). ACM.<a href="#fnref4">↩</a></li>
<li id="fn5"></li>
<li id="fn6">Haussler, D. (1988). <em><a href="http://cs.ecs.baylor.edu/~hamerly/courses/5325_10s/papers/learning_theory/haussler1988inductive-bias.pdf">Quantifying inductive bias: AI learning algorithms and Valiant's learning framework</a></em>. Artificial intelligence, 36(2), 177-221.<a href="#fnref6">↩</a></li>
<li id="fn7">Rivest, R. L. (1987). <em><a href="http://people.csail.mit.edu/rivest/pubs/Riv87b.pdf">Learning decision lists. Machine learning</a></em>, 2(3), 229-246.<a href="#fnref7">↩</a></li>
<li id="fn8">Angluin, D., &amp; Laird, P. (1988). Learning from noisy examples. Machine Learning, 2(4), 343-370.<a href="#fnref8">↩</a></li>
<li id="fn9">Kearns, M., &amp; Li, M. (1993). Learning in the presence of malicious errors. SIAM Journal on Computing, 22(4), 807-837.<a href="#fnref9">↩</a></li>
<li id="fn10">Kearns, M. J., &amp; Schapire, R. E. (1990, October). <em><a href="http://www.cis.upenn.edu/~mkearns/papers/pconcepts.pdf">Efficient distribution-free learning of probabilistic concepts</a></em>. In Foundations of Computer Science, 1990. Proceedings., 31st Annual Symposium on (pp. 382-391). IEEE.<a href="#fnref10">↩</a></li>
<li id="fn11">Natarajan, B. K. (1993, August). Occam's razor for functions. In Proceedings of the sixth annual conference on Computational learning theory (pp. 370-376). ACM.<a href="#fnref11">↩</a></li>
<li id="fn12">Aldous, D., &amp; Vazirani, U. (1990, October). <em><a href="http://www.eecs.berkeley.edu/~vazirani/pubs/markovian.pdf">A Markovian extension of Valiant's learning model</a></em>. In Foundations of Computer Science, 1990. Proceedings., 31st Annual Symposium on (pp. 392-396). IEEE.<a href="#fnref12">↩</a></li>
</ol>
</section>
</body>
</html>
