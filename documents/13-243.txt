


Fork–join queue




Fork–join queue

(Figure)
A fork–join queueing node

In queueing theory, a discipline within the mathematical theory of probability, a fork–join queue is a queue where incoming jobs are split on arrival for service by numerous servers and joined before departure.1 The model is often used for parallel computations2 or systems where products need to be obtained simultaneously from different suppliers (in a warehouse or manufacturing setting).3 The key quantity of interest in this model is usually the time taken to service a complete job. The model has been described as a "key model for the performance analysis of parallel and distributed systems."4 Few analytical results exist for fork–join queues, but various approximations are known.
The situation where jobs arrive according to a Poisson process and service times are exponentially distributed is sometimes referred to as a Flatto–Hahn–Wright model or FHW model.567
Definition
On arrival at the fork point, a job is split into N sub-jobs which are served by each of the N servers. After service, sub-job wait until all other sub-jobs have also been processed. The sub-jobs are then rejoined and leave the system.8
For the fork–join queue to be stable the input rate must be strictly less than sum of the service rates at the service nodes.9
Applications
Fork–join queues have been used to model zoned RAID systems,10 parallel computations11 and for modelling order fulfilment in warehouses.12
Response time
The response time (or sojourn time13) is the total amount of time a job spends in the system.
Distribution
Ko and Serfozo give an approximation for the response time distribution when service times are exponentially distributed and jobs arrive either according to a Poisson process14 or a general distribution.15
Average response time
An exact formula for the average response time is only known in the case of two servers (N=2) with exponentially distributed service times (where each server is an M/M/1 queue). In this situation, the response time (total time a job spends in the system) is16


 
  where



 
  is the utilization.


 
  is the arrival rate of jobs to all the nodes.


 
  is the service rate across all the nodes.

In the situation where nodes are M/M/1 queues and N > 2, Varki's modification of mean value analysis can also be used to give an approximate value for the average response time.17
For general service times (where each node is an M/G/1 queue) Baccelli and Makowski give bounds for the average response time and higher moments of this quantity both in the transient and steady state situations.18 Kemper and Mandjes show that for some parameters these bounds are not tight and show demonstrate an approximation technique.19 For heterogeneous fork-join queues (fork-join queues with different service times), Alomari and Menasce propose an approximation based on harmonic numbers that can be extended to cover more general cases such as probabilistic fork, open and closed fork-join queues.20
Subtask dispersion
The subtask dispersion, defined to be the range of service times, can be numerically computed and optimal deterministic delays introduced to minimize the range.21
Stationary distribution
In general the stationary distribution of the number of jobs at each queue is intractable.22 Flatto considered the case of two servers (N=2) and derived the stationary distribution for the number of jobs at each queue via uniformization techniques.23 Pinotsi and Zazanis show that a product form solution exists when arrivals are deterministic as the queue lengths are then independent D/M/1 queues.24
Heavy traffic/diffusion approximation
When the server is heavily loaded (service rate of the queue is only just larger than arrival rate) the queue length process can be approximated by a reflected Brownian motion which converges to the same stationary distribution as the original queueing process.2526 Under limiting conditions the state space of the synchronisation queues collapses and all queues behave identically.27
Join queue distribution
Once jobs are served, the parts are reassembled at the join queue. Nelson and Tantawi published the distribution of the join queue length in the situation where all servers have the same service rate.28 Heterogeneous service rates and distribution asymptotic analysis are considered by Li and Zhao.29
Networks of fork–join queues
An approximate formula can be used to calculate the response time distribution for a network of fork–join queues joined in series (one after the other).30
Split–merge model
A related model is the split–merge model, for which analytical results exist.3132 Here on arrival a job is split into N sub-tasks which are serviced in parallel. Only when all the tasks ﬁnish servicing and have rejoined can the next job start. This leads to a slower response time on average.
Generalized (n,k) fork-join system
A generalization of the fork-join queueing system is the 
 
 
 
  fork-join system where the job exits the system when any 
 
 
 
  out of 
 
 
 
  tasks are served. The traditional fork-join queueing system is a special case of the 
 
 
 
  system when 
 
 
 
 . Bounds on the mean response time of this generalized system were found by Joshi, Liu and Soljanin. 33 34
References
"
Category:Single queueing nodes



↩

↩
↩

↩
↩

↩
↩




↩
↩
↩
↩
↩
↩
↩
↩
↩

↩
↩
↩

↩
↩
↩
↩
↩
↩




