   Moving average      Moving average   (Figure)  MovingAverage.GIF   In statistics , a moving average ( rolling average or running average ) is a calculation to analyze data points by creating a series of averages of different subsets of the full data set. It is also called a moving mean (MM) 1 or rolling mean and is a type of finite impulse response filter. Variations include: simple , and cumulative , or weighted forms (described below).  Given a series of numbers and a fixed subset size, the first element of the moving average is obtained by taking the average of the initial fixed subset of the number series. Then the subset is modified by "shifting forward"; that is, excluding the first number of the series and including the next number following the original subset in the series. This creates a new subset of numbers, which is averaged. This process is repeated over the entire data series. The plot line connecting all the (fixed) averages is the moving average. A moving average is a set of numbers, each of which is the average of the corresponding subset of a larger set of datum points. A moving average may also use unequal weights for each datum value in the subset to emphasize particular values in the subset.  A moving average is commonly used with time series data to smooth out short-term fluctuations and highlight longer-term trends or cycles. The threshold between short-term and long-term depends on the application, and the parameters of the moving average will be set accordingly. For example, it is often used in technical analysis of financial data, like stock prices , returns or trading volumes. It is also used in economics to examine gross domestic product, employment or other macroeconomic time series. Mathematically, a moving average is a type of convolution and so it can be viewed as an example of a low-pass filter used in signal processing . When used with non-time series data, a moving average filters higher frequency components without any specific connection to time, although typically some kind of ordering is implied. Viewed simplistically it can be regarded as smoothing the data.  Simple moving average  In financial applications a simple moving average (SMA) is the unweighted mean of the previous n data. However, in science and engineering the mean is normally taken from an equal number of data on either side of a central value. This ensures that variations in the mean are aligned with the variations in the data rather than being shifted in time.  An example of a simple equally weighted running mean for a n-day sample of closing price is the mean of the previous n days' closing prices. If those prices are     p  M   ,   p   M  -  1    ,  â€¦  ,   p   M  -   (   n  -  1   )         subscript  p  M    subscript  p    M  1    normal-â€¦   subscript  p    M    n  1       p_{M},p_{M-1},\dots,p_{M-(n-1)}   then the formula is      ð‘†ð‘€ð´  =     p  M   +   p   M  -  1    +  â‹¯  +   p   M  -   (   n  -  1   )      n       SMA       subscript  p  M    subscript  p    M  1    normal-â‹¯   subscript  p    M    n  1      n     \textit{SMA}={p_{M}+p_{M-1}+\cdots+p_{M-(n-1)}\over n}     When calculating successive values, a new value comes into the sum and an old value drops out, meaning a full summation each time is unnecessary for this simple case,       ð‘†ð‘€ð´  today   =     ð‘†ð‘€ð´  yesterday   +    p   M  -  n    n    -    p  M   n         subscript  SMA  today        subscript  SMA  yesterday      subscript  p    M  n    n       subscript  p  M   n      \textit{SMA}_{\mathrm{today}}=\textit{SMA}_{\mathrm{yesterday}}+{p_{M-n}\over n%
 }-{p_{M}\over n}     The period selected depends on the type of movement of interest, such as short, intermediate, or long-term. In financial terms moving-average levels can be interpreted as support in a falling market, or resistance in a rising market.  If the data used are not centered around the mean, a simple moving average lags behind the latest datum point by half the sample width. An SMA can also be disproportionately influenced by old datum points dropping out or new data coming in. One characteristic of the SMA is that if the data have a periodic fluctuation, then applying an SMA of that period will eliminate that variation (the average always containing one complete cycle). But a perfectly regular cycle is rarely encountered. 2  For a number of applications, it is advantageous to avoid the shifting induced by using only 'past' data. Hence a central moving average can be computed, using data equally spaced on either side of the point in the series where the mean is calculated. 3 This requires using an odd number of datum points in the sample window.  A major drawback of the SMA is that it lets through a significant amount of the signal shorter than the window length. Worse, it actually inverts it . This can lead to unexpected artifacts, such as peaks in the smoothed result appearing where there were troughs in the data. It also leads to the result being less smooth than expected since some of the higher frequencies are not properly removed.  Cumulative moving average  In a cumulative moving average , the data arrive in an ordered datum stream, and the user would like to get the average of all of the data up until the current datum point. For example, an investor may want the average price of all of the stock transactions for a particular stock up until the current time. As each new transaction occurs, the average price at the time of the transaction can be calculated for all of the transactions up to that point using the cumulative average, typically an equally weighted average of the sequence of n values     x  1   .   â€¦  ,   x  n       formulae-sequence   subscript  x  1    normal-â€¦   subscript  x  n      x_{1}.\ldots,x_{n}   up to the current time:        ð¶ð‘€ð´  n   =      x  1   +  â‹¯  +   x  n    n     .       subscript  CMA  n        subscript  x  1   normal-â‹¯   subscript  x  n    n     \textit{CMA}_{n}={{x_{1}+\cdots+x_{n}}\over n}\,.     The brute-force method to calculate this would be to store all of the data and calculate the sum and divide by the number of datum points every time a new datum point arrived. However, it is possible to simply update cumulative average as a new value,    x   n  +  1      subscript  x    n  1     x_{n+1}   becomes available, using the formula:       ð¶ð‘€ð´   n  +  1    =     x   n  +  1    +   n  â‹…   ð¶ð‘€ð´  n      n  +  1         subscript  CMA    n  1         subscript  x    n  1     normal-â‹…  n   subscript  CMA  n       n  1      \textit{CMA}_{n+1}={{x_{n+1}+n\cdot\textit{CMA}_{n}}\over{n+1}}     Thus the current cumulative average for a new datum point is equal to the previous cumulative average, times n , plus the latest datum point, all divided by the number of points received so far, n +1. When all of the datum points arrive (), then the cumulative average will equal the final average.  The derivation of the cumulative average formula is straightforward. Using        x  1   +  â‹¯  +   x  n    =   n  â‹…   ð¶ð‘€ð´  n           subscript  x  1   normal-â‹¯   subscript  x  n     normal-â‹…  n   subscript  CMA  n      x_{1}+\cdots+x_{n}=n\cdot\textit{CMA}_{n}     and similarly for , it is seen that       x   n  +  1    =    (    x  1   +  â‹¯  +   x   n  +  1     )   -   (    x  1   +  â‹¯  +   x  n    )    =     (   n  +  1   )   â‹…   ð¶ð‘€ð´   n  +  1     -   n  â‹…   ð¶ð‘€ð´  n            subscript  x    n  1         subscript  x  1   normal-â‹¯   subscript  x    n  1        subscript  x  1   normal-â‹¯   subscript  x  n             normal-â‹…    n  1    subscript  CMA    n  1      normal-â‹…  n   subscript  CMA  n        x_{n+1}=(x_{1}+\cdots+x_{n+1})-(x_{1}+\cdots+x_{n})=(n+1)\cdot\textit{CMA}_{n+%
 1}-n\cdot\textit{CMA}_{n}     Solving this equation for    ð¶ð‘€ð´   n  +  1      subscript  CMA    n  1     \textit{CMA}_{n+1}   results in:       ð¶ð‘€ð´   n  +  1    =     x   n  +  1    +   n  â‹…   ð¶ð‘€ð´  n      n  +  1    =    ð¶ð‘€ð´  n   +     x   n  +  1    -   ð¶ð‘€ð´  n     n  +  1            subscript  CMA    n  1         subscript  x    n  1     normal-â‹…  n   subscript  CMA  n       n  1            subscript  CMA  n        subscript  x    n  1     subscript  CMA  n      n  1        \textit{CMA}_{n+1}={x_{n+1}+n\cdot\textit{CMA}_{n}\over{n+1}}={\textit{CMA}_{n%
 }}+{{x_{n+1}-\textit{CMA}_{n}}\over{n+1}}     Weighted moving average  A weighted average is any average that has multiplying factors to give different weights to data at different positions in the sample window. Mathematically, the moving average is the convolution of the datum points with a fixed weighting function. One application is removing pixelisation from a digital graphical image.  In technical analysis of financial data, a weighted moving average (WMA) has the specific meaning of weights that decrease in arithmetical progression. 4 In an n -day WMA the latest day has weight n , the second latest n âˆ’Â 1, etc., down to one.       WMA  M   =     n   p  M    +    (   n  -  1   )    p   M  -  1     +  â‹¯  +   2   p   (    M  -  n   +  2   )     +   p   (    M  -  n   +  1   )      n  +   (   n  -  1   )   +  â‹¯  +  2  +  1         subscript  WMA  M         n   subscript  p  M        n  1    subscript  p    M  1     normal-â‹¯    2   subscript  p      M  n   2      subscript  p      M  n   1       n    n  1   normal-â‹¯  2  1      \text{WMA}_{M}={np_{M}+(n-1)p_{M-1}+\cdots+2p_{(M-n+2)}+p_{(M-n+1)}\over n+(n-%
 1)+\cdots+2+1}     (Figure)  WMA weights n =Â 15   The denominator is a triangle number equal to      n   (   n  +  1   )    2   .        n    n  1    2    \frac{n(n+1)}{2}.   In the more general case the denominator will always be the sum of the individual weights.  When calculating the WMA across successive values, the difference between the numerators of WMA M +1 and WMA M is np M +1 âˆ’ p M âˆ’Â â‹…â‹…â‹…Â âˆ’ p M âˆ’n+1 . If we denote the sum p M +Â â‹…â‹…â‹…Â + p M âˆ’ n +1 by Total M , then       Total   M  +  1    =     T  o  t  a   l  M    +   p   M  +  1     -    p    M  -  n   +  1           subscript  Total    M  1          T  o  t  a   subscript  l  M     subscript  p    M  1      subscript  p      M  n   1       \text{Total}_{M+1}=Total_{M}+p_{M+1}-p_{M-n+1}\,          Numerator   M  +  1    =     Numerator  M   +   n   p   M  +  1      -   T  o  t  a    l  M           subscript  Numerator    M  1         subscript  Numerator  M     n   subscript  p    M  1        T  o  t  a   subscript  l  M       \text{Numerator}_{M+1}=\text{Numerator}_{M}+np_{M+1}-Total_{M}\,          WMA   M  +  1    =     Numerator   M  +  1     n  +   (   n  -  1   )   +  â‹¯  +  2  +  1          subscript  WMA    M  1       subscript  Numerator    M  1      n    n  1   normal-â‹¯  2  1      \text{WMA}_{M+1}={\text{Numerator}_{M+1}\over n+(n-1)+\cdots+2+1}\,     The graph at the right shows how the weights decrease, from highest weight for the most recent datum points, down to zero. It can be compared to the weights in the exponential moving average which follows.  Exponential moving average  (Figure)  EMA weights N =15   An exponential moving average (EMA), also known as an exponentially weighted moving average (EWMA), 5 is a type of infinite impulse response filter that applies weighting factors which decrease exponentially . The weighting for each older datum decreases exponentially, never reaching zero. The graph at right shows an example of the weight decrease.  The EMA for a series Y may be calculated recursively:       S  1   =   Y  1        subscript  S  1    subscript  Y  1     S_{1}=Y_{1}   for     t  >  1   ,    S  t   =    Î±  â‹…   Y  t    +    (   1  -  Î±   )   â‹…   S   t  -  1          formulae-sequence    t  1      subscript  S  t      normal-â‹…  Î±   subscript  Y  t     normal-â‹…    1  Î±    subscript  S    t  1         t>1,\ \ S_{t}=\alpha\cdot Y_{t}+(1-\alpha)\cdot S_{t-1}     Where:   The coefficient Î± represents the degree of weighting decrease, a constant smoothing factor between 0 and 1. A higher Î± discounts older observations faster.  Y t is the value at a time period t .  S t is the value of the EMA at any time period t .   S 1 is undefined. S 1 may be initialized in a number of different ways, most commonly by setting S 1 to Y 1 , though other techniques exist, such as setting S 1 to an average of the first 4 or 5 observations. The importance of the S 1 initialisations effect on the resultant moving average depends on Î± ; smaller Î± values make the choice of S 1 relatively more important than larger Î± values, since a higher Î± discounts older observations faster.  Whatever is done for S 1 it assumes something about values prior to the available data and is necessarily in error. In view of this the early results should be regarded as unreliable until the iterations have had time to converge . This is sometimes called a 'spin-up' interval. One way to assess when it can be regarded as reliable is to consider the required accuracy of the result. For example, if 3% accuracy is required, initialising with Y 1 and taking data after five time constants (defined above) will ensure that the calculation has converged to within 3% (only 1 will remain in the result ). Sometimes with very small alpha, this can mean little of the result is useful. This is analogous to the problem of using a convolution filter (such as a weighted average) with a very long window.  This formulation is according to Hunter (1986). 6 By repeated application of this formula for different times, we can eventually write S t as a weighted sum of the datum points Y t , as:       S  t   =    Î±  Ã—   (    Y   t  -  1    +    (   1  -  Î±   )   Ã—   Y   t  -  2     +     (   1  -  Î±   )   2   Ã—   Y   t  -  3     +  â‹¯  +     (   1  -  Î±   )   k   Ã—   Y   t  -   (   k  +  1   )       )    +     (   1  -  Î±   )    k  +  1    Ã—   S   t  -   (   k  +  1   )            subscript  S  t       Î±     subscript  Y    t  1        1  Î±    subscript  Y    t  2        superscript    1  Î±   2    subscript  Y    t  3     normal-â‹¯     superscript    1  Î±   k    subscript  Y    t    k  1           superscript    1  Î±     k  1     subscript  S    t    k  1         S_{t}=\alpha\times(Y_{t-1}+(1-\alpha)\times Y_{t-2}+(1-\alpha)^{2}\times Y_{t-%
 3}+\cdots+(1-\alpha)^{k}\times Y_{t-(k+1)})+(1-\alpha)^{k+1}\times S_{t-(k+1)}     for any suitable k = 0, 1, 2, ... The weight of the general datum point    Y   t  -  i      subscript  Y    t  i     Y_{t-i}   is    Î±    (   1  -  Î±   )    i  -  1        Î±   superscript    1  Î±     i  1      \alpha(1-\alpha)^{i-1}   .  An alternate approach by Roberts (1959) uses Y t in lieu of Y t âˆ’1 : 7       S   t  ,  alternate    =    Î±  â‹…   Y  t    +    (   1  -  Î±   )   â‹…   S   t  -  1           subscript  S   t  alternate       normal-â‹…  Î±   subscript  Y  t     normal-â‹…    1  Î±    subscript  S    t  1        S_{t,\text{ alternate}}=\alpha\cdot Y_{t}+(1-\alpha)\cdot S_{t-1}     This formula can also be expressed in technical analysis terms as follows, showing how the EMA steps towards the latest datum point, but only by a proportion of the difference (each time):       EMA  today   =    EMA  yesterday   +   Î±  Ã—   (    price  today   -   EMA  yesterday    )          subscript  EMA  today      subscript  EMA  yesterday     Î±     subscript  price  today    subscript  EMA  yesterday        \text{EMA}_{\text{today}}=\text{EMA}_{\text{yesterday}}+\alpha\times\par
 (%
 \text{price}_{\text{today}}-\text{EMA}_{\text{yesterday}})     Expanding out    EMA  yesterday     subscript  EMA  yesterday    \text{EMA}_{\text{yesterday}}   each time results in the following power series, showing how the weighting factor on each datum point p 1 , p 2 , etc., decreases exponentially:       EMA  today   =   Î±  Ã—   (    p  1   +    (   1  -  Î±   )    p  2    +     (   1  -  Î±   )   2    p  3    +     (   1  -  Î±   )   3    p  4    +  â‹¯   )         subscript  EMA  today     Î±     subscript  p  1       1  Î±    subscript  p  2       superscript    1  Î±   2    subscript  p  3       superscript    1  Î±   3    subscript  p  4    normal-â‹¯      \text{EMA}_{\text{today}}={\alpha\times(p_{1}+(1-\alpha)p_{2}+(1-\alpha)^{2}p_%
 {3}+(1-\alpha)^{3}p_{4}+\cdots)}     where       p  1     subscript  p  1    p_{1}   is    price  today     subscript  price  today    \text{price}_{\text{today}}         p  2     subscript  p  2    p_{2}   is    price  yesterday     subscript  price  yesterday    \text{price}_{\text{yesterday}}     and so on        EMA  today   =     p  1   +    (   1  -  Î±   )    p  2    +     (   1  -  Î±   )   2    p  3    +     (   1  -  Î±   )   3    p  4    +  â‹¯    1  +   (   1  -  Î±   )   +    (   1  -  Î±   )   2   +    (   1  -  Î±   )   3   +  â‹¯         subscript  EMA  today        subscript  p  1       1  Î±    subscript  p  2       superscript    1  Î±   2    subscript  p  3       superscript    1  Î±   3    subscript  p  4    normal-â‹¯     1    1  Î±    superscript    1  Î±   2    superscript    1  Î±   3   normal-â‹¯      \text{EMA}_{\text{today}}={p_{1}+(1-\alpha)p_{2}+(1-\alpha)^{2}p_{3}+(1-\alpha%
 )^{3}p_{4}+\cdots\over 1+(1-\alpha)+(1-\alpha)^{2}+(1-\alpha)^{3}+\cdots}   ,  since     1  /  Î±   =   1  +   (   1  -  Î±   )   +    (   1  -  Î±   )   2   +  â‹¯         1  Î±     1    1  Î±    superscript    1  Î±   2   normal-â‹¯     1/\alpha=1+(1-\alpha)+(1-\alpha)^{2}+\cdots   .  This is an infinite sum with decreasing terms.  The N periods in an N -day EMA only specify the Î± factor. N is not a stopping point for the calculation in the way it is in an SMA or WMA . For sufficiently large N , the first N datum points in an EMA represent about 86% of the total weight in the calculation when    Î±  =   2  /   (   N  +  1   )        Î±    2    N  1      \alpha=2/(N+1)   : 8        Î±  Ã—   (   1  +   (   1  -  Î±   )   +    (   1  -  Î±   )   2   +  â‹¯  +    (   1  -  Î±   )   N    )     Î±  Ã—   (   1  +   (   1  -  Î±   )   +    (   1  -  Î±   )   2   +  â‹¯  +    (   1  -  Î±   )   âˆž    )     =   1  -    (   1  -   2   N  +  1     )    N  +  1             Î±    1    1  Î±    superscript    1  Î±   2   normal-â‹¯   superscript    1  Î±   N       Î±    1    1  Î±    superscript    1  Î±   2   normal-â‹¯   superscript    1  Î±          1   superscript    1    2    N  1       N  1       {{\alpha\times\left(1+(1-\alpha)+(1-\alpha)^{2}+\cdots+(1-\alpha)^{N}\right)}%
 \over{\alpha\times\left(1+(1-\alpha)+(1-\alpha)^{2}+\cdots+(1-\alpha)^{\infty}%
 \right)}}=1-{\left(1-{2\over N+1}\right)}^{N+1}      i.e.     lim   N  â†’  âˆž     [   1  -    (   1  -   2   N  +  1     )    N  +  1     ]       subscript    normal-â†’  N      delimited-[]    1   superscript    1    2    N  1       N  1        \lim_{N\to\infty}\left[1-{\left(1-{2\over N+1}\right)}^{N+1}\right]   simplified, 9 tends to     1  -   e   -  2     â‰ˆ  0.8647        1   superscript  e    2     0.8647    1-\text{e}^{-2}\approx 0.8647   .   The above discussion requires a bit of clarification. The sum of the weights of all the terms (i.e., infinite number of terms) in an exponential moving average is 1. The sum of the weights of   N   N   N   terms is    1  -    (   1  -  Î±   )    N  +  1        1   superscript    1  Î±     N  1      1-(1-\alpha)^{N+1}   . Both of these sums can be derived by using the formula for the sum of a geometric series. The weight omitted after   N   N   N   terms is given by subtracting this from 1, and you get     1  -   (   1  -    (   1  -  Î±   )    N  +  1     )    =    (   1  -  Î±   )    N  +  1          1    1   superscript    1  Î±     N  1       superscript    1  Î±     N  1      1-(1-(1-\alpha)^{N+1})=(1-\alpha)^{N+1}   (this is essentially the formula given below for the weight omitted). Note that there is no "accepted" value that should be chosen for   Î±   Î±   \alpha   although there are some recommended values based on the application. In the above discussion, we have substituted a commonly used value for    Î±  =   2  /   (   N  +  1   )        Î±    2    N  1      \alpha=2/(N+1)   in the formula for the weight of   N   N   N   terms. This value for   Î±   Î±   \alpha   comes from setting the average age of the data from a SMA equal to the average age of the data from an EMA and solving for   Î±   Î±   \alpha   . Again, it is just a recommendationâ€”not a requirement. If you make this substitution, and you make use of 10       lim   n  â†’  âˆž      (   1  +   a   1  +  n     )   n    =   e  a         subscript    normal-â†’  n      superscript    1    a    1  n     n     superscript  e  a     \lim_{n\to\infty}\left(1+{a\over{1+n}}\right)^{n}=e^{a}   , then you get the 0.864 approximation. Intuitively, what this is telling us is that the weight after   N   N   N   terms of an ``   N   N   N   -period" exponential moving average converges to 0.864.  The power formula above gives a starting value for a particular day, after which the successive days formula shown first can be applied. The question of how far back to go for an initial value depends, in the worst case, on the data. Large price values in old data will affect on the total even if their weighting is very small. If prices have small variations then just the weighting can be considered. The weight omitted by stopping after k terms is       Î±  Ã—   (     (   1  -  Î±   )   k   +    (   1  -  Î±   )    k  +  1    +    (   1  -  Î±   )    k  +  2    +  â‹¯   )    ,      Î±     superscript    1  Î±   k    superscript    1  Î±     k  1     superscript    1  Î±     k  2    normal-â‹¯     \alpha\times\left((1-\alpha)^{k}+(1-\alpha)^{k+1}+(1-\alpha)^{k+2}+\cdots%
 \right),     which is       Î±  Ã—    (   1  -  Î±   )   k   Ã—   (   1  +   (   1  -  Î±   )   +    (   1  -  Î±   )   2   +  â‹¯   )    ,      Î±   superscript    1  Î±   k     1    1  Î±    superscript    1  Î±   2   normal-â‹¯     \alpha\times(1-\alpha)^{k}\times\left(1+(1-\alpha)+(1-\alpha)^{2}+\cdots\right),     i.e. a fraction       weight omitted by stopping after k terms  total weight   =    Î±  Ã—   [     (   1  -  Î±   )   k   +    (   1  -  Î±   )    k  +  1    +    (   1  -  Î±   )    k  +  2    +  â‹¯   ]     Î±  Ã—   [   1  +   (   1  -  Î±   )   +    (   1  -  Î±   )   2   +  â‹¯   ]           weight omitted by stopping after k terms  total weight       Î±   delimited-[]     superscript    1  Î±   k    superscript    1  Î±     k  1     superscript    1  Î±     k  2    normal-â‹¯       Î±   delimited-[]    1    1  Î±    superscript    1  Î±   2   normal-â‹¯        {{\text{weight omitted by stopping after k terms}}\over{\text{total weight}}}=%
 {{\alpha\times\left[(1-\alpha)^{k}+(1-\alpha)^{k+1}+(1-\alpha)^{k+2}+\cdots%
 \right]}\over{{\alpha\times\left[1+(1-\alpha)+(1-\alpha)^{2}+\cdots\right]}}}          =     Î±    (   1  -  Î±   )   k    Ã—   1   1  -   (   1  -  Î±   )       Î±   1  -   (   1  -  Î±   )          absent        Î±   superscript    1  Î±   k      1    1    1  Î±        Î±    1    1  Î±        ={{\alpha(1-\alpha)^{k}\times{{1}\over{1-(1-\alpha)}}}\over{{{\alpha}\over{1-(%
 1-\alpha)}}}}          =    (   1  -  Î±   )   k       absent   superscript    1  Î±   k     =(1-\alpha)^{k}     out of the total weight.  For example, to have 99.9% of the weight, set above ratio equal to 0.1% and solve for k :      k  =    log   (  0.001  )     log   (   1  -  Î±   )         k      0.001       1  Î±       k={\log(0.001)\over\log(1-\alpha)}     terms should be used. Since     log    (   1  -  Î±   )         1  Î±     \log\,(1-\alpha)   approaches     -  2    N  +  1         2     N  1     -2\over N+1   as N increases, 11 this simplifies to approximately 12      k  =   3.45   (   N  +  1   )        k    3.45    N  1      k=3.45(N+1)\,     for this example (99.9% weight).  Modified moving average  A modified moving average (MMA), running moving average (RMA), or smoothed moving average (SMMA) is defined as:       MMA  today   =      (   N  -  1   )   Ã—   MMA  yesterday    +  price   N        subscript  MMA  today           N  1    subscript  MMA  yesterday    price   N     \text{MMA}_{\text{today}}={(N-1)\times\text{MMA}_{\text{yesterday}}+\text{%
 price}\over{N}}     In short, this is an exponential moving average, with    Î±  =   1  /  N       Î±    1  N     \alpha=1/N   .  Application to measuring computer performance  Some computer performance metrics, e.g. the average process queue length, or the average CPU utilization, use a form of exponential moving average.        S  n   =     Î±   (    t  n   -   t   n  -  1     )    Ã—   Y  n    +    (   1  -   Î±   (    t  n   -   t   n  -  1     )     )   Ã—   S   n  -  1       .       subscript  S  n         Î±     subscript  t  n    subscript  t    n  1       subscript  Y  n        1    Î±     subscript  t  n    subscript  t    n  1        subscript  S    n  1        S_{n}=\alpha(t_{n}-t_{n-1})\times Y_{n}+(1-\alpha(t_{n}-t_{n-1}))\times S_{n-1}.     Here   Î±   Î±   \alpha   is defined as a function of time between two readings. An example of a coefficient giving bigger weight to the current reading, and smaller weight to the older readings is       Î±   (    t  n   -   t   n  -  1     )    =   1  -   exp   (   -     t  n   -   t   n  -  1      W  Ã—  60     )           Î±     subscript  t  n    subscript  t    n  1        1           subscript  t  n    subscript  t    n  1       W  60         \alpha(t_{n}-t_{n-1})=1-\exp\left({-{{t_{n}-t_{n-1}}\over{W\times 60}}}\right)     where exp() is the exponential function , time for readings t n is expressed in seconds, and   W   W   W   is the period of time in minutes over which the reading is said to be averaged (the mean lifetime of each reading in the average). Given the above definition of   Î±   Î±   \alpha   , the moving average can be expressed as       S  n   =     (   1  -   exp   (   -     t  n   -   t   n  -  1      W  Ã—  60     )     )   Ã—   Y  n    +    exp   (   -     t  n   -   t   n  -  1      W  Ã—  60     )    Ã—   S   n  -  1           subscript  S  n         1           subscript  t  n    subscript  t    n  1       W  60        subscript  Y  n               subscript  t  n    subscript  t    n  1       W  60       subscript  S    n  1        S_{n}=(1-\exp\left({-{{t_{n}-t_{n-1}}\over{W\times 60}}}\right))\times Y_{n}+%
 \par
 \exp\left({-{{t_{n}-t_{n-1}}\over{W\times 60}}}\right)\times S_{n-1}     For example, a 15-minute average L of a process queue length Q , measured every 5 seconds (time difference is 5 seconds), is computed as       L  n   =     (   1  -   exp   (   -   5   15  Ã—  60     )     )   Ã—   Q  n    +    e   -   5   15  Ã—  60      Ã—   L   n  -  1      =     (   1  -   exp   (   -   1  180    )     )   Ã—   Q  n    +    e   -   1  /  180     Ã—   L   n  -  1      =    Q  n   +    e   -   1  /  180     Ã—   (    L   n  -  1    -   Q  n    )            subscript  L  n         1        5    15  60        subscript  Q  n       superscript  e      5    15  60       subscript  L    n  1                 1        1  180       subscript  Q  n       superscript  e      1  180      subscript  L    n  1              subscript  Q  n      superscript  e      1  180        subscript  L    n  1     subscript  Q  n         L_{n}=(1-\exp\left({-{5\over{15\times 60}}}\right))\times Q_{n}+e^{-{5\over{15%
 \times 60}}}\times L_{n-1}=(1-\exp\left({-{1\over{180}}}\right))\times Q_{n}+e%
 ^{-1/180}\times L_{n-1}=Q_{n}+e^{-1/180}\times(L_{n-1}-Q_{n})     Other weightings  Other weighting systems are used occasionally â€“ for example, in share trading a volume weighting will weight each time period in proportion to its trading volume.  A further weighting, used by actuaries, is Spencer's 15-Point Moving Average 13 (a central moving average). The symmetric weight coefficients are âˆ’3, âˆ’6, âˆ’5, 3, 21, 46, 67, 74, 67, 46, 21, 3, âˆ’5, âˆ’6, âˆ’3.  Outside the world of finance, weighted running means have many forms and applications. Each weighting function or "kernel" has its own characteristics. In engineering and science the frequency and phase response of the filter is often of primary importance in understanding the desired and undesired distortions that a particular filter will apply to the data.  A mean does not just "smooth" the data. A mean is a form of low-pass filter. The effects of the particular filter used should be understood in order to make an appropriate choice. On this point, the French version of this article discusses the spectral effects of 3 kinds of means (cumulative, exponential, Gaussian).  Moving median  From a statistical point of view, the moving average, when used to estimate the underlying trend in a time series, is susceptible to rare events such as rapid shocks or other anomalies. A more robust estimate of the trend is the simple moving median over n time points:      ð‘†ð‘€ð‘€  =   Median   (   p  M   ,   p   M  -  1    ,  â€¦  ,   p    M  -  n   +  1    )        SMM    Median    subscript  p  M    subscript  p    M  1    normal-â€¦   subscript  p      M  n   1        \textit{SMM}=\text{Median}(p_{M},p_{M-1},\ldots,p_{M-n+1})     where the median is found by, for example, sorting the values inside the brackets and finding the value in the middle. For larger values of n , the median can be efficiently computed by updating an indexable skiplist . 14  Statistically, the moving average is optimal for recovering the underlying trend of the time series when the fluctuations about the trend are normally distributed . However, the normal distribution does not place high probability on very large deviations from the trend which explains why such deviations will have a disproportionately large effect on the trend estimate. It can be shown that if the fluctuations are instead assumed to be Laplace distributed , then the moving median is statistically optimal. 15 For a given variance, the Laplace distribution places higher probability on rare events than does the normal, which explains why the moving median tolerates shocks better than the moving mean.  When the simple moving median above is central, the smoothing is identical to the median filter which has applications in, for example, image signal processing.  Moving average regression model  In a moving average regression model , a variable of interest is assumed to be a weighted moving average of an unobserved error term; the weights in the moving average are parameters to be estimated.  See also   Exponential smoothing  Moving average convergence/divergence indicator  Window function  Moving average crossover  Rising moving average  Running total  Local regression  Kernel smoothing   Notes and references  "  Category:Statistical charts and diagrams  Category:Time series analysis  Category:Mathematical finance  Category:Chart overlays     Hydrologic Variability of the Cosumnes River Floodplain (Booth et al., San Francisco Estuary and Watershed Science, Volume 4, Issue 2, 2006) â†©  Statistical Analysis , Ya-lun Chou, Holt International, 1975, ISBN 0-03-089422-0, section 17.9. â†©  The derivation and properties of the simple central moving average are given in full at Savitzkyâ€“Golay filter â†©  â†©  http://lorien.ncl.ac.uk/ming/filter/filewma.htm â†©  NIST/SEMATECH e-Handbook of Statistical Methods: Single Exponential Smoothing at the National Institute of Standards and Technology â†©  NIST/SEMATECH e-Handbook of Statistical Methods: EWMA Control Charts at the National Institute of Standards and Technology â†©  The denominator on the left-hand side should be unity, and the numerator will become the right-hand side ( geometric series ),    Î±   (    1  -    (   1  -  Î±   )    N  +  1      1  -   (   1  -  Î±   )     )       Î±      1   superscript    1  Î±     N  1       1    1  Î±       \alpha\left({1-(1-\alpha)^{N+1}\over 1-(1-\alpha)}\right)   . â†©  Because (1+ x / n ) n tends to the limit e x for large n . â†©  See the following link for a proof. â†©  It means   Î±   Î±   \alpha   -> 0, and the Taylor series of     log   (   1  -  Î±   )    =    -  Î±   -    Î±  2   /  2   -  â‹¯           1  Î±        Î±      superscript  Î±  2   2   normal-â‹¯     \log(1-\alpha)=-\alpha-\alpha^{2}/2-\cdots   is equivalent to    -  Î±      Î±    -\alpha   . â†©  log e (0.001) / 2 = -3.45 â†©  Spencer's 15-Point Moving Average â€” from Wolfram MathWorld â†©  http://code.activestate.com/recipes/576930/ â†©  G.R. Arce, "Nonlinear Signal Processing: A Statistical Approach", Wiley:New Jersey, USA, 2005. â†©     