   Linear hashing      Linear hashing   Linear hashing is a dynamic hash table algorithm invented by Witold Litwin (1980), 1 and later popularized by Paul Larson . Linear hashing allows for the expansion of the hash table one slot at a time. The frequent single slot expansion can very effectively control the length of the collision chain. The cost of hash table expansion is spread out across each hash table insertion operation, as opposed to being incurred all at once. 2 Linear hashing is therefore well suited for interactive applications.  Algorithm Details  First the initial hash table is set up with some arbitrary initial number of buckets. The following values need to be kept track of:      N   N   N   : The initial number of buckets.     L   L   L   : The current level which is an integer that indicates on a logarithmic scale approximately how many buckets the table has grown by. This is initially   0   0    .     S   S   S   : The step pointer which points to a bucket. It initially points to the first bucket in the table.   Bucket collisions can be handled in a variety of ways but it is typical to have space for two items in each bucket and to add more buckets whenever a bucket overflows. More than two items can be used once the implementation is debugged. Addresses are calculated in the following way:   Apply a hash function to the key and call the result   H   H   H   .  If    H  mod   (   N  ×   2  L    )      modulo  H    N   superscript  2  L      H\bmod(N\times 2^{L})   is an address that comes before   S   S   S   , the address is    H  mod   (   N  ×   2   L  +  1     )      modulo  H    N   superscript  2    L  1       H\bmod(N\times 2^{L+1})   .  If    H  mod   (   N  ×   2  L    )      modulo  H    N   superscript  2  L      H\bmod(N\times 2^{L})   is   S   S   S   or an address that comes after   S   S   S   , the address is    H  mod   (   N  ×   2  L    )      modulo  H    N   superscript  2  L      H\bmod(N\times 2^{L})   .   To add a bucket:   Allocate a new bucket at the end of the table.  If   S   S   S   points to the    N  ×   2  L       N   superscript  2  L     N\times 2^{L}   th bucket in the table, reset   S   S   S   and increment   L   L   L   .  Otherwise increment   S   S   S   .   The effect of all of this is that the table is split into three sections; the section before   S   S   S   , the section from   S   S   S   to    N  ×   2  L       N   superscript  2  L     N\times 2^{L}   , and the section after    N  ×   2  L       N   superscript  2  L     N\times 2^{L}   . The first and last sections are stored using    H  mod   (   N  ×   2   L  +  1     )      modulo  H    N   superscript  2    L  1       H\bmod(N\times 2^{L+1})   and the middle section is stored using    H  mod   (   N  ×   2  L    )      modulo  H    N   superscript  2  L      H\bmod(N\times 2^{L})   . Each time   S   S   S   reaches    N  ×   2  L       N   superscript  2  L     N\times 2^{L}   the table has doubled in size.  Points to ponder over       Full buckets are not necessarily split, and an overflow space for temporary overflow buckets is required. In external storage, this could mean a second file.  Buckets split are not necessarily full  Every bucket will be split sooner or later and so all Overflows will be reclaimed and rehashed.  Split pointer s decides which bucket to split  s is independent to overflowing bucket  At level i, s is between 0 and 2^i  s is incremented and if at end, is reset to 0.  since a bucket at s is split then s is in incremented, only buckets before s have the second doubled hash space .  a large good pseudo random number is first obtained , and then is bit-masked with either (2^i) -1 or (2^(i+1)) -1, but the latter only applies if x, the random number, bit-masked with the former , (2^i) - 1, is less than S, so the larger range of hash values only apply to buckets that have already been split.  e.g. To bit-mask a number , use x & 0111 , where & is the AND operator, 111 is binary 7 , where 7 = 8 - 1 and 8 is 2^3 and i = 3.  what if s lands on a bucket which has 1 or more full overflow buckets ? The split will only reduce the overflow bucket count by 1, and the remaining overflow buckets will have to be recreated by seeing which of the new 2 buckets, or their overflow buckets, the overflow entries belong.   h i (k)= h(k) mod(2^i n)  h i+1 doubles the range of h i   Algorithm for inserting ‘k’ and checking overflow condition   b = h 0 (k)  if b < split-pointer then  b = h 1 (k)   Searching in the hash table for ‘k’   b = h 0 (k)  if b < split-pointer then  b = h 1 (k)  read bucket b and search there   Adoption in language systems  Griswold and Townsend 3 discussed the adoption of linear hashing in the Icon language . They discussed the implementation alternatives of dynamic array algorithm used in linear hashing, and presented performance comparisons using a list of Icon benchmark applications.  Adoption in database systems  Linear hashing is used in the BDB Berkeley database system, which in turn is used by many software systems such as OpenLDAP, using a C implementation derived from the CACM article and first published on the Usenet in 1988 by Esmond Pitt.  References  External links   Sorted Linear Hash Table, C++ implementation of a Linear Hashtable  TommyDS, C implementation of a Linear Hashtable  An in Memory Go Implementation with Explanation   A C++ Implementation of Linear Hashtable which Supports Both Filesystem and In-Memory Storage   See also   Extendible hashing  Consistent hashing   "  Category:Search algorithms  Category:Hashing     ↩  ↩  ↩     