   Wishart distribution      Wishart distribution   e^{-\frac{{\rm tr}(\mathbf{V}^{-1}\mathbf{X})}{2}}}{2^\frac{np}{2}|{\mathbf V}|^\frac{n}{2}\Gamma_p(\frac{n}{2})}   is the multivariate gamma function      t  r      t  r    tr   is the trace function   | cdf        =  | mean       =     n    𝐕        n  normal-  normal-  𝐕  normal-  normal-    n \mathbf{ V }     | median     =  | mode       =      (    n   −   p   −   1   )     𝐕          normal-  n  normal-  normal-−  normal-  p  normal-  normal-−  normal-  1   normal-  normal-  𝐕  normal-  normal-    ( n − p − 1) \mathbf{ V }    for      n   ≥   p    +    1         n  normal-  normal-≥  normal-  p  normal-     normal-  1     n ≥ p + 1     | variance   =      Var   (   𝐗   i  j    )    =   n   (    v   i  j   2   +    v   i  i     v   j  j      )         Var   subscript  𝐗    i  j       n     superscript   subscript  v    i  j    2      subscript  v    i  i     subscript  v    j  j         \operatorname{Var}(\mathbf{X}_{ij})=n\left(v_{ij}^{2}+v_{ii}v_{jj}\right)     | skewness   =  | kurtosis   =  | entropy    = see  below  | mgf        =  | char       =     Θ  ↦    |   𝐈  -   2   i   𝚯  𝐕    |    -   n  2        maps-to  normal-Θ   superscript      𝐈    2  i  𝚯  𝐕         n  2       \Theta\mapsto\left|{\mathbf{I}}-2i\,{\mathbf{\Theta}}{\mathbf{V}}\right|^{-%
 \frac{n}{2}}     }}  In statistics , the Wishart distribution is a generalization to multiple dimensions of the chi-squared distribution , or, in the case of non-integer degrees of freedom, of the gamma distribution . It is named in honor of John Wishart , who first formulated the distribution in 1928. 1  It is a family of probability distributions defined over symmetric, nonnegative-definite  matrix -valued random variables (“random matrices”). These distributions are of great importance in the estimation of covariance matrices in multivariate statistics . In Bayesian statistics , the Wishart distribution is the conjugate prior of the inverse  covariance-matrix of a multivariate-normal random-vector .  Definition  Suppose   X   X   X   is an    n  ×  p      n  normal-×  p    n×p   matrix, each row of which is independently drawn from a    p   p   p   -variate normal distribution with zero mean:        X   (  i  )    =    (   x  i  1   ,  …  ,   x  i  p   )   T   ∼    N  p    (  0  ,  V  )     .         subscript  X  i    superscript    superscript   subscript  x  i   1   normal-…   superscript   subscript  x  i   p    T     similar-to       subscript  N  p    0  V       X_{(i)}{=}(x_{i}^{1},\dots,x_{i}^{p})^{T}\sim N_{p}(0,V).     Then the Wishart distribution is the probability distribution of the    p  ×  p      p  normal-×  p    p×p   random matrix  X T X }} known as the scatter matrix . One indicates that   S   S   S   has that probability distribution by writing       S  ∼    W  p    (  V  ,  n  )     .     similar-to  S     subscript  W  p    V  n      S\sim W_{p}(V,n).     The positive integer   n   n   n   is the number of degrees of freedom . Sometimes this is written    W   (  V  ,  p  ,  n  )       W   V  p  n     W(V,p,n)   . For    n  ≥  p      n  normal-≥  p    n≥p   the matrix   S   S   S   is invertible with probability   1   1   1   if   V   V   V   is invertible.  If    p  =  V  =  1        p  V       1     p=V=1   then this distribution is a chi-squared distribution with   n   n   n   degrees of freedom.  Occurrence  The Wishart distribution arises as the distribution of the sample covariance matrix for a sample from a multivariate normal distribution . It occurs frequently in likelihood-ratio tests in multivariate statistical analysis. It also arises in the spectral theory of random matrices and in multidimensional Bayesian analysis. 2 It is also encountered in wireless communications, while analyzing the performance of Rayleigh fading  MIMO wireless channels . 3  Probability density function  The Wishart distribution can be characterized by its probability density function as follows:  Let   𝐗   𝐗   \mathbf{X}   be a    p  ×  p      p  normal-×  p    p×p   symmetric matrix of random variables that is positive definite . Let   𝐕   𝐕   \mathbf{V}   be a (fixed) positive definite matrix of size    p  ×  p      p  normal-×  p    p×p   .  Then, if    n  ≥  p      n  normal-≥  p    n≥p   ,   𝐗   𝐗   \mathbf{X}   has a Wishart distribution with   n   n   n   degrees of freedom if it has a probability density function given by       1    2    n  p   2      |  𝐕  |    n  2     Γ  p    (   n  2   )       |  𝐗  |     n  -  p  -  1   2     e   -    1  2   tr   (    𝐕   -  1    𝐗   )            1     superscript  2      n  p   2     superscript    𝐕     n  2     subscript  normal-Γ  p     n  2      superscript    𝐗       n  p  1   2     superscript  e        1  2   tr     superscript  𝐕    1    𝐗        \frac{1}{2^{\frac{np}{2}}\left|{\mathbf{V}}\right|^{\frac{n}{2}}\Gamma_{p}(%
 \frac{n}{2})}{\left|\mathbf{X}\right|}^{\frac{n-p-1}{2}}e^{-\frac{1}{2}{\rm tr%
 }({\mathbf{V}}^{-1}\mathbf{X})}     where    |  𝐗  |      𝐗    \left|{\mathbf{X}}\right|   denotes determinant and is the multivariate gamma function defined as         Γ  p    (    n  2    )    =    π    p   (   p  -  1   )    4     Π   j  =  1   p   Γ   (     n  2    +     1  -  j   2     )     .         subscript  normal-Γ  p     n  2       superscript  π      p    p  1    4     superscript   subscript  normal-Π    j  1    p   normal-Γ      n  2       1  j   2       \Gamma_{p}\left(\tfrac{n}{2}\right)=\pi^{\frac{p(p-1)}{4}}\Pi_{j=1}^{p}\Gamma%
 \left(\tfrac{n}{2}+\tfrac{1-j}{2}\right).     In fact the above definition can be extended to any real    n  >   p  −  1       n    p  normal-−  1     n>p−1   . If    n  ≤  p  −  1      n  normal-≤  p  normal-−  1    n≤p−1   , then the Wishart no longer has a density—instead it represents a singular distribution that takes values in a lower-dimension subspace of the space of    p  ×  p      p  normal-×  p    p×p   matrices. 4  Use in Bayesian statistics  In Bayesian statistics , in the context of the multivariate normal distribution , the Wishart distribution is the conjugate prior to the precision matrix  Σ −1 }} , where   𝚺   𝚺   \mathbf{Σ}   is the covariance matrix.  Choice of parameters  The least informative, proper Wishart prior is obtained by setting    n  =  p      n  p    n=p   .  The prior mean of is    n  𝐕      n  𝐕    n\mathbf{V}   , suggesting that a reasonable choice for would be , where is some prior guess for the covariance matrix.  Properties  Log-expectation  Note the following formula: 5       E   [   ln   |  𝐗  |    ]    =     ψ  p    (   n  /  2   )    +   p   ln   (  2  )     +   ln   |  𝐕  |          normal-E      𝐗          subscript  ψ  p     n  2      p    2        𝐕       \operatorname{E}[\ln|\mathbf{X}|]=\psi_{p}(n/2)+p\ln(2)+\ln|\mathbf{V}|     where    ψ  p     subscript  ψ  p    \psi_{p}   is the multivariate digamma function (the derivative of the log of the multivariate gamma function ).  This plays a role in variational Bayes derivations for Bayes networks involving the Wishart distribution.  Entropy  The information entropy of the distribution has the following formula: 6       H   [  𝐗  ]    =     -   ln   (   B   (  𝐕  ,  n  )    )     -     n  -  p  -  1   2    E   [   ln   |  𝐗  |    ]      +    n  p   2         normal-H  𝐗             B   𝐕  n            n  p  1   2    normal-E      𝐗           n  p   2      \operatorname{H}[\mathbf{X}]=-\ln\left(B(\mathbf{V},n)\right)-\frac{n-p-1}{2}%
 \operatorname{E}[\ln|\mathbf{X}|]+\frac{np}{2}     where    B   (  𝐕  ,  n  )       B   𝐕  n     B(\mathbf{V},n)   is the normalizing constant of the distribution:       B   (  𝐕  ,  n  )    =   1     |  𝐕  |    n  2     2    n  p   2     Γ  p    (   n  2   )           B   𝐕  n      1     superscript    𝐕     n  2     superscript  2      n  p   2     subscript  normal-Γ  p     n  2       B(\mathbf{V},n)=\frac{1}{\left|\mathbf{V}\right|^{\frac{n}{2}}2^{\frac{np}{2}}%
 \Gamma_{p}(\frac{n}{2})}     This can be expanded as follows:      H   [  𝐗  ]      normal-H  𝐗    \displaystyle\operatorname{H}[\mathbf{X}]     Cross-Entropy  The cross entropy of two Wishart distributions    p  0     subscript  p  0    p_{0}   with parameters     n  0   ,   V  0       subscript  n  0    subscript  V  0     n_{0},V_{0}   and    p  1     subscript  p  1    p_{1}   with parameters     n  1   ,   V  1       subscript  n  1    subscript  V  1     n_{1},V_{1}   is      H   (   p  0   ,   p  1   )       H    subscript  p  0    subscript  p  1      \displaystyle H(p_{0},p_{1})     Note that when     p  0   =   p  1        subscript  p  0    subscript  p  1     p_{0}=p_{1}   we recover the entropy.  KL-Divergence  The Kullback–Leibler divergence of    p  1     subscript  p  1    p_{1}   from    p  0     subscript  p  0    p_{0}   is       D   K  L     (   p  0   ∥   p  1   )   =  H   (   p  0   ,   p  1   )   -  H   (   p  0   )   =  -     n  1   2    log  |   𝐕  1   -  1     𝐕  0   |  +     n  0   2     (  tr   (   𝐕  1   -  1     𝐕  0   )   -  p  )   +  log     Γ  p    (    n  1   2   )      Γ  p    (    n  0   2   )     +      n  0   -   n  1    2     ψ  p    (     n  0   2    )      fragments   subscript  D    K  L     fragments  normal-(   subscript  p  0   parallel-to   subscript  p  1   normal-)    H   fragments  normal-(   subscript  p  0   normal-,   subscript  p  1   normal-)    H   fragments  normal-(   subscript  p  0   normal-)        subscript  n  1   2    normal-|   superscript   subscript  𝐕  1     1     subscript  𝐕  0   normal-|      subscript  n  0   2    fragments  normal-(  tr   fragments  normal-(   superscript   subscript  𝐕  1     1     subscript  𝐕  0   normal-)    p  normal-)          subscript  normal-Γ  p      subscript  n  1   2       subscript  normal-Γ  p      subscript  n  0   2           subscript  n  0    subscript  n  1    2    subscript  ψ  p    fragments  normal-(     subscript  n  0   2   normal-)     D_{KL}(p_{0}\|p_{1})=H(p_{0},p_{1})-H(p_{0})=-\tfrac{n_{1}}{2}\log|\mathbf{V}_%
 {1}^{-1}\mathbf{V}_{0}|+\tfrac{n_{0}}{2}(\mathrm{tr}(\mathbf{V}_{1}^{-1}%
 \mathbf{V}_{0})-p)+\log\frac{\Gamma_{p}(\tfrac{n_{1}}{2})}{\Gamma_{p}(\tfrac{n%
 _{0}}{2})}+\tfrac{n_{0}-n_{1}}{2}\psi_{p}(\tfrac{n_{0}}{2})     Characteristic function  The characteristic function of the Wishart distribution is       Θ  ↦    |   𝐈  -   2   i   𝚯  𝐕    |    -   n  2      .     maps-to  normal-Θ   superscript      𝐈    2  i  𝚯  𝐕         n  2       \Theta\mapsto\left|{\mathbf{I}}-2i\,{\mathbf{\Theta}}{\mathbf{V}}\right|^{-%
 \frac{n}{2}}.     In other words,      Θ  ↦   E   [   exp   (   i  tr   (   𝐗  𝚯   )    )    ]    =    |   𝐈  -   2  i  𝚯  𝐕    |    -   n  2          maps-to  normal-Θ   normal-E    exp    i  tr    𝐗  𝚯            superscript      𝐈    2  i  𝚯  𝐕         n  2        \Theta\mapsto\operatorname{E}\left[\mathrm{exp}\left(i\mathrm{tr}(\mathbf{X}{%
 \mathbf{\Theta}})\right)\right]=\left|{\mathbf{I}}-2i{\mathbf{\Theta}}{\mathbf%
 {V}}\right|^{-\frac{n}{2}}     where    E  ⋅  ⋅      E  normal-⋅  normal-⋅    E⋅⋅   denotes expectation. (Here   Θ   normal-Θ   Θ   and   𝐈   𝐈   \mathbf{I}   are matrices the same size as   𝐕   𝐕   \mathbf{V}   (   𝐈   𝐈   \mathbf{I}   is the identity matrix ); and   i   i   i   is the square root of −1). 7  Theorem  If a    p  ×  p      p  normal-×  p    p×p   random matrix   𝐗   𝐗   \mathbf{X}   has a Wishart distribution with   m   m   m   degrees of freedom and variance matrix   𝐕   𝐕   \mathbf{V}   — write    𝐗  ∼    𝒲  p    (  𝐕  ,  m  )       similar-to  𝐗     subscript  𝒲  p    𝐕  m      \mathbf{X}\sim\mathcal{W}_{p}({\mathbf{V}},m)   — and   𝐂   𝐂   \mathbf{C}   is a    q  ×  p      q  normal-×  p    q×p   matrix of rank    q   q   q   , then 8        𝐂𝐗𝐂  T   ∼    𝒲  q    (   𝐂𝐕𝐂  T   ,  m  )     .     similar-to   superscript  𝐂𝐗𝐂  T      subscript  𝒲  q     superscript  𝐂𝐕𝐂  T   m      \mathbf{C}\mathbf{X}{\mathbf{C}}^{T}\sim\mathcal{W}_{q}\left({\mathbf{C}}{%
 \mathbf{V}}{\mathbf{C}}^{T},m\right).     Corollary 1  If   𝐳   𝐳   \mathbf{z}   is a nonzero    p  ×  1      p  normal-×  1    p×1   constant vector, then: 9         𝐳  T   𝐗𝐳   ∼    σ  z  2    χ  m  2     .     similar-to     superscript  𝐳  T   𝐗𝐳      superscript   subscript  σ  z   2    superscript   subscript  χ  m   2      {\mathbf{z}}^{T}\mathbf{X}{\mathbf{z}}\sim\sigma_{z}^{2}\chi_{m}^{2}.     In this case,    χ  m  2     superscript   subscript  χ  m   2    \chi_{m}^{2}   is the chi-squared distribution and     σ  z  2   =    𝐳  T   𝐕𝐳        superscript   subscript  σ  z   2      superscript  𝐳  T   𝐕𝐳     \sigma_{z}^{2}={\mathbf{z}}^{T}{\mathbf{V}}{\mathbf{z}}   (note that    σ  z  2     superscript   subscript  σ  z   2    \sigma_{z}^{2}   is a constant; it is positive because   𝐕   𝐕   \mathbf{V}   is positive definite).  Corollary 2  Consider the case where (0, ..., 0, 1, 0, ..., 0)}} (that is, the   j   j   j   -th element is one and all others zero). Then corollary 1 above shows that       w   j  j    ∼    σ   j  j     χ  m  2       similar-to   subscript  w    j  j       subscript  σ    j  j     subscript   superscript  χ  2   m      w_{jj}\sim\sigma_{jj}\chi^{2}_{m}     gives the marginal distribution of each of the elements on the matrix's diagonal.  Noted statistician George Seber points out that the Wishart distribution is not called the “multivariate chi-squared distribution” because the marginal distribution of the off-diagonal elements is not chi-squared. Seber prefers to reserve the term multivariate for the case when all univariate marginals belong to the same family. 10  Estimator of the multivariate normal distribution  The Wishart distribution is the sampling distribution of the maximum-likelihood estimator (MLE) of the covariance matrix of a multivariate normal distribution . 11 A derivation of the MLE uses the spectral theorem .  Bartlett decomposition  The Bartlett decomposition of a matrix   𝐗   𝐗   \mathbf{X}   from a   p   p   p   -variate Wishart distribution with scale matrix   𝐕   𝐕   \mathbf{V}   and   n   n   n   degrees of freedom is the factorization:       𝐗  =     𝐋   𝐀   𝐀   T    𝐋  T     ,      𝐗     superscript  L
                       A
                       A  T    superscript  L  T      \mathbf{X}={\textbf{L}}{\textbf{A}}{\textbf{A}}^{T}{\textbf{L}}^{T},     where   𝐋   𝐋   \mathbf{L}   is the Cholesky factor of   𝐕   𝐕   \mathbf{V}   , and:      𝐀  =   (      c  1     0    0    ⋯    0       n  21      c  2     0    ⋯    0       n  31      n  32      c  3     ⋯    0      ⋮    ⋮    ⋮    ⋱    ⋮       n   p  1       n   p  2       n   p  3      ⋯     c  p      )       𝐀     subscript  c  1   0  0  normal-⋯  0     subscript  n  21    subscript  c  2   0  normal-⋯  0     subscript  n  31    subscript  n  32    subscript  c  3   normal-⋯  0    normal-⋮  normal-⋮  normal-⋮  normal-⋱  normal-⋮     subscript  n    p  1     subscript  n    p  2     subscript  n    p  3    normal-⋯   subscript  c  p       \mathbf{A}=\begin{pmatrix}c_{1}&0&0&\cdots&0\\
 n_{21}&c_{2}&0&\cdots&0\\
 n_{31}&n_{32}&c_{3}&\cdots&0\\
 \vdots&\vdots&\vdots&\ddots&\vdots\\
 n_{p1}&n_{p2}&n_{p3}&\cdots&c_{p}\end{pmatrix}     where     c  i  2   ∼   χ    n  -  i   +  1   2      similar-to   superscript   subscript  c  i   2    subscript   superscript  χ  2       n  i   1      c_{i}^{2}\sim\chi^{2}_{n-i+1}   and independently. 12 This provides a useful method for obtaining random samples from a Wishart distribution. 13  Marginal distribution of matrix elements  Let   𝐕   𝐕   \mathbf{V}   be a    2  ×  2      2  normal-×  2    2×2   variance matrix characterized by correlation coefficient    𝐋   𝐋   \mathbf{L}         2  ×  2      2  normal-×  2    2×2     Multiplying through the Bartlett decomposition above, we find that a random sample from the    𝐗  =   (       σ  1  2    c  1  2        σ  1    σ  2    (    ρ   c  1  2    +     1  -   ρ  2      c  1    n  21     )          σ  1    σ  2    (    ρ   c  1  2    +     1  -   ρ  2      c  1    n  21     )        σ  2  2    (     (   1  -   ρ  2    )    c  2  2    +    (      1  -   ρ  2      n  21    +   ρ   c  1     )   2    )       )       𝐗       superscript   subscript  σ  1   2    superscript   subscript  c  1   2       subscript  σ  1    subscript  σ  2       ρ   superscript   subscript  c  1   2          1   superscript  ρ  2      subscript  c  1    subscript  n  21           subscript  σ  1    subscript  σ  2       ρ   superscript   subscript  c  1   2          1   superscript  ρ  2      subscript  c  1    subscript  n  21         superscript   subscript  σ  2   2         1   superscript  ρ  2     superscript   subscript  c  2   2     superscript          1   superscript  ρ  2      subscript  n  21      ρ   subscript  c  1     2         \mathbf{X}=\begin{pmatrix}\sigma_{1}^{2}c_{1}^{2}&\sigma_{1}\sigma_{2}\left(%
 \rho c_{1}^{2}+\sqrt{1-\rho^{2}}c_{1}n_{21}\right)\\
 \sigma_{1}\sigma_{2}\left(\rho c_{1}^{2}+\sqrt{1-\rho^{2}}c_{1}n_{21}\right)&%
 \sigma_{2}^{2}\left(\left(1-\rho^{2}\right)c_{2}^{2}+\left(\sqrt{1-\rho^{2}}n_%
 {21}+\rho c_{1}\right)^{2}\right)\end{pmatrix}   Wishart distribution is     n   n   n     The diagonal elements, most evidently in the first element, follow the distribution with     f   (   x  12   )    =       |   x  12   |     n  -  1   2     Γ   (   n  2   )      2   n  -  1    π   (   1  -   ρ  2    )     (    σ  1    σ  2    )    n  +  1        ⋅   K    n  -  1   2      (    |   x  12   |     σ  1    σ  2    (   1  -   ρ  2    )     )    exp   (    ρ   x  12      σ  1    σ  2    (   1  -   ρ  2    )     )           f   subscript  x  12       normal-⋅     superscript     subscript  x  12        n  1   2      normal-Γ    n  2        superscript  2    n  1    π    1   superscript  ρ  2     superscript     subscript  σ  1    subscript  σ  2      n  1         subscript  K      n  1   2          subscript  x  12       subscript  σ  1    subscript  σ  2     1   superscript  ρ  2            ρ   subscript  x  12       subscript  σ  1    subscript  σ  2     1   superscript  ρ  2          f(x_{12})=\frac{\left|x_{12}\right|^{\frac{n-1}{2}}}{\Gamma\left(\frac{n}{2}%
 \right)\sqrt{2^{n-1}\pi\left(1-\rho^{2}\right)\left(\sigma_{1}\sigma_{2}\right%
 )^{n+1}}}\cdot K_{\frac{n-1}{2}}\left(\frac{\left|x_{12}\right|}{\sigma_{1}%
 \sigma_{2}\left(1-\rho^{2}\right)}\right)\exp{\left(\frac{\rho x_{12}}{\sigma_%
 {1}\sigma_{2}(1-\rho^{2})}\right)}   degrees of freedom (scaled by ) as expected. The off-diagonal element is less familiar but can be identified as a normal variance-mean mixture where the mixing density is a distribution. The corresponding marginal probability density for the off-diagonal element is therefore the variance-gamma distribution     𝐧   𝐧   \mathbf{n}     where is the modified Bessel function of the second kind . 14 Similar results may be found for higher dimensions, but the interdependence of the off-diagonal correlations becomes increasingly complicated. It is also possible to write down the moment-generating function even in the noncentral case (essentially the n th power of Craig (1936) 15 equation 10) although the probability density becomes an infinite sum of Bessel functions.  The possible range of the shape parameter  It can be shown 16 that the Wishart distribution can be defined if and only if the shape parameter      Λ  p   :=    {  0  ,  ⋯  ,   p  -  1   }   ∪   (   p  -  1   ,  ∞  )     .     assign   subscript  normal-Λ  p      0  normal-⋯    p  1       p  1        \Lambda_{p}:=\{0,\cdots,p-1\}\cup\left(p-1,\infty\right).   belongs to the set        Λ  p  *   :=   {  0  ,  ⋯  ,   p  -  1   }    ,     assign   superscript   subscript  normal-Λ  p      0  normal-⋯    p  1      \Lambda_{p}^{*}:=\{0,\cdots,p-1\},     This set is named after Gindikin, who introduced it 17 in the seventies in the context of gamma distributions on homogeneous cones. However, for the new parameters in the discrete spectrum of the Gindikin ensemble, namely,      W  p   -  1      superscript   subscript  W  p     1     W_{p}^{-1}     the corresponding Wishart distribution has no Lebesgue density.  Relationships to other distributions   The Wishart distribution is related to the Inverse-Wishart distribution , denoted by    𝐂  ∼    W  p   -  1     (   𝐕   -  1    ,  n  )       similar-to  𝐂     superscript   subscript  W  p     1      superscript  𝐕    1    n      \mathbf{C}\sim W_{p}^{-1}(\mathbf{V}^{-1},n)   , as follows: If and if we do the change of variables  X −1 }} , then $\mathbf{C}\sim W_p^{-1}(\mathbf{V}^{-1},n)$ . This relationship may be derived by noting that the absolute value of the Jacobian determinant of this change of variables is C {{!}} p +1 }} , see for example equation (15.15) in. 18  In Bayesian statistics , the Wishart distribution is a conjugate prior for the precision parameter of the multivariate normal distribution , when the mean parameter is known. 19  A generalization is the multivariate gamma distribution .  A different type of generalization is the normal-Wishart distribution , essentially the product of a multivariate normal distribution with a Wishart distribution.   See also   Chi-squared distribution  F-distribution  Gamma distribution  Hotelling's T-squared distribution  Inverse-Wishart distribution  Multivariate gamma distribution  Student's t-distribution  Wilks' lambda distribution   References  External links   A C++ library for random matrix generator   "  Category:Continuous distributions  Category:Multivariate continuous distributions  Category:Multivariate statistics  Category:Random matrices  Category:Conjugate prior distributions  Category:Exponential family distributions  Category:Probability distributions     ↩  ↩  ↩  ↩  C.M. Bishop, Pattern Recognition and Machine Learning , Springer 2006, p. 693. ↩   ↩  ↩   ↩  ↩  ↩  ↩  ↩  ↩  ↩  ↩  ↩  ↩     