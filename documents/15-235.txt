   Common spatial pattern      Common spatial pattern   Common spatial pattern ( CSP ) is a mathematical procedure used in signal processing for separating a multivariate signal into additive subcomponents which have maximum differences in variance between two windows . 1  Details  Let    𝐗  1     subscript  𝐗  1    \mathbf{X}_{1}   of size    (  n  ,   t  1   )     n   subscript  t  1     (n,t_{1})   and    𝐗  2     subscript  𝐗  2    \mathbf{X}_{2}   of size    (  n  ,   t  2   )     n   subscript  t  2     (n,t_{2})   be two windows of a multivariate signal , where   n   n   n   is the number of signals and    t  1     subscript  t  1    t_{1}   and    t  2     subscript  t  2    t_{2}   are the respective number of samples.  The CSP algorithm determines the component    𝐰  T     superscript  𝐰  T    \mathbf{w}^{\text{T}}   such that the ratio of variance (or second-order moment ) is maximized between the two windows:      𝐰  =   arg    max  𝐰      ∥   𝐰𝐗  1   ∥   2     ∥   𝐰𝐗  2   ∥   2          𝐰      subscript   𝐰      superscript   norm   subscript  𝐰𝐗  1    2    superscript   norm   subscript  𝐰𝐗  2    2        \mathbf{w}={\arg\max}_{\mathbf{w}}\frac{\left\|\mathbf{wX}_{1}\right\|^{2}}{%
 \left\|\mathbf{wX}_{2}\right\|^{2}}     The solution is given by computing the two covariance matrices :       𝐑  1   =     𝐗  1    𝐗  1  T     t  1         subscript  𝐑  1        subscript  𝐗  1    superscript   subscript  𝐗  1   T     subscript  t  1      \mathbf{R}_{1}=\frac{\mathbf{X}_{1}\mathbf{X}_{1}^{\text{T}}}{t_{1}}          𝐑  2   =     𝐗  2    𝐗  2  T     t  2         subscript  𝐑  2        subscript  𝐗  2    superscript   subscript  𝐗  2   T     subscript  t  2      \mathbf{R}_{2}=\frac{\mathbf{X}_{2}\mathbf{X}_{2}^{\text{T}}}{t_{2}}     Then, the simultaneous diagonalization of those two matrices (also called generalized eigenvalue decomposition ) is realized. We find the matrix of eigenvectors     𝐏  =   [      𝐩  1     ⋯     𝐩  n      ]       𝐏     subscript  𝐩  1   normal-⋯   subscript  𝐩  n       \mathbf{P}=\begin{bmatrix}\mathbf{p}_{1}&\cdots&\mathbf{p}_{n}\end{bmatrix}   and the diagonal matrix    𝐃   𝐃   \mathbf{D}   of eigenvalues     {   λ  1   ,  ⋯  ,   λ  n   }      subscript  λ  1   normal-⋯   subscript  λ  n     \{\lambda_{1},\cdots,\lambda_{n}\}   sorted by decreasing order such that:        𝐏   -  1     𝐑  1   𝐏   =  𝐃         superscript  𝐏    1     subscript  𝐑  1   𝐏   𝐃    \mathbf{P}^{-1}\mathbf{R}_{1}\mathbf{P}=\mathbf{D}     and        𝐏   -  1     𝐑  2   𝐏   =   𝐈  n          superscript  𝐏    1     subscript  𝐑  2   𝐏    subscript  𝐈  n     \mathbf{P}^{-1}\mathbf{R}_{2}\mathbf{P}=\mathbf{I}_{n}     with    𝐈  n     subscript  𝐈  n    \mathbf{I}_{n}   the identity matrix .  This is equivalent to the eigendecomposition of     𝐑  2   -  1     𝐑  1        superscript   subscript  𝐑  2     1     subscript  𝐑  1     \mathbf{R}_{2}^{-1}\mathbf{R}_{1}   :        𝐑  2   -  1     𝐑  1    =   𝐏𝐃𝐏   -  1           superscript   subscript  𝐑  2     1     subscript  𝐑  1     superscript  𝐏𝐃𝐏    1      \mathbf{R}_{2}^{-1}\mathbf{R}_{1}=\mathbf{PDP}^{-1}         𝐰  T     superscript  𝐰  T    \mathbf{w}^{\text{T}}   will correspond to the first column of   𝐏   𝐏   \mathbf{P}   :      𝐰  =   𝐩  1  T       𝐰   superscript   subscript  𝐩  1   T     \mathbf{w}=\mathbf{p}_{1}^{\text{T}}     Discussion  Relation between variance ratio and eigenvalue  The eigenvectors composing   𝐏   𝐏   \mathbf{P}   are components with variance ratio between the two windows equal to their corresponding eigenvalue:       λ  i   =     ∥    𝐩  i  T    𝐗  1    ∥   2     ∥    𝐩  i  T    𝐗  2    ∥   2         subscript  λ  i      superscript   norm     superscript   subscript  𝐩  i   T    subscript  𝐗  1     2    superscript   norm     superscript   subscript  𝐩  i   T    subscript  𝐗  2     2      \mathbf{\lambda}_{i}=\frac{\left\|\mathbf{p}_{i}^{\text{T}}\mathbf{X}_{1}%
 \right\|^{2}}{\left\|\mathbf{p}_{i}^{\text{T}}\mathbf{X}_{2}\right\|^{2}}     Other components  The vectorial subspace     E  i     subscript  E  i    E_{i}   generated by the   i   i   i   first eigenvectors    [      𝐩  1     ⋯     𝐩  i      ]       subscript  𝐩  1   normal-⋯   subscript  𝐩  i      \begin{bmatrix}\mathbf{p}_{1}&\cdots&\mathbf{p}_{i}\end{bmatrix}   will be the subspace maximizing the variance ratio of all components belonging to it:       E  i   =   arg    max  E    (       min   p  ∈  E        ∥    𝐩  T    𝐗  1    ∥   2     ∥    𝐩  T    𝐗  2    ∥   2         )          subscript  E  i       subscript   E       subscript     p  E       superscript   norm     superscript  𝐩  T    subscript  𝐗  1     2    superscript   norm     superscript  𝐩  T    subscript  𝐗  2     2           E_{i}={\arg\max}_{E}\begin{pmatrix}\min_{p\in E}\frac{\left\|\mathbf{p^{\text{%
 T}}X}_{1}\right\|^{2}}{\left\|\mathbf{p^{\text{T}}X}_{2}\right\|^{2}}\end{pmatrix}     On the same way, the vectorial subpsace    F  j     subscript  F  j    F_{j}   generated by the   j   j   j   last eigenvectors    [      𝐩    n  -  j   +  1      ⋯     𝐩  n      ]       subscript  𝐩      n  j   1    normal-⋯   subscript  𝐩  n      \begin{bmatrix}\mathbf{p}_{n-j+1}&\cdots&\mathbf{p}_{n}\end{bmatrix}   will be the subspace minimizing the variance ratio of all components belonging to it:       F  j   =   arg    min  F    (       max   p  ∈  F        ∥    𝐩  T    𝐗  1    ∥   2     ∥    𝐩  T    𝐗  2    ∥   2         )          subscript  F  j       subscript   F       subscript     p  F       superscript   norm     superscript  𝐩  T    subscript  𝐗  1     2    superscript   norm     superscript  𝐩  T    subscript  𝐗  2     2           F_{j}={\arg\min}_{F}\begin{pmatrix}\max_{p\in F}\frac{\left\|\mathbf{p^{\text{%
 T}}X}_{1}\right\|^{2}}{\left\|\mathbf{p^{\text{T}}X}_{2}\right\|^{2}}\end{pmatrix}     Variance or second-order moment  CSP can be applied after a mean subtraction (a.k.a. "mean centering") on signals in order to realize a variance ratio optimization. Otherwize CSP optimizes the ratio of second-order moment.  Choice of windows X 1 and X 2   The standard use consists on choosing the windows to correspond to two periods of time with different activation of sources (e.g. during rest and during a specific task).    It is also possible to choose the two windows to correspond to two different frequency bands in order to find components with specific frequency pattern. 2 Those frequency bands can be on temporal or on frequential basis. Since the matrix   𝐏   𝐏   \mathbf{P}   depends only of the covariance matrices, the same results can be obtained if the processing is applied on the Fourier transform of the signals.    Y. Wang 3 has proposed a particular choice for the first window    𝐗  1     subscript  𝐗  1    \mathbf{X}_{1}   in order to extract components which have a specific period.    𝐗  1     subscript  𝐗  1    \mathbf{X}_{1}   was the mean of the different periods for the examined signals.    If there is only one window,    𝐑  2     subscript  𝐑  2    \mathbf{R}_{2}   can be considered as the identity matrix and then CSP corresponds to Principal component analysis .   Applications  This method can be applied to several multivariate signal but it seems that most works on it concern electroencephalographic signals.  Particularly, the method is mostly used on brain–computer interface in order to retrieve the component signal which best transduce the cerebral activity for a specific task (e.g. hand movement). 4  It can also be used to separate artifacts from electroencephalographics signals. 5  See also   Blind signal separation   References  "  Category:Signal processing     Zoltan J. Koles, Michael S. Lazaret and Steven Z. Zhou, "Spatial patterns underlying population differences in the background EEG" , Brain topography, Vol. 2 (4) pp. 275-284, 1990 ↩  S. Boudet, "Filtrage d'artefacts par analyse multicomposantes de l'électroencephalogramme de patients épileptiques." , PhD. Thesis: Unviversité de Lille 1, 07/2008 ↩  Y. Wang, "Reduction of cardiac artifacts in magnetoencephalogram." Proc. of the 12th Int. Conf. on Biomagnetism, 2000 ↩  G. Pfurtscheller, C. Gugeret and H. Ramoser "EEG-based brain-computer interface using subject-specific spatial filters" , Engineering applications of bio-inspired artificial neural networks, Lecture Notes in Computer Science, 1999, Vol. 1607/1999, pp. 248-254 ↩      