<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="1079">Bernoulli stochastics</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>Bernoulli stochastics</h1>
<hr/>

<p><strong>Bernoulli stochastics</strong> is a new branch of science and deals with human uncertainty of future developments.<a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a> It aims at developing quantitative models of the transition from past to future for making reliable and accurate predictions. Bernoulli stochastics should not be confused with <a class="uri" href="stochastics" title="wikilink">stochastics</a> which is a special branch of mathematics covering <a href="probability_theory" title="wikilink">probability theory</a>, the theory of <a href="stochastic_processes" title="wikilink">stochastic processes</a> and <a href="mathematical_statistics" title="wikilink">mathematical statistics</a>.</p>

<p>Bernoulli stochastics is based on Jakob Bernoulli's <a href="quantification_of_randomness" title="wikilink">quantification of randomness</a> and it was mainly developed by Elart von Collani<a class="footnoteRef" href="#fn2" id="fnref2"><sup>2</sup></a><a class="footnoteRef" href="#fn3" id="fnref3"><sup>3</sup></a> during the last two decades. Since uncertainty of the future constitutes one of the main problems of mankind, Bernoulli stochastics adopts an exceptional position as it provides the means to define and measure uncertainty and thus enables to handle risks adequately for preventing catastrophic developments.</p>
<h2 id="scope">Scope</h2>

<p>Uncertainty of the future constitutes not only the main problem for individuals but also for societies and science. Therefore, Bernoulli stochastics which develops models of uncertainty can be considered as a universal approach for solving problems since it provides the rules how to deal with uncertainty and the indeterminate future.</p>

<p>The quantitative models of uncertainty developed according to the rules of Bernoulli stochastics include the two sources of human uncertainty of future development. These are human <a class="uri" href="ignorance" title="wikilink">ignorance</a> about the past or the initial conditions and <a class="uri" href="randomness" title="wikilink">randomness</a> which affects the future. Ignorance represents the internal source of human uncertainty, while randomness is the external source. Ignorance is characteristic for man, while randomness is characteristic for universe.</p>

<p>There are two types of methods in Bernoulli stochastics. The first type of method enables a glance into the future, while the second type enables to look into the past. The first type is called <a href="stochastic_prediction_procedure" title="wikilink">stochastic prediction procedure</a>, the second type <a href="stochastic_measurement_procedure" title="wikilink">stochastic measurement procedure</a>. These stochastic procedures which are based on a model that objectively reflects reality aim at replacing belief and opinion which are still the prevailing means to overcome the problems generated by uncertainty and risks.</p>

<p>For understanding and applying Bernoulli stochastics the prevailing <a href="causal_thinking" title="wikilink">causal thinking</a> must be abandoned in favor of <a href="stochastic_thinking" title="wikilink">stochastic thinking</a>.<a class="footnoteRef" href="#fn4" id="fnref4"><sup>4</sup></a> Actually, adopting stochastic thinking constitutes a major difficulty in understanding and applying Bernoulli stochastics.</p>
<h2 id="history">History</h2>

<p>The development of Bernoulli stochastics started more than 300 years ago with the theologian and mathematician <a href="Jakob_Bernoulli" title="wikilink">Jakob Bernoulli</a> (1655‚Äì1705)<a class="footnoteRef" href="#fn5" id="fnref5"><sup>5</sup></a> from Basel in Switzerland. Jakob Bernoulli succeeded to quantify randomness of future events.<a class="footnoteRef" href="#fn6" id="fnref6"><sup>6</sup></a> Due to randomness a future event may or may not occur. Randomness can be observed by repeating the same experiment several times. Then some events will occur often and others more seldom. Bernoulli explained randomness of a future event by "the degree of certainty of the occurrence of the event" and called this degree "probability of the event". He planned to develop a science based on the concept of <a class="uri" href="probability" title="wikilink">probability</a> and named this science in Latin "Ars conjectandi" or in Greek "stochastike", i.e. "science of prediction.". Unfortunately, he died too early and his masterpiece <a href="Ars_conjectandi" title="wikilink">Ars conjectandi</a> was only published posthumously in 1713.<a class="footnoteRef" href="#fn7" id="fnref7"><sup>7</sup></a> His proposal was not taken up by science and instead "<a href="probability_theory" title="wikilink">probability theory</a>" as a branch of mathematics, and "<a class="uri" href="statistics" title="wikilink">statistics</a>" as a branch of empirical science were developed.<a class="footnoteRef" href="#fn8" id="fnref8"><sup>8</sup></a></p>

<p>Bernoulli stochastics was introduced in 2000 during the BS Symposium<a class="footnoteRef" href="#fn9" id="fnref9"><sup>9</sup></a> on "Defining the Science Stochastics, in Memoriam Jakob Bernoulli". The revised and updated versions of the lectures delivered at the symposium were published in 2004. Since then Bernoulli stochastics has been further developed and its methods have been successfully applied in various areas of science and technology, for example in metrology,<a class="footnoteRef" href="#fn10" id="fnref10"><sup>10</sup></a> quality control,<a class="footnoteRef" href="#fn11" id="fnref11"><sup>11</sup></a> wind energy<a class="footnoteRef" href="#fn12" id="fnref12"><sup>12</sup></a> and nuclear technology.<a class="footnoteRef" href="#fn13" id="fnref13"><sup>13</sup></a><a class="footnoteRef" href="#fn14" id="fnref14"><sup>14</sup></a></p>

<p>In 2002 the company Stochastikon GmbH was founded and started to further develop Bernoulli stochastics. In 2008 the first PhD-thesis <a class="footnoteRef" href="#fn15" id="fnref15"><sup>15</sup></a> by Andreas Binder was published dealing with Bernoulli stochastics and two subsystems of a web-based information and application system for its establishment. In April 2011, the second PhD-thesis <a class="footnoteRef" href="#fn16" id="fnref16"><sup>16</sup></a> on Bernoulli stochastics by Xiaomin Zhai was completed about design, development and evaluation of a virtual classroom and teaching contents for Bernoulli stochastics.</p>
<h2 id="overview">Overview</h2>

<p>The models in Bernoulli stochastics describe the change from the past to the future including the entire uncertainty as good as the available information permit. When developing a model of uncertainty, then one should have always in mind that not the mechanism of the considered process is of major interest, but the future events as expressed by Dennis Lindley.</p>
<ol>
<li>The first step consists of identifying the aspect of the future development which is of interest. Since the future development is subject to randomness it is quantified by a variable <em>X</em> which is called random variable. The future value of a random variable is indeterminate and generally varies when an experiment is repeated.</li>
<li>In a second step the relevant aspects of the past must be identified and represented by a variable <em>D</em>. Since the past is determinate, the variable <em>D</em> is called deterministic variable.</li>
</ol>

<p>The model refers to the stochastic relation between the deterministic variable <em>D</em> and the random variable <em>X</em> and in order to describe the uncertainty of the future development realistically it must necessarily cover the two sources of uncertainty, i.e., ignorance about the past and randomness of the future.</p>
<h2 id="stochastic-model">Stochastic model</h2>

<p>The stochastic model of uncertainty specifies what is known about the past, i.e., what is known about the value of the deterministic variable <em>D</em>, and what can occur in the future with respect to the random variable <em>X</em>. A stochastic model describes quantitatively the relation between past and future by considering the entire uncertainty generated by ignorance and randomness. The model is called <a href="Bernoulli_space" title="wikilink">Bernoulli space</a> and is denoted by 

<math display="inline" id="Bernoulli_stochastics:0">
 <semantics>
  <msub>
   <mi class="ltx_font_mathcaligraphic">‚Ñ¨</mi>
   <mrow>
    <mi>X</mi>
    <mo>,</mo>
    <mi>D</mi>
   </mrow>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>‚Ñ¨</ci>
    <list>
     <ci>X</ci>
     <ci>D</ci>
    </list>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \mathcal{B}_{X,D}
  </annotation>
 </semantics>
</math>

. It consists of three components.</p>
<ul>
<li>The <a href="ignorance_space" title="wikilink">ignorance space</a> denoted 

<math display="inline" id="Bernoulli_stochastics:1">
 <semantics>
  <mi class="ltx_font_mathcaligraphic">ùíü</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>ùíü</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \mathcal{D}
  </annotation>
 </semantics>
</math>

 is a bounded set that contains all those values of the deterministic variable <em>D</em> which according the available knowledge cannot be excluded. The ignorance space thus describes quantitatively the existing ignorance about the initial conditions. Each subset of the ignorance space represents a certain level of knowledge or equivalently of ignorance, where the singletons represent complete knowledge.</li>
<li>The <a href="variability_function" title="wikilink">variability function</a> denoted 

<math display="inline" id="Bernoulli_stochastics:2">
 <semantics>
  <mi class="ltx_font_mathcaligraphic">ùí≥</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>ùí≥</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \mathcal{X}
  </annotation>
 </semantics>
</math>

 assigns to each level of knowledge (= subset of the ignorance space) a corresponding <a href="range_of_variability" title="wikilink">range of variability</a> of the random variable <em>X</em>. In other words, each image of the variability function consists of those values of <em>X</em> which might occur in the future, under the condition that the true, but unknown value of <em>D</em> is an element of the considered subset of the ignorance space.</li>
<li>The <a href="random_structure_function" title="wikilink">random structure function</a> denoted 

<math display="inline" id="Bernoulli_stochastics:3">
 <semantics>
  <mi class="ltx_font_mathcaligraphic">ùí´</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>ùí´</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \mathcal{P}
  </annotation>
 </semantics>
</math>

 assigns to each level of knowledge (= subset of the ignorance space) a corresponding probability distribution over the corresponding image of the variability function.</li>
</ul>

<p>A Bernoulli Space 

<math display="inline" id="Bernoulli_stochastics:4">
 <semantics>
  <mrow>
   <msub>
    <mi class="ltx_font_mathcaligraphic">‚Ñ¨</mi>
    <mrow>
     <mi>X</mi>
     <mo>,</mo>
     <mi>D</mi>
    </mrow>
   </msub>
   <mo>=</mo>
   <mrow>
    <mo stretchy="false">(</mo>
    <mi class="ltx_font_mathcaligraphic">ùíü</mi>
    <mo>,</mo>
    <mi class="ltx_font_mathcaligraphic">ùí≥</mi>
    <mo>,</mo>
    <mi class="ltx_font_mathcaligraphic">ùí´</mi>
    <mo stretchy="false">)</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>‚Ñ¨</ci>
     <list>
      <ci>X</ci>
      <ci>D</ci>
     </list>
    </apply>
    <vector>
     <ci>ùíü</ci>
     <ci>ùí≥</ci>
     <ci>ùí´</ci>
    </vector>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \mathcal{B}_{X,D}=(\mathcal{D},\mathcal{X},\mathcal{P})
  </annotation>
 </semantics>
</math>

 refers to the pair of variables 

<math display="inline" id="Bernoulli_stochastics:5">
 <semantics>
  <mrow>
   <mo stretchy="false">(</mo>
   <mi>X</mi>
   <mo>,</mo>
   <mi>D</mi>
   <mo stretchy="false">)</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <interval closure="open">
    <ci>X</ci>
    <ci>D</ci>
   </interval>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   (X,D)
  </annotation>
 </semantics>
</math>

 where <em>X</em> represents the future and <em>D</em> the past. The ignorance space

<math display="inline" id="Bernoulli_stochastics:6">
 <semantics>
  <mi class="ltx_font_mathcaligraphic">ùíü</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>ùíü</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \mathcal{D}
  </annotation>
 </semantics>
</math>

 specifies the available knowledge about the past, the variability function 

<math display="inline" id="Bernoulli_stochastics:7">
 <semantics>
  <mi class="ltx_font_mathcaligraphic">ùí≥</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>ùí≥</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \mathcal{X}
  </annotation>
 </semantics>
</math>

 gives the amount of variability in the future as function of the available knowledge, and finally the random structure function 

<math display="inline" id="Bernoulli_stochastics:8">
 <semantics>
  <mi class="ltx_font_mathcaligraphic">ùí´</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>ùí´</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \mathcal{P}
  </annotation>
 </semantics>
</math>

 specifies the probabilities of future events again as a function of the available knowledge about the initial conditions.</p>
<h3 id="learning-theory">Learning theory</h3>

<p>Knowledge or equivalently ignorance refers to facts, i.e., the past, since the future does not exist so far and which of the many future developments will actually occur is subject to randomness and it is therefore in principle impossible to know it.</p>

<p>Learning means to increase knowledge or reduce ignorance about facts implying that modelling a learning process is possible only, if ignorance and randomness are explicitly incorporated into the model. In case of a Bernoulli Space, ignorance is modelled by the ignorance space 

<math display="inline" id="Bernoulli_stochastics:9">
 <semantics>
  <mi class="ltx_font_mathcaligraphic">ùíü</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>ùíü</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \mathcal{D}
  </annotation>
 </semantics>
</math>

 and randomness by the variability function 

<math display="inline" id="Bernoulli_stochastics:10">
 <semantics>
  <mi class="ltx_font_mathcaligraphic">ùí≥</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>ùí≥</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \mathcal{X}
  </annotation>
 </semantics>
</math>

 and the random structure function 

<math display="inline" id="Bernoulli_stochastics:11">
 <semantics>
  <mi class="ltx_font_mathcaligraphic">ùí´</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>ùí´</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \mathcal{P}
  </annotation>
 </semantics>
</math>

. It follows that the stochastic model given by the Bernoulli Space may be used as basis for developing a theory of learning.</p>
<h3 id="natural-laws">Natural laws</h3>

<p><a href="Physical_law" title="wikilink">Natural laws in physics</a> are quantitative models of the transition from the past to the future, and therefore competitors to the Bernoulli Space. Thus, it is of interest to compare the two approaches.</p>

<p>A natural law is a function which maps the initial conditions represented by the variable <em>D</em> on the future outcome of the variable <em>X</em>. For any natural law it is assumed that the initial conditions are known exactly, i.e., the ignorance space is assumed to be a singleton 

<math display="inline" id="Bernoulli_stochastics:12">
 <semantics>
  <mrow>
   <mi>ùîá</mi>
   <mo>=</mo>
   <mrow>
    <mo stretchy="false">{</mo>
    <mi>d</mi>
    <mo stretchy="false">}</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <ci>ùîá</ci>
    <set>
     <ci>d</ci>
    </set>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \mathfrak{D}=\{d\}
  </annotation>
 </semantics>
</math>

. Moreover most natural laws assume that the future is a mere transformation of the past, i.e., it is assumed that for given initial conditions <em>d</em> there is only exactly one possible future outcome implying that the range of variability of <em>X</em> is given by a singleton 

<math display="inline" id="Bernoulli_stochastics:13">
 <semantics>
  <mrow>
   <mo stretchy="false">{</mo>
   <mrow>
    <mi>x</mi>
    <mrow>
     <mo stretchy="false">(</mo>
     <mi>d</mi>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
   <mo stretchy="false">}</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <set>
    <apply>
     <times></times>
     <ci>x</ci>
     <ci>d</ci>
    </apply>
   </set>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \{x(d)\}
  </annotation>
 </semantics>
</math>

. The image of the random structure function is a probability distribution. In case of a natural law it degenerates to a one-point distribution. Thus, natural laws prove to be degenerate limiting cases of the Bernoulli Space.</p>

<p>None of the natural laws invented in physics incorporates the always existing human ignorance. Contrary, the natural laws assume complete knowledge and do therefore not admit improving by learning. Consequently, the approach that results in natural laws turns out to be one of the most serious obstacles for any learning process.</p>
<h2 id="procedures-of-bernoulli-stochastics">Procedures of Bernoulli stochastics</h2>

<p>There are two main types of procedures in Bernoulli stochastics referring to the two main types of problems mankind is confronted with. The first type consists of prediction procedures and the second type of measurement procedures. Prediction procedures allow to look into the future, while measurement procedures allow to look into the past. The future is characterized by indeterminate events, while the past is characterized by determinate facts.</p>
<h3 id="stochastic-prediction-procedure">Stochastic prediction procedure</h3>

<p>A stochastic prediction procedure aims at reducing the uncertainty about the future development of interest represented by the random variable <em>X</em>. A Bernoulli Space is developed in order to enable reliable and accurate prediction about the future development, i.e., about the indeterminate outcome of the random variable <em>X</em>. A stochastic prediction procedure is a function denoted 

<math display="inline" id="Bernoulli_stochastics:14">
 <semantics>
  <msub>
   <mi>A</mi>
   <mi>X</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>A</ci>
    <ci>X</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   A_{X}
  </annotation>
 </semantics>
</math>

 which assigns to each level of knowledge (= subset of the ignorance space) a prediction, i.e., a subset of the corresponding range of variability of $X$. The quality of a prediction is determined by its reliability and its accuracy. The reliability of a prediction is defined by the probability of its occurrence, and the accuracy of a prediction is defined by its size. A stochastic prediction procedure 

<math display="inline" id="Bernoulli_stochastics:15">
 <semantics>
  <msub>
   <mi>A</mi>
   <mi>X</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>A</ci>
    <ci>X</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   A_{X}
  </annotation>
 </semantics>
</math>

 is derived in a way that it meets the following two requirements:</p>
<ul>
<li>Reliability requirement: A stochastic prediction procedure yields predictions that will occur with a probability of at least 

<math display="inline" id="Bernoulli_stochastics:16">
 <semantics>
  <mi>Œ≤</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>Œ≤</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \beta
  </annotation>
 </semantics>
</math>

 where the lower bound 

<math display="inline" id="Bernoulli_stochastics:17">
 <semantics>
  <mi>Œ≤</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>Œ≤</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \beta
  </annotation>
 </semantics>
</math>

 is called <a href="reliability_level" title="wikilink">reliability level</a> of the prediction procedure.</li>
<li>Accuracy requirement: The size of the predictions obtained by a stochastic prediction procedure is minimum.</li>
</ul>

<p>The first condition guarantees a sufficient large reliability of the predictions, while the second condition ensures that the accuracy of the obtained predictions is optimal. A prediction procedure meeting the reliability requirement given by the reliability level 

<math display="inline" id="Bernoulli_stochastics:18">
 <semantics>
  <mi>Œ≤</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>Œ≤</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \beta
  </annotation>
 </semantics>
</math>

 is called 

<math display="inline" id="Bernoulli_stochastics:19">
 <semantics>
  <mi>Œ≤</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>Œ≤</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \beta
  </annotation>
 </semantics>
</math>

-prediction procedure denoted 

<math display="inline" id="Bernoulli_stochastics:20">
 <semantics>
  <msubsup>
   <mi>A</mi>
   <mi>X</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <mi>Œ≤</mi>
    <mo stretchy="false">)</mo>
   </mrow>
  </msubsup>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">superscript</csymbol>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>A</ci>
     <ci>X</ci>
    </apply>
    <ci>Œ≤</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   A_{X}^{(\beta)}
  </annotation>
 </semantics>
</math>

.</p>
<h3 id="stochastic-measurement-procedure">Stochastic measurement procedure</h3>

<p>A stochastic measurement procedure aims at reducing the ignorance about the true but unknown value of the deterministic variable <em>D</em>. Reducing ignorance is equivalent with learning and learning is possible only by a learning process, which is called here a measurement process. The measurement process has an indeterminate outcome which is represented by a random variable <em>X</em> and for deriving a suitable stochastic measurement procedure the uncertainty related to the measurement process must be described by a Bernoulli Space 

<math display="inline" id="Bernoulli_stochastics:21">
 <semantics>
  <msub>
   <mi class="ltx_font_mathcaligraphic">‚Ñ¨</mi>
   <mrow>
    <mi>X</mi>
    <mo>,</mo>
    <mi>D</mi>
   </mrow>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>‚Ñ¨</ci>
    <list>
     <ci>X</ci>
     <ci>D</ci>
    </list>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \mathcal{B}_{X,D}
  </annotation>
 </semantics>
</math>

. The Bernoulli Space allows to predict for any possible value of <em>D</em> which is an element of the ignorance space 

<math display="inline" id="Bernoulli_stochastics:22">
 <semantics>
  <mi class="ltx_font_mathcaligraphic">ùíü</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>ùíü</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \mathcal{D}
  </annotation>
 </semantics>
</math>

 and any reliability level 

<math display="inline" id="Bernoulli_stochastics:23">
 <semantics>
  <mi>Œ≤</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>Œ≤</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \beta
  </annotation>
 </semantics>
</math>

 a prediction 

<math display="inline" id="Bernoulli_stochastics:24">
 <semantics>
  <mrow>
   <msubsup>
    <mi>A</mi>
    <mi>X</mi>
    <mrow>
     <mo stretchy="false">(</mo>
     <mi>Œ≤</mi>
     <mo stretchy="false">)</mo>
    </mrow>
   </msubsup>
   <mrow>
    <mo stretchy="false">(</mo>
    <mrow>
     <mo stretchy="false">{</mo>
     <mi>d</mi>
     <mo stretchy="false">}</mo>
    </mrow>
    <mo stretchy="false">)</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <ci>A</ci>
      <ci>Œ≤</ci>
     </apply>
     <ci>X</ci>
    </apply>
    <set>
     <ci>d</ci>
    </set>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   A^{(\beta)}_{X}(\{d\})
  </annotation>
 </semantics>
</math>

.</p>

<p>A stochastic measurement procedure assigns to each outcome of the measurement process, i.e., a subset of the range of variability of <em>X</em>, a measurement result, i.e., a subset of the ignorance space. Thus, a measurement procedure is a function denoted by 

<math display="inline" id="Bernoulli_stochastics:25">
 <semantics>
  <msub>
   <mi>C</mi>
   <mi>D</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>C</ci>
    <ci>D</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   C_{D}
  </annotation>
 </semantics>
</math>

. A stochastic measurement procedure meets the following three requirements:</p>
<ul>
<li>Reliability requirement: The probability to obtain a correct result when applying a stochastic measurement procedure is not smaller than a prescribed reliability level 

<math display="inline" id="Bernoulli_stochastics:26">
 <semantics>
  <mi>Œ≤</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>Œ≤</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \beta
  </annotation>
 </semantics>
</math>

, where a result is called correct if it contains the true value of the deterministic variable. If a measurement procedure meets this condition it is called 

<math display="inline" id="Bernoulli_stochastics:27">
 <semantics>
  <mi>Œ≤</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>Œ≤</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \beta
  </annotation>
 </semantics>
</math>

-measurement procedure denoted 

<math display="inline" id="Bernoulli_stochastics:28">
 <semantics>
  <msubsup>
   <mi>C</mi>
   <mi>D</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <mi>Œ≤</mi>
    <mo stretchy="false">)</mo>
   </mrow>
  </msubsup>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <apply>
     <csymbol cd="ambiguous">superscript</csymbol>
     <ci>C</ci>
     <ci>Œ≤</ci>
    </apply>
    <ci>D</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   C^{(\beta)}_{D}
  </annotation>
 </semantics>
</math>

.</li>
</ul>
<ul>
<li>Completeness requirement: Each possible, i.e., observable result of the measurement process yields a meaningful measurement result, i.e., a nonempty subset of the ignorance space.</li>
</ul>
<ul>
<li>Accuracy requirement: The measurement results of a stochastic 

<math display="inline" id="Bernoulli_stochastics:29">
 <semantics>
  <mi>Œ≤</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>Œ≤</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \beta
  </annotation>
 </semantics>
</math>

-measurement procedure are on average most accurate, i.e., have on average minimum size.</li>
</ul>

<p>Any stochastic 

<math display="inline" id="Bernoulli_stochastics:30">
 <semantics>
  <mi>Œ≤</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>Œ≤</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \beta
  </annotation>
 </semantics>
</math>

-measurement procedure 

<math display="inline" id="Bernoulli_stochastics:31">
 <semantics>
  <msubsup>
   <mi>C</mi>
   <mi>D</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <mi>Œ≤</mi>
    <mo stretchy="false">)</mo>
   </mrow>
  </msubsup>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <apply>
     <csymbol cd="ambiguous">superscript</csymbol>
     <ci>C</ci>
     <ci>Œ≤</ci>
    </apply>
    <ci>D</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   C^{(\beta)}_{D}
  </annotation>
 </semantics>
</math>

 is based on a suitable stochastic 

<math display="inline" id="Bernoulli_stochastics:32">
 <semantics>
  <mi>Œ≤</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>Œ≤</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \beta
  </annotation>
 </semantics>
</math>

-prediction procedure 

<math display="inline" id="Bernoulli_stochastics:33">
 <semantics>
  <msubsup>
   <mi>A</mi>
   <mi>X</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <mi>Œ≤</mi>
    <mo stretchy="false">)</mo>
   </mrow>
  </msubsup>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">superscript</csymbol>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>A</ci>
     <ci>X</ci>
    </apply>
    <ci>Œ≤</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   A_{X}^{(\beta)}
  </annotation>
 </semantics>
</math>

 by the following relation:</p>
<dl>
<dd><dl>
<dd>

<math display="inline" id="Bernoulli_stochastics:34">
 <semantics>
  <mrow>
   <mrow>
    <msubsup>
     <mi>C</mi>
     <mi>D</mi>
     <mrow>
      <mo stretchy="false">(</mo>
      <mi>Œ≤</mi>
      <mo stretchy="false">)</mo>
     </mrow>
    </msubsup>
    <mrow>
     <mo stretchy="false">(</mo>
     <mrow>
      <mo stretchy="false">{</mo>
      <mi>x</mi>
      <mo stretchy="false">}</mo>
     </mrow>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
   <mo>=</mo>
   <mrow>
    <mo stretchy="false">{</mo>
    <mi>d</mi>
    <mo stretchy="false">|</mo>
    <mrow>
     <mi>x</mi>
     <mi>œµ</mi>
     <msubsup>
      <mi>A</mi>
      <mi>X</mi>
      <mrow>
       <mo stretchy="false">(</mo>
       <mi>Œ≤</mi>
       <mo stretchy="false">)</mo>
      </mrow>
     </msubsup>
     <mrow>
      <mo stretchy="false">(</mo>
      <mrow>
       <mo stretchy="false">{</mo>
       <mi>d</mi>
       <mo stretchy="false">}</mo>
      </mrow>
      <mo stretchy="false">)</mo>
     </mrow>
    </mrow>
    <mo stretchy="false">}</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <times></times>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <apply>
       <csymbol cd="ambiguous">superscript</csymbol>
       <ci>C</ci>
       <ci>Œ≤</ci>
      </apply>
      <ci>D</ci>
     </apply>
     <set>
      <ci>x</ci>
     </set>
    </apply>
    <apply>
     <csymbol cd="latexml">conditional-set</csymbol>
     <ci>d</ci>
     <apply>
      <times></times>
      <ci>x</ci>
      <ci>œµ</ci>
      <apply>
       <csymbol cd="ambiguous">superscript</csymbol>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <ci>A</ci>
        <ci>X</ci>
       </apply>
       <ci>Œ≤</ci>
      </apply>
      <set>
       <ci>d</ci>
      </set>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   C^{(\beta)}_{D}(\{x\})=\{d|x\epsilon A_{X}^{(\beta)}(\{d\})\}
  </annotation>
 </semantics>
</math>


</dd>
</dl>
</dd>
</dl>

<p>where 

<math display="inline" id="Bernoulli_stochastics:35">
 <semantics>
  <mrow>
   <mo stretchy="false">{</mo>
   <mi>x</mi>
   <mo stretchy="false">}</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <set>
    <ci>x</ci>
   </set>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \{x\}
  </annotation>
 </semantics>
</math>

 is the observed result of the measurement process. The above relation means that every value <em>d</em> of the deterministic variable <em>D</em> is considered in the measurement result 

<math display="inline" id="Bernoulli_stochastics:36">
 <semantics>
  <mrow>
   <msubsup>
    <mi>C</mi>
    <mi>D</mi>
    <mrow>
     <mo stretchy="false">(</mo>
     <mi>Œ≤</mi>
     <mo stretchy="false">)</mo>
    </mrow>
   </msubsup>
   <mrow>
    <mo stretchy="false">(</mo>
    <mrow>
     <mo stretchy="false">{</mo>
     <mi>x</mi>
     <mo stretchy="false">}</mo>
    </mrow>
    <mo stretchy="false">)</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <ci>C</ci>
      <ci>Œ≤</ci>
     </apply>
     <ci>D</ci>
    </apply>
    <set>
     <ci>x</ci>
    </set>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   C^{(\beta)}_{D}(\{x\})
  </annotation>
 </semantics>
</math>

 for which the observation 

<math display="inline" id="Bernoulli_stochastics:37">
 <semantics>
  <mrow>
   <mo stretchy="false">{</mo>
   <mi>x</mi>
   <mo stretchy="false">}</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <set>
    <ci>x</ci>
   </set>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \{x\}
  </annotation>
 </semantics>
</math>

 had been predicted.</p>

<p>The reliability requirement of the measurement procedures is met by the reliability level 

<math display="inline" id="Bernoulli_stochastics:38">
 <semantics>
  <mi>Œ≤</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>Œ≤</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \beta
  </annotation>
 </semantics>
</math>

 of the involved prediction procedure. The completeness and accuracy requirements are met by rather complicated mathematical optimization procedures. Because of these two requirements, the prediction procedures for measurement procedures are different from those obtained for prediction procedures.</p>
<h2 id="stochastic-thinking">Stochastic thinking</h2>

<p>Bernoulli stochastics explicitly admits randomness as a characteristic feature of real world. However, as shown in subsection "Natural Law", the stochastic model also covers deterministic relations, however, as degenerate limiting cases. The stochastic approach emanates from the almost obvious fact that everything in the universe is connected with everything. This universal connectivity excludes causal relations since any change is simultaneously cause and effect.</p>

<p>Furthermore, the universal connectivity is a property of the entire universe and not of any part of it. It follows that the whole cannot be understood by investigating parts of it and in particular not by investigating elementary particles, i.e., the smallest parts of the universe. Bernoulli stochastics therefore represents not only a stochastic, but also a holistic approach in contrast to physics which is based on determinism and reductionism.</p>

<p>As already mentioned applying Bernoulli stochastics requires to abandon causal thinking in favor of stochastic thinking. The difficulty is that almost everybody seems to understand causal thinking, but only very few can explain stochastic thinking. Therefore, the main differences are listed below.</p>
<ul>
<li>Causal thinking means to trace back the occurrence of a problem to a culprit, i.e., a part of the system. In contrast, according to stochastic thinking the design of the system yields a positive probability for the problem.</li>
</ul>
<ul>
<li>The solution of a problem based on causal thinking consists of eliminating the culprit but maintaining the system. In contrast, according to stochastic thinking the situation can only be improved by changing the design of the system to reduce the probability of the problem.</li>
</ul>
<ul>
<li>Causal thinking means to explain developments by cause and effect chains which refer to isolated parts of the system. Stochastic thinking does not explain certain partial developments, but looks at the entire system and its stochastic evolution rules.</li>
</ul>

<p>Similar as in subsection Learning Theory the above list illustrates that the stochastic approach represents a learning approach while the causal approach appears as an unsurmountable obstacle for learning.</p>
<h2 id="references">References</h2>
<h2 id="external-links">External links</h2>
<ul>
<li>Stochastikon Ecyclopedia, <a href="http://www.encyclopedia.stochastikon.com">5</a></li>
<li>E-Learning Programme Stochastikon Magister, <a href="http://www.magister.stochastikon.com">6</a></li>
<li>Homepage of Stochastikon GmbH, <a href="http://www.stochastikon.com/">7</a></li>
<li>Economic Quality Control, <a href="http://www.heldermann-verlag.de/eqc/eqc23/eqc23003.pdf">8</a></li>
<li>Journal of Uncertain Systems, <a href="http://www.worldacademicunion.com/journal/jus/jusVol02No3paper05.pdf">9</a></li>
</ul>

<p>"</p>

<p><a href="Category:Information,_knowledge,_and_uncertainty" title="wikilink">Category:Information, knowledge, and uncertainty</a> <a class="uri" href="Category:Randomness" title="wikilink">Category:Randomness</a> <a href="Category:Probability_interpretations" title="wikilink">Category:Probability interpretations</a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1">Elart von Collani, State of the Art and Future of Stochastics, in: Ivor Grattan-Guinness and B.S. Yadav (eds): <em>History of Mathematical Sciences</em>, Hindustan Book Agency, New Delhi, pp. 171‚Äì190, 2004.<a href="#fnref1">‚Ü©</a></li>
<li id="fn2">Elart von Collani (ed), Defining the Science of Stochastics, Helderman, Lemgo,2004.<a href="#fnref2">‚Ü©</a></li>
<li id="fn3">Elart von Collani and Xiaomin Zhai, <em>Stochastics</em>, Beijing Publisher Group, Beijing, 2005 (in Chinese).<a href="#fnref3">‚Ü©</a></li>
<li id="fn4">Elart von Collani, <a href="http://pubs.amstat.org/doi/pdfplus/10.1198/tast.2010.09190">"Response to ‚ÄòDesired and Feared‚ÄîWhat Do We Do Now and Over the Next 50 Years‚Äô by Xiao-Li Meng"</a>, <em>The American Statistician</em>, 2010, 64(1): 23‚Äì25.<a href="#fnref4">‚Ü©</a></li>
<li id="fn5">Usually the year of Jakob Bernoulli's birth is given as 1654, however, this is not correct if the nowadays valid Gregorian calendar is applied.<a href="#fnref5">‚Ü©</a></li>
<li id="fn6">Elart von Collani, <a href="http://isi.cbs.nl/bnews/06b/index.html">"Jacob Bernoulli Deciphered"</a>, Bernoulli News, 2006, Vol. 13/2.<a href="#fnref6">‚Ü©</a></li>
<li id="fn7">Jacob Bernoulli, The Art of Conjecturing, translated by Edith Dudley Sykka, 2006, Johns Hopkins University Press, Baltimore.<a href="#fnref7">‚Ü©</a></li>
<li id="fn8">Elart von Collani, The forgotton science of prediction, in: V. Nithyanantha Bhat, T. Thrivikraman, V. Madhikar Mallayya, and S. Madhavan (eds.), <em>History and Heritage of Mathematical Sciences</em>, Sukrtindra Oriental Research Institute, Kerala, pp. 54‚Äì70, 2009.<a href="#fnref8">‚Ü©</a></li>
<li id="fn9">During the World Mathematical Year 2000 a number of international conferences and workshop were organized under the aegis of the <a href="Bernoulli_Society" title="wikilink">Bernoulli Society</a>, <a href="http://isi.cbs.nl/bnews/00b/bn_4.html">1</a>.<a href="#fnref9">‚Ü©</a></li>
<li id="fn10"><a href="http://ib.ptb.de/8/84/MATHMET2010/VORTRAEGE/MathMet2010_Collani.pdf">2</a><a href="#fnref10">‚Ü©</a></li>
<li id="fn11">Elart von Collani and Karl Baur: Was zum Teufel ist Qualit√§t? Heldermann Verlag, Lemgo, 2007.<a href="#fnref11">‚Ü©</a></li>
<li id="fn12">Elart von Collani, A. Binder, W. Sans, A. Heitmann, K. Al-Ghazali: Design Load Definition by LEXPOL. Wind Energy 11, 637‚Äì653, 2008.<a href="#fnref12">‚Ü©</a></li>
<li id="fn13">Elart von Collani and Karl Baur, Brennstabauslegung und Brennstabmodellierung ‚Äì Teil 1 (Fuel rod design and modeling of fuel rods ‚Äì Part I), 'Kerntechnik', Vol. 64, 253‚Äì260, 2004.<a href="#fnref13">‚Ü©</a></li>
<li id="fn14">Elart von Collani and Karl Baur, Brennstabauslegung und Brennstabmodellierung ‚Äì Teil 2 (Fuel rod design and modeling of fuel rods ‚Äì Part II), 'Kerntechnik', Vol. 70, 158‚Äì167, 2005.<a href="#fnref14">‚Ü©</a></li>
<li id="fn15">Andreas Binder, <em>Die stochastische Wissenschyaft und zwei Teilsysteme eines Web-basierten Informations- und Anwendungesystems zu ihrer Etablierung</em>, Ph.D. Thesis, Faculty of Mathematics and Computer Science, University W√ºrzburg, 2006, <a href="http://www.opus-bayern.de/uni-wuerzburg/volltexte/2008/2614/">3</a>.<a href="#fnref15">‚Ü©</a></li>
<li id="fn16">Xiaomin Zhai, <em>Design, Development and Evaluation of a Virtual Classroom and Teaching Contents for Bernoulli Stochastics</em>, Ph.D. Thesis, Faculty of Mathematics and Computer Science, University W√ºrzburg, 2011, <a href="http://www.opus-bayern.de/uni-wuerzburg/volltexte/2011/5610/">4</a><a href="#fnref16">‚Ü©</a></li>
</ol>
</section>
</body>
</html>
