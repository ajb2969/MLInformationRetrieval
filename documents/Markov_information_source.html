<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="671">Markov information source</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>Markov information source</h1>
<hr/>

<p>In <a class="uri" href="mathematics" title="wikilink">mathematics</a>, a <strong>Markov information source</strong>, or simply, a <strong>Markov source</strong>, is an <a href="information_source_(mathematics)" title="wikilink">information source</a> whose underlying dynamics are given by a stationary finite <a href="Markov_chain" title="wikilink">Markov chain</a>.</p>
<h2 id="formal-definition">Formal definition</h2>

<p>An <strong>information source</strong> is a sequence of <a href="random_variable" title="wikilink">random variables</a> ranging over a finite alphabet Γ, having a <a href="stationary_distribution" title="wikilink">stationary distribution</a>.</p>

<p>A Markov information source is then a (stationary) Markov chain <em>M</em>, together with a function</p>

<p>

<math display="block" id="Markov_information_source:0">
 <semantics>
  <mrow>
   <mi>f</mi>
   <mo>:</mo>
   <mrow>
    <mi>S</mi>
    <mo>→</mo>
    <mi mathvariant="normal">Γ</mi>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <ci>normal-:</ci>
    <ci>f</ci>
    <apply>
     <ci>normal-→</ci>
     <ci>S</ci>
     <ci>normal-Γ</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   f:S\to\Gamma
  </annotation>
 </semantics>
</math>

</p>

<p>that maps states <em>S</em> in the Markov chain to letters in the alphabet Γ.</p>

<p>A <strong>unifilar Markov source</strong> is a Markov source for which the values 

<math display="inline" id="Markov_information_source:1">
 <semantics>
  <mrow>
   <mi>f</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <msub>
     <mi>s</mi>
     <mi>k</mi>
    </msub>
    <mo stretchy="false">)</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <ci>f</ci>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>s</ci>
     <ci>k</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   f(s_{k})
  </annotation>
 </semantics>
</math>

 are distinct whenever each of the states 

<math display="inline" id="Markov_information_source:2">
 <semantics>
  <msub>
   <mi>s</mi>
   <mi>k</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>s</ci>
    <ci>k</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   s_{k}
  </annotation>
 </semantics>
</math>

 are reachable, in one step, from a common prior state. Unifilar sources are notable in that many of their properties are far more easily analyzed, as compared to the general case.</p>
<h2 id="applications">Applications</h2>

<p>Markov sources are commonly used in <a href="communication_theory" title="wikilink">communication theory</a>, as a model of a <a class="uri" href="transmitter" title="wikilink">transmitter</a>. Markov sources also occur in <a href="natural_language_processing" title="wikilink">natural language processing</a>, where they are used to represent hidden meaning in a text. Given the output of a Markov source, whose underlying Markov chain is unknown, the task of solving for the underlying chain is undertaken by the techniques of <a href="hidden_Markov_model" title="wikilink">hidden Markov models</a>, such as the <a href="Viterbi_algorithm" title="wikilink">Viterbi algorithm</a>.</p>
<h2 id="see-also">See also</h2>
<ul>
<li><a href="Entropy_rate" title="wikilink">Entropy rate</a></li>
</ul>
<h2 id="references">References</h2>
<ul>
<li>Robert B. Ash, <em>Information Theory</em>, (1965) Dover Publications. ISBN 0-486-66521-6</li>
</ul>

<p>"</p>

<p><a href="Category:Probability_theory" title="wikilink">Category:Probability theory</a> <a href="Category:Stochastic_processes" title="wikilink">Category:Stochastic processes</a> <a href="Category:Statistical_natural_language_processing" title="wikilink">Category:Statistical natural language processing</a></p>
</body>
</html>
