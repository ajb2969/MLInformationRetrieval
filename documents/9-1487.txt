   Principal axis theorem      Principal axis theorem   In the mathematical fields of geometry and linear algebra , a principal axis is a certain line in a Euclidean space associated to an ellipsoid or hyperboloid , generalizing the major and minor axes of an ellipse . The principal axis theorem states that the principal axes are perpendicular, and gives a constructive procedure for finding them.  Mathematically, the principal axis theorem is a generalization of the method of completing the square from elementary algebra . In linear algebra and functional analysis , the principal axis theorem is a geometrical counterpart of the spectral theorem . It has applications to the statistics of principal components analysis and the singular value decomposition . In physics , the theorem is fundamental to the study of angular momentum .  Motivation  The equations in the Cartesian plane  R 2 :         x  2   9   +    y  2   25    =  1           superscript  x  2   9      superscript  y  2   25    1    \frac{x^{2}}{9}+\frac{y^{2}}{25}=1            x  2   9   -    y  2   25    =  1           superscript  x  2   9      superscript  y  2   25    1    {}\frac{x^{2}}{9}-\frac{y^{2}}{25}=1   define, respectively, an ellipse and a hyperbola. In each case, the x and y axes are the principal axes. This is easily seen, given that there are no cross-terms involving products xy in either expression. However, the situation is more complicated for equations like        5   x  2    +   8  x  y   +   5   y  2     =  1.          5   superscript  x  2      8  x  y     5   superscript  y  2     1.    5x^{2}+8xy+5y^{2}=1.   Here some method is required to determine whether this is an ellipse or a hyperbola. The basic observation is that if, by completing the square, the expression can be reduced to a sum of two squares then it defines an ellipse, whereas if it reduces to a difference of two squares then it is the equation of a hyperbola:        u    (  x  ,  y  )   2    +   v    (  x  ,  y  )   2     =   1  (ellipse)           u   superscript   x  y   2      v   superscript   x  y   2      1  (ellipse)     u(x,y)^{2}+v(x,y)^{2}=1\qquad\text{(ellipse)}            u    (  x  ,  y  )   2    -   v    (  x  ,  y  )   2     =   1  (hyperbola)    .          u   superscript   x  y   2      v   superscript   x  y   2      1  (hyperbola)     u(x,y)^{2}-v(x,y)^{2}=1\qquad\text{(hyperbola)}.   Thus, in our example expression, the problem is how to absorb the coefficient of the cross-term 8 xy into the functions u and v . Formally, this problem is similar to the problem of matrix diagonalization , where one tries to find a suitable coordinate system in which the matrix of a linear transformation is diagonal. The first step is to find a matrix in which the technique of diagonalization can be applied.  The trick is to write the equation in the following form:        5   x  2    +   8  x  y   +   5   y  2     =    [     x     y  ;      ]    [     5    4      4    5     ]    [     x      y     ]    =    ùê±  T   A  ùê±             5   superscript  x  2      8  x  y     5   superscript  y  2         x  y      5  4    4  5      x    y             superscript  ùê±  T   A  ùê±      5x^{2}+8xy+5y^{2}=\begin{bmatrix}x&y\end{bmatrix}\begin{bmatrix}5&4\\
 4&5\end{bmatrix}\begin{bmatrix}x\\
 y\end{bmatrix}=\mathbf{x}^{T}A\mathbf{x}   where the cross-term has been split into two equal parts. The matrix A in the above decomposition is a symmetric matrix . In particular, by the spectral theorem , it has real  eigenvalues and is diagonalizable by an orthogonal matrix ( orthogonally diagonalizable ).  To orthogonally diagonalize A , one must first find its eigenvalues, and then find an orthonormal  eigenbasis . Calculation reveals that the eigenvalues of A are        Œª  1   =  1   ,    Œª  2   =  9      formulae-sequence     subscript  Œª  1   1      subscript  Œª  2   9     \lambda_{1}=1,\quad\lambda_{2}=9   with corresponding eigenvectors         ùêØ  1   =   [     1       -  1      ]    ,    ùêØ  2   =   [     1      1     ]     .     formulae-sequence     subscript  ùêØ  1     1      1         subscript  ùêØ  2     1    1       \mathbf{v}_{1}=\begin{bmatrix}1\\
 -1\end{bmatrix},\quad\mathbf{v}_{2}=\begin{bmatrix}1\\
 1\end{bmatrix}.   Dividing these by their respective lengths yields an orthonormal eigenbasis:         ùêÆ  1   =   [      1  /   2         -   1  /   2        ]    ,    ùêÆ  2   =   [      1  /   2         1  /   2       ]     .     formulae-sequence     subscript  ùêÆ  1       1    2          1    2           subscript  ùêÆ  2       1    2        1    2         \mathbf{u}_{1}=\begin{bmatrix}1/\sqrt{2}\\
 -1/\sqrt{2}\end{bmatrix},\quad\mathbf{u}_{2}=\begin{bmatrix}1/\sqrt{2}\\
 1/\sqrt{2}\end{bmatrix}.     Now the matrix S = [ u 1  u 2 ] is an orthogonal matrix, since it has orthonormal columns, and A is diagonalized by:       A  =   S  D   S   -  1     =   S  D   S  T    =    [      1  /   2       1  /   2         -   1  /   2        1  /   2       ]    [     1    0      0    9     ]    [      1  /   2       -   1  /   2          1  /   2       1  /   2       ]     .        A    S  D   superscript  S    1            S  D   superscript  S  T               1    2      1    2          1    2       1    2        1  0    0  9        1    2        1    2         1    2      1    2          A=SDS^{-1}=SDS^{T}=\begin{bmatrix}1/\sqrt{2}&1/\sqrt{2}\\
 -1/\sqrt{2}&1/\sqrt{2}\end{bmatrix}\begin{bmatrix}1&0\\
 0&9\end{bmatrix}\begin{bmatrix}1/\sqrt{2}&-1/\sqrt{2}\\
 1/\sqrt{2}&1/\sqrt{2}\end{bmatrix}.     This applies to the present problem of "diagonalizing" the equation through the observation that         5   x  2    +   8  x  y   +   5   y  2     =    ùê±  T   A  ùê±   =     (    S  T   ùê±   )   T   D   (    S  T   ùê±   )    =    1    (    x  -  y    2    )   2    +   9    (    x  +  y    2    )   2      .            5   superscript  x  2      8  x  y     5   superscript  y  2        superscript  ùê±  T   A  ùê±           superscript     superscript  S  T   ùê±   T   D     superscript  S  T   ùê±             1   superscript      x  y     2    2      9   superscript      x  y     2    2        5x^{2}+8xy+5y^{2}=\mathbf{x}^{T}A\mathbf{x}=(S^{T}\mathbf{x})^{T}D(S^{T}%
 \mathbf{x})=1\left(\frac{x-y}{\sqrt{2}}\right)^{2}+9\left(\frac{x+y}{\sqrt{2}}%
 \right)^{2}.   Thus, the equation is that of an ellipse, since it is the sum of two squares.  It is tempting to simplify this expression by pulling out factors of 2. However, it is important not to do this. The quantities        c  1   =    x  -  y    2     ,    c  2   =    x  +  y    2        formulae-sequence     subscript  c  1       x  y     2        subscript  c  2       x  y     2       c_{1}=\frac{x-y}{\sqrt{2}},\quad c_{2}=\frac{x+y}{\sqrt{2}}   have a geometrical meaning. They determine an orthonormal coordinate system on R 2 . In other words, they are obtained from the original coordinates by the application of a rotation (and possibly a reflection). Consequently, one may use the c 1 and c 2 coordinates to make statements about length and angles (particularly length), which would otherwise be more difficult in a different choice of coordinates (by rescaling them, for instance). For example, the maximum distance from the origin on the ellipse c 1 2 + 9 c 2 2 = 1 occurs when c 2 =0, so at the points c 1 =¬±1. Similarly, the minimum distance is where c 2 =¬±1/3.  It is possible now to read off the major and minor axes of this ellipse. These are precisely the individual eigenspaces of the matrix A , since these are where c 2 = 0 or c 1 =0. Symbolically, the principal axes are         E  1   =   span   (   [      1  /   2         -   1  /   2        ]   )     ,    E  2   =   span   (   [      1  /   2         1  /   2       ]   )      .     formulae-sequence     subscript  E  1     span      1    2          1    2            subscript  E  2     span      1    2        1    2          E_{1}=\text{span}\left(\begin{bmatrix}1/\sqrt{2}\\
 -1/\sqrt{2}\end{bmatrix}\right),\quad E_{2}=\text{span}\left(\begin{bmatrix}1/%
 \sqrt{2}\\
 1/\sqrt{2}\end{bmatrix}\right).   To summarize:   The equation is for an ellipse, since both eigenvalues are positive. (Otherwise, if one were positive and the other negative, it would be a hyperbola.)  The principal axes are the lines spanned by the eigenvectors.  The minimum and maximum distances to the origin can be read off the equation in diagonal form.   Using this information, it is possible to attain a clear geometrical picture of the ellipse: to graph it, for instance.  Formal statement  The principal axis theorem concern quadratic forms in R n , which are homogeneous polynomial s of degree 2. Any quadratic form may be represented as       Q   (  ùê±  )    =    ùê±  T   A  ùê±         Q  ùê±      superscript  ùê±  T   A  ùê±     Q(\mathbf{x})=\mathbf{x}^{T}A\mathbf{x}   where A is a symmetric matrix.  The first part of the theorem is contained in the following statements guaranteed by the spectral theorem:   The eigenvalues of A are real.  A is diagonalizable, and the eigenspaces of A are mutually orthogonal.   In particular, A is orthogonally diagonalizable , since one may take a basis of each eigenspace and apply the Gram-Schmidt process separately within the eigenspace to obtain an orthonormal eigenbasis.  For the second part, suppose that the eigenvalues of A are Œª 1 , ..., Œª n (possibly repeated according to their algebraic multiplicities) and the corresponding orthonormal eigenbasis is u 1 ,..., u n . Then         Q   (  ùê±  )    =     Œª  1    c  1  2    +    Œª  2    c  2  2    +  ‚Ä¶  +    Œª  n    c  n  2      ,        Q  ùê±        subscript  Œª  1    superscript   subscript  c  1   2       subscript  Œª  2    superscript   subscript  c  2   2    normal-‚Ä¶     subscript  Œª  n    superscript   subscript  c  n   2       Q(\mathbf{x})=\lambda_{1}c_{1}^{2}+\lambda_{2}c_{2}^{2}+\dots+\lambda_{n}c_{n}%
 ^{2},      where the c i are the coordinates with respect to the given eigenbasis. Furthermore,   The i -th principal axis is the line determined by the n -1 equations c j = 0, j ‚â† i . This axis is the span of the vector u i .   See also   Sylvester's law of inertia   References     "  Category:Theorems in geometry  Category:Theorems in linear algebra   