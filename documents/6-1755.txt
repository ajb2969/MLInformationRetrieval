   Control variates      Control variates   The control variates method is a variance reduction technique used in Monte Carlo methods . It exploits information about the errors in estimates of known quantities to reduce the error of an estimate of an unknown quantity. 1  Underlying principle  Let the unknown parameter of interest be   μ   μ   \mu   , and assume we have a statistic    m   m   m   such that the expected value of m is μ     𝔼   [  m  ]    =  μ        𝔼   delimited-[]  m    μ    \mathbb{E}\left[m\right]=\mu   , i.e. m is an unbiased estimator for μ. Suppose we calculate another statistic   t   t   t   such that     𝔼   [  t  ]    =  τ        𝔼   delimited-[]  t    τ    \mathbb{E}\left[t\right]=\tau   is a known value. Then       m  ⋆   =   m  +   c   (   t  -  τ   )          superscript  m  normal-⋆     m    c    t  τ       m^{\star}=m+c\left(t-\tau\right)\,     is also an unbiased estimator for   μ   μ   \mu   for any choice of the coefficient   c   c   c   . The variance of the resulting estimator    m  ⋆     superscript  m  normal-⋆    m^{\star}   is        Var   (   m  ⋆   )    =    Var   (  m  )    +     c  2    Var   (  t  )    +   2   c   Cov   (  m  ,  t  )      ;        Var   superscript  m  normal-⋆        Var  m      superscript  c  2   Var  t     2  c  Cov   m  t       \textrm{Var}\left(m^{\star}\right)=\textrm{Var}\left(m\right)+c^{2}\,\textrm{%
 Var}\left(t\right)+2c\,\textrm{Cov}\left(m,t\right);     It can be shown that choosing the optimal coefficient        c  ⋆   =   -    Cov   (  m  ,  t  )     Var   (  t  )       ;       superscript  c  normal-⋆         Cov   m  t      Var  t       c^{\star}=-\frac{\textrm{Cov}\left(m,t\right)}{\textrm{Var}\left(t\right)};     minimizes the variance of    m  ⋆     superscript  m  normal-⋆    m^{\star}   , and that with this choice,      Var   (   m  ⋆   )       Var   superscript  m  normal-⋆     \displaystyle\textrm{Var}\left(m^{\star}\right)     where        ρ   m  ,  t    =   Corr   (  m  ,  t  )     ;       subscript  ρ   m  t      Corr   m  t      \rho_{m,t}=\textrm{Corr}\left(m,t\right);\,     is the correlation coefficient of m and t . The greater the value of    |   ρ   m  ,  t    |       subscript  ρ   m  t      |\rho_{m,t}|   , the greater the variance reduction achieved.  In the case that    Cov   (  m  ,  t  )       Cov   m  t     \textrm{Cov}\left(m,t\right)   ,    Var   (  t  )       Var  t    \textrm{Var}\left(t\right)   , and/or     ρ   m  ,  t       subscript  ρ   m  t     \rho_{m,t}\;   are unknown, they can be estimated across the Monte Carlo replicates. This is equivalent to solving a certain least squares system; therefore this technique is also known as regression sampling .  Example  We would like to estimate      I  =    ∫  0  1      1   1  +  x     d  x        I    superscript   subscript   0   1       1    1  x    normal-d  x      I=\int_{0}^{1}\frac{1}{1+x}\,\mathrm{d}x   using Monte Carlo integration . This integral is the expected value of    f   (  U  )       f  U    f(U)   , where       f   (  x  )    =   1   1  +  x          f  x     1    1  x      f(x)=\frac{1}{1+x}   and U follows a uniform distribution [0, 1]. Using a sample of size n denote the points in the sample as     u  1   ,  ⋯  ,   u  n       subscript  u  1   normal-⋯   subscript  u  n     u_{1},\cdots,u_{n}   . Then the estimate is given by       I  ≈    1  n     ∑  i    f   (   u  i   )       ;      I      1  n     subscript   i     f   subscript  u  i        I\approx\frac{1}{n}\sum_{i}f(u_{i});     Now we introduce     g   (  x  )    =   1  +  x         g  x     1  x     g(x)=1+x   as a control variate with a known expected value     𝔼   [   g   (  U  )    ]    =    ∫  0  1     (   1  +  x   )   d  x    =   3  2           𝔼   delimited-[]    g  U       superscript   subscript   0   1       1  x   normal-d  x           3  2      \mathbb{E}\left[g\left(U\right)\right]=\int_{0}^{1}(1+x)\,\mathrm{d}x=\frac{3}%
 {2}   and combine the two into a new estimate       I  ≈     1  n     ∑  i    f   (   u  i   )      +   c   (     1  n     ∑  i    g   (   u  i   )      -   3  /  2    )      .      I        1  n     subscript   i     f   subscript  u  i        c        1  n     subscript   i     g   subscript  u  i        3  2        I\approx\frac{1}{n}\sum_{i}f(u_{i})+c\left(\frac{1}{n}\sum_{i}g(u_{i})-3/2%
 \right).     Using    n  =  1500      n  1500    n=1500   realizations and an estimated optimal coefficient     c  ⋆   ≈  0.4773       superscript  c  normal-⋆   0.4773    c^{\star}\approx 0.4773   we obtain the following results       Estimate   Variance     Classical estimate   0.69475   0.01947     ''Control variates ''   0.69295   0.00060     The variance was significantly reduced after using the control variates technique. (The exact result is    I  =   ln  2   ≈  0.69314718        I    2        0.69314718     I=\ln 2\approx 0.69314718   .)  See also  :* Antithetic variates  :* Importance sampling  Notes    References   Ross, Sheldon M. (2002) Simulation 3rd edition ISBN 978-0-12-598053-1  Averill M. Law & W. David Kelton (2000), Simulation Modeling and Analysis , 3rd edition. ISBN 0-07-116537-1  S. P. Meyn (2007) Control Techniques for Complex Networks , Cambridge University Press. ISBN 978-0-521-88441-9. Downloadable draft (Section 11.4: Control variates and shadow functions)   "  Category:Monte Carlo methods  Category:Randomness  Category:Computational statistics     Glasserman, P. (2004). Monte Carlo Methods in Financial Engineering . New York: Springer. ISBN 0-387-00451-3 (p. 185) ↩     