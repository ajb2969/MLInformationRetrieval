<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="654">Hebbian theory</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>Hebbian theory</h1>
<hr/>

<p><strong>Hebbian theory</strong> is a theory in <a class="uri" href="neuroscience" title="wikilink">neuroscience</a> that proposes an explanation for the adaptation of <a href="neuron" title="wikilink">neurons</a> in the brain during the learning process. It describes a basic mechanism for <a href="synaptic_plasticity" title="wikilink">synaptic plasticity</a>, where an increase in <a href="synapse" title="wikilink">synaptic</a> efficacy arises from the presynaptic cell's repeated and persistent stimulation of the postsynaptic cell. Introduced by <a href="Donald_Hebb" title="wikilink">Donald Hebb</a> in his 1949 book <em><a href="The_Organization_of_Behavior" title="wikilink">The Organization of Behavior</a></em>,<a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a> the theory is also called <strong>Hebb's rule</strong>, <strong>Hebb's postulate</strong>, and <strong>cell assembly theory</strong>. Hebb states it as follows:</p>
<blockquote>

<p>Let us assume that the persistence or repetition of a reverberatory activity (or "trace") tends to induce lasting cellular changes that add to its stability.â€¦ When an <a class="uri" href="axon" title="wikilink">axon</a> of cell <em>A</em> is near enough to excite a cell <em>B</em> and repeatedly or persistently takes part in firing it, some growth process or metabolic change takes place in one or both cells such that <em>A</em>{{'}}s efficiency, as one of the cells firing <em>B</em>, is increased.<a class="footnoteRef" href="#fn2" id="fnref2"><sup>2</sup></a></p>
</blockquote>

<p>The theory is often summarized by <a href="Carla_Shatz" title="wikilink">Carla Shatz</a>'s phrase: "Cells that fire together, wire together".<a class="footnoteRef" href="#fn3" id="fnref3"><sup>3</sup></a> However, this summary should not be taken literally. Hebb emphasized that cell A needs to "take part in firing" cell B, and such causality can only occur if cell A fires just before, not at the same time as, cell B. This important aspect of causation in Hebb's work foreshadowed what is now known about <a href="spike-timing-dependent_plasticity" title="wikilink">spike-timing-dependent plasticity</a>, which requires temporal precedence.<a class="footnoteRef" href="#fn4" id="fnref4"><sup>4</sup></a> The theory attempts to explain <a href="associative_learning" title="wikilink">associative</a> or <strong>Hebbian learning</strong>, in which simultaneous activation of cells leads to pronounced increases in <a href="synaptic_strength" title="wikilink">synaptic strength</a> between those cells, and provides a biological basis for <a href="errorless_learning" title="wikilink">errorless learning</a> methods for education and memory rehabilitation.</p>
<h2 id="hebbian-engrams-and-cell-assembly-theory">Hebbian engrams and cell assembly theory</h2>

<p>Hebbian theory concerns how neurons might connect themselves to become <a href="Engram_(neuropsychology)" title="wikilink">engrams</a>. Hebb's theories on the form and function of cell assemblies can be understood from the following: "The general idea is an old one, that any two cells or systems of cells that are repeatedly active at the same time will tend to become 'associated', so that activity in one facilitates activity in the other."<a class="footnoteRef" href="#fn5" id="fnref5"><sup>5</sup></a> He also wrote: "When one cell repeatedly assists in firing another, the axon of the first cell develops synaptic knobs (or enlarges them if they already exist) in contact with the soma of the second cell."<a class="footnoteRef" href="#fn6" id="fnref6"><sup>6</sup></a></p>

<p><a href="Gordon_Allport" title="wikilink">Gordon Allport</a> posits additional ideas regarding cell assembly theory and its role in forming engrams, along the lines of the concept of auto-association, described as follows:</p>
<blockquote>

<p>If the inputs to a system cause the same pattern of activity to occur repeatedly, the set of active elements constituting that pattern will become increasingly strongly interassociated. That is, each element will tend to turn on every other element and (with negative weights) to turn off the elements that do not form part of the pattern. To put it another way, the pattern as a whole will become 'auto-associated'. We may call a learned (auto-associated) pattern an engram.<a class="footnoteRef" href="#fn7" id="fnref7"><sup>7</sup></a></p>
</blockquote>

<p>Hebbian theory has been the primary basis for the conventional view that, when analyzed from a holistic level, engrams are neuronal nets or <a href="neural_networks" title="wikilink">neural networks</a>.</p>

<p>Work in the laboratory of <a href="Eric_R._Kandel#Experimental_support_for_Hebbian_learning" title="wikilink">Eric Kandel</a> has provided evidence for the involvement of Hebbian learning mechanisms at synapses in the marine <a href="Gastropoda" title="wikilink">gastropod</a> <em><a href="Aplysia_californica" title="wikilink">Aplysia californica</a></em>.</p>

<p>Experiments on Hebbian synapse modification mechanisms at the <a href="central_nervous_system" title="wikilink">central nervous system</a> synapses of <a href="vertebrate" title="wikilink">vertebrates</a> are much more difficult to control than are experiments with the relatively simple <a href="peripheral_nervous_system" title="wikilink">peripheral nervous system</a> synapses studied in marine invertebrates. Much of the work on long-lasting synaptic changes between vertebrate neurons (such as <a href="long-term_potentiation" title="wikilink">long-term potentiation</a>) involves the use of non-physiological experimental stimulation of brain cells. However, some of the physiologically relevant synapse modification mechanisms that have been studied in vertebrate brains do seem to be examples of Hebbian processes. One such study reviews results from experiments that indicate that long-lasting changes in synaptic strengths can be induced by physiologically relevant synaptic activity working through both Hebbian and non-Hebbian mechanisms.</p>
<h2 id="principles">Principles</h2>

<p>From the point of view of <a href="artificial_neuron" title="wikilink">artificial neurons</a> and <a href="artificial_neural_network" title="wikilink">artificial neural networks</a>, Hebb's principle can be described as a method of determining how to alter the weights between model neurons. The weight between two neurons increases if the two neurons activate simultaneously, and reduces if they activate separately. Nodes that tend to be either both positive or both negative at the same time have strong positive weights, while those that tend to be opposite have strong negative weights.</p>

<p>The following is a formulaic description of Hebbian learning: (note that many other descriptions are possible)</p>

<p>

<math display="block" id="Hebbian_theory:0">
 <semantics>
  <mrow>
   <msub>
    <mpadded lspace="1.7pt" width="+1.7pt">
     <mi>w</mi>
    </mpadded>
    <mrow>
     <mi>i</mi>
     <mi>j</mi>
    </mrow>
   </msub>
   <mo>=</mo>
   <mrow>
    <msub>
     <mi>x</mi>
     <mi>i</mi>
    </msub>
    <msub>
     <mi>x</mi>
     <mi>j</mi>
    </msub>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>w</ci>
     <apply>
      <times></times>
      <ci>i</ci>
      <ci>j</ci>
     </apply>
    </apply>
    <apply>
     <times></times>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>x</ci>
      <ci>i</ci>
     </apply>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>x</ci>
      <ci>j</ci>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \,w_{ij}=x_{i}x_{j}
  </annotation>
 </semantics>
</math>

</p>

<p>where 

<math display="inline" id="Hebbian_theory:1">
 <semantics>
  <msub>
   <mi>w</mi>
   <mrow>
    <mi>i</mi>
    <mi>j</mi>
   </mrow>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>w</ci>
    <apply>
     <times></times>
     <ci>i</ci>
     <ci>j</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   w_{ij}
  </annotation>
 </semantics>
</math>

 is the weight of the connection from neuron 

<math display="inline" id="Hebbian_theory:2">
 <semantics>
  <mi>j</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>j</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   j
  </annotation>
 </semantics>
</math>

 to neuron 

<math display="inline" id="Hebbian_theory:3">
 <semantics>
  <mi>i</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>i</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   i
  </annotation>
 </semantics>
</math>

 and 

<math display="inline" id="Hebbian_theory:4">
 <semantics>
  <msub>
   <mi>x</mi>
   <mi>i</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>x</ci>
    <ci>i</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   x_{i}
  </annotation>
 </semantics>
</math>

 the input for neuron 

<math display="inline" id="Hebbian_theory:5">
 <semantics>
  <mi>i</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>i</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   i
  </annotation>
 </semantics>
</math>

. Note that this is pattern learning (weights updated after every training example). In a <a href="Hopfield_network" title="wikilink">Hopfield network</a>, connections 

<math display="inline" id="Hebbian_theory:6">
 <semantics>
  <msub>
   <mi>w</mi>
   <mrow>
    <mi>i</mi>
    <mi>j</mi>
   </mrow>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>w</ci>
    <apply>
     <times></times>
     <ci>i</ci>
     <ci>j</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   w_{ij}
  </annotation>
 </semantics>
</math>

 are set to zero if 

<math display="inline" id="Hebbian_theory:7">
 <semantics>
  <mrow>
   <mi>i</mi>
   <mo>=</mo>
   <mi>j</mi>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <ci>i</ci>
    <ci>j</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   i=j
  </annotation>
 </semantics>
</math>

 (no reflexive connections allowed). With binary neurons (activations either 0 or 1), connections would be set to 1 if the connected neurons have the same activation for a pattern.</p>

<p>Another formulaic description is:</p>

<p>

<math display="block" id="Hebbian_theory:8">
 <semantics>
  <mrow>
   <msub>
    <mi>w</mi>
    <mrow>
     <mi>i</mi>
     <mi>j</mi>
    </mrow>
   </msub>
   <mo>=</mo>
   <mrow>
    <mfrac>
     <mn>1</mn>
     <mi>p</mi>
    </mfrac>
    <mrow>
     <munderover>
      <mo largeop="true" movablelimits="false" symmetric="true">âˆ‘</mo>
      <mrow>
       <mi>k</mi>
       <mo>=</mo>
       <mn>1</mn>
      </mrow>
      <mi>p</mi>
     </munderover>
     <mrow>
      <msubsup>
       <mi>x</mi>
       <mi>i</mi>
       <mi>k</mi>
      </msubsup>
      <mpadded width="+1.7pt">
       <msubsup>
        <mi>x</mi>
        <mi>j</mi>
        <mi>k</mi>
       </msubsup>
      </mpadded>
     </mrow>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>w</ci>
     <apply>
      <times></times>
      <ci>i</ci>
      <ci>j</ci>
     </apply>
    </apply>
    <apply>
     <times></times>
     <apply>
      <divide></divide>
      <cn type="integer">1</cn>
      <ci>p</ci>
     </apply>
     <apply>
      <apply>
       <csymbol cd="ambiguous">superscript</csymbol>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <sum></sum>
        <apply>
         <eq></eq>
         <ci>k</ci>
         <cn type="integer">1</cn>
        </apply>
       </apply>
       <ci>p</ci>
      </apply>
      <apply>
       <times></times>
       <apply>
        <csymbol cd="ambiguous">superscript</csymbol>
        <apply>
         <csymbol cd="ambiguous">subscript</csymbol>
         <ci>x</ci>
         <ci>i</ci>
        </apply>
        <ci>k</ci>
       </apply>
       <apply>
        <csymbol cd="ambiguous">superscript</csymbol>
        <apply>
         <csymbol cd="ambiguous">subscript</csymbol>
         <ci>x</ci>
         <ci>j</ci>
        </apply>
        <ci>k</ci>
       </apply>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   w_{ij}=\frac{1}{p}\sum_{k=1}^{p}x_{i}^{k}x_{j}^{k}\,
  </annotation>
 </semantics>
</math>

 ,</p>

<p>where 

<math display="inline" id="Hebbian_theory:9">
 <semantics>
  <msub>
   <mi>w</mi>
   <mrow>
    <mi>i</mi>
    <mi>j</mi>
   </mrow>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>w</ci>
    <apply>
     <times></times>
     <ci>i</ci>
     <ci>j</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   w_{ij}
  </annotation>
 </semantics>
</math>

 is the weight of the connection from neuron 

<math display="inline" id="Hebbian_theory:10">
 <semantics>
  <mi>j</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>j</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   j
  </annotation>
 </semantics>
</math>

 to neuron 

<math display="inline" id="Hebbian_theory:11">
 <semantics>
  <mi>i</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>i</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   i
  </annotation>
 </semantics>
</math>

, 

<math display="inline" id="Hebbian_theory:12">
 <semantics>
  <mi>p</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>p</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   p
  </annotation>
 </semantics>
</math>

 is the number of training patterns, and 

<math display="inline" id="Hebbian_theory:13">
 <semantics>
  <msubsup>
   <mi>x</mi>
   <mi>i</mi>
   <mi>k</mi>
  </msubsup>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">superscript</csymbol>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>x</ci>
     <ci>i</ci>
    </apply>
    <ci>k</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   x_{i}^{k}
  </annotation>
 </semantics>
</math>

 the 

<math display="inline" id="Hebbian_theory:14">
 <semantics>
  <mi>k</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>k</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   k
  </annotation>
 </semantics>
</math>

th input for neuron 

<math display="inline" id="Hebbian_theory:15">
 <semantics>
  <mi>i</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>i</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   i
  </annotation>
 </semantics>
</math>

. This is learning by epoch (weights updated after all the training examples are presented). Again, in a Hopfield network, connections 

<math display="inline" id="Hebbian_theory:16">
 <semantics>
  <msub>
   <mi>w</mi>
   <mrow>
    <mi>i</mi>
    <mi>j</mi>
   </mrow>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>w</ci>
    <apply>
     <times></times>
     <ci>i</ci>
     <ci>j</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   w_{ij}
  </annotation>
 </semantics>
</math>

 are set to zero if 

<math display="inline" id="Hebbian_theory:17">
 <semantics>
  <mrow>
   <mi>i</mi>
   <mo>=</mo>
   <mi>j</mi>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <ci>i</ci>
    <ci>j</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   i=j
  </annotation>
 </semantics>
</math>

 (no reflexive connections).</p>

<p>A variation of Hebbian learning that takes into account phenomena such as blocking and many other neural learning phenomena is the mathematical model of <a href="Harry_Klopf" title="wikilink">Harry Klopf</a>. <a href="Heterostatic_theory" title="wikilink">Klopf's model</a> reproduces a great many biological phenomena, and is also simple to implement.</p>
<h2 id="generalization-and-stability">Generalization and stability</h2>

<p>Hebb's Rule is often generalized as</p>

<p>

<math display="block" id="Hebbian_theory:18">
 <semantics>
  <mrow>
   <mrow>
    <mrow>
     <mpadded lspace="1.7pt" width="+1.7pt">
      <mi mathvariant="normal">Î”</mi>
     </mpadded>
     <msub>
      <mi>w</mi>
      <mi>i</mi>
     </msub>
    </mrow>
    <mo>=</mo>
    <mrow>
     <mi>Î·</mi>
     <msub>
      <mi>x</mi>
      <mi>i</mi>
     </msub>
     <mi>y</mi>
    </mrow>
   </mrow>
   <mo>,</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <times></times>
     <ci>normal-Î”</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>w</ci>
      <ci>i</ci>
     </apply>
    </apply>
    <apply>
     <times></times>
     <ci>Î·</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>x</ci>
      <ci>i</ci>
     </apply>
     <ci>y</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \,\Delta w_{i}=\eta x_{i}y,
  </annotation>
 </semantics>
</math>

</p>

<p>or the change in the 

<math display="inline" id="Hebbian_theory:19">
 <semantics>
  <mi>i</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>i</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   i
  </annotation>
 </semantics>
</math>

th synaptic weight 

<math display="inline" id="Hebbian_theory:20">
 <semantics>
  <msub>
   <mi>w</mi>
   <mi>i</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>w</ci>
    <ci>i</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   w_{i}
  </annotation>
 </semantics>
</math>

 is equal to a learning rate 

<math display="inline" id="Hebbian_theory:21">
 <semantics>
  <mi>Î·</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>Î·</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \eta
  </annotation>
 </semantics>
</math>

 times the 

<math display="inline" id="Hebbian_theory:22">
 <semantics>
  <mi>i</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>i</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   i
  </annotation>
 </semantics>
</math>

th input 

<math display="inline" id="Hebbian_theory:23">
 <semantics>
  <msub>
   <mi>x</mi>
   <mi>i</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>x</ci>
    <ci>i</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   x_{i}
  </annotation>
 </semantics>
</math>

 times the postsynaptic response 

<math display="inline" id="Hebbian_theory:24">
 <semantics>
  <mi>y</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>y</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   y
  </annotation>
 </semantics>
</math>

. Often cited is the case of a linear neuron,</p>

<p>

<math display="block" id="Hebbian_theory:25">
 <semantics>
  <mrow>
   <mrow>
    <mpadded lspace="1.7pt" width="+1.7pt">
     <mi>y</mi>
    </mpadded>
    <mo>=</mo>
    <mrow>
     <munder>
      <mo largeop="true" movablelimits="false" symmetric="true">âˆ‘</mo>
      <mi>j</mi>
     </munder>
     <mrow>
      <msub>
       <mi>w</mi>
       <mi>j</mi>
      </msub>
      <msub>
       <mi>x</mi>
       <mi>j</mi>
      </msub>
     </mrow>
    </mrow>
   </mrow>
   <mo>,</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <ci>y</ci>
    <apply>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <sum></sum>
      <ci>j</ci>
     </apply>
     <apply>
      <times></times>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>w</ci>
       <ci>j</ci>
      </apply>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>x</ci>
       <ci>j</ci>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \,y=\sum_{j}w_{j}x_{j},
  </annotation>
 </semantics>
</math>

</p>

<p>and the previous section's simplification takes both the learning rate and the input weights to be 1. This version of the rule is clearly unstable, as in any network with a dominant signal the synaptic weights will increase or decrease exponentially. However, it can be shown that for <em>any</em> neuron model, Hebb's rule is unstable. Therefore, network models of neurons usually employ other learning theories such as <a href="BCM_theory" title="wikilink">BCM theory</a>, <a href="Oja's_rule" title="wikilink">Oja's rule</a>,<a class="footnoteRef" href="#fn8" id="fnref8"><sup>8</sup></a> or the <a href="Generalized_Hebbian_Algorithm" title="wikilink">Generalized Hebbian Algorithm</a>.</p>
<h2 id="exceptions">Exceptions</h2>

<p>Despite the common use of Hebbian models for long-term potentiation, there exists several exceptions to Hebb's principles and examples that demonstrate that some aspects of the theory are oversimplified. One of the most well-documented of these exceptions pertains to how synaptic modification may not simply occur only between activated neurons A and B, but to neighboring neurons as well.<a class="footnoteRef" href="#fn9" id="fnref9"><sup>9</sup></a> This is due to how Hebbian modification depends on <a href="retrograde_signaling" title="wikilink">retrograde signaling</a> in order to modify the presynaptic neuron.<a class="footnoteRef" href="#fn10" id="fnref10"><sup>10</sup></a> The compound most commonly identified as fulfilling this retrograde transmitter role is <a href="nitric_oxide" title="wikilink">nitric oxide</a>, which, due to its high solubility and diffusibility, often exerts effects on nearby neurons.<a class="footnoteRef" href="#fn11" id="fnref11"><sup>11</sup></a> This type of diffuse synaptic modification, known as volume learning, counters, or at least supplements, the traditional Hebbian model.<a class="footnoteRef" href="#fn12" id="fnref12"><sup>12</sup></a></p>
<h2 id="hebbian-learning-account-of-mirror-neurons">Hebbian learning account of mirror neurons</h2>

<p>Hebbian learning and spike-timing-dependent plasticity have been used in an influential theory of how <a href="mirror_neuron" title="wikilink">mirror neurons</a> emerge.<a class="footnoteRef" href="#fn13" id="fnref13"><sup>13</sup></a><a class="footnoteRef" href="#fn14" id="fnref14"><sup>14</sup></a> Mirror neurons are neurons that fire both when an individual performs an action and when the individual sees<a class="footnoteRef" href="#fn15" id="fnref15"><sup>15</sup></a> or hears<a class="footnoteRef" href="#fn16" id="fnref16"><sup>16</sup></a> another perform a similar action. The discovery of these neurons has been very influential in explaining how individuals make sense of the actions of others, by showing that, when a person perceives the actions of others, the person activates the motor programs which they would use to perform similar actions. The activation of these motor programs then adds information to the perception and helps predict what the person will do next based on the perceiver's own motor program. A challenge has been to explain how individuals come to have neurons that respond both while performing an action and while hearing or seeing another perform similar actions.</p>

<p><a href="Christian_Keysers" title="wikilink">Christian Keysers</a> and David Perrett suggested that, while an individual performs a particular action, the individual will see, hear, and feel himself perform the action. These re-afferent sensory signals will trigger activity in neurons responding to the sight, sound, and feel of the action. Because the activity of these sensory neurons will consistently overlap in time with those of the motor neurons that caused the action, Hebbian learning would predict that the synapses connecting neurons responding to the sight, sound, and feel of an action and those of the neurons triggering the action should be potentiated. The same is true while people look at themselves in the mirror, hear themselves babble, or are imitated by others. After repeated experience of this re-afference, the synapses connecting the sensory and motor representations of an action would be so strong that the motor neurons would start firing to the sound or the vision of the action, and a mirror neuron would have been created.</p>

<p>Evidence for that perspective comes from many experiments that show that motor programs can be triggered by novel auditory or visual stimuli after repeated pairing of the stimulus with the execution of the motor program (for a review of the evidence, see Giudice et al., 2009<a class="footnoteRef" href="#fn17" id="fnref17"><sup>17</sup></a>). For instance, people who have never played the piano do not activate brain regions involved in playing the piano when listening to piano music. Five hours of piano lessons, in which the participant is exposed to the sound of the piano each time he presses a key, suffices to later trigger activity in motor regions of the brain upon listening to piano music.<a class="footnoteRef" href="#fn18" id="fnref18"><sup>18</sup></a> Consistent with the fact that spike-timing-dependent plasticity occurs only if the presynaptic neuron's firing predicts the post-synaptic neuron's firing,<a class="footnoteRef" href="#fn19" id="fnref19"><sup>19</sup></a> the link between sensory stimuli and motor programs also only seem to be potentiated if the stimulus is contingent on the motor program.</p>
<h2 id="see-also">See also</h2>
<ul>
<li><a href="Dale's_principle" title="wikilink">Dale's principle</a></li>
<li><a href="Coincidence_detection_in_neurobiology" title="wikilink">Coincidence detection in neurobiology</a></li>
<li><a class="uri" href="Leabra" title="wikilink">Leabra</a></li>
<li><a class="uri" href="Metaplasticity" title="wikilink">Metaplasticity</a></li>
<li><a href="Tetanic_stimulation" title="wikilink">Tetanic stimulation</a></li>
<li><a href="Synaptotropic_hypothesis" title="wikilink">Synaptotropic hypothesis</a></li>
</ul>
<h2 id="references">References</h2>
<h2 id="further-reading">Further reading</h2>
<ul>
<li></li>
<li></li>
<li></li>
<li></li>
</ul>
<h2 id="external-links">External links</h2>
<ul>
<li><a href="http://icwww.epfl.ch/~gerstner//SPNM/node71.html">Overview</a></li>
<li>Hebbian Learning tutorial (<a href="http://blog.peltarion.com/2006/05/11/the-talented-dr-hebb-part-1-novelty-filtering">Part 1: Novelty Filtering</a>, <a href="http://blog.peltarion.com/2006/06/20/the-talented-drhebb-part-2-pca/">Part 2: PCA</a>)</li>
</ul>

<p>"</p>

<p><a href="Category:Computational_neuroscience" title="wikilink">Category:Computational neuroscience</a> <a href="Category:Learning_theory_(education)" title="wikilink">Category:Learning theory (education)</a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1"><a href="#fnref1">â†©</a></li>
<li id="fn2"></li>
<li id="fn3"><a href="Carla_Shatz" title="wikilink">Carla Shatz</a>, Stanford University; The exact sentence is: "Segregation to form the columns in the visual cortex [...] proceeds when the two nerves are stimulated asynchronously. In a sense, then, cells that fire together wire together. The timing of action-potential activity is critical in determing which synaptic connections are strenghtened and retained and which are weakened and eliminated." . Also referenced in <a href="#fnref3">â†©</a></li>
<li id="fn4"><a href="#fnref4">â†©</a></li>
<li id="fn5"></li>
<li id="fn6"></li>
<li id="fn7"><a href="#fnref7">â†©</a></li>
<li id="fn8"><a href="#fnref8">â†©</a></li>
<li id="fn9"><a href="#fnref9">â†©</a></li>
<li id="fn10"><a href="#fnref10">â†©</a></li>
<li id="fn11"><a href="#fnref11">â†©</a></li>
<li id="fn12"><a href="#fnref12">â†©</a></li>
<li id="fn13"><a href="#fnref13">â†©</a></li>
<li id="fn14">Keysers, C. (2011). <em>The Empathic Brain</em>.<a href="#fnref14">â†©</a></li>
<li id="fn15"><a href="#fnref15">â†©</a></li>
<li id="fn16"><a href="#fnref16">â†©</a></li>
<li id="fn17"><a href="#fnref17">â†©</a></li>
<li id="fn18"><a href="#fnref18">â†©</a></li>
<li id="fn19"><a href="#fnref19">â†©</a></li>
</ol>
</section>
</body>
</html>
