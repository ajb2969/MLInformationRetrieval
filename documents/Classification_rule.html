<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="1602">Classification rule</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>Classification rule</h1>
<hr/>

<p>Given a population whose members can be potentially separated into a number of different sets or <a href="Class_(set_theory)" title="wikilink">classes</a>, a <strong>classification rule</strong> is a procedure in which the elements of the population set are each assigned to one of the classes.<a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a> A perfect test is such that every element in the population is assigned to the class it really belongs. An imperfect test is such that some errors appear, and then <a href="statistics" title="wikilink">statistical analysis</a> must be applied to analyse the <a href="statistical_classification" title="wikilink">classification</a>.</p>

<p>A special kind of classification rule are <a href="binary_classification" title="wikilink">binary classifications</a>.</p>
<h2 id="testing-classification-rules">Testing classification rules</h2>
<figure><b>(Figure)</b>
<figcaption>The <a href="confusion_matrix" title="wikilink">confusion matrix</a> can be used to derive four basic measures</figcaption>
</figure>

<p>Having a dataset consisting in couples <em>x</em> and <em>y</em>, where <em>x</em> is each element of the population and <em>y</em> the class it belongs to, a <strong>classification rule</strong> can be considered as a function that assigns its class to each element. A binary classification is such that the label <em>y</em> can take only a two values.</p>

<p>A classification rule or <strong>classifier</strong> is a function <em>h</em> that can be evaluated for any possible value of <em>x</em>, specifically, given the data 

<math display="inline" id="Classification_rule:0">
 <semantics>
  <mrow>
   <mo stretchy="false">{</mo>
   <mrow>
    <mo stretchy="false">(</mo>
    <msub>
     <mi>x</mi>
     <mn>1</mn>
    </msub>
    <mo>,</mo>
    <msub>
     <mi>y</mi>
     <mn>1</mn>
    </msub>
    <mo stretchy="false">)</mo>
   </mrow>
   <mo>,</mo>
   <mi mathvariant="normal">…</mi>
   <mo>,</mo>
   <mrow>
    <mo stretchy="false">(</mo>
    <msub>
     <mi>x</mi>
     <mi>n</mi>
    </msub>
    <mo>,</mo>
    <msub>
     <mi>y</mi>
     <mi>n</mi>
    </msub>
    <mo stretchy="false">)</mo>
   </mrow>
   <mo stretchy="false">}</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <set>
    <interval closure="open">
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>x</ci>
      <cn type="integer">1</cn>
     </apply>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>y</ci>
      <cn type="integer">1</cn>
     </apply>
    </interval>
    <ci>normal-…</ci>
    <interval closure="open">
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>x</ci>
      <ci>n</ci>
     </apply>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>y</ci>
      <ci>n</ci>
     </apply>
    </interval>
   </set>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \{(x_{1},y_{1}),\dots,(x_{n},y_{n})\}
  </annotation>
 </semantics>
</math>

, <em>h</em>(<em>x</em>) will yields a similar classification 

<math display="inline" id="Classification_rule:1">
 <semantics>
  <mrow>
   <mrow>
    <mover accent="true">
     <mi>y</mi>
     <mo stretchy="false">^</mo>
    </mover>
    <mo>=</mo>
    <mrow>
     <mi>h</mi>
     <mrow>
      <mo stretchy="false">(</mo>
      <mi>x</mi>
      <mo stretchy="false">)</mo>
     </mrow>
    </mrow>
   </mrow>
   <mo>,</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <ci>normal-^</ci>
     <ci>y</ci>
    </apply>
    <apply>
     <times></times>
     <ci>h</ci>
     <ci>x</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \hat{y}=h(x),
  </annotation>
 </semantics>
</math>

 as close as possible to the true group label <em>y</em>.</p>

<p>The true labels <em>y<sub>i</sub></em> can be known but will not necessarily match their approximations 

<math display="inline" id="Classification_rule:2">
 <semantics>
  <mrow>
   <mover accent="true">
    <msub>
     <mi>y</mi>
     <mi>i</mi>
    </msub>
    <mo stretchy="false">^</mo>
   </mover>
   <mo>=</mo>
   <mrow>
    <mi>h</mi>
    <mrow>
     <mo stretchy="false">(</mo>
     <msub>
      <mi>x</mi>
      <mi>i</mi>
     </msub>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <ci>normal-^</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>y</ci>
      <ci>i</ci>
     </apply>
    </apply>
    <apply>
     <times></times>
     <ci>h</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>x</ci>
      <ci>i</ci>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \hat{y_{i}}=h(x_{i})
  </annotation>
 </semantics>
</math>

. In a binary classification, the elements that are not correctly classified are named false positives and false negatives.</p>

<p>Some classification rules are static functions. Others can be computer programs. A <a href="Statistical_classification_(machine_learning)" title="wikilink">computer classifier</a> can be able to learn or can implement static classification rules. For a training data-set, the true labels <em>y<sub>j</sub></em> are unknown, but it is a prime target for the classification procedure that the approximation 

<math display="block" id="Classification_rule:3">
 <semantics>
  <mrow>
   <mover accent="true">
    <msub>
     <mi>y</mi>
     <mi>j</mi>
    </msub>
    <mo stretchy="false">^</mo>
   </mover>
   <mo>=</mo>
   <mrow>
    <mi>h</mi>
    <mrow>
     <mo stretchy="false">(</mo>
     <msub>
      <mi>x</mi>
      <mi>j</mi>
     </msub>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
   <mo>≈</mo>
   <msub>
    <mi>y</mi>
    <mi>j</mi>
   </msub>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <and></and>
    <apply>
     <eq></eq>
     <apply>
      <ci>normal-^</ci>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>y</ci>
       <ci>j</ci>
      </apply>
     </apply>
     <apply>
      <times></times>
      <ci>h</ci>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>x</ci>
       <ci>j</ci>
      </apply>
     </apply>
    </apply>
    <apply>
     <approx></approx>
     <share href="#.cmml">
     </share>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>y</ci>
      <ci>j</ci>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \hat{y_{j}}=h(x_{j})\approx y_{j}
  </annotation>
 </semantics>
</math>

 as well as possible, where the quality of this approximation needs to be judged on the basis of the statistical or probabilistic properties of the overall population from which future observations will be drawn.</p>

<p>Given a classification rule, a <strong>classification test</strong> is the result of applying the rule to a finite sample of the initial data set.</p>
<h2 id="binary-and-multiclass-classification">Binary and multiclass classification</h2>

<p>Classification can be thought of as two separate problems – <a href="binary_classification" title="wikilink">binary classification</a> and <a href="multiclass_classification" title="wikilink">multiclass classification</a>. In binary classification, a better understood task, only two classes are involved, whereas multiclass classification involves assigning an object to one of several classes.<a class="footnoteRef" href="#fn2" id="fnref2"><sup>2</sup></a> Since many classification methods have been developed specifically for binary classification, multiclass classification often requires the combined use of multiple binary classifiers. An important point is that in many practical binary classification problems, the two groups are not symmetric – rather than overall accuracy, the relative proportion of different types of errors is of interest. For example, in medical testing, a false positive (detecting a disease when it is not present) is considered differently from a false negative (not detecting a disease when it is present). In multiclass classifications, the classes may be considered symmetrically (all errors are equivalent), or asymmetrically, which is considerably more complicated.</p>

<p>Binary classification methods include <a href="probit_regression" title="wikilink">probit regression</a> and <a href="logistic_regression" title="wikilink">logistic regression</a>. Multiclass classification methods include <a href="multinomial_probit" title="wikilink">multinomial probit</a> and <a href="multinomial_logit" title="wikilink">multinomial logit</a>.</p>
<h2 id="table-of-confusion">Table of Confusion</h2>

<p>When the classification function is not perfect, false results will appear. The example confusion matrix below, of the 8 actual cats, a function predicted that three were dogs, and of the six dogs, it predicted that one was a rabbit and two were cats. We can see from the matrix that the system in question has trouble distinguishing between cats and dogs, but can make the distinction between rabbits and other types of animals pretty well.</p>
<table>
<tbody>
<tr class="odd">
<td style="text-align: left;">
<p>Example confusion matrix</p></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">
<p>Predicted</p></td>
</tr>
<tr class="even">
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">
<p>Cat</p></td>
<td style="text-align: left;">
<p>Dog</p></td>
</tr>
<tr class="odd">
<td style="text-align: left;">
<p>Actual</p></td>
<td style="text-align: left;">
<p>Cat</p></td>
<td style="text-align: left;">
<p>5</p></td>
<td style="text-align: left;">
<p>3</p></td>
</tr>
<tr class="even">
<td style="text-align: left;">
<p>Dog</p></td>
<td style="text-align: left;">
<p>2</p></td>
<td style="text-align: left;">
<p>3</p></td>
<td style="text-align: left;">
<p>1</p></td>
</tr>
<tr class="odd">
<td style="text-align: left;">
<p>Rabbit</p></td>
<td style="text-align: left;">
<p>0</p></td>
<td style="text-align: left;">
<p>2</p></td>
<td style="text-align: left;">
<p>11</p></td>
</tr>
</tbody>
</table>

<p>When dealing with binary classifications these concepts are simpler</p>
<h3 id="false-positives">False positives</h3>

<p><a href="Type_I_and_type_II_errors" title="wikilink">False positives</a> result when a test falsely or incorrectly reports a positive result. For example, a <a href="medical_test" title="wikilink">medical test</a> for a <a class="uri" href="disease" title="wikilink">disease</a> may return a positive result indicating that patient has a disease even if the patient does not have the disease. We can use <a href="Bayes'_theorem" title="wikilink">Bayes' theorem</a> to determine the probability that a positive result is in fact a false positive. We find that if a disease is rare, then the majority of positive results may be false positives, even if the test is accurate.</p>

<p>Suppose that a test for a disease generates the following results:</p>
<ul>
<li>If a tested patient has the disease, the test returns a positive result 99% of the time, or with probability 0.99</li>
<li>If a tested patient does not have the disease, the test returns a positive result 5% of the time, or with probability 0.05.</li>
</ul>

<p>Naively, one might think that only 5% of positive test results are false, but that is quite wrong, as we shall see.</p>

<p>Suppose that only 0.1% of the population has that disease, so that a randomly selected patient has a 0.001 prior probability of having the disease.</p>

<p>We can use Bayes' theorem to calculate the probability that a positive test result is a false positive.</p>

<p>Let <em>A</em> represent the condition in which the patient has the disease, and <em>B</em> represent the evidence of a positive test result. Then, the probability that the patient actually has the disease given the positive test result is</p>
<dl>
<dd><math>\begin{align} P(A | B) &amp;= \frac{P(B | A) P(A)}{P(B | A)P(A) + P(B |\text{not }A)P(\text{not }A)} \\ \\
</math></dd>
</dl>

<p><code>&amp;= \frac{0.99\times 0.001}{0.99 \times 0.001 + 0.05\times 0.999} \\ ~\\ &amp;\approx 0.019. \end{align}</code></p>

<p>and hence the probability that a positive result is a false positive is about 1 − 0.019 = 0.98, or 98%.</p>

<p>Despite the apparent high accuracy of the test, the incidence of the disease is so low that the vast majority of patients who test positive do not have the disease. Nonetheless, the fraction of patients who test positive who do have the disease (0.019) is 19 times the fraction of people who have not yet taken the test who have the disease (0.001). Thus the test is not useless, and re-testing may improve the reliability of the result.</p>

<p>In order to reduce the problem of false positives, a test should be very accurate in reporting a <em>negative</em> result when the patient does not have the disease. If the test reported a negative result in patients without the disease with probability 0.999, then</p>
<dl>
<dd>

<math display="inline" id="Classification_rule:4">
 <semantics>
  <mrow>
   <mi>P</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <mi>A</mi>
    <mo stretchy="false">|</mo>
    <mi>B</mi>
    <mo stretchy="false">)</mo>
   </mrow>
   <mo>=</mo>
   <mfrac>
    <mrow>
     <mn>0.99</mn>
     <mo>×</mo>
     <mn>0.001</mn>
    </mrow>
    <mrow>
     <mrow>
      <mn>0.99</mn>
      <mo>×</mo>
      <mn>0.001</mn>
     </mrow>
     <mo>+</mo>
     <mrow>
      <mn>0.001</mn>
      <mo>×</mo>
      <mn>0.999</mn>
     </mrow>
    </mrow>
   </mfrac>
   <mo>≈</mo>
   <mn>0.5</mn>
   <mo>,</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <cerror>
    <csymbol cd="ambiguous">fragments</csymbol>
    <csymbol cd="unknown">P</csymbol>
    <cerror>
     <csymbol cd="ambiguous">fragments</csymbol>
     <ci>normal-(</ci>
     <csymbol cd="unknown">A</csymbol>
     <ci>normal-|</ci>
     <csymbol cd="unknown">B</csymbol>
     <ci>normal-)</ci>
    </cerror>
    <eq></eq>
    <apply>
     <divide></divide>
     <apply>
      <times></times>
      <cn type="float">0.99</cn>
      <cn type="float">0.001</cn>
     </apply>
     <apply>
      <plus></plus>
      <apply>
       <times></times>
       <cn type="float">0.99</cn>
       <cn type="float">0.001</cn>
      </apply>
      <apply>
       <times></times>
       <cn type="float">0.001</cn>
       <cn type="float">0.999</cn>
      </apply>
     </apply>
    </apply>
    <approx></approx>
    <cn type="float">0.5</cn>
    <ci>normal-,</ci>
   </cerror>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   P(A|B)=\frac{0.99\times 0.001}{0.99\times 0.001+0.001\times 0.999}\approx 0.5,
  </annotation>
 </semantics>
</math>


</dd>
</dl>

<p>so that 1 − 0.5 = 0.5 now is the probability of a false positive.</p>
<h3 id="false-negatives">False negatives</h3>

<p>On the other hand, <a href="Type_I_and_type_II_errors" title="wikilink">false negatives</a> result when a test falsely or incorrectly reports a negative result. For example, a medical test for a disease may return a negative result indicating that patient does not have a disease even though the patient actually has the disease. We can also use Bayes' theorem to calculate the probability of a false negative. In the first example above,</p>
<dl>
<dd><math>\begin{align} P(A |\text{not }B) &amp;= \frac{P(\text{not }B | A) P(A)}{P(\text{not }B | A)P(A) + P(\text{not }B |\text{not }A)P(\text{not }A)} \\ \\
</math></dd>
</dl>

<p><code>&amp;= \frac{0.01\times 0.001}{0.01 \times 0.001 + 0.95\times 0.999} \\ ~\\ &amp;\approx 0.0000105.\end{align}</code></p>

<p>The probability that a negative result is a false negative is about 0.0000105 or 0.00105%. When a disease is rare, false negatives will not be a major problem with the test.</p>

<p>But if 60% of the population had the disease, then the probability of a false negative would be greater. With the above test, the probability of a false negative would be</p>
<dl>
<dd><math>\begin{align} P(A |\text{not }B) &amp; = \frac{P(\text{not }B | A) P(A)}{P(\text{not }B | A)P(A) + P(\text{not }B |\text{not } A) P(\text{not }A)} \\ \\
</math></dd>
</dl>

<p><code>&amp;= \frac{0.01\times 0.6}{0.01 \times 0.6 + 0.95\times 0.4} \\ ~\\ &amp;\approx 0.0155.\end{align}</code></p>

<p>The probability that a negative result is a false negative rises to 0.0155 or 1.55%.</p>
<h3 id="worked-example">Worked example</h3>
<h2 id="measuring-a-classifier-with-sensitivity-and-specificity">Measuring a classifier with sensitivity and specificity</h2>

<p>In training a classifier, one may wish to measure its performance using the well-accepted metrics of sensitivity and specificity. It may be instructive to compare the classifier to a random classifier that flips a coin based on the prevalence of a disease. Suppose that the probability a person has the disease is 

<math display="inline" id="Classification_rule:5">
 <semantics>
  <mi>p</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>p</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   p
  </annotation>
 </semantics>
</math>

 and the probability that they do not is 

<math display="inline" id="Classification_rule:6">
 <semantics>
  <mrow>
   <mi>q</mi>
   <mo>=</mo>
   <mrow>
    <mn>1</mn>
    <mo>-</mo>
    <mi>p</mi>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <ci>q</ci>
    <apply>
     <minus></minus>
     <cn type="integer">1</cn>
     <ci>p</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   q=1-p
  </annotation>
 </semantics>
</math>

. Suppose then that we have a random classifier that guesses that the patient has the disease with that same probability 

<math display="inline" id="Classification_rule:7">
 <semantics>
  <mi>p</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>p</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   p
  </annotation>
 </semantics>
</math>

 and guesses that he does not with the same probability 

<math display="inline" id="Classification_rule:8">
 <semantics>
  <mi>q</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>q</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   q
  </annotation>
 </semantics>
</math>


.</p>

<p>The probability of a true positive is the probability that the patient has the disease and the probability that the random classifier guesses this correcty, or 

<math display="inline" id="Classification_rule:9">
 <semantics>
  <msup>
   <mi>p</mi>
   <mn>2</mn>
  </msup>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">superscript</csymbol>
    <ci>p</ci>
    <cn type="integer">2</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   p^{2}
  </annotation>
 </semantics>
</math>

. With similar reasoning, the probability of a false negative is 

<math display="inline" id="Classification_rule:10">
 <semantics>
  <mrow>
   <mi>p</mi>
   <mi>q</mi>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <ci>p</ci>
    <ci>q</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   pq
  </annotation>
 </semantics>
</math>

. From the definitions above, the sensitivity of this classifier is 

<math display="inline" id="Classification_rule:11">
 <semantics>
  <mrow>
   <mrow>
    <msup>
     <mi>p</mi>
     <mn>2</mn>
    </msup>
    <mo>/</mo>
    <mrow>
     <mo stretchy="false">(</mo>
     <mrow>
      <msup>
       <mi>p</mi>
       <mn>2</mn>
      </msup>
      <mo>+</mo>
      <mrow>
       <mi>p</mi>
       <mi>q</mi>
      </mrow>
     </mrow>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
   <mo>=</mo>
   <mi>p</mi>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <divide></divide>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <ci>p</ci>
      <cn type="integer">2</cn>
     </apply>
     <apply>
      <plus></plus>
      <apply>
       <csymbol cd="ambiguous">superscript</csymbol>
       <ci>p</ci>
       <cn type="integer">2</cn>
      </apply>
      <apply>
       <times></times>
       <ci>p</ci>
       <ci>q</ci>
      </apply>
     </apply>
    </apply>
    <ci>p</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   p^{2}/(p^{2}+pq)=p
  </annotation>
 </semantics>
</math>

. With more similar reasoning, we can calculate the specificity as 

<math display="inline" id="Classification_rule:12">
 <semantics>
  <mrow>
   <mrow>
    <msup>
     <mi>q</mi>
     <mn>2</mn>
    </msup>
    <mo>/</mo>
    <mrow>
     <mo stretchy="false">(</mo>
     <mrow>
      <msup>
       <mi>q</mi>
       <mn>2</mn>
      </msup>
      <mo>+</mo>
      <mrow>
       <mi>p</mi>
       <mi>q</mi>
      </mrow>
     </mrow>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
   <mo>=</mo>
   <mi>q</mi>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <divide></divide>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <ci>q</ci>
      <cn type="integer">2</cn>
     </apply>
     <apply>
      <plus></plus>
      <apply>
       <csymbol cd="ambiguous">superscript</csymbol>
       <ci>q</ci>
       <cn type="integer">2</cn>
      </apply>
      <apply>
       <times></times>
       <ci>p</ci>
       <ci>q</ci>
      </apply>
     </apply>
    </apply>
    <ci>q</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   q^{2}/(q^{2}+pq)=q
  </annotation>
 </semantics>
</math>

.</p>

<p>So, while the measure itself is independent of disease prevalence, the performance of this random classifier depends on disease prevalence. The classifier may have performance that is like this random classifier, but with a better-weighted coin (higher sensitivity and specificity). So, these measures may be influenced by disease prevalence. An alternative measure of performance is the <a href="Matthews_correlation_coefficient" title="wikilink">Matthews correlation coefficient</a>, for which any random classifier will get an average score of 0.</p>

<p>The extension of this concept to non-binary classifications yields the <a href="confusion_matrix" title="wikilink">confusion matrix</a>.</p>
<h2 id="see-also">See also</h2>
<ul>
<li><a href="Bayesian_inference" title="wikilink">Bayesian inference</a></li>
<li><a href="Binary_classification" title="wikilink">Binary classification</a></li>
<li><a href="Diagnostic_test" title="wikilink">Diagnostic test</a></li>
<li><a href="Gold_standard_(test)" title="wikilink">Gold standard (test)</a></li>
<li><a href="Medical_test" title="wikilink">Medical test</a></li>
<li><a href="Sensitivity_and_specificity" title="wikilink">Sensitivity and specificity</a></li>
<li><a href="Statistical_classification" title="wikilink">Statistical classification</a></li>
</ul>
<h2 id="references">References</h2>
<references>
</references>

<p>"</p>

<p><a href="Category:Statistical_classification" title="wikilink">Category:Statistical classification</a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1"><a href="http://mathworld.wolfram.com/StatisticalTest.html">Mathworld article for statistical test</a><a href="#fnref1">↩</a></li>
<li id="fn2">Har-Peled, S., Roth, D., Zimak, D. (2003) "Constraint Classification for Multiclass Classification and Ranking." In: Becker, B., Thrun, S., Obermayer, K. (Eds) <em>Advances in Neural Information Processing Systems 15: Proceedings of the 2002 Conference</em>, MIT Press. ISBN 0-262-02550-7<a href="#fnref2">↩</a></li>
</ol>
</section>
</body>
</html>
