   Hindley–Milner type system      Hindley–Milner type system  In [[type theory]] and [[functional programming]], '''Hindley–Milner''' ('''HM''') (also known as '''Damas–Milner''' or '''Damas–Hindley–Milner''') is a classical [[type system]] for the [[lambda calculus]] with [[parametric polymorphism]], first described by [[J. Roger Hindley]] {{cite journal | authorlink = J. Roger Hindley | first = J. Roger | last = Hindley | date = 1969 | title = The Principal Type-Scheme of an Object in Combinatory Logic | journal = Transactions of the American Mathematical Society | volume = 146 | pages = 29–60 | jstor = 1 995158 }} and later rediscovered by Robin Milner . 1 Luis Damas contributed a close formal analysis and proof of the method in his PhD thesis. 2 3  Among HM's more notable properties is completeness and its ability to deduce the most general type of a given program without the need of any type annotations or other hints supplied by the programmer. Algorithm W is a fast algorithm, performing type inference in almost linear time with respect to the size of the source, making it practically usable to type large programs. 4 HM is preferably used for functional languages . It was first implemented as part of the type system of the programming language ML . Since then, HM has been extended in various ways, most notably by constrained types as used in Haskell .  Introduction  Organizing their original paper, Damas and Milner 5 clearly separated two very different tasks. One is to describe what types an expression can have and another to present an algorithm actually computing a type. Keeping both aspects apart from each other allows one to focus separately on the logic (i.e. meaning) behind the algorithm, as well as to establish a benchmark for the algorithm's properties.  How expressions and types fit to each other is described by means of a deductive system . Like any proof system , it allows different ways to come to a conclusion and since one and the same expression arguably might have different types, dissimilar conclusions about an expression are possible. Contrary to this, the type inference method itself ( Algorithm W ) is defined as a deterministic step-by-step procedure, leaving no choice what to do next. Thus clearly, decisions not present in the logic might have been made constructing the algorithm, which demand a closer look and justifications but would perhaps remain non-obvious without the above differentiation.  Syntax      Expressions           e    =    x    variable       |       e  1     e  2      application       |       λ    x    .  e     abstraction       |       𝚕𝚎𝚝   x   =     e  1     𝚒𝚗    e  2            e   x  variable     missing-subexpression   normal-|     subscript  e  1    subscript  e  2    application     missing-subexpression   normal-|   formulae-sequence    λ  x   e   abstraction     missing-subexpression   normal-|      𝚕𝚎𝚝  x      subscript  e  1   𝚒𝚗   subscript  e  2      missing-subexpression      \begin{array}[]{lrll}e&=&x&\textrm{variable}\\
 &|&e_{1}\ e_{2}&\textrm{application}\\
 &|&\lambda\ x\ .\ e&\textrm{abstraction}\\
 &|&\mathtt{let}\ x=e_{1}\ \mathtt{in}\ e_{2}\\
 \end{array}        Types           mono    τ    =    α     variable         |      D   τ  …  τ      application       poly    σ    =    τ         |      ∀   α    .  σ      quantifier                mono  τ   α  variable     missing-subexpression    missing-subexpression   normal-|    D  τ  normal-…  τ   application    poly  σ   τ   missing-subexpression      missing-subexpression    missing-subexpression   normal-|   formulae-sequence   for-all  α   σ   quantifier     missing-subexpression    missing-subexpression    missing-subexpression    missing-subexpression    missing-subexpression      \begin{array}[]{llrll}\textrm{mono}&\tau&=&\alpha&\ \textrm{variable}\\
 &&|&D\ \tau\dots\tau&\ \textrm{application}\\
 \textrm{poly}&\sigma&=&\tau\\
 &&|&\forall\ \alpha\ .\ \sigma&\ \textrm{quantifier}\\
 \\
 \end{array}        Logic and algorithm share the notions of "expression" and "type", whose form is made precise by the syntax .  The expressions to be typed are exactly those of the lambda calculus , enhanced by a let-expression. These are shown in the table to the right. For readers unfamiliar with the lambda calculus, here is a brief explanation: The application     e  1    e  2        subscript  e  1    subscript  e  2     e_{1}e_{2}   represents applying the function    e  1     subscript  e  1    e_{1}   to the argument    e  2     subscript  e  2    e_{2}   , often written     e  1    (   e  2   )        subscript  e  1    subscript  e  2     e_{1}(e_{2})   . The abstraction      λ    x    .  e     formulae-sequence    λ  x   e    \lambda\ x\ .\ e   represents an anonymous function that maps the input   x   x   x   to the output   e   e   e   . This is also called function literal, common in most contemporary programming languages, and sometimes written as     𝚏𝚞𝚗𝚌𝚝𝚒𝚘𝚗    (  x  )    𝚛𝚎𝚝𝚞𝚛𝚗    e   𝚎𝚗𝚍      𝚏𝚞𝚗𝚌𝚝𝚒𝚘𝚗  x  𝚛𝚎𝚝𝚞𝚛𝚗  e  𝚎𝚗𝚍    \mathtt{function}\,(x)\ \mathtt{return}\ e\ \mathtt{end}   . The let expression      𝚕𝚎𝚝   x   =     e  1     𝚒𝚗    e  2          𝚕𝚎𝚝  x      subscript  e  1   𝚒𝚗   subscript  e  2      \mathtt{let}\ x=e_{1}\ \mathtt{in}\ e_{2}   represents the result of substituting every occurrence of   x   x   x   in    e  2     subscript  e  2    e_{2}   with    e  1     subscript  e  1    e_{1}   .  Types as a whole are split into two groups, called mono- and polytypes. 6  Monotypes  Monotypes   τ   τ   \tau   are syntactically represented as terms . A monotype always designates a particular type, in the sense that it is equal only to itself and different from all others.  Examples of monotypes include type constants like   𝚒𝚗𝚝   𝚒𝚗𝚝   \mathtt{int}   or   𝚜𝚝𝚛𝚒𝚗𝚐   𝚜𝚝𝚛𝚒𝚗𝚐   \mathtt{string}   , and parametric types like     𝙼𝚊𝚙    (    𝚂𝚎𝚝   𝚜𝚝𝚛𝚒𝚗𝚐   )   𝚒𝚗𝚝      𝙼𝚊𝚙    𝚂𝚎𝚝  𝚜𝚝𝚛𝚒𝚗𝚐   𝚒𝚗𝚝    \mathtt{Map\ (Set\ string)\ int}   . These types are examples of applications of type functions, for example, from the set    {   𝙼𝚊𝚙  𝟸   ,   𝚂𝚎𝚝  𝟷   ,   𝚜𝚝𝚛𝚒𝚗𝚐  𝟶   ,   𝚒𝚗𝚝  𝟶   }      superscript  𝙼𝚊𝚙  2    superscript  𝚂𝚎𝚝  1    superscript  𝚜𝚝𝚛𝚒𝚗𝚐  0    superscript  𝚒𝚗𝚝  0     \{\mathtt{Map^{2},\ Set^{1},\ string^{0},\ int^{0}}\}   , where the superscript indicates the number of type parameters. The complete set of type functions   D   D   D   is arbitrary in HM, except that it must contain at least    →  2     superscript  normal-→  2    \rightarrow^{2}   , the type of functions. It is often written in infix notation for convenience. For example, a function mapping integers to strings has type    𝚒𝚗𝚝  →  𝚜𝚝𝚛𝚒𝚗𝚐     normal-→  𝚒𝚗𝚝  𝚜𝚝𝚛𝚒𝚗𝚐    \mathtt{int}\rightarrow\mathtt{string}   . 7  Type variables are monotypes. Standing alone, a type variable   α   α   \alpha   is meant to be as concrete as   𝚒𝚗𝚝   𝚒𝚗𝚝   \mathtt{int}   or   β   β   \beta   , and clearly different from both. Type variables occurring as monotypes behave as if they were type constants whose identity is unknown. Correspondingly, a function typed    α  →  α     normal-→  α  α    \alpha\rightarrow\alpha   only maps values of the particular type   α   α   \alpha   on itself. Such a function can only be applied to values having type   α   α   \alpha   and to no others.  Polytype  Polytypes (or type schemes ) are types containing variables bound by one or more for-all quantifiers, e.g.     ∀  α   .   α  →  α      formulae-sequence   for-all  α    normal-→  α  α     \forall\alpha.\alpha\rightarrow\alpha   .  A function with polytype     ∀  α   .   α  →  α      formulae-sequence   for-all  α    normal-→  α  α     \forall\alpha.\alpha\rightarrow\alpha   can map any value of the same type to itself, and the identity function is a value for this type. As another example     ∀  α   .    (    𝚂𝚎𝚝   α   )   →  𝚒𝚗𝚝      formulae-sequence   for-all  α    normal-→    𝚂𝚎𝚝  α   𝚒𝚗𝚝     \forall\alpha.(\mathtt{Set}\ \alpha)\rightarrow\mathtt{int}   is the type of a function mapping all finite sets to integers. The count of members is a value for this type. Note that quantifiers can only appear top level, i.e. a type     ∀  α   .   α  →   ∀  α    .  α     formulae-sequence   for-all  α    normal-→  α   for-all  α    α    \forall\alpha.\alpha\rightarrow\forall\alpha.\alpha   for instance, is excluded by the syntax of types and that monotypes are included in the polytypes, thus a type has the general form     ∀    α  1   …   ∀   α  n      .  τ     formulae-sequence   for-all     subscript  α  1   normal-…   for-all   subscript  α  n      τ    \forall\alpha_{1}\dots\forall\alpha_{n}.\tau   .  Free type variables      Free Type Variables            free   (   α   )        =   {  α  }         free   (    D    τ  1   …    τ  n     )        =    ⋃   i  =  1   n    free   (    τ  i    )           free   (  ∀   α   .   σ   )        =    free   (   σ   )    -   {  α  }             free  α     absent   α        free    D   subscript  τ  1   normal-…   subscript  τ  n       absent    superscript   subscript     i  1    n     free   subscript  τ  i         fragments  free   fragments  normal-(  for-all  α  normal-.  σ  normal-)      absent      free  σ    α        \begin{array}[]{ll}\text{free}(\ \alpha\ )&=\ \left\{\alpha\right\}\\
 \text{free}(\ D\ \tau_{1}\dots\tau_{n}\ )&=\ \bigcup\limits_{i=1}^{n}{\text{%
 free}(\ \tau_{i}\ )}\\
 \text{free}(\ \forall\ \alpha\ .\ \sigma\ )&=\ \text{free}(\ \sigma\ )\ -\ %
 \left\{\alpha\right\}\\
 \end{array}        In a type     ∀    α  1   …   ∀   α  n      .  τ     formulae-sequence   for-all     subscript  α  1   normal-…   for-all   subscript  α  n      τ    \forall\alpha_{1}\dots\forall\alpha_{n}.\tau   , the symbol   ∀   for-all   \forall   is the quantifier binding the type variables    α  i     subscript  α  i    \alpha_{i}   in the monotype   τ   τ   \tau   . The variables    α  i     subscript  α  i    \alpha_{i}   are called quantified and any occurrence of a quantified type variable in   τ   τ   \tau   is called bound and all unbound type variables in   τ   τ   \tau   are called free . Like in the lambda calculus , the notion of free and bound variables is essential for the understanding of the meaning of types.  This is certainly the hardest part of HM, perhaps because polytypes containing free variables are not represented in programming languages like Haskell . Likewise, one does not have clauses with free variables in Prolog . In particular developers experienced with both languages and actually knowing all the prerequisites of HM, are likely to slip this point. In Haskell for example, all type variables implicitly occur quantified, i.e. a Haskell type a -> a means     ∀  α   .   α  →  α      formulae-sequence   for-all  α    normal-→  α  α     \forall\alpha.\alpha\rightarrow\alpha   here. Because a type like    α  →  α     normal-→  α  α    \alpha\rightarrow\alpha   , though it may practically occur in a Haskell program, cannot be expressed there, it can easily be confused with its quantified version.  So what function can have a type like e.g.     ∀  β   .   β  →  α      formulae-sequence   for-all  β    normal-→  β  α     \forall\beta.\beta\rightarrow\alpha   , i.e. a mixture of both bound and free type variables and what could the free type variable   α   α   \alpha   therein mean?      Example 1             𝐥𝐞𝐭    𝑏𝑎𝑟    [  ∀  α  .  ∀  β  .  α  →   (  β  →  α  )   ]   =   λ   x  .         𝐥𝐞𝐭    𝑓𝑜𝑜    [  ∀  β  .  β  →  α  ]   =   λ   y  .  x         𝐢𝐧   𝑓𝑜𝑜         𝐢𝐧   𝑏𝑎𝑟          fragments  let  bar   fragments  normal-[  for-all  α  normal-.  for-all  β  normal-.  α  normal-→   fragments  normal-(  β  normal-→  α  normal-)   normal-]    λ  x  normal-.      fragments  let  foo   fragments  normal-[  for-all  β  normal-.  β  normal-→  α  normal-]    λ  y  normal-.  x       in  𝑓𝑜𝑜       in  𝑏𝑎𝑟      \begin{array}[]{l}\textbf{let}\ \mathit{bar}\ [\forall\alpha.\forall\beta.%
 \alpha\rightarrow(\beta\rightarrow\alpha)]=\lambda\ x.\\
 \quad\textbf{let}\ \mathit{foo}\ [\forall\beta.\beta\rightarrow\alpha]=\lambda%
 \ y.x\\
 \quad\textbf{in}\ \mathit{foo}\\
 \textbf{in}\ \mathit{bar}\end{array}        Consider   𝑓𝑜𝑜   𝑓𝑜𝑜   \mathit{foo}   in Example 1, with type annotations in brackets. Its parameter   y   y   y   is not used in the body, but the variable   x   x   x   bound in the outer context of   𝑓𝑜𝑜   𝑓𝑜𝑜   \mathit{foo}   surely is. As a consequence,   𝑓𝑜𝑜   𝑓𝑜𝑜   \mathit{foo}   accepts every value as argument, while returning a value bound outside and with it its type.   𝑏𝑎𝑟   𝑏𝑎𝑟   \mathit{bar}   to the contrary has type    ∀  α  .  ∀  β  .  α  →   (  β  →  α  )      fragments  for-all  α  normal-.  for-all  β  normal-.  α  normal-→   fragments  normal-(  β  normal-→  α  normal-)     \forall\alpha.\forall\beta.\alpha\rightarrow(\beta\rightarrow\alpha)   , in which all occurring type variables are bound. Evaluating, for instance    𝑏𝑎𝑟  1      𝑏𝑎𝑟  1    \mathit{bar}\ 1   , results in a function of type     ∀  β   .   β  →  𝑖𝑛𝑡      formulae-sequence   for-all  β    normal-→  β  𝑖𝑛𝑡     \forall\beta.\beta\rightarrow\ \mathit{int}   , perfectly reflecting that foo's monotype   α   α   \alpha   in     ∀  β   .   β  →  α      formulae-sequence   for-all  β    normal-→  β  α     \forall\beta.\beta\rightarrow\alpha   has been refined by this call.  In this example, the free monotype variable   α   α   \alpha   in foo's type becomes meaningful by being quantified in the outer scope, namely in bar's type. I.e. in context of the example, the same type variable   α   α   \alpha   appears both bound and free in different types. As a consequence, a free type variable cannot be interpreted better than stating it is a monotype without knowing the context. Turning the statement around, in general, a typing is not meaningful without a context.  Context and typing      Syntax           Context    Γ    =      ϵ    (  𝚎𝚖𝚙𝚝𝚢  )          |      Γ  ,  x   :  σ       Typing     =     Γ  ⊢  e  :  σ               Context  normal-Γ     ϵ  𝚎𝚖𝚙𝚝𝚢      missing-subexpression    missing-subexpression   normal-|   normal-:   normal-Γ  x   σ     Typing   missing-subexpression       proves  normal-Γ  e    normal-:    σ       missing-subexpression    missing-subexpression    missing-subexpression    missing-subexpression      \begin{array}[]{llrl}\text{Context}&\Gamma&=&\epsilon\ \mathtt{(empty)}\\
 &&|&\Gamma,\ x:\sigma\\
 \text{Typing}&&=&\Gamma\vdash e:\sigma\\
 \\
 \end{array}        Free Type Variables            free   (   Γ   )        =    ⋃   x  :   σ  ∈  Γ      free   (   σ   )              free  normal-Γ     absent    subscript    normal-:  x    σ  normal-Γ       free  σ        \begin{array}[]{ll}\text{free}(\ \Gamma\ )&=\ \bigcup\limits_{x:\sigma\in%
 \Gamma}\text{free}(\ \sigma\ )\end{array}        Consequently, to get the yet disjoint parts of the syntax, expressions and types together meaningfully, a third part, the context is needed. Syntactically, it is a list of pairs    x  :  σ     normal-:  x  σ    x:\sigma   , called assignments or assumptions , stating for each value variable    x  i     subscript  x  i    x_{i}   therein a type    σ  i     subscript  σ  i    \sigma_{i}   . All three parts combined gives a typing judgment of the form     Γ   ⊢  e  :  σ       proves  normal-Γ  e    normal-:    σ     \Gamma\ \vdash\ e:\sigma   , stating, that under assumptions   Γ   normal-Γ   \Gamma   , the expression   e   e   e   has type   σ   σ   \sigma   .  Now having the complete syntax at hand, one can finally make a meaningful statement about the type of   𝑓𝑜𝑜   𝑓𝑜𝑜   \mathit{foo}   in example 1, above, namely    x  :  α  ⊢   λ   y  .  x  :  ∀  β  .  β  →  α     fragments  x  normal-:  α  proves  λ  y  normal-.  x  normal-:  for-all  β  normal-.  β  normal-→  α    x:\alpha\vdash\lambda\ y.x:\forall\beta.\beta\rightarrow\alpha   . Contrary to the above formulations, the monotype variable   α   α   \alpha   no longer appears unbound, i.e. meaningless, but bound in the context as the type of the value variable   x   x   x   . The circumstance whether a type variable is bound or free in the context apparently plays a significant role for a type as part of a typing, so    free   (   Γ   )       free  normal-Γ    \text{free}(\ \Gamma\ )   it is made precise in the side box.  Polymorphic type order  While the equality of monotypes is purely syntactical, polytypes offer a richer structure by being related to other types through a specialization relation    σ  ⊑   σ  ′      square-image-of-or-equals  σ   superscript  σ  normal-′     \sigma\sqsubseteq\sigma^{\prime}   expressing that    σ  ′     superscript  σ  normal-′    \sigma^{\prime}   is more special than   σ   σ   \sigma   .  When being applied to a value a polymorphic function has to change its shape specializing to deal with this particular type of values. During this process, it also changes its type to match that of the parameter. If for instance the identity function having type     ∀  α   .   α  →  α      formulae-sequence   for-all  α    normal-→  α  α     \forall\alpha.\alpha\rightarrow\alpha   is to be applied on a number having type    i  n  t      i  n  t    int   , both simply cannot work together, because all the types are different and nothing fits. What is needed is a function of type     i  n  t   →   i  n  t      normal-→    i  n  t     i  n  t     int\rightarrow int   . Thus, during application, the polymorphic identity is specialized to a monomorphic version of itself. In terms of the specialization relation, one writes     ∀  α   .   α  →  α  ⊑   i  n  t   →   i  n  t       formulae-sequence   for-all  α      normal-→  α  α    square-image-of-or-equals      i  n  t     normal-→      i  n  t       \forall\alpha.\alpha\rightarrow\alpha\sqsubseteq\ int\rightarrow int     Now the shape shifting of polymorphic values is not fully arbitrary but rather limited by their pristine polytype. Following what has happened in the example one could paraphrase the rule of specialization, saying, a polymorphic type     ∀  α   .  τ     formulae-sequence   for-all  α   τ    \forall\alpha.\tau   is specialized by consistently replacing each occurrence of   α   α   \alpha   in   τ   τ   \tau   and dropping the quantifier. While this rule works well for any monotype used as replacement, it fails when a polytype, say     ∀  β   .  β     formulae-sequence   for-all  β   β    \forall\beta.\beta   is tried as a replacement, resulting in the non-syntactical type     ∀  β   .   β  →   ∀  β    .  β     formulae-sequence   for-all  β    normal-→  β   for-all  β    β    \forall\beta.\beta\rightarrow\forall\beta.\beta   . But not only that. Even if a type with nested quantified types would be allowed in the syntax, the result of the substitution would not longer preserve the property of the pristine type, in which both the parameter and the result of the function have the same type, which are now only seemingly equal because both subtypes became independent from each other allowing to specialize the parameter and the result with different types resulting in, e.g.     s  t  r  i  n  g   →   S  e   t   i  n  t      normal-→    s  t  r  i  n  g     S  e  t  i  n  t     string\rightarrow Set\ int   , hardly the right task for an identity function.  The syntactic restriction to allow quantification only top-level is imposed to prevent generalization while specializing. Instead of     ∀  β   .   β  →   ∀  β    .  β     formulae-sequence   for-all  β    normal-→  β   for-all  β    β    \forall\beta.\beta\rightarrow\forall\beta.\beta   , the more special type     ∀  β   .   β  →  β      formulae-sequence   for-all  β    normal-→  β  β     \forall\beta.\beta\rightarrow\beta   must be produced in this case.  One could undo the former specialization by specializing on some value of type     ∀  α   .  α     formulae-sequence   for-all  α   α    \forall\alpha.\alpha   again. In terms of the relation one gains     ∀  α   .   α  →  α  ⊑   ∀  β    .   β  →  β  ⊑   ∀  α    .   α  →  α      formulae-sequence   for-all  α      normal-→  α  α    square-image-of-or-equals     for-all  β        normal-→  β  β    square-image-of-or-equals     for-all  α      normal-→  α  α     \forall\alpha.\alpha\rightarrow\alpha\sqsubseteq\forall\beta.\beta\rightarrow%
 \beta\sqsubseteq\forall\alpha.\alpha\rightarrow\alpha   as a summary, meaning that syntactically different polytypes are equal with respect to renaming their quantified variables.      Specialization Rule            τ  ′   =   [   α  i   :=   τ  i   ]   τ   β  i   ∉  free   (  ∀   α  1   …  ∀   α  n   .  τ  )      ∀    α  1   …   ∀   α  n      .   τ  ⊑   ∀    β  1   …   ∀   β  m       .   τ  ′          fragments   superscript  τ  normal-′     fragments  normal-[   subscript  α  i   assign   subscript  τ  i   normal-]   τ    subscript  β  i    free   fragments  normal-(  for-all   subscript  α  1   normal-…  for-all   subscript  α  n   normal-.  τ  normal-)     formulae-sequence   for-all     subscript  α  1   normal-…   for-all   subscript  α  n       square-image-of-or-equals  τ   for-all     subscript  β  1   normal-…   for-all   subscript  β  m        superscript  τ  normal-′      \displaystyle\frac{\tau^{\prime}=\left[\alpha_{i}:=\tau_{i}\right]\tau\quad%
 \beta_{i}\not\in\textrm{free}(\forall\alpha_{1}...\forall\alpha_{n}.\tau)}{%
 \forall\alpha_{1}...\forall\alpha_{n}.\tau\sqsubseteq\forall\beta_{1}...%
 \forall\beta_{m}.\tau^{\prime}}        Now focusing only on the question whether a type is more special than another and no longer what the specialized type is used for, one could summarize the specialization as in the box above. Paraphrasing it clockwise, a type     ∀    α  1   …   ∀   α  n      .  τ     formulae-sequence   for-all     subscript  α  1   normal-…   for-all   subscript  α  n      τ    \forall\alpha_{1}\dots\forall\alpha_{n}.\tau   is specialized by consistently replacing any of the quantified variables    α  i     subscript  α  i    \alpha_{i}   by arbitrary monotypes    τ  i     subscript  τ  i    \tau_{i}   gaining a monotype    τ  ′     superscript  τ  normal-′    \tau^{\prime}   . Finally, type variables in    τ  ′     superscript  τ  normal-′    \tau^{\prime}   not occurring free in the pristine type can optionally be quantified.  Thus the specialization rules makes sure that no free variable, i.e. monotype in the pristine type becomes unintentionally bound by a quantifier, but originally quantified variable can be replaced with whatever, even with types introducing new quantified or unquantified type variables.  Starting with a polytype     ∀  α   .  α     formulae-sequence   for-all  α   α    \forall\alpha.\alpha   , the specialization could either replace the body by another quantified variable, actually a rename or by some type constant (including the function type) which may or may not have parameters filled either with monotypes or quantified type variables. Once a quantified variable is replaced by a type application, this specialization cannot be undone through another substitution as it was possible for quantified variables. Thus the type application is there to stay. Only if it contains another quantified type variable, the specialization could continue further replacing for it.  So the specialization introduces no further equivalence on polytype beside the already known renaming. Polytypes are syntactically equal up to renaming their quantified variables. The equality of types is a reflexive, antisymmetric and transitive relation and the remaining specializations of polytypes are transitive and with this the relation   ⊑   square-image-of-or-equals   \sqsubseteq   is an order .  Deductive system      The Syntax of Rules           Predicate    =     σ  ⊑   σ  ′         |     α  ∉   f  r  e  e   (  Γ  )          |     x  ;  :  α  ∈  Γ            Judgment    =    Typing      Premise    =      Judgment   |  Predicate       Conclusion    =    Judgment           Rule    =         Premise   …   Conclusion     [  𝙽𝚊𝚖𝚎  ]          Predicate    square-image-of-or-equals  σ   superscript  σ  normal-′       missing-subexpression   normal-|    α    f  r  e  e  normal-Γ       missing-subexpression   normal-|   fragments  x  normal-;  normal-:  α   Γ      missing-subexpression    missing-subexpression    missing-subexpression     Judgment   Typing    Premise    fragments  Judgment  normal-|  Predicate     Conclusion   Judgment     missing-subexpression    missing-subexpression    missing-subexpression     Rule        Premise  normal-…   Conclusion    delimited-[]  𝙽𝚊𝚖𝚎       \begin{array}[]{lrl}\text{Predicate}&=&\sigma\sqsubseteq\sigma^{\prime}\\
 &|&\alpha\not\in free(\Gamma)\\
 &|&x:\alpha\in\Gamma\\
 \\
 \text{Judgment}&=&\text{Typing}\\
 \text{Premise}&=&\text{Judgment}\ |\ \text{Predicate}\\
 \text{Conclusion}&=&\text{Judgment}\\
 \\
 \text{Rule}&=&\displaystyle\frac{\textrm{Premise}\ \dots}{\textrm{Conclusion}}%
 \quad[\mathtt{Name}]\end{array}        The syntax of HM is carried forward to the syntax of the inference rules that form the body of the formal system , by using the typings as judgments . Each of the rules define what conclusion could be drawn from what premises. Additionally to the judgments, some extra conditions introduced above might be used as premises, too.  A proof using the rules is a sequence of judgments such that all premises are listed before a conclusion. Please see the Examples 2 and 3 below for a possible format of proofs. From left to right, each line shows the conclusion, the    [  𝙽𝚊𝚖𝚎  ]     delimited-[]  𝙽𝚊𝚖𝚎    [\mathtt{Name}]   of the rule applied and the premises, either by referring to an earlier line (number) if the premise is a judgment or by making the predicate explicit.  Typing rules      Declarative Rule System              x  :   σ  ∈  Γ     Γ  ⊢  x  :  σ        [  𝚅𝚊𝚛  ]              Γ  ⊢   e  0   :   τ  →    τ  ′   Γ    ⊢   e  1   :  τ    Γ  ⊢     e  0     e  1    :   τ  ′         [  𝙰𝚙𝚙  ]               Γ  ,  x   :  τ  ⊢  e  :   τ  ′     Γ  ⊢   λ    x   .  e  :  τ  →   τ  ′         [  𝙰𝚋𝚜  ]              Γ  ⊢   e  0   :   σ  Γ  ,  x   :  σ  ⊢   e  1   :  τ    Γ  ⊢     𝚕𝚎𝚝   x   =     e  0     𝚒𝚗    e  1     :  τ        [  𝙻𝚎𝚝  ]                  Γ  ⊢  e  :     σ  ′    σ  ′    ⊑  σ     Γ  ⊢  e  :  σ        [  𝙸𝚗𝚜𝚝  ]              Γ  ⊢  e  :    σ  α   ∉   free   (  Γ  )       Γ  ⊢  e  :  ∀   α   .  σ        [  𝙶𝚎𝚗  ]                normal-:  x    σ  normal-Γ       proves  normal-Γ  x    normal-:    σ      delimited-[]  𝚅𝚊𝚛      missing-subexpression    missing-subexpression          proves  normal-Γ   subscript  e  0     normal-:     normal-→  τ    superscript  τ  normal-′   normal-Γ      proves     subscript  e  1     normal-:    τ       proves  normal-Γ     subscript  e  0    subscript  e  1      normal-:     superscript  τ  normal-′       delimited-[]  𝙰𝚙𝚙      missing-subexpression    missing-subexpression          normal-:   normal-Γ  x   τ    proves    e    normal-:     superscript  τ  normal-′      fragments  Γ  proves  λ  x  normal-.  e  normal-:  τ  normal-→   superscript  τ  normal-′      delimited-[]  𝙰𝚋𝚜      missing-subexpression    missing-subexpression          proves  normal-Γ   subscript  e  0     normal-:     σ  normal-Γ  x     normal-:    σ    proves     subscript  e  1     normal-:    τ       proves  normal-Γ      𝚕𝚎𝚝  x      subscript  e  0   𝚒𝚗   subscript  e  1       normal-:    τ      delimited-[]  𝙻𝚎𝚝      missing-subexpression    missing-subexpression      missing-subexpression    missing-subexpression          proves  normal-Γ  e    normal-:     square-image-of-or-equals    superscript  σ  normal-′    superscript  σ  normal-′    σ        proves  normal-Γ  e    normal-:    σ      delimited-[]  𝙸𝚗𝚜𝚝      missing-subexpression    missing-subexpression          proves  normal-Γ  e    normal-:       σ  α     free  normal-Γ       fragments  Γ  proves  e  normal-:  for-all  α  normal-.  σ     delimited-[]  𝙶𝚎𝚗      missing-subexpression    missing-subexpression      \begin{array}[]{cl}\displaystyle\frac{x:\sigma\in\Gamma}{\Gamma\vdash x:\sigma%
 }&[\mathtt{Var}]\\
 \\
 \displaystyle\frac{\Gamma\vdash e_{0}:\tau\rightarrow\tau^{\prime}\quad\quad%
 \Gamma\vdash e_{1}:\tau}{\Gamma\vdash e_{0}\ e_{1}:\tau^{\prime}}&[\mathtt{App%
 }]\\
 \\
 \displaystyle\frac{\Gamma,\;x:\tau\vdash e:\tau^{\prime}}{\Gamma\vdash\lambda%
 \ x\ .\ e:\tau\rightarrow\tau^{\prime}}&[\mathtt{Abs}]\\
 \\
 \displaystyle\frac{\Gamma\vdash e_{0}:\sigma\quad\quad\Gamma,\,x:\sigma\vdash e%
 _{1}:\tau}{\Gamma\vdash\mathtt{let}\ x=e_{0}\ \mathtt{in}\ e_{1}:\tau}&[%
 \mathtt{Let}]\\
 \\
 \\
 \displaystyle\frac{\Gamma\vdash e:\sigma^{\prime}\quad\sigma^{\prime}%
 \sqsubseteq\sigma}{\Gamma\vdash e:\sigma}&[\mathtt{Inst}]\\
 \\
 \displaystyle\frac{\Gamma\vdash e:\sigma\quad\alpha\notin\text{free}(\Gamma)}{%
 \Gamma\vdash e:\forall\ \alpha\ .\ \sigma}&[\mathtt{Gen}]\\
 \\
 \end{array}        The side box shows the deduction rules of the HM type system. One can roughly divide them into two groups:  The first four rules    [  𝚅𝚊𝚛  ]     delimited-[]  𝚅𝚊𝚛    [\mathtt{Var}]   (variable or function access),    [  𝙰𝚙𝚙  ]     delimited-[]  𝙰𝚙𝚙    [\mathtt{App}]   ( application , i.e. function call with one parameter),    [  𝙰𝚋𝚜  ]     delimited-[]  𝙰𝚋𝚜    [\mathtt{Abs}]   ( abstraction , i.e. function declaration) and    [  𝙻𝚎𝚝  ]     delimited-[]  𝙻𝚎𝚝    [\mathtt{Let}]   (variable declaration) are centered around the syntax, presenting one rule for each of the expression forms. Their meaning is pretty obvious at the first glance, as they decompose each expression, prove their sub-expressions and finally combine the individual types found in the premises to the type in the conclusion.  The second group is formed by the remaining two rules    [  𝙸𝚗𝚜𝚝  ]     delimited-[]  𝙸𝚗𝚜𝚝    [\mathtt{Inst}]   and    [  𝙶𝚎𝚗  ]     delimited-[]  𝙶𝚎𝚗    [\mathtt{Gen}]   . They handle specialization and generalization of types. While the rule    [  𝙸𝚗𝚜𝚝  ]     delimited-[]  𝙸𝚗𝚜𝚝    [\mathtt{Inst}]   should be clear from the section on specialization above,    [  𝙶𝚎𝚗  ]     delimited-[]  𝙶𝚎𝚗    [\mathtt{Gen}]   complements the former, working in the opposite direction. It allows generalization, i.e. to quantify monotype variables that are not bound in the context. The necessity of this restriction    α  ∉   f  r  e  e   (   Γ   )        α    f  r  e  e  normal-Γ     \alpha\not\in free(\ \Gamma\ )   is introduced in the section on free type variables .  The following two examples exercise the rule system in action  Example 2 : A proof for    Γ  ⊢   i  d   (  n  )    :   i  n  t        proves  normal-Γ    i  d  n     normal-:      i  n  t      \Gamma\vdash id(n):int   where    Γ  =  i  d  :  ∀  α  .  α  →  α  ,  n  :  i  n  t     fragments  Γ   i  d  normal-:  for-all  α  normal-.  α  normal-→  α  normal-,  n  normal-:  i  n  t    \Gamma=id:\forall\alpha.\alpha\rightarrow\alpha,\ n:int   , could be written         1  :       Γ  ⊢  i  d  :  ∀  α  .  α  →  α      [  𝚅𝚊𝚛  ]      (  i  d  :  ∀  α  .  α  →  α  ∈  Γ  )        2  :       Γ  ⊢   i  d   :    i  n  t   →   i  n  t        [  𝙸𝚗𝚜𝚝  ]       (  1  )   ,   (  ∀  α  .  α  →  α  ⊑  i  n  t  →  i  n  t  )         3  :       Γ  ⊢  n  :   i  n  t       [  𝚅𝚊𝚛  ]      (   n  :    i  n  t   ∈  Γ    )        4  :       Γ  ⊢   i  d   (  n  )    :   i  n  t       [  𝙰𝚙𝚙  ]       (  2  )   ,   (  3  )           normal-:  1  absent    fragments  Γ  proves  i  d  normal-:  for-all  α  normal-.  α  normal-→  α    delimited-[]  𝚅𝚊𝚛    fragments  normal-(  i  d  normal-:  for-all  α  normal-.  α  normal-→  α   Γ  normal-)      normal-:  2  absent      proves  normal-Γ    i  d     normal-:     normal-→    i  n  t     i  n  t       delimited-[]  𝙸𝚗𝚜𝚝    fragments   fragments  normal-(  1  normal-)   normal-,   fragments  normal-(  for-all  α  normal-.  α  normal-→  α  square-image-of-or-equals  i  n  t  normal-→  i  n  t  normal-)       normal-:  3  absent      proves  normal-Γ  n    normal-:      i  n  t      delimited-[]  𝚅𝚊𝚛    normal-:  n      i  n  t   normal-Γ       normal-:  4  absent      proves  normal-Γ    i  d  n     normal-:      i  n  t      delimited-[]  𝙰𝚙𝚙    2  3      \begin{array}[]{llll}1:&\Gamma\vdash id:\forall\alpha.\alpha\rightarrow\alpha&%
 [\mathtt{Var}]&(id:\forall\alpha.\alpha\rightarrow\alpha\in\Gamma)\\
 2:&\Gamma\vdash id:int\rightarrow int&[\mathtt{Inst}]&(1),\ (\forall\alpha.%
 \alpha\rightarrow\alpha\sqsubseteq int\rightarrow int)\\
 3:&\Gamma\vdash n:int&[\mathtt{Var}]&(n:int\in\Gamma)\\
 4:&\Gamma\vdash id(n):int&[\mathtt{App}]&(2),\ (3)\\
 \end{array}     Example 3 : To demonstrate generalization,    ⊢   𝐥𝐞𝐭   i  d  =  λ  x  .   x    𝐢𝐧   i   d   :  ∀  α  .  α  →  α     fragments  proves  let  i  d   λ  x  normal-.  x  in  i  d  normal-:  for-all  α  normal-.  α  normal-→  α    \vdash\ \textbf{let}\,id=\lambda x.x\ \textbf{in}\ id\,:\,\forall\alpha.\alpha\rightarrow\alpha   is shown below:         1  :       x  :  α  ⊢  x  :  α      [  𝚅𝚊𝚛  ]      (   x  :   α  ∈   {  x  :  α  }     )        2  :       ⊢  λ  x  .  x  :  α  →  α      [  𝙰𝚋𝚜  ]      (  1  )        3  :       ⊢  λ  x  .  x  :  ∀  α  .  α  →  α      [  𝙶𝚎𝚗  ]       (  2  )   ,   (  α  ∉  f  r  e  e   (  ϵ  )   )         4  :       i  d  :  ∀  α  .  α  →  α  ⊢  i  d  :  ∀  α  .  α  →  α      [  𝚅𝚊𝚛  ]      (  i  d  :  ∀  α  .  α  →  α  ∈   {  i  d  :  ∀  α  .  α  →  α  }   )        5  :       ⊢   𝐥𝐞𝐭   i  d  =  λ  x  .   x    𝐢𝐧   i   d   :  ∀  α  .  α  →  α      [  𝙻𝚎𝚝  ]       (  3  )   ,   (  4  )           normal-:  1  absent      normal-:  x  α    proves    x    normal-:    α     delimited-[]  𝚅𝚊𝚛    normal-:  x    α   conditional-set  x  α        normal-:  2  absent    fragments  proves  λ  x  normal-.  x  normal-:  α  normal-→  α    delimited-[]  𝙰𝚋𝚜   1     normal-:  3  absent    fragments  proves  λ  x  normal-.  x  normal-:  for-all  α  normal-.  α  normal-→  α    delimited-[]  𝙶𝚎𝚗    fragments   fragments  normal-(  2  normal-)   normal-,   fragments  normal-(  α   f  r  e  e   fragments  normal-(  ϵ  normal-)   normal-)       normal-:  4  absent    fragments  i  d  normal-:  for-all  α  normal-.  α  normal-→  α  proves  i  d  normal-:  for-all  α  normal-.  α  normal-→  α    delimited-[]  𝚅𝚊𝚛    fragments  normal-(  i  d  normal-:  for-all  α  normal-.  α  normal-→  α    fragments  normal-{  i  d  normal-:  for-all  α  normal-.  α  normal-→  α  normal-}   normal-)      normal-:  5  absent    fragments  proves  let  i  d   λ  x  normal-.  x  in  i  d  normal-:  for-all  α  normal-.  α  normal-→  α    delimited-[]  𝙻𝚎𝚝    3  4      \begin{array}[]{llll}1:&x:\alpha\vdash x:\alpha&[\mathtt{Var}]&(x:\alpha\in%
 \left\{x:\alpha\right\})\\
 2:&\vdash\lambda x.x:\alpha\rightarrow\alpha&[\mathtt{Abs}]&(1)\\
 3:&\vdash\lambda x.x:\forall\alpha.\alpha\rightarrow\alpha&[\mathtt{Gen}]&(2),%
 \ (\alpha\not\in free(\epsilon))\\
 4:&id:\forall\alpha.\alpha\rightarrow\alpha\vdash id:\forall\alpha.\alpha%
 \rightarrow\alpha&[\mathtt{Var}]&(id:\forall\alpha.\alpha\rightarrow\alpha\in%
 \left\{id:\forall\alpha.\alpha\rightarrow\alpha\right\})\\
 5:&\vdash\textbf{let}\,id=\lambda x.x\ \textbf{in}\ id\,:\,\forall\alpha.%
 \alpha\rightarrow\alpha&[\mathtt{Let}]&(3),\ (4)\\
 \end{array}     Principal type  As mentioned in the introduction , the rules allow one to deduce different types for one and the same expression. See for instance, Example 2, steps 1,2 and Example 3, steps 2,3 for three different typings of the same expression. Clearly, the different results are not fully unrelated, but connected by the type order . It is an important property of the rule system and this order that whenever more than one type can be deduced for an expression, among them is (modulo alpha-renaming of the type variables ) a unique most general type in the sense, that all others are specialization of it. Though the rule system must allow to derive specialized types, a type inference algorithm should deliver this most general or principal type as its result.  Let-polymorphism  Not visible immediately, the rule set encodes a regulation under which circumstances a type might be generalized or not by a slightly varying use of mono- and polytypes in the rules    [  𝙰𝚋𝚜  ]     delimited-[]  𝙰𝚋𝚜    [\mathtt{Abs}]   and    [  𝙻𝚎𝚝  ]     delimited-[]  𝙻𝚎𝚝    [\mathtt{Let}]   .  In rule    [  𝙰𝚋𝚜  ]     delimited-[]  𝙰𝚋𝚜    [\mathtt{Abs}]   , the value variable of the parameter of the function     λ  x   .  e     formulae-sequence    λ  x   e    \lambda x.e   is added to the context with a monomorphic type through the premise     Γ  ,  x   :  τ  ⊢  e  :   τ  ′        normal-:   normal-Γ  x   τ    proves    e    normal-:     superscript  τ  normal-′      \Gamma,\ x:\tau\vdash e:\tau^{\prime}   , while in the rule    [  𝙻𝚎𝚝  ]     delimited-[]  𝙻𝚎𝚝    [\mathtt{Let}]   , the variable enters the environment in polymorphic form     Γ  ,  x   :  σ  ⊢   e  1   :  τ       normal-:   normal-Γ  x   σ    proves     subscript  e  1     normal-:    τ     \Gamma,\ x:\sigma\vdash e_{1}:\tau   . Though in both cases the presence of x in the context prevents the use of the generalisation rule for any monotype variable in the assignment, this regulation forces the parameter x in a   λ   λ   \lambda   -expression to remain monomorphic, while in a let-expression, the variable could already be introduced polymorphic, making specializations possible.  As a consequence of this regulation, no type can be inferred for     λ  f   .   (    f   true   ,    f   0   )      formulae-sequence    λ  f      f  true     f  0      \lambda f.(f\,\textrm{true},f\,\textrm{0})   since the parameter   f   f   f   is in a monomorphic position, while       𝐥𝐞𝐭   f   =   λ  x    .    x    𝐢𝐧    (    f   true   ,    f   0   )       formulae-sequence      let  f     λ  x      x  in     f  true     f  0       \textbf{let}\ f=\lambda x.x\,\textbf{in}\,(f\,\textrm{true},f\,\textrm{0})   yields a type    (   b  o  o  l   ,   i  n  t   )       b  o  o  l     i  n  t     (bool,int)   , because   f   f   f   has been introduced in a let-expression and is treated polymorphic therefore. Note that this behaviour is in strong contrast to the usual definition     𝐥𝐞𝐭   x  =    e  1     𝐢𝐧     e  2    :  :=   (   λ   x  .   e  2   )    e  1      fragments  let  x    subscript  e  1   in   subscript  e  2   normal-:  assign   fragments  normal-(  λ  x  normal-.   subscript  e  2   normal-)    subscript  e  1     \textbf{let}\ x=e_{1}\ \textbf{in}\ e_{2}\ ::=(\lambda\ x.e_{2})\ e_{1}   and the reason why the let-expression appears in the syntax at all. This distinction is called let-polymorphism or let generalization and is a conception owed to HM.  Towards an algorithm  Now that the deduction system of HM is at hand, one could present an algorithm and validate it with respect to the rules. Alternatively, it might be possible to derive it by taking a closer look on how the rules interact and proof are formed. This is done in the remainder of this article focusing on the possible decisions one can make while proving a typing.  Degrees of freedom choosing the rules  Isolating the points in a proof, where no decision is possible at all, the first group of rules centered around the syntax leaves no choice since to each syntactical rule corresponds a unique typing rule, which determines a part of the proof, while between the conclusion and the premises of these fixed parts chains of    [  𝙸𝚗𝚜𝚝  ]     delimited-[]  𝙸𝚗𝚜𝚝    [\mathtt{Inst}]   and    [  𝙶𝚎𝚗  ]     delimited-[]  𝙶𝚎𝚗    [\mathtt{Gen}]   could occur. Such a chain could also exist between the conclusion of the proof and the rule for topmost expression. All proofs must have the so sketched shape.  Because the only choice in a proof with respect of rule selection are the    [  𝙸𝚗𝚜𝚝  ]     delimited-[]  𝙸𝚗𝚜𝚝    [\mathtt{Inst}]   and    [  𝙶𝚎𝚗  ]     delimited-[]  𝙶𝚎𝚗    [\mathtt{Gen}]   chains, the form of the proof suggests the question whether it can be made more precise, where these chains might be needed. This is in fact possible and leads to a variant of the rules system with no such rules.  Syntax-directed rule system      Syntactical Rule System              x  :    σ  ∈  Γ    τ  ⊑  σ      Γ  ⊢  x  :  τ        [  𝚅𝚊𝚛  ]              Γ  ⊢   e  0   :   τ  →    τ  ′   Γ    ⊢   e  1   :  τ    Γ  ⊢     e  0     e  1    :   τ  ′         [  𝙰𝚙𝚙  ]               Γ  ,  x   :  τ  ⊢  e  :   τ  ′     Γ  ⊢   λ    x   .  e  :  τ  →   τ  ′         [  𝙰𝚋𝚜  ]              Γ  ⊢   e  0   :   τ  Γ  ,  x   :    Γ  ¯    (  τ  )    ⊢   e  1   :   τ  ′     Γ  ⊢     𝚕𝚎𝚝   x   =     e  0     𝚒𝚗    e  1     :   τ  ′         [  𝙻𝚎𝚝  ]            normal-:  x   formulae-sequence    σ  normal-Γ    square-image-of-or-equals  τ  σ        proves  normal-Γ  x    normal-:    τ      delimited-[]  𝚅𝚊𝚛      missing-subexpression    missing-subexpression          proves  normal-Γ   subscript  e  0     normal-:     normal-→  τ    superscript  τ  normal-′   normal-Γ      proves     subscript  e  1     normal-:    τ       proves  normal-Γ     subscript  e  0    subscript  e  1      normal-:     superscript  τ  normal-′       delimited-[]  𝙰𝚙𝚙      missing-subexpression    missing-subexpression          normal-:   normal-Γ  x   τ    proves    e    normal-:     superscript  τ  normal-′      fragments  Γ  proves  λ  x  normal-.  e  normal-:  τ  normal-→   superscript  τ  normal-′      delimited-[]  𝙰𝚋𝚜      missing-subexpression    missing-subexpression          proves  normal-Γ   subscript  e  0     normal-:     τ  normal-Γ  x     normal-:       normal-¯  normal-Γ   τ     proves     subscript  e  1     normal-:     superscript  τ  normal-′        proves  normal-Γ      𝚕𝚎𝚝  x      subscript  e  0   𝚒𝚗   subscript  e  1       normal-:     superscript  τ  normal-′       delimited-[]  𝙻𝚎𝚝      \begin{array}[]{cl}\displaystyle\frac{x:\sigma\in\Gamma\quad\tau\sqsubseteq%
 \sigma}{\Gamma\vdash x:\tau}&[\mathtt{Var}]\\
 \\
 \displaystyle\frac{\Gamma\vdash e_{0}:\tau\rightarrow\tau^{\prime}\quad\quad%
 \Gamma\vdash e_{1}:\tau}{\Gamma\vdash e_{0}\ e_{1}:\tau^{\prime}}&[\mathtt{App%
 }]\\
 \\
 \displaystyle\frac{\Gamma,\;x:\tau\vdash e:\tau^{\prime}}{\Gamma\vdash\lambda%
 \ x\ .\ e:\tau\rightarrow\tau^{\prime}}&[\mathtt{Abs}]\\
 \\
 \displaystyle\frac{\Gamma\vdash e_{0}:\tau\quad\quad\Gamma,\,x:\bar{\Gamma}(%
 \tau)\vdash e_{1}:\tau^{\prime}}{\Gamma\vdash\mathtt{let}\ x=e_{0}\ \mathtt{in%
 }\ e_{1}:\tau^{\prime}}&[\mathtt{Let}]\end{array}        Generalization            Γ  ¯    (  τ  )    =   ∀    α  ^      .    τ   α  ^    =    free   (  τ  )    -   free   (  Γ  )         formulae-sequence       normal-¯  normal-Γ   τ    for-all   normal-^  α        τ   normal-^  α        free  τ     free  normal-Γ       \bar{\Gamma}(\tau)=\forall\ \hat{\alpha}\ .\ \tau\quad\quad\hat{\alpha}=%
 \textrm{free}(\tau)-\textrm{free}(\Gamma)        A contemporary treatment of HM uses a purely syntax-directed rule system due to Clement 8 as an intermediate step. In this system, the specialization is located directly after the original    [  𝚅𝚊𝚛  ]     delimited-[]  𝚅𝚊𝚛    [\mathtt{Var}]   rule and merged into it, while the generalization becomes part of the    [  𝙻𝚎𝚝  ]     delimited-[]  𝙻𝚎𝚝    [\mathtt{Let}]   rule. There the generalization is also determined to always produce the most general type by introducing the function     Γ  ¯    (  τ  )        normal-¯  normal-Γ   τ    \bar{\Gamma}(\tau)   , which quantifies all monotype variables not bound in   Γ   normal-Γ   \Gamma   .  Formally, to validate, that this new rule system    ⊢  S     subscript  proves  S    \vdash_{S}   is equivalent to the original    ⊢  D     subscript  proves  D    \vdash_{D}   , one has to show that    Γ    ⊢  D    e  :  σ  ⇔  Γ    ⊢  S    e  :  σ     fragments  Γ   subscript  proves  D   e  normal-:  σ  normal-⇔  Γ   subscript  proves  S   e  normal-:  σ    \Gamma\vdash_{D}\ e:\sigma\Leftrightarrow\Gamma\vdash_{S}\ e:\sigma   , which falls apart into two sub-proofs:       Γ    ⊢  D    e  :  σ  ⇐  Γ    ⊢  S    e  :  σ     fragments  Γ   subscript  proves  D   e  normal-:  σ  normal-⇐  Γ   subscript  proves  S   e  normal-:  σ    \Gamma\vdash_{D}\ e:\sigma\Leftarrow\Gamma\vdash_{S}\ e:\sigma   ( Consistency )      Γ    ⊢  D    e  :  σ  ⇒  Γ    ⊢  S    e  :  σ     fragments  Γ   subscript  proves  D   e  normal-:  σ  normal-⇒  Γ   subscript  proves  S   e  normal-:  σ    \Gamma\vdash_{D}\ e:\sigma\Rightarrow\Gamma\vdash_{S}\ e:\sigma   ( Completeness )   While consistency can be seen by decomposing the rules    [  𝙻𝚎𝚝  ]     delimited-[]  𝙻𝚎𝚝    [\mathtt{Let}]   and    [  𝚅𝚊𝚛  ]     delimited-[]  𝚅𝚊𝚛    [\mathtt{Var}]   of    ⊢  S     subscript  proves  S    \vdash_{S}   into proofs in    ⊢  D     subscript  proves  D    \vdash_{D}   , it is likely visible that    ⊢  S     subscript  proves  S    \vdash_{S}   is incomplete, as one cannot show     λ   x  .  x  :  ∀  α  .  α  →  α     fragments  λ  x  normal-.  x  normal-:  for-all  α  normal-.  α  normal-→  α    \lambda\ x.x:\forall\alpha.\alpha\rightarrow\alpha   in    ⊢  S     subscript  proves  S    \vdash_{S}   , for instance, but only     λ   x  .  x  :  α  →  α     fragments  λ  x  normal-.  x  normal-:  α  normal-→  α    \lambda\ x.x:\alpha\rightarrow\alpha   . An only slightly weaker version of completeness is provable 9 though, namely       Γ    ⊢  D    e  :  σ  ⇒  Γ    ⊢  S    e  :  τ  ∧   Γ  ¯    (  τ  )   ⊑  σ     fragments  Γ   subscript  proves  D   e  normal-:  σ  normal-⇒  Γ   subscript  proves  S   e  normal-:  τ    normal-¯  normal-Γ    fragments  normal-(  τ  normal-)   square-image-of-or-equals  σ    \Gamma\vdash_{D}\ e:\sigma\Rightarrow\Gamma\vdash_{S}\ e:\tau\wedge\bar{\Gamma%
 }(\tau)\sqsubseteq\sigma      implying, one can derive the principal type for an expression in    ⊢  S     subscript  proves  S    \vdash_{S}   allowing to generalize the proof in the end.  Comparing    ⊢  D     subscript  proves  D    \vdash_{D}   and    ⊢  S     subscript  proves  S    \vdash_{S}   note that only monotypes appear in the judgments of all rules, now.  Degrees of freedom instantiating the rules  Within the rules themselves, assuming a given expression, one is free to pick the instances for (rule) variables not occurring in this expression. These are the instances for the type variable in the rules. Working towards finding the most general type, this choice can be limited to picking suitable types for   τ   τ   \tau   in    [  𝚅𝚊𝚛  ]     delimited-[]  𝚅𝚊𝚛    [\mathtt{Var}]   and    [  𝙰𝚋𝚜  ]     delimited-[]  𝙰𝚋𝚜    [\mathtt{Abs}]   . The decision of a suitable choice cannot be made locally, but its quality becomes apparent in the premises of    [  𝙰𝚙𝚙  ]     delimited-[]  𝙰𝚙𝚙    [\mathtt{App}]   , the only rule, in which two different types, namely the function's formal and actual parameter type have to come together as one.  Therefore, the general strategy for finding a proof would be to make the most general assumption (    α  ∉   f  r  e  e   (  Γ  )        α    f  r  e  e  normal-Γ     \alpha\not\in free(\Gamma)   ) for   τ   τ   \tau   in    [  𝙰𝚋𝚜  ]     delimited-[]  𝙰𝚋𝚜    [\mathtt{Abs}]   and to refine this and the choice to be made in    [  𝚅𝚊𝚛  ]     delimited-[]  𝚅𝚊𝚛    [\mathtt{Var}]   until all side conditions imposed by the    [  𝙰𝚙𝚙  ]     delimited-[]  𝙰𝚙𝚙    [\mathtt{App}]   rules are finally met. Fortunately, no trial and error is needed, since an effective method is known to compute all the choices, Robinson's  Unification in combination with the so-called Union-Find algorithm.  To briefly summarize the union-find algorithm, given the set of all types in a proof, it allows one to group them together into equivalence classes by means of a   𝚞𝚗𝚒𝚘𝚗   𝚞𝚗𝚒𝚘𝚗   \mathtt{union}   procedure and to pick a representative for each such class using a   𝚏𝚒𝚗𝚍   𝚏𝚒𝚗𝚍   \mathtt{find}   procedure. Emphasizing on the word procedure in the sense of side effect , we're clearly leaving the realm of logic to prepare an effective algorithm. The representative of a    𝚞𝚗𝚒𝚘𝚗   (  a  ,  b  )       𝚞𝚗𝚒𝚘𝚗   a  b     \mathtt{union}(a,b)   is determined such, that if both   a   a   a   and   b   b   b   are type variables the representative is arbitrarily one of them, while uniting a variable and a term, the term becomes the representative. Assuming an implementation of union-find at hand, one can formulate the unification of two monotypes as follows:  unify(ta,tb):  ta = find(ta)  tb = find(tb)   if both ta,tb are terms of the form D p1..pn with identical D,n then  unify(ta[i],tb[i]) for each corresponding i th parameter   else   if at least one of ta,tb is a type variable then  union(ta,tb)   else  error 'types do not match'  Algorithm W      Algorithm W              x  :    σ  ∈  Γ    τ  =   𝑖𝑛𝑠𝑡   (  σ  )        Γ  ⊢  x  :  τ        [  𝚅𝚊𝚛  ]              Γ  ⊢   e  0   :   τ  0   Γ  ⊢   e  1   :   τ  1    τ  ′   =  𝑛𝑒𝑤𝑣𝑎𝑟  𝑢𝑛𝑖𝑓𝑦   (   τ  0   ,   τ  1   →   τ  ′   )     Γ  ⊢     e  0     e  1    :   τ  ′         [  𝙰𝚙𝚙  ]               τ  =   𝑛𝑒𝑤𝑣𝑎𝑟  Γ  ,  x    :  τ  ⊢  e  :   τ  ′     Γ  ⊢   λ    x   .  e  :  τ  →   τ  ′         [  𝙰𝚋𝚜  ]              Γ  ⊢   e  0   :   τ  Γ  ,  x   :    Γ  ¯    (  τ  )    ⊢   e  1   :   τ  ′     Γ  ⊢     𝚕𝚎𝚝   x   =     e  0     𝚒𝚗    e  1     :   τ  ′         [  𝙻𝚎𝚝  ]            normal-:  x   formulae-sequence    σ  normal-Γ     τ    𝑖𝑛𝑠𝑡  σ         proves  normal-Γ  x    normal-:    τ      delimited-[]  𝚅𝚊𝚛      missing-subexpression    missing-subexpression        fragments  Γ  proves   subscript  e  0   normal-:   subscript  τ  0    Γ  proves   subscript  e  1   normal-:   subscript  τ  1     superscript  τ  normal-′    newvar   unify   fragments  normal-(   subscript  τ  0   normal-,   subscript  τ  1   normal-→   superscript  τ  normal-′   normal-)       proves  normal-Γ     subscript  e  0    subscript  e  1      normal-:     superscript  τ  normal-′       delimited-[]  𝙰𝚙𝚙      missing-subexpression    missing-subexpression          normal-:    τ   𝑛𝑒𝑤𝑣𝑎𝑟  normal-Γ  x    τ    proves    e    normal-:     superscript  τ  normal-′      fragments  Γ  proves  λ  x  normal-.  e  normal-:  τ  normal-→   superscript  τ  normal-′      delimited-[]  𝙰𝚋𝚜      missing-subexpression    missing-subexpression          proves  normal-Γ   subscript  e  0     normal-:     τ  normal-Γ  x     normal-:       normal-¯  normal-Γ   τ     proves     subscript  e  1     normal-:     superscript  τ  normal-′        proves  normal-Γ      𝚕𝚎𝚝  x      subscript  e  0   𝚒𝚗   subscript  e  1       normal-:     superscript  τ  normal-′       delimited-[]  𝙻𝚎𝚝      \begin{array}[]{cl}\displaystyle\frac{x:\sigma\in\Gamma\quad\tau=\mathit{inst}%
 (\sigma)}{\Gamma\vdash x:\tau}&[\mathtt{Var}]\\
 \\
 \displaystyle\frac{\Gamma\vdash e_{0}:\tau_{0}\quad\Gamma\vdash e_{1}:\tau_{1}%
 \quad\tau^{\prime}=\mathit{newvar}\quad\mathit{unify}(\tau_{0},\ \tau_{1}%
 \rightarrow\tau^{\prime})}{\Gamma\vdash e_{0}\ e_{1}:\tau^{\prime}}&[\mathtt{%
 App}]\\
 \\
 \displaystyle\frac{\tau=\mathit{newvar}\quad\Gamma,\;x:\tau\vdash e:\tau^{%
 \prime}}{\Gamma\vdash\lambda\ x\ .\ e:\tau\rightarrow\tau^{\prime}}&[\mathtt{%
 Abs}]\\
 \\
 \displaystyle\frac{\Gamma\vdash e_{0}:\tau\quad\quad\Gamma,\,x:\bar{\Gamma}(%
 \tau)\vdash e_{1}:\tau^{\prime}}{\Gamma\vdash\mathtt{let}\ x=e_{0}\ \mathtt{in%
 }\ e_{1}:\tau^{\prime}}&[\mathtt{Let}]\end{array}        The presentation of Algorithm W as shown in the side box does not only deviate significantly from the original 10 but is also a gross abuse of the notation of logical rules, since it includes side effects. It is legitimized here, for allowing a direct comparison with    ⊢  S     subscript  proves  S    \vdash_{S}   while expressing an efficient implementation at the same time. The rules now specify a procedure with parameters    Γ  ,  e     normal-Γ  e    \Gamma,e   yielding   τ   τ   \tau   in the conclusion where the execution of the premises proceeds from left to right. Alternatively to a procedure, it could be viewed as an attributation of the expression.  The procedure    i  n  s  t   (  σ  )       i  n  s  t  σ    inst(\sigma)   specializes the polytype   σ   σ   \sigma   by copying the term and replacing the bound type variables consistently by new monotype variables. '    n  e  w  v  a  r      n  e  w  v  a  r    newvar   ' produces a new monotype variable. Likely,     Γ  ¯    (  τ  )        normal-¯  normal-Γ   τ    \bar{\Gamma}(\tau)   has to copy the type introducing new variables for the quantification to avoid unwanted captures. Overall, the algorithm now proceeds by always making the most general choice leaving the specialization to the unification, which by itself produces the most general result. As noted above , the final result   τ   τ   \tau   has to be generalized to     Γ  ¯    (  τ  )        normal-¯  normal-Γ   τ    \bar{\Gamma}(\tau)   in the end, to gain the most general type for a given expression.  Because the procedures used in the algorithm have nearly O(1) cost, the overall cost of the algorithm is close to linear in the size of the expression for which a type is to be inferred. This is in strong contrast to many other attempts to derive type inference algorithms, which often came out to be NP-hard , if not undecidable with respect to termination. Thus the HM performs as well as the best fully informed type-checking algorithms can. Type-checking here means that an algorithm does not have to find a proof, but only to validate a given one.  Efficiency is slightly reduced because the binding of type variables in the context has to be maintained to allow computation of     Γ  ¯    (  τ  )        normal-¯  normal-Γ   τ    \bar{\Gamma}(\tau)   and enable an occurs check to prevent the building of recursive types during    u  n  i  o  n   (  α  ,  τ  )       u  n  i  o  n   α  τ     union(\alpha,\tau)   . An example of such a case is      λ   x   .   (    x   x   )      formulae-sequence    λ  x     x  x     \lambda\ x.(x\ x)   , for which no type can be derived using HM. Practically, types are only small terms and do not build up expanding structures. Thus, in complexity analysis, one can treat comparing them as a constant, retaining O(1) costs.  Original presentation of Algorithm W  In the original paper, 11 the algorithm is presented more formally using a substitution style instead of side effects in the method above. In the latter form, the side effect invisibly takes care of all places where a type variable is used. Explicitly using substitutions not only makes the algorithm hard to read, because the side effect occurs virtually everywhere, but also gives the false impression that the method might be costly. When implemented using purely functional means or for the purpose of proving the algorithm to be basically equivalent to the deduction system, full explicitness is of course needed and the original formulation a necessary refinement.  Further topics  Recursive definitions  A central property of the lambda calculus is, that recursive definitions are non-elemental, but can instead be expressed by a fixed point combinator . The original paper 12 notes that recursion can realized by this combinator's type    𝑓𝑖𝑥  :  ∀  α  .   (  α  →  α  )   →  α     fragments  fix  normal-:  for-all  α  normal-.   fragments  normal-(  α  normal-→  α  normal-)   normal-→  α    \mathit{fix}:\forall\alpha.(\alpha\rightarrow\alpha)\rightarrow\alpha   . A possible recursive definitions could thus be formulated as     𝚛𝚎𝚌   v  =    e  1     𝚒𝚗     e  2    :  :=   𝚕𝚎𝚝   v  =  𝑓𝑖𝑥   (  λ  v  .   e  1   )    𝚒𝚗    e  2      fragments  rec  v    subscript  e  1   in   subscript  e  2   normal-:  assign  let  v   fix   fragments  normal-(  λ  v  normal-.   subscript  e  1   normal-)   in   subscript  e  2     \mathtt{rec}\ v=e_{1}\ \mathtt{in}\ e_{2}\ ::=\mathtt{let}\ v=\mathit{fix}(%
 \lambda v.e_{1})\ \mathtt{in}\ e_{2}   .  Alternatively an extension of the expression syntax and an extra typing rule is possible as:         Γ  ,   Γ  ′    ⊢   e  1   :    τ  1   …  Γ  ,   Γ  ′    ⊢   e  n   :    τ  n   Γ  ,   Γ  ′′    ⊢  e  :  τ     Γ   ⊢     𝚛𝚎𝚌    v  1    =     e  1     𝚊𝚗𝚍    …    𝚊𝚗𝚍    v  n    =     e  n     𝚒𝚗   e    :  τ     [  𝚁𝚎𝚌  ]           proves   normal-Γ   superscript  normal-Γ  normal-′     subscript  e  1     normal-:      subscript  τ  1   normal-…  normal-Γ   superscript  normal-Γ  normal-′      proves     subscript  e  n     normal-:      subscript  τ  n   normal-Γ   superscript  normal-Γ  ′′      proves    e    normal-:    τ       proves  normal-Γ        𝚛𝚎𝚌   subscript  v  1       subscript  e  1   𝚊𝚗𝚍  normal-…  𝚊𝚗𝚍   subscript  v  n            subscript  e  n   𝚒𝚗  e       normal-:    τ      delimited-[]  𝚁𝚎𝚌     \displaystyle\frac{\Gamma,\Gamma^{\prime}\vdash e_{1}:\tau_{1}\quad\dots\quad%
 \Gamma,\Gamma^{\prime}\vdash e_{n}:\tau_{n}\quad\Gamma,\Gamma^{\prime\prime}%
 \vdash e:\tau}{\Gamma\ \vdash\ \mathtt{rec}\ v_{1}=e_{1}\ \mathtt{and}\ \dots%
 \ \mathtt{and}\ v_{n}=e_{n}\ \mathtt{in}\ e:\tau}\quad[\mathtt{Rec}]     where         Γ  ′   =   v  1    :    τ  1   ,  …  ,   v  n    :   τ  n        normal-:     superscript  normal-Γ  normal-′    subscript  v  1      subscript  τ  1   normal-…   subscript  v  n      normal-:     subscript  τ  n      \Gamma^{\prime}=v_{1}:\tau_{1},\ \dots,\ v_{n}:\tau_{n}           Γ  ′′   =   v  1    :     Γ  ¯    (    τ  1    )    ,  …  ,   v  n    :    Γ  ¯    (    τ  n    )         normal-:     superscript  normal-Γ  ′′    subscript  v  1        normal-¯  normal-Γ    subscript  τ  1    normal-…   subscript  v  n      normal-:       normal-¯  normal-Γ    subscript  τ  n       \Gamma^{\prime\prime}=v_{1}:\bar{\Gamma}(\ \tau_{1}\ ),\ \dots,\ v_{n}:\bar{%
 \Gamma}(\ \tau_{n}\ )      basically merging    [  𝙰𝚋𝚜  ]     delimited-[]  𝙰𝚋𝚜    [\mathtt{Abs}]   and    [  𝙻𝚎𝚝  ]     delimited-[]  𝙻𝚎𝚝    [\mathtt{Let}]   while including the recursively defined variables in monotype positions where they occur left to the   𝚒𝚗   𝚒𝚗   \mathtt{in}   but as polytypes right to it. This formulation perhaps best summarizes the essence of let-polymorphism .  Notes  References      External links   A literate Haskell implementation of Algorithm W along with its source code on GitHub .   "  Category:Type systems  Category:Type theory  Category:Type inference  Hindley-Milner type system  Category:Theoretical computer science  Category:Formal methods  Category:1969 in computer science  Category:1978 in computer science  Category:1985 in computer science  Category:Algorithms     ↩  ↩  ↩  Hindley–Milner is DEXPTIME -complete. However, non-linear behaviour only manifests itself on pathological inputs, as such the complexity theoretic proofs by  and  came as a surprise to the research community. When the depth of nested let-bindings is bounded—as is the case in realistic programs—Hindley–Milner type inference becomes polynomial. ↩   Polytypes are called "type schemes" in the original article. ↩  The parametric types     D   τ  …  τ      D  τ  normal-…  τ    D\ \tau\dots\tau   were not present in the original paper on HM and are not needed to present the method. None of the inference rules below will take care or even note them. The same holds for the non-parametric "primitive types" in said paper. All the machinery for polymorphic type inference can be defined without them. They have been included here for sake of examples but also because the nature of HM is all about parametric types. This comes from the function type    τ  →  τ     normal-→  τ  τ    \tau\rightarrow\tau   , hard-wired in the inference rules, below, which already has two parameters and has been presented here as only a special case. ↩  ↩  ↩        