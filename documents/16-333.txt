   Hermite distribution      Hermite distribution   | kurtosis =      a  1   +   16   a  2       (    a  1   +   4   a  2     )   2          subscript  a  1     16   subscript  a  2      superscript     subscript  a  1     4   subscript  a  2     2     \frac{a_{1}+16a_{2}}{(a_{1}+4a_{2})^{2}}   | pgf =    exp   (     a  1    (   s  -  1   )    +    a  2    (    s  2   -  1   )     )            subscript  a  1     s  1       subscript  a  2      superscript  s  2   1       \exp(a_{1}(s-1)+a_{2}(s^{2}-1))\,   | mgf =    exp   (     a  1    (    e  t   -  1   )    +    a  2    (    e   2  t    -  1   )     )            subscript  a  1      superscript  e  t   1       subscript  a  2      superscript  e    2  t    1       \exp(a_{1}(e^{t}-1)+a_{2}(e^{2t}-1))\,   | char =    exp   (     a  1    (    e   t  i    -  1   )    +    a  2    (    e   2  t  i    -  1   )     )            subscript  a  1      superscript  e    t  i    1       subscript  a  2      superscript  e    2  t  i    1       \exp(a_{1}(e^{ti}-1)+a_{2}(e^{2ti}-1))\,   }}  In probability theory and statistics , the Hermite distribution , named after Charles Hermite , is a discrete probability distribution used to model count data with more than one parameter. This distribution is flexible in terms of its ability to allow a moderate over-dispersion in the data. The Hermite distribution is a special case of the Poisson binomial distribution , when n = 2.  The authors Kemp and Kemp 1 have called it "Hermite distribution" from the fact its probability function and the moment generating function can be expressed in terms of the coefficients of (modified) Hermite polynomials .  History  The distribution first appeared in the paper Applications of Mathematics to Medical Problems , 2 by Anderson Gray McKendrick in 1926. In this work the author explains several mathematical methods that can be applied to medical research. In one of this methods he considered the bivariate Poisson distribution and showed that the distribution of the sum of two correlated Poisson variables follow a distribution that later would be known as Hermite distribution.  As a practical application, McKendrick considered the distribution of counts of bacteria in leucocytes . Using the method of moments he fitted the data with the Hermite distribution and found the model more satisfactory than fitting it with a Poisson distribution .  The distribution was formally introduced and published by C. D. Kemp and Adrienne W.Kemp in 1965 in their work Some Properties of ‘Hermite’ Distribution . The work is focused on the properties of this distribution for instance a necessary condition on the parameters and their Maximum Likelihood (MLE), the analysis of the probability generating function (PGF) and how it can be expressed in terms of the coefficients of (modified) Hermite polynomials . An example they have used in this publication is the distribution of counts of bacteria in leucocytes that used McKendrick but Kemp and Kemp estimate the model using the maximum likelihood method.  Hermite distribution is is a special case of discrete compound Poisson distribution with only 2 parameters. 3  4  The same authors published in 1966 the paper An alternative Derivation of the Hermite Distribution . 5 In this work established that the Hermite distribution can be obtained formally by combining a Poisson distribution with a Normal distribution .  In 1971, Y. C. Patel 6 did a comparative study of various estimation procedures for the Hermite distribution in his doctoral thesis. It included maximum likelihood, moment estimators, mean and zero frequency estimators and the method of even points.  In 1974, Gupta and Jain 7 did a research on a generalized form of Hermite distribution.  In the probabilistic number theory, due to Bekelis's work, 8 when a strongly additive function     f  x    (  m  )   ,   (  x  ≥  1  )      fragments   subscript  f  x    fragments  normal-(  m  normal-)   normal-,   fragments  normal-(  x   1  normal-)     {f_{x}}(m),(x\geq 1)   only takes value {0,1,2} on prime number p , under some conditions, then the frequent number of     f  x    (  m  )        subscript  f  x   m    {f_{x}}(m)   convergent to a Hermite distribution for    x  →  ∞     normal-→  x     x\to\infty   . 9  Definition  Probability mass function  Let X 1 and X 2 be two independent Poisson variables with parameters a 1 and a 2 . The probability distribution of the random variable  Y = X 1 + 2 X 2 is the Hermite distribution with parameters a 1 and a 2 and probability mass function is given by 10       p  n   =  P   (  Y  =  n  )   =   e   [    -   a  1    +   a  2    ]     ∑   j  =  0    [   n  /  2   ]       a  1   n  -   2  j      a  2  j       (   n  -   2  j    )   !    j  !        fragments   subscript  p  n    P   fragments  normal-(  Y   n  normal-)     superscript  e   delimited-[]       subscript  a  1     subscript  a  2       superscript   subscript     j  0     delimited-[]    n  2          superscript   subscript  a  1     n    2  j      superscript   subscript  a  2   j          n    2  j       j       p_{n}=P(Y=n)=e^{[-a_{1}+a_{2}]}\sum_{j=0}^{[n/2]}\frac{a_{1}^{n-2j}a_{2}^{j}}{%
 (n-2j)!j!}     where   n = 0, 1, 2, ...  a 1 , a 2 ≥ 0.  ( n − 2 j )! and j ! are the factorial of ( n − 2 j ) and j , respectively.  [ n /2] is the integer part of [ n /2].   As a special case of discrete compound Poisson, there are at least ten approaches to proving the probability mass function of Hermite distribution. 11  The probability generating function of the probability mass is, 12        G  Y    (  s  )    =    ∑   n  =  0   ∞     p  n    s  n     =   exp   (     a  1    (   s  -  1   )    +    a  2    (    s  2   -  1   )     )             subscript  G  Y   s     superscript   subscript     n  0         subscript  p  n    superscript  s  n                 subscript  a  1     s  1       subscript  a  2      superscript  s  2   1         G_{Y}(s)=\sum_{n=0}^{\infty}p_{n}s^{n}=\exp(a_{1}(s-1)+a_{2}(s^{2}-1))     Notation  When a random variable  Y = X 1 + 2 X 2 is distributed by an Hermite distribution, where X 1 and X 2 are two independent Poisson variables with parameters a 1 and a 2 , we write       Y   ∼   Herm   (   a  1   ,   a  2   )       similar-to  Y    Herm    subscript  a  1    subscript  a  2       Y\ \sim\ \mathrm{Herm}(a_{1},a_{2})\,     Properties  Moment and cumulant generating functions  The moment generating function of a random variable X is defined as the expected value of e t , as a function of the real parameter t . For an Hermite distribution with parameters X 1 and X 2 , the moment generating function exists and is equal to       M   (  t  )    =   G   (   e  t   )    =   exp   (     a  1    (    e  t   -  1   )    +    a  2    (    e   2  t    -  1   )     )            M  t     G   superscript  e  t                subscript  a  1      superscript  e  t   1       subscript  a  2      superscript  e    2  t    1         M(t)=G(e^{t})=\exp(a_{1}(e^{t}-1)+a_{2}(e^{2t}-1))     The cumulant generating function is the logarithm of the moment generating function and is equal to 13       K   (  t  )    =   log   (   M   (  t  )    )    =     a  1    (    e  t   -  1   )    +    a  2    (    e   2  t    -  1   )             K  t       M  t              subscript  a  1      superscript  e  t   1       subscript  a  2      superscript  e    2  t    1        K(t)=\log(M(t))=a_{1}(e^{t}-1)+a_{2}(e^{2t}-1)     If we consider the coefficient of ( it ) r r ! in the expansion of K ( t ) we obtain the r -cumulant       k  n   =    a  1   +    2  n    a  2          subscript  k  n      subscript  a  1      superscript  2  n    subscript  a  2       k_{n}=a_{1}+2^{n}a_{2}     Hence the mean and the succeeding three moments about it are      Order   Moment   Cumulant       1        μ  1   =   k  1   =    a  1   +   2   a  2            subscript  μ  1    subscript  k  1           subscript  a  1     2   subscript  a  2        \mu_{1}=k_{1}=a_{1}+2a_{2}         μ   μ   \mu        2        μ  2   =   k  2   =    a  1   +   4   a  2            subscript  μ  2    subscript  k  2           subscript  a  1     4   subscript  a  2        \mu_{2}=k_{2}=a_{1}+4a_{2}          σ  2     superscript  σ  2    \sigma^{2}        3        μ  3   =   k  3   =    a  1   +   8   a  2            subscript  μ  3    subscript  k  3           subscript  a  1     8   subscript  a  2        \mu_{3}=k_{3}=a_{1}+8a_{2}          k  3     subscript  k  3    k_{3}        4        μ  4   =    k  4   +   3   k  2  2     =    a  1   +   16   a  2    +   3    (    a  1   +   4   a  2     )   2            subscript  μ  4      subscript  k  4     3   superscript   subscript  k  2   2             subscript  a  1     16   subscript  a  2      3   superscript     subscript  a  1     4   subscript  a  2     2        \mu_{4}=k_{4}+3k_{2}^{2}=a_{1}+16a_{2}+3(a_{1}+4a_{2})^{2}          k  4     subscript  k  4    k_{4}        Skewness  The skewness is the third moment centered around the mean divided by the 3/2 power of the standard deviation , and for the hermite distribution is, 14       γ  1   =    μ  3    μ  2   3  /  2     =    (    a  1   +   8   a  2     )     (    a  1   +   4   a  2     )    3  /  2            subscript  γ  1      subscript  μ  3    superscript   subscript  μ  2     3  2               subscript  a  1     8   subscript  a  2      superscript     subscript  a  1     4   subscript  a  2       3  2        \gamma_{1}=\frac{\mu_{3}}{\mu_{2}^{3/2}}=\frac{(a_{1}+8a_{2})}{(a_{1}+4a_{2})^%
 {3/2}}      Always     γ  1   >  0       subscript  γ  1   0    \gamma_{1}>0   , so the mass of the distribution is concentrated on the left.   Kurtosis  The kurtosis is the fourth moment centered around the mean, divided by the square of the variance , and for the Hermite distribution is, 15       β  2   =    μ  4    μ  2  2    =     a  1   +   16   a  2    +   3    (    a  1   +   4   a  2     )   2       (    a  1   +   4   a  2     )   2    =      a  1   +   16   a  2       (    a  1   +   4   a  2     )   2    +  3          subscript  β  2      subscript  μ  4    superscript   subscript  μ  2   2              subscript  a  1     16   subscript  a  2      3   superscript     subscript  a  1     4   subscript  a  2     2      superscript     subscript  a  1     4   subscript  a  2     2                subscript  a  1     16   subscript  a  2      superscript     subscript  a  1     4   subscript  a  2     2    3      \beta_{2}=\frac{\mu_{4}}{\mu_{2}^{2}}=\frac{a_{1}+16a_{2}+3(a_{1}+4a_{2})^{2}}%
 {(a_{1}+4a_{2})^{2}}=\frac{a_{1}+16a_{2}}{(a_{1}+4a_{2})^{2}}+3     The excess kurtosis is just a correction to make the kurtosis of the normal distribution equal to zero, and it is the following,       γ  2   =     μ  4    μ  2  2    -  3   =     a  1   +   16   a  2       (    a  1   +   4   a  2     )   2           subscript  γ  2        subscript  μ  4    superscript   subscript  μ  2   2    3             subscript  a  1     16   subscript  a  2      superscript     subscript  a  1     4   subscript  a  2     2       \gamma_{2}=\frac{\mu_{4}}{\mu_{2}^{2}}-3=\frac{a_{1}+16a_{2}}{(a_{1}+4a_{2})^{%
 2}}      Always     β  2   >  3       subscript  β  2   3    \beta_{2}>3   , or     γ  2   >  0       subscript  γ  2   0    \gamma_{2}>0   the distribution has a high acute peak around the mean and fatter tails.   Characteristic function  In a discrete distribution the characteristic function of any real-valued random variable is defined as the expected value of    e   i  t  X      superscript  e    i  t  X     e^{itX}   , where i is the imaginary unit and t ∈ R      ϕ   (  t  )   =  E   [   e   i  t  X    ]   =   ∑   j  =  0   ∞    e   i  j  t    P   [  X  =  j  ]      fragments  ϕ   fragments  normal-(  t  normal-)    E   fragments  normal-[   superscript  e    i  t  X    normal-]     superscript   subscript     j  0       superscript  e    i  j  t    P   fragments  normal-[  X   j  normal-]     \phi(t)=E[e^{itX}]=\sum_{j=0}^{\infty}e^{ijt}P[X=j]     This function is related to the moment-generating function via      ϕ  x    (  t  )    =    M  X    (   i  t   )           subscript  ϕ  x   t      subscript  M  X     i  t      \phi_{x}(t)=M_{X}(it)   . Hence for this distribution the characteristic function is, 16        ϕ  x    (  t  )    =   exp   (     a  1    (    e   i  t    -  1   )    +    a  2    (    e   2  i  t    -  1   )     )           subscript  ϕ  x   t          subscript  a  1      superscript  e    i  t    1       subscript  a  2      superscript  e    2  i  t    1        \phi_{x}(t)=\exp(a_{1}(e^{it}-1)+a_{2}(e^{2it}-1))     Cumulative distribution function  The cumulative distribution function is, 17      F   (  x  ;   a  1   ,   a  2   )       F   x   subscript  a  1    subscript  a  2      \displaystyle F(x;a_{1},a_{2})     Other properties   This distribution can have any number of modes . As an example, the fitted distribution for McKendrick’s 18 data has an estimated parameters of      a  1   ^   =  0.0135       normal-^   subscript  a  1    0.0135    \hat{a_{1}}=0.0135   ,      a  2   ^   =  0.0932       normal-^   subscript  a  2    0.0932    \hat{a_{2}}=0.0932   . Therefore, the first five estimated probabilities are 0.899, 0.012, 0.084, 0.001, 0.004.   (Figure)  Example of a multi-modal data, Hermite Distribution(0.1,1.5).    This distribution is closed under addition or closed under convolutions. 19 As the Poisson distribution , the Hermite distribution has this property. Given 2 random Hermite variables     X  1   ∼   Herm   (   a  1   ,   a  2   )       similar-to   subscript  X  1     Herm    subscript  a  1    subscript  a  2       X_{1}\sim\mathrm{Herm}(a_{1},a_{2})   and     X  2   ∼   Herm   (   b  1   ,   b  2   )       similar-to   subscript  X  2     Herm    subscript  b  1    subscript  b  2       X_{2}\sim\mathrm{Herm}(b_{1},b_{2})   , then Y = X 1 + X 2 follows an Hermite distribution,    Y  ∼   Herm   (    a  1   +   b  1    ,    a  2   +   b  2    )       similar-to  Y    Herm      subscript  a  1    subscript  b  1       subscript  a  2    subscript  b  2        Y\sim\mathrm{Herm}(a_{1}+b_{1},a_{2}+b_{2})   .    This distribution allows a moderate overdispersion , so it can be used when data has this property. 20 A random variable has overdispersion, or it is overdispersed with respect the Poisson distribution, when its variance is greater than its expected value. The Hermite distribution allows a moderate overdispersion because the coefficient of dispersion is always between 1 and 2,       d  =    Var   (  Y  )     E   (  y  )     =     a  1   +   4   a  2       a  1   +   2   a  2      =   1  +    2   a  2      a  1   +   2   a  2             d      Var  Y     E  y              subscript  a  1     4   subscript  a  2        subscript  a  1     2   subscript  a  2             1      2   subscript  a  2       subscript  a  1     2   subscript  a  2          d=\frac{\mathrm{Var}(Y)}{E(y)}=\frac{a_{1}+4a_{2}}{a_{1}+2a_{2}}=1+\frac{2a_{2%
 }}{a_{1}+2a_{2}}     Parameter estimation  Method of moments  The mean and the variance of the Hermite distribution are    μ  =    a  1   +   2   a  2         μ     subscript  a  1     2   subscript  a  2       \mu=a_{1}+2a_{2}   and     σ  2   =    a  1   +   4   a  2          superscript  σ  2      subscript  a  1     4   subscript  a  2       \sigma^{2}=a_{1}+4a_{2}   , respectively. So we have these two equation,      {       x  ¯   =    a  1   +   2   a  2             σ  2   =    a  1   +   4   a  2             cases     normal-¯  x      subscript  a  1     2   subscript  a  2      otherwise     superscript  σ  2      subscript  a  1     4   subscript  a  2      otherwise    \begin{cases}\bar{x}=a_{1}+2a_{2}\\
 \sigma^{2}=a_{1}+4a_{2}\end{cases}     Solving these two equation we get the moment estimators     a  1   ^     normal-^   subscript  a  1     \hat{a_{1}}   and     a  2   ^     normal-^   subscript  a  2     \hat{a_{2}}   of a 1 and a 2 . 21        a  1   ^   =    2   x  ¯    -   σ  2         normal-^   subscript  a  1        2   normal-¯  x     superscript  σ  2      \hat{a_{1}}=2\bar{x}-\sigma^{2}           a  2   ^   =     σ  2   -   x  ^    2        normal-^   subscript  a  2         superscript  σ  2    normal-^  x    2     \hat{a_{2}}=\frac{\sigma^{2}-\hat{x}}{2}     Since a 1 and a 2 both are positive, the estimator     a  1   ^     normal-^   subscript  a  1     \hat{a_{1}}   and     a  2   ^     normal-^   subscript  a  2     \hat{a_{2}}   are admissible (≥ 0) only if,     x  ¯   <   σ  2   <   2   x  ¯           normal-¯  x    superscript  σ  2          2   normal-¯  x       \bar{x}<\sigma^{2}<2\bar{x}   .  Maximum likelihood  Given a sample X 1 ... X m are independent random variables each having an Hermite distribution we wish to estimate the value of the parameters     a  1   ^     normal-^   subscript  a  1     \hat{a_{1}}   and     a  2   ^     normal-^   subscript  a  2     \hat{a_{2}}   . We know that the mean and the variance of the distribution are    μ  =    a  1   +   2   a  2         μ     subscript  a  1     2   subscript  a  2       \mu=a_{1}+2a_{2}   and     σ  2   =    a  1   +   4   a  2          superscript  σ  2      subscript  a  1     4   subscript  a  2       \sigma^{2}=a_{1}+4a_{2}   , respectively. Using these two equation,      {       a  1   =   μ   (   2  -  d   )            a  2   =     μ   (   d  -  1   )    2            cases     subscript  a  1     μ    2  d     otherwise     subscript  a  2       μ    d  1    2    otherwise    \begin{cases}a_{1}=\mu(2-d)\\
 a_{2}=\frac{\mu(d-1)}{2}\end{cases}     We can parameterize the probability function by μ and d      P   (  X  =  x  )   =  exp   (  -   (  μ   (  2  -  d  )   +    μ   (   d  -  1   )    2   )   )    ∑   j  =  0    [   x  /  2   ]        (   μ   (   2  -  d   )    )    x  -   2  j       (    μ   (   d  -  1   )    2   )   j       (   x  -   2  j    )   !    j  !        fragments  P   fragments  normal-(  X   x  normal-)      fragments  normal-(    fragments  normal-(  μ   fragments  normal-(  2   d  normal-)        μ    d  1    2   normal-)   normal-)    superscript   subscript     j  0     delimited-[]    x  2          superscript    μ    2  d      x    2  j      superscript      μ    d  1    2   j          x    2  j       j       P(X=x)=\exp\left(-\left(\mu(2-d)+\frac{\mu(d-1)}{2}\right)\right)\sum_{j=0}^{[%
 x/2]}\frac{(\mu(2-d))^{x-2j}\left(\frac{\mu(d-1)}{2}\right)^{j}}{(x-2j)!j!}     Hence the log-likelihood function is, 22      ℒ   (   x  1   ,  …  ,   x  m   ;  μ  ,  d  )       ℒ    subscript  x  1   normal-…   subscript  x  m   μ  d     \displaystyle\mathcal{L}(x_{1},\ldots,x_{m};\mu,d)     where         q  i    (  θ  )    =    ∑   j  =  0    [    x  i   /  2   ]      θ  j      (    x  i   -   2  j    )   !    j  !             subscript  q  i   θ     superscript   subscript     j  0     delimited-[]     subscript  x  i   2        superscript  θ  j          subscript  x  i     2  j       j        q_{i}(\theta)=\sum_{j=0}^{[x_{i}/2]}\frac{\theta^{j}}{(x_{i}-2j)!j!}         θ  =    d  -  1    2  μ    (   2  -  d   )   2         θ      d  1     2  μ   superscript    2  d   2       \theta=\frac{d-1}{2\mu(2-d)^{2}}      From the log-likelihood function, the likelihood equations are, 23        ∂  l    ∂  μ    =     m   (    -  1   +    d  -  1   2    )    +    1  μ     ∑   i  =  1   m    x  i      -     d  -  1    2   μ  2     (   2  -  d   )   2       ∑   i  =  1   m      q  i    ′     (  θ  )      q  i    (  θ  )                l     μ          m      1       d  1   2         1  μ     superscript   subscript     i  1    m    subscript  x  i            d  1     2   superscript  μ  2    superscript    2  d   2       superscript   subscript     i  1    m        superscript   subscript  q  i    normal-′    θ      subscript  q  i   θ         \frac{\partial l}{\partial\mu}=m\left(-1+\frac{d-1}{2}\right)+\frac{1}{\mu}%
 \sum_{i=1}^{m}x_{i}-\frac{d-1}{2\mu^{2}(2-d)^{2}}\sum_{i=1}^{m}\frac{q_{i}^{{}%
 ^{\prime}}(\theta)}{q_{i}(\theta)}           ∂  l    ∂  d    =    m   μ  2    -     ∑   i  =  1   m    x  i     2  -  d    -    d   2  μ    (   2  -  d   )   3       ∑   i  =  1   m     ∑   i  =  1   m      q  i    ′     (  θ  )      q  i    (  θ  )                 l     d        m    μ  2        superscript   subscript     i  1    m    subscript  x  i      2  d        d    2  μ   superscript    2  d   3       superscript   subscript     i  1    m     superscript   subscript     i  1    m        superscript   subscript  q  i    normal-′    θ      subscript  q  i   θ          \frac{\partial l}{\partial d}=m\frac{\mu}{2}-\frac{\sum_{i=1}^{m}x_{i}}{2-d}-%
 \frac{d}{2\mu(2-d)^{3}}\sum_{i=1}^{m}\sum_{i=1}^{m}\frac{q_{i}^{{}^{\prime}}(%
 \theta)}{q_{i}(\theta)}     Straightforward calculations show that, 24       μ  =   x  ¯       μ   normal-¯  x     \mu=\bar{x}     And d can be found by solving,           ∑   i  =  1   m      q  i    ′     (   θ  ~   )      q  i    (   θ  ~   )      =   m    (    x  ¯    (   2  -  d   )    )   2          superscript   subscript     i  1    m        superscript   subscript  q  i    normal-′     normal-~  θ       subscript  q  i    normal-~  θ        m   superscript     normal-¯  x     2  d    2      \sum_{i=1}^{m}\frac{q_{i}^{{}^{\prime}}(\tilde{\theta})}{q_{i}(\tilde{\theta})%
 }=m(\bar{x}(2-d))^{2}        where     θ  ~   =    d  -  1    2   x  ¯     (   2  -  d   )   2          normal-~  θ       d  1     2   normal-¯  x    superscript    2  d   2       \tilde{\theta}=\frac{d-1}{2\bar{x}(2-d)^{2}}      It can be shown that the log-likelihood function is strictly concave in the domain of the parameters. Consequently, the MLE is unique.   The likelihood equation does not always have a solution like as it shows the following proposition,  Proposition: 25 Let X 1 , ..., X m come from a generalized Hermite distribution with fixed n . Then the MLEs of the parameters are    μ  ^     normal-^  μ    \hat{\mu}   and    d  ~     normal-~  d    \tilde{d}   if only if      m   (  2  )    /    x  ¯   2    >  1         superscript  m  2    superscript   normal-¯  x   2    1    m^{(2)}/\bar{x}^{2}>1   , where     m   (  2  )    =    ∑   i  =  1   n      x  i    (    x  i   -  1   )    /  n         superscript  m  2     superscript   subscript     i  1    n        subscript  x  i      subscript  x  i   1    n      m^{(2)}=\sum_{i=1}^{n}x_{i}(x_{i}-1)/n   indicates the empirical factorial momement of order 2.   Remark 1: The condition      m   (  2  )    /    x  ¯   2    >  1         superscript  m  2    superscript   normal-¯  x   2    1    m^{(2)}/\bar{x}^{2}>1   is equivalent to     d  ~   >  1       normal-~  d   1    \tilde{d}>1   where     d  ~   =    σ  2   /   x  ¯         normal-~  d      superscript  σ  2    normal-¯  x      \tilde{d}=\sigma^{2}/\bar{x}   is the empirical dispersion index    Remark 2: If the condition is not satisfied, then the MLEs of the parameters are     μ  ^   =   x  ¯        normal-^  μ    normal-¯  x     \hat{\mu}=\bar{x}   and     d  ~   =  1       normal-~  d   1    \tilde{d}=1   , that is, the data are fitted using the Poisson distribution.   Zero frequency and the mean estimators  A usual choice for discrete distributions is the zero relative frequency of the data set which is equated to the probability of zero under the assumed distribution. Observing that     f  0   =   exp   (   -   (    a  1   +   a  2    )    )         subscript  f  0          subscript  a  1    subscript  a  2        f_{0}=\exp(-(a_{1}+a_{2}))   and    μ  =    a  1   +   2   a  2         μ     subscript  a  1     2   subscript  a  2       \mu=a_{1}+2a_{2}   . Following the example of Y. C. Patel (1976) the resulting system of equations,      {       x  ¯   =    a  1   +   2   a  2             f  0   =   exp   (   -   (    a  1   +   a  2    )    )            cases     normal-¯  x      subscript  a  1     2   subscript  a  2      otherwise     subscript  f  0          subscript  a  1    subscript  a  2       otherwise    \begin{cases}\bar{x}=a_{1}+2a_{2}\\
 f_{0}=\exp(-(a_{1}+a_{2}))\end{cases}     We obtain the zero frequency and the mean estimator  a 1 of     a  1   ^     normal-^   subscript  a  1     \hat{a_{1}}   and a 2 of     a  2   ^     normal-^   subscript  a  2     \hat{a_{2}}   , 26        a  1   ^   =   -   (    x  ¯   +   2   log   (   f  0   )      )         normal-^   subscript  a  1         normal-¯  x     2     subscript  f  0         \hat{a_{1}}=-(\bar{x}+2\log(f_{0}))           a  2   ^   =    x  ¯   +   log   (   f  0   )          normal-^   subscript  a  2       normal-¯  x      subscript  f  0       \hat{a_{2}}=\bar{x}+\log(f_{0})     where     f  0   =    n  0   n        subscript  f  0      subscript  n  0   n     f_{0}=\frac{n_{0}}{n}   , is the zero relative frequency, n > 0  It can be seen that for distributions with a high probability at 0, the efficiency is high.   For admissible values of     a  1   ^     normal-^   subscript  a  1     \hat{a_{1}}   and     a  2   ^     normal-^   subscript  a  2     \hat{a_{2}}   , we must have          -   log   (    n  0   n   )     <   x  ¯   <   -   2   log   (    n  0   n   )                   subscript  n  0   n      normal-¯  x            2       subscript  n  0   n         -\log\left(\frac{n_{0}}{n}\right)<\bar{x}<-2\log\left(\frac{n_{0}}{n}\right)        Testing Poisson assumption  When Hermite distribution is used to model a data sample is important to check if the Poisson distribution is enough to fit the data. Following the parametrized probability mass function used to calculate the maximum likelihood estimator, is important to corroborate the following hypothesis,      {       H  0   :   d  =  1           H  1   :   d  >  1           cases   normal-:   subscript  H  0     d  1    otherwise   normal-:   subscript  H  1     d  1    otherwise    \begin{cases}H_{0}:d=1\\
 H_{1}:d>1\end{cases}     Likelihood-ratio test  The Likelihood-ratio test statistic 27 for hermite distribution is,      W  =   2   (    ℒ   (  X  ;   μ  ^   ,   d  ^   )    -   ℒ   (  X  ;   μ  ^   ,  1  )     )        W    2      ℒ   X   normal-^  μ    normal-^  d       ℒ   X   normal-^  μ   1        W=2(\mathcal{L}(X;\hat{\mu},\hat{d})-\mathcal{L}(X;\hat{\mu},1))     Where    ℒ   (  )       ℒ     \mathcal{L}()   is the log-likelihood function. As d = 1 belongs to the boundary of the domain of parameters, under the null hypothesis, W does not have an asymptotic    χ  1  2     superscript   subscript  χ  1   2    \chi_{1}^{2}   distribution as expected. It can be established that the asymptotic distribution of W is a 50:50 mixture of the constant 0 and the    χ  1  2     superscript   subscript  χ  1   2    \chi_{1}^{2}   . The α upper-tail percentage points for this mixture are the same as the 2α upper-tail percentage points for a    χ  1  2     superscript   subscript  χ  1   2    \chi_{1}^{2}   ; for instance, for α=0.01,0.05, and 0.10 they are 5.41189, 2.70554 and 1.64237.  The "score" or Lagrange multiplier test  The score statistic is, 28       S  2   =   2  m    [     m   (  2  )    -    x  ¯   2     2   x  ¯     ]   2    =    m    (    d  ~   -  1   )   2    2          subscript  S  2     2  m   superscript   delimited-[]       superscript  m  2    superscript   normal-¯  x   2      2   normal-¯  x      2             m   superscript     normal-~  d   1   2    2      S_{2}=2m\left[\frac{m^{(2)}-\bar{x}^{2}}{2\bar{x}}\right]^{2}=\frac{m(\tilde{d%
 }-1)^{2}}{2}     where m is the number of observations.  The asymptotic distribution of the score test statistic under the null hypothesis is a    χ  1  2     superscript   subscript  χ  1   2    \chi_{1}^{2}   distribution. It may be convenient to use a signed version of the score test, that is,     sgn   (    m   (  2  )    -    x  ¯   2    )     S       sgn     superscript  m  2    superscript   normal-¯  x   2       S     \operatorname{sgn}(m^{(2)}-\bar{x}^{2})\sqrt{S}   , following asymptotically a standard normal.  See also   Compound Poisson distribution  Poisson distribution   References  "  Category:Discrete distributions  Category:Hermite polynomials  Category:Probability distributions     ↩  ↩  ↩  Johnson, N.L., Kemp, A.W., and Kotz, S. (2005) Univariate Discrete Distributions, 3rd Edition, Wiley, ISBN 978-0-471-27246-5. ↩  ↩  ↩  ↩  ↩  ↩  ↩  ↩   ↩       ↩              