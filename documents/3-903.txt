   Matrix normal distribution      Matrix normal distribution   | cdf = | mean =   𝐌   𝐌   \mathbf{M}   | median = | mode = | variance =   𝐔   𝐔   \mathbf{U}   (among-row) and   𝐕   𝐕   \mathbf{V}   (among-column) | skewness = | kurtosis = | entropy = | mgf = | char = }}  In statistics , the matrix normal distribution is a probability distribution that is a generalization of the multivariate normal distribution to matrix-valued random variables.  Definition  The probability density function for the random matrix X ( n × p ) that follows the matrix normal distribution    ℳ   𝒩   n  ,  p     (  𝐌  ,  𝐔  ,  𝐕  )       ℳ   subscript  𝒩   n  p     𝐌  𝐔  𝐕     \mathcal{MN}_{n,p}(\mathbf{M},\mathbf{U},\mathbf{V})   has the form:      p   (  𝐗  ∣  𝐌  ,  𝐔  ,  𝐕  )   =    exp   (   -     1  2    tr   [    𝐕   -  1      (   𝐗  -  𝐌   )   T    𝐔   -  1     (   𝐗  -  𝐌   )    ]     )       (   2  π   )     n  p   /  2      |  𝐕  |    n  /  2      |  𝐔  |    p  /  2         fragments  p   fragments  normal-(  X  normal-∣  M  normal-,  U  normal-,  V  normal-)              1  2   tr   delimited-[]     superscript  𝐕    1     superscript    𝐗  𝐌   T    superscript  𝐔    1      𝐗  𝐌           superscript    2  π       n  p   2     superscript    𝐕     n  2     superscript    𝐔     p  2        p(\mathbf{X}\mid\mathbf{M},\mathbf{U},\mathbf{V})=\frac{\exp\left(-\frac{1}{2}%
 \,\mathrm{tr}\left[\mathbf{V}^{-1}(\mathbf{X}-\mathbf{M})^{T}\mathbf{U}^{-1}(%
 \mathbf{X}-\mathbf{M})\right]\right)}{(2\pi)^{np/2}|\mathbf{V}|^{n/2}|\mathbf{%
 U}|^{p/2}}     where   tr   tr   \mathrm{tr}   denotes trace and M is n × p , U is n × n and V is p × p .  The matrix normal is related to the multivariate normal distribution in the following way:       𝐗  ∼   ℳ   𝒩   n  ×  p     (  𝐌  ,  𝐔  ,  𝐕  )     ,     similar-to  𝐗    ℳ   subscript  𝒩    n  p     𝐌  𝐔  𝐕      \mathbf{X}\sim\mathcal{MN}_{n\times p}(\mathbf{M},\mathbf{U},\mathbf{V}),     if and only if       vec   (  𝐗  )    ∼    𝒩   n  p     (   vec   (  𝐌  )    ,   𝐕  ⊗  𝐔   )       similar-to    vec  𝐗      subscript  𝒩    n  p       vec  𝐌    tensor-product  𝐕  𝐔       \mathrm{vec}(\mathbf{X})\sim\mathcal{N}_{np}(\mathrm{vec}(\mathbf{M}),\mathbf{%
 V}\otimes\mathbf{U})     where   ⊗   tensor-product   \otimes   denotes the Kronecker product and    vec   (  𝐌  )       vec  𝐌    \mathrm{vec}(\mathbf{M})   denotes the vectorization of   𝐌   𝐌   \mathbf{M}   .  Proof  The equivalence between the above matrix normal and multivariate normal density functions can be shown using several properties of the trace and Kronecker product , as follows. We start with the argument of the exponent of the matrix normal PDF:      -     1  2    tr   [    𝐕   -  1      (   𝐗  -  𝐌   )   T    𝐔   -  1     (   𝐗  -  𝐌   )    ]            1  2   tr   delimited-[]     superscript  𝐕    1     superscript    𝐗  𝐌   T    superscript  𝐔    1      𝐗  𝐌        \displaystyle\;\;\;\;-\frac{1}{2}\text{tr}\left[\mathbf{V}^{-1}(\mathbf{X}-%
 \mathbf{M})^{T}\mathbf{U}^{-1}(\mathbf{X}-\mathbf{M})\right]   which is the argument of the exponent of the multivariate normal PDF. The proof is completed by using the determinant property      |   𝐕  ⊗  𝐔   |   =     |  𝐕  |   n     |  𝐔  |   p     .         tensor-product  𝐕  𝐔       superscript    𝐕   n    superscript    𝐔   p      |\mathbf{V}\otimes\mathbf{U}|=|\mathbf{V}|^{n}|\mathbf{U}|^{p}.     Properties  If    𝐗  ∼   ℳ   𝒩   n  ×  p     (  𝐌  ,  𝐔  ,  𝐕  )       similar-to  𝐗    ℳ   subscript  𝒩    n  p     𝐌  𝐔  𝐕      \mathbf{X}\sim\mathcal{MN}_{n\times p}(\mathbf{M},\mathbf{U},\mathbf{V})   , then we have the following properties: 1 2  Expected values  The mean, or expected value is:       E   [  𝐗  ]    =  𝐌        E   delimited-[]  𝐗    𝐌    E[\mathbf{X}]=\mathbf{M}   and we have the following second-order expectations:       E   [    (   𝐗  -  𝐌   )     (   𝐗  -  𝐌   )   T    ]    =   𝐔   tr   (  𝐕  )           E   delimited-[]      𝐗  𝐌    superscript    𝐗  𝐌   T        𝐔   tr  𝐕      E[(\mathbf{X}-\mathbf{M})(\mathbf{X}-\mathbf{M})^{T}]=\mathbf{U}\operatorname{%
 tr}(\mathbf{V})          E   [     (   𝐗  -  𝐌   )   T    (   𝐗  -  𝐌   )    ]    =   𝐕   tr   (  𝐔  )           E   delimited-[]     superscript    𝐗  𝐌   T     𝐗  𝐌        𝐕   tr  𝐔      E[(\mathbf{X}-\mathbf{M})^{T}(\mathbf{X}-\mathbf{M})]=\mathbf{V}\operatorname{%
 tr}(\mathbf{U})   where   tr   tr   \operatorname{tr}   denotes trace .  More generally, for appropriately dimensioned matrices A , B , C :      E   [   𝐗𝐀𝐗  T   ]       E   delimited-[]   superscript  𝐗𝐀𝐗  T      \displaystyle E[\mathbf{X}\mathbf{A}\mathbf{X}^{T}]     Transformation  Transpose transform:       𝐗  T   ∼   ℳ   𝒩   p  ×  n     (   𝐌  T   ,  𝐕  ,  𝐔  )       similar-to   superscript  𝐗  T     ℳ   subscript  𝒩    p  n      superscript  𝐌  T   𝐕  𝐔      \mathbf{X}^{T}\sim\mathcal{MN}_{p\times n}(\mathbf{M}^{T},\mathbf{V},\mathbf{U})     Linear transform: let D ( r -by- n ), be of full rank  r ≤ n and C ( p -by- s ), be of full rank s ≤ p , then:      𝐃𝐗𝐂  ∼   ℳ   𝒩   n  ×  p     (  𝐃𝐌𝐂  ,   𝐃𝐔𝐃  T   ,    𝐂  T   𝐕𝐂   )       similar-to  𝐃𝐗𝐂    ℳ   subscript  𝒩    n  p     𝐃𝐌𝐂   superscript  𝐃𝐔𝐃  T      superscript  𝐂  T   𝐕𝐂       \mathbf{DXC}\sim\mathcal{MN}_{n\times p}(\mathbf{DMC},\mathbf{DUD}^{T},\mathbf%
 {C}^{T}\mathbf{VC})     Example  Let's imagine a sample of n independent p -dimensional random variables identically distributed according to a multivariate normal distribution :       𝐘  i   ∼    𝒩  p    (  𝝁  ,  𝚺  )   with  i   ∈   {  1  ,  …  ,  n  }        similar-to   subscript  𝐘  i      subscript  𝒩  p    𝝁  𝚺   with  i         1  normal-…  n      \mathbf{Y}_{i}\sim\mathcal{N}_{p}({\boldsymbol{\mu}},{\boldsymbol{\Sigma}})%
 \text{ with }i\in\{1,\ldots,n\}   . When defining the n × p matrix   𝐗   𝐗   \mathbf{X}   for which the i th row is    𝐘  i     subscript  𝐘  i    \mathbf{Y}_{i}   , we obtain:      𝐗  ∼   ℳ   𝒩   n  ×  p     (  𝐌  ,  𝐔  ,  𝐕  )       similar-to  𝐗    ℳ   subscript  𝒩    n  p     𝐌  𝐔  𝐕      \mathbf{X}\sim\mathcal{MN}_{n\times p}(\mathbf{M},\mathbf{U},\mathbf{V})   where each row of   𝐌   𝐌   \mathbf{M}   is equal to   𝝁   𝝁   {\boldsymbol{\mu}}   , that is    𝐌  =    𝟏  n   ×   𝝁  T        𝐌     subscript  1  n    superscript  𝝁  T      \mathbf{M}=\mathbf{1}_{n}\times{\boldsymbol{\mu}}^{T}   ,   𝐔   𝐔   \mathbf{U}   is the n × n identity matrix, that is the rows are independent, and    𝐕  =  𝚺      𝐕  𝚺    \mathbf{V}={\boldsymbol{\Sigma}}   .  Maximum Likelihood Parameter Estimation  Given k matrices, each of size n × p , denoted     𝐗  1   ,   𝐗  2   ,  …  ,   𝐗  k       subscript  𝐗  1    subscript  𝐗  2   normal-…   subscript  𝐗  k     \mathbf{X}_{1},\mathbf{X}_{2},\ldots,\mathbf{X}_{k}   , which we assume have been sampled i.i.d. from a matrix normal distribution, the maximum likelihood estimate of the parameters can be obtained by maximizing:       ∏   i  =  1   k   ℳ   𝒩   n  ×  p     (   𝐗  i   ∣  𝐌  ,  𝐔  ,  𝐕  )   .     fragments   superscript   subscript  product    i  1    k   M   subscript  𝒩    n  p     fragments  normal-(   subscript  𝐗  i   normal-∣  M  normal-,  U  normal-,  V  normal-)   normal-.    \prod_{i=1}^{k}\mathcal{MN}_{n\times p}(\mathbf{X}_{i}\mid\mathbf{M},\mathbf{U%
 },\mathbf{V}).   The solution for the mean has a closed form, namely      𝐌  =    1  k     ∑   i  =  1   k    𝐗  i         𝐌      1  k     superscript   subscript     i  1    k    subscript  𝐗  i       \mathbf{M}=\frac{1}{k}\sum_{i=1}^{k}\mathbf{X}_{i}   but the covariance parameters do not. However, these parameters can be iteratively maximized by zero-ing their gradients at:      𝐔  =    1   k  p      ∑   i  =  1   k     (    𝐗  i   -  𝐌   )    𝐕   -  1      (    𝐗  i   -  𝐌   )   T          𝐔      1    k  p      superscript   subscript     i  1    k        subscript  𝐗  i   𝐌    superscript  𝐕    1     superscript     subscript  𝐗  i   𝐌   T        \mathbf{U}=\frac{1}{kp}\sum_{i=1}^{k}(\mathbf{X}_{i}-\mathbf{M})\mathbf{V}^{-1%
 }(\mathbf{X}_{i}-\mathbf{M})^{T}   and       𝐕  =    1   k  n      ∑   i  =  1   k      (    𝐗  i   -  𝐌   )   T    𝐔   -  1     (    𝐗  i   -  𝐌   )       ,      𝐕      1    k  n      superscript   subscript     i  1    k      superscript     subscript  𝐗  i   𝐌   T    superscript  𝐔    1       subscript  𝐗  i   𝐌        \mathbf{V}=\frac{1}{kn}\sum_{i=1}^{k}(\mathbf{X}_{i}-\mathbf{M})^{T}\mathbf{U}%
 ^{-1}(\mathbf{X}_{i}-\mathbf{M}),   See for example 3 and references therein. It should be noted that the covariance parameters are non-identifiable in the sense that for any scale factor, s>0 , we have:      ℳ   𝒩   n  ×  p     (  𝐗  ∣  𝐌  ,  𝐔  ,  𝐕  )   =  ℳ   𝒩   n  ×  p     (  𝐗  ∣  𝐌  ,  s  𝐔  ,  1  /  s  𝐕  )   .     fragments  M   subscript  𝒩    n  p     fragments  normal-(  X  normal-∣  M  normal-,  U  normal-,  V  normal-)    M   subscript  𝒩    n  p     fragments  normal-(  X  normal-∣  M  normal-,  s  U  normal-,  1   s  V  normal-)   normal-.    \mathcal{MN}_{n\times p}(\mathbf{X}\mid\mathbf{M},\mathbf{U},\mathbf{V})=%
 \mathcal{MN}_{n\times p}(\mathbf{X}\mid\mathbf{M},s\mathbf{U},1/s\mathbf{V}).     Drawing values from the distribution  Sampling from the matrix normal distribution is a special case of the sampling procedure for the multivariate normal distribution . Let   𝐗   𝐗   \mathbf{X}   be an n by p matrix of np independent samples from the standard normal distribution, so that       𝐗  ∼   ℳ   𝒩   n  ×  p     (  𝟎  ,  𝐈  ,  𝐈  )     .     similar-to  𝐗    ℳ   subscript  𝒩    n  p     0  𝐈  𝐈      \mathbf{X}\sim\mathcal{MN}_{n\times p}(\mathbf{0},\mathbf{I},\mathbf{I}).   Then let       𝐘  =   𝐌  +  𝐀𝐗𝐁    ,      𝐘    𝐌  𝐀𝐗𝐁     \mathbf{Y}=\mathbf{M}+\mathbf{A}\mathbf{X}\mathbf{B},   so that       𝐘  ∼   ℳ   𝒩   n  ×  p     (  𝐌  ,   𝐀𝐀  T   ,    𝐁  T   𝐁   )     ,     similar-to  𝐘    ℳ   subscript  𝒩    n  p     𝐌   superscript  𝐀𝐀  T      superscript  𝐁  T   𝐁       \mathbf{Y}\sim\mathcal{MN}_{n\times p}(\mathbf{M},\mathbf{AA}^{T},\mathbf{B}^{%
 T}\mathbf{B}),   where A and B can be chosen by Cholesky decomposition or a similar matrix square root operation.  Relation to other distributions  Dawid (1981) provides a discussion of the relation of the matrix-valued normal distribution to other distributions, including the Wishart distribution , Inverse Wishart distribution and matrix t-distribution , but uses different notation from that employed here.  See also   Multivariate normal distribution .   References       "  Category:Random matrices  Category:Continuous distributions  Category:Multivariate continuous distributions  Category:Probability distributions     ↩  ↩  ↩     