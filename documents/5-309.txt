   Markov random field      Markov random field   (Figure)  An example of a Markov random field. Each edge represents dependency. In this example: A depends on B and D. B depends on A and D. D depends on A, B, and E. E depends on D and C. C depends on E.   In the domain of physics and probability , a Markov random field (often abbreviated as MRF ), Markov network or undirected graphical model is a set of random variables having a Markov property described by an undirected graph . A Markov random field is similar to a Bayesian network in its representation of dependencies; the differences being that Bayesian networks are directed and acyclic, whereas Markov networks are undirected and may be cyclic. Thus, a Markov network can represent certain dependencies that a Bayesian network cannot (such as cyclic dependencies); on the other hand, it can't represent certain dependencies that a Bayesian network can (such as induced dependencies). The underlying graph of a Markov random field may be finite or infinite.  When the joint probability density of the random variables is strictly positive, it is also referred to as a Gibbs random field , because, according to the Hammersley‚ÄìClifford theorem , it can then be represented by a Gibbs measure for an appropriate (locally defined) energy function. The prototypical Markov random field is the Ising model ; indeed, the Markov random field was introduced as the general setting for the Ising model . 1 In the domain of artificial intelligence , a Markov random field is used to model various low- to mid-level tasks in image processing and computer vision . 2 For example, MRFs are used for image restoration , image completion, segmentation , image registration , texture synthesis , super-resolution , stereo matching and information retrieval .  Definition  Given an undirected graph  G =¬†( V , E ), a set of random variables  X = ( X v ) v ‚àà V indexed by V form a Markov random field with respect to G if they satisfy the local Markov properties :   Pairwise Markov property : Any two non-adjacent variables are conditionally independent given all other variables:          X  u   ‚üÇ  ‚üÇ   X  v   ‚à£   X   V  ‚àñ   {  u  ,  v  }     if   {  u  ,  v  }   ‚àâ  E     fragments   subscript  X  u   perpendicular-to  perpendicular-to   subscript  X  v   normal-‚à£   subscript  X    V   u  v      if   fragments  normal-{  u  normal-,  v  normal-}    E    X_{u}\perp\!\!\!\perp X_{v}\mid X_{V\setminus\{u,v\}}\quad\text{if }\{u,v\}\notin
 E         Local Markov property : A variable is conditionally independent of all other variables given its neighbors:          X  v   ‚üÇ  ‚üÇ   X   V  ‚àñ   cl   (  v  )      ‚à£   X   ne   (  v  )        fragments   subscript  X  v   perpendicular-to  perpendicular-to   subscript  X    V   cl  v     normal-‚à£   subscript  X   ne  v      X_{v}\perp\!\!\!\perp X_{V\setminus\operatorname{cl}(v)}\mid X_{\operatorname{%
 ne}(v)}       where ne( v ) is the set of neighbors of v , and cl( v ) = { v } ‚à™ ne( v ) is the closed neighbourhood of v .    Global Markov property : Any two subsets of variables are conditionally independent given a separating subset:          X  A   ‚üÇ  ‚üÇ   X  B   ‚à£   X  S      fragments   subscript  X  A   perpendicular-to  perpendicular-to   subscript  X  B   normal-‚à£   subscript  X  S     X_{A}\perp\!\!\!\perp X_{B}\mid X_{S}       where every path from a node in A to a node in B passes through S .   The above three Markov properties are not equivalent: The Local Markov property is stronger than the Pairwise one, while weaker than the Global one.  Clique factorization  As the Markov properties of an arbitrary probability distribution can be difficult to establish, a commonly used class of Markov random fields are those that can be factorized according to the cliques of the graph.  Given a set of random variables X =¬†( X v ) v ‚àà V , let P ( X = x ) be the probability of a particular field configuration x in X . That is, P ( X = x ) is the probability of finding that the random variables X take on the particular value x . Because X is a set, the probability of x should be understood to be taken with respect to a joint distribution of the X v .  If this joint density can be factorized over the cliques of G :      P   (  X  =  x  )   =   ‚àè   C  ‚àà   cl   (  G  )       œï  C    (   x  C   )      fragments  P   fragments  normal-(  X   x  normal-)     subscript  product    C   cl  G      subscript  œï  C    fragments  normal-(   subscript  x  C   normal-)     P(X=x)=\prod_{C\in\operatorname{cl}(G)}\phi_{C}(x_{C})     then X forms a Markov random field with respect to G . Here, cl( G ) is the set of cliques of G . The definition is equivalent if only maximal cliques are used. The functions œÜ C are sometimes referred to as factor potentials or clique potentials . Note, however, conflicting terminology is in use: the word potential is often applied to the logarithm of œÜ C . This is because, in statistical mechanics , log( œÜ C ) has a direct interpretation as the potential energy of a configuration  x C .  Although some MRFs do not factorize (a simple example can be constructed on a cycle of 4 nodes 3 ), in certain cases they can be shown to be equivalent conditions:   if the density is positive (by the Hammersley‚ÄìClifford theorem ),  if the graph is chordal (by equivalence to a Bayesian network ).   When such a factorization does exist, it is possible to construct a factor graph for the network.  Logistic model  Any Markov random field (with a strictly positive density) can be written as log-linear model with feature functions    f  k     subscript  f  k    f_{k}   such that the full-joint distribution can be written as      P   (  X  =  x  )   =   1  Z   exp   (   ‚àë  k    w  k  ‚ä§    f  k    (   x   {  k  }    )   )      fragments  P   fragments  normal-(  X   x  normal-)      1  Z     fragments  normal-(   subscript   k    superscript   subscript  w  k   top    subscript  f  k    fragments  normal-(   subscript  x   k    normal-)   normal-)     P(X=x)=\frac{1}{Z}\exp\left(\sum_{k}w_{k}^{\top}f_{k}(x_{\{k\}})\right)   where the notation        w  k  ‚ä§    f  k    (   x   {  k  }    )    =    ‚àë   i  =  1    N  k       w   k  ,  i    ‚ãÖ   f   k  ,  i      (   x   {  k  }    )            superscript   subscript  w  k   top    subscript  f  k    subscript  x   k       superscript   subscript     i  1     subscript  N  k       normal-‚ãÖ   subscript  w   k  i     subscript  f   k  i      subscript  x   k        w_{k}^{\top}f_{k}(x_{\{k\}})=\sum_{i=1}^{N_{k}}w_{k,i}\cdot f_{k,i}(x_{\{k\}})   is simply a dot product over field configurations, and Z is the partition function :       Z  =    ‚àë   x  ‚àà  ùí≥     exp   (    ‚àë  k     w  k  ‚ä§    f  k    (   x   {  k  }    )     )      .      Z    subscript     x  ùí≥        subscript   k      superscript   subscript  w  k   top    subscript  f  k    subscript  x   k          Z=\sum_{x\in\mathcal{X}}\exp\left(\sum_{k}w_{k}^{\top}f_{k}(x_{\{k\}})\right).     Here,   ùí≥   ùí≥   \mathcal{X}   denotes the set of all possible assignments of values to all the network's random variables. Usually, the feature functions    f   k  ,  i      subscript  f   k  i     f_{k,i}   are defined such that they are indicators of the clique's configuration, i.e.       f   k  ,  i     (   x   {  k  }    )    =  1         subscript  f   k  i     subscript  x   k     1    f_{k,i}(x_{\{k\}})=1   if    x   {  k  }      subscript  x   k     x_{\{k\}}   corresponds to the i -th possible configuration of the k -th clique and 0 otherwise. This model is equivalent to the clique factorization model given above, if     N  k   =   |   dom   (   C  k   )    |        subscript  N  k      dom   subscript  C  k       N_{k}=|\operatorname{dom}(C_{k})|   is the cardinality of the clique, and the weight of a feature    f   k  ,  i      subscript  f   k  i     f_{k,i}   corresponds to the logarithm of the corresponding clique factor, i.e.      w   k  ,  i    =    log  œï    (   c   k  ,  i    )         subscript  w   k  i        œï    subscript  c   k  i       w_{k,i}=\log\phi(c_{k,i})   , where    c   k  ,  i      subscript  c   k  i     c_{k,i}   is the i -th possible configuration of the k -th clique, i.e. the i -th value in the domain of the clique    C  k     subscript  C  k    C_{k}   .  The probability P is often called the Gibbs measure . This expression of a Markov field as a logistic model is only possible if all clique factors are non-zero, i.e. if none of the elements of   ùí≥   ùí≥   \mathcal{X}   are assigned a probability of 0. This allows techniques from matrix algebra to be applied, e.g. that the trace of a matrix is log of the determinant , with the matrix representation of a graph arising from the graph's incidence matrix .  The importance of the partition function Z is that many concepts from statistical mechanics , such as entropy , directly generalize to the case of Markov networks, and an intuitive understanding can thereby be gained. In addition, the partition function allows variational methods to be applied to the solution of the problem: one can attach a driving force to one or more of the random variables, and explore the reaction of the network in response to this perturbation . Thus, for example, one may add a driving term J v , for each vertex v of the graph, to the partition function to get:       Z   [  J  ]    =    ‚àë   x  ‚àà  ùí≥     exp   (     ‚àë  k     w  k  ‚ä§    f  k    (   x   {  k  }    )     +    ‚àë  v     J  v    x  v      )           Z   delimited-[]  J      subscript     x  ùí≥          subscript   k      superscript   subscript  w  k   top    subscript  f  k    subscript  x   k        subscript   v      subscript  J  v    subscript  x  v          Z[J]=\sum_{x\in\mathcal{X}}\exp\left(\sum_{k}w_{k}^{\top}f_{k}(x_{\{k\}})+\sum%
 _{v}J_{v}x_{v}\right)     Formally differentiating with respect to J v gives the expectation value of the random variable X v associated with the vertex v :        E   [   X  v   ]    =      1  Z      ‚àÇ  Z    [  J  ]     ‚àÇ   J  v      |     J  v   =  0     .        E   delimited-[]   subscript  X  v      evaluated-at      1  Z         Z    delimited-[]  J       subscript  J  v         subscript  J  v   0      E[X_{v}]=\frac{1}{Z}\left.\frac{\partial Z[J]}{\partial J_{v}}\right|_{J_{v}=0}.     Correlation functions are computed likewise; the two-point correlation is:        C   [   X  u   ,   X  v   ]    =      1  Z       ‚àÇ  2   Z    [  J  ]      ‚àÇ   J  u     ‚àÇ   J  v       |      J  u   =  0   ,    J  v   =  0      .        C    subscript  X  u    subscript  X  v      evaluated-at      1  Z         superscript   2   Z    delimited-[]  J         subscript  J  u       subscript  J  v        formulae-sequence     subscript  J  u   0      subscript  J  v   0       C[X_{u},X_{v}]=\frac{1}{Z}\left.\frac{\partial^{2}Z[J]}{\partial J_{u}\partial
 J%
 _{v}}\right|_{J_{u}=0,J_{v}=0}.     Log-linear models are especially convenient for their interpretation. A log-linear model can provide a much more compact representation for many distributions, especially when variables have large domains. They are convenient too because their negative log likelihoods are convex . Unfortunately, though the likelihood of a logistic Markov network is convex, evaluating the likelihood or gradient of the likelihood of a model requires inference in the model, which is in general computationally infeasible.  Examples  Gaussian Markov random field  A multivariate normal distribution forms a Markov random field with respect to a graph G =¬†( V , E ) if the missing edges correspond to zeros on the precision matrix (the inverse covariance matrix ):      X  =    (   X  v   )    v  ‚àà  V    ‚àº   ùí©   (  ùùÅ  ,  Œ£  )          X   subscript   subscript  X  v     v  V      similar-to      ùí©   ùùÅ  normal-Œ£       X=(X_{v})_{v\in V}\sim\mathcal{N}(\boldsymbol{\mu},\Sigma)   such that          (   Œ£   -  1    )    u  v    =   0  if      {  u  ,  v  }   ‚àâ  E    .     formulae-sequence     subscript   superscript  normal-Œ£    1      u  v     0  if       u  v   E     (\Sigma^{-1})_{uv}=0\quad\text{if}\quad\{u,v\}\notin E.    4  Inference  As in a Bayesian network, one may calculate the conditional distribution of a set of nodes     V  ‚Ä≤   =   {   v  1   ,  ‚Ä¶  ,   v  i   }        superscript  V  normal-‚Ä≤     subscript  v  1   normal-‚Ä¶   subscript  v  i      V^{\prime}=\{v_{1},\ldots,v_{i}\}   given values to another set of nodes     W  ‚Ä≤   =   {   w  1   ,  ‚Ä¶  ,   w  j   }        superscript  W  normal-‚Ä≤     subscript  w  1   normal-‚Ä¶   subscript  w  j      W^{\prime}=\{w_{1},\ldots,w_{j}\}   in the Markov random field by summing over all possible assignments to    u  ‚àâ    V  ‚Ä≤   ,   W  ‚Ä≤        u    superscript  V  normal-‚Ä≤    superscript  W  normal-‚Ä≤      u\notin V^{\prime},W^{\prime}   ; this is called exact inference . However, exact inference is a #P-complete problem, and thus computationally intractable in the general case. Approximation techniques such as Markov chain Monte Carlo and loopy belief propagation are often more feasible in practice. Some particular subclasses of MRFs, such as trees (see Chow‚ÄìLiu tree ), have polynomial-time inference algorithms; discovering such subclasses is an active research topic. There are also subclasses of MRFs that permit efficient MAP , or most likely assignment, inference; examples of these include associative networks. 5 6 Another interesting sub-class is the one of decomposable models (when the graph is chordal ): having a closed-form for the MLE , it is possible to discover a consistent structure for hundreds of variables. 7  Conditional random fields  One notable variant of a Markov random field is a conditional random field , in which each random variable may also be conditioned upon a set of global observations   o   o   o   . In this model, each function    œï  k     subscript  œï  k    \phi_{k}   is a mapping from all assignments to both the clique  k and the observations   o   o   o   to the nonnegative real numbers. This form of the Markov network may be more appropriate for producing discriminative classifiers , which do not model the distribution over the observations. CRFs were proposed by John D. Lafferty , Andrew McCallum and Fernando C.N. Pereira in 2001. 8  See also   Maximum entropy method  Hopfield network  Graphical model  Markov chain  Markov logic network  Hammersley‚ÄìClifford theorem  Interacting particle system  Probabilistic cellular automata  Log-linear analysis   References  External links   MRF implementation in C++ for regular 2D lattices   "  Category:Graphical models    Category:Probability theory     ‚Ü©  ‚Ü©  ‚Ü©  ‚Ü©  . ‚Ü©  . ‚Ü©  ‚Ü©  ‚Ü©     