


Taylor expansions for the moments of functions of random variables




Taylor expansions for the moments of functions of random variables

In probability theory, it is possible to approximate the moments of a function f of a random variable X using Taylor expansions, provided that f is sufficiently differentiable and that the moments of X are finite. This technique is often used by statisticians.
First moment



Notice that 
 
 
 
 , the 2nd term disappears. Also 
 
 
 
  is 
 
 
 
 . Therefore,


 
  where 
 
 
 
  and 
 
 
 
  are the mean and variance of X respectively.1
It is possible to generalize this to functions of more than one variable using multivariate Taylor expansions. For example,



Second moment
Analogously,2



The above is using a first order approximation unlike for the method used in estimating the first moment. It will be a poor approximation in cases where 
 
 
 
  is highly non-linear. This is a special case of the delta method. For example,



See also

Propagation of uncertainty
WKB approximation
http://web.stanford.edu/class/cme308/OldWebsite/notes/TaylorAppDeltaMethod.pdf

Notes
"
Category:Statistical approximations Category:Algebra of random variables



Haym Benaroya, Seon Mi Han, and Mark Nagurka. Probability Models in Engineering and Science. CRC Press, 2005.





