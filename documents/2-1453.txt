


Binary logarithm




Binary logarithm

(Figure)
Plot of log2 n

In mathematics, the binary logarithm () is the logarithm to the base 
 
 
. It is the inverse function of the power of two function. The binary logarithm of 
 
 
 
  is the power to which the number 
 
 
 
  must be raised to obtain the value 
 
 
 
 . That is:


 
  For example, the binary logarithm of 
 
 
 
  is 
 
 
 
 , the binary logarithm of 
 
 
 
  is 
 
 
 
 , the binary logarithm of 
 
 
 
  is 
 
 
 
 , the binary logarithm of 
 
 
 
  is 
 
 
 
 , the binary logarithm of 
 
 
 
  is 
 
 
 
  and the binary logarithm of 
 
 
 
  is 
 
 
 
 .
The binary logarithm is closely connected to the binary numeral system. Historically, the first application of binary logarithms was in music theory, by Leonhard Euler. Other areas in which the binary logarithm is frequently used include information theory, combinatorics, computer science, bioinformatics, the design of sports tournaments, and photography.
History
 Michael Stifel has been credted with publishing the first known table of binary logarithms, in 1544. His book Arthmetica Integra contains several tables that show the integers with their corresponding powers of two. Reversing the rows of these tables allow them to be interpreted as tables of binary logarithms.12
Binary logarithms were considered more explicitly by Leonhard Euler in 1739. Euler established their application to music theory, long before their more significant applications in information theory and computer science became known. As part of his work in this area, Euler published a table of binary logarithms of the integers from 1 to 8, to seven decimal digits of accuracy.34
Notation
In mathematics, the binary logarithm of a number 
 
 
 
  is written as . However, several other notations for this function have been used or proposed, especially in application areas.
Some authors write the binary logarithm as 
 
 
 
 .56 Donald Knuth credits this notation to a suggestion of Edward Reingold,7 but its use in both information theory and computer science dates to before Reingold was active.89 The binary logarithm has also been written as 
 
 
 
  with a prior statement that the default base for the logarithm is 
 
 
 
 .101112
Another notation that is sometimes used for the same function (especially in the German language) is 
 
 
 
 , from Latin logarithmus duālis.13 The ISO 31-11 and ISO 80000-2 specifications recommend yet another notation, 
 
 
 
 ; in this specification, 
 
 
 
  cannot be used for the binary logarithm, as it is instead reserved for . However, the ISO notation has not come into common use.
Applications
Information theory
The number of digits (bits) in the binary representation of a positive integer 
 
 
 
  is the integral part of , i.e.14



In information theory, the definition of the amount of self-information and information entropy is often expressed with the binary logarithm, corresponding to making the bit be the fundamental unit of information. However, the natural logarithm and the nat are also used in alternative notations for these definitions.15
Combinatorics
 Although the natural logarithm is more important than the binary logarithm in many areas of pure mathematics such as number theory and mathematical analysis, the binary logarithm has several applications in combinatorics:

Every binary tree with 
 
 
 
  leaves has height at least , with equality when 
 
 
 
  is a power of two and the tree is a complete binary tree.16
Every family of sets with 
 
 
 
  different sets has at least  elements in its union, with equality when the family is a power set.17
Every partial cube with 
 
 
 
  vertices has isometric dimension at least , and has at most  edges, with equality when the partial cube is a hypercube graph.18
According to Ramsey's theorem, every 
 
 
 
 -vertex undirected graph has either a clique or an independent set of size logarithmic in 
 
 
 
 . The precise size that can be guaranteed is not known, but the best bounds known on its size involve binary logarithms. In particular, all graphs have a clique or independent set of size at least  and almost all graphs do not have a clique or independent set of size larger than .19
From a mathematical analysis of the Gilbert–Shannon–Reeds model of random shuffles, one can show that the number of times one needs to shuffle an 
 
 
 
 -card deck of cards, using riffle shuffles, to get a distribution on permutations that is close to uniformly random, is approximately . This calculation forms the basis for a recommendation that 52-card decks should be shuffled seven times.20

Computational complexity
 The binary logarithm also frequently appears in the analysis of algorithms,21 not only because of the frequent use of binary number arithmetic in algorithms, but also because binary logarithms occur in the analysis of algorithms based on two-way branching.22 If a problem initially has 
 
 
 
  choices for its solution, and each iteration of the algorithm reduces the number of choices by a factor of two, then the number of iterations needed to select a single choice is again the integral part of . This idea is used in the analysis of several algorithms and data structures. For example, in binary search, the size of the problem to be solved is halved with each iteration, and therefore roughly  iterations are needed to obtain a problem of size 
 
 
 
 , which is solved easily in constant time. Similarly, a perfectly balanced binary search tree containing 
 
 
 
  elements has height .
However, the running time of an algorithm is usually expressed in big O notation, ignoring constant factors. Since , where 
 
 
 
  can be any number greater than 
 
 
 
 , algorithms that run in  time can also be said to run in, say,  time. The base of the logarithm in expressions such as 
 
 
 
  or 
 
 
 
  is therefore not important.23 In other contexts, though, the base of the logarithm needs to be specified. For example  is not the same as  because the former is equal to 
 
 
 
  and the latter to .
Algorithms with running time 
 
 
 
  are sometimes called linearithmic.24 Some examples of algorithms with running time 
 
 
 
  or 
 
 
 
  are:

Average time quicksort and other comparison sort algorithms25
Searching in balanced binary search trees26
Exponentiation by squaring27
Longest increasing subsequence28

Binary logarithms also occur in the exponents of the time bounds for some divide and conquer algorithms, such as the Karatsuba algorithm for multiplying 
 
 
 
 -bit numbers in time .29
Bioinformatics
 In the analysis of microarray data in bioinformatics, expression rates of genes are often compared by using the binary logarithm of the ratio of expression rates. By using base 
 
 
 
  for the logarithm, a doubled expression rate can be described by a log ratio of 
 
 
 
 , a halved expression rate can be described by a log ratio of 
 
 
 
 , and an unchanged expression rate can be described by a log ratio of zero, for instance.30 Data points obtained in this way are often visualized as a scatterplot in which one or both of the coordinate axes are binary logarithms of intensity ratios, or in visualizations such as the MA plot and RA plot which rotate and scale these log ratio scatterplots.31
Music theory
In music theory, the interval or perceptual difference between two tones is determined by the ratio of their frequencies. Intervals coming from rational number ratios with small numerators and denominators are perceived as particularly euphonius. The simplest and most important of these intervals is the octave, a frequency ratio of 
 
 
 
 . The number of octaves by which two tones differ is the binary logarithm of their frequency ratio.32
In order to study tuning systems and other aspects of music theory requiring finer distinctions between tones, it is helpful to have a measure of the size of an interval that is finer than an octave and is additive (as logarithms are) rather than multiplicative (as frequency ratios are). That is, if tones 
 
 
 
 , 
 
 
 
 , and 
 
 
 
  form a rising sequence of tones, then the measure of the interval from 
 
 
 
  to 
 
 
 
  plus the measure of the interval from 
 
 
 
  to 
 
 
 
  should equal the measure of the interval from 
 
 
 
  to 
 
 
 
 . Such a measure is given by the cent, which divides the octave into 
 
 
 
  equal intervals (
 
 
semitones of 
 
 
 
  cents each). Mathematically, given tones with frequencies  and , the number of cents in the interval from  to  is33


 
  The millioctave is defined in the same way, but with a multiplier of 
 
 
 
  instead of 
 
 
 
 .
Sports scheduling
In competitive games and sports involving two players or teams in each game or match, the binary logarithm indicates the number of rounds necessary in a single-elimination tournament in order to determine a winner. For example, a tournament of 
 
 
 
  players requires  rounds to determine the winner, a tournament of 
 
 
 
  teams requires  rounds, etc. In this case, for 
 
 
 
  players/teams where 
 
 
 
  is not a power of 2,  is rounded up since it will be necessary to have at least one round in which not all remaining competitors play. For example,  is approximately 
 
 
 
 , which rounds up to 
 
 
 
 , indicating that a tournament of 
 
 
 
  teams requires 
 
 
 
  rounds (either two teams will sit out the first round, or one team will sit out the second round). The same number of rounds is also necessary to determine a clear winner in a Swiss-system tournament.34
Photography
In photography, exposure values are measured in terms of the binary logarithm of the amount of light reaching the film or sensor, in accordance with the Weber–Fechner law describing a logarithmic response of the human visual system to light. A single stop of exposure is one unit on a base-
 
 
 
  logarithmic scale.3536 More precisely, the exposure value of a photograph is defined as


 
  where 
 
 
 
  is the f-number measuring the aperture of the lens during the exposure, and 
 
 
 
  is the number of seconds of exposure.
Binary logarithms (expressed as stops) are also used in densitometry, to express the dynamic range of light-sensitive materials or digital sensors.37
Calculation
(Figure)
TI SR-50 scientific calculator (1974). The ln and log keys are in the second row; there is no log2 key.

Conversion from other bases
An easy way to calculate  on calculators that do not have a  function is to use the natural logarithm (
 
 
 
 ) or the common logarithm (
 
 
 
  or ) functions, which are found on most scientific calculators. The specific change of logarithm base formulae for this are:3839


 
  or approximately



Integer rounding
The binary logarithm can be made into a function from integers and to integers by rounding it up or down. These two forms of integer binary logarithm are related by this formula:


40 The definition can be extended by defining 
 
 
 
 . Extended in this way, this function is related to the number of leading zeros of the 32-bit unsigned binary representation of 
 
 
 
 , 
 
 
 
 .


41
The integer binary logarithm can be interpreted as the zero-based index of the most significant 
 
 
 
  bit in the input. In this sense it is the complement of the find first set operation, which finds the index of the least significant 
 
 
 
  bit. Many hardware platforms include support for finding the number of leading zeros, or equivalent operations, which can be used to quickly find the binary logarithm; see find first set for details. The fls and flsl functions in the Linux kernel42 and in some versions of the libc software library also compute the binary logarithm (rounded up to an integer, plus one).
Recursive approximation
For a general positive real number, the binary logarithm may be computed in two parts:43

Compute the integer part, 
 
 
 
  (called the characteristic of the logarithm)
Compute the fractional part (the mantissa of the logarithm)

Computing the integer part is straightforward. For any 
 
 
 
 , there exists a unique integer 
 
 
 
  such that , or equivalently . Now the integer part of the logarithm is simply 
 
 
 
 , and the fractional part is .44 In other words:



The fractional part of the result is , and can be computed recursively, using only elementary multiplication and division.45 To compute the fractional part:

Start with a real number 
 
 
 
  in the half-open interval 
 
 
 
 . If 
 
 
 
 , then we are done and the fractional part is zero.
Otherwise, square 
 
 
 
  repeatedly until the result 
 
 
 
  lies in the interval 
 
 
 
 . Let 
 
 
 
  be the number of squarings needed. That is,  with 
 
 
 
  chosen such that 
 
 
 
  is in 
 
 
 
 .
Taking the logarithm of both sides and doing some algebra:
 
 :

\log_2 z &= 2^m \log_2 y \\ \log_2 y &= \frac{ \log_2 z }{ 2^m } \\ &= \frac{ 1 + \log_2(z/2) }{ 2^m } \\ &= 2^{-m} + 2^{-m}\log_2(z/2) \end{align}

Once again 
 
 
 
  is a real number in the interval 
 
 
 
 . Return to step 1, and compute the binary logarithm of 
 
 
 
  using the same method recursively.

The result of this is expressed by the following formulas, in which 
 
 
 
  is the number of squarings required in the i-th recursion of the algorithm:



In the special case where the fractional part in step 1 is found to be zero, this is a finite sequence terminating at some point. Otherwise, it is an infinite series which converges according to the ratio test, since each term is strictly less than the previous one (since every ). For practical use, this infinite series must be truncated to reach an approximate result. If the series is truncated after the 
 
 
 
 th term, then the error in the result is less than .
An alternative algorithm that computes a single bit of the output in each iteration, using a sequence of shift and comparison operations to determine which bit to output, is also possible.46
Software library support
The log2 function is included in the standard C mathematical functions. The default version of this function takes double precision arguments but variants of it allow the argument to be single-precision or to be a long double.47
References
External links


Feynman and the Connection Machine

"
Category:Binary arithmetic Category:Calculus Category:Logarithms



.↩
. A copy of the same table with two more entries appears on p. 237, and another copy extended to negative powers appears on p. 249b.↩
.↩
.↩
↩
.↩
, [http://books.google.com/books?id=x9AsAwAAQBAJ&pg;;=PA11 p. 11]. The same notation was in the 1973 2nd edition of the same book (p. 23) but without the credit to Reingold.↩
.↩
.↩
.↩
.↩
↩
For instance, see .↩

.↩
.↩
Equivalently, a family with 
 
 
 
  distinct elements has at most  distinct sets, with equality when it is a power set.↩
.↩
.↩
.↩



, [http://books.google.com/books?id=MTpsAQAAQBAJ&pg;;=PA186 p. 186].↩
Cormen et al., p. 156; Goodrich & Tamassia, p. 238.↩
Cormen et al., p. 276; Goodrich & Tamassia, p. 159.↩
Cormen et al., pp. 879–880; Goodrich & Tamassia, p. 464.↩
.↩
Cormen et al., p. 844; Goodrich & Tamassia, p. 279.↩
.↩
.↩
.↩

.↩
.↩
.↩
.↩

.↩
↩

fls, Linux kernel API, kernel.org, retrieved 2010-10-17.↩
.↩


.↩
.↩




