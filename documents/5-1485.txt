   Symmetric bilinear form      Symmetric bilinear form   A symmetric bilinear form on a vector space is a linear map from two copies of the vector space to the field of scalars such that the order of the two vectors does not affect the value of the map. In other words, it is a bilinear function   B   B   B   that maps every pair    (  u  ,  v  )     u  v    (u,v)   of elements of the vector space   V   V   V   to the underlying field such that     B   (  u  ,  v  )    =   B   (  v  ,  u  )          B   u  v      B   v  u      B(u,v)=B(v,u)   for every   u   u   u   and   v   v   v   in   V   V   V   . They are also referred to more briefly as just symmetric forms when "bilinear" is understood.  Symmetric bilinear forms on finite-dimensional vector spaces precisely correspond to symmetric matrices given a basis for V . Among bilinear forms, the symmetric ones are important because they are the ones for which the vector space admits a particularly simple kind of basis known as an orthogonal basis (at least when the characteristic of the field is not 2).  Given a symmetric bilinear form B , the function  is the associated quadratic form on the vector space. Moreover, if the characteristic of the field is not 2, B is the unique symmetric bilinear form associated with q .  Formal definition  Let '' V'' be a vector space of dimension n over a field K . A map     B  :    V  Ã—  V   â†’  K      normal-:  B   normal-â†’    V  V   K     B:V\times V\rightarrow K   is a symmetric bilinear form on the space if:         B   (  u  ,  v  )    =    B   (  v  ,  u  )     âˆ€  u     ,   v  âˆˆ  V      formulae-sequence      B   u  v       B   v  u     for-all  u       v  V     B(u,v)=B(v,u)\ \quad\forall u,v\in V           B   (   u  +  v   ,  w  )    =     B   (  u  ,  w  )    +   B   (  v  ,  w  )      âˆ€  u   ,  v    ,   w  âˆˆ  V      formulae-sequence      B     u  v   w         B   u  w      B   v  w      for-all  u   v      w  V     B(u+v,w)=B(u,w)+B(v,w)\ \quad\forall u,v,w\in V           B   (   Î»  v   ,  w  )    =   Î»  B   (  v  ,  w  )        âˆ€  Î»   âˆˆ   K  ,   âˆ€  v     ,   w  âˆˆ  V       formulae-sequence      B     Î»  v   w      Î»  B   v  w      formulae-sequence     for-all  Î»    K   for-all  v       w  V      B(\lambda v,w)=\lambda B(v,w)\ \quad\forall\lambda\in K,\forall v,w\in V      The last two axioms only imply linearity in the first argument, but the first axiom then immediately implies linearity in the second argument as well.  Examples  Let , the n dimensional real vector space. Then the standard dot product is a symmetric bilinear form, . The matrix corresponding to this bilinear form (see below) on a standard basis is the identity matrix.  Let V be any vector space (including possibly infinite-dimensional), and assume T 1 and T 2 are linear functions from V to the field. Then the function defined by is a symmetric bilinear form.  Let V be the vector space of continuous single-variable real functions. For     f  ,  g   âˆˆ  V       f  g   V    f,g\in V   one can define     B   (  f  ,  g  )    =    âˆ«  0  1    f   (  t  )   g   (  t  )   d  t          B   f  g      superscript   subscript   0   1     f  t  g  t  d  t      B(f,g)=\int_{0}^{1}f(t)g(t)dt   . By the properties of definite integrals , this defines a symmetric bilinear form on V . This is an example of a symmetric bilinear form which is not associated to any symmetric matrix (since the vector space is infinite-dimensional).  Matrix representation  Let    C  =   {   e  1   ,  â€¦  ,   e  n   }       C    subscript  e  1   normal-â€¦   subscript  e  n      C=\{e_{1},\ldots,e_{n}\}   be a basis for V . Define the  matrix A by     A   i  j    =   B   (   e  i   ,   e  j   )         subscript  A    i  j      B    subscript  e  i    subscript  e  j       A_{ij}=B(e_{i},e_{j})   . The matrix A is a symmetric matrix exactly due to symmetry of the bilinear form. If the n Ã—1 matrix x represents a vector v with respect to this basis, and analogously, y represents w , then    B   (  v  ,  w  )       B   v  w     B(v,w)   is given by :         x  ð–³   A  y   =    y  ð–³   A  x    .         superscript  x  ð–³   A  y      superscript  y  ð–³   A  x     x^{\mathsf{T}}Ay=y^{\mathsf{T}}Ax.     Suppose '' C' '' is another basis for V , with :     [      e  1  â€²     â‹¯     e  n  â€²      ]   =    [      e  1     â‹¯     e  n      ]   S          subscript   superscript  e  normal-â€²   1   normal-â‹¯   subscript   superscript  e  normal-â€²   n          subscript  e  1   normal-â‹¯   subscript  e  n     S     \begin{bmatrix}e^{\prime}_{1}&\cdots&e^{\prime}_{n}\end{bmatrix}=\begin{%
 bmatrix}e_{1}&\cdots&e_{n}\end{bmatrix}S   with S an invertible n Ã— n matrix. Now the new matrix representation for the symmetric bilinear form is given by        A  â€²   =    S  ð–³   A  S    .       superscript  A  normal-â€²      superscript  S  ð–³   A  S     A^{\prime}=S^{\mathsf{T}}AS.     Orthogonality and singularity  A symmetric bilinear form is always reflexive . Two vectors v and w are defined to be orthogonal with respect to the bilinear form B if , which is, due to reflexivity, equivalent to .  The radical of a bilinear form B is the set of vectors orthogonal with every vector in V . That this is a subspace of V follows from the linearity of B in each of its arguments. When working with a matrix representation A with respect to a certain basis, v , represented by x , is in the radical if and only if        A  x   =  0   âŸº     x  ð–³   A   =  0.      normal-âŸº      A  x   0        superscript  x  ð–³   A   0.     Ax=0\Longleftrightarrow x^{\mathsf{T}}A=0.     The matrix A is singular if and only if the radical is nontrivial.  If W is a subset of V , then its orthogonal complement  W âŠ¥ is the set of all vectors in V that are orthogonal to every vector in W ; it is a subspace of V . When B is non-degenerate, the radical of B is trivial and the dimension of W âŠ¥ is .  Orthogonal basis  A basis    C  =   {   e  1   ,  â€¦  ,   e  n   }       C    subscript  e  1   normal-â€¦   subscript  e  n      C=\{e_{1},\ldots,e_{n}\}   is orthogonal with respect to B if and only if :        B   (   e  i   ,   e  j   )    =    0    âˆ€  i    â‰   j   .          B    subscript  e  i    subscript  e  j       0   for-all  i         j     B(e_{i},e_{j})=0\ \forall i\neq j.     When the characteristic of the field is not two, V always has an orthogonal basis. This can be proven by induction .  A basis C is orthogonal if and only if the matrix representation A is a diagonal matrix .  Signature and Sylvester's law of inertia  In a more general form, Sylvester's law of inertia says that, when working over an ordered field , the numbers of diagonal elements in the diagonalized form of a matrix that are positive, negative and zero respectively are independent of the chosen orthogonal basis. These three numbers form the signature of the bilinear form.  Real case  When working in a space over the reals, one can go a bit a further. Let    C  =   {   e  1   ,  â€¦  ,   e  n   }       C    subscript  e  1   normal-â€¦   subscript  e  n      C=\{e_{1},\ldots,e_{n}\}   be an orthogonal basis.  We define a new basis     C  â€²   =   {   e  1  â€²   ,  â€¦  ,   e  n  â€²   }        superscript  C  normal-â€²     subscript   superscript  e  normal-â€²   1   normal-â€¦   subscript   superscript  e  normal-â€²   n      C^{\prime}=\{e^{\prime}_{1},\ldots,e^{\prime}_{n}\}          e  i  â€²   =   {      e  i       if  B   (   e  i   ,   e  i   )    =  0          e  i     B   (   e  i   ,   e  i   )           if  B   (   e  i   ,   e  i   )    >  0          e  i     -   B   (   e  i   ,   e  i   )            if  B   (   e  i   ,   e  i   )    <  0            subscript   superscript  e  normal-â€²   i    cases   subscript  e  i       if  B    subscript  e  i    subscript  e  i     0      subscript  e  i       B    subscript  e  i    subscript  e  i           if  B    subscript  e  i    subscript  e  i     0      subscript  e  i         B    subscript  e  i    subscript  e  i            if  B    subscript  e  i    subscript  e  i     0      e^{\prime}_{i}=\begin{cases}e_{i}&\text{if }B(e_{i},e_{i})=0\\
 \frac{e_{i}}{\sqrt{B(e_{i},e_{i})}}&\text{if }B(e_{i},e_{i})>0\\
 \frac{e_{i}}{\sqrt{-B(e_{i},e_{i})}}&\text{if }B(e_{i},e_{i})<0\end{cases}     Now, the new matrix representation A will be a diagonal matrix with only 0, 1 and âˆ’1 on the diagonal. Zeroes will appear if and only if the radical is nontrivial.  Complex case  When working in a space over the complex numbers, one can go further as well and it is even easier. Let    C  =   {   e  1   ,  â€¦  ,   e  n   }       C    subscript  e  1   normal-â€¦   subscript  e  n      C=\{e_{1},\ldots,e_{n}\}   be an orthogonal basis.  We define a new basis     C  â€²   =   {   e  1  â€²   ,  â€¦  ,   e  n  â€²   }        superscript  C  normal-â€²     subscript   superscript  e  normal-â€²   1   normal-â€¦   subscript   superscript  e  normal-â€²   n      C^{\prime}=\{e^{\prime}_{1},\ldots,e^{\prime}_{n}\}   :       e  i  â€²   =   {      e  i        if   B   (   e  i   ,   e  i   )    =  0         e  i   /    B   (   e  i   ,   e  i   )           if   B   (   e  i   ,   e  i   )    â‰   0            subscript   superscript  e  normal-â€²   i    cases   subscript  e  i       if  B    subscript  e  i    subscript  e  i     0      subscript  e  i       B    subscript  e  i    subscript  e  i           if  B    subscript  e  i    subscript  e  i     0      e^{\prime}_{i}=\begin{cases}e_{i}&\text{if }\;B(e_{i},e_{i})=0\\
 e_{i}/\sqrt{B(e_{i},e_{i})}&\text{if }\;B(e_{i},e_{i})\neq 0\\
 \end{cases}     Now the new matrix representation A will be a diagonal matrix with only 0 and 1 on the diagonal. Zeroes will appear if and only if the radical is nontrivial.  Orthogonal polarities  Let B be a symmetric bilinear form with a trivial radical on the space V over the field K with characteristic not 2. One can now define a map from D( V ), the set of all subspaces of V , to itself:       Î±  :    D   (  V  )    â†’   D   (  V  )     :   W  â†¦   W  âŸ‚     .       normal-:  Î±   normal-â†’    D  V     D  V      normal-:     maps-to  W   superscript  W  perpendicular-to       \alpha:D(V)\rightarrow D(V):W\mapsto W^{\perp}.     This map is an orthogonal polarity on the projective space PG( W ). Conversely, one can prove all orthogonal polarities are induced in this way, and that two symmetric bilinear forms with trivial radical induce the same polarity if and only if they are equal up to scalar multiplication.  References       "  Category:Bilinear forms   