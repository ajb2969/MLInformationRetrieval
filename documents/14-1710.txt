   Rank SIFT      Rank SIFT   Rank SIFT algorithm is the revised SIFT ( Scale-invariant feature transform ) algorithm which uses ranking techniques to improve the performance of the SIFT algorithm. In fact, ranking techniques can be used in key point localization or descriptor generation of the original SIFT algorithm.  SIFT With Ranking Techniques  Ranking the Key Point  Ranking techniques can be used to keep certain number of key points which are detected by SIFT detector. 1  Suppose    {      I  m   ,  m   =  0   ,   1  ,   …  M     }      formulae-sequence      subscript  I  m   m   0    1    normal-…  M       \left\{I_{m},m=0,1,...M\right\}   is a training image sequence and   p   p   p   is a key point obtained by SIFT detector. The following equation determines the rank of   p   p   p   in the key point set. Larger value of    R   (  p  )       R  p    R(p)   corresponds to the higher rank of   p   p   p   .      R   (  p  ∈   I  0   )   =   ∑  m   I   (   min   q  ∈   I  m       ∥   H  m    (  p  )   -  q  ∥   2   <  ϵ  )   ,     fragments  R   fragments  normal-(  p    subscript  I  0   normal-)     subscript   m   I   fragments  normal-(   subscript     q   subscript  I  m      subscript   fragments  normal-∥   subscript  H  m    fragments  normal-(  p  normal-)    q  normal-∥   2    ϵ  normal-)   normal-,    R(p\in I_{0})=\sum_{m}I(\min_{q\in I_{m}}{\lVert H_{m}(p)-q\rVert}_{2}<%
 \epsilon),     where    I   (  .  )      fragments  I   fragments  normal-(  normal-.  normal-)     I(.)   is the indicator function,    H  m     subscript  H  m    H_{m}   is the homography transformation from    I  0     subscript  I  0    I_{0}   to    I  m     subscript  I  m    I_{m}   , and   ϵ   ϵ   \epsilon   is the threshold.  Suppose    x  i     subscript  x  i    x_{i}   is the feature descriptor of key point    p  i     subscript  p  i    p_{i}   defined above. So    x  i     subscript  x  i    x_{i}   can be labeled with the rank of    p  i     subscript  p  i    p_{i}   in the feature vector space. Then the vector set     X   f  e  a  t  u  r  e  s  p  a  c  e    =   {    x  →   1   ,    x  →   2   ,  …  }        subscript  X    f  e  a  t  u  r  e  s  p  a  c  e      subscript   normal-→  x   1    subscript   normal-→  x   2   normal-…     X_{featurespace}=\left\{\vec{x}_{1},\vec{x}_{2},...\right\}   containing labeled elements can be used as a training set for the Ranking SVM 2 problem.  The learning process can be represented as follows:          m  i  n  i  m  i  z  e   :    V   (   w  →   )    =     1  2    w  →    ⋅   w  →              s  .  t   .               ∀      x  →   i    a  n   d     x  →   j     ∈   X   f  e  a  t  u  r  e  s  p  a  c  e     ,            w  →   T    (    x  →   i   -    x  →   j   )   ≧  1  i   f   R   (   p  i   ∈   I  0   )   >  R   (   p  j   ∈   I  0   )   .                 normal-:    m  i  n  i  m  i  z  e       V   normal-→  w     normal-⋅      1  2    normal-→  w     normal-→  w       missing-subexpression    missing-subexpression      formulae-sequence  s  t    missing-subexpression    missing-subexpression          for-all     subscript   normal-→  x   i   a  n  d   subscript   normal-→  x   j      subscript  X    f  e  a  t  u  r  e  s  p  a  c  e      missing-subexpression    missing-subexpression      fragments   superscript   normal-→  w   T    fragments  normal-(   subscript   normal-→  x   i     subscript   normal-→  x   j   normal-)    1  normal-  i  f  R   fragments  normal-(   subscript  p  i     subscript  I  0   normal-)    R   fragments  normal-(   subscript  p  j     subscript  I  0   normal-)   normal-.    missing-subexpression    missing-subexpression      missing-subexpression    missing-subexpression      \begin{array}[]{lcl}minimize:V(\vec{w})={1\over 2}\vec{w}\cdot\vec{w}\\
 s.t.\\
 \begin{array}[]{lcl}\forall\ \vec{x}_{i}\ and\ \vec{x}_{j}\in X_{featurespace}%
 ,\\
 \vec{w}^{T}(\vec{x}_{i}-\vec{x}_{j})\geqq 1\quad if\ R(p_{i}\in I_{0})>R(p_{j}%
 \in I_{0}).\end{array}\end{array}     The obtained optimal     w  →   *     superscript   normal-→  w      \vec{w}^{*}   can be used to order the future key points.  Ranking the Elements of Descriptor  Ranking techniques also can be used to generate the key point descriptor. 3  Suppose     X  →   =   {   x  1   ,  …  ,   x  N   }        normal-→  X     subscript  x  1   normal-…   subscript  x  N      {\vec{X}}=\left\{x_{1},...,x_{N}\right\}   is the feature vector of a key point and the elements of    R  =   {   r  1   ,   …   r  N    }       R    subscript  r  1     normal-…   subscript  r  N       {R}=\left\{r_{1},...r_{N}\right\}   is the corresponding rank of    x  i     subscript  x  i    x_{i}   in   X   X   X   .    r  i     subscript  r  i    r_{i}   is defined as follows:        r  i   =   |   {   x  k   :    x  k   ≧   x  i    }   |    .       subscript  r  i      conditional-set   subscript  x  k      subscript  x  k    subscript  x  i        r_{i}=\left|\left\{x_{k}:x_{k}\geqq x_{i}\right\}\right|.     After transforming original feature vector    X  →     normal-→  X    \vec{X}   to the ordinal descriptor    R  →     normal-→  R    \vec{R}   , the difference between two ordinal descriptors can be evaluated in the following two measurements.   The Spearman corelation coefficient   The spearman correlation coefficient also refers to Spearman's rank correlation coefficient . For two ordinal descriptors    R  →     normal-→  R    \vec{R}   and     R  →     ′      superscript   normal-→  R    normal-′     \vec{R}^{^{\prime}}   , it can be proved that       ρ   (   R  →   ,    R  →     ′    )    =   1  -    6    ∑   i  =  1   N     (    r  i   -   r  i    ′     )   2      N   (    N  2   -  1   )            ρ    normal-→  R    superscript   normal-→  R    normal-′        1      6    superscript   subscript     i  1    N    superscript     subscript  r  i    superscript   subscript  r  i    normal-′     2       N     superscript  N  2   1        \rho(\vec{R},\vec{R}^{^{\prime}})=1-{6\sum_{i=1}^{N}(r_{i}-r_{i}^{^{\prime}})^%
 {2}\over N(N^{2}-1)}      The Kendall's Tau   The Kedall's Tau also refers to Kendall tau rank correlation coefficient . In the above case, the Kedall's Tau between   R   R   R   and    R    ′      superscript  R   normal-′     R^{^{\prime}}   is        τ   (   R  →   ,    R  →     ′    )    =    2    ∑   i  =  1   N     ∑   j  =   i  +  1    N    s   (    r  i   -   r  j    ,    r  i    ′    -   r  j    ′     )        N   (   N  -  1   )      ,        τ    normal-→  R    superscript   normal-→  R    normal-′          2    superscript   subscript     i  1    N     superscript   subscript     j    i  1     N     s      subscript  r  i    subscript  r  j       superscript   subscript  r  i    normal-′     superscript   subscript  r  j    normal-′            N    N  1       \tau(\vec{R},\vec{R}^{^{\prime}})={2\sum_{i=1}^{N}\sum_{j=i+1}^{N}s(r_{i}-r_{j%
 },r_{i}^{^{\prime}}-r_{j}^{^{\prime}})\over N(N-1)},         w  h  e  r  e    s   (  a  ,  b  )     =   {      1  ,       if  s  i  g  n   (  a  )    =   s  i  g  n   (  b  )           -  1   ,       o  .  w   .              w  h  e  r  e     s   a  b      cases  1      if  s  i  g  n  a     s  i  g  n  b      1    formulae-sequence  o  w      where\quad s(a,b)=\begin{cases}1,&\text{if }sign(a)=sign(b)\\
 -1,&o.w.\end{cases}     References  "  Category:Articles created via the Article Wizard  Category:Object recognition and categorization     Bing Li; Rong Xiao; Zhiwei Li; Rui Cai; Bao-Liang Lu; Lei Zhang; "Rank-SIFT: Learning to rank repeatable local interest points",Computer Vision and Pattern Recognition (CVPR), 2011 ↩  Joachims, T. (2003), "Optimizing Search Engines using Clickthrough Data", Proceedings of the ACM Conference on Knowledge Discovery and Data Mining ↩  Toews, M.; Wells, W."SIFT-Rank: Ordinal Description for Invariant Feature Correspondence",Computer Vision and Pattern Recognition, 2009. ↩     