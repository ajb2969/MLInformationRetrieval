<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="1434">Robust statistics</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>Robust statistics</h1>
<hr/>

<p><strong>Robust statistics</strong> are <a href="statistic" title="wikilink">statistics</a> with good performance for data drawn from a wide range of <a href="probability_distribution" title="wikilink">probability distributions</a>, especially for distributions that are not <a href="normal_distribution" title="wikilink">normal</a>. Robust <a href="Statistics" title="wikilink">statistical</a> methods have been developed for many common problems, such as estimating <a href="location_parameter" title="wikilink">location</a>, <a href="scale_parameter" title="wikilink">scale</a> and <a href="regression_coefficient" title="wikilink">regression parameters</a>. One motivation is to produce <a href="statistical_method" title="wikilink">statistical methods</a> that are not unduly affected by <a href="outlier" title="wikilink">outliers</a>. Another motivation is to provide methods with good performance when there are small departures from parametric distributions. For example, robust methods work well for mixtures of two normal distributions with different standard-deviations, for example, one and three; under this model, non-robust methods like a t-test work badly.</p>
<h2 id="introduction">Introduction</h2>

<p>Robust statistics seeks to provide methods that emulate popular statistical methods, but which are not unduly affected by <a class="uri" href="outliers" title="wikilink">outliers</a> or other small departures from <a href="Statistical_assumption" title="wikilink">model assumptions</a>. In <a class="uri" href="statistics" title="wikilink">statistics</a>, classical estimation methods rely heavily on assumptions which are often not met in practice. In particular, it is often assumed that the data errors are normally distributed, at least approximately, or that the <a href="central_limit_theorem" title="wikilink">central limit theorem</a> can be relied on to produce normally distributed estimates. Unfortunately, when there are outliers in the data, classical <a href="estimator" title="wikilink">estimators</a> often have very poor performance, when judged using the <em><a href="#Breakdown_point" title="wikilink">breakdown point</a></em> and the <em><a href="#Influence_function_and_sensitivity_curve" title="wikilink">influence function</a></em>, described below.</p>

<p>The practical effect of problems seen in the influence function can be studied empirically by examining the <a href="sampling_distribution" title="wikilink">sampling distribution</a> of proposed estimators under a <a href="mixture_model" title="wikilink">mixture model</a>, where one mixes in a small amount (1–5% is often sufficient) of contamination. For instance, one may use a mixture of 95% a normal distribution, and 5% a normal distribution with the same mean but significantly higher standard deviation (representing outliers).</p>

<p>Robust <a href="parametric_statistics" title="wikilink">parametric statistics</a> can proceed in two ways:</p>
<ul>
<li>by designing estimators so that a pre-selected behaviour of the influence function is achieved</li>
<li>by replacing estimators that are optimal under the assumption of a normal distribution with estimators that are optimal for, or at least derived for, other distributions: for example using the <a href="Student's_t-distribution" title="wikilink"><em>t</em>-distribution</a> with low degrees of freedom (high kurtosis; degrees of freedom between 4 and 6 have often been found to be useful in practice ) or with a <a href="Mixture_density" title="wikilink">mixture</a> of two or more distributions.</li>
</ul>

<p>Robust estimates have been studied for the following problems:</p>
<dl>
<dd>estimating <a href="location_parameter" title="wikilink">location parameters</a>
</dd>
<dd>estimating <a href="scale_parameter" title="wikilink">scale parameters</a>
</dd>
<dd>estimating <a href="regression_coefficient" title="wikilink">regression coefficients</a>
</dd>
<dd>estimation of model-states in models expressed in <a href="State_space_(controls)" title="wikilink">state-space</a> form, for which the standard method is equivalent to a <a href="Kalman_filter" title="wikilink">Kalman filter</a>.
</dd>
</dl>
<h2 id="examples">Examples</h2>
<ul>
<li>The <a class="uri" href="median" title="wikilink">median</a> is a robust measure of <a href="central_tendency" title="wikilink">central tendency</a>, while the <a href="Arithmetic_mean" title="wikilink">mean</a> is not. The median has a breakdown point of 50%, while the mean has a breakdown point of 0% (a single large observation can throw it off).</li>
<li>The <a href="median_absolute_deviation" title="wikilink">median absolute deviation</a> and <a href="interquartile_range" title="wikilink">interquartile range</a> are robust measures of <a href="statistical_dispersion" title="wikilink">statistical dispersion</a>, while the <a href="standard_deviation" title="wikilink">standard deviation</a> and <a href="range_(statistics)" title="wikilink">range</a> are not.</li>
</ul>

<p><a href="Trimmed_estimator" title="wikilink">Trimmed estimators</a> and <a href="Winsorising" title="wikilink">Winsorised estimators</a> are general methods to make statistics more robust. <a href="L-estimator" title="wikilink">L-estimators</a> are a general class of simple statistics, often robust, while <a href="#M-estimators" title="wikilink">M-estimators</a> are a general class of robust statistics, and are now the preferred solution, though they can be quite involved to calculate.</p>
<h2 id="definition">Definition</h2>

<p>There are various definitions of a "robust statistic." Strictly speaking, a <strong>robust statistic</strong> is resistant to errors in the results, produced by deviations from assumptions<a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a> (e.g., of normality). This means that if the assumptions are only approximately met, the <strong>robust estimator</strong> will still have a reasonable <a href="efficiency_(statistics)" title="wikilink">efficiency</a>, and reasonably small <a href="bias_(statistics)" title="wikilink">bias</a>, as well as being <a href="asymptotically_unbiased" title="wikilink">asymptotically unbiased</a>, meaning having a bias tending towards 0 as the sample size tends towards infinity.</p>

<p>One of the most important cases is distributional robustness.<a class="footnoteRef" href="#fn2" id="fnref2"><sup>2</sup></a> Classical statistical procedures are typically sensitive to "longtailedness" (e.g., when the distribution of the data has longer tails than the assumed normal distribution). Thus, in the context of robust statistics, <em>distributionally robust</em> and <em>outlier-resistant</em> are effectively synonymous.<a class="footnoteRef" href="#fn3" id="fnref3"><sup>3</sup></a> For one perspective on research in robust statistics up to 2000, see Portnoy and He (2000).</p>

<p>A related topic is that of <a href="resistant_statistics" title="wikilink">resistant statistics</a>, which are resistant to the effect of extreme scores.</p>
<h2 id="example-speed-of-light-data">Example: speed of light data</h2>

<p>Gelman et al. in Bayesian Data Analysis (2004) consider a data set relating to speed of light measurements made by <a href="Simon_Newcomb" title="wikilink">Simon Newcomb</a>. The data sets for that book can be found via the <a href="Classic_data_sets" title="wikilink">Classic data sets</a> page, and the book's website contains more information on the data.</p>

<p>Although the bulk of the data look to be more or less normally distributed, there are two obvious outliers. These outliers have a large effect on the mean, dragging it towards them, and away from the center of the bulk of the data. Thus, if the mean is intended as a measure of the location of the center of the data, it is, in a sense, biased when outliers are present.</p>

<p>Also, the distribution of the mean is known to be asymptotically normal due to the central limit theorem. However, outliers can make the distribution of the mean non-normal even for fairly large data sets. Besides this non-normality, the mean is also <a href="Efficiency_(statistics)" title="wikilink">inefficient</a> in the presence of outliers and less variable measures of location are available.</p>
<h3 id="estimation-of-location">Estimation of location</h3>

<p>The plot below shows a density plot of the speed of light data, together with a rug plot (panel (a)). Also shown is a normal <a href="Q–Q_plot" title="wikilink">Q–Q plot</a> (panel (b)). The outliers are clearly visible in these plots.</p>

<p>Panels (c) and (d) of the plot show the bootstrap distribution of the mean (c) and the 10% <a href="trimmed_mean" title="wikilink">trimmed mean</a> (d). The trimmed mean is a simple robust estimator of location that deletes a certain percentage of observations (10% here) <em>from each end</em> of the data, then computes the mean in the usual way. The analysis was performed in <a href="R_(programming_language)" title="wikilink">R</a> and 10,000 <a href="bootstrapping_(statistics)" title="wikilink">bootstrap</a> samples were used for each of the raw and trimmed means.</p>

<p>The distribution of the mean is clearly much wider than that of the 10% trimmed mean (the plots are on the same scale). Also note that whereas the distribution of the trimmed mean appears to be close to normal, the distribution of the raw mean is quite skewed to the left. So, in this sample of 66 observations, only 2 outliers cause the central limit theorem to be inapplicable.</p>
<figure><b>(Figure)</b>
<figcaption>speedOfLight.png</figcaption>
</figure>

<p>Robust statistical methods, of which the trimmed mean is a simple example, seek to outperform classical statistical methods in the presence of outliers, or, more generally, when underlying parametric assumptions are not quite correct.</p>

<p>Whilst the trimmed mean performs well relative to the mean in this example, better robust estimates are available. In fact, the mean, median and trimmed mean are all special cases of <a class="uri" href="M-estimators" title="wikilink">M-estimators</a>. Details appear in the sections below.</p>
<h3 id="estimation-of-scale">Estimation of scale</h3>

<p>The outliers in the speed of light data have more than just an adverse effect on the mean; the usual estimate of scale is the standard deviation, and this quantity is even more badly affected by outliers because the squares of the deviations from the mean go into the calculation, so the outliers' effects are exacerbated.</p>

<p>The plots below show the bootstrap distributions of the standard deviation, <a href="median_absolute_deviation" title="wikilink">median absolute deviation</a> (MAD) and <a href="Robust_measures_of_scale#Robust_measures_of_scale_based_on_absolute_pairwise_differences" title="wikilink">Qn estimator</a> of scale (Rousseeuw and Croux, 1993). The plots are based on 10000 bootstrap samples for each estimator, with some Gaussian noise added to the resampled data (<a href="smoothed_bootstrap" title="wikilink">smoothed bootstrap</a>). Panel (a) shows the distribution of the standard deviation, (b) of the MAD and (c) of Qn.</p>
<figure><b>(Figure)</b>
<figcaption>speedOfLightScale.png</figcaption>
</figure>

<p>The distribution of standard deviation is erratic and wide, a result of the outliers. The MAD is better behaved, and Qn is a little bit more efficient than MAD. This simple example demonstrates that when outliers are present, the standard deviation cannot be recommended as an estimate of scale.</p>
<h3 id="manual-screening-for-outliers">Manual screening for outliers</h3>

<p>Traditionally, statisticians would manually screen data for <a class="uri" href="outliers" title="wikilink">outliers</a>, and remove them, usually checking the source of the data to see if the outliers were erroneously recorded. Indeed, in the speed of light example above, it is easy to see and remove the two outliers prior to proceeding with any further analysis. However, in modern times, data sets often consist of large numbers of variables being measured on large numbers of experimental units. Therefore, manual screening for outliers is often impractical.</p>

<p>Outliers can often interact in such a way that they mask each other. As a simple example, consider a small univariate data set containing one modest and one large outlier. The estimated standard deviation will be grossly inflated by the large outlier. The result is that the modest outlier looks relatively normal. As soon as the large outlier is removed, the estimated standard deviation shrinks, and the modest outlier now looks unusual.</p>

<p>This problem of masking gets worse as the complexity of the data increases. For example, in regression problems, diagnostic plots are used to identify outliers. However, it is common that once a few outliers have been removed, others become visible. The problem is even worse in higher dimensions.</p>

<p>Robust methods provide automatic ways of detecting, downweighting (or removing), and flagging outliers, largely removing the need for manual screening. Care must be taken; initial data showing the <a href="ozone_hole" title="wikilink">ozone hole</a> first appearing over Antarctica were rejected as outliers by non-human screening<a class="footnoteRef" href="#fn4" id="fnref4"><sup>4</sup></a></p>
<h3 id="variety-of-applications">Variety of applications</h3>

<p>Although this article deals with general principles for univariate statistical methods, robust methods also exist for regression problems, generalized linear models, and parameter estimation of various distributions.</p>
<h2 id="measures-of-robustness">Measures of robustness</h2>

<p>The basic tools used to describe and measure robustness are, the <em>breakdown point</em>, the <em>influence function</em> and the <em>sensitivity curve</em>.</p>
<h3 id="breakdown-point">Breakdown point</h3>

<p>Intuitively, the breakdown point of an <a class="uri" href="estimator" title="wikilink">estimator</a> is the proportion of incorrect observations (e.g. arbitrarily large observations) an estimator can handle before giving an incorrect (e.g., arbitrarily large) result. For example, given 

<math display="inline" id="Robust_statistics:0">
 <semantics>
  <mi>n</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>n</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   n
  </annotation>
 </semantics>
</math>

 independent random variables 

<math display="inline" id="Robust_statistics:1">
 <semantics>
  <mrow>
   <mo stretchy="false">(</mo>
   <msub>
    <mi>X</mi>
    <mn>1</mn>
   </msub>
   <mo>,</mo>
   <mi mathvariant="normal">…</mi>
   <mo>,</mo>
   <msub>
    <mi>X</mi>
    <mi>n</mi>
   </msub>
   <mo stretchy="false">)</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <vector>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>X</ci>
     <cn type="integer">1</cn>
    </apply>
    <ci>normal-…</ci>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>X</ci>
     <ci>n</ci>
    </apply>
   </vector>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   (X_{1},\dots,X_{n})
  </annotation>
 </semantics>
</math>

 and the corresponding realizations 

<math display="inline" id="Robust_statistics:2">
 <semantics>
  <mrow>
   <msub>
    <mi>x</mi>
    <mn>1</mn>
   </msub>
   <mo>,</mo>
   <mi mathvariant="normal">…</mi>
   <mo>,</mo>
   <msub>
    <mi>x</mi>
    <mi>n</mi>
   </msub>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <list>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>x</ci>
     <cn type="integer">1</cn>
    </apply>
    <ci>normal-…</ci>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>x</ci>
     <ci>n</ci>
    </apply>
   </list>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   x_{1},\dots,x_{n}
  </annotation>
 </semantics>
</math>

, we can use 

<math display="inline" id="Robust_statistics:3">
 <semantics>
  <mrow>
   <mover accent="true">
    <msub>
     <mi>X</mi>
     <mi>n</mi>
    </msub>
    <mo>¯</mo>
   </mover>
   <mo>:=</mo>
   <mfrac>
    <mrow>
     <msub>
      <mi>X</mi>
      <mn>1</mn>
     </msub>
     <mo>+</mo>
     <mi mathvariant="normal">⋯</mi>
     <mo>+</mo>
     <msub>
      <mi>X</mi>
      <mi>n</mi>
     </msub>
    </mrow>
    <mi>n</mi>
   </mfrac>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="latexml">assign</csymbol>
    <apply>
     <ci>normal-¯</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>X</ci>
      <ci>n</ci>
     </apply>
    </apply>
    <apply>
     <divide></divide>
     <apply>
      <plus></plus>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>X</ci>
       <cn type="integer">1</cn>
      </apply>
      <ci>normal-⋯</ci>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>X</ci>
       <ci>n</ci>
      </apply>
     </apply>
     <ci>n</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \overline{X_{n}}:=\frac{X_{1}+\cdots+X_{n}}{n}
  </annotation>
 </semantics>
</math>

 to estimate the mean. Such an estimator has a breakdown point of 0 because we can make 

<math display="inline" id="Robust_statistics:4">
 <semantics>
  <mover accent="true">
   <mi>x</mi>
   <mo>¯</mo>
  </mover>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <ci>normal-¯</ci>
    <ci>x</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \overline{x}
  </annotation>
 </semantics>
</math>

 arbitrarily large just by changing any of 

<math display="inline" id="Robust_statistics:5">
 <semantics>
  <mrow>
   <msub>
    <mi>x</mi>
    <mn>1</mn>
   </msub>
   <mo>,</mo>
   <mi mathvariant="normal">…</mi>
   <mo>,</mo>
   <msub>
    <mi>x</mi>
    <mi>n</mi>
   </msub>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <list>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>x</ci>
     <cn type="integer">1</cn>
    </apply>
    <ci>normal-…</ci>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>x</ci>
     <ci>n</ci>
    </apply>
   </list>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   x_{1},\dots,x_{n}
  </annotation>
 </semantics>
</math>

.</p>

<p>The higher the breakdown point of an estimator, the more robust it is. Intuitively, we can understand that a breakdown point cannot exceed 50% because if more than half of the observations are contaminated, it is not possible to distinguish between the underlying distribution and the contaminating distribution. Therefore, the maximum breakdown point is 0.5 and there are estimators which achieve such a breakdown point. For example, the median has a breakdown point of 0.5. The X% trimmed mean has breakdown point of X%, for the chosen level of X. Huber (1981) and Maronna et al. (2006) contain more details. The level and the power breakdown points of tests are investigated in He et al. (1990).</p>

<p><span id="resistant statistic"></span>Statistics with high breakdown points are sometimes called <strong>resistant statistics.</strong><a class="footnoteRef" href="#fn5" id="fnref5"><sup>5</sup></a></p>
<h4 id="example-speed-of-light-data-1">Example: speed of light data</h4>

<p>In the speed of light example, removing the two lowest observations causes the mean to change from 26.2 to 27.75, a change of 1.55. The estimate of scale produced by the Qn method is 6.3. We can divide this by the square root of the sample size to get a robust standard error, and we find this quantity to be 0.78. Thus, the change in the mean resulting from removing two <a class="uri" href="outliers" title="wikilink">outliers</a> is approximately twice the robust standard error.</p>

<p>The 10% trimmed mean for the speed of light data is 27.43. Removing the two lowest observations and recomputing gives 27.67. Clearly, the trimmed mean is less affected by the outliers and has a higher breakdown point.</p>

<p>Notice that if we replace the lowest observation, -44, by -1000, the mean becomes 11.73, whereas the 10% trimmed mean is still 27.43. In many areas of applied statistics, it is common for data to be log-transformed to make them near symmetrical. Very small values become large negative when log-transformed, and zeroes become negatively infinite. Therefore, this example is of practical interest.</p>
<h3 id="empirical-influence-function">Empirical influence function</h3>

<p> The empirical influence function is a measure of the dependence of the estimator on the value of one of the points in the sample. It is a model-free measure in the sense that it simply relies on calculating the estimator again with a different sample. On the right is Tukey's biweight function, which, as we will later see, is an example of what a "good" (in a sense defined later on) empirical influence function should look like.</p>

<p>In mathematical terms, an influence function is defined as a vector in the space of the estimator, which is in turn defined for a sample which is a subset of the population:</p>
<ol>
<li>

<math display="inline" id="Robust_statistics:6">
 <semantics>
  <mrow>
   <mo stretchy="false">(</mo>
   <mi mathvariant="normal">Ω</mi>
   <mo>,</mo>
   <mi class="ltx_font_mathcaligraphic">𝒜</mi>
   <mo>,</mo>
   <mi>P</mi>
   <mo stretchy="false">)</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <vector>
    <ci>normal-Ω</ci>
    <ci>𝒜</ci>
    <ci>P</ci>
   </vector>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   (\Omega,\mathcal{A},P)
  </annotation>
 </semantics>
</math>

 is a probability space,</li>
<li>

<math display="inline" id="Robust_statistics:7">
 <semantics>
  <mrow>
   <mo stretchy="false">(</mo>
   <mi class="ltx_font_mathcaligraphic">𝒳</mi>
   <mo>,</mo>
   <mi mathvariant="normal">Σ</mi>
   <mo stretchy="false">)</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <interval closure="open">
    <ci>𝒳</ci>
    <ci>normal-Σ</ci>
   </interval>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   (\mathcal{X},\Sigma)
  </annotation>
 </semantics>
</math>

 is a measure space (state space),</li>
<li>

<math display="inline" id="Robust_statistics:8">
 <semantics>
  <mi mathvariant="normal">Θ</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>normal-Θ</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \Theta
  </annotation>
 </semantics>
</math>

 is a <a href="parameter_space" title="wikilink">parameter space</a> of dimension 

<math display="inline" id="Robust_statistics:9">
 <semantics>
  <mrow>
   <mi>p</mi>
   <mo>∈</mo>
   <msup>
    <mi>ℕ</mi>
    <mo>*</mo>
   </msup>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <in></in>
    <ci>p</ci>
    <apply>
     <csymbol cd="ambiguous">superscript</csymbol>
     <ci>ℕ</ci>
     <times></times>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   p\in\mathbb{N}^{*}
  </annotation>
 </semantics>
</math>

,</li>
<li>

<math display="inline" id="Robust_statistics:10">
 <semantics>
  <mrow>
   <mo stretchy="false">(</mo>
   <mi mathvariant="normal">Γ</mi>
   <mo>,</mo>
   <mi>S</mi>
   <mo stretchy="false">)</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <interval closure="open">
    <ci>normal-Γ</ci>
    <ci>S</ci>
   </interval>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   (\Gamma,S)
  </annotation>
 </semantics>
</math>

 is a measure space,</li>
</ol>

<p>For example,</p>
<ol>
<li>

<math display="inline" id="Robust_statistics:11">
 <semantics>
  <mrow>
   <mo stretchy="false">(</mo>
   <mi mathvariant="normal">Ω</mi>
   <mo>,</mo>
   <mi class="ltx_font_mathcaligraphic">𝒜</mi>
   <mo>,</mo>
   <mi>P</mi>
   <mo stretchy="false">)</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <vector>
    <ci>normal-Ω</ci>
    <ci>𝒜</ci>
    <ci>P</ci>
   </vector>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   (\Omega,\mathcal{A},P)
  </annotation>
 </semantics>
</math>

 is any probability space,</li>
<li>

<math display="inline" id="Robust_statistics:12">
 <semantics>
  <mrow>
   <mrow>
    <mo stretchy="false">(</mo>
    <mi class="ltx_font_mathcaligraphic">𝒳</mi>
    <mo>,</mo>
    <mi mathvariant="normal">Σ</mi>
    <mo stretchy="false">)</mo>
   </mrow>
   <mo>=</mo>
   <mrow>
    <mo stretchy="false">(</mo>
    <mi>ℝ</mi>
    <mo>,</mo>
    <mi class="ltx_font_mathcaligraphic">ℬ</mi>
    <mo stretchy="false">)</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <interval closure="open">
     <ci>𝒳</ci>
     <ci>normal-Σ</ci>
    </interval>
    <interval closure="open">
     <ci>ℝ</ci>
     <ci>ℬ</ci>
    </interval>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   (\mathcal{X},\Sigma)=(\mathbb{R},\mathcal{B})
  </annotation>
 </semantics>
</math>

,</li>
<li>

<math display="inline" id="Robust_statistics:13">
 <semantics>
  <mrow>
   <mi mathvariant="normal">Θ</mi>
   <mo>=</mo>
   <mrow>
    <mi>ℝ</mi>
    <mo>×</mo>
    <msup>
     <mi>ℝ</mi>
     <mo>+</mo>
    </msup>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <ci>normal-Θ</ci>
    <apply>
     <times></times>
     <ci>ℝ</ci>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <ci>ℝ</ci>
      <plus></plus>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \Theta=\mathbb{R}\times\mathbb{R}^{+}
  </annotation>
 </semantics>
</math>

</li>
<li>

<math display="inline" id="Robust_statistics:14">
 <semantics>
  <mrow>
   <mrow>
    <mo stretchy="false">(</mo>
    <mi mathvariant="normal">Γ</mi>
    <mo>,</mo>
    <mi>S</mi>
    <mo stretchy="false">)</mo>
   </mrow>
   <mo>=</mo>
   <mrow>
    <mo stretchy="false">(</mo>
    <mi>ℝ</mi>
    <mo>,</mo>
    <mi class="ltx_font_mathcaligraphic">ℬ</mi>
    <mo stretchy="false">)</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <interval closure="open">
     <ci>normal-Γ</ci>
     <ci>S</ci>
    </interval>
    <interval closure="open">
     <ci>ℝ</ci>
     <ci>ℬ</ci>
    </interval>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   (\Gamma,S)=(\mathbb{R},\mathcal{B})
  </annotation>
 </semantics>
</math>

,</li>
</ol>

<p>The definition of an empirical influence function is: Let 

<math display="inline" id="Robust_statistics:15">
 <semantics>
  <mrow>
   <mi>n</mi>
   <mo>∈</mo>
   <msup>
    <mi>ℕ</mi>
    <mo>*</mo>
   </msup>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <in></in>
    <ci>n</ci>
    <apply>
     <csymbol cd="ambiguous">superscript</csymbol>
     <ci>ℕ</ci>
     <times></times>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   n\in\mathbb{N}^{*}
  </annotation>
 </semantics>
</math>

 and 

<math display="inline" id="Robust_statistics:16">
 <semantics>
  <mrow>
   <mrow>
    <msub>
     <mi>X</mi>
     <mn>1</mn>
    </msub>
    <mo>,</mo>
    <mi mathvariant="normal">…</mi>
    <mo>,</mo>
    <msub>
     <mi>X</mi>
     <mi>n</mi>
    </msub>
   </mrow>
   <mo>:</mo>
   <mrow>
    <mrow>
     <mo stretchy="false">(</mo>
     <mi mathvariant="normal">Ω</mi>
     <mo>,</mo>
     <mi class="ltx_font_mathcaligraphic">𝒜</mi>
     <mo stretchy="false">)</mo>
    </mrow>
    <mo>→</mo>
    <mrow>
     <mo stretchy="false">(</mo>
     <mi class="ltx_font_mathcaligraphic">𝒳</mi>
     <mo>,</mo>
     <mi mathvariant="normal">Σ</mi>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <ci>normal-:</ci>
    <list>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>X</ci>
      <cn type="integer">1</cn>
     </apply>
     <ci>normal-…</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>X</ci>
      <ci>n</ci>
     </apply>
    </list>
    <apply>
     <ci>normal-→</ci>
     <interval closure="open">
      <ci>normal-Ω</ci>
      <ci>𝒜</ci>
     </interval>
     <interval closure="open">
      <ci>𝒳</ci>
      <ci>normal-Σ</ci>
     </interval>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   X_{1},\dots,X_{n}:(\Omega,\mathcal{A})\rightarrow(\mathcal{X},\Sigma)
  </annotation>
 </semantics>
</math>

 are <a class="uri" href="i.i.d." title="wikilink">i.i.d.</a> and 

<math display="inline" id="Robust_statistics:17">
 <semantics>
  <mrow>
   <mo stretchy="false">(</mo>
   <msub>
    <mi>x</mi>
    <mn>1</mn>
   </msub>
   <mo>,</mo>
   <mi mathvariant="normal">…</mi>
   <mo>,</mo>
   <msub>
    <mi>x</mi>
    <mi>n</mi>
   </msub>
   <mo stretchy="false">)</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <vector>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>x</ci>
     <cn type="integer">1</cn>
    </apply>
    <ci>normal-…</ci>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>x</ci>
     <ci>n</ci>
    </apply>
   </vector>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   (x_{1},\dots,x_{n})
  </annotation>
 </semantics>
</math>

 is a sample from these variables. 

<math display="inline" id="Robust_statistics:18">
 <semantics>
  <mrow>
   <msub>
    <mi>T</mi>
    <mi>n</mi>
   </msub>
   <mo>:</mo>
   <mrow>
    <mrow>
     <mo stretchy="false">(</mo>
     <msup>
      <mi class="ltx_font_mathcaligraphic">𝒳</mi>
      <mi>n</mi>
     </msup>
     <mo>,</mo>
     <msup>
      <mi mathvariant="normal">Σ</mi>
      <mi>n</mi>
     </msup>
     <mo stretchy="false">)</mo>
    </mrow>
    <mo>→</mo>
    <mrow>
     <mo stretchy="false">(</mo>
     <mi mathvariant="normal">Γ</mi>
     <mo>,</mo>
     <mi>S</mi>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <ci>normal-:</ci>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>T</ci>
     <ci>n</ci>
    </apply>
    <apply>
     <ci>normal-→</ci>
     <interval closure="open">
      <apply>
       <csymbol cd="ambiguous">superscript</csymbol>
       <ci>𝒳</ci>
       <ci>n</ci>
      </apply>
      <apply>
       <csymbol cd="ambiguous">superscript</csymbol>
       <ci>normal-Σ</ci>
       <ci>n</ci>
      </apply>
     </interval>
     <interval closure="open">
      <ci>normal-Γ</ci>
      <ci>S</ci>
     </interval>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   T_{n}:(\mathcal{X}^{n},\Sigma^{n})\rightarrow(\Gamma,S)
  </annotation>
 </semantics>
</math>

 is an estimator. Let 

<math display="inline" id="Robust_statistics:19">
 <semantics>
  <mrow>
   <mi>i</mi>
   <mo>∈</mo>
   <mrow>
    <mo stretchy="false">{</mo>
    <mn>1</mn>
    <mo>,</mo>
    <mi mathvariant="normal">…</mi>
    <mo>,</mo>
    <mi>n</mi>
    <mo stretchy="false">}</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <in></in>
    <ci>i</ci>
    <set>
     <cn type="integer">1</cn>
     <ci>normal-…</ci>
     <ci>n</ci>
    </set>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   i\in\{1,\dots,n\}
  </annotation>
 </semantics>
</math>

. The empirical influence function 

<math display="inline" id="Robust_statistics:20">
 <semantics>
  <mrow>
   <mi>E</mi>
   <mi>I</mi>
   <msub>
    <mi>F</mi>
    <mi>i</mi>
   </msub>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <ci>E</ci>
    <ci>I</ci>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>F</ci>
     <ci>i</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   EIF_{i}
  </annotation>
 </semantics>
</math>

 at observation 

<math display="inline" id="Robust_statistics:21">
 <semantics>
  <mi>i</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>i</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   i
  </annotation>
 </semantics>
</math>

 is defined by:</p>

<p>

<math display="inline" id="Robust_statistics:22">
 <semantics>
  <mrow>
   <mrow>
    <mi>E</mi>
    <mi>I</mi>
    <msub>
     <mi>F</mi>
     <mi>i</mi>
    </msub>
   </mrow>
   <mo>:</mo>
   <mrow>
    <mi>x</mi>
    <mo>∈</mo>
    <mi class="ltx_font_mathcaligraphic">𝒳</mi>
    <mo>↦</mo>
    <mrow>
     <mi>n</mi>
     <mo>*</mo>
     <mrow>
      <mo stretchy="false">(</mo>
      <mrow>
       <mrow>
        <msub>
         <mi>T</mi>
         <mi>n</mi>
        </msub>
        <mrow>
         <mo stretchy="false">(</mo>
         <msub>
          <mi>x</mi>
          <mn>1</mn>
         </msub>
         <mo>,</mo>
         <mi mathvariant="normal">…</mi>
         <mo>,</mo>
         <msub>
          <mi>x</mi>
          <mrow>
           <mi>i</mi>
           <mo>-</mo>
           <mn>1</mn>
          </mrow>
         </msub>
         <mo>,</mo>
         <mi>x</mi>
         <mo>,</mo>
         <msub>
          <mi>x</mi>
          <mrow>
           <mi>i</mi>
           <mo>+</mo>
           <mn>1</mn>
          </mrow>
         </msub>
         <mo>,</mo>
         <mi mathvariant="normal">…</mi>
         <mo>,</mo>
         <msub>
          <mi>x</mi>
          <mi>n</mi>
         </msub>
         <mo stretchy="false">)</mo>
        </mrow>
       </mrow>
       <mo>-</mo>
       <mrow>
        <msub>
         <mi>T</mi>
         <mi>n</mi>
        </msub>
        <mrow>
         <mo stretchy="false">(</mo>
         <msub>
          <mi>x</mi>
          <mn>1</mn>
         </msub>
         <mo>,</mo>
         <mi mathvariant="normal">…</mi>
         <mo>,</mo>
         <msub>
          <mi>x</mi>
          <mrow>
           <mi>i</mi>
           <mo>-</mo>
           <mn>1</mn>
          </mrow>
         </msub>
         <mo>,</mo>
         <msub>
          <mi>x</mi>
          <mi>i</mi>
         </msub>
         <mo>,</mo>
         <msub>
          <mi>x</mi>
          <mrow>
           <mi>i</mi>
           <mo>+</mo>
           <mn>1</mn>
          </mrow>
         </msub>
         <mo>,</mo>
         <mi mathvariant="normal">…</mi>
         <mo>,</mo>
         <msub>
          <mi>x</mi>
          <mi>n</mi>
         </msub>
         <mo stretchy="false">)</mo>
        </mrow>
       </mrow>
      </mrow>
      <mo stretchy="false">)</mo>
     </mrow>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <ci>normal-:</ci>
    <apply>
     <times></times>
     <ci>E</ci>
     <ci>I</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>F</ci>
      <ci>i</ci>
     </apply>
    </apply>
    <apply>
     <and></and>
     <apply>
      <in></in>
      <ci>x</ci>
      <ci>𝒳</ci>
     </apply>
     <apply>
      <csymbol cd="latexml">maps-to</csymbol>
      <share href="#.cmml">
      </share>
      <apply>
       <times></times>
       <ci>n</ci>
       <apply>
        <minus></minus>
        <apply>
         <times></times>
         <apply>
          <csymbol cd="ambiguous">subscript</csymbol>
          <ci>T</ci>
          <ci>n</ci>
         </apply>
         <vector>
          <apply>
           <csymbol cd="ambiguous">subscript</csymbol>
           <ci>x</ci>
           <cn type="integer">1</cn>
          </apply>
          <ci>normal-…</ci>
          <apply>
           <csymbol cd="ambiguous">subscript</csymbol>
           <ci>x</ci>
           <apply>
            <minus></minus>
            <ci>i</ci>
            <cn type="integer">1</cn>
           </apply>
          </apply>
          <ci>x</ci>
          <apply>
           <csymbol cd="ambiguous">subscript</csymbol>
           <ci>x</ci>
           <apply>
            <plus></plus>
            <ci>i</ci>
            <cn type="integer">1</cn>
           </apply>
          </apply>
          <ci>normal-…</ci>
          <apply>
           <csymbol cd="ambiguous">subscript</csymbol>
           <ci>x</ci>
           <ci>n</ci>
          </apply>
         </vector>
        </apply>
        <apply>
         <times></times>
         <apply>
          <csymbol cd="ambiguous">subscript</csymbol>
          <ci>T</ci>
          <ci>n</ci>
         </apply>
         <vector>
          <apply>
           <csymbol cd="ambiguous">subscript</csymbol>
           <ci>x</ci>
           <cn type="integer">1</cn>
          </apply>
          <ci>normal-…</ci>
          <apply>
           <csymbol cd="ambiguous">subscript</csymbol>
           <ci>x</ci>
           <apply>
            <minus></minus>
            <ci>i</ci>
            <cn type="integer">1</cn>
           </apply>
          </apply>
          <apply>
           <csymbol cd="ambiguous">subscript</csymbol>
           <ci>x</ci>
           <ci>i</ci>
          </apply>
          <apply>
           <csymbol cd="ambiguous">subscript</csymbol>
           <ci>x</ci>
           <apply>
            <plus></plus>
            <ci>i</ci>
            <cn type="integer">1</cn>
           </apply>
          </apply>
          <ci>normal-…</ci>
          <apply>
           <csymbol cd="ambiguous">subscript</csymbol>
           <ci>x</ci>
           <ci>n</ci>
          </apply>
         </vector>
        </apply>
       </apply>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   EIF_{i}:x\in\mathcal{X}\mapsto n*(T_{n}(x_{1},\dots,x_{i-1},x,x_{i+1},\dots,x_%
{n})-T_{n}(x_{1},\dots,x_{i-1},x_{i},x_{i+1},\dots,x_{n}))
  </annotation>
 </semantics>
</math>

</p>

<p>Note that 

<math display="inline" id="Robust_statistics:23">
 <semantics>
  <mrow>
   <mrow>
    <mi>E</mi>
    <mi>I</mi>
    <msub>
     <mi>F</mi>
     <mi>i</mi>
    </msub>
   </mrow>
   <mo>:</mo>
   <mrow>
    <mi>x</mi>
    <mo>∈</mo>
    <mi mathvariant="normal">Γ</mi>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <ci>normal-:</ci>
    <apply>
     <times></times>
     <ci>E</ci>
     <ci>I</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>F</ci>
      <ci>i</ci>
     </apply>
    </apply>
    <apply>
     <in></in>
     <ci>x</ci>
     <ci>normal-Γ</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   EIF_{i}:x\in\Gamma
  </annotation>
 </semantics>
</math>

.</p>

<p>What this actually means is that we are replacing the i-th value in the sample by an arbitrary value and looking at the output of the estimator. Alternatively, the EIF is defined as the (scaled by n+1 instead of n) effect on the estimator of adding the point 

<math display="inline" id="Robust_statistics:24">
 <semantics>
  <mi>x</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>x</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   x
  </annotation>
 </semantics>
</math>

 to the sample.<a class="footnoteRef" href="#fn6" id="fnref6"><sup>6</sup></a></p>
<h3 id="influence-function-and-sensitivity-curve">Influence function and sensitivity curve</h3>

<p>Instead of relying solely on the data, we could use the distribution of the random variables. The approach is quite different from that of the previous paragraph. What we are now trying to do is to see what happens to an estimator when we change the distribution of the data slightly: it assumes a <em>distribution,</em> and measures sensitivity to change in this distribution. By contrast, the empirical influence assumes a <em>sample set,</em> and measures sensitivity to change in the samples.<a class="footnoteRef" href="#fn7" id="fnref7"><sup>7</sup></a></p>

<p>Let 

<math display="inline" id="Robust_statistics:25">
 <semantics>
  <mi>A</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>A</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   A
  </annotation>
 </semantics>
</math>

 be a convex subset of the set of all finite signed measures on 

<math display="inline" id="Robust_statistics:26">
 <semantics>
  <mi mathvariant="normal">Σ</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>normal-Σ</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \Sigma
  </annotation>
 </semantics>
</math>

. We want to estimate the parameter 

<math display="inline" id="Robust_statistics:27">
 <semantics>
  <mrow>
   <mi>θ</mi>
   <mo>∈</mo>
   <mi mathvariant="normal">Θ</mi>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <in></in>
    <ci>θ</ci>
    <ci>normal-Θ</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \theta\in\Theta
  </annotation>
 </semantics>
</math>

 of a distribution 

<math display="inline" id="Robust_statistics:28">
 <semantics>
  <mi>F</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>F</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   F
  </annotation>
 </semantics>
</math>

 in 

<math display="inline" id="Robust_statistics:29">
 <semantics>
  <mi>A</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>A</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   A
  </annotation>
 </semantics>
</math>

. Let the functional 

<math display="inline" id="Robust_statistics:30">
 <semantics>
  <mrow>
   <mi>T</mi>
   <mo>:</mo>
   <mrow>
    <mi>A</mi>
    <mo>→</mo>
    <mi mathvariant="normal">Γ</mi>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <ci>normal-:</ci>
    <ci>T</ci>
    <apply>
     <ci>normal-→</ci>
     <ci>A</ci>
     <ci>normal-Γ</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   T:A\rightarrow\Gamma
  </annotation>
 </semantics>
</math>

 be the asymptotic value of some estimator sequence 

<math display="inline" id="Robust_statistics:31">
 <semantics>
  <msub>
   <mrow>
    <mo stretchy="false">(</mo>
    <msub>
     <mi>T</mi>
     <mi>n</mi>
    </msub>
    <mo stretchy="false">)</mo>
   </mrow>
   <mrow>
    <mi>n</mi>
    <mo>∈</mo>
    <mi>ℕ</mi>
   </mrow>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>T</ci>
     <ci>n</ci>
    </apply>
    <apply>
     <in></in>
     <ci>n</ci>
     <ci>ℕ</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   (T_{n})_{n\in\mathbb{N}}
  </annotation>
 </semantics>
</math>

. We will suppose that this functional is <a href="Fisher_consistency" title="wikilink">Fisher consistent</a>, i.e. 

<math display="inline" id="Robust_statistics:32">
 <semantics>
  <mrow>
   <mrow>
    <mrow>
     <mo>∀</mo>
     <mi>θ</mi>
    </mrow>
    <mo>∈</mo>
    <mi mathvariant="normal">Θ</mi>
   </mrow>
   <mo>,</mo>
   <mrow>
    <mrow>
     <mi>T</mi>
     <mrow>
      <mo stretchy="false">(</mo>
      <msub>
       <mi>F</mi>
       <mi>θ</mi>
      </msub>
      <mo stretchy="false">)</mo>
     </mrow>
    </mrow>
    <mo>=</mo>
    <mi>θ</mi>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">formulae-sequence</csymbol>
    <apply>
     <in></in>
     <apply>
      <csymbol cd="latexml">for-all</csymbol>
      <ci>θ</ci>
     </apply>
     <ci>normal-Θ</ci>
    </apply>
    <apply>
     <eq></eq>
     <apply>
      <times></times>
      <ci>T</ci>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>F</ci>
       <ci>θ</ci>
      </apply>
     </apply>
     <ci>θ</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \forall\theta\in\Theta,T(F_{\theta})=\theta
  </annotation>
 </semantics>
</math>

. This means that at the model 

<math display="inline" id="Robust_statistics:33">
 <semantics>
  <mi>F</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>F</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   F
  </annotation>
 </semantics>
</math>

, the estimator sequence asymptotically measures the correct quantity.</p>

<p>Let 

<math display="inline" id="Robust_statistics:34">
 <semantics>
  <mi>G</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>G</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   G
  </annotation>
 </semantics>
</math>

 be some distribution in 

<math display="inline" id="Robust_statistics:35">
 <semantics>
  <mi>A</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>A</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   A
  </annotation>
 </semantics>
</math>

. What happens when the data doesn't follow the model 

<math display="inline" id="Robust_statistics:36">
 <semantics>
  <mi>F</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>F</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   F
  </annotation>
 </semantics>
</math>

 exactly but another, slightly different, "going towards" 

<math display="inline" id="Robust_statistics:37">
 <semantics>
  <mi>G</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>G</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   G
  </annotation>
 </semantics>
</math>

?</p>

<p>We're looking at

<math display="block" id="Robust_statistics:38">
 <semantics>
  <mrow>
   <mrow>
    <mi>d</mi>
    <msub>
     <mi>T</mi>
     <mrow>
      <mi>G</mi>
      <mo>-</mo>
      <mi>F</mi>
     </mrow>
    </msub>
    <mrow>
     <mo stretchy="false">(</mo>
     <mi>F</mi>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
   <mo>=</mo>
   <mrow>
    <munder>
     <mo movablelimits="false">lim</mo>
     <mrow>
      <mi>t</mi>
      <mo>→</mo>
      <msup>
       <mn>0</mn>
       <mo>+</mo>
      </msup>
     </mrow>
    </munder>
    <mfrac>
     <mrow>
      <mrow>
       <mi>T</mi>
       <mrow>
        <mo stretchy="false">(</mo>
        <mrow>
         <mrow>
          <mi>t</mi>
          <mi>G</mi>
         </mrow>
         <mo>+</mo>
         <mrow>
          <mrow>
           <mo stretchy="false">(</mo>
           <mrow>
            <mn>1</mn>
            <mo>-</mo>
            <mi>t</mi>
           </mrow>
           <mo stretchy="false">)</mo>
          </mrow>
          <mi>F</mi>
         </mrow>
        </mrow>
        <mo stretchy="false">)</mo>
       </mrow>
      </mrow>
      <mo>-</mo>
      <mrow>
       <mi>T</mi>
       <mrow>
        <mo stretchy="false">(</mo>
        <mi>F</mi>
        <mo stretchy="false">)</mo>
       </mrow>
      </mrow>
     </mrow>
     <mi>t</mi>
    </mfrac>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <times></times>
     <ci>d</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>T</ci>
      <apply>
       <minus></minus>
       <ci>G</ci>
       <ci>F</ci>
      </apply>
     </apply>
     <ci>F</ci>
    </apply>
    <apply>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <limit></limit>
      <apply>
       <ci>normal-→</ci>
       <ci>t</ci>
       <apply>
        <csymbol cd="ambiguous">superscript</csymbol>
        <cn type="integer">0</cn>
        <plus></plus>
       </apply>
      </apply>
     </apply>
     <apply>
      <divide></divide>
      <apply>
       <minus></minus>
       <apply>
        <times></times>
        <ci>T</ci>
        <apply>
         <plus></plus>
         <apply>
          <times></times>
          <ci>t</ci>
          <ci>G</ci>
         </apply>
         <apply>
          <times></times>
          <apply>
           <minus></minus>
           <cn type="integer">1</cn>
           <ci>t</ci>
          </apply>
          <ci>F</ci>
         </apply>
        </apply>
       </apply>
       <apply>
        <times></times>
        <ci>T</ci>
        <ci>F</ci>
       </apply>
      </apply>
      <ci>t</ci>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   dT_{G-F}(F)=\lim_{t\rightarrow 0^{+}}\frac{T(tG+(1-t)F)-T(F)}{t}
  </annotation>
 </semantics>
</math>

,</p>

<p>which is the <a href="one-sided_limit" title="wikilink">one-sided</a> <a href="Gâteaux_derivative" title="wikilink">directional derivative</a> of 

<math display="inline" id="Robust_statistics:39">
 <semantics>
  <mi>T</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>T</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   T
  </annotation>
 </semantics>
</math>

 at 

<math display="inline" id="Robust_statistics:40">
 <semantics>
  <mi>F</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>F</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   F
  </annotation>
 </semantics>
</math>

, in the direction of 

<math display="inline" id="Robust_statistics:41">
 <semantics>
  <mrow>
   <mi>G</mi>
   <mo>-</mo>
   <mi>F</mi>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <minus></minus>
    <ci>G</ci>
    <ci>F</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   G-F
  </annotation>
 </semantics>
</math>

.</p>

<p>Let 

<math display="inline" id="Robust_statistics:42">
 <semantics>
  <mrow>
   <mi>x</mi>
   <mo>∈</mo>
   <mi class="ltx_font_mathcaligraphic">𝒳</mi>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <in></in>
    <ci>x</ci>
    <ci>𝒳</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   x\in\mathcal{X}
  </annotation>
 </semantics>
</math>

. 

<math display="inline" id="Robust_statistics:43">
 <semantics>
  <msub>
   <mi mathvariant="normal">Δ</mi>
   <mi>x</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>normal-Δ</ci>
    <ci>x</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \Delta_{x}
  </annotation>
 </semantics>
</math>

 is the probability measure which gives mass 1 to 

<math display="inline" id="Robust_statistics:44">
 <semantics>
  <mrow>
   <mo stretchy="false">{</mo>
   <mi>x</mi>
   <mo stretchy="false">}</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <set>
    <ci>x</ci>
   </set>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \{x\}
  </annotation>
 </semantics>
</math>

. We choose 

<math display="inline" id="Robust_statistics:45">
 <semantics>
  <mrow>
   <mi>G</mi>
   <mo>=</mo>
   <msub>
    <mi mathvariant="normal">Δ</mi>
    <mi>x</mi>
   </msub>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <ci>G</ci>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>normal-Δ</ci>
     <ci>x</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   G=\Delta_{x}
  </annotation>
 </semantics>
</math>

. The influence function is then defined by:</p>

<p>

<math display="inline" id="Robust_statistics:46">
 <semantics>
  <mrow>
   <mrow>
    <mrow>
     <mi>I</mi>
     <mi>F</mi>
     <mrow>
      <mo stretchy="false">(</mo>
      <mi>x</mi>
      <mo>;</mo>
      <mi>T</mi>
      <mo>;</mo>
      <mi>F</mi>
      <mo stretchy="false">)</mo>
     </mrow>
    </mrow>
    <mo>:=</mo>
    <mrow>
     <msub>
      <mo>lim</mo>
      <mrow>
       <mi>t</mi>
       <mo>→</mo>
       <msup>
        <mn>0</mn>
        <mo>+</mo>
       </msup>
      </mrow>
     </msub>
     <mfrac>
      <mrow>
       <mrow>
        <mi>T</mi>
        <mrow>
         <mo stretchy="false">(</mo>
         <mrow>
          <mrow>
           <mi>t</mi>
           <msub>
            <mi mathvariant="normal">Δ</mi>
            <mi>x</mi>
           </msub>
          </mrow>
          <mo>+</mo>
          <mrow>
           <mrow>
            <mo stretchy="false">(</mo>
            <mrow>
             <mn>1</mn>
             <mo>-</mo>
             <mi>t</mi>
            </mrow>
            <mo stretchy="false">)</mo>
           </mrow>
           <mi>F</mi>
          </mrow>
         </mrow>
         <mo stretchy="false">)</mo>
        </mrow>
       </mrow>
       <mo>-</mo>
       <mrow>
        <mi>T</mi>
        <mrow>
         <mo stretchy="false">(</mo>
         <mi>F</mi>
         <mo stretchy="false">)</mo>
        </mrow>
       </mrow>
      </mrow>
      <mi>t</mi>
     </mfrac>
    </mrow>
   </mrow>
   <mo>.</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="latexml">assign</csymbol>
    <apply>
     <times></times>
     <ci>I</ci>
     <ci>F</ci>
     <list>
      <ci>x</ci>
      <ci>T</ci>
      <ci>F</ci>
     </list>
    </apply>
    <apply>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <limit></limit>
      <apply>
       <ci>normal-→</ci>
       <ci>t</ci>
       <apply>
        <csymbol cd="ambiguous">superscript</csymbol>
        <cn type="integer">0</cn>
        <plus></plus>
       </apply>
      </apply>
     </apply>
     <apply>
      <divide></divide>
      <apply>
       <minus></minus>
       <apply>
        <times></times>
        <ci>T</ci>
        <apply>
         <plus></plus>
         <apply>
          <times></times>
          <ci>t</ci>
          <apply>
           <csymbol cd="ambiguous">subscript</csymbol>
           <ci>normal-Δ</ci>
           <ci>x</ci>
          </apply>
         </apply>
         <apply>
          <times></times>
          <apply>
           <minus></minus>
           <cn type="integer">1</cn>
           <ci>t</ci>
          </apply>
          <ci>F</ci>
         </apply>
        </apply>
       </apply>
       <apply>
        <times></times>
        <ci>T</ci>
        <ci>F</ci>
       </apply>
      </apply>
      <ci>t</ci>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   IF(x;T;F):=\lim_{t\rightarrow 0^{+}}\frac{T(t\Delta_{x}+(1-t)F)-T(F)}{t}.
  </annotation>
 </semantics>
</math>

</p>

<p>It describes the effect of an infinitesimal contamination at the point 

<math display="inline" id="Robust_statistics:47">
 <semantics>
  <mi>x</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>x</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   x
  </annotation>
 </semantics>
</math>

 on the estimate we are seeking, standardized by the mass 

<math display="inline" id="Robust_statistics:48">
 <semantics>
  <mi>t</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>t</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   t
  </annotation>
 </semantics>
</math>

 of the contamination (the asymptotic bias caused by contamination in the observations). For a robust estimator, we want a bounded influence function, that is, one which does not go to infinity as x becomes arbitrarily large.</p>
<h3 id="desirable-properties">Desirable properties</h3>

<p>Properties of an influence function which bestow it with desirable performance are:</p>
<ol>
<li>Finite rejection point 

<math display="inline" id="Robust_statistics:49">
 <semantics>
  <msup>
   <mi>ρ</mi>
   <mo>*</mo>
  </msup>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">superscript</csymbol>
    <ci>ρ</ci>
    <times></times>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \rho^{*}
  </annotation>
 </semantics>
</math>

,</li>
<li>Small gross-error sensitivity 

<math display="inline" id="Robust_statistics:50">
 <semantics>
  <msup>
   <mi>γ</mi>
   <mo>*</mo>
  </msup>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">superscript</csymbol>
    <ci>γ</ci>
    <times></times>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \gamma^{*}
  </annotation>
 </semantics>
</math>

,</li>
<li>Small local-shift sensitivity 

<math display="inline" id="Robust_statistics:51">
 <semantics>
  <msup>
   <mi>λ</mi>
   <mo>*</mo>
  </msup>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">superscript</csymbol>
    <ci>λ</ci>
    <times></times>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \lambda^{*}
  </annotation>
 </semantics>
</math>

.</li>
</ol>
<h4 id="rejection-point">Rejection point</h4>

<p>

<math display="inline" id="Robust_statistics:52">
 <semantics>
  <mrow>
   <msup>
    <mi>ρ</mi>
    <mo>*</mo>
   </msup>
   <mo>:=</mo>
   <mrow>
    <msub>
     <mo>inf</mo>
     <mrow>
      <mi>r</mi>
      <mo>></mo>
      <mn>0</mn>
     </mrow>
    </msub>
    <mrow>
     <mo stretchy="false">{</mo>
     <mi>r</mi>
     <mo>:</mo>
     <mrow>
      <mrow>
       <mrow>
        <mi>I</mi>
        <mi>F</mi>
        <mrow>
         <mo stretchy="false">(</mo>
         <mi>x</mi>
         <mo>;</mo>
         <mi>T</mi>
         <mo>;</mo>
         <mi>F</mi>
         <mo stretchy="false">)</mo>
        </mrow>
       </mrow>
       <mo>=</mo>
       <mn>0</mn>
      </mrow>
      <mo>,</mo>
      <mrow>
       <mrow>
        <mo stretchy="false">|</mo>
        <mi>x</mi>
        <mo stretchy="false">|</mo>
       </mrow>
       <mo>></mo>
       <mi>r</mi>
      </mrow>
     </mrow>
     <mo stretchy="false">}</mo>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="latexml">assign</csymbol>
    <apply>
     <csymbol cd="ambiguous">superscript</csymbol>
     <ci>ρ</ci>
     <times></times>
    </apply>
    <apply>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <csymbol cd="latexml">infimum</csymbol>
      <apply>
       <gt></gt>
       <ci>r</ci>
       <cn type="integer">0</cn>
      </apply>
     </apply>
     <apply>
      <csymbol cd="latexml">conditional-set</csymbol>
      <ci>r</ci>
      <apply>
       <csymbol cd="ambiguous">formulae-sequence</csymbol>
       <apply>
        <eq></eq>
        <apply>
         <times></times>
         <ci>I</ci>
         <ci>F</ci>
         <list>
          <ci>x</ci>
          <ci>T</ci>
          <ci>F</ci>
         </list>
        </apply>
        <cn type="integer">0</cn>
       </apply>
       <apply>
        <gt></gt>
        <apply>
         <abs></abs>
         <ci>x</ci>
        </apply>
        <ci>r</ci>
       </apply>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \rho^{*}:=\inf_{r>0}\{r:IF(x;T;F)=0,|x|>r\}
  </annotation>
 </semantics>
</math>

</p>
<h4 id="gross-error-sensitivity">Gross-error sensitivity</h4>

<p>

<math display="inline" id="Robust_statistics:53">
 <semantics>
  <mrow>
   <mrow>
    <msup>
     <mi>γ</mi>
     <mo>*</mo>
    </msup>
    <mrow>
     <mo stretchy="false">(</mo>
     <mi>T</mi>
     <mo>;</mo>
     <mi>F</mi>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
   <mo>:=</mo>
   <mrow>
    <msub>
     <mo>sup</mo>
     <mrow>
      <mi>x</mi>
      <mo>∈</mo>
      <mi class="ltx_font_mathcaligraphic">𝒳</mi>
     </mrow>
    </msub>
    <mrow>
     <mo stretchy="false">|</mo>
     <mrow>
      <mi>I</mi>
      <mi>F</mi>
      <mrow>
       <mo stretchy="false">(</mo>
       <mi>x</mi>
       <mo>;</mo>
       <mi>T</mi>
       <mo>;</mo>
       <mi>F</mi>
       <mo stretchy="false">)</mo>
      </mrow>
     </mrow>
     <mo stretchy="false">|</mo>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="latexml">assign</csymbol>
    <apply>
     <times></times>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <ci>γ</ci>
      <times></times>
     </apply>
     <list>
      <ci>T</ci>
      <ci>F</ci>
     </list>
    </apply>
    <apply>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <csymbol cd="latexml">supremum</csymbol>
      <apply>
       <in></in>
       <ci>x</ci>
       <ci>𝒳</ci>
      </apply>
     </apply>
     <apply>
      <abs></abs>
      <apply>
       <times></times>
       <ci>I</ci>
       <ci>F</ci>
       <list>
        <ci>x</ci>
        <ci>T</ci>
        <ci>F</ci>
       </list>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \gamma^{*}(T;F):=\sup_{x\in\mathcal{X}}|IF(x;T;F)|
  </annotation>
 </semantics>
</math>

</p>
<h4 id="local-shift-sensitivity">Local-shift sensitivity</h4>

<p>

<math display="inline" id="Robust_statistics:54">
 <semantics>
  <mrow>
   <mrow>
    <msup>
     <mi>λ</mi>
     <mo>*</mo>
    </msup>
    <mrow>
     <mo stretchy="false">(</mo>
     <mi>T</mi>
     <mo>;</mo>
     <mi>F</mi>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
   <mo>:=</mo>
   <mrow>
    <msub>
     <mo>sup</mo>
     <mstyle scriptlevel="+1">
      <mtable columnspacing="0.4em" rowspacing="0.2ex">
       <mtr>
        <mtd>
         <mrow>
          <mrow>
           <mo stretchy="false">(</mo>
           <mi>x</mi>
           <mo>,</mo>
           <mi>y</mi>
           <mo stretchy="false">)</mo>
          </mrow>
          <mo>∈</mo>
          <msup>
           <mi class="ltx_font_mathcaligraphic">𝒳</mi>
           <mn>2</mn>
          </msup>
         </mrow>
        </mtd>
       </mtr>
       <mtr>
        <mtd>
         <mrow>
          <mi>x</mi>
          <mo>≠</mo>
          <mi>y</mi>
         </mrow>
        </mtd>
       </mtr>
      </mtable>
     </mstyle>
    </msub>
    <mrow>
     <mo>∥</mo>
     <mfrac>
      <mrow>
       <mrow>
        <mi>I</mi>
        <mi>F</mi>
        <mrow>
         <mo stretchy="false">(</mo>
         <mi>y</mi>
         <mo>;</mo>
         <mi>T</mi>
         <mo>;</mo>
         <mi>F</mi>
         <mo stretchy="false">)</mo>
        </mrow>
       </mrow>
       <mo>-</mo>
       <mrow>
        <mi>I</mi>
        <mi>F</mi>
        <mrow>
         <mo stretchy="false">(</mo>
         <mi>x</mi>
         <mo>;</mo>
         <mi>T</mi>
         <mo>;</mo>
         <mi>F</mi>
         <mo stretchy="false">)</mo>
        </mrow>
       </mrow>
      </mrow>
      <mrow>
       <mi>y</mi>
       <mo>-</mo>
       <mi>x</mi>
      </mrow>
     </mfrac>
     <mo>∥</mo>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="latexml">assign</csymbol>
    <apply>
     <times></times>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <ci>λ</ci>
      <times></times>
     </apply>
     <list>
      <ci>T</ci>
      <ci>F</ci>
     </list>
    </apply>
    <apply>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <csymbol cd="latexml">supremum</csymbol>
      <apply>
       <ci>STACKED</ci>
       <apply>
        <in></in>
        <interval closure="open">
         <ci>x</ci>
         <ci>y</ci>
        </interval>
        <apply>
         <csymbol cd="ambiguous">superscript</csymbol>
         <ci>𝒳</ci>
         <cn type="integer">2</cn>
        </apply>
       </apply>
       <apply>
        <neq></neq>
        <ci>x</ci>
        <ci>y</ci>
       </apply>
      </apply>
     </apply>
     <apply>
      <csymbol cd="latexml">norm</csymbol>
      <apply>
       <divide></divide>
       <apply>
        <minus></minus>
        <apply>
         <times></times>
         <ci>I</ci>
         <ci>F</ci>
         <list>
          <ci>y</ci>
          <ci>T</ci>
          <ci>F</ci>
         </list>
        </apply>
        <apply>
         <times></times>
         <ci>I</ci>
         <ci>F</ci>
         <list>
          <ci>x</ci>
          <ci>T</ci>
          <ci>F</ci>
         </list>
        </apply>
       </apply>
       <apply>
        <minus></minus>
        <ci>y</ci>
        <ci>x</ci>
       </apply>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \lambda^{*}(T;F):=\sup_{(x,y)\in\mathcal{X}^{2}\atop x\neq y}\left\|\frac{IF(y%
;T;F)-IF(x;T;F)}{y-x}\right\|
  </annotation>
 </semantics>
</math>

</p>

<p>This value, which looks a lot like a <a href="Lipschitz_constant" title="wikilink">Lipschitz constant</a>, represents the effect of shifting an observation slightly from 

<math display="inline" id="Robust_statistics:55">
 <semantics>
  <mi>x</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>x</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   x
  </annotation>
 </semantics>
</math>

 to a neighbouring point 

<math display="inline" id="Robust_statistics:56">
 <semantics>
  <mi>y</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>y</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   y
  </annotation>
 </semantics>
</math>

, i.e., add an observation at 

<math display="inline" id="Robust_statistics:57">
 <semantics>
  <mi>y</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>y</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   y
  </annotation>
 </semantics>
</math>

 and remove one at 

<math display="inline" id="Robust_statistics:58">
 <semantics>
  <mi>x</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>x</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   x
  </annotation>
 </semantics>
</math>

.</p>
<h2 id="m-estimators">M-estimators</h2>

<p><em>(The mathematical context of this paragraph is given in the section on empirical influence functions.)</em></p>

<p>Historically, several approaches to robust estimation were proposed, including R-estimators and <a href="L-estimator" title="wikilink">L-estimators</a>. However, M-estimators now appear to dominate the field as a result of their generality, high breakdown point, and their efficiency. See Huber (1981).</p>

<p>M-estimators are a generalization of <a href="maximum_likelihood_estimator" title="wikilink">maximum likelihood estimators</a> (MLEs). What we try to do with MLE's is to maximize 

<math display="inline" id="Robust_statistics:59">
 <semantics>
  <mrow>
   <msubsup>
    <mo largeop="true" symmetric="true">∏</mo>
    <mrow>
     <mi>i</mi>
     <mo>=</mo>
     <mn>1</mn>
    </mrow>
    <mi>n</mi>
   </msubsup>
   <mrow>
    <mi>f</mi>
    <mrow>
     <mo stretchy="false">(</mo>
     <msub>
      <mi>x</mi>
      <mi>i</mi>
     </msub>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <apply>
     <csymbol cd="ambiguous">superscript</csymbol>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <csymbol cd="latexml">product</csymbol>
      <apply>
       <eq></eq>
       <ci>i</ci>
       <cn type="integer">1</cn>
      </apply>
     </apply>
     <ci>n</ci>
    </apply>
    <apply>
     <times></times>
     <ci>f</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>x</ci>
      <ci>i</ci>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \prod_{i=1}^{n}f(x_{i})
  </annotation>
 </semantics>
</math>

 or, equivalently, minimize 

<math display="inline" id="Robust_statistics:60">
 <semantics>
  <mrow>
   <msubsup>
    <mo largeop="true" symmetric="true">∑</mo>
    <mrow>
     <mi>i</mi>
     <mo>=</mo>
     <mn>1</mn>
    </mrow>
    <mi>n</mi>
   </msubsup>
   <mo>-</mo>
   <mrow>
    <mrow>
     <mi>log</mi>
     <mi>f</mi>
    </mrow>
    <mrow>
     <mo stretchy="false">(</mo>
     <msub>
      <mi>x</mi>
      <mi>i</mi>
     </msub>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <minus></minus>
    <apply>
     <csymbol cd="ambiguous">superscript</csymbol>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <sum></sum>
      <apply>
       <eq></eq>
       <ci>i</ci>
       <cn type="integer">1</cn>
      </apply>
     </apply>
     <ci>n</ci>
    </apply>
    <apply>
     <times></times>
     <apply>
      <log></log>
      <ci>f</ci>
     </apply>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>x</ci>
      <ci>i</ci>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \sum_{i=1}^{n}-\log f(x_{i})
  </annotation>
 </semantics>
</math>

. In 1964, Huber proposed to generalize this to the minimization of 

<math display="inline" id="Robust_statistics:61">
 <semantics>
  <mrow>
   <msubsup>
    <mo largeop="true" symmetric="true">∑</mo>
    <mrow>
     <mi>i</mi>
     <mo>=</mo>
     <mn>1</mn>
    </mrow>
    <mi>n</mi>
   </msubsup>
   <mrow>
    <mi>ρ</mi>
    <mrow>
     <mo stretchy="false">(</mo>
     <msub>
      <mi>x</mi>
      <mi>i</mi>
     </msub>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <apply>
     <csymbol cd="ambiguous">superscript</csymbol>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <sum></sum>
      <apply>
       <eq></eq>
       <ci>i</ci>
       <cn type="integer">1</cn>
      </apply>
     </apply>
     <ci>n</ci>
    </apply>
    <apply>
     <times></times>
     <ci>ρ</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>x</ci>
      <ci>i</ci>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \sum_{i=1}^{n}\rho(x_{i})
  </annotation>
 </semantics>
</math>

, where 

<math display="inline" id="Robust_statistics:62">
 <semantics>
  <mi>ρ</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>ρ</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \rho
  </annotation>
 </semantics>
</math>

 is some function. MLE are therefore a special case of M-estimators (hence the name: "<em>M</em>aximum likelihood type" estimators).</p>

<p>Minimizing 

<math display="inline" id="Robust_statistics:63">
 <semantics>
  <mrow>
   <msubsup>
    <mo largeop="true" symmetric="true">∑</mo>
    <mrow>
     <mi>i</mi>
     <mo>=</mo>
     <mn>1</mn>
    </mrow>
    <mi>n</mi>
   </msubsup>
   <mrow>
    <mi>ρ</mi>
    <mrow>
     <mo stretchy="false">(</mo>
     <msub>
      <mi>x</mi>
      <mi>i</mi>
     </msub>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <apply>
     <csymbol cd="ambiguous">superscript</csymbol>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <sum></sum>
      <apply>
       <eq></eq>
       <ci>i</ci>
       <cn type="integer">1</cn>
      </apply>
     </apply>
     <ci>n</ci>
    </apply>
    <apply>
     <times></times>
     <ci>ρ</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>x</ci>
      <ci>i</ci>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \sum_{i=1}^{n}\rho(x_{i})
  </annotation>
 </semantics>
</math>

 can often be done by differentiating 

<math display="inline" id="Robust_statistics:64">
 <semantics>
  <mi>ρ</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>ρ</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \rho
  </annotation>
 </semantics>
</math>

 and solving 

<math display="inline" id="Robust_statistics:65">
 <semantics>
  <mrow>
   <mrow>
    <msubsup>
     <mo largeop="true" symmetric="true">∑</mo>
     <mrow>
      <mi>i</mi>
      <mo>=</mo>
      <mn>1</mn>
     </mrow>
     <mi>n</mi>
    </msubsup>
    <mrow>
     <mi>ψ</mi>
     <mrow>
      <mo stretchy="false">(</mo>
      <msub>
       <mi>x</mi>
       <mi>i</mi>
      </msub>
      <mo stretchy="false">)</mo>
     </mrow>
    </mrow>
   </mrow>
   <mo>=</mo>
   <mn>0</mn>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <sum></sum>
       <apply>
        <eq></eq>
        <ci>i</ci>
        <cn type="integer">1</cn>
       </apply>
      </apply>
      <ci>n</ci>
     </apply>
     <apply>
      <times></times>
      <ci>ψ</ci>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>x</ci>
       <ci>i</ci>
      </apply>
     </apply>
    </apply>
    <cn type="integer">0</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \sum_{i=1}^{n}\psi(x_{i})=0
  </annotation>
 </semantics>
</math>

, where 

<math display="inline" id="Robust_statistics:66">
 <semantics>
  <mrow>
   <mrow>
    <mi>ψ</mi>
    <mrow>
     <mo stretchy="false">(</mo>
     <mi>x</mi>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
   <mo>=</mo>
   <mfrac>
    <mrow>
     <mi>d</mi>
     <mi>ρ</mi>
     <mrow>
      <mo stretchy="false">(</mo>
      <mi>x</mi>
      <mo stretchy="false">)</mo>
     </mrow>
    </mrow>
    <mrow>
     <mi>d</mi>
     <mi>x</mi>
    </mrow>
   </mfrac>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <times></times>
     <ci>ψ</ci>
     <ci>x</ci>
    </apply>
    <apply>
     <divide></divide>
     <apply>
      <times></times>
      <ci>d</ci>
      <ci>ρ</ci>
      <ci>x</ci>
     </apply>
     <apply>
      <times></times>
      <ci>d</ci>
      <ci>x</ci>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \psi(x)=\frac{d\rho(x)}{dx}
  </annotation>
 </semantics>
</math>

 (if 

<math display="inline" id="Robust_statistics:67">
 <semantics>
  <mi>ρ</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>ρ</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \rho
  </annotation>
 </semantics>
</math>

 has a derivative).</p>

<p>Several choices of 

<math display="inline" id="Robust_statistics:68">
 <semantics>
  <mi>ρ</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>ρ</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \rho
  </annotation>
 </semantics>
</math>

 and 

<math display="inline" id="Robust_statistics:69">
 <semantics>
  <mi>ψ</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>ψ</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \psi
  </annotation>
 </semantics>
</math>

 have been proposed. The two figures below show four 

<math display="inline" id="Robust_statistics:70">
 <semantics>
  <mi>ρ</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>ρ</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \rho
  </annotation>
 </semantics>
</math>

 functions and their corresponding 

<math display="inline" id="Robust_statistics:71">
 <semantics>
  <mi>ψ</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>ψ</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \psi
  </annotation>
 </semantics>
</math>

 functions.</p>
<figure><b>(Figure)</b>
<figcaption>RhoFunctions.png</figcaption>
</figure>

<p>For squared errors, 

<math display="inline" id="Robust_statistics:72">
 <semantics>
  <mrow>
   <mi>ρ</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <mi>x</mi>
    <mo stretchy="false">)</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <ci>ρ</ci>
    <ci>x</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \rho(x)
  </annotation>
 </semantics>
</math>

 increases at an accelerating rate, whilst for absolute errors, it increases at a constant rate. When Winsorizing is used, a mixture of these two effects is introduced: for small values of x, 

<math display="inline" id="Robust_statistics:73">
 <semantics>
  <mi>ρ</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>ρ</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \rho
  </annotation>
 </semantics>
</math>

 increases at the squared rate, but once the chosen threshold is reached (1.5 in this example), the rate of increase becomes constant. This Winsorised estimator is also known as the <a href="Huber_loss_function" title="wikilink">Huber loss function</a>.</p>

<p>Tukey's biweight (also known as bisquare) function behaves in a similar way to the squared error function at first, but for larger errors, the function tapers off.</p>
<figure><b>(Figure)</b>
<figcaption>PsiFunctions.png</figcaption>
</figure>
<h3 id="properties-of-m-estimators">Properties of M-estimators</h3>

<p>Notice that M-estimators do not necessarily relate to a probability density function. Therefore, off-the-shelf approaches to inference that arise from likelihood theory can not, in general, be used.</p>

<p>It can be shown that M-estimators are asymptotically normally distributed, so that as long as their standard errors can be computed, an approximate approach to inference is available.</p>

<p>Since M-estimators are normal only asymptotically, for small sample sizes it might be appropriate to use an alternative approach to inference, such as the bootstrap. However, M-estimates are not necessarily unique (i.e., there might be more than one solution that satisfies the equations). Also, it is possible that any particular bootstrap sample can contain more outliers than the estimator's breakdown point. Therefore, some care is needed when designing bootstrap schemes.</p>

<p>Of course, as we saw with the speed of light example, the mean is only normally distributed asymptotically and when outliers are present the approximation can be very poor even for quite large samples. However, classical statistical tests, including those based on the mean, are typically bounded above by the nominal size of the test. The same is not true of M-estimators and the type I error rate can be substantially above the nominal level.</p>

<p>These considerations do not "invalidate" M-estimation in any way. They merely make clear that some care is needed in their use, as is true of any other method of estimation.</p>
<h3 id="influence-function-of-an-m-estimator">Influence function of an M-estimator</h3>

<p>It can be shown that the influence function of an M-estimator 

<math display="inline" id="Robust_statistics:74">
 <semantics>
  <mi>T</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>T</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   T
  </annotation>
 </semantics>
</math>

 is proportional to 

<math display="inline" id="Robust_statistics:75">
 <semantics>
  <mi>ψ</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>ψ</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \psi
  </annotation>
 </semantics>
</math>

 (see Huber, 1981 (and 2004), page 45), which means we can derive the properties of such an estimator (such as its rejection point, gross-error sensitivity or local-shift sensitivity) when we know its 

<math display="inline" id="Robust_statistics:76">
 <semantics>
  <mi>ψ</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>ψ</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \psi
  </annotation>
 </semantics>
</math>

 function.</p>

<p>

<math display="inline" id="Robust_statistics:77">
 <semantics>
  <mrow>
   <mrow>
    <mi>I</mi>
    <mi>F</mi>
    <mrow>
     <mo stretchy="false">(</mo>
     <mi>x</mi>
     <mo>;</mo>
     <mi>T</mi>
     <mo>,</mo>
     <mi>F</mi>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
   <mo>=</mo>
   <mrow>
    <msup>
     <mi>M</mi>
     <mrow>
      <mo>-</mo>
      <mn>1</mn>
     </mrow>
    </msup>
    <mi>ψ</mi>
    <mrow>
     <mo stretchy="false">(</mo>
     <mi>x</mi>
     <mo>,</mo>
     <mrow>
      <mi>T</mi>
      <mrow>
       <mo stretchy="false">(</mo>
       <mi>F</mi>
       <mo stretchy="false">)</mo>
      </mrow>
     </mrow>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <times></times>
     <ci>I</ci>
     <ci>F</ci>
     <list>
      <ci>x</ci>
      <ci>T</ci>
      <ci>F</ci>
     </list>
    </apply>
    <apply>
     <times></times>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <ci>M</ci>
      <apply>
       <minus></minus>
       <cn type="integer">1</cn>
      </apply>
     </apply>
     <ci>ψ</ci>
     <interval closure="open">
      <ci>x</ci>
      <apply>
       <times></times>
       <ci>T</ci>
       <ci>F</ci>
      </apply>
     </interval>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   IF(x;T,F)=M^{-1}\psi(x,T(F))
  </annotation>
 </semantics>
</math>

 with the 

<math display="inline" id="Robust_statistics:78">
 <semantics>
  <mrow>
   <mi>p</mi>
   <mo>×</mo>
   <mi>p</mi>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <ci>p</ci>
    <ci>p</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   p\times p
  </annotation>
 </semantics>
</math>

 given by: 

<math display="inline" id="Robust_statistics:79">
 <semantics>
  <mrow>
   <mi>M</mi>
   <mo>=</mo>
   <mrow>
    <mo>-</mo>
    <mrow>
     <msub>
      <mo largeop="true" symmetric="true">∫</mo>
      <mi class="ltx_font_mathcaligraphic">𝒳</mi>
     </msub>
     <mrow>
      <msub>
       <mrow>
        <mo>(</mo>
        <mfrac>
         <mrow>
          <mrow>
           <mo>∂</mo>
           <mi>ψ</mi>
          </mrow>
          <mrow>
           <mo stretchy="false">(</mo>
           <mi>x</mi>
           <mo>,</mo>
           <mi>θ</mi>
           <mo stretchy="false">)</mo>
          </mrow>
         </mrow>
         <mrow>
          <mo>∂</mo>
          <mi>θ</mi>
         </mrow>
        </mfrac>
        <mo>)</mo>
       </mrow>
       <mrow>
        <mi>T</mi>
        <mrow>
         <mo stretchy="false">(</mo>
         <mi>F</mi>
         <mo stretchy="false">)</mo>
        </mrow>
       </mrow>
      </msub>
      <mi>d</mi>
      <mi>F</mi>
      <mrow>
       <mo stretchy="false">(</mo>
       <mi>x</mi>
       <mo stretchy="false">)</mo>
      </mrow>
     </mrow>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <ci>M</ci>
    <apply>
     <minus></minus>
     <apply>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <int></int>
       <ci>𝒳</ci>
      </apply>
      <apply>
       <times></times>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <apply>
         <divide></divide>
         <apply>
          <times></times>
          <apply>
           <partialdiff></partialdiff>
           <ci>ψ</ci>
          </apply>
          <interval closure="open">
           <ci>x</ci>
           <ci>θ</ci>
          </interval>
         </apply>
         <apply>
          <partialdiff></partialdiff>
          <ci>θ</ci>
         </apply>
        </apply>
        <apply>
         <times></times>
         <ci>T</ci>
         <ci>F</ci>
        </apply>
       </apply>
       <ci>d</ci>
       <ci>F</ci>
       <ci>x</ci>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   M=-\int_{\mathcal{X}}\left(\frac{\partial\psi(x,\theta)}{\partial\theta}\right%
)_{T(F)}dF(x)
  </annotation>
 </semantics>
</math>

.</p>
<h3 id="choice-of-ψ-and-ρ">Choice of <em>ψ</em> and <em>ρ</em></h3>

<p>In many practical situations, the choice of the 

<math display="inline" id="Robust_statistics:80">
 <semantics>
  <mi>ψ</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>ψ</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \psi
  </annotation>
 </semantics>
</math>

 function is not critical to gaining a good robust estimate, and many choices will give similar results that offer great improvements, in terms of efficiency and bias, over classical estimates in the presence of outliers (Huber, 1981).</p>

<p>Theoretically, 

<math display="inline" id="Robust_statistics:81">
 <semantics>
  <mi>ψ</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>ψ</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \psi
  </annotation>
 </semantics>
</math>

 functions are to be preferred, and Tukey's biweight (also known as bisquare) function is a popular choice. Maronna et al. (2006) recommend the biweight function with efficiency at the normal set to 85%.</p>
<h2 id="robust-parametric-approaches">Robust parametric approaches</h2>

<p>M-estimators do not necessarily relate to a density function and so are not fully parametric. Fully parametric approaches to robust modeling and inference, both Bayesian and likelihood approaches, usually deal with heavy tailed distributions such as Student's <em>t</em>-distribution.</p>

<p>For the <em>t</em>-distribution with 

<math display="inline" id="Robust_statistics:82">
 <semantics>
  <mi>ν</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>ν</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \nu
  </annotation>
 </semantics>
</math>

 degrees of freedom, it can be shown that</p>

<p>

<math display="inline" id="Robust_statistics:83">
 <semantics>
  <mrow>
   <mrow>
    <mi>ψ</mi>
    <mrow>
     <mo stretchy="false">(</mo>
     <mi>x</mi>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
   <mo>=</mo>
   <mfrac>
    <mi>x</mi>
    <mrow>
     <msup>
      <mi>x</mi>
      <mn>2</mn>
     </msup>
     <mo>+</mo>
     <mi>ν</mi>
    </mrow>
   </mfrac>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <times></times>
     <ci>ψ</ci>
     <ci>x</ci>
    </apply>
    <apply>
     <divide></divide>
     <ci>x</ci>
     <apply>
      <plus></plus>
      <apply>
       <csymbol cd="ambiguous">superscript</csymbol>
       <ci>x</ci>
       <cn type="integer">2</cn>
      </apply>
      <ci>ν</ci>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \psi(x)=\frac{x}{x^{2}+\nu}
  </annotation>
 </semantics>
</math>

.</p>

<p>For 

<math display="inline" id="Robust_statistics:84">
 <semantics>
  <mrow>
   <mi>ν</mi>
   <mo>=</mo>
   <mn>1</mn>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <ci>ν</ci>
    <cn type="integer">1</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \nu=1
  </annotation>
 </semantics>
</math>

, the <em>t</em>-distribution is equivalent to the Cauchy distribution. Notice that the degrees of freedom is sometimes known as the <em>kurtosis parameter</em>. It is the parameter that controls how heavy the tails are. In principle, 

<math display="inline" id="Robust_statistics:85">
 <semantics>
  <mi>ν</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>ν</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \nu
  </annotation>
 </semantics>
</math>

 can be estimated from the data in the same way as any other parameter. In practice, it is common for there to be multiple local maxima when 

<math display="inline" id="Robust_statistics:86">
 <semantics>
  <mi>ν</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>ν</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \nu
  </annotation>
 </semantics>
</math>

 is allowed to vary. As such, it is common to fix 

<math display="inline" id="Robust_statistics:87">
 <semantics>
  <mi>ν</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>ν</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \nu
  </annotation>
 </semantics>
</math>

 at a value around 4 or 6. The figure below displays the 

<math display="inline" id="Robust_statistics:88">
 <semantics>
  <mi>ψ</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>ψ</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \psi
  </annotation>
 </semantics>
</math>

-function for 4 different values of 

<math display="inline" id="Robust_statistics:89">
 <semantics>
  <mi>ν</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>ν</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \nu
  </annotation>
 </semantics>
</math>

.</p>
<figure><b>(Figure)</b>
<figcaption>TDistPsi.png</figcaption>
</figure>
<h3 id="example-speed-of-light-data-2">Example: speed of light data</h3>

<p>For the speed of light data, allowing the kurtosis parameter to vary and maximizing the likelihood, we get</p>

<p>

<math display="inline" id="Robust_statistics:90">
 <semantics>
  <mrow>
   <mrow>
    <mover accent="true">
     <mi>μ</mi>
     <mo stretchy="false">^</mo>
    </mover>
    <mo>=</mo>
    <mn>27.40</mn>
   </mrow>
   <mo>,</mo>
   <mrow>
    <mrow>
     <mover accent="true">
      <mi>σ</mi>
      <mo stretchy="false">^</mo>
     </mover>
     <mo>=</mo>
     <mn>3.81</mn>
    </mrow>
    <mo>,</mo>
    <mrow>
     <mover accent="true">
      <mi>ν</mi>
      <mo stretchy="false">^</mo>
     </mover>
     <mo>=</mo>
     <mn>2.13.</mn>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">formulae-sequence</csymbol>
    <apply>
     <eq></eq>
     <apply>
      <ci>normal-^</ci>
      <ci>μ</ci>
     </apply>
     <cn type="float">27.40</cn>
    </apply>
    <apply>
     <csymbol cd="ambiguous">formulae-sequence</csymbol>
     <apply>
      <eq></eq>
      <apply>
       <ci>normal-^</ci>
       <ci>σ</ci>
      </apply>
      <cn type="float">3.81</cn>
     </apply>
     <apply>
      <eq></eq>
      <apply>
       <ci>normal-^</ci>
       <ci>ν</ci>
      </apply>
      <cn type="float">2.13.</cn>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \hat{\mu}=27.40,\hat{\sigma}=3.81,\hat{\nu}=2.13.
  </annotation>
 </semantics>
</math>

</p>

<p>Fixing 

<math display="inline" id="Robust_statistics:91">
 <semantics>
  <mrow>
   <mi>ν</mi>
   <mo>=</mo>
   <mn>4</mn>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <ci>ν</ci>
    <cn type="integer">4</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \nu=4
  </annotation>
 </semantics>
</math>

 and maximizing the likelihood gives</p>

<p>

<math display="inline" id="Robust_statistics:92">
 <semantics>
  <mrow>
   <mrow>
    <mover accent="true">
     <mi>μ</mi>
     <mo stretchy="false">^</mo>
    </mover>
    <mo>=</mo>
    <mn>27.49</mn>
   </mrow>
   <mo>,</mo>
   <mrow>
    <mover accent="true">
     <mi>σ</mi>
     <mo stretchy="false">^</mo>
    </mover>
    <mo>=</mo>
    <mn>4.51.</mn>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">formulae-sequence</csymbol>
    <apply>
     <eq></eq>
     <apply>
      <ci>normal-^</ci>
      <ci>μ</ci>
     </apply>
     <cn type="float">27.49</cn>
    </apply>
    <apply>
     <eq></eq>
     <apply>
      <ci>normal-^</ci>
      <ci>σ</ci>
     </apply>
     <cn type="float">4.51.</cn>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \hat{\mu}=27.49,\hat{\sigma}=4.51.
  </annotation>
 </semantics>
</math>

</p>
<h2 id="related-concepts">Related concepts</h2>

<p>A <a href="pivotal_quantity" title="wikilink">pivotal quantity</a> is a function of data, whose underlying population distribution is a member of a parametric family, that is not dependent on the values of the parameters. An <a href="ancillary_statistic" title="wikilink">ancillary statistic</a> is such a function that is also a statistic, meaning that it is computed in terms of the data alone. Such functions are robust to parameters in the sense that they are independent of the values of the parameters, but not robust to the model in the sense that they assume an underlying model (parametric family), and in fact such functions are often very sensitive to violations of the model assumptions. Thus <a href="test_statistic" title="wikilink">test statistics</a>, frequently constructed in terms of these to not be sensitive to assumptions about parameters, are still very sensitive to model assumptions.</p>
<h2 id="replacing-outliers-and-missing-values">Replacing outliers and missing values</h2>

<p>If there are relatively few missing points, there are some models which can be used to estimate values to complete the series, such as replacing missing values with the mean or median of the data. <a href="Simple_linear_regression" title="wikilink">Simple linear regression</a> can also be used to estimate missing values (MacDonald and Zucchini, 1997; Harvey, 1989). In addition, <a class="uri" href="outliers" title="wikilink">outliers</a> can sometimes be accommodated in the data through the use of trimmed means, other scale estimators apart from standard deviation (e.g., MAD) and Winsorization (McBean and Rovers, 1998). In calculations of a trimmed mean, a fixed percentage of data is dropped from each end of an ordered data, thus eliminating the outliers. The mean is then calculated using the remaining data. <a class="uri" href="Winsorizing" title="wikilink">Winsorizing</a> involves accommodating an outlier by replacing it with the next highest or next smallest value as appropriate (Rustum &amp; Adeloye, 2007).<a class="footnoteRef" href="#fn8" id="fnref8"><sup>8</sup></a></p>

<p>However, using these types of models to predict missing values or outliers in a long time series is difficult and often unreliable, particularly if the number of values to be in-filled is relatively high in comparison with total record length. The accuracy of the estimate depends on how good and representative the model is and how long the period of missing values extends (Rosen and Lennox, 2001). The in a case of a dynamic process, so any variable is dependent, not just on the historical time series of the same variable but also on several other variables or parameters of the process. In other words, the problem is an exercise in multivariate analysis rather than the univariate approach of most of the traditional methods of estimating missing values and outliers; a multivariate model will therefore be more representative than a univariate one for predicting missing values. The kohonin self organising map (KSOM) offers a simple and robust multivariate model for data analysis, thus providing good possibilities to estimate missing values, taking into account its relationship or correlation with other pertinent variables in the data record (Rustum &amp; Adeloye 2007).</p>

<p>Standard <a href="Kalman_filter" title="wikilink">Kalman filters</a> are not robust to outliers. To this end Ting, Theodorou and Schaal have recently shown that a modification of Masreliez's theorem can deal with outliers.<a class="footnoteRef" href="#fn9" id="fnref9"><sup>9</sup></a></p>

<p>One common approach to handle outliers in data analysis is to perform outlier detection first, followed by an efficient estimation method (e.g., the least squares). While this approach is often useful, one must keep in mind two challenges. First, an outlier detection method that relies on a non-robust initial fit can suffer from the effect of masking, that is, a group of outliers can mask each other and escape detection (Rousseeuw and Leroy, 2007). Second, if a high breakdown initial fit is used for outlier detection, the follow-up analysis might inherit some of the inefficiencies of the initial estimator (He and Portnoy, 1992).</p>
<h2 id="see-also">See also</h2>
<ul>
<li><a href="Robust_confidence_intervals" title="wikilink">Robust confidence intervals</a></li>
<li><a href="Robust_regression" title="wikilink">Robust regression</a></li>
<li><a href="Unit-weighted_regression" title="wikilink">Unit-weighted regression</a></li>
</ul>
<h2 id="references">References</h2>
<ul>
<li><em>Robust Statistics - The Approach Based on Influence Functions</em>, Frank R. Hampel, Elvezio M. Ronchetti, <a href="Peter_J._Rousseeuw" title="wikilink">Peter J. Rousseeuw</a> and Werner A. Stahel, Wiley, 1986 (republished in paperback, 2005)</li>
<li><em>Robust Statistics</em>, Peter. J. Huber, Wiley, 1981 (republished in paperback, 2004)</li>
<li><em>Robust Regression and Outlier Detection</em>, <a href="Peter_J._Rousseeuw" title="wikilink">Peter J. Rousseeuw</a> and Annick M. Leroy, Wiley, 1987 (republished in paperback, 2003)</li>
<li>

<p></p></li>
<li><em>Robust Statistics - Theory and Methods</em>, Ricardo Maronna, <a href="R._Douglas_Martin" title="wikilink">R. Douglas Martin</a> and Victor Yohai, Wiley, 2006</li>
</ul>
<ul>
<li><a href="Peter_J._Rousseeuw" title="wikilink">Rousseeuw, P.J.</a> and Croux, C. "Alternatives to the Median Absolute Deviation," <em>Journal of the American Statistical Association</em> 88 (1993), 1273</li>
<li></li>
<li><a href="Xuming_He" title="wikilink">He, X.</a> and Portnoy, S. "Reweighted LS Estimators Converge at the same Rate as the Initial Estimator," <em>Annals of Statistics</em> Vol. 20, No. 4 (1992), 2161–2167</li>
<li><a href="Xuming_He" title="wikilink">He, X.</a>, Simpson, D.G. and Portnoy, S. "Breakdown Robustness of Tests," <em>Journal of the American Statistical Association</em> Vol. 85, No. 40, (1990), 446-452</li>
</ul>
<ul>
<li>Portnoy S. and <a href="Xuming_He" title="wikilink">He, X.</a> "A Robust Journey in the New Millennium," <em>Journal of the American Statistical Association</em> Vol. 95, No. 452 (Dec., 2000), 1331–1335</li>
<li>Stephen M. Stigler. "The Changing History of Robustness," <em>The American Statistician</em> November 1, 2010, 64(4): 277-281. </li>
<li>Wilcox, R. "Introduction to Robust Estimation &amp; Hypothesis Testing," Academic Press, 201</li>
</ul>
<h2 id="external-links">External links</h2>
<ul>
<li><a href="Brian_D._Ripley" title="wikilink">Brian Ripley's</a> <a href="http://www.stats.ox.ac.uk/pub/StatMeth/Robust.pdf">robust statistics course notes.</a></li>
<li><a href="http://www.nickfieller.staff.shef.ac.uk/sheff-only/StatModall05.pdf">Nick Fieller's course notes on Statistical Modelling and Computation</a> contain material on robust regression.</li>
<li><a href="http://lagrange.math.siu.edu/Olive/ol-bookp.htm">David Olive's site</a> contains course notes on robust statistics and some data sets.</li>
<li><a href="http://jsxgraph.uni-bayreuth.de/wiki/index.php/Analyze_data_with_the_Statistics_software_R">Online experiments using R and JSXGraph</a></li>
</ul>

<p>"</p>

<p><a href="Category:Statistical_theory" title="wikilink">Category:Statistical theory</a> <a href="Category:Robust_statistics" title="wikilink"> </a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1"><em>Robust Statistics</em>, <a href="Peter._J._Huber" title="wikilink">Peter. J. Huber</a>, Wiley, 1981 (republished in paperback, 2004), page 1.<a href="#fnref1">↩</a></li>
<li id="fn2"></li>
<li id="fn3"></li>
<li id="fn4">When was the ozone hole discovered, <em>Weather Underground</em><a class="uri" href="http://www.wunderground.com/climate/holefaq.asp">http://www.wunderground.com/climate/holefaq.asp</a><a href="#fnref4">↩</a></li>
<li id="fn5"><a href="http://secamlocal.ex.ac.uk/people/staff/dbs202/cag/courses/MT37C/course/node13.html">Resistant statistics</a>, <a href="http://secamlocal.ex.ac.uk/people/staff/dbs202/">David B. Stephenson</a><a href="#fnref5">↩</a></li>
<li id="fn6">See Ollina and Koivunen <a class="uri" href="http://cc.oulu.fi/~esollila/papers/ssp03fin.pdf">http://cc.oulu.fi/~esollila/papers/ssp03fin.pdf</a><a href="#fnref6">↩</a></li>
<li id="fn7">Mises, R. V. (1947). On the asymptotic distribution of differentiable statistical functions. The annals of mathematical statistics, 309-348.<a href="#fnref7">↩</a></li>
<li id="fn8">Rustum R., and A. J. Adeloye (2007); <em>Replacing outliers and missing values from activated sludge data using Kohonen Self Organizing Map</em>, Journal of Environmental Engineering, 133 (9), 909-916.<a href="#fnref8">↩</a></li>
<li id="fn9">Jo-anne Ting, Evangelos Theodorou and Stefan Schaal; "<em>A Kalman filter for robust outlier detection</em>", International Conference on Intelligent Robots and Systems - IROS , pp. 1514-1519 (2007).<a href="#fnref9">↩</a></li>
</ol>
</section>
</body>
</html>
