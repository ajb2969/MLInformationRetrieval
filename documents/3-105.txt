   Rankâ€“nullity theorem      Rankâ€“nullity theorem   In mathematics , the rankâ€“nullity theorem of linear algebra , in its simplest form, states that the rank and the nullity of a matrix add up to the number of columns of the matrix. Specifically, if A is an m -by- n matrix (with m rows and n columns) over some field , then 1         rk   (  A  )    +   nul   (  A  )     =  n   .         rk  A    nul  A    n    \operatorname{rk}(A)+\operatorname{nul}(A)=n.     This applies to linear maps as well. Let V and W be vector spaces over some field and let  be a linear map. Then the rank of T is the dimension of the image of T and the nullity of T is the dimension of the kernel of T , so we have         dim   (   im   (  T  )    )    +   dim   (   ker   (  T  )    )     =   dim   (  V  )     ,         dim   im  T     dim   ker  T      dim  V     \operatorname{dim}(\operatorname{im}(T))+\operatorname{dim}(\operatorname{ker}%
 (T))=\operatorname{dim}(V),     or, equivalently,         rk   (  T  )    +   nul   (  T  )     =   dim   (  V  )     .         rk  T    nul  T     dim  V     \operatorname{rk}(T)+\operatorname{nul}(T)=\operatorname{dim}(V).     One can refine this statement (via the splitting lemma or the below proof) to be a statement about an isomorphism of spaces, not just dimensions.  More generally, one can consider the image, kernel, coimage, and cokernel, which are related by the fundamental theorem of linear algebra .  Proofs  We give two proofs. The first proof uses notations for linear transformations, but can be easily adapted to matrices by writing , where A is . The second proof looks at the homogeneous system  associated with an  matrix A of rank  r and shows explicitly that there exist a set of linearly independent solutions that span the null space of A .  First proof: Suppose    {   ğ®  1   ,  â€¦  ,   ğ®  m   }      subscript  ğ®  1   normal-â€¦   subscript  ğ®  m     \{\mathbf{u}_{1},\ldots,\mathbf{u}_{m}\}   forms a basis of ker T . We can extend this to form a basis of V     {   ğ®  1   ,  â€¦  ,   ğ®  m   ,   ğ°  1   ,  â€¦  ,   ğ°  n   }      subscript  ğ®  1   normal-â€¦   subscript  ğ®  m    subscript  ğ°  1   normal-â€¦   subscript  ğ°  n     \{\mathbf{u}_{1},\ldots,\mathbf{u}_{m},\mathbf{w}_{1},\ldots,\mathbf{w}_{n}\}   . Since the dimension of ker T is m and the dimension of V is , it suffices to show that the dimension of  is n .  Let us see that    {   T   ğ°  1    ,  â€¦  ,   T   ğ°  n    }       T   subscript  ğ°  1    normal-â€¦    T   subscript  ğ°  n      \{T\mathbf{w}_{1},\ldots,T\mathbf{w}_{n}\}   is a basis of . Let v be an arbitrary vector in V . There exist unique scalars such that:      ğ¯  =     a  1    ğ®  1    +  â‹¯  +    a  m    ğ®  m    +    b  1    ğ°  1    +  â‹¯  +    b  n    ğ°  n         ğ¯       subscript  a  1    subscript  ğ®  1    normal-â‹¯     subscript  a  m    subscript  ğ®  m       subscript  b  1    subscript  ğ°  1    normal-â‹¯     subscript  b  n    subscript  ğ°  n       \mathbf{v}=a_{1}\mathbf{u}_{1}+\cdots+a_{m}\mathbf{u}_{m}+b_{1}\mathbf{w}_{1}+%
 \cdots+b_{n}\mathbf{w}_{n}          â‡’   T  ğ¯   =     a  1   T   ğ®  1    +  â‹¯  +    a  m   T   ğ®  m    +    b  1   T   ğ°  1    +  â‹¯  +    b  n   T   ğ°  n          normal-â‡’  absent    T  ğ¯             subscript  a  1   T   subscript  ğ®  1    normal-â‹¯     subscript  a  m   T   subscript  ğ®  m       subscript  b  1   T   subscript  ğ°  1    normal-â‹¯     subscript  b  n   T   subscript  ğ°  n        \Rightarrow T\mathbf{v}=a_{1}T\mathbf{u}_{1}+\cdots+a_{m}T\mathbf{u}_{m}+b_{1}%
 T\mathbf{w}_{1}+\cdots+b_{n}T\mathbf{w}_{n}           â‡’   T  ğ¯   =     b  1   T   ğ°  1    +  â‹¯  +    b  n   T    ğ°  n       âˆµ    T   ğ®  i    =  0      because     normal-â‡’  absent    T  ğ¯             subscript  b  1   T   subscript  ğ°  1    normal-â‹¯     subscript  b  n   T   subscript  ğ°  n           T   subscript  ğ®  i    0     \Rightarrow T\mathbf{v}=b_{1}T\mathbf{w}_{1}+\cdots+b_{n}T\mathbf{w}_{n}\;\;%
 \because T\mathbf{u}_{i}=0     Thus,    {   T   ğ°  1    ,  â€¦  ,   T   ğ°  n    }       T   subscript  ğ°  1    normal-â€¦    T   subscript  ğ°  n      \{T\mathbf{w}_{1},\ldots,T\mathbf{w}_{n}\}   spans .  We only now need to show that this list is not redundant; that is, that    {   T   ğ°  1    ,  â€¦  ,   T   ğ°  n    }       T   subscript  ğ°  1    normal-â€¦    T   subscript  ğ°  n      \{T\mathbf{w}_{1},\ldots,T\mathbf{w}_{n}\}   are linearly independent. We can do this by showing that a linear combination of these vectors is zero if and only if the coefficient on each vector is zero. Let:          c  1   T   ğ°  1    +  â‹¯  +    c  n   T   ğ°  n     =  0   â‡”    T   {     c  1    ğ°  1    +  â‹¯  +    c  n    ğ°  n     }    =  0      normal-â‡”         subscript  c  1   T   subscript  ğ°  1    normal-â‹¯     subscript  c  n   T   subscript  ğ°  n     0       T        subscript  c  1    subscript  ğ°  1    normal-â‹¯     subscript  c  n    subscript  ğ°  n       0     c_{1}T\mathbf{w}_{1}+\cdots+c_{n}T\mathbf{w}_{n}=0\Leftrightarrow T\{c_{1}%
 \mathbf{w}_{1}+\cdots+c_{n}\mathbf{w}_{n}\}=0          âˆ´      c  1    ğ°  1    +  â‹¯  +    c  n    ğ°  n     âˆˆ   ker  T       therefore  absent         subscript  c  1    subscript  ğ°  1    normal-â‹¯     subscript  c  n    subscript  ğ°  n      ker  T      \therefore c_{1}\mathbf{w}_{1}+\cdots+c_{n}\mathbf{w}_{n}\in\operatorname{ker}\;T     Then, since u i span ker T , there exists a set of scalars d i such that:         c  1    ğ°  1    +  â‹¯  +    c  n    ğ°  n     =     d  1    ğ®  1    +  â‹¯  +    d  m    ğ®  m              subscript  c  1    subscript  ğ°  1    normal-â‹¯     subscript  c  n    subscript  ğ°  n          subscript  d  1    subscript  ğ®  1    normal-â‹¯     subscript  d  m    subscript  ğ®  m       c_{1}\mathbf{w}_{1}+\cdots+c_{n}\mathbf{w}_{n}=d_{1}\mathbf{u}_{1}+\cdots+d_{m%
 }\mathbf{u}_{m}     But, since    {   ğ®  1   ,  â€¦  ,   ğ®  m   ,   ğ°  1   ,  â€¦  ,   ğ°  n   }      subscript  ğ®  1   normal-â€¦   subscript  ğ®  m    subscript  ğ°  1   normal-â€¦   subscript  ğ°  n     \{\mathbf{u}_{1},\ldots,\mathbf{u}_{m},\mathbf{w}_{1},\ldots,\mathbf{w}_{n}\}   form a basis of V , all c i , d i must be zero. Therefore,    {   T   ğ°  1    ,  â€¦  ,   T   ğ°  n    }       T   subscript  ğ°  1    normal-â€¦    T   subscript  ğ°  n      \{T\mathbf{w}_{1},\ldots,T\mathbf{w}_{n}\}   is linearly independent and indeed a basis of . This proves that the dimension of  is n , as desired.  In more abstract terms, the map splits .  Second proof: Let A be an  matrix with r  linearly independent columns (i.e. rank of A is r ). We will show that: (i) there exists a set of  linearly independent solutions to the homogeneous system , and (ii) that every other solution is a linear combination of these  solutions. In other words, we will produce an  matrix X whose columns form a basis of the null space of A .  Without loss of generality, assume that the first r columns of A are linearly independent. So, we can write , where A 1 is  with r linearly independent column vectors and A 2 is , each of whose  columns are linear combinations of the columns of A 1 . This means that for some '' matrix B (see rank factorization ) and, hence, . Let    ğ—  =   (      -  ğ        ğˆ   n  -  r       )       ğ—      ğ      subscript  ğˆ    n  r        \displaystyle\mathbf{X}=\begin{pmatrix}-\mathbf{B}\\
 \mathbf{I}_{n-r}\end{pmatrix}   , where    ğˆ   n  -  r      subscript  ğˆ    n  r     \mathbf{I}_{n-r}   is the identity matrix . We note that X is an  matrix that satisfies      ğ€ğ—  =   [   ğ€  1   :   ğ€  1   ğ  ]    (      -  ğ        ğˆ   n  -  r       )   =  -   ğ€  1   ğ  +   ğ€  1   ğ  =   ğ   .     fragments  AX    fragments  normal-[   subscript  ğ€  1   normal-:   subscript  ğ€  1   B  normal-]       ğ      subscript  ğˆ    n  r         subscript  ğ€  1   B    subscript  ğ€  1   B   O  normal-.    \mathbf{A}\mathbf{X}=[\mathbf{A}_{1}:\mathbf{A}_{1}\mathbf{B}]\begin{pmatrix}-%
 \mathbf{B}\\
 \mathbf{I}_{n-r}\end{pmatrix}=-\mathbf{A}_{1}\mathbf{B}+\mathbf{A}_{1}\mathbf{%
 B}=\mathbf{O}\;.   Therefore, each of the  columns of X are particular solutions of . Furthermore, the  columns of X are linearly independent because  will imply :      ğ—ğ®  =  ğŸ  â‡’    (      -  ğ        ğˆ   n  -  r       )   ğ®   =  ğŸ  â‡’   (      -  ğğ®       ğ®     )   =   (     ğŸ      ğŸ     )   â‡’  ğ®  =  0â€„.        ğ—ğ®  0    normal-â‡’          ğ      subscript  ğˆ    n  r      ğ®        0    normal-â‡’        ğğ®     ğ®           0    0      normal-â‡’    ğ®       0â€„.     \mathbf{X}\mathbf{u}=\mathbf{0}\Rightarrow\begin{pmatrix}-\mathbf{B}\\
 \mathbf{I}_{n-r}\end{pmatrix}\mathbf{u}=\mathbf{0}\Rightarrow\begin{pmatrix}-%
 \mathbf{B}\mathbf{u}\\
 \mathbf{u}\end{pmatrix}=\begin{pmatrix}\mathbf{0}\\
 \mathbf{0}\end{pmatrix}\Rightarrow\mathbf{u}=\mathbf{0}\;.   Therefore, the column vectors of X constitute a set of n âˆ’ r linearly independent solutions for Ax = 0 .  We next prove that any solution of  must be a linear combination of the columns of X For this, let    ğ®  =   (      ğ®  1        ğ®  2      )       ğ®     subscript  ğ®  1      subscript  ğ®  2       \displaystyle\mathbf{u}=\begin{pmatrix}\mathbf{u}_{1}\\
 \mathbf{u}_{2}\end{pmatrix}   be any vector such that . Note that since the columns of A 1 are linearly independent, implies . Therefore,      ğ€ğ®  =  ğŸ  â‡’   [   ğ€  1   :   ğ€  1   ğ  ]    (      ğ®  1        ğ®  2      )   =  ğŸ  â‡’   ğ€  1    (   ğ®  1   +   ğğ®  2   )   =  ğŸ  â‡’   ğ®  1   +   ğğ®  2   =  ğŸ  â‡’   ğ®  1   =  -   ğğ®  2      fragments  Au   0  normal-â‡’   fragments  normal-[   subscript  ğ€  1   normal-:   subscript  ğ€  1   B  normal-]      subscript  ğ®  1      subscript  ğ®  2      0  normal-â‡’   subscript  ğ€  1    fragments  normal-(   subscript  ğ®  1     subscript  ğğ®  2   normal-)    0  normal-â‡’   subscript  ğ®  1     subscript  ğğ®  2    0  normal-â‡’   subscript  ğ®  1      subscript  ğğ®  2     \mathbf{A}\mathbf{u}=\mathbf{0}\Rightarrow[\mathbf{A}_{1}:\mathbf{A}_{1}%
 \mathbf{B}]\begin{pmatrix}\mathbf{u}_{1}\\
 \mathbf{u}_{2}\end{pmatrix}=\mathbf{0}\Rightarrow\mathbf{A}_{1}(\mathbf{u}_{1}%
 +\mathbf{B}\mathbf{u}_{2})=\mathbf{0}\Rightarrow\mathbf{u}_{1}+\mathbf{B}%
 \mathbf{u}_{2}=\mathbf{0}\Rightarrow\mathbf{u}_{1}=-\mathbf{B}\mathbf{u}_{2}           â‡’  ğ®  =   (      ğ®  1        ğ®  2      )   =    (      -  ğ        ğˆ   n  -  r       )    ğ®  2    =   ğ—ğ®  2    .       normal-â‡’  absent  ğ®          subscript  ğ®  1      subscript  ğ®  2                ğ      subscript  ğˆ    n  r       subscript  ğ®  2          subscript  ğ—ğ®  2      \Rightarrow\mathbf{u}=\begin{pmatrix}\mathbf{u}_{1}\\
 \mathbf{u}_{2}\end{pmatrix}=\begin{pmatrix}-\mathbf{B}\\
 \mathbf{I}_{n-r}\end{pmatrix}\mathbf{u}_{2}=\mathbf{X}\mathbf{u}_{2}.   This proves that any vector u that is a solution of  must be a linear combination of the  special solutions given by the columns of X . And we have already seen that the columns of X are linearly independent. Hence, the columns of X constitute a basis for the null space of A . Therefore, the nullity of A is . Since r equals rank of A , it follows that . QED.  Reformulations and generalizations  This theorem is a statement of the first isomorphism theorem of algebra to the case of vector spaces; it generalizes to the splitting lemma .  In more modern language, the theorem can also be phrased as follows: if   0 â†’ U â†’ V â†’ R â†’ 0   is a short exact sequence of vector spaces, then   dim( U ) + dim( R ) = dim( V ).   Here R plays the role of im T and U is ker T , i.e.      0  â†’    ker    T     â†’   I  d      V     â†’  ğ‘‡       im  T    â†’  0       normal-â†’  0     kernel    T     I  d   normal-â†’   V   T  normal-â†’      im  T      normal-â†’    0     0\rightarrow\ker T~{}\overset{Id}{\rightarrow}~{}V~{}\overset{T}{\rightarrow}~%
 {}\operatorname{im}T\rightarrow 0     In the finite-dimensional case, this formulation is susceptible to a generalization: if   0 â†’ V 1 â†’ V 2 â†’ ... â†’ V r â†’ 0   is an exact sequence of finite-dimensional vector spaces, then        âˆ‘   i  =  1   r      (   -  1   )   i    dim   (   V  i   )      =  0.        superscript   subscript     i  1    r      superscript    1   i    dimension   subscript  V  i      0.    \sum_{i=1}^{r}(-1)^{i}\dim(V_{i})=0.     The rankâ€“nullity theorem for finite-dimensional vector spaces may also be formulated in terms of the index of a linear map. The index of a linear map , where V and W are finite-dimensional, is defined by   index T = dim(ker T ) âˆ’ dim( coker  T ).   Intuitively, dim(ker T ) is the number of independent solutions x of the equation , and dim(coker T ) is the number of independent restrictions that have to be put on y to make  solvable. The rankâ€“nullity theorem for finite-dimensional vector spaces is equivalent to the statement   index T = dim( V ) âˆ’ dim( W ).   We see that we can easily read off the index of the linear map T from the involved spaces, without any need to analyze T in detail. This effect also occurs in a much deeper result: the Atiyahâ€“Singer index theorem states that the index of certain differential operators can be read off the geometry of the involved spaces.  Notes    References    .   "  Category:Theorems in linear algebra  Category:Isomorphism theorems  Category:Articles containing proofs     , page 199. â†©     