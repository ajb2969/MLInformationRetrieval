


Rank–nullity theorem




Rank–nullity theorem

In mathematics, the rank–nullity theorem of linear algebra, in its simplest form, states that the rank and the nullity of a matrix add up to the number of columns of the matrix. Specifically, if A is an m-by-n matrix (with m rows and n columns) over some field, then1



This applies to linear maps as well. Let V and W be vector spaces over some field and let  be a linear map. Then the rank of T is the dimension of the image of T and the nullity of T is the dimension of the kernel of T, so we have



or, equivalently,



One can refine this statement (via the splitting lemma or the below proof) to be a statement about an isomorphism of spaces, not just dimensions.
More generally, one can consider the image, kernel, coimage, and cokernel, which are related by the fundamental theorem of linear algebra.
Proofs
We give two proofs. The first proof uses notations for linear transformations, but can be easily adapted to matrices by writing , where A is . The second proof looks at the homogeneous system  associated with an  matrix A of rank r and shows explicitly that there exist a set of  linearly independent solutions that span the null space of A.
First proof: Suppose 
 
 
 
 
  forms a basis of ker T. We can extend this to form a basis of V

 
 . Since the dimension of ker T is m and the dimension of V is , it suffices to show that the dimension of  is n.
Let us see that 
 
 
 
  is a basis of . Let v be an arbitrary vector in V. There exist unique scalars such that:









Thus, 
 
 
 
  spans .
We only now need to show that this list is not redundant; that is, that 
 
 
 
  are linearly independent. We can do this by showing that a linear combination of these vectors is zero if and only if the coefficient on each vector is zero. Let:






Then, since ui span ker T, there exists a set of scalars di such that:



But, since 
 
 
 
  form a basis of V, all ci, di must be zero. Therefore, 
 
 
 
  is linearly independent and indeed a basis of . This proves that the dimension of  is n, as desired.
In more abstract terms, the map  splits.
Second proof: Let A be an  matrix with r linearly independent columns (i.e. rank of A is r). We will show that: (i) there exists a set of  linearly independent solutions to the homogeneous system , and (ii) that every other solution is a linear combination of these  solutions. In other words, we will produce an  matrix X whose columns form a basis of the null space of A.
Without loss of generality, assume that the first r columns of A are linearly independent. So, we can write , where A1 is  with r linearly independent column vectors and A2 is , each of whose  columns are linear combinations of the columns of A1. This means that  for some '' matrix B (see rank factorization) and, hence, . Let 
 
 
 
 , where 
 
 
 
  is the  identity matrix. We note that X is an  matrix that satisfies


 
  Therefore, each of the  columns of X are particular solutions of . Furthermore, the  columns of X are linearly independent because  will imply :


 
  Therefore, the column vectors of X constitute a set of n − r linearly independent solutions for Ax = 0.
We next prove that any solution of  must be a linear combination of the columns of X For this, let 
 
 
 
  be any vector such that . Note that since the columns of A1 are linearly independent,  implies . Therefore,





 
  This proves that any vector u that is a solution of  must be a linear combination of the  special solutions given by the columns of X. And we have already seen that the columns of X are linearly independent. Hence, the columns of X constitute a basis for the null space of A. Therefore, the nullity of A is . Since r equals rank of A, it follows that . QED.
Reformulations and generalizations
This theorem is a statement of the first isomorphism theorem of algebra to the case of vector spaces; it generalizes to the splitting lemma.
In more modern language, the theorem can also be phrased as follows: if

0 → U → V → R → 0
 

is a short exact sequence of vector spaces, then

dim(U) + dim(R) = dim(V).
 

Here R plays the role of im T and U is ker T, i.e.



In the finite-dimensional case, this formulation is susceptible to a generalization: if

0 → V1 → V2 → ... → Vr → 0
 

is an exact sequence of finite-dimensional vector spaces, then



The rank–nullity theorem for finite-dimensional vector spaces may also be formulated in terms of the index of a linear map. The index of a linear map , where V and W are finite-dimensional, is defined by

index T = dim(ker T) − dim(coker T).
 

Intuitively, dim(ker T) is the number of independent solutions x of the equation , and dim(coker T) is the number of independent restrictions that have to be put on y to make  solvable. The rank–nullity theorem for finite-dimensional vector spaces is equivalent to the statement

index T = dim(V) − dim(W).
 

We see that we can easily read off the index of the linear map T from the involved spaces, without any need to analyze T in detail. This effect also occurs in a much deeper result: the Atiyah–Singer index theorem states that the index of certain differential operators can be read off the geometry of the involved spaces.
Notes


References


.

"
Category:Theorems in linear algebra Category:Isomorphism theorems Category:Articles containing proofs



, page 199.↩




