<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="1252">Linear-nonlinear-Poisson cascade model</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>Linear-nonlinear-Poisson cascade model</h1>
<hr>The '''linear-nonlinear-Poisson (LNP) cascade model''' is a simplified functional model of neural spike responses.<ref name="chichilnisky0&lt;p&gt;1">Chichilnisky, E. J., <a href="http://www.stat.columbia.edu/~liam/teaching/neurostat-spr07/papers/Chichilnisky-2001.pdf">A simple white noise analysis of neuronal light responses.</a> Network: Computation in Neural Systems 12:199â€“213. (2001)<a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a><a class="footnoteRef" href="#fn2" id="fnref2"><sup>2</sup></a> It has been successfully used to describe the response characteristics of neurons in early sensory pathways, especially the visual system. The LNP model is generally implicit when using reverse correlation or the <a href="spike-triggered_average" title="wikilink">spike-triggered average</a> to characterize neural responses with white-noise stimuli.</ref></hr></body></html>

<p> There are three stages of the LNP cascade model. The first stage consists of a linear filter, or linear <a href="receptive_field" title="wikilink">receptive field</a>, which describes how the neuron integrates stimulus intensity over space and time. The output of this filter then passes through a nonlinear function, which gives the neuron's instantaneous spike rate as its output. Finally, the spike rate is used to generate spikes according to an inhomogeneous <a href="Poisson_process" title="wikilink">Poisson process</a>.</p>

<p>The linear filtering stage performs <a href="dimensionality_reduction" title="wikilink">dimensionality reduction</a>, reducing the high-dimensional spatio-temporal stimulus space to a low-dimensional feature space, within which the neuron computes its response. The nonlinearity converts the filter output to a (non-negative) spike rate, and accounts for nonlinear phenomena such as spike threshold (or rectification) and response saturation. The Poisson spike generator converts the continuous spike rate to a series of spike times, under the assumption that the probability of a spike depends only on the instantaneous spike rate.</p>
<h2 id="mathematical-formulation">Mathematical formulation</h2>
<h3 id="single-filter-lnp">single-filter LNP</h3>

<p>Let 

<math display="inline" id="Linear-nonlinear-Poisson_cascade_model:0">
 <semantics>
  <mi>ğ±</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>ğ±</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \mathbf{x}
  </annotation>
 </semantics>
</math>

 denote the spatio-temporal stimulus vector at a particular instant, and 

<math display="inline" id="Linear-nonlinear-Poisson_cascade_model:1">
 <semantics>
  <mi>ğ¤</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>ğ¤</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \mathbf{k}
  </annotation>
 </semantics>
</math>

 denote a linear filter (the neuron's linear receptive field), which is a vector with the same number of elements as 

<math display="inline" id="Linear-nonlinear-Poisson_cascade_model:2">
 <semantics>
  <mi>ğ±</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>ğ±</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \mathbf{x}
  </annotation>
 </semantics>
</math>


. Let 

<math display="inline" id="Linear-nonlinear-Poisson_cascade_model:3">
 <semantics>
  <mi>f</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>f</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   f
  </annotation>
 </semantics>
</math>

 denote the nonlinearity, a scalar function with non-negative output. Then the LNP model specifies that, in the limit of small time bins,</p>

<p>

<math display="block" id="Linear-nonlinear-Poisson_cascade_model:4">
 <semantics>
  <mrow>
   <mrow>
    <mi>P</mi>
    <mrow>
     <mo stretchy="false">(</mo>
     <mtext>spike</mtext>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
   <mo>âˆ</mo>
   <mrow>
    <mi>f</mi>
    <mrow>
     <mo stretchy="false">(</mo>
     <mrow>
      <mi>ğ¤</mi>
      <mo>â‹…</mo>
      <mi>ğ±</mi>
     </mrow>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="latexml">proportional-to</csymbol>
    <apply>
     <times></times>
     <ci>P</ci>
     <mtext>spike</mtext>
    </apply>
    <apply>
     <times></times>
     <ci>f</ci>
     <apply>
      <ci>normal-â‹…</ci>
      <ci>ğ¤</ci>
      <ci>ğ±</ci>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   P(\textrm{spike})\propto f(\mathbf{k}\cdot\mathbf{x})
  </annotation>
 </semantics>
</math>

. For finite-sized time bins, this can be stated precisely as the probability of observing <em>y</em> spikes in a single bin:</p>

<p>

<math display="block" id="Linear-nonlinear-Poisson_cascade_model:5">
 <semantics>
  <mrow>
   <mrow>
    <mi>P</mi>
    <mrow>
     <mo stretchy="false">(</mo>
     <mrow>
      <mi>y</mi>
      <mtext>spikes</mtext>
     </mrow>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
   <mo>=</mo>
   <mrow>
    <mfrac>
     <msup>
      <mrow>
       <mo>(</mo>
       <mrow>
        <mi mathvariant="normal">Î”</mi>
        <mi>Î»</mi>
       </mrow>
       <mo>)</mo>
      </mrow>
      <mi>y</mi>
     </msup>
     <mrow>
      <mi>y</mi>
      <mo lspace="0pt" rspace="3.5pt">!</mo>
     </mrow>
    </mfrac>
    <msup>
     <mi>e</mi>
     <mrow>
      <mo>-</mo>
      <mrow>
       <mi mathvariant="normal">Î”</mi>
       <mi>Î»</mi>
      </mrow>
     </mrow>
    </msup>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <times></times>
     <ci>P</ci>
     <apply>
      <times></times>
      <ci>y</ci>
      <mtext>spikes</mtext>
     </apply>
    </apply>
    <apply>
     <times></times>
     <apply>
      <divide></divide>
      <apply>
       <csymbol cd="ambiguous">superscript</csymbol>
       <apply>
        <times></times>
        <ci>normal-Î”</ci>
        <ci>Î»</ci>
       </apply>
       <ci>y</ci>
      </apply>
      <apply>
       <factorial></factorial>
       <ci>y</ci>
      </apply>
     </apply>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <ci>e</ci>
      <apply>
       <minus></minus>
       <apply>
        <times></times>
        <ci>normal-Î”</ci>
        <ci>Î»</ci>
       </apply>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   P(y\textrm{~{}spikes})=\frac{\left(\Delta\lambda\right)^{y}}{y!}e^{-\Delta\lambda}
  </annotation>
 </semantics>
</math>

</p>
<dl>
<dd>where 

<math display="inline" id="Linear-nonlinear-Poisson_cascade_model:6">
 <semantics>
  <mrow>
   <mi>Î»</mi>
   <mo>=</mo>
   <mrow>
    <mi>f</mi>
    <mrow>
     <mo stretchy="false">(</mo>
     <mrow>
      <mi>ğ¤</mi>
      <mo>â‹…</mo>
      <mi>ğ±</mi>
     </mrow>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <ci>Î»</ci>
    <apply>
     <times></times>
     <ci>f</ci>
     <apply>
      <ci>normal-â‹…</ci>
      <ci>ğ¤</ci>
      <ci>ğ±</ci>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \lambda=f(\mathbf{k}\cdot\mathbf{x})
  </annotation>
 </semantics>
</math>

, and 

<math display="inline" id="Linear-nonlinear-Poisson_cascade_model:7">
 <semantics>
  <mi mathvariant="normal">Î”</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>normal-Î”</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \Delta
  </annotation>
 </semantics>
</math>


 is the bin size.
</dd>
</dl>
<h3 id="multi-filter-lnp">Multi-filter LNP</h3>

<p>For neurons sensitive to multiple dimensions of the stimulus space, the linear stage of the LNP model can be generalized to a bank of linear filters, and the nonlinearity becomes a function of multiple inputs. Let 

<math display="inline" id="Linear-nonlinear-Poisson_cascade_model:8">
 <semantics>
  <mrow>
   <msub>
    <mi>ğ¤</mi>
    <mn>ğŸ</mn>
   </msub>
   <mo>,</mo>
   <msub>
    <mi>ğ¤</mi>
    <mn>ğŸ</mn>
   </msub>
   <mo>,</mo>
   <mi mathvariant="normal">â€¦</mi>
   <mo>,</mo>
   <msub>
    <mi>ğ¤</mi>
    <mi>ğ§</mi>
   </msub>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <list>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>ğ¤</ci>
     <cn type="integer">1</cn>
    </apply>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>ğ¤</ci>
     <cn type="integer">2</cn>
    </apply>
    <ci>normal-â€¦</ci>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>ğ¤</ci>
     <ci>ğ§</ci>
    </apply>
   </list>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \mathbf{k_{1}},\mathbf{k_{2}},\ldots,\mathbf{k_{n}}
  </annotation>
 </semantics>
</math>

 denote the set of linear filters that capture a neuron's stimulus dependence. Then the multi-filter LNP model is described by</p>

<p>

<math display="block" id="Linear-nonlinear-Poisson_cascade_model:9">
 <semantics>
  <mrow>
   <mrow>
    <mi>P</mi>
    <mrow>
     <mo stretchy="false">(</mo>
     <mtext>spike</mtext>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
   <mo>âˆ</mo>
   <mrow>
    <mi>f</mi>
    <mrow>
     <mo stretchy="false">(</mo>
     <mrow>
      <mpadded width="-1.7pt">
       <msub>
        <mi>ğ¤</mi>
        <mn>ğŸ</mn>
       </msub>
      </mpadded>
      <mo rspace="0.8pt">â‹…</mo>
      <mi>ğ±</mi>
     </mrow>
     <mo rspace="5.3pt">,</mo>
     <mrow>
      <mpadded width="-1.7pt">
       <msub>
        <mi>ğ¤</mi>
        <mn>ğŸ</mn>
       </msub>
      </mpadded>
      <mo rspace="0.8pt">â‹…</mo>
      <mi>ğ±</mi>
     </mrow>
     <mo rspace="5.3pt">,</mo>
     <mi mathvariant="normal">â€¦</mi>
     <mo rspace="5.3pt">,</mo>
     <mrow>
      <mpadded width="-1.7pt">
       <msub>
        <mi>ğ¤</mi>
        <mi>ğ§</mi>
       </msub>
      </mpadded>
      <mo rspace="0.8pt">â‹…</mo>
      <mi>ğ±</mi>
     </mrow>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="latexml">proportional-to</csymbol>
    <apply>
     <times></times>
     <ci>P</ci>
     <mtext>spike</mtext>
    </apply>
    <apply>
     <times></times>
     <ci>f</ci>
     <vector>
      <apply>
       <ci>normal-â‹…</ci>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <ci>ğ¤</ci>
        <cn type="integer">1</cn>
       </apply>
       <ci>ğ±</ci>
      </apply>
      <apply>
       <ci>normal-â‹…</ci>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <ci>ğ¤</ci>
        <cn type="integer">2</cn>
       </apply>
       <ci>ğ±</ci>
      </apply>
      <ci>normal-â€¦</ci>
      <apply>
       <ci>normal-â‹…</ci>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <ci>ğ¤</ci>
        <ci>ğ§</ci>
       </apply>
       <ci>ğ±</ci>
      </apply>
     </vector>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   P(\textrm{spike})\propto f(\mathbf{k_{1}}\!\cdot\!\mathbf{x},\;\mathbf{k_{2}}%
\!\cdot\!\mathbf{x},\;\ldots,\;\mathbf{k_{n}}\!\cdot\!\mathbf{x})
  </annotation>
 </semantics>
</math>

 or</p>

<p>

<math display="block" id="Linear-nonlinear-Poisson_cascade_model:10">
 <semantics>
  <mrow>
   <mrow>
    <mrow>
     <mi>P</mi>
     <mrow>
      <mo stretchy="false">(</mo>
      <mtext>spike</mtext>
      <mo stretchy="false">)</mo>
     </mrow>
    </mrow>
    <mo>âˆ</mo>
    <mrow>
     <mi>f</mi>
     <mrow>
      <mo stretchy="false">(</mo>
      <mrow>
       <mi>K</mi>
       <mi>ğ±</mi>
      </mrow>
      <mo stretchy="false">)</mo>
     </mrow>
    </mrow>
   </mrow>
   <mo>,</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="latexml">proportional-to</csymbol>
    <apply>
     <times></times>
     <ci>P</ci>
     <mtext>spike</mtext>
    </apply>
    <apply>
     <times></times>
     <ci>f</ci>
     <apply>
      <times></times>
      <ci>K</ci>
      <ci>ğ±</ci>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   P(\textrm{spike})\propto f(K\mathbf{x}),
  </annotation>
 </semantics>
</math>

 where 

<math display="inline" id="Linear-nonlinear-Poisson_cascade_model:11">
 <semantics>
  <mi>K</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>K</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   K
  </annotation>
 </semantics>
</math>

 is a matrix whose columns are the filters 

<math display="inline" id="Linear-nonlinear-Poisson_cascade_model:12">
 <semantics>
  <msub>
   <mi>ğ¤</mi>
   <mi>ğ¢</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>ğ¤</ci>
    <ci>ğ¢</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \mathbf{k_{i}}
  </annotation>
 </semantics>
</math>


.</p>
<h2 id="estimation">Estimation</h2>

<p>The parameters of the LNP model consist of the linear filters 

<math display="inline" id="Linear-nonlinear-Poisson_cascade_model:13">
 <semantics>
  <mrow>
   <mo stretchy="false">{</mo>
   <msub>
    <mi>k</mi>
    <mi>i</mi>
   </msub>
   <mo stretchy="false">}</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <set>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>k</ci>
     <ci>i</ci>
    </apply>
   </set>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \{{k_{i}}\}
  </annotation>
 </semantics>
</math>

 and the nonlinearity 

<math display="inline" id="Linear-nonlinear-Poisson_cascade_model:14">
 <semantics>
  <mi>f</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>f</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   f
  </annotation>
 </semantics>
</math>

. The estimation problem (also known as the problem of <em>neural characterization</em>) is the problem of determining these parameters from data consisting of a time-varying stimulus and the set of observed spike times. Techniques for estimating the LNP model parameters include:</p>
<ul>
<li>moment-based techniques, such as the <a href="spike-triggered_average" title="wikilink">spike-triggered average</a> or <a href="spike-triggered_covariance" title="wikilink">spike-triggered covariance</a><a class="footnoteRef" href="#fn3" id="fnref3"><sup>3</sup></a><a class="footnoteRef" href="#fn4" id="fnref4"><sup>4</sup></a><a class="footnoteRef" href="#fn5" id="fnref5"><sup>5</sup></a><a class="footnoteRef" href="#fn6" id="fnref6"><sup>6</sup></a></li>
<li>with information-maximization or <a href="maximum_likelihood" title="wikilink">maximum likelihood</a> techniques.<a class="footnoteRef" href="#fn7" id="fnref7"><sup>7</sup></a></li>
</ul>
<h2 id="related-models">Related models</h2>
<ul>
<li>The LNP model provides a simplified, mathematically tractable approximation to more biophysically detailed <a href="Biological_neuron_model" title="wikilink">single-neuron models</a> such as the <a class="uri" href="integrate-and-fire" title="wikilink">integrate-and-fire</a> or <a href="Hodgkinâ€“Huxley_model" title="wikilink">Hodgkinâ€“Huxley model</a>.</li>
</ul>
<ul>
<li>If the nonlinearity 

<math display="inline" id="Linear-nonlinear-Poisson_cascade_model:15">
 <semantics>
  <mi>f</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>f</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   f
  </annotation>
 </semantics>
</math>

 is a fixed invertible function, then the LNP model is a <a href="generalized_linear_model" title="wikilink">generalized linear model</a>. In this case, 

<math display="inline" id="Linear-nonlinear-Poisson_cascade_model:16">
 <semantics>
  <mi>f</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>f</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   f
  </annotation>
 </semantics>
</math>

 is the inverse link function.</li>
</ul>
<ul>
<li>An alternative to the LNP model for neural characterization is the <a href="Volterra_series" title="wikilink">Volterra kernel</a> or <a href="Wiener_kernel" title="wikilink">Wiener kernel</a> series expansion, which arises in classical nonlinear systems-identification theory.<a class="footnoteRef" href="#fn8" id="fnref8"><sup>8</sup></a> These models approximate a neuron's input-output characteristics using a polynomial expansion analogous to the <a href="Taylor_series" title="wikilink">Taylor series</a>, but do not explicitly specify the spike-generation process.</li>
</ul>
<h2 id="see-also">See also</h2>
<ul>
<li><a href="Random_neural_network" title="wikilink">Random neural network</a></li>
<li><a href="Spike-triggered_average" title="wikilink">Spike-triggered average</a></li>
<li><a href="Spike-triggered_covariance" title="wikilink">Spike-triggered covariance</a></li>
</ul>
<h2 id="references">References</h2>
<references>
</references>

<p>"</p>

<p><a href="Category:Computational_neuroscience" title="wikilink">Category:Computational neuroscience</a> <a href="Category:Stochastic_models" title="wikilink">Category:Stochastic models</a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1">Simoncelli, E. P., Paninski, L., Pillow, J. &amp; Swartz, O. (2004). <a href="http://www.cns.nyu.edu/~eero/ABSTRACTS/simoncelli03c-abstract.html">Characterization of Neural Responses with Stochastic Stimuli</a> in (Ed. M. Gazzaniga) <em>The Cognitive Neurosciences 3rd edn</em> (pp 327â€“338) MIT press.<a href="#fnref1">â†©</a></li>
<li id="fn2">Schwartz O., Pillow J. W., Rust N. C., &amp; Simoncelli E. P. (2006). Spike-triggered neural characterization. <em>Journal of Vision</em> 6:484â€“507<a href="#fnref2">â†©</a></li>
<li id="fn3"></li>
<li id="fn4"></li>
<li id="fn5"></li>
<li id="fn6">Brenner, N., Bialek, W., &amp; de Ruyter van Steveninck, R. R. (2000).<a href="#fnref6">â†©</a></li>
<li id="fn7">Paninski, L. (2004) Maximum likelihood estimation of cascade point-process neural encoding models. In <em>Network: Computation in Neural Systems</em>.<a href="#fnref7">â†©</a></li>
<li id="fn8">Marmarelis &amp; Marmerelis, 1978. <em>Analysis of Physiological Systems: The White Noise Approach.</em> London: Plenum Press.<a href="#fnref8">â†©</a></li>
</ol>
</section>


