   Winsorising      Winsorising  table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
   margin: 0; padding: 0; vertical-align: baseline; border: none; }
 <style>
 table.sourceCode { width: 100%; line-height: 100%; }
 td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
 td.sourceCode { padding-left: 5px; }
 code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
 code > span.dt { color: #902000; } /* DataType */
 code > span.dv { color: #40a070; } /* DecVal */
 code > span.bn { color: #40a070; } /* BaseN */
 code > span.fl { color: #40a070; } /* Float */
 code > span.ch { color: #4070a0; } /* Char */
 code > span.st { color: #4070a0; } /* String */
 code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
 code > span.ot { color: #007020; } /* Other */
 code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
 code > span.fu { color: #06287e; } /* Function */
 code > span.er { color: #ff0000; font-weight: bold; } /* Error */
 code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
 code > span.cn { color: #880000; } /* Constant */
 code > span.sc { color: #4070a0; } /* SpecialChar */
 code > span.vs { color: #4070a0; } /* VerbatimString */
 code > span.ss { color: #bb6688; } /* SpecialString */
 code > span.im { } /* Import */
 code > span.va { color: #19177c; } /* Variable */
 code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
 code > span.op { color: #666666; } /* Operator */
 code > span.bu { } /* BuiltIn */
 code > span.ex { } /* Extension */
 code > span.pp { color: #bc7a00; } /* Preprocessor */
 code > span.at { color: #7d9029; } /* Attribute */
 code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
 code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
 code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
 code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */     Winsorising or Winsorisation is the transformation of statistics by limiting extreme values in the statistical data to reduce the effect of possibly spurious outliers . It is named after the engineer-turned-biostatistician Charles P. Winsor (1895–1951). The effect is the same as clipping in signal processing.  The distribution of many statistics can be heavily influenced by outliers . A typical strategy is to set all outliers to a specified percentile of the data; for example, a 90% Winsorisation would see all data below the 5th percentile set to the 5th percentile, and data above the 95th percentile set to the 95th percentile. Winsorised estimators are usually more robust to outliers than their more standard forms, although there are alternatives, such as trimming , that will achieve a similar effect.  Example  Consider the data set consisting of:       {  92  ,  19  ,  𝟏𝟎𝟏  ,  58  ,  𝟏𝟎𝟓𝟑  ,  91  ,  26  ,  78  ,  10  ,  13  ,  -  𝟒𝟎  ,  𝟏𝟎𝟏  ,  86  ,  85  ,  15  ,  89  ,  89  ,  28  ,  -  𝟓  ,  41  }    (  N  =  20  ,  m  e  a  n  =  101.5  )      fragments   fragments  normal-{  92  normal-,  19  normal-,  101  normal-,  58  normal-,  1053  normal-,  91  normal-,  26  normal-,  78  normal-,  10  normal-,  13  normal-,   40  normal-,  101  normal-,  86  normal-,  85  normal-,  15  normal-,  89  normal-,  89  normal-,  28  normal-,   5  normal-,  41  normal-}   italic-   fragments  normal-(  N   20  normal-,  m  e  a  n   101.5  normal-)     \{92,19,\mathbf{101},58,\mathbf{1053},91,26,78,10,13,\mathbf{-40},\mathbf{101}%
 ,86,85,15,89,89,28,\mathbf{-5},41\}\qquad(N=20,mean=101.5)   The 5th percentile lies between −40 and −5, while the 95th percentile lies between 101 and 1053. (Values shown in bold.) Then a 90% Winsorisation would result in the following:       {  92  ,  19  ,  𝟏𝟎𝟏  ,  58  ,  𝟏𝟎𝟏  ,  91  ,  26  ,  78  ,  10  ,  13  ,  -  𝟓  ,  𝟏𝟎𝟏  ,  86  ,  85  ,  15  ,  89  ,  89  ,  28  ,  -  𝟓  ,  41  }    (  N  =  20  ,  m  e  a  n  =  55.65  )      fragments   fragments  normal-{  92  normal-,  19  normal-,  101  normal-,  58  normal-,  101  normal-,  91  normal-,  26  normal-,  78  normal-,  10  normal-,  13  normal-,   5  normal-,  101  normal-,  86  normal-,  85  normal-,  15  normal-,  89  normal-,  89  normal-,  28  normal-,   5  normal-,  41  normal-}   italic-   fragments  normal-(  N   20  normal-,  m  e  a  n   55.65  normal-)     \{92,19,\mathbf{101},58,\mathbf{101},91,26,78,10,13,\mathbf{-5},\mathbf{101},8%
 6,85,15,89,89,28,\mathbf{-5},41\}\qquad(N=20,mean=55.65)     Python can winsorise data using NumPy and SciPy libraries :  import scipy.stats import numpy as np
 a = np.array([ 92 , 19 , 101 , 58 , 1053 , 91 , 26 , 78 , 10 , 13 , - 40 , 101 , 86 , 85 , 15 , 89 , 89 , 28 , - 5 , 41 ])
 scipy.stats.mstats.winsorize(a, limits = 0.05 )  Distinction from trimming  Note that Winsorising is not equivalent to simply excluding data, which is a simpler procedure, called trimming or truncation , but is a method of censoring data.  In a trimmed estimator, the extreme values are discarded; in a Winsorised estimator, the extreme values are instead replaced by certain percentiles (the trimmed minimum and maximum).  Thus a Winsorised mean is not the same as a truncated mean . For instance, the 10% trimmed mean is the average of the 5th to 95th percentile of the data, while the 90% Winsorised mean sets the bottom 5% to the 5th percentile, the top 5% to the 95th percentile, and then averages the data. In the previous example the trimmed mean would be obtained from the smaller set:       {  92  ,  19  ,  𝟏𝟎𝟏  ,  58  ,  91  ,  26  ,  78  ,  10  ,  13  ,  𝟏𝟎𝟏  ,  86  ,  85  ,  15  ,  89  ,  89  ,  28  ,  -  𝟓  ,  41  }    (  N  =  18  ,  m  e  a  n  =  56.5  )      fragments   fragments  normal-{  92  normal-,  19  normal-,  101  normal-,  58  normal-,  91  normal-,  26  normal-,  78  normal-,  10  normal-,  13  normal-,  101  normal-,  86  normal-,  85  normal-,  15  normal-,  89  normal-,  89  normal-,  28  normal-,   5  normal-,  41  normal-}   italic-   fragments  normal-(  N   18  normal-,  m  e  a  n   56.5  normal-)     \{92,19,\mathbf{101},58,\quad 91,26,78,10,13,\quad\mathbf{101},86,85,15,89,89,%
 28,\mathbf{-5},41\}\qquad(N=18,mean=56.5)     More formally, they are distinct because the order statistics are not independent.  References   Hasings, C., Mosteller, F., Tukey, J. W., Winsor, C.P. (1947) Low moments for small samples: a comparative study of order statistics , Annals of Mathematical Statistics , 18, 413–426.  W. J. Dixon (1960). Simplified Estimation from Censored Normal Samples , The Annals of Mathematical Statistics, 31, 385–391.  J. W. Tukey (1962) The Future of Data Analysis , The Annals of Mathematical Statistics, 33, p. 18   "  Category:Statistical theory  Category:Robust statistics  