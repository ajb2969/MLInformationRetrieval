<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="846">Network performance</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>Network performance</h1>
<hr/>

<p><strong>Network performance</strong> refers to measures of <a href="service_quality" title="wikilink">service quality</a> of a telecommunications product as seen by the customer.</p>

<p>The following list gives examples of network performance measures for a circuit-switched network and one type of <a href="packet-switched_network" title="wikilink">packet-switched network</a>, viz. ATM:</p>
<ul>
<li>Circuit-switched networks: In <a href="circuit_switched" title="wikilink">circuit switched</a> networks, network performance is synonymous with the <a href="grade_of_service" title="wikilink">grade of service</a>. The number of rejected calls is a measure of how well the network is performing under heavy traffic loads.<a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a> Other types of performance measures can include noise, echo and so on.</li>
</ul>
<ul>
<li>ATM: In an <a href="Asynchronous_Transfer_Mode" title="wikilink">Asynchronous Transfer Mode</a> (ATM) network, performance can be measured by line rate, <a href="quality_of_service" title="wikilink">quality of service</a> (QoS), data throughput, connect time, stability, technology, modulation technique and modem enhancements.<a class="footnoteRef" href="#fn2" id="fnref2"><sup>2</sup></a></li>
</ul>

<p>There are many different ways to measure the performance of a network, as each network is different in nature and design. Performance can also be modelled instead of measured; one example of this is using state transition diagrams to model queuing performance in a circuit-switched network. These diagrams allow the network planner to analyze how the network will perform in each state, ensuring that the network will be optimally designed.<a class="footnoteRef" href="#fn3" id="fnref3"><sup>3</sup></a></p>
<h2 id="performance-measures">Performance measures</h2>

<p>The following measures are often considered important:</p>
<ul>
<li><strong>Bandwidth</strong> commonly measured in bits/second is the maximum rate that information can be transferred</li>
<li><strong>Throughput</strong> is the actual rate that information is transferred</li>
<li><strong>Latency</strong> the delay between the sender and the receiver decoding it, this is mainly a function of the signals travel time, and processing time at any nodes the information traverses</li>
<li><strong>Jitter</strong> variation in the time of arrival at the receiver of the information</li>
<li><strong>Error rate</strong> the number of corrupted bits expressed as a percentage or fraction of the total sent</li>
</ul>

<p>A common misunderstanding is that having greater <a class="uri" href="throughput" title="wikilink">throughput</a> means a "faster" connection. However, throughput, <a href="latency_(engineering)" title="wikilink">latency</a>, the type of information transmitted, and the way that information is applied all affect the <em>perceived speed</em> of a connection.</p>
<h3 id="bandwidth">Bandwidth</h3>

<p>The available channel bandwidth and achievable signal-to-noise ratio determine the maximum possible throughput. It is not generally possible to send more data than dictated by the <a href="Shannon-Hartley_Theorem" title="wikilink">Shannon-Hartley Theorem</a>.</p>
<h3 id="throughput">Throughput</h3>

<p><em>Throughput</em> is the number of messages successfully delivered per unit time. Throughput is controlled by available bandwidth, as well as the available signal-to-noise ratio and hardware limitations. Throughput for the purpose of this article will be understood to be measured from the arrival of the first bit of data at the receiver, to decouple the concept of throughput from the concept of latency. For discussions of this type the terms 'throughput' and 'bandwidth' are often used interchangeably.</p>

<p>The <em>Time Window</em> is the period over which the throughput is measured. Choice of an appropriate time window will often dominate calculations of throughput, and whether latency is taken into account or not will determine whether the latency affects the throughput or not.</p>
<h3 id="latency">Latency</h3>

<p>The <a href="speed_of_light" title="wikilink">speed of light</a> imposes a minimum propagation time on all electromagnetic signals. It is not possible to reduce the latency below</p>

<p>

<math display="block" id="Network_performance:0">
 <semantics>
  <mrow>
   <mi>t</mi>
   <mo>=</mo>
   <mrow>
    <mi>s</mi>
    <mo>/</mo>
    <msub>
     <mi>c</mi>
     <mi>m</mi>
    </msub>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <ci>t</ci>
    <apply>
     <divide></divide>
     <ci>s</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>c</ci>
      <ci>m</ci>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   t=s/c_{m}
  </annotation>
 </semantics>
</math>

</p>

<p>where s is the distance and c<sub>m</sub> is the speed of light in the medium</p>

<p>Other delays also occur in intermediate nodes. In packet switched networks delays can occur due to queueing.</p>
<h3 id="jitter">Jitter</h3>

<p><strong>Jitter</strong> is the undesired deviation from true periodicity of an assumed periodic <a href="Signalling_(telecommunication)" title="wikilink">signal</a> in <a class="uri" href="electronics" title="wikilink">electronics</a> and <a class="uri" href="telecommunications" title="wikilink">telecommunications</a>, often in relation to a reference <a href="clock_signal" title="wikilink">clock source</a>. Jitter may be observed in characteristics such as the <a class="uri" href="frequency" title="wikilink">frequency</a> of successive pulses, the signal <a class="uri" href="amplitude" title="wikilink">amplitude</a>, or <a href="phase_(waves)" title="wikilink">phase</a> of periodic signals. Jitter is a significant, and usually undesired, factor in the design of almost all communications links (e.g., <a class="uri" href="USB" title="wikilink">USB</a>, <a class="uri" href="PCI-e" title="wikilink">PCI-e</a>, <a class="uri" href="SATA" title="wikilink">SATA</a>, <a class="uri" href="OC-48" title="wikilink">OC-48</a>). In <a href="clock_recovery" title="wikilink">clock recovery</a> applications it is called <em>timing jitter</em>.<a class="footnoteRef" href="#fn4" id="fnref4"><sup>4</sup></a></p>
<h3 id="error-rate">Error rate</h3>

<p>In <a href="digital_transmission" title="wikilink">digital transmission</a>, the number of <strong>bit errors</strong> is the number of received <a href="bit" title="wikilink">bits</a> of a <a href="data_stream" title="wikilink">data stream</a> over a <a href="communication_channel" title="wikilink">communication channel</a> that have been altered due to <a href="noise_(telecommunications)" title="wikilink">noise</a>, <a href="interference_(communication)" title="wikilink">interference</a>, <a class="uri" href="distortion" title="wikilink">distortion</a> or <a href="bit_synchronization" title="wikilink">bit synchronization</a> errors.</p>

<p>The <strong>bit error rate</strong> or <strong>bit error ratio</strong> (<strong>BER</strong>) is the number of bit errors divided by the total number of transferred bits during a studied time interval. BER is a unitless performance measure, often expressed as a <a class="uri" href="percentage" title="wikilink">percentage</a>.</p>

<p>The <strong>bit error probability</strong> <em>p<sub>e</sub></em> is the <a href="expectation_value" title="wikilink">expectation value</a> of the BER. The BER can be considered as an approximate estimate of the bit error probability. This estimate is accurate for a long time interval and a high number of bit errors.</p>
<h3 id="interplay-of-factors">Interplay of factors</h3>

<p>All of the factors above, coupled with user requirements and user perceptions, play a role in determining the perceived 'fastness' or utility, of a network connection. The relationship between throughput, latency, and user experience is most aptly understood in the context of a shared network medium, and as a scheduling problem. For systems that are heavily dominated by either latency or throughput considerations.</p>
<h2 id="algorithms-and-protocols">Algorithms and protocols</h2>

<p>For some systems, latency and throughput are coupled entities. In TCP/IP, latency can also directly affect throughput. In <a href="Transmission_Control_Protocol" title="wikilink">TCP</a> connections, the large <a href="bandwidth-delay_product" title="wikilink">bandwidth-delay product</a> of high latency connections, combined with relatively small TCP window sizes on many devices, effectively causes the throughput of a high latency connection to drop sharply with latency. This can be remedied with various techniques, such as increasing the TCP congestion window size, or more drastic solutions, such as packet coalescing, TCP acceleration, and forward error correction, all of which are commonly used for high latency satellite links.</p>

<p>TCP acceleration converts the TCP packets into a stream that is similar to <a href="User_Datagram_Protocol" title="wikilink">UDP</a>. Because of this, the TCP acceleration software must provide its own mechanisms to ensure the reliability of the link, taking the latency and bandwidth of the link into account, and both ends of the high latency link must support the method used.</p>

<p>In Media access control (MAC) layer, performance issues such as throughput and end-to-end delay are also addressed. Different performance models have been developed and applied for performance analysis.<a class="footnoteRef" href="#fn5" id="fnref5"><sup>5</sup></a><a class="footnoteRef" href="#fn6" id="fnref6"><sup>6</sup></a></p>
<h2 id="examples-of-latency-or-throughput-dominated-systems">Examples of latency or throughput dominated systems</h2>

<p>Many systems can be characterized as dominated either by throughput limitations or by latency limitations in terms of end-user utility or experience. In some cases, hard limits such as the speed of light present unique problems to such systems and nothing can be done to correct this. Other systems allow for significant balancing and optimization for best user experience.</p>
<h3 id="satellite-telephony">Satellite telephony</h3>

<p>A telecom satellite in geosynchronous orbit imposes a path length of at least 71000 km between transmitter and receiver.<a class="footnoteRef" href="#fn7" id="fnref7"><sup>7</sup></a> which means a minimum delay between message request and message receipt, or latency of 473 ms. This delay can be very noticeable and affects satellite phone service regardless of available throughput capacity.</p>
<h3 id="deep-space-communication">Deep space communication</h3>

<p>These long path length considerations are exacerbated when communicating with space probes and other long-range targets beyond Earth's atmosphere. The <a href="Deep_Space_Network" title="wikilink">Deep Space Network</a> implemented by NASA is one such system that must cope with these problems. Largely latency driven, the GAO has criticized the current architecture.<a class="footnoteRef" href="#fn8" id="fnref8"><sup>8</sup></a> Several different methods have been proposed to handle the intermittent connectivity and long delays between packets, such as <a href="delay-tolerant_networking" title="wikilink">delay-tolerant networking</a>.<a class="footnoteRef" href="#fn9" id="fnref9"><sup>9</sup></a></p>
<h3 id="even-deeper-space-communication">Even deeper space communication</h3>

<p>At interstellar distances, the difficulties in designing radio systems that can achieve any throughput at all are massive. In these cases, maintaining communication is a bigger issue than how long that communication takes.</p>
<h3 id="offline-data-transport">Offline data transport</h3>

<p>Transportation is concerned almost entirely with throughput, which is why physical deliveries of backup tape archives are still largely done by vehicle.</p>
<h2 id="optimized-systems">Optimized systems</h2>
<h3 id="world-wide-web">World wide web</h3>

<p>Users on the <a class="uri" href="Internet" title="wikilink">Internet</a> feel that responses are "instant" when delays are less than 100 ms from click to response.<a class="footnoteRef" href="#fn10" id="fnref10"><sup>10</sup></a> Latency and throughput together affect the perceived speed of a connection. However, the <a href="perceived_performance" title="wikilink">perceived performance</a> of a connection can still vary widely, depending in part on the type of information transmitted and how it is used.</p>

<p>In a 2001 study, it was found that a typical web page was 53,400 bytes in size.<a class="footnoteRef" href="#fn11" id="fnref11"><sup>11</sup></a> <a class="footnoteRef" href="#fn12" id="fnref12"><sup>12</sup></a> Round-trip packet latency over the Internet is fairly low – typically less than a tenth of a second across North America – and an average web page of 30-100 kilobytes would normally transfer fully in 10–30 seconds, over a <a href="56_kbit/s_line" title="wikilink">56-kbit/s</a> <a class="uri" href="modem" title="wikilink">modem</a>, which yields a 3 KB/s transfer rate. If a user had to wait 10–30 seconds to see anything, after every web-page click, it would be intolerable.</p>

<p>Because latency is so important, the <a class="uri" href="HTTP" title="wikilink">HTTP</a> protocol and <a class="uri" href="HTML" title="wikilink">HTML</a> markup language were invented to reduce the rendering time of hypertext over the internet. These protocols allow incremental rendering, meaning that page text can begin display after the first packet arrives. HTTP and nearly all browsers support gzip (compressed) transfer encoding, which can typically compress text by 2x. Moreover, HTTP 1.0 and later protocols support a rich set of caching primitives, allowing content to be stored closer to the user, in both browser-caches and ISP proxy-caches, all to reduce latency. And finally, in the early days of HTTP, interlaced photos were transmitted via <a class="uri" href="GIF" title="wikilink">GIF</a>, which allowed a rough version of an embedded picture to appear when only half the scan lines had arrived. A few years later <a class="uri" href="JPEG" title="wikilink">JPEG</a> was invented, allowing an almost arbitrary tradeoff between latency and image quality. These optimizations of HTTP and HTML, GIF, and JPEG were crucial to reducing latency and improving the perceived performance of the World Wide Web.</p>

<p>Hence, when a user clicks on a web page, there is a delay of 500-550 milliseconds to transfer a 1500-byte packet over a 56 kbit/s modem, before the user can begin to see up to 3,000 bytes (uncompressed) of text. A DSL line with a throughput of 256kbit/s would produce a delay of roughly 60-110 ms, which would be perceived as an "instant" response.</p>

<p>By comparison, to transfer the contents of a <a class="uri" href="DVD" title="wikilink">DVD</a> over a modem could take a week or more at a 56 kbit/s modem rate. Simply <a href="sneakernet" title="wikilink">packing the DVD into an envelope and mailing it</a> could be faster.</p>
<h4 id="second-rule">8-second rule</h4>

<p>A June 2001 Zona Research report entitled "The Need for Speed II" found that the average web user will wait about eight seconds for a page to download, but that current average download time across backbone connection on most web sites is almost ten seconds.<a class="footnoteRef" href="#fn13" id="fnref13"><sup>13</sup></a></p>

<p>The <strong>8-second rule</strong> is an old (by <a class="uri" href="Internet" title="wikilink">Internet</a> standards) way of determining the adequate <a href="Response_time_(technology)" title="wikilink">response time</a> of a <a class="uri" href="webserver" title="wikilink">webserver</a> through different <a href="Bandwidth_(computing)" title="wikilink">bandwidth</a> connections. It specified that if the load-time of a web page exceeds eight seconds, users are unlikely to wait, or "stick around", for its completion. In order to increase the "stickiness" of a <a class="uri" href="website" title="wikilink">website</a>, faster ways to deliver the content to the user needed to be devised. These included stripping away unnecessary <a class="uri" href="HTML" title="wikilink">HTML</a> code and using fewer images.<a class="footnoteRef" href="#fn14" id="fnref14"><sup>14</sup></a></p>

<p>A more recent 2012 study<a class="footnoteRef" href="#fn15" id="fnref15"><sup>15</sup></a> finds that (by that time's data) viewers of online video streams start to abandon viewing the video when its startup delay reaches 2 seconds. Progressively more viewers abandon viewing as the startup delay increases (roughly 5.8% for each additional second of delay). 10 second startup delay causes about 40% of viewers to give up viewing a video.</p>
<h3 id="online-gaming">Online gaming</h3>

<p>Some <a href="online_games" title="wikilink">online games</a> utilize the <a class="uri" href="Internet" title="wikilink">Internet</a> and/or a <a href="Local_Area_Network" title="wikilink">Local Area Network</a> to coordinate a <a href="multiplayer_game" title="wikilink">multiplayer game</a> experience among two or more players, each of whom is running a copy of the game on a local game system (typically a <a href="video_game_console" title="wikilink">video game console</a> or <a href="gaming_computer" title="wikilink">gaming computer</a>), with messages sent among the multiple game systems (either directly or through a <a href="game_server" title="wikilink">game server</a> reporting the actions of each player so that all the game systems stay synchronized). If the nature of the game is such that the game's local action cannot proceed until it synchronizes with one or more remote game systems, then the latency of the Internet and/or LAN will accordingly delay the responsiveness of a game system. Although such systems may only require very low throughput (e.g. messages of <a href="game_controller" title="wikilink">game controller</a> actions may be only a few kilobits per second), the latency of the Internet and/or LAN must be low enough to meet the requirements of the game.</p>

<p>The maximum acceptable latency is game-type dependent. For example, generally, <a href="twitch_gameplay" title="wikilink">twitch gameplay</a> games such as a <a href="first-person_shooter" title="wikilink">first-person shooter</a> like <a href="Quake_3" title="wikilink">Quake 3</a> require lower latency for the best experience, while generally, a <a href="turn-based_game" title="wikilink">turn-based game</a> such as <a class="uri" href="chess" title="wikilink">chess</a> can tolerate higher latency. But, it entirely depends on the specifics of each game. For example, <a href="fast_chess" title="wikilink">fast chess</a> is a turn-based game that may have low latency requirements. And, in the case of twitch games, some games can be designed such that only events that impact the outcome of the game are subject to synchronization latency, allowing for fast local response time most of the time.</p>

<p><a href="Cloud_gaming" title="wikilink">Cloud gaming</a> is a type of online gaming where the entire game is hosted on a game server in a data center, and the user is only running a <a href="thin_client" title="wikilink">thin client</a> locally that forwards <a href="game_controller" title="wikilink">game controller</a> upstream to the game server. The game server then renders the next frame of the game video which is compressed using low-latency <a href="video_compression" title="wikilink">video compression</a> and is sent downstream and decompressed by the thin client. For the cloud gaming experience to be acceptable, the round-trip latency of all elements of the cloud gaming system (the thin client, the Internet and/or LAN connection the game server, the game execution on the game server, the video and audio compression and decompression, and the display of the video on a <a href="display_device" title="wikilink">display device</a>) must be low enough that the user perception is that the game is running locally.<a class="footnoteRef" href="#fn16" id="fnref16"><sup>16</sup></a><a class="footnoteRef" href="#fn17" id="fnref17"><sup>17</sup></a> Because of such tight latency requirements, distance considerations of the <a href="speed_of_light" title="wikilink">speed of light</a> through <a href="optical_fiber" title="wikilink">optical fiber</a> come into play, currently limiting the distance between a user and a cloud gaming game server to approximately 1000 miles, according to <a class="uri" href="OnLive" title="wikilink">OnLive</a>, the only company thus far operating a cloud gaming service.<a class="footnoteRef" href="#fn18" id="fnref18"><sup>18</sup></a></p>

<p>Online game systems utilizing a <a href="wireless_network" title="wikilink">wireless network</a> may be subject to significant latency, depending on the architecture of the wireless network and local <a href="electromagnetic_interference" title="wikilink">electromagnetic interference</a> impacting that network. Although <a href="radio_propagation" title="wikilink">radio propagation</a> through air is faster than light through optical fiber, wireless systems are often shared among many users and may suffer from latency incurred due to <a href="network_congestion" title="wikilink">network congestion</a> which can trigger <a class="uri" href="bufferbloat" title="wikilink">bufferbloat</a> related issues, or due to <a href="network_protocols" title="wikilink">network protocols</a> that introduce latency. And, in the event of <a href="electromagnetic_interference" title="wikilink">electromagnetic interference</a>, transmitted packets may be lost, requiring a retransmission which also incurs latency.</p>
<h2 id="see-also">See also</h2>
<ul>
<li><a class="uri" href="Bitrate" title="wikilink">Bitrate</a></li>
<li><a href="Digital_bandwidth" title="wikilink">Digital bandwidth</a></li>
<li><a class="uri" href="Goodput" title="wikilink">Goodput</a></li>
<li><a href="Grade_of_service" title="wikilink">Grade of service</a></li>
<li><a href="Ideal_Web_response_time" title="wikilink">Ideal Web response time</a></li>
<li><a class="uri" href="Lag" title="wikilink">Lag</a></li>
<li><a href="Measuring_network_throughput" title="wikilink">Measuring network throughput</a></li>
<li><a href="Network_traffic_measurement" title="wikilink">Network traffic measurement</a></li>
<li><a href="Round-trip_delay_time" title="wikilink">Response time</a></li>
</ul>
<h2 id="notes">Notes</h2>
<h2 id="references">References</h2>
<ul>
<li></li>
<li></li>
<li>Fall, Kevin, <a href="http://www.dtnrg.org/docs/papers/IRB-TR-03-003.pdf">"A Delay-Tolerant Network Architecture for Challenged Internets"</a>, Intel Corporation, February, 2003, Doc No: IRB-TR-03-003</li>
<li>Government Accountability Office (GAO) report 06-445, NASA'S DEEP SPACE NETWORK: Current Management Structure is Not Conducive to Effectively Matching Resources with Future Requirements, April 27, 2006</li>
</ul>
<h2 id="external-links">External links</h2>
<ul>
<li><a href="http://deepspace.jpl.nasa.gov/dsn/">NASA's Deep Space Network Website</a></li>
<li><a href="https://web.archive.org/web/20141204094820/http://www.stuartcheshire.org/rants/Latency.html">It's the Latency, Stupid</a></li>
<li><a href="https://web.archive.org/web/20141204094820/http://www.stuartcheshire.org/papers/LatencyQuest.html">More formal paper by same author</a></li>
<li><a href="http://www.cs.ucsd.edu/~varghese/PAPERS/webinfocom.pdf">A technical article on techniques for reducing web latency</a></li>
<li><a href="http://sites.google.com/site/netperfeval/">Course on 'Network Performance Evaluation' by Virtual University, Pakistan</a></li>
<li><a href="http://www.pcmag.com/article2/0,2817,2381754,00.asp">Wi-Fi Cuts Broadband Speeds by 30 Percent, Study Says</a> PCMag, 2011</li>
</ul>

<p>"</p>

<p><a href="Category:Network_performance" title="wikilink"> </a> <a href="Category:Computing_comparisons" title="wikilink">Category:Computing comparisons</a> <a href="Category:Information_theory" title="wikilink">Category:Information theory</a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1"><a href="http://www.com.dtu.dk/teletraffic/handbook/telenook.pdf">ITU-T Study Group 2, Teletraffic Engineering Handbook</a> (PDF), Retrieved on 2005-02-13.<a href="#fnref1">↩</a></li>
<li id="fn2"><a href="http://www.telecommagazine.com">Telecommunications Magazine Online</a>, Americas January 2003, Issue Highlights, Online Exclusive: Broadband Access Maximum Performance, Retrieved on 2005-02-13.<a href="#fnref2">↩</a></li>
<li id="fn3"><a href="#fnref3">↩</a></li>
<li id="fn4"><a href="#Wol1991" title="wikilink">Wolaver, 1991, p.211</a><a href="#fnref4">↩</a></li>
<li id="fn5"><a href="#fnref5">↩</a></li>
<li id="fn6"><a href="#fnref6">↩</a></li>
<li id="fn7">Roddy, 2001, 67 - 90<a href="#fnref7">↩</a></li>
<li id="fn8">U.S. Government Accounting Office (GAO), 2006<a href="#fnref8">↩</a></li>
<li id="fn9">Kevin Fall, 2003<a href="#fnref9">↩</a></li>
<li id="fn10">Millar, R.B. (1968), Response in man-machine conversational transactions, Proc. AFIPS Fall Joint Computer Conference Vol. 33, 267-277.<a href="#fnref10">↩</a></li>
<li id="fn11"><a href="#fnref11">↩</a></li>
<li id="fn12"><a href="#fnref12">↩</a></li>
<li id="fn13"><a href="#fnref13">↩</a></li>
<li id="fn14"><a href="#fnref14">↩</a></li>
<li id="fn15"><a href="#fnref15">↩</a></li>
<li id="fn16"></li>
<li id="fn17"><a href="#fnref17">↩</a></li>
<li id="fn18"><a href="#fnref18">↩</a></li>
</ol>
</section>
</body>
</html>
