<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="181">Binary entropy function</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>Binary entropy function</h1>
<hr/>
<figure><b>(Figure)</b>
<figcaption>Entropy of a <a href="Bernoulli_trial" title="wikilink">Bernoulli trial</a> as a function of success probability, called the <strong>binary entropy function</strong>.</figcaption>
</figure>

<p>In <a href="information_theory" title="wikilink">information theory</a>, the <strong>binary entropy function</strong>, denoted 

<math display="inline" id="Binary_entropy_function:0">
 <semantics>
  <mrow>
   <mi>H</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <mi>p</mi>
    <mo rspace="4.2pt" stretchy="false">)</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <ci>H</ci>
    <ci>p</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   H(p)\,
  </annotation>
 </semantics>
</math>

 or 

<math display="inline" id="Binary_entropy_function:1">
 <semantics>
  <mrow>
   <msub>
    <mi>H</mi>
    <mi mathvariant="normal">b</mi>
   </msub>
   <mrow>
    <mo stretchy="false">(</mo>
    <mi>p</mi>
    <mo rspace="4.2pt" stretchy="false">)</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>H</ci>
     <ci>normal-b</ci>
    </apply>
    <ci>p</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   H_{\mathrm{b}}(p)\,
  </annotation>
 </semantics>
</math>

, is defined as the <a href="information_entropy" title="wikilink">entropy</a> of a <a href="Bernoulli_process" title="wikilink">Bernoulli process</a> with <a class="uri" href="probability" title="wikilink">probability</a> of success <em>p</em>. Mathematically, the Bernoulli trial is modelled as a <a href="random_variable" title="wikilink">random variable</a> <em>X</em> that can take on only two values: 0 and 1. The event 

<math display="inline" id="Binary_entropy_function:2">
 <semantics>
  <mrow>
   <mi>X</mi>
   <mo>=</mo>
   <mn>1</mn>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <ci>X</ci>
    <cn type="integer">1</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   X=1
  </annotation>
 </semantics>
</math>

 is considered a success and the event 

<math display="inline" id="Binary_entropy_function:3">
 <semantics>
  <mrow>
   <mi>X</mi>
   <mo>=</mo>
   <mn>0</mn>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <ci>X</ci>
    <cn type="integer">0</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   X=0
  </annotation>
 </semantics>
</math>

 is considered a failure. (These two events are mutually exclusive and exhaustive.)</p>

<p>If 

<math display="inline" id="Binary_entropy_function:4">
 <semantics>
  <mrow>
   <mi>Pr</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <mi>X</mi>
    <mo>=</mo>
    <mn>1</mn>
    <mo stretchy="false">)</mo>
   </mrow>
   <mo>=</mo>
   <mi>p</mi>
   <mo>,</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <cerror>
    <csymbol cd="ambiguous">fragments</csymbol>
    <csymbol cd="unknown">Pr</csymbol>
    <cerror>
     <csymbol cd="ambiguous">fragments</csymbol>
     <ci>normal-(</ci>
     <csymbol cd="unknown">X</csymbol>
     <eq></eq>
     <cn type="integer">1</cn>
     <ci>normal-)</ci>
    </cerror>
    <eq></eq>
    <csymbol cd="unknown">p</csymbol>
    <ci>normal-,</ci>
   </cerror>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \mathrm{Pr}(X=1)=p,
  </annotation>
 </semantics>
</math>

 then 

<math display="inline" id="Binary_entropy_function:5">
 <semantics>
  <mrow>
   <mi>Pr</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <mi>X</mi>
    <mo>=</mo>
    <mn>0</mn>
    <mo stretchy="false">)</mo>
   </mrow>
   <mo>=</mo>
   <mn>1</mn>
   <mo>-</mo>
   <mi>p</mi>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <cerror>
    <csymbol cd="ambiguous">fragments</csymbol>
    <csymbol cd="unknown">Pr</csymbol>
    <cerror>
     <csymbol cd="ambiguous">fragments</csymbol>
     <ci>normal-(</ci>
     <csymbol cd="unknown">X</csymbol>
     <eq></eq>
     <cn type="integer">0</cn>
     <ci>normal-)</ci>
    </cerror>
    <eq></eq>
    <cn type="integer">1</cn>
    <minus></minus>
    <csymbol cd="unknown">p</csymbol>
   </cerror>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \mathrm{Pr}(X=0)=1-p
  </annotation>
 </semantics>
</math>

 and the entropy of <em>X</em> (in <a href="Shannon_(unit)" title="wikilink">shannons</a>) is given by</p>

<p>

<math display="block" id="Binary_entropy_function:6">
 <semantics>
  <mrow>
   <mrow>
    <mrow>
     <mi>H</mi>
     <mrow>
      <mo stretchy="false">(</mo>
      <mi>X</mi>
      <mo stretchy="false">)</mo>
     </mrow>
    </mrow>
    <mo>=</mo>
    <mrow>
     <msub>
      <mi>H</mi>
      <mi mathvariant="normal">b</mi>
     </msub>
     <mrow>
      <mo stretchy="false">(</mo>
      <mi>p</mi>
      <mo stretchy="false">)</mo>
     </mrow>
    </mrow>
    <mo>=</mo>
    <mrow>
     <mrow>
      <mo>-</mo>
      <mrow>
       <mi>p</mi>
       <mrow>
        <msub>
         <mi>log</mi>
         <mn>2</mn>
        </msub>
        <mi>p</mi>
       </mrow>
      </mrow>
     </mrow>
     <mo>-</mo>
     <mrow>
      <mrow>
       <mo stretchy="false">(</mo>
       <mrow>
        <mn>1</mn>
        <mo>-</mo>
        <mi>p</mi>
       </mrow>
       <mo stretchy="false">)</mo>
      </mrow>
      <mrow>
       <msub>
        <mi>log</mi>
        <mn>2</mn>
       </msub>
       <mrow>
        <mo stretchy="false">(</mo>
        <mrow>
         <mn>1</mn>
         <mo>-</mo>
         <mi>p</mi>
        </mrow>
        <mo stretchy="false">)</mo>
       </mrow>
      </mrow>
     </mrow>
    </mrow>
   </mrow>
   <mo>.</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <and></and>
    <apply>
     <eq></eq>
     <apply>
      <times></times>
      <ci>H</ci>
      <ci>X</ci>
     </apply>
     <apply>
      <times></times>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>H</ci>
       <ci>normal-b</ci>
      </apply>
      <ci>p</ci>
     </apply>
    </apply>
    <apply>
     <eq></eq>
     <share href="#.cmml">
     </share>
     <apply>
      <minus></minus>
      <apply>
       <minus></minus>
       <apply>
        <times></times>
        <ci>p</ci>
        <apply>
         <apply>
          <csymbol cd="ambiguous">subscript</csymbol>
          <log></log>
          <cn type="integer">2</cn>
         </apply>
         <ci>p</ci>
        </apply>
       </apply>
      </apply>
      <apply>
       <times></times>
       <apply>
        <minus></minus>
        <cn type="integer">1</cn>
        <ci>p</ci>
       </apply>
       <apply>
        <apply>
         <csymbol cd="ambiguous">subscript</csymbol>
         <log></log>
         <cn type="integer">2</cn>
        </apply>
        <apply>
         <minus></minus>
         <cn type="integer">1</cn>
         <ci>p</ci>
        </apply>
       </apply>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   H(X)=H_{\mathrm{b}}(p)=-p\log_{2}p-(1-p)\log_{2}(1-p).\,
  </annotation>
 </semantics>
</math>

</p>

<p>where 

<math display="inline" id="Binary_entropy_function:7">
 <semantics>
  <mrow>
   <mn>0</mn>
   <mrow>
    <msub>
     <mi>log</mi>
     <mn>2</mn>
    </msub>
    <mn>0</mn>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <cn type="integer">0</cn>
    <apply>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <log></log>
      <cn type="integer">2</cn>
     </apply>
     <cn type="integer">0</cn>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   0\log_{2}0
  </annotation>
 </semantics>
</math>

 is taken to be 0. The logarithms in this formula are usually taken (as shown in the graph) to the base 2. See <em><a href="binary_logarithm" title="wikilink">binary logarithm</a></em>.</p>

<p>When 

<math display="inline" id="Binary_entropy_function:8">
 <semantics>
  <mrow>
   <mrow>
    <mi>p</mi>
    <mo>=</mo>
    <mfrac>
     <mn>1</mn>
     <mn>2</mn>
    </mfrac>
   </mrow>
   <mo>,</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <ci>p</ci>
    <apply>
     <divide></divide>
     <cn type="integer">1</cn>
     <cn type="integer">2</cn>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   p=\frac{1}{2},
  </annotation>
 </semantics>
</math>

 the binary entropy function attains its maximum value. This is the case of the unbiased <a class="uri" href="bit" title="wikilink">bit</a>, the most common unit of <a href="information_entropy" title="wikilink">information entropy</a>.</p>

<p>

<math display="inline" id="Binary_entropy_function:9">
 <semantics>
  <mrow>
   <mi>H</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <mi>p</mi>
    <mo stretchy="false">)</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <ci>H</ci>
    <ci>p</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   H(p)
  </annotation>
 </semantics>
</math>

 is distinguished from the <a href="Information_entropy" title="wikilink">entropy function</a> 

<math display="inline" id="Binary_entropy_function:10">
 <semantics>
  <mrow>
   <mi>H</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <mi>X</mi>
    <mo stretchy="false">)</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <ci>H</ci>
    <ci>X</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   H(X)
  </annotation>
 </semantics>
</math>

 in that the former takes a single real number as a <a class="uri" href="parameter" title="wikilink">parameter</a> whereas the latter takes a distribution or random variables as a parameter. Sometimes the binary entropy function is also written as 

<math display="inline" id="Binary_entropy_function:11">
 <semantics>
  <mrow>
   <msub>
    <mi>H</mi>
    <mn>2</mn>
   </msub>
   <mrow>
    <mo stretchy="false">(</mo>
    <mi>p</mi>
    <mo stretchy="false">)</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>H</ci>
     <cn type="integer">2</cn>
    </apply>
    <ci>p</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   H_{2}(p)
  </annotation>
 </semantics>
</math>

. However, it is different from and should not be confused with the <a href="Rényi_entropy" title="wikilink">Rényi entropy</a>, which is denoted as 

<math display="inline" id="Binary_entropy_function:12">
 <semantics>
  <mrow>
   <msub>
    <mi>H</mi>
    <mn>2</mn>
   </msub>
   <mrow>
    <mo stretchy="false">(</mo>
    <mi>X</mi>
    <mo stretchy="false">)</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>H</ci>
     <cn type="integer">2</cn>
    </apply>
    <ci>X</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   H_{2}(X)
  </annotation>
 </semantics>
</math>

.</p>
<h2 id="explanation">Explanation</h2>

<p>In terms of information theory, <em>entropy</em> is considered to be a measure of the uncertainty in a message. To put it intuitively, suppose 

<math display="inline" id="Binary_entropy_function:13">
 <semantics>
  <mrow>
   <mi>p</mi>
   <mo>=</mo>
   <mn>0</mn>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <ci>p</ci>
    <cn type="integer">0</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   p=0
  </annotation>
 </semantics>
</math>

. At this probability, the event is certain never to occur, and so there is no uncertainty at all, leading to an entropy of 0. If 

<math display="inline" id="Binary_entropy_function:14">
 <semantics>
  <mrow>
   <mi>p</mi>
   <mo>=</mo>
   <mn>1</mn>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <ci>p</ci>
    <cn type="integer">1</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   p=1
  </annotation>
 </semantics>
</math>

, the result is again certain, so the entropy is 0 here as well. When 

<math display="inline" id="Binary_entropy_function:15">
 <semantics>
  <mrow>
   <mi>p</mi>
   <mo>=</mo>
   <mrow>
    <mn>1</mn>
    <mo>/</mo>
    <mn>2</mn>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <ci>p</ci>
    <apply>
     <divide></divide>
     <cn type="integer">1</cn>
     <cn type="integer">2</cn>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   p=1/2
  </annotation>
 </semantics>
</math>

, the uncertainty is at a maximum; if one were to place a fair bet on the outcome in this case, there is no advantage to be gained with prior knowledge of the probabilities. In this case, the entropy is maximum at a value of 1 bit. Intermediate values fall between these cases; for instance, if 

<math display="inline" id="Binary_entropy_function:16">
 <semantics>
  <mrow>
   <mi>p</mi>
   <mo>=</mo>
   <mrow>
    <mn>1</mn>
    <mo>/</mo>
    <mn>4</mn>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <ci>p</ci>
    <apply>
     <divide></divide>
     <cn type="integer">1</cn>
     <cn type="integer">4</cn>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   p=1/4
  </annotation>
 </semantics>
</math>

, there is still a measure of uncertainty on the outcome, but one can still predict the outcome correctly more often than not, so the uncertainty measure, or entropy, is less than 1 full bit.</p>
<h2 id="derivative">Derivative</h2>

<p>The <a class="uri" href="derivative" title="wikilink">derivative</a> of the <strong>binary entropy function</strong> may be expressed as the negative of the <a class="uri" href="logit" title="wikilink">logit</a> function:</p>

<p>

<math display="block" id="Binary_entropy_function:17">
 <semantics>
  <mrow>
   <mrow>
    <mrow>
     <mfrac>
      <mi>d</mi>
      <mrow>
       <mi>d</mi>
       <mi>p</mi>
      </mrow>
     </mfrac>
     <msub>
      <mi>H</mi>
      <mi mathvariant="normal">b</mi>
     </msub>
     <mrow>
      <mo stretchy="false">(</mo>
      <mi>p</mi>
      <mo stretchy="false">)</mo>
     </mrow>
    </mrow>
    <mo>=</mo>
    <mrow>
     <mo>-</mo>
     <mrow>
      <msub>
       <mo>logit</mo>
       <mn>2</mn>
      </msub>
      <mrow>
       <mo stretchy="false">(</mo>
       <mi>p</mi>
       <mo stretchy="false">)</mo>
      </mrow>
     </mrow>
    </mrow>
    <mo>=</mo>
    <mrow>
     <mo>-</mo>
     <mrow>
      <msub>
       <mi>log</mi>
       <mn>2</mn>
      </msub>
      <mrow>
       <mo>(</mo>
       <mfrac>
        <mi>p</mi>
        <mrow>
         <mn>1</mn>
         <mo>-</mo>
         <mi>p</mi>
        </mrow>
       </mfrac>
       <mo>)</mo>
      </mrow>
     </mrow>
    </mrow>
   </mrow>
   <mo>.</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <and></and>
    <apply>
     <eq></eq>
     <apply>
      <times></times>
      <apply>
       <divide></divide>
       <ci>d</ci>
       <apply>
        <times></times>
        <ci>d</ci>
        <ci>p</ci>
       </apply>
      </apply>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>H</ci>
       <ci>normal-b</ci>
      </apply>
      <ci>p</ci>
     </apply>
     <apply>
      <minus></minus>
      <apply>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <ci>logit</ci>
        <cn type="integer">2</cn>
       </apply>
       <ci>p</ci>
      </apply>
     </apply>
    </apply>
    <apply>
     <eq></eq>
     <share href="#.cmml">
     </share>
     <apply>
      <minus></minus>
      <apply>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <log></log>
        <cn type="integer">2</cn>
       </apply>
       <apply>
        <divide></divide>
        <ci>p</ci>
        <apply>
         <minus></minus>
         <cn type="integer">1</cn>
         <ci>p</ci>
        </apply>
       </apply>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   {d\over dp}H_{\mathrm{b}}(p)=-\operatorname{logit}_{2}(p)=-\log_{2}\left(\frac%
{p}{1-p}\right).\,
  </annotation>
 </semantics>
</math>

</p>
<h2 id="taylor-series">Taylor series</h2>

<p>The <a href="Taylor_series" title="wikilink">Taylor series</a> of the binary entropy function in a neighborhood of 1/2 is</p>

<p>

<math display="block" id="Binary_entropy_function:18">
 <semantics>
  <mrow>
   <mrow>
    <msub>
     <mi>H</mi>
     <mi mathvariant="normal">b</mi>
    </msub>
    <mrow>
     <mo stretchy="false">(</mo>
     <mi>p</mi>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
   <mo>=</mo>
   <mrow>
    <mn>1</mn>
    <mo>-</mo>
    <mrow>
     <mfrac>
      <mn>1</mn>
      <mrow>
       <mn>2</mn>
       <mrow>
        <mi>ln</mi>
        <mn>2</mn>
       </mrow>
      </mrow>
     </mfrac>
     <mrow>
      <munderover>
       <mo largeop="true" movablelimits="false" symmetric="true">∑</mo>
       <mrow>
        <mi>n</mi>
        <mo>=</mo>
        <mn>1</mn>
       </mrow>
       <merror class="ltx_ERROR undefined undefined">
        <mtext>\infin</mtext>
       </merror>
      </munderover>
      <mfrac>
       <msup>
        <mrow>
         <mo stretchy="false">(</mo>
         <mrow>
          <mn>1</mn>
          <mo>-</mo>
          <mrow>
           <mn>2</mn>
           <mi>p</mi>
          </mrow>
         </mrow>
         <mo stretchy="false">)</mo>
        </mrow>
        <mrow>
         <mn>2</mn>
         <mi>n</mi>
        </mrow>
       </msup>
       <mrow>
        <mi>n</mi>
        <mrow>
         <mo stretchy="false">(</mo>
         <mrow>
          <mrow>
           <mn>2</mn>
           <mi>n</mi>
          </mrow>
          <mo>-</mo>
          <mn>1</mn>
         </mrow>
         <mo stretchy="false">)</mo>
        </mrow>
       </mrow>
      </mfrac>
     </mrow>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <times></times>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>H</ci>
      <ci>normal-b</ci>
     </apply>
     <ci>p</ci>
    </apply>
    <apply>
     <minus></minus>
     <cn type="integer">1</cn>
     <apply>
      <times></times>
      <apply>
       <divide></divide>
       <cn type="integer">1</cn>
       <apply>
        <times></times>
        <cn type="integer">2</cn>
        <apply>
         <ln></ln>
         <cn type="integer">2</cn>
        </apply>
       </apply>
      </apply>
      <apply>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <apply>
         <csymbol cd="ambiguous">superscript</csymbol>
         <sum></sum>
         <mtext>\infin</mtext>
        </apply>
        <apply>
         <eq></eq>
         <ci>n</ci>
         <cn type="integer">1</cn>
        </apply>
       </apply>
       <apply>
        <divide></divide>
        <apply>
         <csymbol cd="ambiguous">superscript</csymbol>
         <apply>
          <minus></minus>
          <cn type="integer">1</cn>
          <apply>
           <times></times>
           <cn type="integer">2</cn>
           <ci>p</ci>
          </apply>
         </apply>
         <apply>
          <times></times>
          <cn type="integer">2</cn>
          <ci>n</ci>
         </apply>
        </apply>
        <apply>
         <times></times>
         <ci>n</ci>
         <apply>
          <minus></minus>
          <apply>
           <times></times>
           <cn type="integer">2</cn>
           <ci>n</ci>
          </apply>
          <cn type="integer">1</cn>
         </apply>
        </apply>
       </apply>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   H_{\mathrm{b}}(p)=1-\frac{1}{2\ln 2}\sum^{\infin}_{n=1}\frac{(1-2p)^{2n}}{n(2n%
-1)}
  </annotation>
 </semantics>
</math>

 for 

<math display="inline" id="Binary_entropy_function:19">
 <semantics>
  <mrow>
   <mn>0</mn>
   <mo>≤</mo>
   <mi>p</mi>
   <mo>≤</mo>
   <mn>1</mn>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <and></and>
    <apply>
     <leq></leq>
     <cn type="integer">0</cn>
     <ci>p</ci>
    </apply>
    <apply>
     <leq></leq>
     <share href="#.cmml">
     </share>
     <cn type="integer">1</cn>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   0\leq p\leq 1
  </annotation>
 </semantics>
</math>

.</p>
<h2 id="see-also">See also</h2>
<ul>
<li><a href="Metric_entropy" title="wikilink">Metric entropy</a></li>
<li><a href="Information_theory" title="wikilink">Information theory</a></li>
<li><a href="Information_entropy" title="wikilink">Information entropy</a></li>
</ul>
<h2 id="references">References</h2>
<ul>
<li>David J. C. MacKay. <em><a href="http://www.inference.phy.cam.ac.uk/mackay/itila/book.html">Information Theory, Inference, and Learning Algorithms</a></em> Cambridge: Cambridge University Press, 2003. ISBN 0-521-64298-1</li>
</ul>
<h2 id="external-links">External links</h2>

<p>"</p>

<p><a href="Category:Entropy_and_information" title="wikilink">Category:Entropy and information</a></p>
</body>
</html>
