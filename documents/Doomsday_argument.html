<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title offset="1706">Doomsday argument</title>
   <script type="text/javascript"
      src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js">
    </script>
</head>
<body>
<h1>Doomsday argument</h1>
<hr/>
<figure><b>(Figure)</b>
<figcaption>World population from 10,000 BC to AD 2000</figcaption>
</figure>
<p>The <strong>Doomsday argument</strong> (<strong>DA</strong>) is a <a href="probability_theory" title="wikilink">probabilistic argument</a> that claims to <a class="uri" href="predict" title="wikilink">predict</a> the number of future members of the <a href="human_species" title="wikilink">human species</a> given only an estimate of the total number of humans born so far. Simply put, it says that supposing that all humans are born in a random order, chances are that any one human is born roughly in the middle.</p>
<p>It was first proposed in an explicit way by the astrophysicist <a href="Brandon_Carter" title="wikilink">Brandon Carter</a> in 1983,<a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a> from which it is sometimes called the <strong>Carter catastrophe</strong>; the argument was subsequently championed by the <a class="uri" href="philosopher" title="wikilink">philosopher</a> <a href="John_A._Leslie" title="wikilink">John A. Leslie</a> and has since been independently discovered by <a href="J._Richard_Gott" title="wikilink">J. Richard Gott</a><a class="footnoteRef" href="#fn2" id="fnref2"><sup>2</sup></a> and <a href="Holger_Bech_Nielsen" title="wikilink">Holger Bech Nielsen</a>.<a class="footnoteRef" href="#fn3" id="fnref3"><sup>3</sup></a> Similar principles of <a class="uri" href="eschatology" title="wikilink">eschatology</a> were proposed earlier by <a href="Heinz_von_Foerster" title="wikilink">Heinz von Foerster</a>, among others. A more general form was given earlier in the <a href="Lindy_effect" title="wikilink">Lindy effect</a>,<a class="footnoteRef" href="#fn4" id="fnref4"><sup>4</sup></a> in which for certain phenomena the future life expectancy is <em>proportional to</em> (though not necessarily <em>equal to</em>) the current age, and is based on decreasing <a href="mortality_rate" title="wikilink">mortality rate</a> over time: old things endure.</p>
<p>Denoting by <em>N</em> the total number of humans who were ever or will ever be born, the <a href="Copernican_principle" title="wikilink">Copernican principle</a> suggests that humans are equally likely (along with the other <em>N</em> − 1 humans) to find themselves at any position <em>n</em> of the total population <em>N</em>, so humans assume that our fractional position <em>f</em> = <em>n</em>/<em>N</em> is <a href="Uniform_distribution_(continuous)" title="wikilink">uniformly distributed</a> on the <a href="interval_(mathematics)" title="wikilink">interval</a> [0, 1] <a href="Prior_probability" title="wikilink">prior</a> to learning our absolute position.</p>
<p><em>f</em> is uniformly distributed on (0, 1) even after learning of the absolute position <em>n</em>. That is, for example, there is a 95% chance that <em>f</em> is in the interval (0.05, 1), that is <em>f</em> > 0.05. In other words we could assume that we could be 95% certain that we would be within the last 95% of all the humans ever to be born. If we know our absolute position <em>n</em>, this implies an upper bound for <em>N</em> obtained by rearranging <em>n</em>/<em>N</em> > 0.05 to give <em>N</em> <a class="uri" href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.49.5899&rep">http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.49.5899&rep</a>;=rep1&type;=pdf is used, then 60 billion humans have been born so far, so it can be estimated that there is a 95% chance that the total number of humans <em>N</em> will be less than 20 × 60 billion = 1.2 trillion. Assuming that the <a href="world_population" title="wikilink">world population</a> stabilizes <a href="World_Population#Forecasts" title="wikilink">at 10 billion</a> and a <a href="life_expectancy" title="wikilink">life expectancy</a> of <a href="Longevity#Future" title="wikilink">80 years</a>, it can be estimated that the remaining 1,140 billion humans will be born in 9,120 years. Depending on the projection of world population in the forthcoming centuries, estimates may vary, but the main point of the argument is that it is unlikely that more than 1.2 trillion humans will ever live on Earth. This problem is similar to the famous <a href="German_tank_problem" title="wikilink">German tank problem</a>.</p>
<h2 id="aspects">Aspects</h2>
<h3 id="remarks">Remarks</h3>
<ul>
<li>The step that converts <em>N</em> into an extinction time depends upon a finite human lifespan. If <a class="uri" href="immortality" title="wikilink">immortality</a> becomes common, and the birth rate drops to zero, then the human race could continue forever even if the total number of humans <em>N</em> is finite.</li>
<li>A precise formulation of the Doomsday Argument requires the <a href="Bayesian_probability" title="wikilink">Bayesian</a> interpretation of probability</li>
<li>Even among Bayesians some of the assumptions of the argument's logic would not be acceptable; for instance, the fact that it is applied to a temporal phenomenon (how long something lasts) means that <em>N</em>'s distribution simultaneously represents an "<a href="aleatory_probability" title="wikilink">aleatory probability</a>" (as a future event), and an "<a href="epistemic_probability" title="wikilink">epistemic probability</a>" (as a decided value about which we are uncertain).</li>
<li>The <em>U</em> (0,1] <em>f</em> distribution is derived from two choices, which despite being the default are also arbitrary:
<ul>
<li>The <a href="principle_of_indifference" title="wikilink">principle of indifference</a>, so that it is as likely for any other randomly selected person to be born after you as before you.</li>
<li>The <em>assumption</em> of no 'prior' knowledge on the distribution of <em>N</em>.</li>
</ul></li>
</ul>
<h3 id="simplification-two-possible-total-numbers-of-humans">Simplification: two possible total numbers of humans</h3>
<p>Assume for simplicity that the total number of humans who will ever be born is 60 billion (<em>N</em><sub>1</sub>), or 6,000 billion (<em>N</em><sub>2</sub>).<a class="footnoteRef" href="#fn5" id="fnref5"><sup>5</sup></a> If there is no prior knowledge of the position that a currently living individual, <em>X</em>, has in the history of humanity, we may instead compute how many humans were born before <em>X</em>, and arrive at (say) 59,854,795,447, which would roughly place <em>X</em> amongst the first 60 billion humans who have ever lived.</p>
<p>Now, if we assume that the number of humans who will ever be born equals <em>N</em><sub>1</sub>, the probability that <em>X</em> is amongst the first 60 billion humans who have ever lived is of course 100%. However, if the number of humans who will ever be born equals <em>N</em><sub>2</sub>, then the probability that <em>X</em> is amongst the first 60 billion humans who have ever lived is only 1%. Since X is in fact amongst the first 60 billion humans who have ever lived, this means that the total number of humans who will ever be born is more likely to be much closer to 60 billion than to 6,000 billion. In essence the DA therefore suggests that <a href="human_extinction" title="wikilink">human extinction</a> is more likely to occur sooner rather than later.</p>
<p>It is possible to sum the probabilities for each value of <em>N</em> and therefore to compute a statistical 'confidence limit' on <em>N</em>. For example, taking the numbers above, it is 99% certain that <em>N</em> is smaller than 6,000 billion.</p>
<p>Note that as remarked above, this argument assumes that the prior probability for <em>N</em> is flat, or 50% for <em>N</em><sub>1</sub> and 50% for <em>N</em><sub>2</sub> in the absence of any information about <em>X</em>. On the other hand, it is possible to conclude, given <em>X</em>, that <em>N</em><sub>2</sub> is more likely than <em>N</em><sub>1</sub>, if a different prior is used for <em>N</em>. More precisely, Bayes' theorem tells us that P(<em>N</em>|<em>X</em>)=P(<em>X</em>|<em>N</em>)P(<em>N</em>)/P(<em>X</em>), and the conservative application of the Copernican principle tells us only how to calculate P(<em>X</em>|<em>N</em>). Taking P(<em>X</em>) to be flat, we still have to make an assumption about the prior probability P(<em>N</em>) that the total number of humans is <em>N</em>. If we conclude that <em>N</em><sub>2</sub> is much more likely than <em>N</em><sub>1</sub> (for example, because producing a larger population takes more time, increasing the chance that a low-probability but cataclysmic natural event will take place in that time), then P(<em>X</em>|<em>N</em>) can become more heavily weighted towards the bigger value of <em>N</em>. A further, more detailed discussion, as well as relevant distributions P(<em>N</em>), are given below in the <a href="Doomsday_Argument#Rebuttals" title="wikilink">Rebuttals</a> section.</p>
<h3 id="what-the-argument-is-not">What the argument is not</h3>
<p>The Doomsday argument (DA) does <em>not</em> say that humanity cannot or will not exist indefinitely. It does not put any upper limit on the number of humans that will ever exist, nor provide a date for when humanity will become <a class="uri" href="extinct" title="wikilink">extinct</a>.</p>
<p>An abbreviated form of the argument <em>does</em> make these claims, by confusing probability with certainty. However, the actual DA's conclusion is:</p>
<dl>
<dd>There is a 95% <em>chance</em> of extinction within 9,120 years.
</dd>
</dl>
<p>The DA gives a 5% chance that some humans will still be alive at the end of that period. (These dates are based on the assumptions above; the precise numbers vary among specific <em>Doomsday arguments</em>.)</p>
<h2 id="variations">Variations</h2>
<p>This argument has generated a lively philosophical debate, and no consensus has yet emerged on its solution. The variants described below produce the DA by separate derivations.</p>
<h3 id="gotts-formulation-vague-prior-total-population">Gott's formulation: 'vague prior' total population</h3>
<p>Gott specifically proposes the functional form for the <a href="Prior_probability" title="wikilink">prior distribution</a> of the number of people who will ever be born (<em>N</em>). Gott's DA used the <a href="prior_probability#Uninformative_priors" title="wikilink">vague prior distribution</a>:</p>
<p><span class="LaTeX">$$P(N) = \frac{k}{N}$$</span>. where</p>
<ul>
<li>P(N) is the probability prior to discovering <em>n</em>, the total number of humans who have <em>yet</em> been born.</li>
<li>The constant, <em>k</em>, is chosen to <a href="Normalizing_constant" title="wikilink">normalize</a> the sum of P(<em>N</em>). The value chosen isn't important here, just the functional form (this is an <a href="improper_prior" title="wikilink">improper prior</a>, so no value of <em>k</em> gives a valid distribution, but <a href="Bayesian_inference" title="wikilink">Bayesian inference</a> is still possible using it.)</li>
</ul>
<p>Since Gott specifies the <a href="Prior_probability" title="wikilink">prior</a> distribution of total humans, <em>P(N)</em>, <a href="Bayes's_theorem" title="wikilink">Bayes's theorem</a> and the <a href="principle_of_indifference" title="wikilink">principle of indifference</a> alone give us <em>P(N|n)</em>, the probability of <em>N</em> humans being born if <em>n</em> is a random draw from <em>N</em>:</p>
<p><span class="LaTeX">$$P(N\mid n) = \frac{P(n\mid N) P(N)}{P(n)}.$$</span></p>
<p>This is Bayes's theorem for the <a href="posterior_probability" title="wikilink">posterior probability</a> of total population ever born of <em>N</em>, <a href="conditioning_(probability)" title="wikilink">conditioned</a> on population born thus far of <em>n</em>. Now, using the indifference principle:</p>
<p><span class="LaTeX">$$P(n\mid N) = \frac{1}{N}$$</span>.</p>
<p>The unconditioned <em>n</em> distribution of the current population is identical to the vague prior <em>N</em> probability density function,<ref>The only <a href="probability_density_function" title="wikilink">probability density functions</a> that must be specified <em><a href="A_priori_and_a_posteriori" title="wikilink">a priori</a></em> are:</ref></p>
<ul>
<li>Pr(<em>N</em>) - the ultimate number of people that will be born, assumed by J. Richard Gott to have a vague prior distribution, Pr(<em>N</em>) = <em>k</em>/<em>N</em></li>
<li>Pr(<em>n</em>|<em>N</em>) - the chance of being born in any position based on a total population <em>N</em> - all DA forms assume the <a href="Copernican_principle" title="wikilink">Copernican principle</a>, making Pr(<em>n</em>|<em>N</em>) = 1/<em>N</em></li>
</ul>
<p>From these two distributions, the Doomsday Argument proceeds to create a Bayesian inference on the distribution of <em>N</em> from <em>n</em>, through <a href="Bayes'_theorem#For_probability_densities" title="wikilink">Bayes' rule</a>, which requires P(<em>n</em>); to produce this, integrate over all the possible values of <em>N</em> which might contain an individual born <em>n</em>th (that is, wherever <em>N</em> > <em>n</em>):</p>
<p><span class="LaTeX">$$P(n) = \int_{N=n}^{N=\infty} P(n\mid N) P(N) \,dN = \int_{n}^{\infty}\frac{k}{N^2} \,dN$$</span> <span class="LaTeX">$= \frac{k}{n}.$</span></p>
<p>This is why the marginal distribution of n and N are identical in the case of P(<em>N</em>) = <em>k</em>/''N'  so:</p>
<p><span class="LaTeX">$$P(n) = \frac{k}{n}$$</span>,</p>
<p>giving P (<em>N</em> | <em>n</em>) for each specific <em>N</em> (through a substitution into the posterior probability equation):</p>
<p><span class="LaTeX">$$P(N\mid n) = \frac{n}{N^2}$$</span>.</p>
<p>The easiest way to produce the doomsday estimate with a given confidence (say 95%) is to pretend that <em>N</em> is a <a href="Continuous_random_variable" title="wikilink">continuous variable</a> (since it is very large) and <a href="Integral" title="wikilink">integrate</a> over the probability density from <em>N</em> = <em>n</em> to <em>N</em> = <em>Z</em>. (This will give a function for the probability that <em>N</em> ≤ <em>Z</em>):</p>
<p><span class="LaTeX">$$P(N \leq Z) = \int_{N=n}^{N=Z} P(N|n)\,dN$$</span> <span class="LaTeX">$= \frac{Z-n}{Z}$</span></p>
<p>Defining <em>Z</em> = 20<em>n</em> gives:</p>
<p><span class="LaTeX">$$P(N \leq 20n) = \frac{19}{20}$$</span>.</p>
<p>This is the simplest <a href="Bayes_factor" title="wikilink">Bayesian</a> derivation of the Doomsday Argument:</p>
<dl>
<dd>The chance that the total number of humans that will ever be born (<em>N</em>) is greater than twenty times the total that have been is below 5%
</dd>
</dl>
<p>The use of a <a href="prior_probability#Uninformative_priors" title="wikilink">vague prior</a> distribution seems well-motivated as it assumes as little knowledge as possible about <em>N</em>, given that any particular function must be chosen. It is equivalent to the assumption that the probability density of one's fractional position remains uniformly distributed even after learning of one's absolute position (<em>n</em>).</p>
<p>Gott's 'reference class' in his original 1993 paper was not the number of births, but the number of years 'humans' had existed as a species, which he put <a href="Human_evolution#H._sapiens" title="wikilink">at 200,000</a>. Also, Gott tried to give a 95% confidence interval between a <em>minimum</em> survival time and a maximum. Because of the 2.5% chance that he gives to underestimating the minimum he has only a 2.5% chance of overestimating the maximum. This equates to 97.5% confidence that extinction occurs before the upper boundary of his confidence interval.</p>
<p>97.5% is one chance in forty, which can be used in the integral above with <em>Z</em> = 40<em>n</em>, and <em>n</em> = 200,000 years:</p>
<p><span class="LaTeX">$$P(N \leq 40[200000]) = \frac{39}{40}$$</span></p>
<p>This is how Gott produces a 97.5% confidence of extinction within <em>N</em> ≤ 8,000,000 years. The number he quoted was the likely time remaining, <em>N</em> − <em>n</em> = <strong>7.8 million years</strong>. This was much higher than the temporal confidence bound produced by counting births, because it applied the principle of indifference to time. (Producing different estimates by sampling different parameters in the same hypothesis is <a href="Bertrand's_paradox_(probability)" title="wikilink">Bertrand's paradox</a>.)</p>
<p>His choice of 95% confidence bounds (rather than 80% or 99.9%, say) matched the scientifically accepted limit of <a href="statistical_significance" title="wikilink">statistical significance</a> for hypothesis rejection. Therefore, he argued that the <a class="uri" href="hypothesis" title="wikilink">hypothesis</a>: "humanity will cease to exist before 5,100 years or thrive beyond 7.8 million years" can be rejected.</p>
<p>Leslie's argument differs from Gott's version in that he does not assume a'' vague prior'' probability distribution for <em>N</em>. Instead he argues that the force of the Doomsday Argument resides purely in the increased probability of an early Doomsday once you take into account your birth position, regardless of your prior probability distribution for <em>N</em>. He calls this the <em>probability shift</em>.</p>
<p><a href="Heinz_von_Foerster" title="wikilink">Heinz von Foerster</a> argued that humanity's abilities to construct societies, civilizations and technologies do not result in self inhibition. Rather, societies' success varies directly with population size. Von Foerster found that this model fit some 25 data points from the birth of <a class="uri" href="Jesus" title="wikilink">Jesus</a> to 1958, with only 7% of the <a class="uri" href="variance" title="wikilink">variance</a> left unexplained. Several follow-up letters (1961, 1962, …) were published in <em>Science</em> showing that von Foerster's equation was still on track. The data continued to fit up until 1973. The most remarkable thing about von Foerster's model was it predicted that the human population would reach infinity or a mathematical singularity, on Friday, November 13, 2026. In fact, von Foerster did not imply that the world population on that day could actually become infinite. The real implication was that the world population growth pattern followed for many centuries prior to 1960 was about to come to an end and be transformed into a radically different pattern. Note that this prediction began to be fulfilled just in a few years after the "Doomsday" was published.<a class="footnoteRef" href="#fn6" id="fnref6"><sup>6</sup></a></p>
<h2 id="reference-classes">Reference classes</h2>
<p>One of the major areas of Doomsday Argument debate is the <a href="reference_class_problem" title="wikilink">reference class</a> from which <em>n</em> is drawn, and of which <em>N</em> is the ultimate size. The 'standard' Doomsday Argument <a class="uri" href="hypothesis" title="wikilink">hypothesis</a> doesn't spend very much time on this point, and simply says that the reference class is the number of 'humans'. Given that you are human, the Copernican principle could be applied to ask if you were born unusually early, but the grouping of 'human' has been widely challenged on <a href="Anthropology" title="wikilink">practical</a> and <a href="Philosophy" title="wikilink">philosophical</a> grounds. <a href="Nick_Bostrom" title="wikilink">Nick Bostrom</a> has argued that <a class="uri" href="consciousness" title="wikilink">consciousness</a> is (part of) the discriminator between what is in and what is out of the reference class, and that <a href="extraterrestrial_intelligence" title="wikilink">extraterrestrial intelligences</a> might affect the calculation dramatically.</p>
<p>The following sub-sections relate to different suggested reference classes, each of which has had the standard Doomsday Argument applied to it.</p>
<h3 id="sampling-only-wmd-era-humans">Sampling only WMD-era humans</h3>
<p>The <a href="Doomsday_clock" title="wikilink">Doomsday clock</a> shows the expected time to nuclear <a href="Doomsday_event" title="wikilink">doomsday</a> by the judgment of an <a href="Bulletin_of_the_Atomic_Scientists" title="wikilink">expert board</a>, rather than a Bayesian model. If the twelve hours of the clock symbolize the lifespan of the human species, its current time of 11:54 implies that we are among the last 1% of people who will ever be born (i.e., that <em>n</em> > 0.99<em>N</em>). <a href="J._Richard_Gott" title="wikilink">J. Richard Gott</a>'s temporal version of the Doomsday argument (DA) would require very strong prior evidence to overcome the improbability of being born in such a <a href="Copernican_principle" title="wikilink">special</a> time.</p>
<dl>
<dd>If the clock's doomsday estimate is correct, there is less than 1 chance in 100 of seeing it show such a late time in human history, if observed at a random time within that history.
</dd>
</dl>
<p>The <a href="Bulletin_of_the_Atomic_Scientists" title="wikilink">scientists'</a> warning can be reconciled with the DA, however: The Doomsday clock specifically estimates the proximity of <a href="Nuclear_weapon" title="wikilink">atomic</a> self-destruction—which has only been possible for sixty years.<a class="footnoteRef" href="#fn7" id="fnref7"><sup>7</sup></a> If doomsday requires nuclear weaponry then the Doomsday Argument 'reference class' is: people contemporaneous with nuclear weapons. In this model, the number of people living through, or born after <a href="Atomic_bombings_of_Hiroshima_and_Nagasaki" title="wikilink">Hiroshima</a> is <em>n</em>, and the number of people who ever will is <em>N</em>. Applying <a href="J._Richard_Gott" title="wikilink">Gott's</a> DA to these variable definitions gives a 50% chance of doomsday within 50 years.</p>
<dl>
<dd>In this model, the clock's hands are so close to midnight because a <a href="conditional_probability" title="wikilink">condition</a> of doomsday is living post-1945, a condition which applies now but not to the earlier 11 hours and 53 minutes of the clock's metaphorical human 'day'.
</dd>
</dl>
<p>If your life is randomly selected from all lives lived under the shadow of the bomb, this simple model gives a 95% chance of doomsday within 1000 years.</p>
<p>The scientists' recent use of moving the clock forward to warn of the dangers posed by <a href="global_warming" title="wikilink">global warming</a> muddles this reasoning, however.</p>
<h3 id="sssa-sampling-from-observer-moments">SSSA: Sampling from observer-moments</h3>
<p><a href="Nick_Bostrom" title="wikilink">Nick Bostrom</a>, <a href="Anthropic_principle#Anthropic_bias_and_anthropic_reasoning" title="wikilink">considering observation selection effects</a>, has produced a <a href="Self-Sampling_Assumption" title="wikilink">Self-Sampling Assumption</a> (SSA): "<em>that you should think of yourself as if you were a random observer from a suitable reference class</em>". If the 'reference class' is the set of humans to ever be born, this gives <em>N</em> 12 to 10<sup>13</sup>, for example, then the probability of <em>N</em> N = \frac{e^{U(0, q]}}{c}</p>
<p>Here, <em>c</em> and'' q'' are constants. If <em>q</em> is large, then our 95% confidence upper bound is on the uniform draw, not the exponential value of <em>N</em>.</p>
<p>The best way to compare this with Gott's Bayesian argument is to flatten the distribution from the vague prior by having the probability fall off more slowly with <em>N</em> (than inverse proportionally). This corresponds to the idea that humanity's growth may be exponential in time with doomsday having a vague prior <a href="probability_density_function" title="wikilink">pdf</a> in <em>time</em>. This would mean than <em>N</em>, the last birth, would have a distribution looking like the following:</p>
<p><span class="LaTeX">$$\Pr(N) = \frac{k}{N^\alpha}, 0 < \alpha < 1.$$</span></p>
<p>This prior <em>N</em> distribution is all that is required (with the principle of indifference) to produce the inference of <em>N</em> from <em>n</em>, and this is done in an identical way to the standard case, as described by Gott (equivalent to <span class="LaTeX">$\alpha$</span> = 1 in this distribution):</p>
<p><span class="LaTeX">$$\Pr(n) = \int_{N=n}^{N=\infty} \Pr(n\mid N) \Pr(N) \,dN = \int_{n}^{\infty} \frac{k}{N^{(\alpha+1)}} \,dN = \frac{k}{{\alpha}n^{\alpha}}$$</span></p>
<p>Substituting into the posterior probability equation):</p>
<p><span class="LaTeX">$$\Pr(N\mid n) = \frac{{\alpha}n^{\alpha}}{N^{(1+\alpha)}}.$$</span></p>
<p>Integrating the probability of any <em>N</em> above <em>xn</em>:</p>
<p><span class="LaTeX">$$\Pr(N > xn) = \int_{N=xn}^{N=\infty} \Pr(N\mid n)\,dN = \frac{1}{x^{\alpha}}.$$</span></p>
<p>For example, if <em>x</em> = 20, and <span class="LaTeX">$\alpha$</span> = 0.5, this becomes:</p>
<p><span class="LaTeX">$$\Pr(N > 20n) = \frac{1}{\sqrt{20}} \simeq 22.3\%.$$</span></p>
<p>Therefore, with this prior, the chance of a trillion births is well over 20%, rather than the 5% chance given by the standard DA. If <span class="LaTeX">$\alpha$</span> is reduced further by assuming a flatter prior <em>N</em> distribution, then the limits on'' N'' given by <em>n</em> become weaker. An <span class="LaTeX">$\alpha$</span> of one reproduces Gott's calculation with a birth reference class, and <span class="LaTeX">$\alpha$</span> around 0.5 could approximate his temporal confidence interval calculation (if the population were expanding exponentially). As <span class="LaTeX">$\alpha \to 0$</span> (gets smaller) <em>n</em> becomes less and less <a href="uninformative_prior" title="wikilink">informative</a> about <em>N</em>. In the limit this distribution approaches an (unbounded) <a href="uniform_distribution_(continuous)" title="wikilink">uniform distribution</a>, where all values of <em>N</em> are equally likely. This is Page et al.'s<em>' "Assumption 3"</em>', which they find few reasons to reject, <em>a priori</em>. (Although all distributions with <span class="LaTeX">$\alpha \leq 1$</span> are improper priors, this applies to Gott's vague-prior distribution also, and they can all be converted to produce <a href="improper_integral" title="wikilink">proper integrals</a> by postulating a finite upper population limit.) Since the probability of reaching a population of size 2<em>N</em> is usually thought of as the chance of reaching <em>N</em> multiplied by the survival probability from <em>N</em> to 2<em>N</em> it seems that Pr(<em>N</em>) must be a <a href="monotonic_function" title="wikilink">monotonically</a> decreasing function of <em>N</em>, but this doesn't necessarily require an inverse proportionality.</p>
<p>A prior distribution with a very low <span class="LaTeX">$\alpha$</span> <a class="uri" href="parameter" title="wikilink">parameter</a> makes the DA's ability to constrain the ultimate size of humanity very weak.</p>
<h3 id="infinite-expectation">Infinite Expectation</h3>
<p>Another objection to the Doomsday Argument is that the <a href="Expected_value" title="wikilink">expected</a> total human population is actually <a href="Infinity" title="wikilink">infinite</a>. The calculation is as follows:</p>
<dl>
<dd>The total human population <var>N</var> = <var>n</var>/<var>f</var>, where <var>n</var> is the human population to date and <var>f</var> is our fractional position in the total.
</dd>
<dd>We assume that <var>f</var> is uniformly distributed on (0,1].
</dd>
<dd>The expectation of <var>N</var> is <span class="LaTeX">$E(N) = \int_{0}^{1} {n \over f} \, df = n \ln (1) - n \ln (0) = + \infty .$</span>
</dd>
</dl>
<p>For a similar example of counterintuitive infinite expectations, see the <a href="St._Petersburg_paradox" title="wikilink">St. Petersburg paradox</a>.</p>
<h3 id="self-indication-assumption-the-possibility-of-not-existing-at-all">Self-Indication Assumption: The possibility of not existing at all</h3>
<p>One objection is that the possibility of your existing at all depends on how many humans will ever exist (<em>N</em>). If this is a high number, then the possibility of your existing is higher than if only a few humans will ever exist. Since you do indeed exist, this is evidence that the number of humans that will ever exist is high.</p>
<p>This objection, originally by <a href="Dennis_Dieks" title="wikilink">Dennis Dieks</a> (1992), is now known by <a href="Nick_Bostrom" title="wikilink">Nick Bostrom</a>'s name for it: the "<a href="Self-Indication_Assumption" title="wikilink">Self-Indication Assumption</a> objection". It can be shown that some <a href="Self-Indication_Assumption" title="wikilink">SIAs</a> prevent any inference of <em>N</em> from <em>n</em> (the current population).</p>
<h3 id="caves-rebuttal">Caves' rebuttal</h3>
<p>The <a href="Bayesian_inference" title="wikilink">Bayesian</a> argument by <a href="Carlton_M._Caves" title="wikilink">Carlton M. Caves</a> says that the uniform distribution assumption is incompatible with the <a href="Copernican_principle" title="wikilink">Copernican principle</a>, not a consequence of it.</p>
<p>He gives a number of examples to argue that Gott's rule is implausible. For instance, he says, imagine stumbling into a birthday party, about which you know nothing:</p>
<blockquote>
<p>Your friendly enquiry about the age of the celebrant elicits the reply that she is celebrating her (<em>t</em><sub><em>p</em></sub> = ) 50th birthday. According to Gott, you can predict with 95% confidence that the woman will survive between [50]/39 = 1.28 years and 39[×50] = 1,950 years into the future. Since the wide range encompasses reasonable expectations regarding the woman's survival, it might not seem so bad, till one realizes that [Gott's rule] predicts that with probability 1/2 the woman will survive beyond 100 years old and with probability 1/3 beyond 150. Few of us would want to bet on the woman's survival using Gott's rule. <em>(See Caves' online paper <a href="Doomsday_argument#External_links" title="wikilink">below</a>.)</em></p>
</blockquote>
<p>Although this example exposes a weakness in <a href="J._Richard_Gott" title="wikilink">J. Richard Gott</a>'s "Copernicus method" DA (that he does not specify when the "Copernicus method" can be applied) it is not precisely analogous with the <a href="Doomsday_argument#Numerical_estimates_of_the_Doomsday_argument" title="wikilink">modern DA</a>; <a href="Epistemology" title="wikilink">epistemological</a> refinements of Gott's argument by <a href="philosopher" title="wikilink">philosophers</a> such as <a href="Nick_Bostrom" title="wikilink">Nick Bostrom</a> specify that:</p>
<dl>
<dd>Knowing the absolute birth rank (<em>n</em>) must give no information on the total population (<em>N</em>).
</dd>
</dl>
<p>Careful DA variants specified with this rule aren't shown implausible by Caves' "Old Lady" example above, because, the woman's age is given prior to the estimate of her lifespan. Since human age gives an estimate of survival time (via <a href="actuary" title="wikilink">actuarial</a> tables) Caves' Birthday party age-estimate could not fall into the class of DA problems defined with this proviso.</p>
<p>To produce a comparable "Birthday party example" of the carefully specified Bayesian DA we would need to completely exclude all prior knowledge of likely human life spans; in principle this could be done (e.g.: hypothetical <a href="Amnesia_chamber" title="wikilink">Amnesia chamber</a>). However, this would remove the modified example from everyday experience. To keep it in the everyday realm the lady's age must be <em>hidden</em> prior to the survival estimate being made. (Although this is no longer exactly the DA, it is much more comparable to it.)</p>
<p>Without knowing the lady’s age, the DA reasoning produces a <em>rule</em> to convert the birthday (<em>n</em>) into a maximum lifespan with 50% confidence (<em>N</em>). Gott's <a href="Copernicus_principle" title="wikilink">Copernicus method</a> rule is simply: Prob (<em>N</em> ] draw where <em>M</em> is the maximum lifespan in the census. In this 'flat' model, everyone shares the same lifespan so <em>N</em> = <em>M</em>. If <em>n</em> happens to be less than (<em>M</em>)/2 then Gott's 2<em>n</em> estimate of <em>N</em> will be under <em>M</em>, its true figure. The other half of the time 2<em>n</em> underestimates <em>M</em>, and in this case (the one Caves highlights in his example) the subject will die before the 2<em>n</em> estimate is reached. In this 'flat demographics' model Gott's 50% confidence figure is proven right 50% of the time.</p>
<h3 id="self-referencing-doomsday-argument-rebuttal">Self-referencing doomsday argument rebuttal</h3>
<p>Some philosophers have been bold enough to suggest that only people who have contemplated the Doomsday argument (DA) belong in the reference class '<a class="uri" href="human" title="wikilink">human</a>'. If that is the appropriate reference class, <a href="Brandon_Carter" title="wikilink">Carter</a> defied his own prediction when he first described the argument (to the <a href="Royal_Society" title="wikilink">Royal Society</a>). A member present could have argued thus:</p>
<blockquote>
<p>Presently, only one person in the world understands the Doomsday argument, so by its own logic there is a 95% chance that it is a minor problem which will only ever interest twenty people, and I should ignore it.</p>
</blockquote>
<p><a href="Jeff_Dewynne" title="wikilink">Jeff Dewynne</a> and Professor <a href="Peter_Landsberg" title="wikilink">Peter Landsberg</a> suggested that this line of reasoning will create a <a class="uri" href="paradox" title="wikilink">paradox</a> for the Doomsday argument:</p>
<p>If a member did pass such a comment, it would indicate that they understood the DA sufficiently well that in fact 2 people could be considered to understand it, and thus there would a 5% chance that 40 or more people would actually be interested. Also, of course, ignoring something because you only expect a small number of people to be interested in it is extremely short sighted—if this approach were to be taken, nothing new would ever be explored, if we assume no <em>a priori</em> knowledge of the nature of interest and attentional mechanisms.</p>
<p>Additionally, it should be considered that because <a href="Brandon_Carter" title="wikilink">Carter</a> did present and describe his argument, in which case the people to whom he explained it did contemplate the DA, as it was inevitable, the conclusion could then be drawn that in the moment of explanation <a href="Brandon_Carter" title="wikilink">Carter</a> created the basis for his own prediction.</p>
<h3 id="conflation-of-future-duration-with-total-duration">Conflation of future duration with total duration</h3>
<p>Various authors have argued that the doomsday argument rests on an incorrect conflation of future duration with total duration. This occurs in the specification of the two time periods as "doom soon" and "doom deferred" which means that both periods are selected to occur <em>after</em> the observed value of the birth order. A rebuttal in Pisaturo (2009)<a class="footnoteRef" href="#fn8" id="fnref8"><sup>8</sup></a> argues that the Doomsday Argument relies on the equivalent of this equation:</p>
<p><span class="LaTeX">$$P(H_{TS}|D_pX)/P(H_{TL}|D_pX) = [P(H_{FS}|X)/P(H_{FL}|X)] \cdot [P(D_p|H_{TS}X)/P(D_p|H_{TL}X)]$$</span>,</p>
<dl>
<dd>where:
</dd>
<dd><em>X</em> = the prior information;
</dd>
<dd><em>D<sub>p</sub></em> = the data that past duration is <em>t<sub>p</sub></em>;
</dd>
<dd><em>H<sub>FS</sub></em> = the hypothesis that the future duration of the phenomenon will be short;
</dd>
<dd><em>H<sub>FL</sub></em> = the hypothesis that the future duration of the phenomenon will be long;
</dd>
<dd><em>H<sub>TS</sub></em> = the hypothesis that the <em>total</em> duration of the phenomenon will be short—i.e., that <em>t<sub>t</sub></em>, the phenomenon’s <em>total</em> longevity, = <em>t<sub>TS</sub></em>;
</dd>
<dd><em>H<sub>TL</sub></em> = the hypothesis that the <em>total</em> duration of the phenomenon will be long—i.e., that <em>t<sub>t</sub></em>, the phenomenon’s <em>total</em> longevity, = <em>t<sub>TL</sub></em>, with <em>t<sub>TL</sub></em> > <em>t<sub>TS</sub></em>.
</dd>
</dl>
<p>Pisaturo then observes:</p>
<dl>
<dd>Clearly, this is an invalid application of Bayes’ theorem, as it conflates future duration and total duration.
</dd>
</dl>
<p>Pisaturo takes numerical examples based on two possible corrections to this equation: considering only future durations, and considering only total durations. In both cases, he concludes that the Doomsday Argument’s claim, that there is a ‘Bayesian shift’ in favor of the shorter future duration, is fallacious.</p>
<p>This argument is also echoed in O'Neill (2014).<a class="footnoteRef" href="#fn9" id="fnref9"><sup>9</sup></a> In this work the author argues that a unidirectional "Bayesian Shift" is an impossibility within the standard formulation of probability theory and is contradictory to the rules of probability. As with Pisaturo, he argues that the doomsday argument conflates future duration with total duration by specification of doom times that occur after the observed birth order. According to O'Neill:</p>
<dl>
<dd>The reason for the hostility to the doomsday argument and its assertion of a "Bayesian shift" is that many people who are familiar with probability theory are implicitly aware of the absurdity of the claim that one can have an automatic unidirectional shift in beliefs regardless of the actual outcome that is observed. This is an example of the "reasoning to a foregone conclusion" that arises in certain kinds of failures of an underlying inferential mechanism. An examination of the inference problem used in the argument shows that this suspicion is indeed correct and the doomsday argument is invalid. (pp. 216-217)
</dd>
</dl>
<h2 id="mathematics-free-explanation-by-analogy">Mathematics-free explanation by analogy</h2>
<p>Assume the human species is a car driver. The driver has encountered some bumps but no catastrophes, and the car (<a class="uri" href="Earth" title="wikilink">Earth</a>) is still road-worthy. However, insurance is required. The cosmic insurer has not dealt with humanity before, and needs some basis on which to calculate the premium. According to the Doomsday Argument, the insurer merely need ask how long the car and driver have been on the road—currently at least 40,000 years without an "accident"—and use the response to calculate insurance based on a 50% chance that a fatal "accident" will occur inside that time period.</p>
<p>Consider a hypothetical insurance company that tries to attract drivers with long accident-free histories not because they necessarily drive more safely than newly qualified drivers, but for statistical reasons: the hypothetical insurer estimates that each driver looks for insurance quotes every year, so that the time since the last <a class="uri" href="accident" title="wikilink">accident</a> is an evenly distributed random sample between accidents. The chance of being more than halfway through an evenly distributed random sample is one-half, and (ignoring old-age effects) if the driver is more than half way between accidents then he is closer to his next accident than his previous one. A driver who was accident-free for 10 years would be quoted a very low premium for this reason, but someone should not expect cheap insurance if he only passed his test two hours ago (equivalent to the accident-free record of the human species in relation to 40,000 years of <a href="geological_time" title="wikilink">geological time</a>.)</p>
<h3 id="analogy-to-the-estimated-final-score-of-a-cricket-batsman">Analogy to the estimated final score of a cricket batsman</h3>
<p>A random in-progress <a class="uri" href="cricket" title="wikilink">cricket</a> <a href="Test_cricket" title="wikilink">test match</a> is sampled for a single piece of information: the current <a class="uri" href="batsman" title="wikilink">batsman</a>'s run tally so far. If the batsman is dismissed (rather than declaring they have enough runs and stopping), what is the chance that he will end up with a score more than double his current total?</p>
<dl>
<dd>A <em>rough</em> <a class="uri" href="empirical" title="wikilink">empirical</a> result is that the chance is half (on average).
</dd>
</dl>
<p>The <strong>Doomsday argument</strong> (DA) is that even if we were completely ignorant of the game we could make the same prediction, or profit by offering a bet paying <a class="uri" href="odds" title="wikilink">odds</a> of 2-to-3 on the batsmen doubling his current score.</p>
<p>Importantly, we can only offer the bet before the current score is given (this is necessary because the absolute value of the current score would give a cricket expert a lot of information about the chance of that tally doubling). It is necessary to be ignorant of the absolute run tally before making the prediction because this is linked to the likely total, but if the likely total and absolute value are <em>not</em> linked, the survival prediction can be made <em>after</em> discovering the batter's current score. Analogously, the DA says that <em>if the absolute number of humans born gives no information on the number that will be</em>, we can predict the species’ total number of births after discovering that 60 billion people have ever been born: with 50% confidence it is 120 billion people, so that there is better-chance-than-not that <strong>the last human birth will occur before the 23rd century</strong>.</p>
<p>It is <em>not</em> true that the chance is half, <em>whatever</em> the number of runs currently scored; <a href="batting_(baseball)" title="wikilink">batting</a> records give an empirical <a class="uri" href="correlation" title="wikilink">correlation</a> between reaching a given score (50 say) and reaching any other, higher score (say 100). On the average, the chance of doubling the current tally may be half, but the chance of reaching 100 having scored 50 is much lower than reaching ten from five. Thus, the <em>absolute</em> value of the score gives information about the likely final total the batsman will reach, beyond the "scale invariant".<a class="footnoteRef" href="#fn10" id="fnref10"><sup>10</sup></a></p>
<p>An analogous Bayesian critique of the DA is that it somehow possessed <a href="Prior_probability" title="wikilink">prior</a> knowledge of the all-time human population distribution (total runs scored), and that this is more significant than the finding of a low number of births until now (a low current run count).</p>
<p>There are two alternative methods of making <a class="uri" href="uniform" title="wikilink">uniform</a> draws from the current score (<em>n</em>):</p>
<ol>
<li>Put the runs actually scored by dismissed player in order, say 200, and randomly choose between these scoring increments by U(0, 200].</li>
<li>Select a <em>time</em> randomly from the beginning of the match to the final dismissal.</li>
</ol>
<p>The second sampling-scheme will include those lengthy periods of a game where a dismissed player is replaced, during which the ‘current batsman’ is preparing to take the field and has no runs. If people sample based on time-of-day rather than running-score they will often find that a new batsman has a score of zero <em>when the total score that day was low</em>, but humans will rarely sample a zero if one batsman continued piling on runs all day long. Therefore, sampling a non-zero score would tell us something about the likely final score the current batsman will achieve.</p>
<p>Choosing sampling method 2 rather than method 1 would give a different statistical link between current and final score: any non-zero score would imply that the batsman reached a high final total, especially if the time to replace batsman is <em>very</em> long. This is analogous to the <a href="Self-Indication_Assumption" title="wikilink">SIA</a>-DA-refutation that <em>N</em>'s distribution should include <em>N</em> = 0 states, which leads to the DA having reduced <a href="predictive_power" title="wikilink">predictive power</a> (in the extreme, no power to predict <em>N</em> from <em>n</em> at all).</p>
<h3 id="the-doomsday-argument-as-a-tricky-problem">The Doomsday Argument as a tricky problem</h3>
<p>Sometimes, the Doomsday Argument is presented as a probability problem using Bayes’ formula.<a class="footnoteRef" href="#fn11" id="fnref11"><sup>11</sup></a></p>
<p><strong>Hypotheses</strong></p>
<p>Two hypotheses are in competition:</p>
<ol>
<li>The theory A says that humanity will disappear in 2150,</li>
<li>and the theory B says that it will be much later.</li>
</ol>
<p>Under assumption A, a tenth of humanity was alive in the year 2000, and humanity has included 50 billion individuals.</p>
<p>Under assumption B, one thousandth of humanity was alive in the year 2000, and humanity has included 5 trillion individuals.</p>
<p>The first theory seems less likely, and its <em>a priori</em> probability is set at 1%, while the probability of the second is logically set to 99%.</p>
<p>Now consider an event E, for example: "a person is part of the 5 billion people alive in the year 2000". One may ask "What is the most likely hypothesis, if you take into account this event?" and apply Bayes' formula:</p>
<p><span class="LaTeX">$$\mathbb{P}(A\mid E) = \frac{\mathbb{P}(E\mid A)\cdot \mathbb{P}(A)}{\mathbb{P}(E)}$$</span> According to the above figures:</p>
<p><span class="LaTeX">$$\mathbb{P}(E\mid A) = 10\%\ , \ \mathbb{P}(E\mid B) = 0.10\%$$</span> Now with :</p>
<p><span class="LaTeX">$$\mathbb{P}(A) = \frac {1}{100}\ , \ \mathbb{P}(B) = \frac {99}{100}$$</span> We get :</p>
<p><span class="LaTeX">$$\mathbb{P}(E) = \mathbb{P}(E \cap A) + \mathbb{P}(E\cap B) = \mathbb{P}(E\mid A)\cdot\mathbb{P}(A) + \mathbb{P}(E\mid B)\cdot \mathbb{P}(B)=\frac{19.9}{10 000}$$</span></p>
<p>Finally the probabilities have changed dramatically:</p>
<p><span class="LaTeX">$$\mathbb{P}(A\mid E) = \frac{10}{19.2}=50.25\%$$</span></p>
<p><span class="LaTeX">$$\mathbb{P}(B\mid E) = \frac{9.9}{19.2}=49.75\%$$</span></p>
<p>Because an individual was chosen randomly, the probability of the end of the world has significantly increased.</p>
<p><strong>Attempted Refutations</strong></p>
<p>A potential refutation was provided in July 2003:<a class="footnoteRef" href="#fn12" id="fnref12"><sup>12</sup></a> Jean-Paul Delahaye showed that Bayes' formula introduces "probabilistic anamorphosis", and demonstrated that Bayes' formula is prone to misleading errors made in good faith by its users. In 2011,<a class="footnoteRef" href="#fn13" id="fnref13"><sup>13</sup></a> Philippe Gay showed that many similar problems can lead to these mistakes: each change of a weighted average by a simple one leads to odd results.</p>
<p>In 2010,<a class="footnoteRef" href="#fn14" id="fnref14"><sup>14</sup></a> Philippe Gay and Édouard Thomas described a slightly different understanding: the formula must take into account the number of humans involved in each case. Whatever the explanation, both show the same algebra:</p>
<p><span class="LaTeX">$$\mathbb{P}(B\mid E) = \frac{0.1\% \times 5 \cdot 10^{12} \times 99\%}{0.1%\times 5\cdot 10^{12} \times 99\% +10\% \times 50\cdot 10^{9} \times 1\%} = \frac{99\%}{99\% + 1\%} =99\%=\mathbb{P}(B)$$</span></p>
<p>Using a similar method, we get:</p>
<p><span class="LaTeX">$$\mathbb{P}(A\mid E) = \frac{1\%}{99\% + 1\%} = 1\%=\mathbb{P}(A)$$</span></p>
<h2 id="see-also">See also</h2>
<ul>
<li><a href="Doomsday_event" title="wikilink">Doomsday events</a></li>
<li><a href="Fermi_paradox" title="wikilink">Fermi paradox</a></li>
<li><a href="Final_anthropic_principle" title="wikilink">Final anthropic principle</a></li>
<li><a href="List_of_disasters#Causes_of_hypothetical_future_disasters" title="wikilink">Hypothetical disasters</a></li>
<li><a href="Mediocrity_principle" title="wikilink">Mediocrity principle</a></li>
<li><a href="Quantum_immortality" title="wikilink">Quantum immortality</a></li>
<li><a href="Simulated_reality" title="wikilink">Simulated reality</a></li>
<li><a href="Sic_transit_gloria_mundi" title="wikilink">Sic transit gloria mundi</a></li>
<li><a href="Survival_analysis" title="wikilink">Survival analysis</a></li>
<li><a class="uri" href="Survivalism" title="wikilink">Survivalism</a></li>
<li><a href="Technological_singularity" title="wikilink">Technological singularity</a></li>
</ul>
<h2 id="notes">Notes</h2>
<h2 id="references">References</h2>
<ul>
<li>John Leslie, <em>The End of the World: The Science and Ethics of Human Extinction</em>, Routledge, 1998, ISBN 0-415-18447-9.</li>
<li>J. R. Gott III, <em>Future Prospects Discussed</em>, Nature, vol. 368, p. 108, 1994.</li>
<li>This argument plays a central role in <a href="Stephen_Baxter" title="wikilink">Stephen Baxter</a>'s science fiction book, <em><a href="Manifold:_Time" title="wikilink">Manifold: Time</a></em>, Del Rey Books, 2000, ISBN 0-345-43076-X.</li>
</ul>
<ul>
<li>The same principle plays a major role in the <a href="Dan_Brown" title="wikilink">Dan Brown</a> novel, <a href="Inferno_(Dan_Brown_novel)" title="wikilink">Inferno</a>, Corgy Books, ISBN 978-0-552-16959-2</li>
</ul>
<h2 id="external-links">External links</h2>
<ul>
<li><a href="http://philpapers.org/browse/doomsday-argument">The Doomsday argument category on PhilPapers</a></li>
<li><a href="http://flatrock.org.nz/topics/environment/doom_soon.htm">A non-mathematical, unpartisan introduction to the DA</a></li>
<li><a href="http://www.anthropic-principle.com/preprints/ali/alive.html">Nick Bostrom's response to Korb and Oliver</a></li>
<li><a href="http://www.anthropic-principle.com/preprints.html#doomsday">Nick Bostrom's annotated collection of references</a></li>
<li><a href="http://arxiv.org/abs/gr-qc/9407002">Kopf, Krtouš & Page's early (1994) refutation</a> based on the <a href="Self-Indication_Assumption" title="wikilink">SIA</a>, which they called "Assumption 2".</li>
<li><a href="http://xxx.lanl.gov/abs/gr-qc/0009081">The Doomsday argument and the number of possible observers by Ken Olum</a> In 1993 <a href="J._Richard_Gott" title="wikilink">J. Richard Gott</a> used his "Copernicus method" to predict the lifetime of Broadway shows. One part of this paper uses the same reference class as an empirical counter-example to Gott's method.</li>
<li><a href="http://hanson.gmu.edu/nodoom.html">A Critique of the Doomsday Argument by Robin Hanson</a></li>
<li><a href="http://cogprints.org/7044/">A Third Route to the Doomsday Argument by Paul Franceschi</a>, <em>Journal of Philosophical Research</em>, 2009, vol. 34, pp. 263–278</li>
<li>[<a class="uri" href="http://journals.cambridge.org/action/displayAbstract?fromPage=online&aid">http://journals.cambridge.org/action/displayAbstract?fromPage=online&aid</a>;=82931 Chambers' Ussherian Corollary Objection]</li>
<li><a href="http://info.phys.unm.edu/papers/2000/Caves2000a.pdf">Caves' Bayesian critique of Gott's argument. C. M. Caves, "Predicting future duration from present age: A critical assessment", Contemporary Physics 41, 143-153 (2000).</a></li>
<li><a href="http://arxiv.org/abs/0806.3538v1">C.M. Caves, "Predicting future duration from present age: Revisiting a critical assessment of Gott's rule.</a></li>
<li>[<a class="uri" href="http://journals.cambridge.org/action/displayAbstract?fromPage=online&aid">http://journals.cambridge.org/action/displayAbstract?fromPage=online&aid</a>;=2400044 "Infinitely Long Afterlives and the Doomsday Argument" by John Leslie] shows that Leslie has recently modified his analysis and conclusion (Philosophy 83 (4) 2008 pp. 519–524): Abstract—A recent book of mine defends three distinct varieties of immortality. One of them is an infinitely lengthy afterlife; however, any hopes of it might seem destroyed by something like Brandon Carter's ‘doomsday argument’ against viewing ourselves as extremely early humans. The apparent difficulty might be overcome in two ways. First, if the world is non-deterministic then anything on the lines of the doomsday argument may prove unable to deliver a strongly pessimistic conclusion. Secondly, anything on those lines may break down when an infinite sequence of experiences is in question.</li>
<li><a href="http://www.lrb.co.uk/v21/n13/gree04_.html">Mark Greenberg, "Apocalypse Not Just Now" in London Review of Books</a></li>
<li><a href="http://pthbb.org/manual/services/grim/laster.html">Laster</a>: A simple webpage applet giving the min & max survival times of anything with 50% and 95% confidence requiring only that you input how old it is. It is designed to use the same mathematics as <a href="J._Richard_Gott" title="wikilink">J. Richard Gott</a>'s form of the DA, and was programmed by <a href="sustainable_development" title="wikilink">sustainable development</a> researcher Jerrad Pierce.</li>
</ul>
<p>"</p>
<p><a class="uri" href="Category:Eschatology" title="wikilink">Category:Eschatology</a> <a href="Category:Probabilistic_arguments" title="wikilink">Category:Probabilistic arguments</a> <a href="Category:Sociocultural_evolution" title="wikilink">Category:Sociocultural evolution</a> <a href="Category:Fermi_paradox" title="wikilink">Category:Fermi paradox</a> <a href="Category:1983_introductions" title="wikilink">Category:1983 introductions</a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1"><a href="#fnref1">↩</a></li>
<li id="fn2"><a href="#fnref2">↩</a></li>
<li id="fn3"><a href="#fnref3">↩</a></li>
<li id="fn4"><a href="http://www.amstat.org/meetings/jsm/2014/onlineprogram/AbstractDetails.cfm?abstractid=313738">Predicting Future Lifespan: The Lindy Effect, Gott's Predictions and Caves' Corrections, and Confidence Intervals</a>, Colman Humphrey<a href="#fnref4">↩</a></li>
<li id="fn5">Doomsday argument two-case section is partially based on "<a href="http://dx.doi.org/10.1093/mind/107.426.403">A Refutation of the Doomsday Argument</a>" by Korb and Oliver.<a href="#fnref5">↩</a></li>
<li id="fn6">See, for example, [<a class="uri" href="http://urss.ru/cgi-bin/db.pl?cp">http://urss.ru/cgi-bin/db.pl?cp</a>=&page;=Book&id;=34250〈=en&blang;=en&list;=38 <em>Introduction to Social Macrodynamics</em>] by <a href="Andrey_Korotayev" title="wikilink">Andrey Korotayev</a> <em>et al.</em><a href="#fnref6">↩</a></li>
<li id="fn7">The clock first appeared in 1949, and the date on which humanity gained the power to destroy itself is debatable, but to simplify the argument the numbers here are based on an assumption of fifty years.<a href="#fnref7">↩</a></li>
<li id="fn8"><a href="#fnref8">↩</a></li>
<li id="fn9"><a href="#fnref9">↩</a></li>
<li id="fn10">The cricketing rationale for the lengthening of future survival time with current score is that batting is a test of skill that a high-scoring batsman has passed. Therefore, higher scores are correlated with better players who will then be more likely to continue scoring heavily. Historic batting records give a <a href="Prior_probability" title="wikilink">prior</a> distribution that provides other useful data. In particular, we know the <a class="uri" href="mean" title="wikilink">mean</a> score across all players and matches. High and low <a href="Posterior_probability" title="wikilink">posterior</a> information (the current score) only gives a weak indication of the player's skill, which is more strongly described by this <em>prior</em> mean. (This statistical phenomenon of <a href="Prior_probability#Informative_priors" title="wikilink">informative</a> averages is called <a href="Regression_toward_the_mean" title="wikilink">Regression toward the mean</a>.)<a href="#fnref10">↩</a></li>
<li id="fn11"><em>"Logique, informatique et paradoxes"</em> <a href="Jean-Paul_Delahaye" title="wikilink">Jean-Paul Delahaye</a>, Belin, pages 30-32<a href="#fnref11">↩</a></li>
<li id="fn12"><em>"La Belle au bois dormant, la fin du monde et les extraterrestres"</em>, Jean-Paul Delahaye, Belin, Pour la science, juillet 2003, pages 30-32, <a href="#fnref12">↩</a></li>
<li id="fn13"><em>"L’Argument de l’Apocalypse… selon la Répression des Fraudes|collection"</em> Philippe Gay, Image des mathématiques (CNRS),août 2011, <a class="uri" href="http://images.math.cnrs.fr/L-Argument-de-l-Apocalypse-selon.html">http://images.math.cnrs.fr/L-Argument-de-l-Apocalypse-selon.html</a><a href="#fnref13">↩</a></li>
<li id="fn14"><em>"Détournements de Bayes"</em> Philippe Gay and Édouard Thomas, Tangente, septembre-octobre 2010, n°136<a href="#fnref14">↩</a></li>
</ol>
</section>
</body>
</html>
