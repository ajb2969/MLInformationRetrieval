   Gain (information retrieval)      Gain (information retrieval)   In information retrieval , the gain or improvement over random of a classifier is a set of measures of the classifier's performance. Gain is calculated between a random classifier on a given metric (such as precision or accuracy) versus the same metric on the classifier being measured.  Definition  In the following a random classifier is defined such that it randomly predicts the same amount of either class.  The gain is defined as described in the following:  Gain in Precision  The random precision of a classifier is defined as      r  =     T  P   +   F  N      T  P   +   T  N   +   F  P   +   F  N     =   ğ‘ƒğ‘œğ‘ ğ‘–ğ‘¡ğ‘–ğ‘£ğ‘’ğ‘   N         r        T  P     F  N        T  P     T  N     F  P     F  N            Positives  N      r=\frac{TP+FN}{TP+TN+FP+FN}=\frac{\textit{Positives}}{N}     where TP, TN, FP and FN are the numbers of true positives, true negatives, false positives and false negatives respectively, positives is the number of positive instances in the target dataset and N is the size of the dataset.  The random precision defines the lowest baseline of a classifier.  And Gain is defined as      G  =   ğ‘ğ‘Ÿğ‘’ğ‘ğ‘–ğ‘ ğ‘–ğ‘œğ‘›  r       G    precision  r     G=\frac{\textit{precision}}{r}     which gives a factor by which a classifier is better when compared to its random counterpart. A Gain of 1 would indicate a classifier that is not better than random. The larger the gain, the better.  Gain in Overall Accuracy  The accuracy of a classifier in general is defined as       A  c  c   =     T  P   +   T  N      T  P   +   T  N   +   F  P   +   F  N     =   ğ¶ğ‘œğ‘Ÿğ‘Ÿğ‘’ğ‘ğ‘¡ğ‘   N           A  c  c         T  P     T  N        T  P     T  N     F  P     F  N            Corrects  N      Acc=\frac{TP+TN}{TP+TN+FP+FN}=\frac{\textit{Corrects}}{N}     Here, the random accuracy of a classifier can be defined as      r  =     (   ğ‘ƒğ‘œğ‘ ğ‘–ğ‘¡ğ‘–ğ‘£ğ‘’ğ‘   N   )   2   +    (   ğ‘ğ‘’ğ‘”ğ‘ğ‘¡ğ‘–ğ‘£ğ‘’ğ‘   N   )   2    =    f    (  ğ‘ƒğ‘œğ‘ ğ‘–ğ‘¡ğ‘–ğ‘£ğ‘’ğ‘   )   2    +   f    (  ğ‘ğ‘’ğ‘”ğ‘ğ‘¡ğ‘–ğ‘£ğ‘’ğ‘   )   2           r     superscript    Positives  N   2    superscript    Negatives  N   2             f   superscript  Positives  2      f   superscript  Negatives  2        r=\left(\frac{\textit{Positives}}{N}\right)^{2}+\left(\frac{\textit{Negatives}%
 }{N}\right)^{2}=f(\textit{Positives})^{2}+f(\textit{Negatives})^{2}     f(Positives) and f(Negatives) is the fraction of positive and negative classes in the dataset.  And again gain is      G  =   ğ´ğ‘ğ‘  r       G    Acc  r     G=\frac{\textit{Acc}}{r}     This time the gain is measured not only with respect to the prediction of a so-called positive class, but with respect to the overall classifier ability to distinguish the two equally important classes.  Application  In Bioinformatics as an example, the gain is measured for methods that predict residue contacts in proteins.  See also   Accuracy and precision  Binary classification  Brier score  Confusion matrix  Detection theory  F-score  Information retrieval  Matthews correlation coefficient  Receiver operating characteristic or ROC curve  Selectivity  Sensitivity and specificity  Sensitivity index  Statistical significance  Youden's J statistic   "  Category:Logic  Category:Information retrieval evaluation   