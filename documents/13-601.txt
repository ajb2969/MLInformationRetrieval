   Symmetric tensor      Symmetric tensor   In mathematics , a symmetric tensor is a tensor that is invariant under a permutation of its vector arguments:       T   (   v  1   ,   v  2   ,  …  ,   v  r   )    =   T   (   v   σ  1    ,   v   σ  2    ,  …  ,   v   σ  r    )          T    subscript  v  1    subscript  v  2   normal-…   subscript  v  r       T    subscript  v    σ  1     subscript  v    σ  2    normal-…   subscript  v    σ  r        T(v_{1},v_{2},\dots,v_{r})=T(v_{\sigma 1},v_{\sigma 2},\dots,v_{\sigma r})   for every permutation σ of the symbols {1,2,..., r }. Alternatively, a symmetric tensor of order r represented in coordinates as a quantity with r indices satisfies        T    i  1    i  2   …   i  r     =   T    i   σ  1     i   σ  2    …   i   σ  r       .       subscript  T     subscript  i  1    subscript  i  2   normal-…   subscript  i  r      subscript  T     subscript  i    σ  1     subscript  i    σ  2    normal-…   subscript  i    σ  r        T_{i_{1}i_{2}\dots i_{r}}=T_{i_{\sigma 1}i_{\sigma 2}\dots i_{\sigma r}}.     The space of symmetric tensors of order r on a finite-dimensional vector space is naturally isomorphic to the dual of the space of homogeneous polynomials of degree r on V . Over fields of characteristic zero , the graded vector space of all symmetric tensors can be naturally identified with the symmetric algebra on V . A related concept is that of the antisymmetric tensor or alternating form . Symmetric tensors occur widely in engineering , physics and mathematics .  Definition  Let V be a vector space and      T  ∈   V    ⊗  k        T   superscript  V   tensor-product  absent  k      T\in V^{\otimes k}   a tensor of order k . Then T is a symmetric tensor if        τ  σ   T   =   T          subscript  τ  σ   T   T    \tau_{\sigma}T=T\,   for the braiding maps associated to every permutation σ on the symbols {1,2,..., k } (or equivalently for every transposition on these symbols).  Given a basis { e i } of V , any symmetric tensor T of rank k can be written as      T  =    ∑     i  1   ,  …  ,   i  k    =  1   N      T    i  1    i  2   …   i  k      e   i  1     ⊗   e   i  2    ⊗  ⋯  ⊗   e   i  k          T    superscript   subscript       subscript  i  1   normal-…   subscript  i  k    1    N    tensor-product     subscript  T     subscript  i  1    subscript  i  2   normal-…   subscript  i  k      superscript  e   subscript  i  1      superscript  e   subscript  i  2    normal-⋯   superscript  e   subscript  i  k        T=\sum_{i_{1},\dots,i_{k}=1}^{N}T_{i_{1}i_{2}\dots i_{k}}e^{i_{1}}\otimes e^{i%
 _{2}}\otimes\cdots\otimes e^{i_{k}}     for some unique list of coefficients    T    i  1    i  2   …   i  k       subscript  T     subscript  i  1    subscript  i  2   normal-…   subscript  i  k      T_{i_{1}i_{2}\dots i_{k}}   (the components of the tensor in the basis) that are symmetric on the indices. That is to say       T    i   σ  1     i   σ  2    …   i   σ  k      =   T    i  1    i  2   …   i  k          subscript  T     subscript  i    σ  1     subscript  i    σ  2    normal-…   subscript  i    σ  k       subscript  T     subscript  i  1    subscript  i  2   normal-…   subscript  i  k       T_{i_{\sigma 1}i_{\sigma 2}\dots i_{\sigma k}}=T_{i_{1}i_{2}\dots i_{k}}     for every permutation σ.  The space of all symmetric tensors of order k defined on V is often denoted by S k ( V ) or Sym k ( V ). It is itself a vector space, and if V has dimension N then the dimension of Sym k ( V ) is the binomial coefficient        dim    Sym  k    (  V  )     =   (       N  +  k   -  1       k     )    .       dimension    superscript  Sym  k   V     binomial      N  k   1   k     \dim\,\operatorname{Sym}^{k}(V)={N+k-1\choose k}.     We then construct Sym( V ) as the direct sum of Sym k ( V ) for k = 0,1,2,…        Sym   (  V  )    =    ⊕   k  =  0   ∞     Sym  k    (  V  )      .       Sym  V     superscript   subscript  direct-sum    k  0        superscript  Sym  k   V      \operatorname{Sym}(V)=\bigoplus_{k=0}^{\infty}\operatorname{Sym}^{k}(V).     Examples  There are many examples of symmetric tensors. Some include, the metric tensor ,    g   μ  ν      subscript  g    μ  ν     g_{\mu\nu}   , the Einstein tensor ,    G   μ  ν      subscript  G    μ  ν     G_{\mu\nu}   and the Ricci tensor ,    R   μ  ν      subscript  R    μ  ν     R_{\mu\nu}   .  Many material properties and fields used in physics and engineering can be represented as symmetric tensor fields; for example: stress , strain , and anisotropic  conductivity . Also, in diffusion MRI one often uses symmetric tensors to describe diffusion in the brain or other parts of the body.  Ellipsoids are examples of algebraic varieties ; and so, for general rank, symmetric tensors, in the guise of homogeneous polynomials , are used to define projective varieties , and are often studied as such.  Symmetric part of a tensor  Suppose   V   V   V   is a vector space over a field of characteristic 0. If T ∈ V ⊗ k is a tensor of order   k   k   k   , then the symmetric part of   T   T   T   is the symmetric tensor defined by        Sym  T   =    1   k  !      ∑   σ  ∈   𝔖  k       τ  σ   T      ,       Sym  T       1    k      subscript     σ   subscript  𝔖  k        subscript  τ  σ   T       \operatorname{Sym}\,T=\frac{1}{k!}\sum_{\sigma\in\mathfrak{S}_{k}}\tau_{\sigma%
 }T,   the summation extending over the symmetric group on k symbols. In terms of a basis, and employing the Einstein summation convention , if       T  =     T    i  1    i  2   …   i  k      e   i  1     ⊗   e   i  2    ⊗  ⋯  ⊗   e   i  k      ,      T   tensor-product     subscript  T     subscript  i  1    subscript  i  2   normal-…   subscript  i  k      superscript  e   subscript  i  1      superscript  e   subscript  i  2    normal-⋯   superscript  e   subscript  i  k       T=T_{i_{1}i_{2}\dots i_{k}}e^{i_{1}}\otimes e^{i_{2}}\otimes\cdots\otimes e^{i%
 _{k}},   then        Sym  T   =    1   k  !      ∑   σ  ∈   𝔖  k        T    i   σ  1     i   σ  2    …   i   σ  k       e   i  1     ⊗   e   i  2    ⊗  ⋯  ⊗   e   i  k        .       Sym  T       1    k      subscript     σ   subscript  𝔖  k      tensor-product     subscript  T     subscript  i    σ  1     subscript  i    σ  2    normal-…   subscript  i    σ  k       superscript  e   subscript  i  1      superscript  e   subscript  i  2    normal-⋯   superscript  e   subscript  i  k         \operatorname{Sym}\,T=\frac{1}{k!}\sum_{\sigma\in\mathfrak{S}_{k}}T_{i_{\sigma
 1%
 }i_{\sigma 2}\dots i_{\sigma k}}e^{i_{1}}\otimes e^{i_{2}}\otimes\cdots\otimes
 e%
 ^{i_{k}}.     The components of the tensor appearing on the right are often denoted by       T   (    i  1    i  2   …   i  k    )    =    1   k  !      ∑   σ  ∈   𝔖  k      T    i   σ  1     i   σ  2    …   i   σ  k             subscript  T     subscript  i  1    subscript  i  2   normal-…   subscript  i  k         1    k      subscript     σ   subscript  𝔖  k      subscript  T     subscript  i    σ  1     subscript  i    σ  2    normal-…   subscript  i    σ  k          T_{(i_{1}i_{2}\dots i_{k})}=\frac{1}{k!}\sum_{\sigma\in\mathfrak{S}_{k}}T_{i_{%
 \sigma 1}i_{\sigma 2}\dots i_{\sigma k}}     with parentheses around the indices which have been symmetrized. [Square brackets are used to indicate anti-symmetrization.]  Symmetric product  If T is a simple tensor, given as a pure tensor product      T  =    v  1   ⊗   v  2   ⊗  ⋯  ⊗   v  r        T   tensor-product   subscript  v  1    subscript  v  2   normal-⋯   subscript  v  r      T=v_{1}\otimes v_{2}\otimes\cdots\otimes v_{r}   then the symmetric part of T is the symmetric product of the factors:         v  1   ⊙   v  2   ⊙  ⋯  ⊙   v  r    :=    1   r  !      ∑   σ  ∈   𝔖  r       v   σ  1    ⊗   v   σ  2    ⊗  ⋯  ⊗   v   σ  r        .     assign   direct-product   subscript  v  1    subscript  v  2   normal-⋯   subscript  v  r        1    r      subscript     σ   subscript  𝔖  r      tensor-product   subscript  v    σ  1     subscript  v    σ  2    normal-⋯   subscript  v    σ  r         v_{1}\odot v_{2}\odot\cdots\odot v_{r}:=\frac{1}{r!}\sum_{\sigma\in\mathfrak{S%
 }_{r}}v_{\sigma 1}\otimes v_{\sigma 2}\otimes\cdots\otimes v_{\sigma r}.     In general we can turn Sym( V ) into an algebra by defining the commutative and associative product '   ⊙   direct-product   \odot   '. 1 Given two tensors T 1 ∈Sym k 1 ( V ) and T 2 ∈Sym k 2 ( V ), we use the symmetrization operator to define:         T  1   ⊙   T  2    =    Sym   (    T  1   ⊗   T  2    )       (    ∈    Sym    k  1   +   k  2      (  V  )     )     .       direct-product   subscript  T  1    subscript  T  2     annotated   Sym   tensor-product   subscript  T  1    subscript  T  2       absent    superscript  Sym     subscript  k  1    subscript  k  2     V       T_{1}\odot T_{2}=\operatorname{Sym}(T_{1}\otimes T_{2})\quad\left(\in%
 \operatorname{Sym}^{k_{1}+k_{2}}(V)\right).   It can be verified (as is done by Kostrikin and Manin 2 ) that the resulting product is in fact commutative and associative. In some cases the operator is not written at all: T 1 T 2 = T 1    ⊙   direct-product   \odot    T 2 .  In some cases an exponential notation is used:        v    ⊙  k    =     v  ⊙  v  ⊙  ⋯  ⊙  v   ⏟    k  times    =     v  ⊗  v  ⊗  ⋯  ⊗  v   ⏟    k  times    =   v    ⊗  k     .         superscript  v   direct-product  absent  k     subscript   normal-⏟   direct-product  v  v  normal-⋯  v      k  times          subscript   normal-⏟   tensor-product  v  v  normal-⋯  v      k  times          superscript  v   tensor-product  absent  k       v^{\odot k}=\underbrace{v\odot v\odot\cdots\odot v}_{k\text{ times}}=%
 \underbrace{v\otimes v\otimes\cdots\otimes v}_{k\text{ times}}=v^{\otimes k}.   Where v is a vector. Again, in some cases the '   ⊙   direct-product   \odot   ' is left out:        v  k   =      v    v    ⋯   v   ⏟    k  times    =     v  ⊙  v  ⊙  ⋯  ⊙  v   ⏟    k  times     .         superscript  v  k    subscript   normal-⏟    v  v  normal-⋯  v      k  times          subscript   normal-⏟   direct-product  v  v  normal-⋯  v      k  times       v^{k}=\underbrace{v\,v\,\cdots\,v}_{k\text{ times}}=\underbrace{v\odot v\odot%
 \cdots\odot v}_{k\text{ times}}.     Decomposition  In analogy with the theory of symmetric matrices , a (real) symmetric tensor of order 2 can be "diagonalized". More precisely, for any tensor T ∈ Sym 2 ( V ), there are an integer r , non-zero unit vectors v 1 ,..., v r ∈ V and weights λ 1 ,..., λ r such that       T  =    ∑   i  =  1   r       λ  i     v  i    ⊗   v  i      .      T    superscript   subscript     i  1    r    tensor-product     subscript  λ  i    subscript  v  i     subscript  v  i       T=\sum_{i=1}^{r}\lambda_{i}\,v_{i}\otimes v_{i}.   The minimum number r for which such a decomposition is possible is the (symmetric) rank of T . The vectors appearing in this minimal expression are the principal axes of the tensor, and generally have an important physical meaning. For example, the principal axes of the inertia tensor define the Poinsot's ellipsoid representing the moment of inertia. Also see Sylvester's law of inertia .  For symmetric tensors of arbitrary order k , decompositions      T  =    ∑   i  =  1   r      λ  i     v  i    ⊗  k          T    superscript   subscript     i  1    r      subscript  λ  i    superscript   subscript  v  i    tensor-product  absent  k        T=\sum_{i=1}^{r}\lambda_{i}\,v_{i}^{\otimes k}   are also possible. The minimum number r for which such a decomposition is possible is the symmetric  rank of T . 3 This minimal decomposition is called a Waring decomposition; it is a symmetric form of the tensor rank decomposition . For second-order tensors this corresponds to the rank of the matrix representing the tensor in any basis, and it is well known that the maximum rank is equal to the dimension of the underlying vector space. However, for higher orders this need not hold: the rank can be higher than the number of dimensions in the underlying vector space.  See also   antisymmetric tensor  Ricci calculus  Schur polynomial  symmetric polynomial  transpose  Young symmetrizer   Notes    References    .   .   .   .   External links   Cesar O. Aguilar, The Dimension of Symmetric k-tensors   "  Category:Tensors     ↩   ↩     