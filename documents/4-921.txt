   Divergent series      Divergent series    For an elementary calculus-based introduction, see Divergent series on Wikiversity    In mathematics , a divergent series is an infinite series that is not convergent , meaning that the infinite sequence of the partial sums of the series does not have a finite limit .  If a series converges, the individual terms of the series must approach zero. Thus any series in which the individual terms do not approach zero diverges. However, convergence is a stronger condition: not all series whose terms approach zero converge. A counterexample is the harmonic series        1  +   1  2   +   1  3   +   1  4   +   1  5   +  ⋯   =    ∑   n  =  1   ∞    1  n     .        1    1  2     1  3     1  4     1  5   normal-⋯     superscript   subscript     n  1        1  n      1+\frac{1}{2}+\frac{1}{3}+\frac{1}{4}+\frac{1}{5}+\cdots=\sum_{n=1}^{\infty}%
 \frac{1}{n}.     The divergence of the harmonic series was proven by the medieval mathematician Nicole Oresme .  In specialized mathematical contexts, values can be objectively assigned to certain series whose sequence of partial sums diverges, this is to make meaning of the divergence of the series. A summability method or summation method is a partial function from the set of series to values. For example, Cesàro summation assigns Grandi's divergent series         1  -  1   +  1   -  1   +  ⋯            1  1   1   1   normal-⋯    1-1+1-1+\cdots     the value 1 / 2 . Cesàro summation is an averaging method, in that it relies on the arithmetic mean of the sequence of partial sums. Other methods involve analytic continuations of related series. In physics , there are a wide variety of summability methods; these are discussed in greater detail in the article on regularization .  History  Before the 19th century divergent series were widely used by Euler and others, but often led to confusing and contradictory results. A major problem was Euler's idea that any divergent series should have a natural sum, without first defining what is meant by the sum of a divergent series. Cauchy eventually gave a rigorous definition of the sum of a (convergent) series, and for some time after this divergent series were mostly excluded from mathematics. They reappeared in 1886 with Poincaré's work on asymptotic series. In 1890 Cesaro realized that one could give a rigorous definition of the sum of some divergent series, and defined Cesaro summation . (This was not the first use of Cesaro summation which was used implicitly by Frobenius in 1880; Cesaro's key contribution was not the discovery of this method but his idea that one should give an explicit definition of the sum of a divergent series.) In the years after Cesaro's paper several other mathematicians gave other definitions of the sum of a divergent series, though these are not always compatible: different definitions can give different answers for the sum of the same divergent series, so when talking about the sum of a divergent series it is necessary to specify which summation method one is using.  Theorems on methods for summing divergent series  A summability method M is regular if it agrees with the actual limit on all convergent series . Such a result is called an abelian theorem for M , from the prototypical Abel's theorem . More interesting and in general more subtle are partial converse results, called tauberian theorems , from a prototype proved by Alfred Tauber . Here partial converse means that if M sums the series Σ, and some side-condition holds, then Σ was convergent in the first place; without any side condition such a result would say that M only summed convergent series (making it useless as a summation method for divergent series).  The operator giving the sum of a convergent series is linear , and it follows from the Hahn–Banach theorem that it may be extended to a summation method summing any series with bounded partial sums. This fact is not very useful in practice since there are many such extensions, inconsistent with each other, and also since proving such operators exist requires invoking the axiom of choice or its equivalents, such as Zorn's lemma . They are therefore nonconstructive.  The subject of divergent series, as a domain of mathematical analysis , is primarily concerned with explicit and natural techniques such as Abel summation , Cesàro summation and Borel summation , and their relationships. The advent of Wiener's tauberian theorem marked an epoch in the subject, introducing unexpected connections to Banach algebra methods in Fourier analysis .  Summation of divergent series is also related to extrapolation methods and sequence transformations as numerical techniques. Examples for such techniques are Padé approximants , Levin-type sequence transformations , and order-dependent mappings related to renormalization techniques for large-order perturbation theory in quantum mechanics .  Properties of summation methods  Summation methods usually concentrate on the sequence of partial sums of the series. While this sequence does not converge, we may often find that when we take an average of larger and larger initial terms of the sequence, the average converges, and we can use this average instead of a limit to evaluate the sum of the series. So in evaluating we work with the sequence s , where and . In the convergent case, the sequence s approaches the limit a . A summation method can be seen as a function from a set of sequences of partial sums to values. If A is any summation method assigning values to a set of sequences, we may mechanically translate this to a series-summation method  A Σ that assigns the same values to the corresponding series. There are certain properties it is desirable for these methods to possess if they are to arrive at values corresponding to limits and sums, respectively.   Regularity . A summation method is regular if, whenever the sequence s converges to x ,  Equivalently, the corresponding series-summation method evaluates  Linearity . A is linear if it is a linear functional on the sequences where it is defined, so that  for sequences r , s and a real or complex scalar k . Since the terms of the series a are linear functionals on the sequence s and vice versa, this is equivalent to A Σ being a linear functional on the terms of the series.  Stability (also called translativity). If s is a sequence starting from s 0 and s ′ is the sequence obtained by omitting the first value and subtracting it from the rest, so that , then A ( s ) is defined if and only if A ( s ′) is defined, and Equivalently, whenever for all n , then 1 2 Another way of stating this is that the shift rule must be valid for the series that are summable by this method.   The third condition is less important, and some significant methods, such as Borel summation , do not possess it. 3  One can also give a weaker alternative to the last condition.   Finite re-indexability . If a and a ′ are two series such that there exists a bijection     f  :   ℕ  →  ℕ      normal-:  f   normal-→  ℕ  ℕ     f:\mathbb{N}\rightarrow\mathbb{N}   such that for all i , and if there exists some    N  ∈  ℕ      N  ℕ    N\in\mathbb{N}   such that for all i > N , then (In other words, a ′ is the same series as a , with only finitely many terms re-indexed.) Note that this is a weaker condition than Stability , because any summation method that exhibits Stability also exhibits Finite Re-indexability , but the converse is not true.   A desirable property for two distinct summation methods A and B to share is consistency : A and B are consistent if for every sequence s to which both assign a value,  If two methods are consistent, and one sums more series than the other, the one summing more series is stronger .  There are powerful numerical summation methods that are neither regular nor linear, for instance nonlinear sequence transformations like Levin-type sequence transformations and Padé approximants , as well as the order-dependent mappings of perturbative series based on renormalization techniques.  Taking regularity, linearity and stability as axioms, it is possible to sum many divergent series by elementary algebraic manipulations. This partly explains why many different summation methods give the same answer for certain series.  For instance, whenever  the geometric series      G   (  r  ,  c  )       G   r  c     \displaystyle G(r,c)   can be evaluated regardless of convergence. More rigorously, any summation method that possesses these properties and which assigns a finite value to the geometric series must assign this value. However, when r is a real number larger than 1, the partial sums increase without bound, and averaging methods assign a limit of ∞.  Classical summation methods  The two classical summation methods for series, ordinary convergence and absolute convergence, define the sum as a limit of certain partial sums. Strictly speaking these are not really summation methods for divergent series, as by definition a series is divergent only if these methods do not work, but are included for completeness. Most but not all summation methods for divergent series extend these methods to a larger class of sequences.  Absolute convergence  Absolute convergence defines the sum of a sequence (or set) of numbers to be the limit of the net of all partial sums a k 1 + ...+ a k n , if it exists. It does not depend on the order of the elements of the sequence, and a classical theorem says that a sequence is absolutely convergent if and only if the sequence of absolute values is convergent in the standard sense.  Sum of a series  Cauchy's classical definition of the sum of a series a 0 + a 1 +... defines the sum to be the limit of the sequence of partial sums a 0 + ...+ a n . This is the default definition of convergence of a sequence.  Nørlund means  Suppose p n is a sequence of positive terms, starting from p 0 . Suppose also that        p  n     p  0   +   p  1   +  ⋯  +   p  n     →  0.     normal-→     subscript  p  n      subscript  p  0    subscript  p  1   normal-⋯   subscript  p  n     0.    \frac{p_{n}}{p_{0}+p_{1}+\cdots+p_{n}}\rightarrow 0.   If now we transform a sequence s by using p to give weighted means, setting       t  m   =      p  m    s  0    +    p   m  -  1     s  1    +  ⋯  +    p  0    s  m       p  0   +   p  1   +  ⋯  +   p  m          subscript  t  m          subscript  p  m    subscript  s  0       subscript  p    m  1     subscript  s  1    normal-⋯     subscript  p  0    subscript  s  m        subscript  p  0    subscript  p  1   normal-⋯   subscript  p  m       t_{m}=\frac{p_{m}s_{0}+p_{m-1}s_{1}+\cdots+p_{0}s_{m}}{p_{0}+p_{1}+\cdots+p_{m}}   then the limit of t n as n goes to infinity is an average called the Nørlund mean  N p ( s ).  The Nørlund mean is regular, linear, and stable. Moreover, any two Nørlund means are consistent.  Cesàro summation  The most significant of the Nørlund means are the Cesàro sums. Here, if we define the sequence p k by       p  n  k   =   (       n  +  k   -  1        k  -  1      )        superscript   subscript  p  n   k    binomial      n  k   1     k  1      p_{n}^{k}={n+k-1\choose k-1}   then the Cesàro sum C k is defined by Cesàro sums are Nørlund means if , and hence are regular, linear, stable, and consistent. C 0 is ordinary summation, and C 1 is ordinary Cesàro summation . Cesàro sums have the property that if  then C h is stronger than C k .  Abelian means  Suppose λ = {λ 0 , λ 1 , λ 2 , ...} is a strictly increasing sequence tending towards infinity, and that . Suppose       f   (  x  )    =    ∑   n  =  0   ∞     a  n    exp   (   -    λ  n   x    )            f  x     superscript   subscript     n  0         subscript  a  n          subscript  λ  n   x         f(x)=\sum_{n=0}^{\infty}a_{n}\exp(-\lambda_{n}x)   converges for all real numbers x >0. Then the Abelian mean  A λ is defined as         A  λ    (  s  )    =    lim   x  →   0  +      f   (  x  )      .         subscript  A  λ   s     subscript    normal-→  x   superscript  0        f  x      A_{\lambda}(s)=\lim_{x\rightarrow 0^{+}}f(x).     More generally, if the series for f only converges for large x but can be analytically continued to all positive real x , then one can still define the sum of the divergent series by the limit above.  A series of this type is known as a generalized Dirichlet series ; in applications to physics, this is known as the method of heat-kernel regularization .  Abelian means are regular and linear, but not stable and not always consistent between different choices of λ. However, some special cases are very important summation methods.  Abel summation  If , then we obtain the method of Abel summation . Here        f   (  x  )    =    ∑   n  =  0   ∞     a  n    e   -   n  x       =    ∑   n  =  0   ∞     a  n    z  n      ,          f  x     superscript   subscript     n  0         subscript  a  n    superscript  e      n  x              superscript   subscript     n  0         subscript  a  n    superscript  z  n        f(x)=\sum_{n=0}^{\infty}a_{n}e^{-nx}=\sum_{n=0}^{\infty}a_{n}z^{n},     where z = exp(− x ). Then the limit of ƒ( x ) as x approaches 0 through positive reals is the limit of the power series for ƒ( z ) as z approaches 1 from below through positive reals, and the Abel sum A ( s ) is defined as        A   (  s  )    =    lim   z  →   1  -       ∑   n  =  0   ∞     a  n    z  n       .        A  s     subscript    normal-→  z   superscript  1        superscript   subscript     n  0         subscript  a  n    superscript  z  n        A(s)=\lim_{z\rightarrow 1^{-}}\sum_{n=0}^{\infty}a_{n}z^{n}.     Abel summation is interesting in part because it is consistent with but more powerful than Cesàro summation : whenever the latter is defined. The Abel sum is therefore regular, linear, stable, and consistent with Cesàro summation.  Lindelöf summation  If , then (indexing from one) we have        f   (  x  )    =    a  1   +    a  2    2   -   2  x      +    a  3    3   -   3  x      +  ⋯    .        f  x      subscript  a  1      subscript  a  2    superscript  2      2  x         subscript  a  3    superscript  3      3  x      normal-⋯     f(x)=a_{1}+a_{2}2^{-2x}+a_{3}3^{-3x}+\cdots.     Then L ( s ), the Lindelöf sum , is the limit of ƒ( x ) as x goes to zero. The Lindelöf sum is a powerful method when applied to power series among other applications, summing power series in the Mittag-Leffler star .  If g ( z ) is analytic in a disk around zero, and hence has a Maclaurin series  G ( z ) with a positive radius of convergence, then  in the Mittag-Leffler star. Moreover, convergence to g ( z ) is uniform on compact subsets of the star.  Analytic continuation  Several summation methods involve taking the value of an analytic continuation of a function.  Analytic continuation of power series  If Σ a n x n converges for small complex x and can be analytically continued along some path from x =0 to the point x =1, then the sum of the series can be defined to be the value at x =1. This value may depend on the choice of path.  Euler summation  Euler summation is essentially an explicit form of analytic continuation. If a power series converges for small complex z and can be analytically continued to the open disk with diameter from −1/( q +1) to 1 and is continuous at 1, then its value at is called the Euler or (E, q ) sum of the series a 0 +.... Euler used it before analytic continuation was defined in general, and gave explicit formulas for the power series of the analytic continuation.  The operation of Euler summation can be repeated several times, and this is essentially equivalent to taking an analytic continuation of a power series to the point z =1.  Analytic continuation of Dirichlet series  This method defines the sum of a series to be the value of the analytic continuation of the Dirichlet series       f   (  s  )    =     a  1    1  s    +    a  2    2  s    +    a  3    3  s    +  ⋯         f  s        subscript  a  1    superscript  1  s       subscript  a  2    superscript  2  s       subscript  a  3    superscript  3  s    normal-⋯     f(s)=\frac{a_{1}}{1^{s}}+\frac{a_{2}}{2^{s}}+\frac{a_{3}}{3^{s}}+\cdots   at s =0, if this exists and is unique. This method is sometimes confused with zeta function regularization.  Zeta function regularization  If the series       f   (  s  )    =    1   a  1  s    +   1   a  2  s    +   1   a  3  s    +  ⋯         f  s       1   superscript   subscript  a  1   s      1   superscript   subscript  a  2   s      1   superscript   subscript  a  3   s    normal-⋯     f(s)=\frac{1}{a_{1}^{s}}+\frac{1}{a_{2}^{s}}+\frac{1}{a_{3}^{s}}+\cdots     (for positive values of the a n ) converges for large real s and can be analytically continued along the real line to s =−1, then its value at s =−1 is called the zeta regularized sum of the series a 1 + a 2 +... Zeta function regularization is nonlinear. In applications, the numbers a i are sometimes the eigenvalues of a self-adjoint operator A with compact resolvent, and f ( s ) is then the trace of A − s . For example, if A has eigenvalues 1, 2, 3, ... then f ( s ) is the Riemann zeta function , ζ( s ), whose value at s =−1 is −1/12, assigning a value to the divergent series is 1 + 2 + 3 + 4 + ⋯ . Other values of s can also be used to assign values for the divergent sums ζ(0)=1 + 1 + 1 + ... = -1/2, ζ(-2)=1 + 4 + 9 + ... = 0 and in general     ζ   (   -  s   )    =    ∑   n  =  1   ∞    n  s    =    1  s   +   2  s   +   3  s   +  …   =   -    B   s  +  1     s  +  1             ζ    s      superscript   subscript     n  1       superscript  n  s            superscript  1  s    superscript  2  s    superscript  3  s   normal-…             subscript  B    s  1      s  1        \zeta(-s)=\sum_{n=1}^{\infty}n^{s}=1^{s}+2^{s}+3^{s}+\ldots=-\frac{B_{s+1}}{s+1}   , where B k is a Bernoulli number . 4  Integral function means  If J (x)=Σ p n x n is an integral function, then the J sum of the series a 0 +... is defined to be        lim   x  →  ∞       ∑  n     p  n    (    a  0   +  ⋯  +   a  n    )    x  n       ∑  n     p  n    x  n       ,      subscript    normal-→  x         subscript   n      subscript  p  n      subscript  a  0   normal-⋯   subscript  a  n     superscript  x  n       subscript   n      subscript  p  n    superscript  x  n        \lim_{x\rightarrow\infty}\frac{\sum_{n}p_{n}(a_{0}+\cdots+a_{n})x^{n}}{\sum_{n%
 }p_{n}x^{n}},   if this limit exists.  There is a variation of this method where the series for J has a finite radius of convergence r and diverges at x = r . In this case one defines the sum as above, except taking the limit as x tends to r rather than infinity.  Borel summation  In the special case when J ( x )= e x this gives one (weak) form of Borel summation .  Valiron's method  Valiron's method is a generalization of Borel summation to certain more general integral functions J . Valiron showed that under certain conditions it is equivalent to defining the sum of a series as       lim   n  →   +  ∞         H   (  n  )     2  π       ∑   h  ∈  Z      e   -     h  2   H   (  n  )    /  2      (    a  0   +  ⋯  +   a  h    )          subscript    normal-→  n                H  n     2  π       subscript     h  Z       superscript  e         superscript  h  2   H  n   2        subscript  a  0   normal-⋯   subscript  a  h         \lim_{n\rightarrow+\infty}\sqrt{\frac{H(n)}{2\pi}}\sum_{h\in Z}e^{-h^{2}H(n)/2%
 }(a_{0}+\cdots+a_{h})   where H is the second derivative of G and c ( n )= e − G ( n ) .  Moment methods  Suppose that dμ is a measure on the real line such that all the moments       μ  n   =   ∫    x  n   d  μ         subscript  μ  n        superscript  x  n   d  μ      \mu_{n}=\int x^{n}d\mu   are finite. If a 0 + a 1 +... is a series such that       a   (  x  )    =      a  0    x  0     μ  0    +     a  1    x  1     μ  1    +  ⋯         a  x          subscript  a  0    superscript  x  0     subscript  μ  0         subscript  a  1    superscript  x  1     subscript  μ  1    normal-⋯     a(x)=\frac{a_{0}x^{0}}{\mu_{0}}+\frac{a_{1}x^{1}}{\mu_{1}}+\cdots   converges for all x in the support of μ, then the (dμ) sum of the series is defined to be the value of the integral      ∫   a   (  x  )   d  μ         a  x  d  μ     \int a(x)d\mu   if it is defined. (Note that if the numbers μ n increase too rapidly then they do not uniquely determine the measure μ.)  Borel summation  For example, if dμ = e − x dx for positive x and 0 for negative x then μ n = n !, and this gives one version of Borel summation , where the value of a sum is given by        ∫  0  ∞     e   -  t     ∑      a  n    t  n     n  !    d  t      .      superscript   subscript   0        superscript  e    t             subscript  a  n    superscript  t  n      n    d  t       \int_{0}^{\infty}e^{-t}\sum\frac{a_{n}t^{n}}{n!}dt.     There is a generalization of this depending on a variable α, called the (B',α) sum, where the sum of a series a 0 +... is defined to be       ∫  0  ∞     e   -  t     ∑      a  n    t   n  α      Γ   (    n  α   +  1   )     d  t         superscript   subscript   0        superscript  e    t             subscript  a  n    superscript  t    n  α       normal-Γ      n  α   1     d  t       \int_{0}^{\infty}e^{-t}\sum\frac{a_{n}t^{n\alpha}}{\Gamma(n\alpha+1)}dt   if this integral exists. A further generalization is to replace the sum under the integral by its analytic continuation from small t .  Miscellaneous methods  Hausdorff transformations  .  Hölder summation  Hutton's method  In 1812 Hutton introduced a method of summing divergent series by starting with the sequence of partial sums, and repeated applying the operation of replacing a sequence s 0 , s 1 , ... by the sequence of averages ( s 0 + s 1 )/2, ( s 1 + s 2 )/2, ..., and then taking the limit .  Ingham summability  The series a 1 +... is called Ingham summable to s if        lim   x  →  ∞      ∑   1  ≤  n  ≤  x      a  n    n  x    [   x  n   ]      =  s        subscript    normal-→  x       subscript       1  n       x        subscript  a  n     n  x    delimited-[]    x  n       s    \lim_{x\rightarrow\infty}\sum_{1\leq n\leq x}a_{n}\frac{n}{x}\left[\frac{x}{n}%
 \right]=s   . Albert Ingham showed that if δ is any positive number then (C,−δ) (Cesaro) summability implies Ingham summability, and Ingham summability implies (C,δ) summability .  Lambert summability  The series a 1 +... is called Lambert summable to s if        lim   y  →   0  +       ∑   n  ≥  1      a  n     n  y   e   -   n  y       1  -   e   -   n  y          =  s        subscript    normal-→  y   superscript  0        subscript     n  1       subscript  a  n       n  y   superscript  e      n  y        1   superscript  e      n  y          s    \lim_{y\rightarrow 0^{+}}\sum_{n\geq 1}a_{n}\frac{nye^{-ny}}{1-e^{-ny}}=s   .  If a series is (C, k ) (Cesaro) summable for any k then it is Lambert summable to the same value, and if a series is Lambert summable then it is Abel summable to the same value .  Le Roy summation  The series a 0 +... is called Le Roy summable to s if        lim   ζ  →   1  -       ∑  n      Γ   (   1  +   ζ  n    )     Γ   (   1  +  n   )      a  n      =  s        subscript    normal-→  ζ   superscript  1        subscript   n         normal-Γ    1    ζ  n       normal-Γ    1  n      subscript  a  n      s    \lim_{\zeta\rightarrow 1^{-}}\sum_{n}\frac{\Gamma(1+\zeta n)}{\Gamma(1+n)}a_{n%
 }=s   .  Mittag-Leffler summation  The series a 0 +... is called Mittag-Leffler (M) summable to s if        lim   δ  →  0      ∑  n     a  n    Γ   (   1  +   δ  n    )       =  s        subscript    normal-→  δ  0      subscript   n      subscript  a  n     normal-Γ    1    δ  n        s    \lim_{\delta\rightarrow 0}\sum_{n}\frac{a_{n}}{\Gamma(1+\delta n)}=s   .  Ramanujan summation  Ramanujan summation is a method of assigning a value to divergent series used by Ramanujan and based on the Euler–Maclaurin summation formula . The Ramanujan sum of a series f (0) + f (1) + ... depends not only on the values of f at integers, but also on values of the function f at non-integral points, so it is not really a summation method in the sense of this article.  Riemann summability  The series a 1 +... is called (R, k ) (or Riemann) summable to s if        lim   h  →  0      ∑  n     a  n     (    sin   n  h     n  h    )   k      =  s        subscript    normal-→  h  0      subscript   n      subscript  a  n    superscript        n  h      n  h    k      s    \lim_{h\rightarrow 0}\sum_{n}a_{n}\left(\frac{\sin nh}{nh}\right)^{k}=s   . . The series a 1 +... is called R 2 summable to s if        lim   h  →  0      2  π     ∑  n       sin  2    n  h      n  2   h     (    a  1   +   ⋯   a  n     )       =  s        subscript    normal-→  h  0        2  π     subscript   n         superscript   2     n  h       superscript  n  2   h       subscript  a  1     normal-⋯   subscript  a  n         s    \lim_{h\rightarrow 0}\frac{2}{\pi}\sum_{n}\frac{\sin^{2}nh}{n^{2}h}(a_{1}+%
 \cdots a_{n})=s   .  Riesz means  If λ n form an increasing sequence of real numbers and         lim   m  →  ∞     a  0    +    a  1    m   m  +  1     +    a  2     m   (   m  -  1   )      (   m  +  1   )    (   m  +  2   )      +  ⋯   =  s          subscript    normal-→  m      subscript  a  0       subscript  a  1     m    m  1        subscript  a  2       m    m  1        m  1     m  2      normal-⋯   s    \lim_{m\rightarrow\infty}a_{0}+a_{1}\frac{m}{m+1}+a_{2}\frac{m(m-1)}{(m+1)(m+2%
 )}+\cdots=s     Vallée-Poussin summability  The series a 1 +... is called VP (or Vallée-Poussin) summable to s if  $$\lim_{m\rightarrow \infty} a_0+a_1\frac{m}{m+1}+a_2\frac{m(m-1)}{(m+1)(m+2)}+\cdots = s$$ . .  See also   1 − 1 + 2 − 6 + 24 − 120 + · · ·  Silverman–Toeplitz theorem   Notes  References    .   .   .   .   .   .   .    "  Category:Divergent series  Category:Mathematical series  Category:Summability methods  Category:Asymptotic analysis  Category:Summability theory     see Michon's Numericana http://www.numericana.com/answer/sums.htm ↩  see also Translativity at The Encyclopedia of Mathematics wiki (Springer) 1 ↩  . Muraev observes that Borel summation is translative in one of the two directions: augmenting a series by a zero placed at its start does not change the summability or value of the series. However, he states "the converse is false". ↩  ↩     