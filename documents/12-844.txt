   Fieller's theorem      Fieller's theorem   In statistics , Fieller's theorem allows the calculation of a confidence interval for the ratio of two means .  Approximate confidence interval  Variables a and b may be measured in different units, so there is no way to directly combine the standard errors as they may also be in different units. The most complete discussion of this is given by Fieller (1954). 1  Fieller showed that if a and b are (possibly correlated ) means of two samples with expectations     μ  a     subscript  μ  a    \mu_{a}   and    μ  b     subscript  μ  b    \mu_{b}   , and variances     ν  11    σ  2        subscript  ν  11    superscript  σ  2     \nu_{11}\sigma^{2}   and     ν  22    σ  2        subscript  ν  22    superscript  σ  2     \nu_{22}\sigma^{2}   and covariance     ν  12    σ  2        subscript  ν  12    superscript  σ  2     \nu_{12}\sigma^{2}   , and if     ν  11   ,   ν  12   ,   ν  22       subscript  ν  11    subscript  ν  12    subscript  ν  22     \nu_{11},\nu_{12},\nu_{22}   are all known, then a (1 − α ) confidence interval ( m L , m U ) for    a  /  b      a  b    a/b   is given by       (   m  L   ,   m  U   )   =    1   (   1  -  g   )     [     a  b   -    g   ν  12     ν  22     ∓      t   r  ,  α    s   b        ν  11   -   2   a  b    ν  12     +     a  2    b  2     ν  22     -   g   (    ν  11   -    ν  12  2    ν  22     )        ]          subscript  m  L    subscript  m  U        1    1  g     delimited-[]   minus-or-plus      a  b       g   subscript  ν  12     subscript  ν  22            subscript  t   r  α    s   b            subscript  ν  11     2    a  b    subscript  ν  12          superscript  a  2    superscript  b  2     subscript  ν  22       g     subscript  ν  11      superscript   subscript  ν  12   2    subscript  ν  22              (m_{L},m_{U})=\frac{1}{(1-g)}\left[\frac{a}{b}-\frac{g\nu_{12}}{\nu_{22}}\mp%
 \frac{t_{r,\alpha}s}{b}\sqrt{\nu_{11}-2\frac{a}{b}\nu_{12}+\frac{a^{2}}{b^{2}}%
 \nu_{22}-g\left(\nu_{11}-\frac{\nu_{12}^{2}}{\nu_{22}}\right)}\right]     where       g  =     t   r  ,  α   2    s  2    ν  22     b  2     .      g       subscript   superscript  t  2    r  α     superscript  s  2    subscript  ν  22     superscript  b  2      g=\frac{t^{2}_{r,\alpha}s^{2}\nu_{22}}{b^{2}}.   Here    s  2     superscript  s  2    s^{2}   is an unbiased estimator of    σ  2     superscript  σ  2    \sigma^{2}   based on r degrees of freedom, and    t   r  ,  α      subscript  t   r  α     t_{r,\alpha}   is the   α   α   \alpha   -level deviate from the Student's t-distribution based on r degrees of freedom.  Three features of this formula are important in this context:  a) The expression inside the square root has to be positive, or else the resulting interval will be imaginary.  b) When g is very close to 1, the confidence interval is infinite.  c) When g is greater than 1, the overall divisor outside the square brackets is negative and the confidence interval is exclusive.  Approximate formulae  These equations approximation to the full formula, and are obtained via a Taylor series expansion of a function of two variables and then taking the variance (i.e. a generalisation to two variables of the formula for the approximate standard error for a function of an estimate).  Case 1  Assume that a and b are jointly  normally distributed , and that b is not too near zero (i.e. more specifically, that the standard error of b is small compared to b ),        Var   (   a  b   )    =     (   a  b   )   2    (     Var   (  a  )     a  2    +    Var   (  b  )     b  2     )     .       Var    a  b       superscript    a  b   2        Var  a    superscript  a  2       Var  b    superscript  b  2        \operatorname{Var}\left(\frac{a}{b}\right)=\left(\frac{a}{b}\right)^{2}\left(%
 \frac{\operatorname{Var}(a)}{a^{2}}+\frac{\operatorname{Var}(b)}{b^{2}}\right).     From this a 95% confidence interval can be constructed in the usual way (degrees of freedom for t * is equal to the total number of values in the numerator and denominator minus 2).  This can be expressed in a more useful form for when (as is usually the case) logged data is used, using the following relation for a function of x and y , say ƒ( x , y ):        Var   (  f  )    =      (    ∂  f    ∂  x    )   2    Var   (  x  )     +     (    ∂  f    ∂  y    )   2    Var   (  y  )     +   2    ∂  f    ∂  x       .     ∂  f    ∂  y     Cov   (  x  ,  y  )        formulae-sequence     Var  f        superscript      f     x    2    Var  x       superscript      f     y    2    Var  y      2      f     x             f     y     Cov  x  y      \operatorname{Var}(f)=\left(\frac{\partial f}{\partial x}\right)^{2}%
 \operatorname{Var}(x)+\left(\frac{\partial f}{\partial y}\right)^{2}%
 \operatorname{Var}(y)+2\frac{\partial f}{\partial x}.\frac{\partial f}{%
 \partial y}\operatorname{Cov}(x,y)     to obtain either,       Var   (    log  e    a  b    )    =     Var   (  a  )     a  2    +    Var   (  b  )     b  2          Var    subscript   e     a  b          Var  a    superscript  a  2       Var  b    superscript  b  2       \operatorname{Var}\left(\log_{e}\frac{a}{b}\right)=\frac{\operatorname{Var}(a)%
 }{a^{2}}+\frac{\operatorname{Var}(b)}{b^{2}}     or        Var   (    log  10    a  b    )    =     (    log  10   e   )   2    (     Var   (  a  )     a  2    +    Var   (  b  )     b  2     )     .       Var    subscript   10     a  b        superscript    subscript   10   e   2        Var  a    superscript  a  2       Var  b    superscript  b  2        \operatorname{Var}\left(\log_{10}\frac{a}{b}\right)=\left(\log_{10}e\right)^{2%
 }\left(\frac{\operatorname{Var}(a)}{a^{2}}+\frac{\operatorname{Var}(b)}{b^{2}}%
 \right).     Case 2  Assume that a and b are jointly normally distributed , and that b is near zero (i.e. SE( b ) is not small compared to b ).  First, calculate the intermediate quantity:       g  =     (    t  *   b   )   2    Var   (  b  )      .      g     superscript     superscript  t    b   2    Var  b      g=\left(\frac{t^{*}}{b}\right)^{2}\operatorname{Var}(b).     You cannot calculate the confidence interval of the quotient if    g  ≥  1      g  1    g\geq 1   , as the CI for the denominator μ b will include zero.  However if    g  <  1      g  1    g<1   then we can obtain        Var   (   a  b   )    =     (   a   b   (   1  -  g   )     )   2    (     (   1  -  g   )     Var   (  a  )     a  2     +    Var   (  b  )     b  2     )     .       Var    a  b       superscript    a    b    1  g     2         1  g      Var  a    superscript  a  2        Var  b    superscript  b  2        \operatorname{Var}\left(\frac{a}{b}\right)=\left(\frac{a}{b(1-g)}\right)^{2}%
 \left((1-g)\frac{\operatorname{Var}(a)}{a^{2}}+\frac{\operatorname{Var}(b)}{b^%
 {2}}\right).     Other  One problem is that, when g is not small, CIs can blow up when using Fieller's theorem. Andy Grieve has provided a Bayesian solution where the CIs are still sensible, albeit wide. 2  Bootstrapping provides another alternative that that does not require the assumption of normality. 3  History  Edgar C. Fieller (1907–1960) first started working on this problem while in Karl Pearson 's group at University College London , where he was employed for five years after graduating in Mathematics from King's College, Cambridge . He then worked for the Boots Pure Drug Company as a statistician and operational researcher before becoming deputy head of operational research at RAF Fighter Command during the Second World War , after which he was appointed the first head of the Statistics Section at the National Physical Laboratory . 4  See also   Gaussian ratio distribution   Notes  Further reading   Iris Pigeot, Juliane Schafer, Joachim Rohmel and Dieter Hauschke (2003) "Assessing non-inferiority of a new treatment in a three-arm clinical trial including a placebo". Statistics in Medicine , 22:883–899,  Fieller, EC. (1932) "The distribution of the index in a bivariate Normal distribution". Biometrika , 24(3–4):428–440.  Fieller, EC. (1940) "The biological standardisation of insulin". Journal of the Royal Statistical Society (Supplement) . 1:1–54.  Fieller, EC. (1944) "A fundamental formula in the statistics of biological assay, and some applications". Quarterly Journal of Pharmacy and Pharmacology . 17: 117-123.  Motulsky, Harvey (1995) Intuitive Biostatistics . Oxford University Press. ISBN 0-19-508607-4  Senn, Steven (2007) Statistical Issues in Drug Development . Second Edition. Wiley. ISBN 0-471-97488-9    "  Category:Statistical theorems  Category:Statistical approximations  Category:Normal distribution     ↩  ↩  ↩  ↩     