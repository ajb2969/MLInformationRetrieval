   Edgeworth series      Edgeworth series   The Gram–Charlier A series (named in honor of Jørgen Pedersen Gram and Carl Charlier ), and the Edgeworth series (named in honor of Francis Ysidro Edgeworth ) are series that approximate a probability distribution in terms of its cumulants . 1 The series are the same; but, the arrangement of terms (and thus the accuracy of truncating the series) differ. 2  Gram–Charlier A series  The key idea of these expansions is to write the characteristic function of the distribution whose probability density function is   F   F   F   to be approximated in terms of the characteristic function of a distribution with known and suitable properties, and to recover   F   F   F   through the inverse Fourier transform .  We examine a continuous random variable. Let   f   f   f   be the characteristic function of its distribution whose density function is   F   F   F   , and    κ  r     subscript  κ  r    \kappa_{r}   its cumulants . We expand in terms of a known distribution with probability density function   Ψ   normal-Ψ   Ψ   , characteristic function   ψ   ψ   ψ   , and cumulants    γ  r     subscript  γ  r    \gamma_{r}   . The density   Ψ   normal-Ψ   Ψ   is generally chosen to be that of the normal distribution , but other choices are possible as well. By the definition of the cumulants, we have (see Wallace, 1958) 3       f   (  t  )    =   exp   [    ∑   r  =  1   ∞     κ  r      (   i  t   )   r    r  !      ]          f  t       superscript   subscript     r  1         subscript  κ  r      superscript    i  t   r     r         f(t)=\exp\left[\sum_{r=1}^{\infty}\kappa_{r}\frac{(it)^{r}}{r!}\right]   and      ψ   (  t  )    =   exp   [    ∑   r  =  1   ∞     γ  r      (   i  t   )   r    r  !      ]     ,        ψ  t       superscript   subscript     r  1         subscript  γ  r      superscript    i  t   r     r         \psi(t)=\exp\left[\sum_{r=1}^{\infty}\gamma_{r}\frac{(it)^{r}}{r!}\right],   which gives the following formal identity:        f   (  t  )    =    exp   [    ∑   r  =  1   ∞     (    κ  r   -   γ  r    )      (   i  t   )   r    r  !      ]    ψ   (  t  )     .        f  t         superscript   subscript     r  1           subscript  κ  r    subscript  γ  r       superscript    i  t   r     r       ψ  t     f(t)=\exp\left[\sum_{r=1}^{\infty}(\kappa_{r}-\gamma_{r})\frac{(it)^{r}}{r!}%
 \right]\psi(t)\,.     By the properties of the Fourier transform,      (   i  t   )   r   ψ   (  t  )        superscript    i  t   r   ψ  t    (it)^{r}\psi(t)   is the Fourier transform of      (   -  1   )   r    [    D  r   Ψ   ]    (   -  x   )        superscript    1   r    delimited-[]     superscript  D  r   normal-Ψ      x     (-1)^{r}[D^{r}\Psi](-x)   , where   D   D   D   is the differential operator with respect to   x   x   x   . Thus, after changing   x   x   x   with    -  x      x    -x   on both sides of the equation, we find for   F   F   F   the formal expansion        F   (  x  )    =    exp   [    ∑   r  =  1   ∞     (    κ  r   -   γ  r    )      (   -  D   )   r    r  !      ]    Ψ   (  x  )     .        F  x         superscript   subscript     r  1           subscript  κ  r    subscript  γ  r       superscript    D   r     r       normal-Ψ  x     F(x)=\exp\left[\sum_{r=1}^{\infty}(\kappa_{r}-\gamma_{r})\frac{(-D)^{r}}{r!}%
 \right]\Psi(x)\,.     If   Ψ   normal-Ψ   Ψ   is chosen as the normal density with mean and variance as given by   F   F   F   , that is, mean    μ  =   κ  1       μ   subscript  κ  1     \mu=\kappa_{1}   and variance     σ  2   =   κ  2        superscript  σ  2    subscript  κ  2     \sigma^{2}=\kappa_{2}   , then the expansion becomes        F   (  x  )    =    exp   [    ∑   r  =  3   ∞     κ  r      (   -  D   )   r    r  !      ]     1     2  π    σ     exp   [   -     (   x  -  μ   )   2    2   σ  2      ]      .        F  x         superscript   subscript     r  3         subscript  κ  r      superscript    D   r     r         1        2  π    σ           superscript    x  μ   2     2   superscript  σ  2          F(x)=\exp\left[\sum_{r=3}^{\infty}\kappa_{r}\frac{(-D)^{r}}{r!}\right]\frac{1}%
 {\sqrt{2\pi}\sigma}\exp\left[-\frac{(x-\mu)^{2}}{2\sigma^{2}}\right].     since     γ  r   =  0       subscript  γ  r   0    \gamma_{r}=0   for all   r   r   r   >2 as higher cumulants of the normal distribution are 0. By expanding the exponential and collecting terms according to the order of the derivatives, we arrive at the Gram–Charlier A series. If we include only the first two correction terms to the normal distribution, we obtain        F   (  x  )    ≈    1     2  π    σ     exp   [   -     (   x  -  μ   )   2    2   σ  2      ]     [   1  +     κ  3     3  !    σ  3      H  3    (    x  -  μ   σ   )    +     κ  4     4  !    σ  4      H  4    (    x  -  μ   σ   )     ]     ,        F  x       1        2  π    σ           superscript    x  μ   2     2   superscript  σ  2        delimited-[]    1       subscript  κ  3       3    superscript  σ  3      subscript  H  3       x  μ   σ         subscript  κ  4       4    superscript  σ  4      subscript  H  4       x  μ   σ         F(x)\approx\frac{1}{\sqrt{2\pi}\sigma}\exp\left[-\frac{(x-\mu)^{2}}{2\sigma^{2%
 }}\right]\left[1+\frac{\kappa_{3}}{3!\sigma^{3}}H_{3}\left(\frac{x-\mu}{\sigma%
 }\right)+\frac{\kappa_{4}}{4!\sigma^{4}}H_{4}\left(\frac{x-\mu}{\sigma}\right)%
 \right]\,,     with      H  3    (  x  )    =    x  3   -   3  x           subscript  H  3   x      superscript  x  3     3  x      H_{3}(x)=x^{3}-3x   and      H  4    (  x  )    =     x  4   -   6   x  2     +  3          subscript  H  4   x        superscript  x  4     6   superscript  x  2     3     H_{4}(x)=x^{4}-6x^{2}+3   (these are Hermite polynomials ).  Note that this expression is not guaranteed to be positive, and is therefore not a valid probability distribution. The Gram–Charlier A series diverges in many cases of interest—it converges only if    F   (  x  )       F  x    F(x)   falls off faster than    exp   (   -    (   x  2   )   /  4    )            superscript  x  2   4      \exp(-(x^{2})/4)   at infinity (Cramér 1957). When it does not converge, the series is also not a true asymptotic expansion , because it is not possible to estimate the error of the expansion. For this reason, the Edgeworth series (see next section) is generally preferred over the Gram–Charlier A series.  Edgeworth developed a similar expansion as an improvement to the central limit theorem . 4 The advantage of the Edgeworth series is that the error is controlled, so that it is a true asymptotic expansion .  Let { X i } be a sequence of independent and identically distributed random variables with mean μ and variance σ 2 , and let Y n be their standardized sums:        Y  n   =    1   n      ∑   i  =  1   n      X  i   -  μ   σ      .       subscript  Y  n       1    n      superscript   subscript     i  1    n        subscript  X  i   μ   σ       Y_{n}=\frac{1}{\sqrt{n}}\sum_{i=1}^{n}\frac{X_{i}-\mu}{\sigma}.     Let F n denote the cumulative distribution functions of the variables Y n . Then by the central limit theorem,        lim   n  →  ∞      F  n    (  x  )     =   Φ   (  x  )    ≡    ∫   -  ∞   x      1    2  π       e   -    1  2    q  2      d  q            subscript    normal-→  n        subscript  F  n   x      normal-Φ  x          superscript   subscript        x       1      2  π      superscript  e        1  2    superscript  q  2      d  q       \lim_{n\to\infty}F_{n}(x)=\Phi(x)\equiv\int_{-\infty}^{x}\tfrac{1}{\sqrt{2\pi}%
 }e^{-\frac{1}{2}q^{2}}dq     for every x , as long as the mean and variance are finite.  Now assume that the random variables X i have mean μ, variance σ 2 , and higher cumulants κ r =σ r λ r . If we expand in terms of the standard normal distribution, that is, if we set       Ψ   (  x  )    =    1    2  π      exp   (   -     1  2     x  2     )           normal-Ψ  x       1      2  π             1  2    superscript  x  2         \Psi(x)=\frac{1}{\sqrt{2\pi}}\exp(-\tfrac{1}{2}x^{2})     then the cumulant differences in the formal expression of the characteristic function f n ( t ) of F n are         κ  1   F   (  n  )     -   γ  1    =  0   ,         subscript   superscript  κ    F  n    1    subscript  γ  1    0    \kappa^{F(n)}_{1}-\gamma_{1}=0,            κ  2   F   (  n  )     -   γ  2    =  0   ,         subscript   superscript  κ    F  n    2    subscript  γ  2    0    \kappa^{F(n)}_{2}-\gamma_{2}=0,            κ  r   F   (  n  )     -   γ  r    =    κ  r     σ  r    n    r  /  2   -  1      =    λ  r    n    r  /  2   -  1      ;   r  ≥  3.      formulae-sequence         subscript   superscript  κ    F  n    r    subscript  γ  r       subscript  κ  r      superscript  σ  r    superscript  n      r  2   1              subscript  λ  r    superscript  n      r  2   1         r  3.     \kappa^{F(n)}_{r}-\gamma_{r}=\frac{\kappa_{r}}{\sigma^{r}n^{r/2-1}}=\frac{%
 \lambda_{r}}{n^{r/2-1}};\qquad r\geq 3.     The Edgeworth series is developed similarly to the Gram–Charlier A series, only that now terms are collected according to powers of n . Thus, we have         f  n    (  t  )    =    [   1  +    ∑   j  =  1   ∞      P  j    (   i  t   )     n   j  /  2       ]    exp   (   -    t  2   /  2    )      ,         subscript  f  n   t      delimited-[]    1    superscript   subscript     j  1           subscript  P  j     i  t     superscript  n    j  2               superscript  t  2   2        f_{n}(t)=\left[1+\sum_{j=1}^{\infty}\frac{P_{j}(it)}{n^{j/2}}\right]\exp(-t^{2%
 }/2)\,,     where P j ( x ) is a polynomial of degree 3 j . Again, after inverse Fourier transform, the density function F n follows as         F  n    (  x  )    =    Φ   (  x  )    +    ∑   j  =  1   ∞       P  j    (   -  D   )     n   j  /  2     Φ   (  x  )       .         subscript  F  n   x       normal-Φ  x     superscript   subscript     j  1             subscript  P  j     D     superscript  n    j  2     normal-Φ  x       F_{n}(x)=\Phi(x)+\sum_{j=1}^{\infty}\frac{P_{j}(-D)}{n^{j/2}}\Phi(x)\,.     The first five terms of the expansion are 5       F  n    (  x  )        subscript  F  n   x    \displaystyle F_{n}(x)     Here, is the j -th derivative of    Φ   (  ·  )       normal-Φ  normal-·    Φ(·)   at point x . Remembering that the derivatives of the density of the normal distribution are related to the normal density by ϕ ( n ) ( x )=(-1) n H n ( x ) ϕ ( x ), (where H n is the Hermite polynomial of order n ), this explains the alternative representations in terms of the density function. Blinnikov and Moessner (1998) have given a simple algorithm to calculate higher-order terms of the expansion.  Note that in case of a lattice distributions (which have discrete values), the Edgeworth expansion must be adjusted to account for the discontinuous jumps between lattice points. 6  Illustration: density of the sample mean of 3 Χ²  (Figure)  Density of the sample mean of three chi2 variables. The chart compares the true density, the normal approximation, and two edgeworth expansions   Take     X  i   ∼   χ  2    (  k  =  2  )   i  =  1  ,  2  ,  3     fragments   subscript  X  i   similar-to   superscript  χ  2    fragments  normal-(  k   2  normal-)   italic-  i   1  normal-,  2  normal-,  3    X_{i}\sim\chi^{2}(k=2)\qquad i=1,2,3   and the sample mean     X  ¯   =    1  3     ∑   i  =  1   3    X  i          normal-¯  X       1  3     superscript   subscript     i  1    3    subscript  X  i       \bar{X}=\frac{1}{3}\sum_{i=1}^{3}X_{i}   .  We can use several distributions for    X  ¯     normal-¯  X    \bar{X}   :   The exact distribution, which follows a gamma distribution      X  ¯   ∼  Gamma   (  α  =  n  ⋅  k  /  2  ,  θ  =  2  /  n  )      fragments   normal-¯  X   similar-to  Gamma   fragments  normal-(  α   n  normal-⋅  k   2  normal-,  θ   2   n  normal-)     \bar{X}\sim\mathrm{Gamma}\left(\alpha=n\cdot k/2,\theta=2/n\right)   =    Gamma   (  α  =  3  ,  θ  =  2  /  3  )      fragments  Gamma   fragments  normal-(  α   3  normal-,  θ   2   3  normal-)     \mathrm{Gamma}\left(\alpha=3,\theta=2/3\right)     The asymptotic normal distribution     X  ¯    →   n  →  ∞     N   (  k  ,    2  ⋅  k   /  n   )    =   N   (  2  ,   4  /  3   )           normal-→  n    normal-→    normal-¯  X     N   k     normal-⋅  2  k   n            N   2    4  3        \bar{X}\xrightarrow{n\to\infty}N(k,2\cdot k/n)=N(2,4/3)     Two Edgeworth expansion, of degree 2 and 3   Disadvantages of the Edgeworth expansion  Edgeworth expansions can suffer from a few issues:   They are not guaranteed to be a proper probability distribution as:  The integral of the density needs not integrate to 1  Probabilities can be negative   They can be inaccurate, especially in the tails, due to mainly two reasons:  They are obtained under a Taylor series around the mean  They guarantee (asymptotically) an absolute error , not a relative one. This is an issue when one wants to approximate very small quantities, for which the absolute error might be small, but the relative error important.    See also   Cornish–Fisher expansion  Edgeworth binomial tree   References  Further reading   H. Cramér . (1957). Mathematical Methods of Statistics . Princeton University Press, Princeton.  D. L. Wallace. (1958). "Asymptotic approximations to distributions". Annals of Mathematical Statistics , 29 : 635–654.  M. Kendall & A. Stuart. (1977), The advanced theory of statistics , Vol 1: Distribution theory, 4th Edition, Macmillan, New York.  P. McCullagh (1987). Tensor Methods in Statistics . Chapman and Hall, London.  D. R. Cox and O. E. Barndorff-Nielsen (1989). Asymptotic Techniques for Use in Statistics . Chapman and Hall, London.  P. Hall (1992). The Bootstrap and Edgeworth Expansion . Springer, New York.   S. Blinnikov and R. Moessner (1998). Expansions for nearly Gaussian distributions . Astronomy and astrophysics Supplement series , 130 : 193–205.  J. E. Kolassa (2006). Series Approximation Methods in Statistics (3rd ed.). (Lecture Notes in Statistics #88). Springer, New York.   "  Category:Mathematical series  Category:Statistical theory  Category:Statistical approximations     Stuart, A., & Kendall, M. G. (1968). The advanced theory of statistics. Hafner Publishing Company. ↩  Kolassa, J. E. (2006). Series approximation methods in statistics (Vol. 88). Springer Science & Business Media. ↩  Wallace, D. L. (1958). Asymptotic approximations to distributions. The Annals of Mathematical Statistics, 635-654. ↩  Hall, P. (2013). The bootstrap and Edgeworth expansion. Springer Science & Business Media. ↩  ↩  ↩     