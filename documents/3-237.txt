   Dimension theorem for vector spaces      Dimension theorem for vector spaces   In mathematics , the dimension theorem for vector spaces states that all bases of a vector space have equally many elements. This number of elements may be finite, or given by an infinite cardinal number , and defines the dimension of the space.  Formally, the dimension theorem for vector spaces states that   Given a vector space  V , any two linearly independent  generating sets (in other words, any two bases) have the same cardinality .   If V is finitely generated , then it has a finite basis, and the result says that any two bases have the same number of elements.  While the proof of the existence of a basis for any vector space in the general case requires Zorn's lemma and is in fact equivalent to the axiom of choice , the uniqueness of the cardinality of the basis requires only the ultrafilter lemma , 1 which is strictly weaker (the proof given below, however, assumes trichotomy , i.e., that all cardinal numbers are comparable, a statement which is also equivalent to the axiom of choice). The theorem can be generalized to arbitrary R -modules for rings R having invariant basis number .  The theorem for finitely generated case can be proved with elementary arguments of linear algebra , and requires no forms of the axiom of choice.  Proof  Assume that { a i : i ∈ I } and { b j : j ∈ J } are both bases, with the cardinality of I bigger than the cardinality of J . From this assumption we will derive a contradiction.  Case 1  Assume that I is infinite.  Every b j can be written as a finite sum       b  j   =    ∑   i  ∈   E  j       λ   i  ,  j     a  i          subscript  b  j     subscript     i   subscript  E  j        subscript  λ   i  j     subscript  a  i       b_{j}=\sum_{i\in E_{j}}\lambda_{i,j}a_{i}   , where    E  j     subscript  E  j    E_{j}   is a finite subset of   I   I   I   . Since the cardinality of I is greater than that of J and the E j 's are finite subsets of I , the cardinality of I is also bigger than the cardinality of     ⋃   j  ∈  J     E  j       subscript     j  J     subscript  E  j     \bigcup_{j\in J}E_{j}   . (Note that this argument works only for infinite I .) So there is some     i  0   ∈  I       subscript  i  0   I    i_{0}\in I   which does not appear in any    E  j     subscript  E  j    E_{j}   . The corresponding    a   i  0      subscript  a   subscript  i  0     a_{i_{0}}   can be expressed as a finite linear combination of    b  j     subscript  b  j    b_{j}   's, which in turn can be expressed as finite linear combination of    a  i     subscript  a  i    a_{i}   's, not involving    a   i  0      subscript  a   subscript  i  0     a_{i_{0}}   . Hence    a   i  0      subscript  a   subscript  i  0     a_{i_{0}}   is linearly dependent on the other    a  i     subscript  a  i    a_{i}   's.  Case 2  Now assume that I is finite and of cardinality bigger than the cardinality of J . Write m and n for the cardinalities of I and J , respectively. Every a i can be written as a sum       a  i   =    ∑   j  ∈  J      μ   i  ,  j     b  j          subscript  a  i     subscript     j  J       subscript  μ   i  j     subscript  b  j       a_{i}=\sum_{j\in J}\mu_{i,j}b_{j}   The matrix    (    μ   i  ,  j    :    i  ∈  I   ,   j  ∈  J     )     normal-:   subscript  μ   i  j     formulae-sequence    i  I     j  J      (\mu_{i,j}:i\in I,j\in J)   has n columns (the j -th column is the m -tuple    (    μ   i  ,  j    :   i  ∈  I    )     normal-:   subscript  μ   i  j      i  I     (\mu_{i,j}:i\in I)   ), so it has rank at most n . This means that its m rows cannot be linearly independent . Write     r  i   =   (   μ   i  ,  j    :  j  ∈  J  )      fragments   subscript  r  i     fragments  normal-(   subscript  μ   i  j    normal-:  j   J  normal-)     r_{i}=(\mu_{i,j}:j\in J)   for the i -th row, then there is a nontrivial linear combination        ∑   i  ∈  I      ν  i    r  i     =  0        subscript     i  I       subscript  ν  i    subscript  r  i     0    \sum_{i\in I}\nu_{i}r_{i}=0   But then also       ∑   i  ∈  I      ν  i    a  i     =    ∑   i  ∈  I      ν  i     ∑   j  ∈  J      μ   i  ,  j     b  j       =    ∑   j  ∈  J      (    ∑   i  ∈  I      ν  i    μ   i  ,  j      )    b  j     =  0   ,          subscript     i  I       subscript  ν  i    subscript  a  i       subscript     i  I       subscript  ν  i     subscript     j  J       subscript  μ   i  j     subscript  b  j              subscript     j  J        subscript     i  I       subscript  ν  i    subscript  μ   i  j       subscript  b  j          0     \sum_{i\in I}\nu_{i}a_{i}=\sum_{i\in I}\nu_{i}\sum_{j\in J}\mu_{i,j}b_{j}=\sum%
 _{j\in J}\biggl(\sum_{i\in I}\nu_{i}\mu_{i,j}\biggr)b_{j}=0,   so the    a  i     subscript  a  i    a_{i}   are linearly dependent.  Alternative Proof  The proof above uses several non-trivial results. If these results are not carefully established in advance, the proof may give rise to circular reasoning. Here is a proof of the finite case which requires less prior development.  Theorem 1: If    A  =   (   a  1   ,  …  ,   a  n   )   ⊆  V        A    subscript  a  1   normal-…   subscript  a  n         V     A=(a_{1},\dots,a_{n})\subseteq V   is a linearly independent tuple in a vector space   V   V   V   , and     B  0   =   (   b  1   ,  …  ,   b  r   )        subscript  B  0     subscript  b  1   normal-…   subscript  b  r      B_{0}=(b_{1},...,b_{r})   is a tuple that spans    V   V   V   , then    n  ≤  r      n  r    n\leq r   . 2 The argument is as follows:  Since    B  0     subscript  B  0    B_{0}   spans   V   V   V   , the tuple    (   a  1   ,   b  1   ,  …  ,   b  r   )      subscript  a  1    subscript  b  1   normal-…   subscript  b  r     (a_{1},b_{1},\dots,b_{r})   also spans. Since     a  1   ≠  0       subscript  a  1   0    a_{1}\neq 0   (because   A   A   A   is linearly independent), there is at least one    t  ∈   {  1  ,  …  ,  r  }       t   1  normal-…  r     t\in\{1,\ldots,r\}   such that    b  t     subscript  b  t    b_{t}   can be written as a linear combination of     B  1   =   (   a  1   ,   b  1   ,  …  ,   b   t  -  1    ,   b   t  +  1    ,   …   b  r    )        subscript  B  1     subscript  a  1    subscript  b  1   normal-…   subscript  b    t  1     subscript  b    t  1      normal-…   subscript  b  r       B_{1}=(a_{1},b_{1},\dots,b_{t-1},b_{t+1},...b_{r})   . Thus,    B  1     subscript  B  1    B_{1}   is a spanning tuple , and its length is the same as    B  0     subscript  B  0    B_{0}   's.  Repeat this process. Because   A   A   A   is linearly independent, we can always remove an element from the list    B  i     subscript  B  i    B_{i}   which is not one of the    a  j     subscript  a  j    a_{j}   's that we prepended to the list in a prior step (because   A   A   A   is linearly independent, and so there must be some nonzero coefficient in front of one of the    b  i     subscript  b  i    b_{i}   's). Thus, after   n   n   n   iterations, the result will be a tuple     B  n   =   (   a  1   ,  …  ,   a  n   ,   b   m  1    ,  …  ,   b   m  k    )        subscript  B  n     subscript  a  1   normal-…   subscript  a  n    subscript  b   subscript  m  1    normal-…   subscript  b   subscript  m  k       B_{n}=(a_{1},\ldots,a_{n},b_{m_{1}},\ldots,b_{m_{k}})   (possibly with    k  =  0      k  0    k=0   ) of length   r   r   r   . In particular,    A  ⊆   B  n       A   subscript  B  n     A\subseteq B_{n}   , so     |  A  |   ≤   |   B  n   |         A      subscript  B  n      |A|\leq|B_{n}|   , i.e.,    n  ≤  r      n  r    n\leq r   .  To prove the finite case of the dimension theorem from this, suppose that   V   V   V   is a vector space and    S  =   {   v  1   ,  …  ,   v  n   }       S    subscript  v  1   normal-…   subscript  v  n      S=\{v_{1},\ldots,v_{n}\}   and    T  =   {   w  1   ,  …  ,   w  m   }       T    subscript  w  1   normal-…   subscript  w  m      T=\{w_{1},\ldots,w_{m}\}   are both bases of   V   V   V   . Since   S   S   S   is linearly independent and   T   T   T   spans, we can apply Theorem 1 to get    m  ≥  n      m  n    m\geq n   . And since   T   T   T   is linearly independent and   S   S   S   spans, we get    n  ≥  m      n  m    n\geq m   . From these, we get    m  =  n      m  n    m=n   .  Kernel extension theorem for vector spaces  This application of the dimension theorem is sometimes itself called the dimension theorem . Let   T : U → V    be a linear transformation . Then   dim ( range ( T )) + dim ( kernel ( T )) = dim ( U ),   that is, the dimension of U is equal to the dimension of the transformation's range plus the dimension of the kernel . See rank-nullity theorem for a fuller discussion.  References    "  Category:Theorems in abstract algebra  Category:Theorems in linear algebra  Category:Articles containing proofs     Howard, P., Rubin, J.: "Consequences of the axiom of choice" - Mathematical Surveys and Monographs, vol 59 (1998) ISSN 0076-5376. ↩  S. Axler, "Linear Algebra Done Right," Springer, 2000. ↩     