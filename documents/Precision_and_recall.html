<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="276">Precision and recall</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>Precision and recall</h1>
<hr/>

<p> In <a href="pattern_recognition" title="wikilink">pattern recognition</a> and <a href="information_retrieval" title="wikilink">information retrieval</a> with <a href="binary_classification" title="wikilink">binary classification</a>, <strong>precision</strong> (also called <a href="positive_predictive_value" title="wikilink">positive predictive value</a>) is the fraction of retrieved instances that are relevant, while <strong>recall</strong> (also known as <a href="Sensitivity_and_specificity" title="wikilink">sensitivity</a>) is the fraction of relevant instances that are retrieved. Both precision and recall are therefore based on an understanding and measure of <a class="uri" href="relevance" title="wikilink">relevance</a>. Suppose a program for recognizing dogs in scenes from a video identifies 7 dogs in a scene containing 9 dogs and some cats. If 4 of the identifications are correct, but 3 are actually cats, the program's precision is 4/7 while its recall is 4/9. When a <a href="Search_engine_(computing)" title="wikilink">search engine</a> returns 30 pages only 20 of which were relevant while failing to return 40 additional relevant pages, its precision is 20/30 = 2/3 while its recall is 20/60 = 1/3.</p>

<p>In <a class="uri" href="statistics" title="wikilink">statistics</a>, if the <a href="null_hypothesis" title="wikilink">null hypothesis</a> is that all and only the relevant items are retrieved, absence of <a href="type_I_and_type_II_errors" title="wikilink">type I and type II errors</a> corresponds respectively to maximum precision (no false positive) and maximum recall (no false negative). The above pattern recognition example contained 7 − 4 = 3 type I errors and 9 − 4 = 5 type II errors. Precision can be seen as a measure of exactness or <em>quality</em>, whereas recall is a measure of completeness or <em>quantity</em>.</p>

<p>In simple terms, high <strong>precision</strong> means that an algorithm returned substantially more relevant results than irrelevant, while high <strong>recall</strong> means that an algorithm returned most of the relevant results.</p>
<h2 id="introduction">Introduction</h2>

<p>As an example, in an <a href="information_retrieval" title="wikilink">information retrieval</a> scenario, the instances are documents and the task is to return a set of relevant documents given a search term; or equivalently, to assign each document to one of two categories, "relevant" and "not relevant". In this case, the "relevant" documents are simply those that belong to the "relevant" category. Recall is defined as the <em>number of relevant documents</em> retrieved by a search <em>divided by the total number of existing relevant documents</em>, while precision is defined as the <em>number of relevant documents</em> retrieved by a search <em>divided by the total number of documents retrieved</em> by that search.</p>

<p>In a <a href="classification_(machine_learning)" title="wikilink">classification</a> task, the precision for a class is the <em>number of <strong>true positives</strong></em> (i.e. the <em>number of items correctly labeled as belonging to the positive class</em>) <em>divided by the total number of elements labeled as belonging to the positive class</em> (i.e. the sum of true positives and <strong><a href="Type_I_and_type_II_errors" title="wikilink">false positives</a></strong>, which are items incorrectly labeled as belonging to the class). Recall in this context is defined as the <em>number of true positives</em> <em>divided by the total number of elements that actually belong to the positive class</em> (i.e. the sum of true positives and <strong><a href="Type_I_and_type_II_errors" title="wikilink">false negatives</a></strong>, which are items which were not labeled as belonging to the positive class but should have been).</p>

<p>In information retrieval, a perfect precision score of 1.0 means that every result retrieved by a search was relevant (but says nothing about whether all relevant documents were retrieved) whereas a perfect recall score of 1.0 means that all relevant documents were retrieved by the search (but says nothing about how many irrelevant documents were also retrieved).</p>

<p>In a classification task, a precision score of 1.0 for a class C means that every item labeled as belonging to class C does indeed belong to class C (but says nothing about the number of items from class C that were not labeled correctly) whereas a recall of 1.0 means that every item from class C was labeled as belonging to class C (but says nothing about how many other items were incorrectly also labeled as belonging to class C).</p>

<p>Often, there is an inverse relationship between precision and recall, where it is possible to increase one at the cost of reducing the other. Brain surgery provides an obvious example of the tradeoff. Consider a brain surgeon tasked with removing a cancerous tumor from a patient’s brain. The surgeon needs to remove all of the tumor cells since any remaining cancer cells will regenerate the tumor. Conversely, the surgeon must not remove healthy brain cells since that would leave the patient with impaired brain function. The surgeon may be more liberal in the area of the brain she removes to ensure she has extracted all the cancer cells. This decision increases recall but reduces precision. On the other hand, the surgeon may be more conservative in the brain she removes to ensure she extracts only cancer cells. This decision increases precision but reduces recall. That is to say, greater recall increases the chances of removing healthy cells (negative outcome) and increases the chances of removing all cancer cells (positive outcome). Greater precision decreases the chances of removing healthy cells (positive outcome) but also decreases the chances of removing all cancer cells (negative outcome).</p>

<p>Usually, precision and recall scores are not discussed in isolation. Instead, either values for one measure are compared for a fixed level at the other measure (e.g. <em>precision at a recall level of 0.75</em>) or both are combined into a single measure. Examples for measures that are a combination of precision and recall are the <a href="Precision_and_recall#F-measure" title="wikilink">F-measure</a> (the weighted <a href="harmonic_mean" title="wikilink">harmonic mean</a> of precision and recall), or the <a href="Matthews_correlation_coefficient" title="wikilink">Matthews correlation coefficient</a>, which is a <a href="geometric_mean" title="wikilink">geometric mean</a> of the chance-corrected variants: the <a href="regression_coefficient" title="wikilink">regression coefficients</a> Informedness (DeltaP') and Markedness (DeltaP).<a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a><a class="footnoteRef" href="#fn2" id="fnref2"><sup>2</sup></a> <a href="Accuracy_and_precision#In_binary_classification" title="wikilink">Accuracy</a> is a weighted arithmetic mean of Precision and Inverse Precision (weighted by Bias) as well as a weighted arithmetic mean of Recall and Inverse Recall (weighted by Prevalence).<a class="footnoteRef" href="#fn3" id="fnref3"><sup>3</sup></a> Inverse Precision and Recall are simply the Precision and Recall of the inverse problem where positive and negative labels are exchanged (for both real classes and prediction labels). Recall and Inverse Recall, or equivalently true positive rate and false positive rate, are frequently plotted against each other as <a href="Receiver_operating_characteristic" title="wikilink">ROC</a> curves and provide a principled mechanism to explore operating point tradeoffs. Outside of Information Retrieval, the application of Recall, Precision and F-measure are argued to be flawed as they ignore the true negative cell of the contingency table, and they are easily manipulated by biasing the predictions.<a class="footnoteRef" href="#fn4" id="fnref4"><sup>4</sup></a> The first problem is 'solved' by using <a href="Accuracy_and_precision#In_binary_classification" title="wikilink">Accuracy</a> and the second problem is 'solved' by discounting the chance component and renormalizing to <a href="Cohen's_kappa" title="wikilink">Cohen's kappa</a>, but this no longer affords the opportunity to explore tradeoffs graphically. However, Informedness and Markedness are Kappa-like renormalizations of Recall and Precision,<a class="footnoteRef" href="#fn5" id="fnref5"><sup>5</sup></a> and their geometric mean <a href="Matthews_correlation_coefficient" title="wikilink">Matthews correlation coefficient</a> thus acts like a debiased F-measure.</p>
<h2 id="definition-information-retrieval-context">Definition (information retrieval context)</h2>

<p>In <a href="information_retrieval" title="wikilink">information retrieval</a> contexts, precision and recall are defined in terms of a set of <strong>retrieved documents</strong> (e.g. the list of documents produced by a <a href="web_search_engine" title="wikilink">web search engine</a> for a query) and a set of <strong>relevant documents</strong> (e.g. the list of all documents on the internet that are relevant for a certain topic), cf. <a class="uri" href="relevance" title="wikilink">relevance</a>.</p>
<h3 id="precision"><a href="Positive_predictive_value" title="wikilink"> Precision</a></h3>

<p>In the field of <a href="information_retrieval" title="wikilink">information retrieval</a>, <strong>precision</strong> is the fraction of retrieved documents that are <a href="Relevance_(information_retrieval)" title="wikilink">relevant</a> to the query:</p>

<p>

<math display="block" id="Precision_and_recall:0">
 <semantics>
  <mrow>
   <mtext>precision</mtext>
   <mo>=</mo>
   <mfrac>
    <mrow>
     <mo stretchy="false">|</mo>
     <mrow>
      <mrow>
       <mo stretchy="false">{</mo>
       <mtext>relevant documents</mtext>
       <mo stretchy="false">}</mo>
      </mrow>
      <mo>∩</mo>
      <mrow>
       <mo stretchy="false">{</mo>
       <mtext>retrieved documents</mtext>
       <mo stretchy="false">}</mo>
      </mrow>
     </mrow>
     <mo stretchy="false">|</mo>
    </mrow>
    <mrow>
     <mo stretchy="false">|</mo>
     <mrow>
      <mo stretchy="false">{</mo>
      <mtext>retrieved documents</mtext>
      <mo stretchy="false">}</mo>
     </mrow>
     <mo stretchy="false">|</mo>
    </mrow>
   </mfrac>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <mtext>precision</mtext>
    <apply>
     <divide></divide>
     <apply>
      <abs></abs>
      <apply>
       <intersect></intersect>
       <set>
        <mtext>relevant documents</mtext>
       </set>
       <set>
        <mtext>retrieved documents</mtext>
       </set>
      </apply>
     </apply>
     <apply>
      <abs></abs>
      <set>
       <mtext>retrieved documents</mtext>
      </set>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \text{precision}=\frac{|\{\text{relevant documents}\}\cap\{\text{retrieved %
documents}\}|}{|\{\text{retrieved documents}\}|}
  </annotation>
 </semantics>
</math>

</p>

<p>Precision takes all retrieved documents into account, but it can also be evaluated at a given cut-off rank, considering only the topmost results returned by the system. This measure is called <strong>precision at n</strong> or <strong>P@n</strong>.</p>

<p>For example for a text search on a set of documents precision is the number of correct results divided by the number of all returned results.</p>

<p>Precision is also used with <a href="recall_(information_retrieval)" title="wikilink">recall</a>, the percent of <em>all</em> relevant documents that is returned by the search. The two measures are sometimes used together in the <a href="F1_Score" title="wikilink">F1 Score</a> (or f-measure) to provide a single measurement for a system.</p>

<p>Note that the meaning and usage of "precision" in the field of Information Retrieval differs from the definition of <a href="accuracy_and_precision" title="wikilink">accuracy and precision</a> within other branches of science and technology.</p>
<h3 id="recall">Recall</h3>

<p>Recall in information retrieval is the fraction of the documents that are relevant to the query that are successfully retrieved.</p>

<p>

<math display="block" id="Precision_and_recall:1">
 <semantics>
  <mrow>
   <mtext>recall</mtext>
   <mo>=</mo>
   <mfrac>
    <mrow>
     <mo stretchy="false">|</mo>
     <mrow>
      <mrow>
       <mo stretchy="false">{</mo>
       <mtext>relevant documents</mtext>
       <mo stretchy="false">}</mo>
      </mrow>
      <mo>∩</mo>
      <mrow>
       <mo stretchy="false">{</mo>
       <mtext>retrieved documents</mtext>
       <mo stretchy="false">}</mo>
      </mrow>
     </mrow>
     <mo stretchy="false">|</mo>
    </mrow>
    <mrow>
     <mo stretchy="false">|</mo>
     <mrow>
      <mo stretchy="false">{</mo>
      <mtext>relevant documents</mtext>
      <mo stretchy="false">}</mo>
     </mrow>
     <mo stretchy="false">|</mo>
    </mrow>
   </mfrac>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <mtext>recall</mtext>
    <apply>
     <divide></divide>
     <apply>
      <abs></abs>
      <apply>
       <intersect></intersect>
       <set>
        <mtext>relevant documents</mtext>
       </set>
       <set>
        <mtext>retrieved documents</mtext>
       </set>
      </apply>
     </apply>
     <apply>
      <abs></abs>
      <set>
       <mtext>relevant documents</mtext>
      </set>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \text{recall}=\frac{|\{\text{relevant documents}\}\cap\{\text{retrieved %
documents}\}|}{|\{\text{relevant documents}\}|}
  </annotation>
 </semantics>
</math>

</p>

<p>For example for text search on a set of documents recall is the number of correct results divided by the number of results that should have been returned</p>

<p>In binary classification, recall is called <a href="Sensitivity_and_specificity#Sensitivity" title="wikilink">sensitivity</a>. So it can be looked at as the probability that a relevant document is retrieved by the query.</p>

<p>It is trivial to achieve recall of 100% by returning all documents in response to any query. Therefore, recall alone is not enough but one needs to measure the number of non-relevant documents also, for example by computing the precision.</p>
<h2 id="definition-classification-context">Definition (classification context)</h2>
<table>
<tbody>
<tr class="odd">
<td style="text-align: left;">
<p>Terminology and derivations<br/>
from a confusion matrix</p></td>
</tr>
<tr class="even">
<td style="text-align: left;"><dl>
<dt>true positive (TP)</dt>
<dd>eqv. with hit
</dd>
<dt>true negative (TN)</dt>
<dd>eqv. with correct rejection
</dd>
<dt>false positive (FP)</dt>
<dd>eqv. with <a href="false_alarm" title="wikilink">false alarm</a>, <a href="Type_I_error" title="wikilink">Type I error</a>
</dd>
<dt>false negative (FN)</dt>
<dd>eqv. with miss, <a href="Type_II_error" title="wikilink">Type II error</a>
</dd>
</dl>
<hr/>
<dl>
<dt><a href="sensitivity_(test)" title="wikilink">sensitivity</a> or true positive rate (TPR)</dt>
<dd>eqv. with <a href="hit_rate" title="wikilink">hit rate</a>, <a href="Information_retrieval#Recall" title="wikilink">recall</a>
</dd>
<dd>

<math display="inline" id="Precision_and_recall:2">
 <semantics>
  <mrow>
   <mi>𝑇𝑃𝑅</mi>
   <mo>=</mo>
   <mrow>
    <mi>𝑇𝑃</mi>
    <mo>/</mo>
    <mi>P</mi>
   </mrow>
   <mo>=</mo>
   <mrow>
    <mi>𝑇𝑃</mi>
    <mo>/</mo>
    <mrow>
     <mo stretchy="false">(</mo>
     <mrow>
      <mi>𝑇𝑃</mi>
      <mo>+</mo>
      <mi>𝐹𝑁</mi>
     </mrow>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <and></and>
    <apply>
     <eq></eq>
     <ci>𝑇𝑃𝑅</ci>
     <apply>
      <divide></divide>
      <ci>𝑇𝑃</ci>
      <ci>P</ci>
     </apply>
    </apply>
    <apply>
     <eq></eq>
     <share href="#.cmml">
     </share>
     <apply>
      <divide></divide>
      <ci>𝑇𝑃</ci>
      <apply>
       <plus></plus>
       <ci>𝑇𝑃</ci>
       <ci>𝐹𝑁</ci>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \mathit{TPR}=\mathit{TP}/P=\mathit{TP}/(\mathit{TP}+\mathit{FN})
  </annotation>
 </semantics>
</math>


</dd>
<dt><a href="Specificity_(tests)" title="wikilink">specificity</a> (SPC) or true negative rate (TNR)</dt>
<dd>

<math display="inline" id="Precision_and_recall:3">
 <semantics>
  <mrow>
   <mi>𝑆𝑃𝐶</mi>
   <mo>=</mo>
   <mrow>
    <mi>𝑇𝑁</mi>
    <mo>/</mo>
    <mi>N</mi>
   </mrow>
   <mo>=</mo>
   <mrow>
    <mi>𝑇𝑁</mi>
    <mo>/</mo>
    <mrow>
     <mo stretchy="false">(</mo>
     <mrow>
      <mi>𝑇𝑁</mi>
      <mo>+</mo>
      <mi>𝐹𝑃</mi>
     </mrow>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <and></and>
    <apply>
     <eq></eq>
     <ci>𝑆𝑃𝐶</ci>
     <apply>
      <divide></divide>
      <ci>𝑇𝑁</ci>
      <ci>N</ci>
     </apply>
    </apply>
    <apply>
     <eq></eq>
     <share href="#.cmml">
     </share>
     <apply>
      <divide></divide>
      <ci>𝑇𝑁</ci>
      <apply>
       <plus></plus>
       <ci>𝑇𝑁</ci>
       <ci>𝐹𝑃</ci>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \mathit{SPC}=\mathit{TN}/N=\mathit{TN}/(\mathit{TN}+\mathit{FP})
  </annotation>
 </semantics>
</math>


</dd>
<dt><a href="Information_retrieval#Precision" title="wikilink">precision</a> or <a href="positive_predictive_value" title="wikilink">positive predictive value</a> (PPV)</dt>
<dd>

<math display="inline" id="Precision_and_recall:4">
 <semantics>
  <mrow>
   <mi>𝑃𝑃𝑉</mi>
   <mo>=</mo>
   <mrow>
    <mi>𝑇𝑃</mi>
    <mo>/</mo>
    <mrow>
     <mo stretchy="false">(</mo>
     <mrow>
      <mi>𝑇𝑃</mi>
      <mo>+</mo>
      <mi>𝐹𝑃</mi>
     </mrow>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <ci>𝑃𝑃𝑉</ci>
    <apply>
     <divide></divide>
     <ci>𝑇𝑃</ci>
     <apply>
      <plus></plus>
      <ci>𝑇𝑃</ci>
      <ci>𝐹𝑃</ci>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \mathit{PPV}=\mathit{TP}/(\mathit{TP}+\mathit{FP})
  </annotation>
 </semantics>
</math>


</dd>
<dt><a href="negative_predictive_value" title="wikilink">negative predictive value</a> (NPV)</dt>
<dd>

<math display="inline" id="Precision_and_recall:5">
 <semantics>
  <mrow>
   <mi>𝑁𝑃𝑉</mi>
   <mo>=</mo>
   <mrow>
    <mi>𝑇𝑁</mi>
    <mo>/</mo>
    <mrow>
     <mo stretchy="false">(</mo>
     <mrow>
      <mi>𝑇𝑁</mi>
      <mo>+</mo>
      <mi>𝐹𝑁</mi>
     </mrow>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <ci>𝑁𝑃𝑉</ci>
    <apply>
     <divide></divide>
     <ci>𝑇𝑁</ci>
     <apply>
      <plus></plus>
      <ci>𝑇𝑁</ci>
      <ci>𝐹𝑁</ci>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \mathit{NPV}=\mathit{TN}/(\mathit{TN}+\mathit{FN})
  </annotation>
 </semantics>
</math>


</dd>
<dt><a href="Information_retrieval#Fall-out" title="wikilink">fall-out</a> or false positive rate (FPR)</dt>
<dd>

<math display="inline" id="Precision_and_recall:6">
 <semantics>
  <mrow>
   <mi>𝐹𝑃𝑅</mi>
   <mo>=</mo>
   <mrow>
    <mi>𝐹𝑃</mi>
    <mo>/</mo>
    <mi>N</mi>
   </mrow>
   <mo>=</mo>
   <mrow>
    <mi>𝐹𝑃</mi>
    <mo>/</mo>
    <mrow>
     <mo stretchy="false">(</mo>
     <mrow>
      <mi>𝐹𝑃</mi>
      <mo>+</mo>
      <mi>𝑇𝑁</mi>
     </mrow>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <and></and>
    <apply>
     <eq></eq>
     <ci>𝐹𝑃𝑅</ci>
     <apply>
      <divide></divide>
      <ci>𝐹𝑃</ci>
      <ci>N</ci>
     </apply>
    </apply>
    <apply>
     <eq></eq>
     <share href="#.cmml">
     </share>
     <apply>
      <divide></divide>
      <ci>𝐹𝑃</ci>
      <apply>
       <plus></plus>
       <ci>𝐹𝑃</ci>
       <ci>𝑇𝑁</ci>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \mathit{FPR}=\mathit{FP}/N=\mathit{FP}/(\mathit{FP}+\mathit{TN})
  </annotation>
 </semantics>
</math>


</dd>
<dt><a href="false_negative_rate" title="wikilink">false negative rate</a> (FNR)</dt>
<dd>

<math display="inline" id="Precision_and_recall:7">
 <semantics>
  <mrow>
   <mi>𝐹𝑁𝑅</mi>
   <mo>=</mo>
   <mrow>
    <mi>𝐹𝑁</mi>
    <mo>/</mo>
    <mrow>
     <mo stretchy="false">(</mo>
     <mrow>
      <mi>𝐹𝑁</mi>
      <mo>+</mo>
      <mi>𝑇𝑃</mi>
     </mrow>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
   <mo>=</mo>
   <mrow>
    <mn>1</mn>
    <mo>-</mo>
    <mi>𝑇𝑃𝑅</mi>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <and></and>
    <apply>
     <eq></eq>
     <ci>𝐹𝑁𝑅</ci>
     <apply>
      <divide></divide>
      <ci>𝐹𝑁</ci>
      <apply>
       <plus></plus>
       <ci>𝐹𝑁</ci>
       <ci>𝑇𝑃</ci>
      </apply>
     </apply>
    </apply>
    <apply>
     <eq></eq>
     <share href="#.cmml">
     </share>
     <apply>
      <minus></minus>
      <cn type="integer">1</cn>
      <ci>𝑇𝑃𝑅</ci>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \mathit{FNR}=\mathit{FN}/(\mathit{FN}+\mathit{TP})=1-\mathit{TPR}
  </annotation>
 </semantics>
</math>


</dd>
<dt><a href="false_discovery_rate" title="wikilink">false discovery rate</a> (FDR)</dt>
<dd>

<math display="inline" id="Precision_and_recall:8">
 <semantics>
  <mrow>
   <mi>𝐹𝐷𝑅</mi>
   <mo>=</mo>
   <mrow>
    <mi>𝐹𝑃</mi>
    <mo>/</mo>
    <mrow>
     <mo stretchy="false">(</mo>
     <mrow>
      <mi>𝐹𝑃</mi>
      <mo>+</mo>
      <mi>𝑇𝑃</mi>
     </mrow>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
   <mo>=</mo>
   <mrow>
    <mn>1</mn>
    <mo>-</mo>
    <mi>𝑃𝑃𝑉</mi>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <and></and>
    <apply>
     <eq></eq>
     <ci>𝐹𝐷𝑅</ci>
     <apply>
      <divide></divide>
      <ci>𝐹𝑃</ci>
      <apply>
       <plus></plus>
       <ci>𝐹𝑃</ci>
       <ci>𝑇𝑃</ci>
      </apply>
     </apply>
    </apply>
    <apply>
     <eq></eq>
     <share href="#.cmml">
     </share>
     <apply>
      <minus></minus>
      <cn type="integer">1</cn>
      <ci>𝑃𝑃𝑉</ci>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \mathit{FDR}=\mathit{FP}/(\mathit{FP}+\mathit{TP})=1-\mathit{PPV}
  </annotation>
 </semantics>
</math>


</dd>
</dl>
<hr/>
<dl>
<dt><a class="uri" href="accuracy" title="wikilink">accuracy</a> (ACC)</dt>
<dd>

<math display="inline" id="Precision_and_recall:9">
 <semantics>
  <mrow>
   <mi>𝐴𝐶𝐶</mi>
   <mo>=</mo>
   <mrow>
    <mrow>
     <mo stretchy="false">(</mo>
     <mrow>
      <mi>𝑇𝑃</mi>
      <mo>+</mo>
      <mi>𝑇𝑁</mi>
     </mrow>
     <mo stretchy="false">)</mo>
    </mrow>
    <mo>/</mo>
    <mrow>
     <mo stretchy="false">(</mo>
     <mrow>
      <mi>P</mi>
      <mo>+</mo>
      <mi>N</mi>
     </mrow>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <ci>𝐴𝐶𝐶</ci>
    <apply>
     <divide></divide>
     <apply>
      <plus></plus>
      <ci>𝑇𝑃</ci>
      <ci>𝑇𝑁</ci>
     </apply>
     <apply>
      <plus></plus>
      <ci>P</ci>
      <ci>N</ci>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \mathit{ACC}=(\mathit{TP}+\mathit{TN})/(P+N)
  </annotation>
 </semantics>
</math>


</dd>
<dt><a href="F1_score" title="wikilink">F1 score</a></dt>
<dd>is the <a href="Harmonic_mean#Harmonic_mean_of_two_numbers" title="wikilink">harmonic mean</a> of <a href="Information_retrieval#Precision" title="wikilink">precision</a> and <a href="sensitivity_(test)" title="wikilink">sensitivity</a>
</dd>
<dd>

<math display="inline" id="Precision_and_recall:10">
 <semantics>
  <mrow>
   <mi mathvariant="italic">F1</mi>
   <mo>=</mo>
   <mrow>
    <mrow>
     <mn>2</mn>
     <mi>𝑇𝑃</mi>
    </mrow>
    <mo>/</mo>
    <mrow>
     <mo stretchy="false">(</mo>
     <mrow>
      <mrow>
       <mn>2</mn>
       <mi>𝑇𝑃</mi>
      </mrow>
      <mo>+</mo>
      <mi>𝐹𝑃</mi>
      <mo>+</mo>
      <mi>𝐹𝑁</mi>
     </mrow>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <ci>italic-F1</ci>
    <apply>
     <divide></divide>
     <apply>
      <times></times>
      <cn type="integer">2</cn>
      <ci>𝑇𝑃</ci>
     </apply>
     <apply>
      <plus></plus>
      <apply>
       <times></times>
       <cn type="integer">2</cn>
       <ci>𝑇𝑃</ci>
      </apply>
      <ci>𝐹𝑃</ci>
      <ci>𝐹𝑁</ci>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \mathit{F1}=2\mathit{TP}/(2\mathit{TP}+\mathit{FP}+\mathit{FN})
  </annotation>
 </semantics>
</math>


</dd>
<dt><a href="Matthews_correlation_coefficient" title="wikilink">Matthews correlation coefficient</a> (MCC)</dt>
<dd><math> \frac{ TP \times TN - FP \times FN } {\sqrt{ (TP+FP) ( TP + FN ) ( TN + FP ) ( TN + FN ) } }
</math></dd>
</dl>

<p></p>

<p>; <span style="font-size:90%;"><em>Sources: Fawcett (2006) and Powers (2011).</em><a class="footnoteRef" href="#fn6" id="fnref6"><sup>6</sup></a><a class="footnoteRef" href="#fn7" id="fnref7"><sup>7</sup></a></span></p></td>
</tr>
</tbody>
</table>

<p>For classification tasks, the terms <strong>true positives</strong>, <strong>true negatives</strong>, <strong>false positives</strong>, and <strong>false negatives</strong> (see also <a href="Type_I_and_type_II_errors" title="wikilink">Type I and type II errors</a>) compare the results of the classifier under test with trusted external judgments. The terms <em>positive</em> and <em>negative</em> refer to the classifier's prediction (sometimes known as the <em>expectation</em>), and the terms <em>true</em> and <em>false</em> refer to whether that prediction corresponds to the external judgment (sometimes known as the <em>observation</em>).</p>

<p>Let us define an experiment from <strong>P</strong> positive instances and <strong>N</strong> negative instances for some condition. The four outcomes can be formulated in a 2×2 <em><a href="contingency_table" title="wikilink">contingency table</a></em> or <em><a href="confusion_matrix" title="wikilink">confusion matrix</a></em>, as follows:</p>

<p>Precision and recall are then defined as:<a class="footnoteRef" href="#fn8" id="fnref8"><sup>8</sup></a></p>

<p>

<math display="block" id="Precision_and_recall:11">
 <semantics>
  <mrow>
   <mtext>Precision</mtext>
   <mo>=</mo>
   <mpadded width="+1.7pt">
    <mfrac>
     <mrow>
      <mi>t</mi>
      <mi>p</mi>
     </mrow>
     <mrow>
      <mrow>
       <mi>t</mi>
       <mi>p</mi>
      </mrow>
      <mo>+</mo>
      <mrow>
       <mi>f</mi>
       <mi>p</mi>
      </mrow>
     </mrow>
    </mfrac>
   </mpadded>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <mtext>Precision</mtext>
    <apply>
     <divide></divide>
     <apply>
      <times></times>
      <ci>t</ci>
      <ci>p</ci>
     </apply>
     <apply>
      <plus></plus>
      <apply>
       <times></times>
       <ci>t</ci>
       <ci>p</ci>
      </apply>
      <apply>
       <times></times>
       <ci>f</ci>
       <ci>p</ci>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \text{Precision}=\frac{tp}{tp+fp}\,
  </annotation>
 </semantics>
</math>

</p>

<p>

<math display="block" id="Precision_and_recall:12">
 <semantics>
  <mrow>
   <mtext>Recall</mtext>
   <mo>=</mo>
   <mpadded width="+1.7pt">
    <mfrac>
     <mrow>
      <mi>t</mi>
      <mi>p</mi>
     </mrow>
     <mrow>
      <mrow>
       <mi>t</mi>
       <mi>p</mi>
      </mrow>
      <mo>+</mo>
      <mrow>
       <mi>f</mi>
       <mi>n</mi>
      </mrow>
     </mrow>
    </mfrac>
   </mpadded>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <mtext>Recall</mtext>
    <apply>
     <divide></divide>
     <apply>
      <times></times>
      <ci>t</ci>
      <ci>p</ci>
     </apply>
     <apply>
      <plus></plus>
      <apply>
       <times></times>
       <ci>t</ci>
       <ci>p</ci>
      </apply>
      <apply>
       <times></times>
       <ci>f</ci>
       <ci>n</ci>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \text{Recall}=\frac{tp}{tp+fn}\,
  </annotation>
 </semantics>
</math>

</p>

<p>Recall in this context is also referred to as the true positive rate or <a href="Sensitivity_and_specificity" title="wikilink">sensitivity</a>, and precision is also referred to as <a href="positive_predictive_value" title="wikilink">positive predictive value</a> (PPV); other related measures used in classification include true negative rate and <a href="Accuracy_and_precision#In_binary_classification" title="wikilink">accuracy</a>.<a class="footnoteRef" href="#fn9" id="fnref9"><sup>9</sup></a> True negative rate is also called <a href="Specificity_(tests)#Specificity" title="wikilink">specificity</a>.</p>

<p>

<math display="block" id="Precision_and_recall:13">
 <semantics>
  <mrow>
   <mtext>True negative rate</mtext>
   <mo>=</mo>
   <mpadded width="+1.7pt">
    <mfrac>
     <mrow>
      <mi>t</mi>
      <mi>n</mi>
     </mrow>
     <mrow>
      <mrow>
       <mi>t</mi>
       <mi>n</mi>
      </mrow>
      <mo>+</mo>
      <mrow>
       <mi>f</mi>
       <mi>p</mi>
      </mrow>
     </mrow>
    </mfrac>
   </mpadded>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <mtext>True negative rate</mtext>
    <apply>
     <divide></divide>
     <apply>
      <times></times>
      <ci>t</ci>
      <ci>n</ci>
     </apply>
     <apply>
      <plus></plus>
      <apply>
       <times></times>
       <ci>t</ci>
       <ci>n</ci>
      </apply>
      <apply>
       <times></times>
       <ci>f</ci>
       <ci>p</ci>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \text{True negative rate}=\frac{tn}{tn+fp}\,
  </annotation>
 </semantics>
</math>

</p>

<p>

<math display="block" id="Precision_and_recall:14">
 <semantics>
  <mrow>
   <mtext>Accuracy</mtext>
   <mo>=</mo>
   <mpadded width="+1.7pt">
    <mfrac>
     <mrow>
      <mrow>
       <mi>t</mi>
       <mi>p</mi>
      </mrow>
      <mo>+</mo>
      <mrow>
       <mi>t</mi>
       <mi>n</mi>
      </mrow>
     </mrow>
     <mrow>
      <mrow>
       <mi>t</mi>
       <mi>p</mi>
      </mrow>
      <mo>+</mo>
      <mrow>
       <mi>t</mi>
       <mi>n</mi>
      </mrow>
      <mo>+</mo>
      <mrow>
       <mi>f</mi>
       <mi>p</mi>
      </mrow>
      <mo>+</mo>
      <mrow>
       <mi>f</mi>
       <mi>n</mi>
      </mrow>
     </mrow>
    </mfrac>
   </mpadded>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <mtext>Accuracy</mtext>
    <apply>
     <divide></divide>
     <apply>
      <plus></plus>
      <apply>
       <times></times>
       <ci>t</ci>
       <ci>p</ci>
      </apply>
      <apply>
       <times></times>
       <ci>t</ci>
       <ci>n</ci>
      </apply>
     </apply>
     <apply>
      <plus></plus>
      <apply>
       <times></times>
       <ci>t</ci>
       <ci>p</ci>
      </apply>
      <apply>
       <times></times>
       <ci>t</ci>
       <ci>n</ci>
      </apply>
      <apply>
       <times></times>
       <ci>f</ci>
       <ci>p</ci>
      </apply>
      <apply>
       <times></times>
       <ci>f</ci>
       <ci>n</ci>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \text{Accuracy}=\frac{tp+tn}{tp+tn+fp+fn}\,
  </annotation>
 </semantics>
</math>

</p>
<h2 id="probabilistic-interpretation">Probabilistic interpretation</h2>

<p>It is possible to interpret precision and recall not as ratios but as probabilities:</p>
<ul>
<li><strong>Precision</strong> is the probability that a (randomly selected) retrieved document is relevant.</li>
</ul>
<ul>
<li><strong>Recall</strong> is the probability that a (randomly selected) relevant document is retrieved in a search.</li>
</ul>

<p>Note that the random selection refers to a uniform distribution over the appropriate pool of documents; i.e. by <strong>randomly selected retrieved document</strong>, we mean selecting a document from the set of retrieved documents in a random fashion. The random selection should be such that all documents in the set are equally likely to be selected.</p>

<p>Note that, in a typical classification system, the probability that a retrieved document is relevant depends on the document. The above interpretation extends to that scenario also (needs explanation).</p>

<p>Another interpretation for precision and recall is as follows. Precision is the average probability of relevant retrieval. Recall is the average probability of complete retrieval. Here we average over multiple retrieval queries.</p>
<h2 id="f-measure">F-measure</h2>

<p>A measure that combines precision and recall is the <a href="harmonic_mean" title="wikilink">harmonic mean</a> of precision and recall, the traditional F-measure or balanced F-score:</p>

<p>

<math display="block" id="Precision_and_recall:15">
 <semantics>
  <mrow>
   <mi>F</mi>
   <mo>=</mo>
   <mrow>
    <mn>2</mn>
    <mo>⋅</mo>
    <mfrac>
     <mrow>
      <mi>precision</mi>
      <mo>⋅</mo>
      <mi>recall</mi>
     </mrow>
     <mrow>
      <mi>precision</mi>
      <mo>+</mo>
      <mi>recall</mi>
     </mrow>
    </mfrac>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <ci>F</ci>
    <apply>
     <ci>normal-⋅</ci>
     <cn type="integer">2</cn>
     <apply>
      <divide></divide>
      <apply>
       <ci>normal-⋅</ci>
       <ci>precision</ci>
       <ci>recall</ci>
      </apply>
      <apply>
       <plus></plus>
       <ci>precision</ci>
       <ci>recall</ci>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   F=2\cdot\frac{\mathrm{precision}\cdot\mathrm{recall}}{\mathrm{precision}+%
\mathrm{recall}}
  </annotation>
 </semantics>
</math>

</p>

<p>There are several reasons that the F-score can be criticized in particular circumstances due to its bias as an evaluation metric. <a class="footnoteRef" href="#fn10" id="fnref10"><sup>10</sup></a> This is also known as the 

<math display="inline" id="Precision_and_recall:16">
 <semantics>
  <msub>
   <mi>F</mi>
   <mn>1</mn>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>F</ci>
    <cn type="integer">1</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   F_{1}
  </annotation>
 </semantics>
</math>

 measure, because recall and precision are evenly weighted.</p>

<p>It is a special case of the general 

<math display="inline" id="Precision_and_recall:17">
 <semantics>
  <msub>
   <mi>F</mi>
   <mi>β</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>F</ci>
    <ci>β</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   F_{\beta}
  </annotation>
 </semantics>
</math>

 measure (for non-negative real values of 

<math display="inline" id="Precision_and_recall:18">
 <semantics>
  <mi>β</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>β</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \beta
  </annotation>
 </semantics>
</math>

):</p>

<p>

<math display="block" id="Precision_and_recall:19">
 <semantics>
  <mrow>
   <msub>
    <mi>F</mi>
    <mi>β</mi>
   </msub>
   <mo>=</mo>
   <mrow>
    <mrow>
     <mo stretchy="false">(</mo>
     <mrow>
      <mn>1</mn>
      <mo>+</mo>
      <msup>
       <mi>β</mi>
       <mn>2</mn>
      </msup>
     </mrow>
     <mo stretchy="false">)</mo>
    </mrow>
    <mo>⋅</mo>
    <mfrac>
     <mrow>
      <mi>precision</mi>
      <mo>⋅</mo>
      <mi>recall</mi>
     </mrow>
     <mrow>
      <mrow>
       <msup>
        <mi>β</mi>
        <mn>2</mn>
       </msup>
       <mo>⋅</mo>
       <mi>precision</mi>
      </mrow>
      <mo>+</mo>
      <mi>recall</mi>
     </mrow>
    </mfrac>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>F</ci>
     <ci>β</ci>
    </apply>
    <apply>
     <ci>normal-⋅</ci>
     <apply>
      <plus></plus>
      <cn type="integer">1</cn>
      <apply>
       <csymbol cd="ambiguous">superscript</csymbol>
       <ci>β</ci>
       <cn type="integer">2</cn>
      </apply>
     </apply>
     <apply>
      <divide></divide>
      <apply>
       <ci>normal-⋅</ci>
       <ci>precision</ci>
       <ci>recall</ci>
      </apply>
      <apply>
       <plus></plus>
       <apply>
        <ci>normal-⋅</ci>
        <apply>
         <csymbol cd="ambiguous">superscript</csymbol>
         <ci>β</ci>
         <cn type="integer">2</cn>
        </apply>
        <ci>precision</ci>
       </apply>
       <ci>recall</ci>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   F_{\beta}=(1+\beta^{2})\cdot\frac{\mathrm{precision}\cdot\mathrm{recall}}{%
\beta^{2}\cdot\mathrm{precision}+\mathrm{recall}}
  </annotation>
 </semantics>
</math>

</p>

<p>Two other commonly used 

<math display="inline" id="Precision_and_recall:20">
 <semantics>
  <mi>F</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>F</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   F
  </annotation>
 </semantics>
</math>

 measures are the 

<math display="inline" id="Precision_and_recall:21">
 <semantics>
  <msub>
   <mi>F</mi>
   <mn>2</mn>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>F</ci>
    <cn type="integer">2</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   F_{2}
  </annotation>
 </semantics>
</math>

 measure, which weights recall higher than precision, and the 

<math display="inline" id="Precision_and_recall:22">
 <semantics>
  <msub>
   <mi>F</mi>
   <mn>0.5</mn>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>F</ci>
    <cn type="float">0.5</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   F_{0.5}
  </annotation>
 </semantics>
</math>

 measure, which puts more emphasis on precision than recall.</p>

<p>The F-measure was derived by van Rijsbergen (1979) so that 

<math display="inline" id="Precision_and_recall:23">
 <semantics>
  <msub>
   <mi>F</mi>
   <mi>β</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>F</ci>
    <ci>β</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   F_{\beta}
  </annotation>
 </semantics>
</math>

 "measures the effectiveness of retrieval with respect to a user who attaches 

<math display="inline" id="Precision_and_recall:24">
 <semantics>
  <mi>β</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>β</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \beta
  </annotation>
 </semantics>
</math>

 times as much importance to recall as precision". It is based on van Rijsbergen's effectiveness measure 

<math display="inline" id="Precision_and_recall:25">
 <semantics>
  <mrow>
   <mi>E</mi>
   <mo>=</mo>
   <mrow>
    <mn>1</mn>
    <mo>-</mo>
    <mfrac>
     <mn>1</mn>
     <mrow>
      <mfrac>
       <mi>α</mi>
       <mi>P</mi>
      </mfrac>
      <mo>+</mo>
      <mfrac>
       <mrow>
        <mn>1</mn>
        <mo>-</mo>
        <mi>α</mi>
       </mrow>
       <mi>R</mi>
      </mfrac>
     </mrow>
    </mfrac>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <ci>E</ci>
    <apply>
     <minus></minus>
     <cn type="integer">1</cn>
     <apply>
      <divide></divide>
      <cn type="integer">1</cn>
      <apply>
       <plus></plus>
       <apply>
        <divide></divide>
        <ci>α</ci>
        <ci>P</ci>
       </apply>
       <apply>
        <divide></divide>
        <apply>
         <minus></minus>
         <cn type="integer">1</cn>
         <ci>α</ci>
        </apply>
        <ci>R</ci>
       </apply>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   E=1-\frac{1}{\frac{\alpha}{P}+\frac{1-\alpha}{R}}
  </annotation>
 </semantics>
</math>

. Their relationship is 

<math display="inline" id="Precision_and_recall:26">
 <semantics>
  <mrow>
   <msub>
    <mi>F</mi>
    <mi>β</mi>
   </msub>
   <mo>=</mo>
   <mrow>
    <mn>1</mn>
    <mo>-</mo>
    <mi>E</mi>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>F</ci>
     <ci>β</ci>
    </apply>
    <apply>
     <minus></minus>
     <cn type="integer">1</cn>
     <ci>E</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   F_{\beta}=1-E
  </annotation>
 </semantics>
</math>

 where 

<math display="inline" id="Precision_and_recall:27">
 <semantics>
  <mrow>
   <mi>α</mi>
   <mo>=</mo>
   <mfrac>
    <mn>1</mn>
    <mrow>
     <mn>1</mn>
     <mo>+</mo>
     <msup>
      <mi>β</mi>
      <mn>2</mn>
     </msup>
    </mrow>
   </mfrac>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <ci>α</ci>
    <apply>
     <divide></divide>
     <cn type="integer">1</cn>
     <apply>
      <plus></plus>
      <cn type="integer">1</cn>
      <apply>
       <csymbol cd="ambiguous">superscript</csymbol>
       <ci>β</ci>
       <cn type="integer">2</cn>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \alpha=\frac{1}{1+\beta^{2}}
  </annotation>
 </semantics>
</math>

.</p>
<h2 id="limitations-as-goals">Limitations as goals</h2>

<p>There are other parameters and strategies for performance metric of information retrieval system, such as the area under the precision-recall curve (AUC).<a class="footnoteRef" href="#fn11" id="fnref11"><sup>11</sup></a></p>

<p>For <a href="web_document" title="wikilink">web document</a> retrieval, if the user's objectives are not clear, the precision and recall can't be optimized. As summarized by Lopresti,<a class="footnoteRef" href="#fn12" id="fnref12"><sup>12</sup></a></p>
<dl>
<dd><em>"<a class="uri" href="Browsing" title="wikilink">Browsing</a> is a comfortable and powerful paradigm (the <a href="Serendipity" title="wikilink">serendipity effect</a>).</em>
<ul>
<li><em>Search results don't have to be very good.</em></li>
<li><em>Recall? Not important (as long as you get at least some good hits).</em></li>
<li><em>Precision? Not important (as long as at least some of the hits on the first page you return are good)."</em></li>
</ul>
</dd>
</dl>
<h2 id="see-also">See also</h2>
<ul>
<li><a href="Binary_classification" title="wikilink">Binary classification</a></li>
<li><a href="Information_retrieval" title="wikilink">Information retrieval</a></li>
<li><a href="Receiver_operating_characteristic" title="wikilink">Receiver operating characteristic</a></li>
<li><a class="uri" href="Relevance" title="wikilink">Relevance</a></li>
<li><a href="Sensitivity_and_specificity" title="wikilink">Sensitivity and specificity</a></li>
<li><a href="Type_I_and_type_II_errors" title="wikilink">Type I and type II errors</a>, where <em>false positives</em> and <em>false negatives</em> are defined</li>
<li><a href="Uncertainty_coefficient" title="wikilink">Uncertainty coefficient</a>, aka Proficiency</li>
</ul>
<h2 id="sources">Sources</h2>
<references>
<ul>
<li>Baeza-Yates, Ricardo; Ribeiro-Neto, Berthier (1999). <em>Modern Information Retrieval</em>. New York, NY: ACM Press, Addison-Wesley, Seiten 75 ff. ISBN 0-201-39829-X</li>
<li>Hjørland, Birger (2010); <em>The foundation of the concept of relevance</em>, Journal of the American Society for Information Science and Technology, 61(2), 217-237</li>
<li>Makhoul, John; Kubala, Francis; Schwartz, Richard; and Weischedel, Ralph (1999); <a href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.27.4637"><em>Performance measures for information extraction</em></a>, in <em>Proceedings of DARPA Broadcast News Workshop, Herndon, VA, February 1999</em></li>
<li>van Rijsbergen, Cornelis Joost "Keith" (1979); <em>Information Retrieval</em>, London, GB; Boston, MA: Butterworth, 2nd Edition, ISBN 0-408-70929-4</li>
</ul>
</references>
<h2 id="external-links">External links</h2>
<ul>
<li><a href="http://www.dcs.gla.ac.uk/Keith/Preface.html">Information Retrieval – C. J. van Rijsbergen 1979</a></li>
<li><a href="http://www.text-analytics101.com/2014/10/computing-precision-and-recall-for.html">Computing Precision and Recall for a Multi-class Classification Problem</a></li>
</ul>

<p><a href="de:Beurteilung_eines_Klassifikators#Anwendung_im_Information_Retrieval" title="wikilink">de:Beurteilung eines Klassifikators#Anwendung im Information Retrieval</a>"</p>

<p><a href="Category:Information_retrieval_evaluation" title="wikilink">Category:Information retrieval evaluation</a> <a href="Category:Information_science" title="wikilink">Category:Information science</a> <a class="uri" href="Category:Bioinformatics" title="wikilink">Category:Bioinformatics</a> <a href="Category:Summary_statistics_for_contingency_tables" title="wikilink">Category:Summary statistics for contingency tables</a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1"></li>
<li id="fn2"><a href="#fnref2">↩</a></li>
<li id="fn3"></li>
<li id="fn4"></li>
<li id="fn5"><a href="#fnref5">↩</a></li>
<li id="fn6"><a href="#fnref6">↩</a></li>
<li id="fn7"><a href="#fnref7">↩</a></li>
<li id="fn8">Olson, David L.; and Delen, Dursun (2008); <em>Advanced Data Mining Techniques</em>, Springer, 1st edition (February 1, 2008), page 138, ISBN 3-540-76916-1<a href="#fnref8">↩</a></li>
<li id="fn9"></li>
<li id="fn10"></li>
<li id="fn11">Zygmunt Zając. What you wanted to know about AUC. <a class="uri" href="http://fastml.com/what-you-wanted-to-know-about-auc/">http://fastml.com/what-you-wanted-to-know-about-auc/</a><a href="#fnref11">↩</a></li>
<li id="fn12">Lopresti, Daniel (2001); <a href="http://www.csc.liv.ac.uk/~wda2001/Panel_Presentations/Lopresti/Lopresti_files/v3_document.htm"><em>WDA 2001 panel</em></a><a href="#fnref12">↩</a></li>
</ol>
</section>
</body>
</html>
