   Hierarchical generalized linear model      Hierarchical generalized linear model  In [[statistics]], '''hierarchical generalized linear models (HGLM)''' extend [[generalized linear models]] by relaxing the assumption that [[Errors a nd residuals in statistics|error components]] are independent . 1 This allows models to be built in situations where more than one error term is necessary and also allows for dependencies between error terms 2 The error components can be correlated and not necessarily follow a normal distribution . When there are different clusters, that is, groups of observations, the observations in the same cluster are correlated. In fact, they are positively correlated because observations in the same cluster share some common features. In this situation, using generalized linear models and ignoring the correlations may cause problems. 3  Overview and model  Model  In a hierarchical model, observations are grouped into clusters, and the distribution of an observation is determined not only by common structure among all clusters but also by the specific structure of the cluster where this observation belongs. So a random effect component, different for different clusters, is introduced into the model. Let   y   y   y   be the response,   u   u   u   be the random effect,   g   g   g   be the link function,    Œ∑  =   X  Œ≤       Œ∑    X  Œ≤     \eta=X\beta   , and    v  =   v   (  u  )        v    v  u     v=v(u)   is some strictly monotone function of   u   u   u   . In a hierarchical generalized linear model, the assumption on    y  |  u     fragments  y  normal-|  u    y|u   and   u   u   u   need to be made: 4     y  ‚à£  u  ‚àº  f   (  Œ∏  ,  œï  )      fragments  y  normal-‚à£  u  similar-to  f   fragments  normal-(  Œ∏  normal-,  œï  normal-)     y\mid u\sim\ f(\theta,\,\phi)   and     u  ‚àº    f  u    (  Œ±  )     .     similar-to  u     subscript  f  u   Œ±     u\sim\ f_{u}(\alpha).     The linear predictor is in the form:       g   (   E   (  y  )    )    =   g   (  Œº  )    =  Œ∑  =    X  Œ≤   +   v            g    E  y      g  Œº        Œ∑           X  Œ≤   v      g(E(y))=g(\mu)=\eta=X\beta+v\,     where   g   g   g   is the link function,    Œº  =   E   (  y  )        Œº    E  y     \mu=E(y)   ,    Œ∑  =    X  Œ≤   +  v       Œ∑      X  Œ≤   v     \eta=X\beta+v   , and    v  =   v   (  u  )        v    v  u     v=v(u)   is a monotone function of   u   u   u   . In this hierarchical generalized linear model, the fixed effect is described by   Œ≤   Œ≤   \beta   , which is the same for all observations. The random component   u   u   u   is unobserved and varies among clusters randomly. So   u   u   u   takes the same value for observations in the same cluster and different values for observations in different clusters. 5  Identifiability  Identifiability is a concept in statistics . In order to perform parameter inference, it is necessary to make sure that the identifiability property holds. 6 In the model stated above, the location of v is not identifiable, since        X  Œ≤   +  v   =    (    X  Œ≤   +  a   )   +   (   v  -  a   )            X  Œ≤   v         X  Œ≤   a     v  a      X\beta+v=(X\beta+a)+(v-a)\,     for constant   a   a   a   . 7 In order to make the model identifiable, we need to impose constraints on parameters. The constraint is usually imposed on random effects, such as     E   (  v  )    =  0        E  v   0    E(v)=0   . 8  Models with different distributions and link functions  By assuming different distributions of    y  ‚à£  u     fragments  y  normal-‚à£  u    y\mid u   and   u   u   u   , and using different functions of   g   g   g   and '   v   v   v   , we will be able to obtain different models. Moreover, the generalized linear mixed model (GLMM) is a special case of the hierarchical generalized linear model. In hierarchical generalized linear models, the distributions of random effect   u   u   u   do not necessarily follow normal distribution . If the distribution of   u   u   u   is normal and the link function of   v   v   v   is the identity function , then hierarchical generalized linear model is the same as GLMM. 9  Distributions of    y  ‚à£  u     fragments  y  normal-‚à£  u    y\mid u   and   u   u   u   can also be chosen to be conjugate, since nice properties hold and it is easier for computation and interpretation. 10 For example, if the distribution of    y  ‚à£  u     fragments  y  normal-‚à£  u    y\mid u   is Poisson with certain mean, the distribution of   u   u   u   is Gamma , and canonical log link is used, then we call the model Poisson conjugate HGLM. If    y  ‚à£  u     fragments  y  normal-‚à£  u    y\mid u   follows binomial distribution with certain mean,   u   u   u   has the conjugate beta distribution , and canonical logit link is used, then we call the model Beta conjugate model. Moreover, the mixed linear model is in fact the normal conjugate HGLM. 11  A summary of commonly used models are: 12      Commonly used models   Model name   distribution of y   Link function between y and u   distribution of u   Link function between u and v     Normal conjugate   Normal   Identity   Normal   Identity     Binomial conjugate   Binomial   Logit   Beta   Logit     Poisson conjugate   Poisson   Log   Gamma   Log     Gamma conjugate   Gamma   Reciprocal   Inv-gamma   Reciprocal     Binomial GLMM   Binomial   Logit   Normal   Identity     Poisson GLMM   Poisson   Log   Normal   Identity     Gamma GLMM   Gamma   Log   Normal   Identity     Fitting the hierarchical generalized linear models  Hierarchical generalized linear models are used when observations come from different clusters. There are two types of estimators: fixed effect estimators and random effect estimators, corresponding to parameters in    Œ∑  =   ùê±  ùú∑       Œ∑    ùê±  ùú∑     \eta=\mathbf{x}\boldsymbol{\beta}   and in    ùêØ   (  ùêÆ  )       ùêØ  ùêÆ    \mathbf{v(u)}   , respectively. There are different ways to obtain parameter estimates for a hierarchical generalized linear model. If only fixed effect estimators are of interests, the population-averaged model can be used. If inference is focused on individuals, random effects will have to be estimated. 13 There are different techniques to fit a hierarchical generalized linear model.  Examples and applications  Hierarchical generalized linear model have been used to solve different real-life problems.  Engineering  For example, this method was used to analyze semiconductor manufacturing, because interrelated processes form a complex hierarchy. 14 Semiconductor fabrication is a complex process which requires different interrelated processes. 15 Hierarchical generalized linear model, requiring clustered data,is able to deal with complicated process. Engineers can use this model to find out and analyze important subprocesses, and at the same time, evaluate the influences of these subprocesses on final performance. 16  Business  Market research problems can also be analyzed by using hierarchical generalized linear models. Researchers applied the model to consumers within countries in order to solve problems in nested data structure in international marketing research. 17  References  "  Category:Regression analysis  Category:Statistical models  Category:Generalized linear models     ‚Ü©   ‚Ü©    ‚Ü©      ‚Ü©  ‚Ü©   ‚Ü©  ‚Ü©   ‚Ü©     