   Central moment      Central moment   In probability theory and statistics , a central moment is a moment of a probability distribution of a random variable about the random variable's mean . The rth moment about any point a is called a central moment; it is the expected value of a specified integer power of the deviation of the random variable from the mean. The various moments form one set of values by which the properties of a probability distribution can be usefully characterised. Central moments are used in preference to ordinary moments, computed in terms of deviations from the mean instead of from the zero, because the higher-order central moments relate only to the spread and shape of the distribution, rather than also to its location .  Sets of central moments can be defined for both univariate and multivariate distributions.  Univariate moments  The n th moment about the mean (or n th central moment ) of a real-valued random variable  X is the quantity μ n := E[( X − E[ X ]) n ], where E is the expectation operator . For a continuous  univariate  probability distribution with probability density function  f ( x ), the n th moment about the mean μ is        μ  n   =   E   [    (   X  -   E   [  X  ]     )   n   ]    =    ∫   -  ∞    +  ∞       (   x  -  μ   )   n   f   (  x  )   d  x     .         subscript  μ  n    normal-E   superscript    X   normal-E  X    n           superscript   subscript                superscript    x  μ   n   f  x  d  x       \mu_{n}=\operatorname{E}\left[(X-\operatorname{E}[X])^{n}\right]=\int_{-\infty%
 }^{+\infty}(x-\mu)^{n}f(x)\,dx.    1  For random variables that have no mean, such as the Cauchy distribution , central moments are not defined.  The first few central moments have intuitive interpretations:   The "zeroth" central moment μ 0 is 1.  The first central moment μ 1 is 0 (not to be confused with the first moment itself, the expected value or mean ).  The second central moment μ 2 is called the variance , and is usually denoted σ 2 , where σ represents the standard deviation .  The third and fourth central moments are used to define the standardized moments which are used to define skewness and kurtosis , respectively.   Properties  The n th central moment is translation-invariant, i.e. for any random variable X and any constant c , we have         μ  n    (   X  +  c   )    =    μ  n    (  X  )     .         subscript  μ  n     X  c       subscript  μ  n   X     \mu_{n}(X+c)=\mu_{n}(X).\,     For all n , the n th central moment is homogeneous of degree n :         μ  n    (   c  X   )    =    c  n    μ  n    (  X  )     .         subscript  μ  n     c  X       superscript  c  n    subscript  μ  n   X     \mu_{n}(cX)=c^{n}\mu_{n}(X).\,     Only for n such that 1 ≤ n ≤ 3 do we have an additivity property for random variables X and Y that are independent :        μ  n    (   X  +  Y   )    =     μ  n    (  X  )    +    μ  n    (  Y  )   provided  1    ≤  n  ≤   3.            subscript  μ  n     X  Y         subscript  μ  n   X      subscript  μ  n   Y  provided  1         n       3.     \mu_{n}(X+Y)=\mu_{n}(X)+\mu_{n}(Y)\text{ provided }1\leq n\leq 3.\,     A related functional that shares the translation-invariance and homogeneity properties with the n th central moment, but continues to have this additivity property even when n ≥ 4 is the n th cumulant κ n ( X ). For n = 1, the n th cumulant is just the expected value ; for n = either 2 or 3, the n th cumulant is just the n th central moment; for n ≥ 4, the n th cumulant is an n th-degree monic polynomial in the first n moments (about zero), and is also a (simpler) n th-degree polynomial in the first n central moments.  Relation to moments about the origin  Sometimes it is convenient to convert moments about the origin to moments about the mean. The general equation for converting the n th-order moment about the origin to the moment about the mean is        μ  n   =   E   [    (   X  -   E   [  X  ]     )   n   ]    =    ∑   j  =  0   n     (     n      j     )     (   -  1   )    n  -  j     μ  j  ′    μ   n  -  j       ,         subscript  μ  n     normal-E   delimited-[]   superscript    X    normal-E   delimited-[]  X     n            superscript   subscript     j  0    n      binomial  n  j    superscript    1     n  j     subscript   superscript  μ  normal-′   j    superscript  μ    n  j         \mu_{n}=\mathrm{E}\left[\left(X-\mathrm{E}\left[X\right]\right)^{n}\right]=%
 \sum_{j=0}^{n}{n\choose j}(-1)^{n-j}\mu^{\prime}_{j}\mu^{n-j},     where μ is the mean of the distribution, and the moment about the origin is given by       μ  j  ′   =    ∫   -  ∞    +  ∞      x  j   f   (  x  )   d  x    =   E   [   X  j   ]           subscript   superscript  μ  normal-′   j     superscript   subscript                superscript  x  j   f  x  d  x           normal-E   delimited-[]   superscript  X  j        \mu^{\prime}_{j}=\int_{-\infty}^{+\infty}x^{j}f(x)\,dx=\mathrm{E}\left[X^{j}\right]     For the cases n = 2, 3, 4 — which are of most interest because of the relations to variance , skewness , and kurtosis , respectively — this formula becomes (noting that    μ  =   μ  1  ′       μ   subscript   superscript  μ  normal-′   1     \mu=\mu^{\prime}_{1}   and     μ  0  ′   =  1       subscript   superscript  μ  normal-′   0   1    \mu^{\prime}_{0}=1   ):,       μ  2   =    μ  2  ′   -    μ  2          subscript  μ  2      subscript   superscript  μ  normal-′   2    superscript  μ  2      \mu_{2}=\mu^{\prime}_{2}-\mu^{2}\,   which is commonly referred to as     Var   (  X  )    =    E   [   X  2   ]    -    (   E   [  X  ]    )   2          Var  X       normal-E   delimited-[]   superscript  X  2      superscript    normal-E   delimited-[]  X    2      \mathrm{Var}\left(X\right)=\mathrm{E}\left[X^{2}\right]-\left(\mathrm{E}\left[%
 X\right]\right)^{2}          μ  3   =     μ  3  ′   -   3  μ   μ  2  ′     +   2    μ  3           subscript  μ  3        subscript   superscript  μ  normal-′   3     3  μ   subscript   superscript  μ  normal-′   2       2   superscript  μ  3       \mu_{3}=\mu^{\prime}_{3}-3\mu\mu^{\prime}_{2}+2\mu^{3}\,           μ  4   =      μ  4  ′   -   4  μ   μ  3  ′     +   6   μ  2    μ  2  ′     -   3   μ  4      .       subscript  μ  4          subscript   superscript  μ  normal-′   4     4  μ   subscript   superscript  μ  normal-′   3       6   superscript  μ  2    subscript   superscript  μ  normal-′   2       3   superscript  μ  4       \mu_{4}=\mu^{\prime}_{4}-4\mu\mu^{\prime}_{3}+6\mu^{2}\mu^{\prime}_{2}-3\mu^{4%
 }.\,     ... and so on, 2 following Pascal's triangle , i.e.        μ  5   =       μ  5  ′   -   5  μ   μ  4  ′     +   10   μ  2    μ  3  ′     -   10   μ  3    μ  2  ′     +   4   μ  5      .       subscript  μ  5            subscript   superscript  μ  normal-′   5     5  μ   subscript   superscript  μ  normal-′   4       10   superscript  μ  2    subscript   superscript  μ  normal-′   3       10   superscript  μ  3    subscript   superscript  μ  normal-′   2       4   superscript  μ  5       \mu_{5}=\mu^{\prime}_{5}-5\mu\mu^{\prime}_{4}+10\mu^{2}\mu^{\prime}_{3}-10\mu^%
 {3}\mu^{\prime}_{2}+4\mu^{5}.\,     because      5   μ  4    μ  1  ′    -    μ  5    μ  0  ′     =    5   μ  4   μ   -   μ  5    =    5   μ  5    -   μ  5    =   4   μ  5              5   superscript  μ  4    subscript   superscript  μ  normal-′   1       superscript  μ  5    subscript   superscript  μ  normal-′   0         5   superscript  μ  4   μ    superscript  μ  5             5   superscript  μ  5     superscript  μ  5           4   superscript  μ  5       5\mu^{4}\mu^{\prime}_{1}-\mu^{5}\mu^{\prime}_{0}=5\mu^{4}\mu-\mu^{5}=5\mu^{5}-%
 \mu^{5}=4\mu^{5}     Symmetric distributions  In a symmetric distribution (one that is unaffected by being reflected about its mean), all odd moments equal zero, because in the formula for the n th moment, each term involving a value of X less than the mean by a certain amount exactly cancels out the term involving a value of X greater than the mean by the same amount.  Multivariate moments  For a continuous  bivariate  probability distribution with probability density function  f ( x , y ) the ( j , k ) moment about the mean μ = (μ X , μ Y ) is        μ   j  ,  k    =   E   [     (   X  -   E   [  X  ]     )   j     (   Y  -   E   [  Y  ]     )   k    ]    =    ∫   -  ∞    +  ∞      ∫   -  ∞    +  ∞       (   x  -   μ  X    )   j     (   y  -   μ  Y    )   k   f   (  x  ,  y  )   d   x   d  y      .         subscript  μ   j  k     normal-E     superscript    X   normal-E  X    j    superscript    Y   normal-E  Y    k            superscript   subscript               superscript   subscript                superscript    x   subscript  μ  X    j    superscript    y   subscript  μ  Y    k   f   x  y   d  x  d  y        \mu_{j,k}=\operatorname{E}\left[(X-\operatorname{E}[X])^{j}(Y-\operatorname{E}%
 [Y])^{k}\right]=\int_{-\infty}^{+\infty}\int_{-\infty}^{+\infty}(x-\mu_{X})^{j%
 }(y-\mu_{Y})^{k}f(x,y)\,dx\,dy.     See also   Standardized moment  Image moment  Normal distribution#Moments   References  fr:Moment (mathématiques)#Moment centré "  Category:Statistical deviation and dispersion  Category:Theory of probability distributions     ↩  http://mathworld.wolfram.com/CentralMoment.html ↩     