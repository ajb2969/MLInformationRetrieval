


Neural decoding




Neural decoding

Neural decoding is a neuroscience-related field concerned with the reconstruction of sensory and other stimuli from information that has already been encoded and represented in the brain by networks of neurons. Reconstruction refers to the ability of the researcher to predict what sensory stimuli the subject is receiving based purely on neuron action potentials. Therefore, the main goal of neural decoding is to characterize how the electrical activity of neurons elicit activity and responses in the brain.1
This article specifically refers to neural decoding as it pertains to the mammalian neocortex.
Overview
When looking at a picture, our brains are constantly making decisions about what object we are looking at, where we need to move our eyes next, and what we find to be the most salient aspects of the input stimulus. As these images hit the back of our retina, these stimuli are converted from varying wavelengths to a series of neural spikes called action potentials. These pattern of action potentials are different for different objects and different colors; we therefore say that the neurons are encoding objects and colors by varying their spike rates or temporal pattern. Now, if someone were to probe the brain by placing electrodes in the primary visual cortex, they may find what appears to be random electrical activity. These neurons are actually firing in response to the lower level features of visual input, possibly the edges of a picture frame. This highlights the crux of the neural decoding hypothesis: that is possible to reconstruct a stimulus from the response of the ensemble of neurons that represent it. By this we mean, it is possible to look at spike train data and say that the person or animal we are recording from is looking at a red ball.
With the recent breakthrough in large-scale neural recording and decoding technologies, researchers have begun to crack the neural code and already provided the first glimpse into the real-time neural code of memory traces as memory is formed and recalled in the hippocampus, a brain region known to be central for memory formation.23 Neuroscientists have initiated large-scale brain activity mapping or brain decoding project 4 to construct the brain-wide neural codes.
Encoding to decoding
Implicit about the decoding hypothesis is the assumption that neural spiking in the brain somehow represents stimuli in the external world. The decoding of neural data would be impossible if the neurons were firing randomly: nothing would be represented. This process of decoding neural data forms a loop with neural encoding. First, the organism must be able to perceive a set of stimuli in the world - say a picture of a hat. Seeing the stimuli must result in some internal learning: the encoding stage. After varying the range of stimuli that is presented to the observer, we expect the neurons to adapt to the statistical properties of the signals, encoding those that occur most frequently:5 the efficient-coding hypothesis. Now neural decoding is the process of taking these statistical consistencies, a statistical model of the world, and reproducing the stimuli. This may map to the process of thinking and acting, which in turn guide what stimuli we receive, and thus, completing the loop.
In order to build a model of neural spike data, one must both understand how information is originally stored in the brain and how this information is used at a later point in time. This neural coding and decoding loop is a symbiotic relationship and the crux of the brain's learning algorithm. Furthermore, the processes that underlie neural decoding and encoding are very tightly coupled and may lead to varying levels of representative ability67
Spatial resolutions
Much of the neural decoding problem depends on the spatial resolution of the data being collected. The number of neurons needed to reconstruct the stimulus with reasonable accuracy depends on the means by which data is collected and the area being recorded. For example, rods and cones (which respond to colors of small visual areas) in the retina may require more recordings than simple cells (which respond to orientation of lines) in the primary visual cortex.
Previous recording methods relied on stimulating single neurons over a repeated series of tests in order to generalize this neuron's behavior.8 New techniques such as high-density multi-electrode array recordings and multi-photon calcium imaging techniques now make it possible to record from upwards of a few hundred neurons. Even with better recording techniques, the focus of these recordings must be on an area of the brain that is both manageable and qualitatively understood. Many studies look at spike train data gathered from the ganglion cells in the retina, since this area has the benefits of being strictly feedforward, retinotopic, and amenable to current recording granularities. The duration, intensity, and location of the stimulus can be controlled to sample, for example, a particular subset of ganglion cells within a structure of the visual system.9 Other studies use spike trains to evaluate the discriminatory ability of non-visual senses such as rat facial whiskers10 and the olfactory coding of moth pheromone receptor neurons.11
Even with ever-improving recording techniques, one will always run into the limited sampling problem: given a limited number of recording trials, it is impossible to completely account for the error associated with noisy data obtained from stochastically functioning neurons (for example, a neuron's electric potential fluctuates around its resting potential due to a constant influx and efflux of sodium and potassium ions). Therefore, it is not possible to perfectly reconstruct a stimulus from spike data. Luckily, even with noisy data, the stimulus can still be reconstructed within acceptable error bounds.12
Temporal resolutions
Timescales and frequencies of stimuli being presented to the observer are also of importance to decoding the neural code. Quicker timescales and higher frequencies demand faster and more precise responses in neural spike data. In humans, millisecond precision has been observed throughout the visual cortex, the retina,13 and the lateral geniculate nucleus, so one would suspect this to be the appropriate measuring frequency. This has been confirmed in studies that quantify the responses of neurons in the lateral geniculate nucleus to white-noise and naturalistic movie stimuli.14 At the cellular level, spike-timing-dependent plasticity operates at millisecond timescales;15 therefore, models seeking biological relevance should be able to perform at these temporal scales.
Probabilistic decoding
When decoding neural data, arrival times of each spike 
 
 
 
 , and the probability of seeing a certain stimulus, 
 
 
 
  may be the extent of the available data. The prior distribution

 
  defines an ensemble of signals, and represents the likelihood of seeing a stimulus in the world based on previous experience. The spike times may also be drawn from a distribution

 
 ; however, what we want to know is the probability distribution over a set of stimuli given a series of spike trains 
 
 
 
 , which is called the response-conditional ensemble. What remains is the characterization of the neural code by translating stimuli into spikes, 
 
 
 
 ; the traditional approach to calculating this probability distribution has been to fix the stimulus and examine the responses of the neuron. Combining everything using Bayes' Rule results in the simplified probabilistic characterization of neural decoding
 
 
 
 . An area of active research consists of finding better ways of representing and determining 
 
 
 
 .16 The following are some such examples.
Spike train number
The simplest coding strategy is the spike train number coding. This method assumes that the spike number is the most important quantification of spike train data. In spike train number coding, each stimulus is represented by a unique firing rate across the sampled neurons. The color red may be signified by 5 total spikes across the entire set of neurons, while the color green may be 10 spikes; each spike is pooled together into an overall count. This is represented by:



where 
 
 
 
  the number of spikes, 
 
 
 
  is the number of spikes of neuron 
 
 
 
  at stimulus presentation time 
 
 
 
 , and s is the stimulus.
Instantaneous rate code
Adding a small temporal component results in the spike timing coding strategy. Here, the main quantity measured is the number of spikes that occur within a predefined window of time T. This method adds another dimension to the previous. This timing code is given by:



where 
 
 
 
  is the jth spike on the lth presentation of neuron i, 
 
 
 
  is the firing rate of neuron i at time t, and 0 to T is the start to stop times of each trial.
Temporal correlation
Temporal correlation code, as the name states, adds correlations between individual spikes. This means that the time between a spike 
 
 
 
  and its preceding spike 
 
 
 
  is included. This is given by:



where 
 
 
 
  is the time interval between a neurons spike and the one preceding it.
Ising decoder
Another description of neural spike train data uses the Ising model borrowed from the physics of magnetic spins. Because neural spike trains effectively binarized(either on or off) at small time scales (10 to 20 ms), the Ising model is able to effectively capture the present pairwise correlations,17 and is given by:



where 
 
 
 
  is the set of binary responses of neuron i, 
 
 
 
  is the external fields function, 
 
 
 
  is the pairwise couplings function, and 
 
 
 
  is the partition function.
Agent-based decoding
In addition to the probabilistic approach, agent-based models exist that capture the spatial dynamics of the neural system under scrutiny. One such model is hierarchical temporal memory, which is a machine learning framework that organizes visual perception problem into a hierarchy of interacting nodes (neurons). The connections between nodes on the same levels and a lower levels are termed synapses, and their interactions are subsequently learning. Synapse strengths modulate learning and are altered based on the temporal and spatial firing of nodes in response to input patterns.1819
While it is possible to take the firing rates of these modeled neurons, and transform them into the probabilistic and mathematical frameworks described above, agent-based models provide the ability to observe the behavior of the entire population of modeled neurons. Researchers can circumvent the limitations implicit with lab-based recording techniques. Because this approach does rely on modeling biological systems, error arises in the assumptions made by the researcher and in the data used in parameter estimation.
Applicability
The advancement in our understanding of neural decoding benefits the development of brain-machine interfaces, prosthetics20 and the understanding of neurological disorders such as epilepsy.21
See also

Rate coding
Sparse coding
Phase-of-firing code
Population coding
Temporal coding
Correlation coding
Independent-spike coding
NeuroElectroDynamics
Neural synchronization
Multielectrode array
Patch clamp
Grandmother Cell
Nervous system network models
Bursting
Neural coding

References
"
  Category:Computational neuroscience Category:Neuroscience Category:Neural networks



↩
Chen G, Wang LP, Tsien JZ. Neural population-level memory traces in the mouse hippocampus. PLoS One. 2009 Dec 16;4(12):e8256. doi: 10.1371/journal.pone.0008256.PMID 20016843. http://www.plosone.org/article/info%3Adoi%2F10.1371%2Fjournal.pone.0008256 ↩
Zhang H, Chen G, Kuang H, Tsien JZ.Mapping and deciphering neural codes of NMDA receptor-dependent fear memory engrams in the hippocampus.PLoS One. 2013 Nov 26;8(11):e79454. doi: 10.1371/journal.pone.0079454. eCollection 2013.PMID: http://www.plosone.org/article/info%3Adoi%2F10.1371%2Fjournal.pone.007945424302990 ↩
The Brain Decoding Project. http://braindecodingproject.org/↩
Barlow, H. (1961). Possible principles underlying the transformation of sensory messages. Sensory communication.↩
↩
↩
↩
↩
↩
 ↩
↩
↩
↩
↩
Rieke, F. (1999). Spikes: exploring the neural code. exploring the neural code (p. 395). The MIT Press.↩
↩
Hawkins, J., Ahmad, S., & Dubinsky, D. (2006). Hierarchical temporal memory: Concepts, theory and terminology. Whitepaper.↩
Hawkins, J., & Blakeslee, S. (2005). On intelligence. Owl Books.↩
↩
↩




