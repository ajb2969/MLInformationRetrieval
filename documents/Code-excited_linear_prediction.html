<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="507">Code-excited linear prediction</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>Code-excited linear prediction</h1>
<hr/>

<p><strong>Code-excited linear prediction</strong> (<strong>CELP</strong>) is a <a href="speech_coding" title="wikilink">speech coding</a> algorithm originally proposed by <a href="Manfred_R._Schroeder" title="wikilink">M. R. Schroeder</a> and <a href="Bishnu_S._Atal" title="wikilink">B. S. Atal</a> in 1985. At the time, it provided significantly better quality than existing low bit-rate algorithms, such as <a href="residual-excited_linear_prediction" title="wikilink">residual-excited linear prediction</a> and <a href="linear_predictive_coding" title="wikilink">linear predictive coding</a> <a class="uri" href="vocoders" title="wikilink">vocoders</a> (e.g., <a class="uri" href="FS-1015" title="wikilink">FS-1015</a>). Along with its variants, such as <a href="algebraic_CELP" title="wikilink">algebraic CELP</a>, <a href="relaxed_CELP" title="wikilink">relaxed CELP</a>, <a href="low-delay_CELP" title="wikilink">low-delay CELP</a> and <a href="vector_sum_excited_linear_prediction" title="wikilink">vector sum excited linear prediction</a>, it is currently the most widely used speech coding algorithm. It is also used in <a href="MPEG-4_Audio" title="wikilink">MPEG-4 Audio</a> speech coding. CELP is commonly used as a generic term for a class of algorithms and not for a particular codec.</p>
<h2 id="introduction">Introduction</h2>

<p>The CELP algorithm is based on four main ideas:</p>
<ul>
<li>Using the <a href="source-filter_model_of_speech_production" title="wikilink">source-filter model of speech production</a> through <a href="linear_prediction" title="wikilink">linear prediction</a> (LP) (see the textbook "speech coding algorithm");</li>
<li>Using an adaptive and a fixed codebook as the input (excitation) of the LP model;</li>
<li>Performing a search in closed-loop in a “perceptually weighted domain”.</li>
<li>Applying <a href="vector_quantization" title="wikilink">vector quantization</a> (VQ)</li>
</ul>

<p>The original algorithm as simulated in 1983 by Schroeder and Atal required 150 seconds to encode 1 second of speech when run on a <a class="uri" href="Cray-1" title="wikilink">Cray-1</a> supercomputer. Since then, more efficient ways of implementing the codebooks and improvements in computing capabilities have made it possible to run the algorithm in embedded devices, such as mobile phones.</p>
<h2 id="celp-decoder">CELP decoder</h2>
<figure><b>(Figure)</b>
<figcaption>Figure 1: CELP decoder</figcaption>
</figure>

<p>Before exploring the complex encoding process of CELP we introduce the decoder here. Figure 1 describes a generic CELP decoder. The excitation is produced by summing the contributions from an adaptive (aka pitch) codebook and a stochastic (aka innovation or fixed) codebook:</p>

<p>

<math display="block" id="Code-excited_linear_prediction:0">
 <semantics>
  <mrow>
   <mrow>
    <mi>e</mi>
    <mrow>
     <mo stretchy="false">[</mo>
     <mi>n</mi>
     <mo stretchy="false">]</mo>
    </mrow>
   </mrow>
   <mo>=</mo>
   <mrow>
    <mrow>
     <msub>
      <mi>e</mi>
      <mi>a</mi>
     </msub>
     <mrow>
      <mo stretchy="false">[</mo>
      <mi>n</mi>
      <mo stretchy="false">]</mo>
     </mrow>
    </mrow>
    <mo>+</mo>
    <mrow>
     <msub>
      <mi>e</mi>
      <mi>f</mi>
     </msub>
     <mrow>
      <mo stretchy="false">[</mo>
      <mi>n</mi>
      <mo rspace="4.2pt" stretchy="false">]</mo>
     </mrow>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <times></times>
     <ci>e</ci>
     <apply>
      <csymbol cd="latexml">delimited-[]</csymbol>
      <ci>n</ci>
     </apply>
    </apply>
    <apply>
     <plus></plus>
     <apply>
      <times></times>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>e</ci>
       <ci>a</ci>
      </apply>
      <apply>
       <csymbol cd="latexml">delimited-[]</csymbol>
       <ci>n</ci>
      </apply>
     </apply>
     <apply>
      <times></times>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>e</ci>
       <ci>f</ci>
      </apply>
      <apply>
       <csymbol cd="latexml">delimited-[]</csymbol>
       <ci>n</ci>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   e[n]=e_{a}[n]+e_{f}[n]\,
  </annotation>
 </semantics>
</math>

</p>

<p>where 

<math display="inline" id="Code-excited_linear_prediction:1">
 <semantics>
  <mrow>
   <msub>
    <mi>e</mi>
    <mi>a</mi>
   </msub>
   <mrow>
    <mo stretchy="false">[</mo>
    <mi>n</mi>
    <mo stretchy="false">]</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>e</ci>
     <ci>a</ci>
    </apply>
    <apply>
     <csymbol cd="latexml">delimited-[]</csymbol>
     <ci>n</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   e_{a}[n]
  </annotation>
 </semantics>
</math>

 is the adaptive (<a href="Pitch_(music)" title="wikilink">pitch</a>) codebook contribution and 

<math display="inline" id="Code-excited_linear_prediction:2">
 <semantics>
  <mrow>
   <msub>
    <mi>e</mi>
    <mi>f</mi>
   </msub>
   <mrow>
    <mo stretchy="false">[</mo>
    <mi>n</mi>
    <mo stretchy="false">]</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>e</ci>
     <ci>f</ci>
    </apply>
    <apply>
     <csymbol cd="latexml">delimited-[]</csymbol>
     <ci>n</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   e_{f}[n]
  </annotation>
 </semantics>
</math>

 is the stochastic (innovation or fixed) codebook contribution. The fixed codebook is a <a href="vector_quantization" title="wikilink">vector quantization</a> dictionary that is (implicitly or explicitly) hard-coded into the codec. This codebook can be algebraic (<a class="uri" href="ACELP" title="wikilink">ACELP</a>) or be stored explicitly (e.g. <a class="uri" href="Speex" title="wikilink">Speex</a>). The entries in the adaptive codebook consist of delayed versions of the excitation. This makes it possible to efficiently code periodic signals, such as voiced sounds.</p>

<p>The filter that shapes the excitation has an all-pole model of the form 

<math display="inline" id="Code-excited_linear_prediction:3">
 <semantics>
  <mrow>
   <mrow>
    <mn>1</mn>
    <mo>/</mo>
    <mi>A</mi>
   </mrow>
   <mrow>
    <mo stretchy="false">(</mo>
    <mi>z</mi>
    <mo stretchy="false">)</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <apply>
     <divide></divide>
     <cn type="integer">1</cn>
     <ci>A</ci>
    </apply>
    <ci>z</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   1/A(z)
  </annotation>
 </semantics>
</math>

, where 

<math display="inline" id="Code-excited_linear_prediction:4">
 <semantics>
  <mrow>
   <mi>A</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <mi>z</mi>
    <mo stretchy="false">)</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <ci>A</ci>
    <ci>z</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   A(z)
  </annotation>
 </semantics>
</math>

 is called the prediction filter and is obtained using linear prediction (<a href="Levinson_recursion" title="wikilink">Levinson–Durbin algorithm</a>). An all-pole filter is used because it is a good representation of the human vocal tract and because it is easy to compute.</p>
<h2 id="celp-encoder">CELP encoder</h2>

<p>The main principle behind CELP is called <a href="Analysis-by-Synthesis" title="wikilink">Analysis-by-Synthesis (AbS)</a> and means that the encoding (analysis) is performed by perceptually optimizing the decoded (synthesis) signal in a closed loop. In theory, the best CELP stream would be produced by trying all possible bit combinations and selecting the one that produces the best-sounding decoded signal. This is obviously not possible in practice for two reasons: the required complexity is beyond any currently available hardware and the “best sounding” selection criterion implies a human listener.</p>

<p>In order to achieve real-time encoding using limited computing resources, the CELP search is broken down into smaller, more manageable, sequential searches using a simple perceptual weighting function. Typically, the encoding is performed in the following order:</p>
<ul>
<li>Linear Prediction Coefficients (LPC) are computed and quantized, usually as <a href="Line_spectral_pairs" title="wikilink">LSPs</a></li>
<li>The adaptive (pitch) codebook is searched and its contribution removed</li>
<li>The fixed (innovation) codebook is searched</li>
</ul>
<h3 id="noise-weighting">Noise weighting</h3>

<p>Most (if not all) modern audio codecs attempt to <a href="Psychoacoustics" title="wikilink">shape the coding noise</a> so that it appears mostly in the frequency regions where the ear cannot detect it. For example, the ear is more tolerant to noise in parts of the spectrum that are louder and vice versa. That's why instead of minimizing the simple quadratic error, CELP minimizes the error for the <em>perceptually weighted</em> domain. The weighting filter W(z) is typically derived from the LPC filter by the use of <a href="bandwidth_expansion" title="wikilink">bandwidth expansion</a>:</p>

<p>

<math display="block" id="Code-excited_linear_prediction:5">
 <semantics>
  <mrow>
   <mrow>
    <mi>W</mi>
    <mrow>
     <mo stretchy="false">(</mo>
     <mi>z</mi>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
   <mo>=</mo>
   <mfrac>
    <mrow>
     <mi>A</mi>
     <mrow>
      <mo stretchy="false">(</mo>
      <mrow>
       <mi>z</mi>
       <mo>/</mo>
       <msub>
        <mi>γ</mi>
        <mn>1</mn>
       </msub>
      </mrow>
      <mo stretchy="false">)</mo>
     </mrow>
    </mrow>
    <mrow>
     <mi>A</mi>
     <mrow>
      <mo stretchy="false">(</mo>
      <mrow>
       <mi>z</mi>
       <mo>/</mo>
       <msub>
        <mi>γ</mi>
        <mn>2</mn>
       </msub>
      </mrow>
      <mo stretchy="false">)</mo>
     </mrow>
    </mrow>
   </mfrac>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <times></times>
     <ci>W</ci>
     <ci>z</ci>
    </apply>
    <apply>
     <divide></divide>
     <apply>
      <times></times>
      <ci>A</ci>
      <apply>
       <divide></divide>
       <ci>z</ci>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <ci>γ</ci>
        <cn type="integer">1</cn>
       </apply>
      </apply>
     </apply>
     <apply>
      <times></times>
      <ci>A</ci>
      <apply>
       <divide></divide>
       <ci>z</ci>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <ci>γ</ci>
        <cn type="integer">2</cn>
       </apply>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   W(z)=\frac{A(z/\gamma_{1})}{A(z/\gamma_{2})}
  </annotation>
 </semantics>
</math>

</p>

<p>where 

<math display="inline" id="Code-excited_linear_prediction:6">
 <semantics>
  <mrow>
   <msub>
    <mi>γ</mi>
    <mn>1</mn>
   </msub>
   <mo>></mo>
   <msub>
    <mi>γ</mi>
    <mn>2</mn>
   </msub>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <gt></gt>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>γ</ci>
     <cn type="integer">1</cn>
    </apply>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>γ</ci>
     <cn type="integer">2</cn>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \gamma_{1}>\gamma_{2}
  </annotation>
 </semantics>
</math>

.</p>
<h2 id="see-also">See also</h2>
<ul>
<li><a href="MPEG-4_Part_3" title="wikilink">MPEG-4 Part 3</a> (CELP as an MPEG-4 Audio Object Type)</li>
<li><a class="uri" href="G.728" title="wikilink">G.728</a> - Coding of speech at 16 kbit/s using low-delay code excited linear prediction</li>
<li><a class="uri" href="G.718" title="wikilink">G.718</a> - uses CELP for the lower two layers for the band (50–6400 Hz) in a two-stage coding structure</li>
<li><a class="uri" href="G.729.1" title="wikilink">G.729.1</a> - uses CELP coding for the lower band (50–4000 Hz) in a three-stage coding structure</li>
<li><a href="Comparison_of_audio_coding_formats" title="wikilink">Comparison of audio coding formats</a></li>
<li><a class="uri" href="CELT" title="wikilink">CELT</a> is a related audio codec that borrows some ideas from CELP.</li>
</ul>
<h2 id="external-links">External links</h2>
<ul>
<li>This article is based on a <a href="http://people.xiph.org/~jm/papers/speex_lca2006.pdf">paper</a> presented at <a href="http://linux.conf.au/">Linux.Conf.Au</a></li>
<li>Some parts based on the <a class="uri" href="Speex" title="wikilink">Speex</a> codec <a href="http://www.speex.org/docs/">manual</a></li>
<li><a href="http://www.speech.cs.cmu.edu/comp.speech/Section3/Software/celp-3.2a.html">reference implementations</a> of CELP 1016A (CELP 3.2a) and LPC 10e.</li>
<li><a href="http://www.otolith.com/otolith/olt/lpc.html">Linear Predictive Coding (LPC)</a></li>
</ul>
<h3 id="selected-readings">Selected readings</h3>
<ul>
<li><a href="http://www.speex.org/docs/manual/speex-manual/node9.html">Introduction to CELP Coding</a></li>
<li><a href="http://cnx.org/content/m10482/latest/">Speech Processing: Theory of LPC Analysis and Synthesis</a></li>
</ul>
<h2 id="references">References</h2>
<ul>
<li>B.S. Atal, "The History of Linear Prediction," <em>IEEE Signal Processing Magazine</em>, vol. 23, no. 2, March 2006, pp. 154–161.</li>
<li>M. R. Schroeder and B. S. Atal, "Code-excited linear prediction (CELP): high-quality speech at very low bit rates," in <em>Proceedings of the IEEE <a href="International_Conference_on_Acoustics,_Speech,_and_Signal_Processing" title="wikilink">International Conference on Acoustics, Speech, and Signal Processing</a></em> (ICASSP), vol. 10, pp. 937–940, 1985.</li>
</ul>

<p>"</p>

<p><a href="Category:Speech_codecs" title="wikilink">Category:Speech codecs</a></p>
</body>
</html>
