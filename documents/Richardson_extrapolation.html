<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title offset="94">Richardson extrapolation</title>
   <script type="text/javascript"
      src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js">
    </script>
</head>
<body>
<h1>Richardson extrapolation</h1>
<style>
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
<style>
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
  </style>
</head>
<body>
<hr/>
<p>In <a href="numerical_analysis" title="wikilink">numerical analysis</a>, <strong>Richardson extrapolation</strong> is a <a href="Series_acceleration" title="wikilink">sequence acceleration</a> method, used to improve the <a href="rate_of_convergence" title="wikilink">rate of convergence</a> of a <a class="uri" href="sequence" title="wikilink">sequence</a>. It is named after <a href="Lewis_Fry_Richardson" title="wikilink">Lewis Fry Richardson</a>, who introduced the technique in the early 20th century.<a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a><a class="footnoteRef" href="#fn2" id="fnref2"><sup>2</sup></a> In the words of <a href="Garrett_Birkhoff" title="wikilink">Birkhoff</a> and <a href="Gian-Carlo_Rota" title="wikilink">Rota</a>, "... its usefulness for practical computations can hardly be overestimated."<a class="footnoteRef" href="#fn3" id="fnref3"><sup>3</sup></a></p>
<p>Practical applications of Richardson extrapolation include <a href="Romberg_integration" title="wikilink">Romberg integration</a>, which applies Richardson extrapolation to the <a href="trapezoid_rule" title="wikilink">trapezoid rule</a>, and the <a href="Bulirsch–Stoer_algorithm" title="wikilink">Bulirsch–Stoer algorithm</a> for solving ordinary differential equations.</p>
<h2 id="example-of-richardson-extrapolation">Example of Richardson extrapolation</h2>
<p>Suppose that we wish to approximate <span class="LaTeX">$A^*$</span>, and we have a method <span class="LaTeX">$A(h)$</span> that depends on a small parameter <span class="LaTeX">$h$</span>, so that</p>
<p><span class="LaTeX">$A(h) = A^\ast + C h^n + o(h^{n+1})\;$</span></p>
<p>Define a new method</p>
<p><span class="LaTeX">$R(h,k) := \frac{ k^n A(h) - A(k\,h)}{k^n-1}$</span></p>
<p>Then</p>
<p><span class="LaTeX">$R(h, k) = \frac{ k^n ( A^* + C h^n + o(h^{n+1}) ) - ( A^* + C k^n h^n + o(h^{n+1}) ) }{ k^n - 1} = A^* + o(h^{n+1}).$</span> <span class="LaTeX">$R(h,k)$</span> is called the Richardson <a class="uri" href="extrapolation" title="wikilink">extrapolation</a> of <em>A</em>(<em>h</em>), and has a higher-order error estimate <span class="LaTeX">$o(h^{n+1})$</span> compared to <span class="LaTeX">$A(h)$</span>.</p>
<p>Very often, it is much easier to obtain a given precision by using <em>R(h)</em> rather than <em>A(h')</em> with a much smaller '' h' '', which can cause problems due to limited precision (<a href="rounding_error" title="wikilink">rounding errors</a>) and/or due to the increasing <a href="Computational_cost" title="wikilink">number of calculations</a> needed (see examples below).</p>
<h2 id="general-formula">General formula</h2>
<p>Let <em>A</em>(<em>h</em>) be an approximation of <em>A</em> that depends on a positive step size <em>h</em> with an <a href="Approximation_error" title="wikilink">error</a> formula of the form</p>
<p><span class="LaTeX">$$A - A(h) = a_0h^{k_0} + a_1h^{k_1} + a_2h^{k_2} + \cdots$$</span> where the <em>a<sub>i</sub></em> are unknown constants and the <em>k<sub>i</sub></em> are known constants such that <em>h<sup>k<sub>i</sub></sup></em> > <em>h<sup>k<sub>i+1</sub></sup></em>.</p>
<p>The exact value sought can be given by</p>
<p><span class="LaTeX">$$A = A(h) + a_0h^{k_0} + a_1h^{k_1} + a_2h^{k_2} + \cdots$$</span> which can be simplified with <a href="Big_O_notation" title="wikilink">Big O notation</a> to be</p>
<p><span class="LaTeX">$$A = A(h)+ a_0h^{k_0} + O(h^{k_1}).  \,\!$$</span></p>
<p>Using the step sizes <em>h</em> and <em>h / t</em> for some <em>t</em>, the two formulas for <em>A</em> are:</p>
<p><span class="LaTeX">$$A = A(h)+ a_0h^{k_0} + O(h^{k_1})  \,\!$$</span></p>
<p><span class="LaTeX">$$A = A\!\left(\frac{h}{t}\right) + a_0\left(\frac{h}{t}\right)^{k_0} + O(h^{k_1}) .$$</span></p>
<p>Multiplying the second equation by <em>t</em><sup><em>k</em><sub>0</sub></sup> and subtracting the first equation gives</p>
<p><span class="LaTeX">$$(t^{k_0}-1)A = t^{k_0}A\left(\frac{h}{t}\right) - A(h) + O(h^{k_1})$$</span> which can be solved for <em>A</em> to give</p>
<p><span class="LaTeX">$$A = \frac{t^{k_0}A\left(\frac{h}{t}\right) - A(h)}{t^{k_0}-1} + O(h^{k_1}) .$$</span></p>
<p>By this process, we have achieved a better approximation of <em>A</em> by subtracting the largest term in the error which was <em>O</em>(<em>h</em><sup><em>k</em><sub>0</sub></sup>). This process can be repeated to remove more error terms to get even better approximations.</p>
<p>A general <a href="recurrence_relation" title="wikilink">recurrence relation</a> can be defined for the approximations by</p>
<p><span class="LaTeX">$$A_{i+1}(h) = \frac{t^{k_i}A_i\left(\frac{h}{t}\right) - A_i(h)}{t^{k_i}-1}$$</span> such that</p>
<p><span class="LaTeX">$$A = A_{i+1}(h) + O(h^{k_{i+1}})$$</span> with <span class="LaTeX">$A_0=A(h)$</span>.</p>
<p>The Richardson extrapolation can be considered as a linear <a href="sequence_transformation" title="wikilink">sequence transformation</a>.</p>
<p>Additionally, the general formula can be used to estimate <em>k</em><sub>0</sub> when neither its value nor <em>A</em> is known <em>a priori</em>. Such a technique can be useful for quantifying an unknown <a href="rate_of_convergence" title="wikilink">rate of convergence</a>. Given approximations of <em>A</em> from three distinct step sizes <em>h</em>, <em>h / t</em>, and <em>h / s</em>, the exact relationship</p>
<p><span class="LaTeX">$$A=\frac{t^{k_0}A\left(\frac{h}{t}\right) - A(h)}{t^{k_0}-1} + O(h^{k_1}) = \frac{s^{k_0}A\left(\frac{h}{s}\right) - A(h)}{s^{k_0}-1} + O(h^{k_1})$$</span> yields an approximate relationship</p>
<p><span class="LaTeX">$$A\left(\frac{h}{t}\right) + \frac{A\left(\frac{h}{t}\right) - A(h)}{t^{k_0}-1} \approx A\left(\frac{h}{s}\right) +\frac{A\left(\frac{h}{s}\right) - A(h)}{s^{k_0}-1}$$</span> which can be solved numerically to estimate <em>k</em><sub>0</sub>.</p>
<h2 id="example">Example</h2>
<p>Using <a href="Taylor's_theorem" title="wikilink">Taylor's theorem</a> about h=0,</p>
<p><span class="LaTeX">$$f(x+h) = f(x) + f'(x)h + \frac{f''(x)}{2}h^2 + \cdots$$</span> the derivative of <em>f</em>(<em>x</em>) is given by</p>
<p><span class="LaTeX">$$f'(x) = \frac{f(x+h) - f(x)}{h} - \frac{f''(x)}{2}h + \cdots.$$</span></p>
<p>If the initial approximations of the derivative are chosen to be</p>
<p><span class="LaTeX">$$A_0(h) = \frac{f(x+h) - f(x)}{h}$$</span> then <em>k<sub>i</sub></em> = <em>i</em>+1.</p>
<p>For <em>t</em> = 2, the first formula extrapolated for <em>A</em> would be</p>
<p><span class="LaTeX">$$A = 2A_0\!\left(\frac{h}{2}\right) - A_0(h) + O(h^2) .$$</span></p>
<p>For the new approximation</p>
<p><span class="LaTeX">$$A_1(h) = 2A_0\!\left(\frac{h}{2}\right) - A_0(h)$$</span> we can extrapolate again to obtain</p>
<p><span class="LaTeX">$$A = \frac{4A_1\!\left(\frac{h}{2}\right) - A_1(h)}{3} + O(h^3) .$$</span></p>
<h2 id="example-pseudocode-code-for-richardson-extrapolation">Example pseudocode code for Richardson extrapolation</h2>
<p>The following pseudocode in MATLAB style demonstrates Richardson extrapolation to help solve the ODE <span class="LaTeX">$y'(t) = -y^2$</span>, <span class="LaTeX">$y(0) = 1$</span> with the Trapezoidal method. In this example we half the step size <span class="LaTeX">$h$</span> each iteration and so in the discussion above we'd have that <span class="LaTeX">$t = 2$</span>. The error of the Trapezoidal method can be expressed in terms of odd powers so that the error over multiple steps can be expressed in even powers and so we take powers of <span class="LaTeX">$4 = 2^2 = t^2$</span> in the pseudocode. We want to find the value of <span class="LaTeX">$y(5)$</span>, which has the exact solution of <span class="LaTeX">$\frac{1}{5 + 1} = \frac{1}{6} = 0.1666...$</span> since the exact solution of the ODE is <span class="LaTeX">$y(t) = \frac{1}{1 + t}$</span>. This pseudocode assumes that a function called <code>Trapezoidal(f, tStart, tEnd, h, y0)</code> exists which performs the trapezoidal method on the function <code>f</code>, with starting point <code>y0</code> and <code>tStart</code>, step size <code>h</code>, and attempts to computes <code>y(tEnd)</code></p>
<p>Starting with too small an initial step size can potentially introduce error into the final solution. Although there are methods designed to help pick the best initial step size, one option is to start with a large step size and then to allow the Richardson extrapolation to reduce the step size each iteration until the error reaches the desired tolerance.</p>
<div class="sourceCode"><pre class="sourceCode matlab"><code class="sourceCode matlab">tStart = <span class="fl">0</span>          <span class="co">%Starting time</span>
tEnd = <span class="fl">5</span>            <span class="co">%Ending time</span>
f = -y^<span class="fl">2</span>            <span class="co">%The derivative of y, so y' = f(t, y(t)) = -y^2</span>
                    <span class="co">% The solution to this ODE is y = 1/(1 + t)</span>
y0 = <span class="fl">1</span>              <span class="co">%The initial position (i.e. y0 = y(tStart) = y(0) = 1)</span>
tolerance = <span class="fl">10</span>^-<span class="fl">11</span>  <span class="co">%10 digit accuracy is desired</span>

maxRows = <span class="fl">20</span>                <span class="co">%Don't allow the iteration to continue indefinitely</span>
initialH = tStart - tEnd    <span class="co">%Pick an initial step size</span>
haveWeFoundSolution = false <span class="co">%Were we able to find the solution to the desired tolerance? not yet.</span>

h = initialH

<span class="co">%Create a 2D matrix of size maxRows by maxRows to hold the Richardson extrapolates</span>
<span class="co">%Note that this will be a lower triangular matrix and that at most two rows are actually</span>
<span class="co">% needed at any time in the compuation.</span>
A = zeroMatrix(maxRows, maxRows)

<span class="co">%Compute the top left element of the matrix</span>
A(<span class="fl">1</span>, <span class="fl">1</span>) = Trapezoidal(f, tStart, tEnd, h, y0)

<span class="co">%Each row of the matrix requires one call to Trapezoidal</span>
<span class="co">%This loops starts by filling the second row of the matrix, since the first row was computed above</span>
for i = <span class="fl">1</span> : maxRows - <span class="fl">1</span> <span class="co">%Starting at i = 1, iterate at most maxRows - 1 times</span>
    h = h/<span class="fl">2</span>             <span class="co">%Half the previous value of h since this is the start of a new row</span>
    
    <span class="co">%Call the Trapezoidal function with this new smaller step size</span>
    A(i + <span class="fl">1</span>, <span class="fl">1</span>) = Trapezoidal(f, tStart, tEnd, h, y0)
    
    for j = <span class="fl">1</span> : i         <span class="co">%Go across the row until the diagonal is reached</span>
        <span class="co">%Use the last value computed (i.e. A(i + 1, j)) and the element from the</span>
        <span class="co">% row above it (i.e. A(i, j)) to compute the next Richardson extrapolate</span>
     
        A(i + <span class="fl">1</span>, j + <span class="fl">1</span>) = ((<span class="fl">4</span>^j).*A(i + <span class="fl">1</span>, j) - A(i, j))/(<span class="fl">4</span>^j - <span class="fl">1</span>);
    end
    
    <span class="co">%After leaving the above inner loop, the diagonal element of row i + 1 has been computed</span>
    <span class="co">% This diagonal element is the last Richardson extrapolate to be computed  </span>
    <span class="co">%The difference between this extrapolate and the last extrapolate of row i is a good</span>
    <span class="co">% indication of the error</span>
    if(absoluteValue(A(i + <span class="fl">1</span>, i + <span class="fl">1</span>) - A(i, i)) < tolerance)   <span class="co">%If the result is within tolerance</span>
        print("y(<span class="fl">5</span>) = ", A(i + <span class="fl">1</span>, i + <span class="fl">1</span>))                      <span class="co">%Display the result of the Richardson extrapolation</span>
        haveWeFoundSolution = true
        break                                                  <span class="co">%Done, so leave the loop</span>
    end
end

if(haveWeFoundSolution == false)   <span class="co">%If we weren't able to find a solution to within the desired tolerance</span>
    print("Warning: Not able to find solution to within the desired tolerance of ", tolerance);
    print("The last computed extrapolate was ", A(maxRows, maxRows))
end</code></pre></div>
<h2 id="see-also">See also</h2>
<ul>
<li><a href="Aitken's_delta-squared_process" title="wikilink">Aitken's delta-squared process</a></li>
<li><a href="Takebe_Kenko" title="wikilink">Takebe Kenko</a></li>
<li><a href="Richardson_iteration" title="wikilink">Richardson iteration</a></li>
</ul>
<h2 id="references">References</h2>
<references>
</references>
<ul>
<li><em>Extrapolation Methods. Theory and Practice</em> by C. Brezinski and M. Redivo Zaglia, North-Holland, 1991.</li>
</ul>
<h2 id="external-links">External links</h2>
<ul>
<li><a href="http://math.fullerton.edu/mathews/n2003/RichardsonExtrapMod.html">Module for Richardson's Extrapolation</a>, fullerton.edu</li>
<li><a href="http://ocw.mit.edu/courses/mathematics/18-304-undergraduate-seminar-in-discrete-mathematics-spring-2006/projects/xtrpltn_liu_xpnd.pdf">Fundamental Methods of Numerical Extrapolation With Applications</a>, mit.edu</li>
<li><a href="http://www.math.ubc.ca/~feldman/m256/richard.pdf">Richardson-Extrapolation</a></li>
<li><a href="http://www.math.ubc.ca/~israel/m215/rich/rich.html">Richardson extrapolation on a website of Robert Israel (University of British Columbia)</a></li>
</ul>
<p>"</p>
<p><a href="Category:Numerical_analysis" title="wikilink">Category:Numerical analysis</a> <a href="Category:Asymptotic_analysis" title="wikilink">Category:Asymptotic analysis</a> <a href="Category:Articles_with_example_MATLAB/Octave_code" title="wikilink">Category:Articles with example MATLAB/Octave code</a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1"><a href="#fnref1">↩</a></li>
<li id="fn2"><a href="#fnref2">↩</a></li>
<li id="fn3">Page 126 of <a href="#fnref3">↩</a></li>
</ol>
</section>
</body>
</html>
