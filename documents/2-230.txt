


Degenerate distribution




Degenerate distribution

In mathematics, a degenerate distribution or deterministic distribution is the probability distribution of a random variable which only takes a single value. Examples include a two-headed coin and rolling a die whose sides all show the same number. This distribution satisfies the definition of "random variable" even though it does not appear random in the everyday sense of the word; hence it is considered degenerate.
The degenerate distribution is localized at a point k0 on the real line. The probability mass function equals 1 at this point and 0 elsewhere.
The distribution can be viewed as the limiting case of a continuous distribution whose variance goes to 0 causing the probability density function to be a delta function at k0, with infinite height there but area equal to 1.
The cumulative distribution function of the degenerate distribution is:
$F(k;k_0)=\left\{\begin{matrix} 1, & \mbox{if }k\ge k_0 \\ 0, & \mbox{if }k
 
 ==Constant random variable==
 In [[probability theory]], a '''constant random variable''' is a [[discrete random variable|discrete]] [[random variable]] that takes a [[Constant function|constant]] value, regardless of any [[event (probability theory)|event]] that occurs.  This is technically different from an '''[[almost surely]] constant random variable''', which may take other values, but only on events with probability zero.  Constant and almost surely constant random variables provide a way to deal with constant values in a probabilistic framework.
 
 Let   ''X'': Ω → '''R'''  be a random variable defined on a probability space  (Ω, ''P'').  Then  ''X''  is an ''almost surely constant random variable'' if there exists  such that
$$\Pr(X = c) = 1,$$ and is furthermore a constant random variable if
$$X(\omega) = c, \quad \forall\omega \in \Omega.$$
Note that a constant random variable is almost surely constant, but not necessarily vice versa, since if  X  is almost surely constant then there may exist  γ ∈ Ω  such that  X(γ) ≠ c  (but then necessarily Pr({γ}) = 0, in fact Pr(X ≠ c) = 0).
For practical purposes, the distinction between  X  being constant or almost surely constant is unimportant, since the cumulative distribution function  F(x)  of  X  does not depend on whether  X  is constant or 'merely' almost surely constant. In this case,
$$F(x) = \begin{cases}1, &x \geq c,\\0, &x < c.\end{cases}$$ The function  F(x)  is a step function; in particular it is a translation of the Heaviside step function.
"
Category:Discrete distributions Category:Types of probability distributions Category:Infinitely divisible probability distributions Category:Probability distributions


