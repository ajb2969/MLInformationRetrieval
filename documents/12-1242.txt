


Fundamental theorem of calculus




Fundamental theorem of calculus

The fundamental theorem of calculus is a theorem that links the concept of the derivative of a function with the concept of the function's integral.
The first part of the theorem, sometimes called the first fundamental theorem of calculus, is that the definite integration of a function1 is related to its antiderivative, and can be reversed by differentiation. This part of the theorem is also important because it guarantees the existence of antiderivatives for continuous functions.2
The second part of the theorem, sometimes called the second fundamental theorem of calculus, is that the definite integral of a function can be computed by using any one of its infinitely-many antiderivatives. This part of the theorem has key practical applications because it markedly simplifies the computation of definite integrals. 
History
The fundamental theorem of calculus relates differentiation and integration, showing that these two operations are essentially inverses of one another. Before the discovery of this theorem, it was not recognized that these two operations were related. Ancient Greek mathematicians knew how to compute area via infinitesimals, an operation that we would now call integration. The origins of differentiation likewise predate the Fundamental Theorem of Calculus by hundreds of years; for example, in the fourteenth century the notions of continuity of functions and motion was studied by the Oxford Calculators and other scholars. The historical relevance of the Fundamental Theorem of Calculus is not the ability to calculate these operations, but the realization that the two seemingly distinct operations (calculation of geometric areas, and calculation of velocities) are actually closely related.
The first published statement and proof of a restricted version of the fundamental theorem was by James Gregory (1638–1675).3 Isaac Barrow (1630–1677) proved a more generalized version of the theorem4 while Barrow's student Isaac Newton (1643–1727) completed the development of the surrounding mathematical theory. Gottfried Leibniz (1646–1716) systematized the knowledge into a calculus for infinitesimal quantities and introduced the notation used today.
Geometric meaning
 For a continuous function  whose graph is plotted as a curve, each value of x has a corresponding area function A(x), representing the area beneath the curve between 0 and x. The function A(x) may not be known, but it is given that it represents the area under the curve.
The area under the curve between x and  could be computed by finding the area between 0 and  then subtracting the area between 0 and x. In other words, the area of this “sliver” would be .
There is another way to estimate the area of this same sliver. As shown in the accompanying figure, h is multiplied by f(x) to find the area of a rectangle that is approximately the same size as this sliver. So:



In fact, this estimate becomes a perfect equality if we add the red portion of the "excess" area shown in the diagram. So:



Rearranging terms:


 
 .
As h approaches 0 in the limit, the last fraction can be shown to go to zero.5 This is true because the area of the red portion of excess region is less than or equal to the area of the tiny black-bordered rectangle; the area of that tiny rectangle, divided by h, is simply the height of the tiny rectangle, which can be seen to go to zero as h goes to zero.
Removing the last fraction from our equation then, we have:


 
 .
It can thus be shown that . That is, the derivative of the area function A(x) is the original function f(x); or, the area function is simply an antiderivative of the original function. Computing the derivative of a function and “finding the area” under its curve are "opposite" operations. This is the crux of the Fundamental Theorem of Calculus.
Physical intuition
Intuitively, the theorem simply states that the sum of infinitesimal changes in a quantity over time (or over some other variable) adds up to the net change in the quantity.
Imagine for example using a stopwatch to mark-off tiny increments of time as a car travels down a highway. Imagine also looking at the car's speedometer as it travels, so that at every moment you know the velocity of the car. To understand the power of this theorem, imagine also that you are not allowed to look out the window of the car, so that you have no direct evidence of how far the car has traveled.
For any tiny interval of time in the car, you could calculate how far the car has traveled in that interval by multiplying the current speed of the car times the length of that tiny interval of time. (This is because distance = speed

time.)
Now imagine doing this instant after instant, so that for every tiny interval of time you know how far the car has traveled. In principle, you could then calculate the total distance traveled in the car (even though you've never looked out the window) by simply summing-up all those tiny distances.

distance traveled = 
 
 
 
  the velocity at any instant 
 
 
 
  a tiny interval of time
 

In other words,

distance traveled = 
 
 


On the right hand side of this equation, as 
 
 
 
  becomes infinitesimally small, the operation of "summing up" corresponds to integration. So what we've shown is that the integral of the velocity function can be used to compute how far the car has traveled.
Now remember that the velocity function is simply the derivative of the position function. So what we have really shown is that integrating the velocity simply recovers the original position function. This is the basic idea of the Theorem: that integration and differentiation are closely related operations, each essentially being the inverse of the other.
In other words, in terms of one's physical intuition, the theorem simply states that the sum of the changes in a quantity over time (such as position, as calculated by multiplying velocity times time) adds up to the total net change in the quantity. Or to put this more generally:

Given a quantity 
 
 
 
  that changes over some variable 
 
 
 
 , and
Given the velocity 
 
 
 
  with which that quantity changes over that variable

then the idea that "distance equals speed times time" corresponds to the statement


 
  meaning that one can recover the original function 
 
 
 
  by integrating its derivative, the velocity 
 
 
 
 , over 
 
 
 
 .
Formal statements
There are two parts to the theorem. Loosely put, the first part deals with the derivative of an antiderivative, while the second part deals with the relationship between antiderivatives and definite integrals.
First part
This part is sometimes referred to as the first fundamental theorem of calculus.6
Let f be a continuous real-valued function defined on a closed interval [a, b]. Let F be the function defined, for all x in [a, b], by
 


Then, F is uniformly continuous on [a, b], differentiable on the open interval  and
 


for all x in (a, b).
Alternatively, if f is merely Riemann integrable, then F is continuous on [a, b] (but not necessarily differentiable).
Corollary
The fundamental theorem is often employed to compute the definite integral of a function f for which an antiderivative F is known. Specifically, if f is a real-valued continuous function on  and F is an antiderivative of f in  then
 


The corollary assumes continuity on the whole interval. This result is strengthened slightly in the following part of the theorem.
Second part
This part is sometimes referred to as the second fundamental theorem of calculus7 or the Newton–Leibniz axiom.
Let f and F be real-valued functions defined on a closed interval [a, b] such that the derivative of F is f. That is, f and F are functions such that for all x in  
 
 

If f is Riemann integrable on  then
 


The Second part is somewhat stronger than the Corollary because it does not assume that f is continuous.
When an antiderivative F exists, then there are infinitely many antiderivatives for f, obtained by adding to F an arbitrary constant. Also, by the first part of the theorem, antiderivatives of f always exist when f is continuous.
Proof of the first part
For a given f(t), define the function F(x) as



For any two numbers x1 and x1 + Δx in [a, b], we have


 
  and



Subtracting the two equalities gives



It can be shown that




(The sum of the areas of two adjacent regions is equal to the area of both regions combined.)
 

Manipulating this equation gives



Substituting the above into (1) results in



According to the mean value theorem for integration, there exists a real number 
 
 
 
  in [x1, x1 + Δx] such that



To keep the notation simple we will continue writing c instead of 
 
 
 
  but one should keep in mind that c does depend on 
 
 
 
 . Substituting the above into (2) we get



Dividing both sides by Δx gives




The expression on the left side of the equation is Newton's difference quotient for F at x1.
 

Take the limit as Δx → 0 on both sides of the equation.



The expression on the left side of the equation is the definition of the derivative of F at x1.



To find the other limit, we use the squeeze theorem. The number c is in the interval [x1, x1 + Δx], so x1 ≤ c ≤ x1 + Δx.
Also, 
 
 
 
  and 
 
 

Therefore, according to the squeeze theorem,



Substituting into (3), we get



The function f is continuous at c, so the limit can be taken inside the function. Therefore, we get


 
  which completes the proof.
(Leithold et al., 1996)  (a rigorous proof can be found http://www.imomath.com/index.php?options=438)
Proof of the corollary
Suppose F is an antiderivative of f, with f continuous on  Let


 
 .
By the first part of the theorem, we know G is also an antiderivative of f. Since F' - G' = 0 the mean value theorem implies that F - G is a constant function, i. e. there is a number c such that , for all x in  Letting , we have



which means  In other words , and so



Proof of the second part
This is a limit proof by Riemann sums. Let f be (Riemann) integrable on the interval  and let f admit an antiderivative F on  Begin with the quantity . Let there be numbers x1, ..., xn such that



It follows that



Now, we add each F(xi) along with its additive inverse, so that the resulting quantity is equal:



The above quantity can be written as the following sum:



Next, we employ the mean value theorem. Stated briefly,
Let F be continuous on the closed interval [a, b] and differentiable on the open interval (a, b). Then there exists some c in (a, b) such that



It follows that



The function F is differentiable on the interval  therefore, it is also differentiable and continuous on each interval . According to the mean value theorem (above),



Substituting the above into (1), we get



The assumption implies 
 
 
 
  Also, 
 
 
 
  can be expressed as 
 
 
 
  of partition 
 
 
 
 .



(Figure)
A converging sequence of Riemann sums. The number in the upper left is the total area of the blue rectangles. They converge to the integral of the function.

We are describing the area of a rectangle, with the width times the height, and we are adding the areas together. Each rectangle, by virtue of the mean value theorem, describes an approximation of the curve section it is drawn over. Also 
 
 
 
  need not be the same for all values of i, or in other words that the width of the rectangles can differ. What we have to do is approximate the curve with n rectangles. Now, as the size of the partitions get smaller and n increases, resulting in more partitions to cover the space, we get closer and closer to the actual area of the curve.
By taking the limit of the expression as the norm of the partitions approaches zero, we arrive at the Riemann integral. We know that this limit exists because f was assumed to be integrable. That is, we take the limit as the largest of the partitions approaches zero in size, so that all other partitions are smaller and the number of partitions approaches infinity.
So, we take the limit on both sides of (2). This gives us



Neither F(b) nor F(a) is dependent on 
 
 
 
 , so the limit on the left side remains 



The expression on the right side of the equation defines the integral over f from a to b. Therefore, we obtain



which completes the proof.
It almost looks like the first part of the theorem follows directly from the second. That is, suppose G is an antiderivative of f. Then by the second theorem, 
 
 
 
 . Now, suppose 
 
 
 
 . Then F has the same derivative as G, and therefore . This argument only works, however, if we already know that f has an antiderivative, and the only way we know that all continuous functions have antiderivatives is by the first part of the Fundamental Theorem.8 For example if  e−x2,}} then f has an antiderivative, namely



and there is no simpler expression for this function. It is therefore important not to interpret the second part of the theorem as the definition of the integral. Indeed, there are many functions that are integrable but lack antiderivatives that can be written as an elementary function. Conversely, many functions that have antiderivatives are not Riemann integrable (see Volterra's function).
Examples
As an example, suppose the following is to be calculated:



Here, 
 
 
 
  and we can use 
 
 
 
  as the antiderivative. Therefore:



Or, more generally, suppose that


 
  is to be calculated. Here, 
 
 
 
  and 
 
 
 
  can be used as the antiderivative. Therefore:



Or, equivalently,



Generalizations
We don't need to assume continuity of f on the whole interval. Part I of the theorem then says: if f is any Lebesgue integrable function on  and x0 is a number in  such that f is continuous at x0, then



is differentiable for  x0}} with  f(x0).}} We can relax the conditions on f still further and suppose that it is merely locally integrable. In that case, we can conclude that the function F is differentiable almost everywhere and  almost everywhere. On the real line this statement is equivalent to Lebesgue's differentiation theorem. These results remain true for the Henstock–Kurzweil integral, which allows a larger class of integrable functions .
In higher dimensions Lebesgue's differentiation theorem generalizes the Fundamental theorem of calculus by stating that for almost every x, the average value of a function f over a ball of radius r centered at x tends to f(x) as r tends to 0.
Part II of the theorem is true for any Lebesgue integrable function f, which has an antiderivative F (not all integrable functions do, though). In other words, if a real function F on  admits a derivative f(x) at every point x of  and if this derivative f is Lebesgue integrable on  then


9
This result may fail for continuous functions F that admit a derivative f(x) at almost every point x, as the example of the Cantor function shows. However, if F is absolutely continuous, it admits a derivative F′(x) at almost every point x, and moreover F′ is integrable, with  equal to the integral of F′ on  Conversely, if f is any integrable function, then F as given in the first formula will be absolutely continuous with F′ = f a.e.
The conditions of this theorem may again be relaxed by considering the integrals involved as Henstock–Kurzweil integrals. Specifically, if a continuous function F(x) admits a derivative f(x) at all but countably many points, then f(x) is Henstock–Kurzweil integrable and  is equal to the integral of f on  The difference here is that the integrability of f does not need to be assumed. 
The version of Taylor's theorem, which expresses the error term as an integral, can be seen as a generalization of the Fundamental Theorem.
There is a version of the theorem for complex functions: suppose U is an open set in C and  is a function that has a holomorphic antiderivative F on U. Then for every curve  the curve integral can be computed as



The fundamental theorem can be generalized to curve and surface integrals in higher dimensions and on manifolds. One such generalization offered by the calculus of moving surfaces is the time evolution of integrals. The most familiar extensions of the Fundamental theorem of calculus in higher dimensions are the Divergence theorem and the Gradient theorem.
One of the most powerful statements in this direction is Stokes' theorem: Let M be an oriented piecewise smooth manifold of dimension n and let 
 
 
 
  be an n−1 form that is a compactly supported differential form on M of class C1. If ∂M denotes the boundary of M with its induced orientation, then



Here d is the exterior derivative, which is defined using the manifold structure only.
The theorem is often used in situations where M is an embedded oriented submanifold of some bigger manifold on which the form 
 
 
 
  is defined.
See also

Differentiation under the integral sign
Telescoping series

Notes


References


.

.

.

.
Malet, A, Studies on James Gregorie (1638-1675) (PhD Thesis, Princeton, 1989).


.

.

.

.

Further reading

Hernandez Rodriguez, O. A.; Lopez Fernandez, J. M. . "Teaching the Fundamental Theorem of Calculus: A Historical Reflection", Loci: Convergence (MAA), January 2012.

External links


[http://mathdl.maa.org/convergence/1/?pa=content&sa;;=viewDocument&nodeId;=388&bodyId;=343 James Gregory's Euclidean Proof of the Fundamental Theorem of Calculus] at Convergence
Isaac Barrow's proof of the Fundamental Theorem of Calculus
Fundamental Theorem of Calculus at imomath.com
Alternative proof the to the fundamental theorem of calculus

"
Category:Articles containing proofs Calculus Category:Theorems in calculus Category:Theorems in real analysis



More exactly, the theorem deals with definite integration with variable upper limit and arbitrarily selected lower limit. This particular kind of definite integration allows us to compute one of the infinitely many antiderivatives of a function (except for those that do not have a zero). Hence, it is almost equivalent to indefinite integration, defined by most authors as an operation that yields any one of the possible antiderivatives of a function, including those without a zero.↩
↩
See, e.g., Marlow Anderson, Victor J. Katz, Robin J. Wilson, Sherlock Holmes in Babylon and Other Tales of Mathematical History, Mathematical Association of America, 2004, [http://books.google.com/books?vid=ISBN0883855461&id;;=BKRE5AjRM3AC&pg;=PA114&lpg;=PA114&ots;=Z01TZKrQXY&dq;=%22james+gregory%22+%22fundamental+theorem%22&sig;=6xDqL0oNAhWw66IqPdI5fQX7euA p. 114].↩
https://archive.org/details/geometricallectu00barruoft↩
Bers, Lipman. Calculus, pp. 180-181 (Holt, Rinehart and Winston (1976).↩
↩
↩
↩
↩




