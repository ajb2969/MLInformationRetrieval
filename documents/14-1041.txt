   GV-linear-code      GV-linear-code   In coding theory , the bound of parameters such as rate R , relative distance, block length , etc. is usually concerned. Here Gilbertâ€“Varshamov bound theorem claims the lower bound of the rate of the general code. Gilbertâ€“Varshamov bound is the best in term of relative distance for codes over alphabets of size less than 49.  Gilbertâ€“Varshamov bound theorem  Theorem: Let    q  â‰¥  2      q  2    q\geq 2   . For every    0  â‰¤  Î´  <   1  -   1  q          0  Î´         1    1  q       0\leq\delta<1-\frac{1}{q}   , and    0  <  Îµ  â‰¤   1  -    H  q    (  Î´  )           0  Îµ         1     subscript  H  q   Î´       0<\varepsilon\leq 1-H_{q}(\delta)   , there exists a code with rate    R  â‰¥   1  -    H  q    (  Î´  )    -  Îµ       R    1     subscript  H  q   Î´   Îµ     R\geq 1-H_{q}(\delta)-\varepsilon   , and relative distance   Î´   Î´   \delta   .  Here    H  q     subscript  H  q    H_{q}   is the q -ary entropy function defined as follows:         H  q    (  x  )    =    x    log  q    (   q  -  1   )     -   x    log  q   x    -    (   1  -  x   )     log  q    (   1  -  x   )       .         subscript  H  q   x       x    subscript   q     q  1       x    subscript   q   x        1  x     subscript   q     1  x        H_{q}(x)=x\log_{q}(q-1)-x\log_{q}x-(1-x)\log_{q}(1-x).     The above result was proved by Edgar Gilbert for general code using the greedy method as here . For linear code , Varshamov proved using the probabilistic method for the random linear code. This proof will be shown in the following part.  High-level proof:  To show the existence of the linear code that satisfies those constraints, the probabilistic method is used to construct the random linear code. Specifically the linear code is chosen randomly by choosing the random generator matrix   G   G   G   in which the element is chosen uniformly over the field    ð”½  q  n     superscript   subscript  ð”½  q   n    \mathbb{F}_{q}^{n}   . Also the Hamming distance of the linear code is equal to the minimum weight of the codeword . So to prove that the linear code generated by   G   G   G   has Hamming distance   d   d   d   , we will show that for any     m  âˆˆ    ð”½  q  k   \   {  0  }     ,    w  t   (   m  G   )    â‰¥  d      formulae-sequence    m   normal-\   superscript   subscript  ð”½  q   k    0         w  t    m  G    d     m\in\mathbb{F}_{q}^{k}\backslash\left\{0\right\},wt(mG)\geq d   . To prove that, we prove the opposite one; that is, the probability that the linear code generated by   G   G   G   has the Hamming distance less than   d   d   d   is exponentially small in   n   n   n   . Then by probabilistic method, there exists the linear code satisfying the theorem.  Formal proof:  By using the probabilistic method, to show that there exists a linear code that has a Hamming distance greater than   d   d   d   , we will show that the probability that the random linear code having the distance less than   d   d   d   is exponentially small in   n   n   n   .  We know that the linear code is defined using the generator matrix . So we use the "random generator matrix"   G   G   G   as a mean to describe the randomness of the linear code. So a random generator matrix   G   G   G   of size    k  n      k  n    kn   contains    k  n      k  n    kn   elements which are chosen independently and uniformly over the field    ð”½  q     subscript  ð”½  q    \mathbb{F}_{q}   .  Recall that in a linear code, the distance = the minimum weight of the non-zero codeword. This fact is one of the properties of linear code .  Denote    w  t   (  y  )       w  t  y    wt(y)   be the weight of the codeword   y   y   y   . So     P   P   \displaystyle P     Also if codeword   y   y   y   belongs to a linear code generated by   G   G   G   , then    y  =   m  G       y    m  G     y=mG   for some vector    m  âˆˆ   ð”½  q  k       m   superscript   subscript  ð”½  q   k     m\in\mathbb{F}_{q}^{k}   .  Therefore    P  =    Pr   random  G     [    there exists a vector  m   âˆˆ     ð”½  q  k   \   {  0  }    such that  w  t   (   m  G   )    <  d   ]        P    subscript  Pr    random  G          there exists a vector  m      normal-\   superscript   subscript  ð”½  q   k    0    such that  w  t    m  G         d       P={\Pr}_{\text{random }G}[\text{there exists a vector }m\in\mathbb{F}_{q}^{k}%
 \backslash\{0\}\text{ such that }wt(mG)     By Boole's inequality , we have:      P  â‰¤    âˆ‘   m  âˆˆ    ð”½  q  k   \   {  0  }        Pr   random  G     [    w  t   (   m  G   )    <  d   ]         P    subscript     m   normal-\   superscript   subscript  ð”½  q   k    0        subscript  Pr    random  G        w  t    m  G    d       P\leq\sum\limits_{m\in\mathbb{F}_{q}^{k}\backslash\{0\}}{{\Pr}_{\text{random }%
 G}}[wt(mG)     Now for a given message    m  âˆˆ    ð”½  q  k   \   {  0  }        m   normal-\   superscript   subscript  ð”½  q   k    0      m\in\mathbb{F}_{q}^{k}\backslash\{0\}   , we want to compute    W  =    Pr   random  G     [    w  t   (   m  G   )    <  d   ]        W    subscript  Pr    random  G        w  t    m  G    d      W={\Pr}_{\text{random }G}[wt(mG)     Denote    Î”   (   m  1   ,   m  2   )       normal-Î”    subscript  m  1    subscript  m  2      \Delta(m_{1},m_{2})   be a Hamming distance of two messages    m  1     subscript  m  1    m_{1}   and    m  2     subscript  m  2    m_{2}     Then for any message   m   m   m   , we have     w  t   (  m  )    =   Î”   (  0  ,  m  )          w  t  m     normal-Î”   0  m      wt(m)=\Delta(0,m)   .  Using this fact, we can come up with the following equality:      W  =    âˆ‘    all  y   âˆˆ    ð”½  q  n   s.t.  Î”   (  0  ,  y  )    â‰¤   d  -  1       Pr   random  G     [    m  G   =  y   ]         W    subscript         all  y      superscript   subscript  ð”½  q   n   s.t.  normal-Î”   0  y           d  1        subscript  Pr    random  G        m  G   y       W=\sum\limits_{\text{all }y\in\mathbb{F}_{q}^{n}\text{s.t. }\Delta(0,y)\leq d-%
 1}{{\Pr}_{\text{random }G}[mG=y]}     Due to the randomness of   G   G   G   ,    m  G      m  G    mG   is a uniformly random vector from    ð”½  q  n     superscript   subscript  ð”½  q   n    \mathbb{F}_{q}^{n}   .  So      Pr   random  G     [    m  G   =  y   ]    =   q   -  n          subscript  Pr    random  G        m  G   y     superscript  q    n      {\Pr}_{\text{random }G}[mG=y]=q^{-n}     Let     Vol  q    (  r  ,  n  )        subscript  Vol  q    r  n     \text{Vol}_{q}(r,n)   is a volume of Hamming ball with the radius   r   r   r   . Then:      W  =     Vol  q    (   d  -  1   ,  n  )     q  n    â‰¤     Vol  q    (   Î´  n   ,  n  )     q  n    â‰¤    q   n   H  q    (  Î´  )      q  n          W       subscript  Vol  q      d  1   n     superscript  q  n              subscript  Vol  q      Î´  n   n     superscript  q  n            superscript  q    n   subscript  H  q   Î´     superscript  q  n       W=\frac{\text{Vol}_{q}(d-1,n)}{q^{n}}\leq\frac{\text{Vol}_{q}(\delta n,n)}{q^{%
 n}}\leq\frac{q^{nH_{q}(\delta)}}{q^{n}}     (The later inequality comes from the upper bound of the Volume of Hamming ball )  Then      P  â‰¤    q  k   â‹…  W   â‰¤    q  k     q   n   H  q    (  Î´  )      q  n     =    q  k    q   -   n   (   1  -    H  q    (  Î´  )     )             P   normal-â‹…   superscript  q  k   W           superscript  q  k      superscript  q    n   subscript  H  q   Î´     superscript  q  n             superscript  q  k    superscript  q      n    1     subscript  H  q   Î´           P\leq q^{k}\cdot W\leq q^{k}\frac{q^{nH_{q}(\delta)}}{q^{n}}=q^{k}q^{-n(1-H_{q%
 }(\delta))}     By choosing    k  =    (   1  -    H  q    (  Î´  )    -  Îµ   )   n       k      1     subscript  H  q   Î´   Îµ   n     k=(1-H_{q}(\delta)-\varepsilon)n   , the above inequality becomes      P  â‰¤   q   -   Îµ  n         P   superscript  q      Îµ  n       P\leq q^{-\varepsilon n}     Finally     q   -   Îµ  n     â‰ª  1     much-less-than   superscript  q      Îµ  n     1    q^{-\varepsilon n}\ll 1   , which is exponentially small in n, that is what we want before. Then by the probabilistic method, there exists a linear code   C   C   C   with relative distance   Î´   Î´   \delta   and rate   R   R   R   at least    (   1  -    H  q    (  Î´  )    -  Îµ   )      1     subscript  H  q   Î´   Îµ    (1-H_{q}(\delta)-\varepsilon)   , which completes the proof.  Comments   The Varshamov construction above is not explicit; that is, it does not specify the deterministic method to construct the linear code that satisfies the Gilbertâ€“Varshamov bound. The naive way that we can do is to go over all the generator matrices   G   G   G   of size    k  n      k  n    kn   over the field    ð”½  q     subscript  ð”½  q    \mathbb{F}_{q}   and check if that linear code has the satisfied Hamming distance. That leads to the exponential time algorithm to implement it.  We also have a Las Vegas construction that takes a random linear code and checks if this code has good Hamming distance. Nevertheless, this construction has the exponential running time.   See also   Gilbertâ€“Varshamov bound due to Gilbert construction for the general code  Hamming Bound  Probabilistic method   References   Lecture 11: Gilbertâ€“Varshamov Bound. Coding Theory Course. Professor Atri Rudra  Lecture 9: Bounds on the Volume of Hamming Ball. Coding Theory Course. Professor Atri Rudra  Coding Theory's Notes: Gilbertâ€“Varshamov Bound. Venkatesan ï¿½Guruswami   "  Category:Coding theory   