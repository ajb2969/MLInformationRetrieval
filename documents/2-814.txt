   Bose‚ÄìEinstein statistics      Bose‚ÄìEinstein statistics   In quantum statistics , Bose‚ÄìEinstein statistics (or more colloquially B‚ÄìE statistics ) is one of two possible ways in which a collection of non-interacting indistinguishable particles may occupy a set of available discrete energy states , at thermodynamic equilibrium . The aggregation of particles in the same state, which is a characteristic of particles obeying Bose‚ÄìEinstein statistics, accounts for the cohesive streaming of laser light and the frictionless creeping of superfluid helium . The theory of this behaviour was developed (1924‚Äì25) by Satyendra Nath Bose , who recognized that a collection of identical and indistinguishable particles can be distributed in this way. The idea was later adopted and extended by Albert Einstein in collaboration with Bose.  The Bose‚ÄìEinstein statistics apply only to those particles not limited to single occupancy of the same state‚Äîthat is, particles that do not obey the Pauli exclusion principle restrictions. Such particles have integer values of spin and are named bosons , after the statistics that correctly describe their behaviour. There must also be no significant interaction between the particles.  Concept  At low temperatures, bosons behave differently from fermions (which obey the Fermi‚ÄìDirac statistics ) in a way that an unlimited number of them can "condense" into the same energy state. This apparently unusual property also gives rise to the special state of matter ‚Äì Bose Einstein Condensate . Fermi‚ÄìDirac and Bose‚ÄìEinstein statistics apply when quantum effects are important and the particles are " indistinguishable ". Quantum effects appear if the concentration of particles satisfies,       N  V   ‚â•   n  q         N  V    subscript  n  q     \frac{N}{V}\geq n_{q}     where N is the number of particles and V is the volume and n q is the quantum concentration , for which the interparticle distance is equal to the thermal de Broglie wavelength , so that the wavefunctions of the particles are barely overlapping. Fermi‚ÄìDirac statistics apply to fermions (particles that obey the Pauli exclusion principle ), and Bose‚ÄìEinstein statistics apply to bosons . As the quantum concentration depends on temperature, most systems at high temperatures obey the classical (Maxwell‚ÄìBoltzmann) limit unless they have a very high density, as for a white dwarf . Both Fermi‚ÄìDirac and Bose‚ÄìEinstein become Maxwell‚ÄìBoltzmann statistics at high temperature or at low concentration.  B‚ÄìE statistics was introduced for photons in 1924 by Bose and generalized to atoms by Einstein in 1924‚Äì25.  The expected number of particles in an energy state i for B‚ÄìE statistics is        n  i    (   Œµ  i   )    =    g  i     e     (    Œµ  i   -  Œº   )   /  k   T    -  1           subscript  n  i    subscript  Œµ  i       subscript  g  i      superscript  e         subscript  Œµ  i   Œº   k   T    1      n_{i}(\varepsilon_{i})=\frac{g_{i}}{e^{(\varepsilon_{i}-\mu)/kT}-1}   with Œµ i > Œº and where n i is the number of particles in state i , g i is the degeneracy of state i , Œµ i is the energy of the i th state, Œº is the chemical potential , k is the Boltzmann constant , and T is absolute temperature . For comparison, the average number of fermions with energy    œµ  i     subscript  œµ  i    \epsilon_{i}   given by Fermi‚ÄìDirac particle-energy distribution has a similar form,         n  ¬Ø   i    (   œµ  i   )    =    g  i     e     (    œµ  i   -  Œº   )   /  k   T    +  1           subscript   normal-¬Ø  n   i    subscript  œµ  i       subscript  g  i      superscript  e         subscript  œµ  i   Œº   k   T    1      \bar{n}_{i}(\epsilon_{i})=\frac{g_{i}}{e^{(\epsilon_{i}-\mu)/kT}+1}     B‚ÄìE statistics reduces to the Rayleigh‚ÄìJeans Law distribution for     k  T   ‚â´    Œµ  i   -  Œº      much-greater-than    k  T      subscript  Œµ  i   Œº     kT\gg\varepsilon_{i}-\mu   , namely     n  i   =     g  i   k  T     Œµ  i   -  Œº         subscript  n  i        subscript  g  i   k  T      subscript  Œµ  i   Œº      n_{i}=\frac{g_{i}kT}{\varepsilon_{i}-\mu}   .  History  While presenting a lecture at the University of Dhaka on the theory of radiation and the ultraviolet catastrophe , Satyendra Nath Bose intended to show his students that the contemporary theory was inadequate, because it predicted results not in accordance with experimental results. During this lecture, Bose committed an error in applying the theory, which unexpectedly gave a prediction that agreed with the experiment. The error was a simple mistake‚Äîsimilar to arguing that flipping two fair coins will produce two heads one-third of the time‚Äîthat would appear obviously wrong to anyone with a basic understanding of statistics (remarkably, this error resembled the famous blunder by d'Alembert known from his " Croix ou Pile " Article). However, the results it predicted agreed with experiment, and Bose realized it might not be a mistake after all. For the first time, he took the position that the Maxwell‚ÄìBoltzmann distribution would not be true for microscopic particles at a scale where fluctuations due to Heisenberg's uncertainty principle will be significant. Thus, he studied the probability of finding particles in various states in phase space, where each state is a little patch having volume h 3 , and the position and momentum of the particles are not kept particularly separate but are considered as one variable.  Bose adapted this lecture into a short article called "Planck's Law and the Hypothesis of Light Quanta" 1 2 and submitted it to the Philosophical Magazine . However, the referee's report was negative, and the paper was rejected. Undaunted, he sent the manuscript to Albert Einstein requesting publication in the Zeitschrift f√ºr Physik . Einstein immediately agreed, personally translated the article into German (Bose had earlier translated Einstein's article on the theory of General Relativity from German to English), and saw to it that it was published. Bose's theory achieved respect when Einstein sent his own paper in support of Bose's to Zeitschrift f√ºr Physik , asking that they be published together. This was done in 1924.  The reason Bose produced accurate results was that since photons are indistinguishable from each other, one cannot treat any two photons having equal energy as being two distinct identifiable photons. By analogy, if in an alternate universe coins were to behave like photons and other bosons, the probability of producing two heads would indeed be one-third, and so is the probability of getting a head and a tail which equals one-half for the conventional (classical, distinguishable) coins. Bose's "error" leads to what is now called Bose‚ÄìEinstein statistics.  Bose and Einstein extended the idea to atoms and this led to the prediction of the existence of phenomena which became known as Bose‚ÄìEinstein condensate , a dense collection of bosons (which are particles with integer spin, named after Bose), which was demonstrated to exist by experiment in 1995.  Two derivations of the Bose‚ÄìEinstein distribution  Derivation from the grand canonical ensemble  The Bose‚ÄìEinstein distribution, which applies only to a quantum system of non-interacting bosons, is easily derived from the grand canonical ensemble . 3 In this ensemble, the system is able to exchange energy and exchange particles with a reservoir (temperature T and chemical potential ¬µ fixed by the reservoir).  Due to the non-interacting quality, each available single-particle level (with energy level œµ ) forms a separate thermodynamic system in contact with the reservoir. In other words, each single-particle level is a separate, tiny grand canonical ensemble. With bosons there is no limit on the number of particles N in the level, but due to indistinguishability each possible N corresponds to only one microstate (with energy Nœµ ). The resulting partition function for that single-particle level therefore forms a geometric series :     ùíµ   ùíµ   \displaystyle\mathcal{Z}   and the average particle number for that single-particle substate is given by       ‚ü®  N  ‚ü©   =    k  B   T   1  ùíµ     (    ‚àÇ  ùíµ    ‚àÇ  Œº    )    V  ,  T     =   1    exp   (     (   œµ  -  Œº   )   /   k  B    T   )    -  1           delimited-‚ü®‚ü©  N      subscript  k  B   T    1  ùíµ    subscript      ùíµ     Œº     V  T            1            œµ  Œº    subscript  k  B    T    1       \langle N\rangle=k_{B}T\frac{1}{\mathcal{Z}}\left(\frac{\partial\mathcal{Z}}{%
 \partial\mu}\right)_{V,T}=\frac{1}{\exp((\epsilon-\mu)/k_{B}T)-1}   This result applies for each single-particle level and thus forms the Bose‚ÄìEinstein distribution for the entire state of the system. 4 5  The variance in particle number (due to thermal fluctuations ) may also be derived:       ‚ü®    (   Œî  N   )   2   ‚ü©   =    k  B   T    (    d   ‚ü®  N  ‚ü©     d  Œº    )    V  ,  T     =    ‚ü®   N  2   ‚ü©   -    ‚ü®  N  ‚ü©   2           delimited-‚ü®‚ü©   superscript    normal-Œî  N   2       subscript  k  B   T   subscript      d   delimited-‚ü®‚ü©  N      d  Œº     V  T             delimited-‚ü®‚ü©   superscript  N  2     superscript   delimited-‚ü®‚ü©  N   2       \langle(\Delta N)^{2}\rangle=k_{B}T\left(\frac{d\langle N\rangle}{d\mu}\right)%
 _{V,T}=\langle N^{2}\rangle-\langle N\rangle^{2}   This level of fluctuation is much larger than for distinguishable particles , which would instead show Poisson statistics (     ‚ü®    (   Œî  N   )   2   ‚ü©   =   ‚ü®  N  ‚ü©        delimited-‚ü®‚ü©   superscript    normal-Œî  N   2     delimited-‚ü®‚ü©  N     \langle(\Delta N)^{2}\rangle=\langle N\rangle   ). This is because the probability distribution for the number of bosons in a given energy level is a geometric distribution , not a Poisson distribution .  Derivation in the canonical approach  It is also possible to derive approximate Bose‚ÄìEinstein statistics in the canonical ensemble . These derivations are lengthy and only yield the above results in the asymptotic limit of a large number of particles. The reason is that the total number of bosons is fixed in the canonical ensemble. That contradicts the implication in Bose‚ÄìEinstein statistics that each energy level is filled independently from the others (which would require the number of particles to be flexible).  Suppose we have a number of energy levels, labeled by index   i   i   \displaystyle i   , each level having energy    Œµ  i     subscript  Œµ  i    \displaystyle\varepsilon_{i}   and containing a total of    n  i     subscript  n  i    \displaystyle n_{i}   particles. Suppose each level contains    g  i     subscript  g  i    \displaystyle g_{i}   distinct sublevels, all of which have the same energy, and which are distinguishable. For example, two particles may have different momenta, in which case they are distinguishable from each other, yet they can still have the same energy. The value of    g  i     subscript  g  i    \displaystyle g_{i}   associated with level   i   i   \displaystyle i   is called the "degeneracy" of that energy level. Any number of bosons can occupy the same sublevel.  Let     w   (  n  ,  g  )       w   n  g     \displaystyle w(n,g)    be the number of ways of distributing   n   n   \displaystyle n   particles among the   g   g   \displaystyle g   sublevels of an energy level. There is only one way of distributing   n   n   \displaystyle n   particles with one sublevel, therefore     w   (  n  ,  1  )    =  1        w   n  1    1    \displaystyle w(n,1)=1   . It is easy to see that there are    (   n  +  1   )      n  1    \displaystyle(n+1)   ways of distributing   n   n   \displaystyle n   particles in two sublevels which we will write as:        w   (  n  ,  2  )    =     (   n  +  1   )   !     n  !    1  !      .        w   n  2          n  1        n     1       w(n,2)=\frac{(n+1)!}{n!1!}.     With a little thought (see Notes below) it can be seen that the number of ways of distributing   n   n   \displaystyle n   particles in three sublevels is       w   (  n  ,  3  )    =    w   (  n  ,  2  )    +   w   (   n  -  1   ,  2  )    +  ‚ãØ  +   w   (  1  ,  2  )    +   w   (  0  ,  2  )           w   n  3        w   n  2      w     n  1   2    normal-‚ãØ    w   1  2      w   0  2       w(n,3)=w(n,2)+w(n-1,2)+\cdots+w(1,2)+w(0,2)   so that       w   (  n  ,  3  )    =    ‚àë   k  =  0   n    w   (   n  -  k   ,  2  )     =    ‚àë   k  =  0   n      (    n  -  k   +  1   )   !      (   n  -  k   )   !    1  !      =     (   n  +  2   )   !     n  !    2  !             w   n  3      superscript   subscript     k  0    n     w     n  k   2            superscript   subscript     k  0    n           n  k   1          n  k      1                 n  2        n     2        w(n,3)=\sum_{k=0}^{n}w(n-k,2)=\sum_{k=0}^{n}\frac{(n-k+1)!}{(n-k)!1!}=\frac{(n%
 +2)!}{n!2!}     where we have used the following theorem involving binomial coefficients :         ‚àë   k  =  0   n      (   k  +  a   )   !     k  !    a  !      =     (   n  +  a  +  1   )   !     n  !     (   a  +  1   )   !      .        superscript   subscript     k  0    n         k  a        k     a            n  a  1        n       a  1        \sum_{k=0}^{n}\frac{(k+a)!}{k!a!}=\frac{(n+a+1)!}{n!(a+1)!}.     Continuing this process, we can see that     w   (  n  ,  g  )       w   n  g     \displaystyle w(n,g)    is just a binomial coefficient (See Notes below)        w   (  n  ,  g  )    =     (    n  +  g   -  1   )   !     n  !     (   g  -  1   )   !      .        w   n  g            n  g   1        n       g  1        w(n,g)=\frac{(n+g-1)!}{n!(g-1)!}.     For example, the population numbers for two particles in three sublevels are 200, 110, 101, 020, 011, or 002 for a total of six which equals 4!/(2!2!). The number of ways that a set of occupation numbers    n  i     subscript  n  i    \displaystyle n_{i}   can be realized is the product of the ways that each individual energy level can be populated:      W  =    ‚àè  i    w   (   n  i   ,   g  i   )     =    ‚àè  i      (     n  i   +   g  i    -  1   )   !      n  i   !     (    g  i   -  1   )   !      ‚âà    ‚àè  i      (    n  i   +   g  i    )   !      n  i   !     (    g  i   -  1   )   !            W    subscript  product  i     w    subscript  n  i    subscript  g  i             subscript  product  i            subscript  n  i    subscript  g  i    1         subscript  n  i         subscript  g  i   1              subscript  product  i          subscript  n  i    subscript  g  i          subscript  n  i         subscript  g  i   1          W=\prod_{i}w(n_{i},g_{i})=\prod_{i}\frac{(n_{i}+g_{i}-1)!}{n_{i}!(g_{i}-1)!}%
 \approx\prod_{i}\frac{(n_{i}+g_{i})!}{n_{i}!(g_{i}-1)!}     where the approximation assumes that     n  i   ‚â´  1     much-greater-than   subscript  n  i   1    n_{i}\gg 1   .  Following the same procedure used in deriving the Maxwell‚ÄìBoltzmann statistics , we wish to find the set of    n  i     subscript  n  i    \displaystyle n_{i}   for which W is maximised, subject to the constraint that there be a fixed total number of particles, and a fixed total energy. The maxima of   W   W   \displaystyle W   and    ln   (  W  )       W    \displaystyle\ln(W)   occur at the same value of    n  i     subscript  n  i    \displaystyle n_{i}   and, since it is easier to accomplish mathematically, we will maximise the latter function instead. We constrain our solution using Lagrange multipliers forming the function:       f   (   n  i   )    =    ln   (  W  )    +   Œ±   (   N  -   ‚àë   n  i     )    +   Œ≤   (   E  -   ‚àë    n  i    Œµ  i      )           f   subscript  n  i        W     Œ±    N     subscript  n  i        Œ≤    E       subscript  n  i    subscript  Œµ  i          f(n_{i})=\ln(W)+\alpha(N-\sum n_{i})+\beta(E-\sum n_{i}\varepsilon_{i})     Using the     n  i   ‚â´  1     much-greater-than   subscript  n  i   1    n_{i}\gg 1   approximation and using Stirling's approximation for the factorials    (    x  !   ‚âà     x  x      e   -  x       2  œÄ  x      )        x      superscript  x  x    superscript  e    x        2  œÄ  x       \left(x!\approx x^{x}\,e^{-x}\,\sqrt{2\pi x}\right)   gives        f   (   n  i   )    =      ‚àë  i     (    n  i   +   g  i    )    ln   (    n  i   +   g  i    )      -    n  i    ln   (   n  i   )      +   Œ±   (   N  -   ‚àë   n  i     )    +   Œ≤   (   E  -   ‚àë    n  i    Œµ  i      )    +  K    .        f   subscript  n  i          subscript   i        subscript  n  i    subscript  g  i         subscript  n  i    subscript  g  i          subscript  n  i      subscript  n  i        Œ±    N     subscript  n  i        Œ≤    E       subscript  n  i    subscript  Œµ  i       K     f(n_{i})=\sum_{i}(n_{i}+g_{i})\ln(n_{i}+g_{i})-n_{i}\ln(n_{i})+\alpha\left(N-%
 \sum n_{i}\right)+\beta\left(E-\sum n_{i}\varepsilon_{i}\right)+K.     Where K is the sum of a number of terms which are not functions of the    n  i     subscript  n  i    n_{i}   . Taking the derivative with respect to    n  i     subscript  n  i    \displaystyle n_{i}   , and setting the result to zero and solving for    n  i     subscript  n  i    \displaystyle n_{i}   , yields the Bose‚ÄìEinstein population numbers:        n  i   =    g  i     e   Œ±  +   Œ≤   Œµ  i      -  1     .       subscript  n  i      subscript  g  i      superscript  e    Œ±    Œ≤   subscript  Œµ  i      1      n_{i}=\frac{g_{i}}{e^{\alpha+\beta\varepsilon_{i}}-1}.     By a process similar to that outlined in the Maxwell‚ÄìBoltzmann statistics article, it can be seen that:       d   ln  W    =     Œ±   d  N   +    Œ≤   d  E          d    W        Œ±  d  N     Œ≤  d  E      d\ln W=\alpha\,dN+\beta\,dE     which, using Boltzmann's famous relationship    S  =    k    ln  W        S    k    W      S=k\,\ln W   becomes a statement of the second law of thermodynamics at constant volume, and it follows that    Œ≤  =   1   k  T        Œ≤    1    k  T      \beta=\frac{1}{kT}   and    Œ±  =   -   Œº   k  T         Œ±      Œº    k  T       \alpha=-\frac{\mu}{kT}   where S is the entropy ,   Œº   Œº   \mu   is the chemical potential , k is Boltzmann's constant and T is the temperature , so that finally:        n  i   =    g  i     e     (    Œµ  i   -  Œº   )   /  k   T    -  1     .       subscript  n  i      subscript  g  i      superscript  e         subscript  Œµ  i   Œº   k   T    1      n_{i}=\frac{g_{i}}{e^{(\varepsilon_{i}-\mu)/kT}-1}.     Note that the above formula is sometimes written:        n  i   =    g  i      e     Œµ  i   /  k   T    /  z   -  1     ,       subscript  n  i      subscript  g  i        superscript  e       subscript  Œµ  i   k   T    z   1      n_{i}=\frac{g_{i}}{e^{\varepsilon_{i}/kT}/z-1},     where    z  =   exp   (    Œº  /  k   T   )        z        Œº  k   T      \displaystyle z=\exp(\mu/kT)   is the absolute activity , as noted by McQuarrie. 6  Also note that when the particle numbers are not conserved, removing the conservation of particle numbers constraint is equivalent to setting   Œ±   Œ±   \alpha   and therefore the chemical potential   Œº   Œº   \mu   to zero. This will be the case for photons and massive particles in mutual equilibrium and the resulting distribution will be the Planck distribution .  A much simpler way to think of Bose‚ÄìEinstein distribution function is to consider that n particles are denoted by identical balls and g shells are marked by g-1 line partitions. It is clear that the permutations of these n balls and g-1 partitions will give different ways of arranging bosons in different energy levels. Say, for 3(=n) particles and 3(=g) shells, therefore (g-1)=2, the arrangement might be |‚óè‚óè|‚óè , or ||‚óè‚óè‚óè , or '''|‚óè|‚óè‚óè ''', etc. Hence the number of distinct permutations of n + (g-1) objects which have n identical items and (g-1) identical items will be:        (    g  -  1   +  n   )   !      (   g  -  1   )   !    n  !              g  1   n          g  1      n      \frac{(g-1+n)!}{(g-1)!n!}     OR  The purpose of these notes is to clarify some aspects of the derivation of the Bose‚ÄìEinstein (B‚ÄìE) distribution for beginners. The enumeration of cases (or ways) in the B‚ÄìE distribution can be recast as follows. Consider a game of dice throwing in which there are   n   n   \displaystyle n   dice, with each die taking values in the set    {  1  ,  ‚Ä¶  ,  g  }     1  normal-‚Ä¶  g    \displaystyle\left\{1,\dots,g\right\}   , for    g  ‚â•  1      g  1    g\geq 1   . The constraints of the game are that the value of a die   i   i   \displaystyle i   , denoted by    m  i     subscript  m  i    \displaystyle m_{i}   , has to be greater than or equal to the value of die    (   i  -  1   )      i  1    \displaystyle(i-1)   , denoted by    m   i  -  1      subscript  m    i  1     \displaystyle m_{i-1}   , in the previous throw, i.e.,     m  i   ‚â•   m   i  -  1         subscript  m  i    subscript  m    i  1      m_{i}\geq m_{i-1}   . Thus a valid sequence of die throws can be described by an n -tuple    (   m  1   ,   m  2   ,  ‚Ä¶  ,   m  n   )      subscript  m  1    subscript  m  2   normal-‚Ä¶   subscript  m  n     \displaystyle\left(m_{1},m_{2},\dots,m_{n}\right)   , such that     m  i   ‚â•   m   i  -  1         subscript  m  i    subscript  m    i  1      m_{i}\geq m_{i-1}   . Let    S   (  n  ,  g  )       S   n  g     \displaystyle S(n,g)   denote the set of these valid n -tuples:            S   (  n  ,  g  )   =   {   (   m  1   ,   m  2   ,  ‚Ä¶  ,   m  n   )   |  .   m  i   ‚â•   m   i  -  1    ,   m  i   ‚àà   {  1  ,  ‚Ä¶  ,  g  }   ,  ‚àÄ  i  =  1  ,  ‚Ä¶  ,  n  }   .     fragments  S   fragments  normal-(  n  normal-,  g  normal-)     fragments  normal-{   fragments  normal-(   subscript  m  1   normal-,   subscript  m  2   normal-,  normal-‚Ä¶  normal-,   subscript  m  n   normal-)   normal-|  normal-.   subscript  m  i     subscript  m    i  1    normal-,   subscript  m  i     fragments  normal-{  1  normal-,  normal-‚Ä¶  normal-,  g  normal-}   normal-,  for-all  i   1  normal-,  normal-‚Ä¶  normal-,  n  normal-}   normal-.    S(n,g)=\Big\{\left(m_{1},m_{2},\dots,m_{n}\right)\Big|\Big.m_{i}\geq m_{i-1},m%
 _{i}\in\left\{1,\dots,g\right\},\forall i=1,\dots,n\Big\}.      (1)       Then the quantity    w   (  n  ,  g  )       w   n  g     \displaystyle w(n,g)   ( defined above as the number of ways to distribute   n   n   \displaystyle n   particles among the   g   g   \displaystyle g   sublevels of an energy level) is the cardinality of    S   (  n  ,  g  )       S   n  g     \displaystyle S(n,g)   , i.e., the number of elements (or valid n -tuples) in    S   (  n  ,  g  )       S   n  g     \displaystyle S(n,g)   . Thus the problem of finding an expression for    w   (  n  ,  g  )       w   n  g     \displaystyle w(n,g)   becomes the problem of counting the elements in    S   (  n  ,  g  )       S   n  g     \displaystyle S(n,g)   .  Example n = 4, g = 3:      S   (  4  ,  3  )   =   {      (  1111  )   ,   (  1112  )   ,   (  1113  )    ‚èü    (  a  )    ,      (  1122  )   ,   (  1123  )   ,   (  1133  )    ‚èü    (  b  )    ,      (  1222  )   ,   (  1223  )   ,   (  1233  )   ,   (  1333  )    ‚èü    (  c  )    ,      fragments  S   fragments  normal-(  4  normal-,  3  normal-)     fragments  normal-{   subscript   normal-‚èü   1111  1112  1113    a   normal-,   subscript   normal-‚èü   1122  1123  1133    b   normal-,   subscript   normal-‚èü   1222  1223  1233  1333    c   normal-,     S(4,3)=\left\{\underbrace{(1111),(1112),(1113)}_{(a)},\underbrace{(1122),(1123%
 ),(1133)}_{(b)},\underbrace{(1222),(1223),(1233),(1333)}_{(c)},\right.            \left.  \underbrace{(2222),¬†(2223),¬†(2233),¬†(2333),¬†(3333)}_{(d)}  \right\}        w   (  4  ,  3  )    =  15        w   4  3    15    \displaystyle w(4,3)=15   (there are   15   15   \displaystyle 15   elements in    S   (  4  ,  3  )       S   4  3     \displaystyle S(4,3)   )  Subset    (  a  )    a   \displaystyle(a)   is obtained by fixing all indices    m  i     subscript  m  i    \displaystyle m_{i}   to   1   1   \displaystyle 1   , except for the last index,    m  n     subscript  m  n    \displaystyle m_{n}   , which is incremented from   1   1   \displaystyle 1   to    g  =  3      g  3    \displaystyle g=3   . Subset    (  b  )    b   \displaystyle(b)   is obtained by fixing     m  1   =   m  2   =  1         subscript  m  1    subscript  m  2        1     \displaystyle m_{1}=m_{2}=1   , and incrementing    m  3     subscript  m  3    \displaystyle m_{3}   from   2   2   \displaystyle 2   to    g  =  3      g  3    \displaystyle g=3   . Due to the constraint     m  i   ‚â•   m   i  -  1         subscript  m  i    subscript  m    i  1      \displaystyle m_{i}\geq m_{i-1}   on the indices in    S   (  n  ,  g  )       S   n  g     \displaystyle S(n,g)   , the index    m  4     subscript  m  4    \displaystyle m_{4}   must automatically take values in    {  2  ,  3  }     2  3    \displaystyle\left\{2,3\right\}   . The construction of subsets    (  c  )    c   \displaystyle(c)   and    (  d  )    d   \displaystyle(d)   follows in the same manner.  Each element of    S   (  4  ,  3  )       S   4  3     \displaystyle S(4,3)   can be thought of as a multiset of cardinality    n  =  4      n  4    \displaystyle n=4   ; the elements of such multiset are taken from the set    {  1  ,  2  ,  3  }     1  2  3    \displaystyle\left\{1,2,3\right\}   of cardinality    g  =  3      g  3    \displaystyle g=3   , and the number of such multisets is the multiset coefficient       ‚ü®     3      4     ‚ü©   =   (       3  +  4   -  1        3  -  1      )   =   (       3  +  4   -  1       4     )   =    6  !     4  !    2  !     =  15         delimited-‚ü®‚ü©    3    4      binomial      3  4   1     3  1          binomial      3  4   1   4            6       4     2          15     \displaystyle\left\langle\begin{matrix}3\\
 4\end{matrix}\right\rangle={3+4-1\choose 3-1}={3+4-1\choose 4}=\frac{6!}{4!2!}%
 =15     More generally, each element of    S   (  n  ,  g  )       S   n  g     \displaystyle S(n,g)   is a multiset of cardinality   n   n   \displaystyle n   (number of dice) with elements taken from the set    {  1  ,  ‚Ä¶  ,  g  }     1  normal-‚Ä¶  g    \displaystyle\left\{1,\dots,g\right\}   of cardinality   g   g   \displaystyle g   (number of possible values of each die), and the number of such multisets, i.e.,    w   (  n  ,  g  )       w   n  g     \displaystyle w(n,g)   is the multiset coefficient             w   (  n  ,  g  )    =   ‚ü®     g      n     ‚ü©   =   (        g  +  n   -  1        g  -  1       )   =   (        g  +  n   -  1       n      )   =      (    g  +  n   -  1   )   !     n  !     (   g  -  1   )   !              w   n  g     delimited-‚ü®‚ü©    g    n           binomial      g  n   1     g  1          binomial      g  n   1   n                g  n   1        n       g  1         \displaystyle w(n,g)=\left\langle\begin{matrix}g\\
 n\end{matrix}\right\rangle={g+n-1\choose g-1}={g+n-1\choose n}=\frac{(g+n-1)!}%
 {n!(g-1)!}      (2)       which is exactly the same as the formula for    w   (  n  ,  g  )       w   n  g     \displaystyle w(n,g)   , as derived above with the aid of a theorem involving binomial coefficients, namely               ‚àë   k  =  0   n      (   k  +  a   )   !     k  !    a  !      =     (   n  +  a  +  1   )   !     n  !     (   a  +  1   )   !      .        superscript   subscript     k  0    n         k  a        k     a            n  a  1        n       a  1        \sum_{k=0}^{n}\frac{(k+a)!}{k!a!}=\frac{(n+a+1)!}{n!(a+1)!}.      (3)       To understand the decomposition             w   (  n  ,  g  )    =     ‚àë   k  =  0   n     w   (   n  -  k   ,   g  -  1   )     =    w   (  n  ,   g  -  1   )    +   w   (   n  -  1   ,   g  -  1   )    +  ‚ãØ  +   w   (  1  ,   g  -  1   )    +   w   (  0  ,   g  -  1   )             w   n  g      superscript   subscript     k  0    n     w     n  k     g  1               w   n    g  1       w     n  1     g  1     normal-‚ãØ    w   1    g  1       w   0    g  1         \displaystyle w(n,g)=\sum_{k=0}^{n}w(n-k,g-1)=w(n,g-1)+w(n-1,g-1)+\cdots+w(1,g%
 -1)+w(0,g-1)      (4)       or for example,    n  =  4      n  4    \displaystyle n=4   and    g  =  3      g  3    \displaystyle g=3           w   (  4  ,  3  )    =    w   (  4  ,  2  )    +   w   (  3  ,  2  )    +   w   (  2  ,  2  )    +   w   (  1  ,  2  )    +   w   (  0  ,  2  )      ,        w   4  3        w   4  2      w   3  2      w   2  2      w   1  2      w   0  2       \displaystyle w(4,3)=w(4,2)+w(3,2)+w(2,2)+w(1,2)+w(0,2),     let us rearrange the elements of    S   (  4  ,  3  )       S   4  3     \displaystyle S(4,3)   as follows      S   (  4  ,  3  )   =   {      (  1111  )   ,   (  1112  )   ,   (  1122  )   ,   (  1222  )   ,   (  2222  )    ‚èü    (  Œ±  )    ,      (   111   \color   R  e  d   3  =    )   ,   (   112   \color   R  e  d   3  =    )   ,   (   122   \color   R  e  d   3  =    )   ,   (   222   \color   R  e  d   3  =    )    ‚èü    (  Œ≤  )    ,      fragments  S   fragments  normal-(  4  normal-,  3  normal-)     fragments  normal-{   subscript   normal-‚èü   1111  1112  1122  1222  2222    Œ±   normal-,   subscript   normal-‚èü     111  \color  R  e  d    3      112  \color  R  e  d    3      122  \color  R  e  d    3      222  \color  R  e  d    3      Œ≤   normal-,     S(4,3)=\left\{\underbrace{(1111),(1112),(1122),(1222),(2222)}_{(\alpha)},%
 \underbrace{(111{\color{Red}{\underset{=}{3}}}),(112{\color{Red}{\underset{=}{%
 3}}}),(122{\color{Red}{\underset{=}{3}}}),(222{\color{Red}{\underset{=}{3}}})}%
 _{(\beta)},\right.            \left.  \underbrace{  (11{\color{Red}{\underset{==}{33}}}),  (12{\color{Red}{\underset{==}{33}}}),  (22{\color{Red}{\underset{==}{33}}})  }_{(\gamma)},  \underbrace{  (1{\color{Red}{\underset{===}{333}}}),  (2{\color{Red}{\underset{===}{333}}})  }_{(\delta)}  \underbrace{  ({\color{Red}{\underset{====}{3333}}})  }_{(\omega)}  \right\}.   Clearly, the subset    (  Œ±  )    Œ±   \displaystyle(\alpha)   of    S   (  4  ,  3  )       S   4  3     \displaystyle S(4,3)   is the same as the set       S   (  4  ,  2  )    =   {   (  1111  )   ,   (  1112  )   ,   (  1122  )   ,   (  1222  )   ,   (  2222  )   }         S   4  2     1111  1112  1122  1222  2222     \displaystyle S(4,2)=\left\{(1111),(1112),(1122),(1222),(2222)\right\}   .  By deleting the index     m  4   =  3       subscript  m  4   3    \displaystyle m_{4}=3   (shown in red with double underline ) in the subset    (  Œ≤  )    Œ≤   \displaystyle(\beta)   of    S   (  4  ,  3  )       S   4  3     \displaystyle S(4,3)   , one obtains the set       S   (  3  ,  2  )    =   {   (  111  )   ,   (  112  )   ,   (  122  )   ,   (  222  )   }         S   3  2     111  112  122  222     \displaystyle S(3,2)=\left\{(111),(112),(122),(222)\right\}   . In other words, there is a one-to-one correspondence between the subset    (  Œ≤  )    Œ≤   \displaystyle(\beta)   of    S   (  4  ,  3  )       S   4  3     \displaystyle S(4,3)   and the set    S   (  3  ,  2  )       S   3  2     \displaystyle S(3,2)   . We write       (  Œ≤  )   ‚ü∑   S   (  3  ,  2  )       normal-‚ü∑  Œ≤    S   3  2      \displaystyle(\beta)\longleftrightarrow S(3,2)   .  Similarly, it is easy to see that       (  Œ≥  )   ‚ü∑    S   (  2  ,  2  )    =   {   (  11  )   ,   (  12  )   ,   (  22  )   }       normal-‚ü∑  Œ≥      S   2  2     11  12  22      \displaystyle(\gamma)\longleftrightarrow S(2,2)=\left\{(11),(12),(22)\right\}          (  Œ¥  )   ‚ü∑    S   (  1  ,  2  )    =   {   (  1  )   ,   (  2  )   }       normal-‚ü∑  Œ¥      S   1  2     1  2      \displaystyle(\delta)\longleftrightarrow S(1,2)=\left\{(1),(2)\right\}          (  œâ  )   ‚ü∑    S   (  0  ,  2  )    =  ‚àÖ      normal-‚ü∑  œâ      S   0  2        \displaystyle(\omega)\longleftrightarrow S(0,2)=\varnothing   (empty set).  Thus we can write       S   (  4  ,  3  )    =    ‚ãÉ   k  =  0   4    S   (   4  -  k   ,  2  )           S   4  3      superscript   subscript     k  0    4     S     4  k   2       \displaystyle S(4,3)=\bigcup_{k=0}^{4}S(4-k,2)     or more generally,             S   (  n  ,  g  )    =     ‚ãÉ   k  =  0   n     S   (   n  -  k   ,   g  -  1   )           S   n  g      superscript   subscript     k  0    n     S     n  k     g  1        \displaystyle S(n,g)=\bigcup_{k=0}^{n}S(n-k,g-1)   ;   (5)       and since the sets         S   (  i  ,   g  -  1   )    ,    for   i    =  0   ,   ‚Ä¶  ,  n      formulae-sequence       S   i    g  1       for  i    0    normal-‚Ä¶  n     \displaystyle S(i,g-1)\ ,\ {\rm for}\ i=0,\dots,n   are non-intersecting, we thus have             w   (  n  ,  g  )    =     ‚àë   k  =  0   n     w   (   n  -  k   ,   g  -  1   )           w   n  g      superscript   subscript     k  0    n     w     n  k     g  1        \displaystyle w(n,g)=\sum_{k=0}^{n}w(n-k,g-1)   ,   (6)       with the convention that              w   (  0  ,  g  )    =    1   ,   ‚àÄ   g      ,     and   w   (  n  ,  0  )    =    1   ,   ‚àÄ  n        formulae-sequence      w   0  g     1   for-all  g         and  w   n  0     1   for-all  n       \displaystyle w(0,g)=1\ ,\forall g\ ,{\rm and}\ w(n,0)=1\ ,\forall n   .   (7)       Continuing the process, we arrive at the following formula        w   (  n  ,  g  )    =    ‚àë    k  1   =  0   n     ‚àë    k  2   =  0    n  -   k  1      w   (   n  -   k  1   -   k  2    ,   g  -  2   )      =    ‚àë    k  1   =  0   n     ‚àë    k  2   =  0    n  -   k  1      ‚ãØ    ‚àë    k  g   =  0    n  -     ‚àë   j  =  1    g  -  1      k  j       w   (   n  -    ‚àë   i  =  1   g    k  i     ,  0  )         .          w   n  g      superscript   subscript      subscript  k  1   0    n     superscript   subscript      subscript  k  2   0      n   subscript  k  1       w     n   subscript  k  1    subscript  k  2      g  2              superscript   subscript      subscript  k  1   0    n     superscript   subscript      subscript  k  2   0      n   subscript  k  1       normal-‚ãØ    superscript   subscript      subscript  k  g   0      n    superscript   subscript     j  1      g  1     subscript  k  j        w     n    superscript   subscript     i  1    g    subscript  k  i     0           \displaystyle w(n,g)=\sum_{k_{1}=0}^{n}\sum_{k_{2}=0}^{n-k_{1}}w(n-k_{1}-k_{2}%
 ,g-2)=\sum_{k_{1}=0}^{n}\sum_{k_{2}=0}^{n-k_{1}}\cdots\sum_{k_{g}=0}^{n-\sum_{%
 j=1}^{g-1}k_{j}}w(n-\sum_{i=1}^{g}k_{i},0).   Using the convention (7) 2 above, we obtain the formula              w   (  n  ,  g  )    =     ‚àë    k  1   =  0   n       ‚àë    k  2   =  0    n  -   k  1       ‚ãØ     ‚àë    k  g   =  0    n  -     ‚àë   j  =  1    g  -  1      k  j       1       ,        w   n  g      superscript   subscript      subscript  k  1   0    n     superscript   subscript      subscript  k  2   0      n   subscript  k  1       normal-‚ãØ    superscript   subscript      subscript  k  g   0      n    superscript   subscript     j  1      g  1     subscript  k  j      1        \displaystyle w(n,g)=\sum_{k_{1}=0}^{n}\sum_{k_{2}=0}^{n-k_{1}}\cdots\sum_{k_{%
 g}=0}^{n-\sum_{j=1}^{g-1}k_{j}}1,      (8)       keeping in mind that for   q   q   \displaystyle q   and   p   p   \displaystyle p   being constants, we have               ‚àë   k  =  0   q    p   =   q  p         superscript   subscript     k  0    q   p     q  p     \displaystyle\sum_{k=0}^{q}p=qp   .   style= | (9)       It can then be verified that (8) and (2) give the same result for    w   (  4  ,  3  )       w   4  3     \displaystyle w(4,3)   ,    w   (  3  ,  3  )       w   3  3     \displaystyle w(3,3)   ,    w   (  3  ,  2  )       w   3  2     \displaystyle w(3,2)   , etc.  Interdisciplinary applications  Viewed as a pure probability distribution , the Bose‚ÄìEinstein distribution has found application in other fields:   In recent years, Bose Einstein statistics have also been used as a method for term weighting in information retrieval . The method is one of a collection of DFR ("Divergence From Randomness") models, 7 the basic notion being that Bose Einstein statistics may be a useful indicator in cases where a particular term and a particular document have a significant relationship that would not have occurred purely by chance. Source code for implementing this model is available from the Terrier project at the University of Glasgow.     The evolution of many complex systems, including the World Wide Web , business, and citation networks, is encoded in the dynamic web describing the interactions between the system's constituents. Despite their irreversible and nonequilibrium nature these networks follow Bose statistics and can undergo Bose‚ÄìEinstein condensation. Addressing the dynamical properties of these nonequilibrium systems within the framework of equilibrium quantum gases predicts that the "first-mover-advantage," "fit-get-rich( FGR )," and "winner-takes-all" phenomena observed in competitive systems are thermodynamically distinct phases of the underlying evolving networks. 8   See also   Bose‚ÄìEinstein correlations  Higgs boson  Parastatistics  Planck's law of black body radiation  Superconductivity  Fermi-Dirac Statistics  Maxwell-Boltzmann Statistics   Notes  References    Bose (1924). "Plancks Gesetz und Lichtquantenhypothese", Zeitschrift f√ºr Physik 26:178‚Äì181. doi:10.1007/BF01327326  (Einstein's translation into German of Bose's paper on Planck's law) .      "    Category:Concepts in physics  Category:Quantum field theory  Category:Albert Einstein  Category:Continuous distributions  Category:Statistical mechanics     See p. 14, note 3, of the Ph.D. Thesis entitled Bose‚ÄìEinstein condensation: analysis of problems and rigorous results , presented by Alessandro Michelangeli to the International School for Advanced Studies, Mathematical Physics Sector, October 2007 for the degree of Ph.D. See: http://digitallibrary.sissa.it/handle/1963/5272?show=full , and download from http://digitallibrary.sissa.it/handle/1963/5272 ‚Ü©  To download the Bose paper, see: http://www.condmat.uni-oldenburg.de/TeachingSP/bose.ps ‚Ü©  Chapter 7 of ‚Ü©  Chapter 6 of ‚Ü©  The BE distribution can be derived also from thermal field theory. ‚Ü©  See McQuarrie in citations ‚Ü©  Amati, G.; C. J. Van Rijsbergen (2002). " Probabilistic models of information retrieval based on measuring the divergence from randomness " ACM TOIS  20 (4) :357‚Äì389. ‚Ü©  Bianconi, G.; Barab√°si, A.-L. (2001). " Bose‚ÄìEinstein Condensation in Complex Networks. " Phys. Rev. Lett.  86 : 5632‚Äì35. ‚Ü©     