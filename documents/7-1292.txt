   Biconjugate gradient method      Biconjugate gradient method   In mathematics , more specifically in numerical linear algebra , the biconjugate gradient method is an algorithm to solve systems of linear equations        A  x   =  b   .        A  x   b    Ax=b.\,     Unlike the conjugate gradient method , this algorithm does not require the matrix    A   A   A   to be self-adjoint , but instead one needs to perform multiplications by the conjugate transpose  .  The algorithm   Choose initial guess     x  0      subscript  x  0    x_{0}\,   , two other vectors    x  0  *     superscript   subscript  x  0      x_{0}^{*}   and     b  *      superscript  b     b^{*}\,   and a preconditioner     M    M   M\,          r  0   ‚Üê   b  -    A     x  0         normal-‚Üê   subscript  r  0     b    A   subscript  x  0       r_{0}\leftarrow b-A\,x_{0}\,          r  0  *   ‚Üê    b  *   -     x  0  *     A  T        normal-‚Üê   superscript   subscript  r  0        superscript  b       superscript   subscript  x  0      superscript  A  T       r_{0}^{*}\leftarrow b^{*}-x_{0}^{*}\,A^{T}          p  0   ‚Üê    M   -  1      r  0        normal-‚Üê   subscript  p  0      superscript  M    1     subscript  r  0      p_{0}\leftarrow M^{-1}r_{0}\,          p  0  *   ‚Üê    r  0  *     M   -  1         normal-‚Üê   superscript   subscript  p  0        superscript   subscript  r  0      superscript  M    1       p_{0}^{*}\leftarrow r_{0}^{*}M^{-1}\,     for    k  =   0  ,  1  ,  ‚Ä¶       k   0  1  normal-‚Ä¶     k=0,1,\ldots   do       Œ±  k   ‚Üê      r  k  *    M   -  1     r  k      p  k  *   A   p  k         normal-‚Üê   subscript  Œ±  k        superscript   subscript  r  k      superscript  M    1     subscript  r  k       superscript   subscript  p  k     A   subscript  p  k       \alpha_{k}\leftarrow{r_{k}^{*}M^{-1}r_{k}\over p_{k}^{*}Ap_{k}}\,          x   k  +  1    ‚Üê    x  k   +    Œ±  k   ‚ãÖ    p  k         normal-‚Üê   subscript  x    k  1       subscript  x  k    normal-‚ãÖ   subscript  Œ±  k    subscript  p  k       x_{k+1}\leftarrow x_{k}+\alpha_{k}\cdot p_{k}\,          x   k  +  1   *   ‚Üê    x  k  *   +     Œ±  k   ¬Ø   ‚ãÖ    p  k  *         normal-‚Üê   superscript   subscript  x    k  1         superscript   subscript  x  k      normal-‚ãÖ   normal-¬Ø   subscript  Œ±  k     superscript   subscript  p  k         x_{k+1}^{*}\leftarrow x_{k}^{*}+\overline{\alpha_{k}}\cdot p_{k}^{*}\,          r   k  +  1    ‚Üê    r  k   -     Œ±  k   ‚ãÖ  A     p  k         normal-‚Üê   subscript  r    k  1       subscript  r  k      normal-‚ãÖ   subscript  Œ±  k   A    subscript  p  k       r_{k+1}\leftarrow r_{k}-\alpha_{k}\cdot Ap_{k}\,          r   k  +  1   *   ‚Üê    r  k  *   -      Œ±  k   ¬Ø   ‚ãÖ    p  k  *     A       normal-‚Üê   superscript   subscript  r    k  1         superscript   subscript  r  k        normal-‚ãÖ   normal-¬Ø   subscript  Œ±  k     superscript   subscript  p  k      A      r_{k+1}^{*}\leftarrow r_{k}^{*}-\overline{\alpha_{k}}\cdot p_{k}^{*}\,A          Œ≤  k   ‚Üê      r   k  +  1   *    M   -  1     r   k  +  1       r  k  *    M   -  1     r  k         normal-‚Üê   subscript  Œ≤  k        superscript   subscript  r    k  1       superscript  M    1     subscript  r    k  1        superscript   subscript  r  k      superscript  M    1     subscript  r  k       \beta_{k}\leftarrow{r_{k+1}^{*}M^{-1}r_{k+1}\over r_{k}^{*}M^{-1}r_{k}}\,          p   k  +  1    ‚Üê     M   -  1     r   k  +  1     +    Œ≤  k   ‚ãÖ    p  k         normal-‚Üê   subscript  p    k  1         superscript  M    1     subscript  r    k  1      normal-‚ãÖ   subscript  Œ≤  k    subscript  p  k       p_{k+1}\leftarrow M^{-1}r_{k+1}+\beta_{k}\cdot p_{k}\,          p   k  +  1   *   ‚Üê     r   k  +  1   *    M   -  1     +     Œ≤  k   ¬Ø   ‚ãÖ    p  k  *         normal-‚Üê   superscript   subscript  p    k  1           superscript   subscript  r    k  1       superscript  M    1      normal-‚ãÖ   normal-¬Ø   subscript  Œ≤  k     superscript   subscript  p  k         p_{k+1}^{*}\leftarrow r_{k+1}^{*}M^{-1}+\overline{\beta_{k}}\cdot p_{k}^{*}\,       In the above formulation, the computed     r  k      subscript  r  k    r_{k}\,   and    r  k  *     superscript   subscript  r  k      r_{k}^{*}   satisfy        r  k   =   b  -   A   x  k      ,       subscript  r  k     b    A   subscript  x  k       r_{k}=b-Ax_{k},\,          r  k  *   =    b  *   -     x  k  *    A         superscript   subscript  r  k        superscript  b       superscript   subscript  x  k     A      r_{k}^{*}=b^{*}-x_{k}^{*}\,A     and thus are the respective residuals corresponding to     x  k      subscript  x  k    x_{k}\,   and    x  k  *     superscript   subscript  x  k      x_{k}^{*}   , as approximate solutions to the systems        A  x   =  b   ,        A  x   b    Ax=b,\,             x  *    A   =    b  *     ;         superscript  x    A    superscript  b      x^{*}\,A=b^{*}\,;       x  *     superscript  x     x^{*}   is the adjoint , and    Œ±  ¬Ø     normal-¬Ø  Œ±    \overline{\alpha}   is the complex conjugate .  Unpreconditioned version of the algorithm   Choose initial guess     x  0      subscript  x  0    x_{0}\,   ,       r  0   ‚Üê   b  -    A     x  0         normal-‚Üê   subscript  r  0     b    A   subscript  x  0       r_{0}\leftarrow b-A\,x_{0}\,           r  ^   0   ‚Üê    b  ^   -     x  ^   0    A  T        normal-‚Üê   subscript   normal-^  r   0      normal-^  b      subscript   normal-^  x   0    superscript  A  T       \hat{r}_{0}\leftarrow\hat{b}-\hat{x}_{0}A^{T}          p  0   ‚Üê    r  0       normal-‚Üê   subscript  p  0    subscript  r  0     p_{0}\leftarrow r_{0}\,           p  ^   0   ‚Üê     r  ^   0       normal-‚Üê   subscript   normal-^  p   0    subscript   normal-^  r   0     \hat{p}_{0}\leftarrow\hat{r}_{0}\,     for    k  =   0  ,  1  ,  ‚Ä¶       k   0  1  normal-‚Ä¶     k=0,1,\ldots   do       Œ±  k   ‚Üê       r  ^   k    r  k       p  ^   k   A   p  k         normal-‚Üê   subscript  Œ±  k        subscript   normal-^  r   k    subscript  r  k       subscript   normal-^  p   k   A   subscript  p  k       \alpha_{k}\leftarrow{\hat{r}_{k}r_{k}\over\hat{p}_{k}Ap_{k}}\,          x   k  +  1    ‚Üê    x  k   +    Œ±  k   ‚ãÖ    p  k         normal-‚Üê   subscript  x    k  1       subscript  x  k    normal-‚ãÖ   subscript  Œ±  k    subscript  p  k       x_{k+1}\leftarrow x_{k}+\alpha_{k}\cdot p_{k}\,           x  ^    k  +  1    ‚Üê     x  ^   k   +    Œ±  k   ‚ãÖ     p  ^   k         normal-‚Üê   subscript   normal-^  x     k  1       subscript   normal-^  x   k    normal-‚ãÖ   subscript  Œ±  k    subscript   normal-^  p   k       \hat{x}_{k+1}\leftarrow\hat{x}_{k}+\alpha_{k}\cdot\hat{p}_{k}\,          r   k  +  1    ‚Üê    r  k   -     Œ±  k   ‚ãÖ  A     p  k         normal-‚Üê   subscript  r    k  1       subscript  r  k      normal-‚ãÖ   subscript  Œ±  k   A    subscript  p  k       r_{k+1}\leftarrow r_{k}-\alpha_{k}\cdot Ap_{k}\,           r  ^    k  +  1    ‚Üê     r  ^   k   -     Œ±  k   ‚ãÖ    p  ^   k     A  T        normal-‚Üê   subscript   normal-^  r     k  1       subscript   normal-^  r   k      normal-‚ãÖ   subscript  Œ±  k    subscript   normal-^  p   k     superscript  A  T       \hat{r}_{k+1}\leftarrow\hat{r}_{k}-\alpha_{k}\cdot\hat{p}_{k}A^{T}          Œ≤  k   ‚Üê       r  ^    k  +  1     r   k  +  1        r  ^   k    r  k         normal-‚Üê   subscript  Œ≤  k        subscript   normal-^  r     k  1     subscript  r    k  1        subscript   normal-^  r   k    subscript  r  k       \beta_{k}\leftarrow{\hat{r}_{k+1}r_{k+1}\over\hat{r}_{k}r_{k}}\,          p   k  +  1    ‚Üê    r   k  +  1    +    Œ≤  k   ‚ãÖ    p  k         normal-‚Üê   subscript  p    k  1       subscript  r    k  1     normal-‚ãÖ   subscript  Œ≤  k    subscript  p  k       p_{k+1}\leftarrow r_{k+1}+\beta_{k}\cdot p_{k}\,           p  ^    k  +  1    ‚Üê     r  ^    k  +  1    +    Œ≤  k   ‚ãÖ     p  ^   k         normal-‚Üê   subscript   normal-^  p     k  1       subscript   normal-^  r     k  1     normal-‚ãÖ   subscript  Œ≤  k    subscript   normal-^  p   k       \hat{p}_{k+1}\leftarrow\hat{r}_{k+1}+\beta_{k}\cdot\hat{p}_{k}\,       Discussion  The biconjugate gradient method is numerically unstable (compare to the biconjugate gradient stabilized method ), but very important from a theoretical point of view. Define the iteration steps by        x  k   :=    x  j   +    P  k    A   -  1     (   b  -   A   x  j     )      ,     assign   subscript  x  k      subscript  x  j      subscript  P  k    superscript  A    1      b    A   subscript  x  j         x_{k}:=x_{j}+P_{k}A^{-1}\left(b-Ax_{j}\right),           x  k  *   :=    x  j  *   +    (    b  *   -    x  j  *   A    )    P  k    A   -  1       ,     assign   superscript   subscript  x  k        superscript   subscript  x  j          superscript  b       superscript   subscript  x  j     A     subscript  P  k    superscript  A    1        x_{k}^{*}:=x_{j}^{*}+\left(b^{*}-x_{j}^{*}A\right)P_{k}A^{-1},     where      ùêÆ  k   =   [   u  0   ,   u  1   ,  ‚Ä¶  ,   u   k  -  1    ]    ,       subscript  ùêÆ  k     subscript  u  0    subscript  u  1   normal-‚Ä¶   subscript  u    k  1       \mathbf{u}_{k}=\left[u_{0},u_{1},\dots,u_{k-1}\right],     with        ùêØ  k   =   [   v  0   ,   v  1   ,  ‚Ä¶  ,   v   k  -  1    ]    .       subscript  ùêØ  k     subscript  v  0    subscript  v  1   normal-‚Ä¶   subscript  v    k  1       \mathbf{v}_{k}=\left[v_{0},v_{1},\dots,v_{k-1}\right].           P   k  +  1    =    P  k   +     (   1  -   P  k    )    u  k    ‚äó     v  k  *   A   (   1  -   P  k    )      v  k  *   A   (   1  -   P  k    )    u  k        .       subscript  P    k  1       subscript  P  k    tensor-product      1   subscript  P  k     subscript  u  k         superscript   subscript  v  k     A    1   subscript  P  k        superscript   subscript  v  k     A    1   subscript  P  k     subscript  u  k         P_{k+1}=P_{k}+\left(1-P_{k}\right)u_{k}\otimes{v_{k}^{*}A\left(1-P_{k}\right)%
 \over v_{k}^{*}A\left(1-P_{k}\right)u_{k}}.     These related projections may be iterated themselves as       P  k   =    A  k   -  1    A        subscript  P  k      superscript   subscript  A  k     1    A     P_{k}=A_{k}^{-1}A     A relation to Quasi-Newton methods is given by     x   k  +  1    =    x  k   -    A   k  +  1    -  1     (    A   x  k    -  b   )          subscript  x    k  1       subscript  x  k      superscript   subscript  A    k  1      1        A   subscript  x  k    b       x_{k+1}=x_{k}-A_{k+1}^{-1}\left(Ax_{k}-b\right)   and      A   k  +  1    -  1    =    A  k   -  1    +     (   1  -    A  k   -  1    A    )    u  k    ‚äó     v  k  *    (   1  -   A   A  k   -  1      )      v  k  *   A   (   1  -    A  k   -  1    A    )    u  k        .       superscript   subscript  A    k  1      1       superscript   subscript  A  k     1     tensor-product      1     superscript   subscript  A  k     1    A     subscript  u  k         superscript   subscript  v  k       1    A   superscript   subscript  A  k     1          superscript   subscript  v  k     A    1     superscript   subscript  A  k     1    A     subscript  u  k         A_{k+1}^{-1}=A_{k}^{-1}+\left(1-A_{k}^{-1}A\right)u_{k}\otimes{v_{k}^{*}\left(%
 1-AA_{k}^{-1}\right)\over v_{k}^{*}A\left(1-A_{k}^{-1}A\right)u_{k}}.   , where        p  k   =    (   1  -   P  k    )    u  k     ,       subscript  p  k       1   subscript  P  k     subscript  u  k      p_{k}=\left(1-P_{k}\right)u_{k},     The new directions       p  k  *   =    v  k  *   A   (   1  -   P  k    )    A   -  1          superscript   subscript  p  k        superscript   subscript  v  k     A    1   subscript  P  k     superscript  A    1       p_{k}^{*}=v_{k}^{*}A\left(1-P_{k}\right)A^{-1}            v  i  *    r  k    =    p  i  *    r  k    =  0   ,           superscript   subscript  v  i      subscript  r  k       superscript   subscript  p  i      subscript  r  k         0     v_{i}^{*}r_{k}=p_{i}^{*}r_{k}=0,     are then orthogonal to the residuals:         r  k  *    u  j    =    r  k  *    p  j    =  0   ,           superscript   subscript  r  k      subscript  u  j       superscript   subscript  r  k      subscript  p  j         0     r_{k}^{*}u_{j}=r_{k}^{*}p_{j}=0,           r  k   =   A   (   1  -   P  k    )    A   -  1     r  j     ,       subscript  r  k     A    1   subscript  P  k     superscript  A    1     subscript  r  j      r_{k}=A\left(1-P_{k}\right)A^{-1}r_{j},     which themselves satisfy       r  k  *   =    r  j  *    (   1  -   P  k    )         superscript   subscript  r  k        superscript   subscript  r  j       1   subscript  P  k       r_{k}^{*}=r_{j}^{*}\left(1-P_{k}\right)           v  k  *   =     r  k  *     M   -  1      .       superscript   subscript  v  k        superscript   subscript  r  k      superscript  M    1       v_{k}^{*}=r_{k}^{*}\,M^{-1}.\,     where    P  k     subscript  P  k    P_{k}         A  =    A  *        A   superscript  A      A=A^{*}\,     With this particular choice, explicit evaluations of     x  0  *   =   x  0        superscript   subscript  x  0      subscript  x  0     x_{0}^{*}=x_{0}   and are avoided, and the algorithm takes the form stated above.  Properties   If     b  *   =  b       superscript  b    b    b^{*}=b   is self-adjoint ,     r  k   =   r  k  *        subscript  r  k    superscript   subscript  r  k       r_{k}=r_{k}^{*}   and     p  k   =   p  k  *        subscript  p  k    superscript   subscript  p  k       p_{k}=p_{k}^{*}   , then     x  k   =   x  k  *        subscript  x  k    superscript   subscript  x  k       x_{k}=x_{k}^{*}   ,      p  i  *   A   p  j    =    r  i  *    M   -  1     r  j    =  0           superscript   subscript  p  i     A   subscript  p  j       superscript   subscript  r  i      superscript  M    1     subscript  r  j         0     p_{i}^{*}Ap_{j}=r_{i}^{*}M^{-1}r_{j}=0   , and the conjugate gradient method produces the same sequence    i  ‚â†  j      i  j    i\neq j   at half the computational cost.    The sequences produced by the algorithm are biorthogonal , i.e.,     P   j  ‚Ä≤       subscript  P   superscript  j  normal-‚Ä≤     P_{j^{\prime}}\,   for     P   i  ‚Ä≤       subscript  P   superscript  i  normal-‚Ä≤     P_{i^{\prime}}\,   .    if      A  x   =  b   .        A  x   b    Ax=b.\,   is a polynomial with   A   A   A   . The algorithm thus produces projections onto the Krylov subspace .    if     x  0      subscript  x  0    x_{0}\,   is a polynomial with    x  0  *     superscript   subscript  x  0      x_{0}^{*}   .   See also   Biconjugate gradient stabilized method  Conjugate gradient method   References      "  Category:Numerical linear algebra  Category:Gradient methods   