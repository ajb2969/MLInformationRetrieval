<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="1686">Elastic net regularization</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>Elastic net regularization</h1>
<hr/>

<p>In <a class="uri" href="statistics" title="wikilink">statistics</a> and, in particular, in the fitting of <a href="linear_regression" title="wikilink">linear</a> or <a href="logistic_regression" title="wikilink">logistic regression</a> models, the <strong>elastic net</strong> is a <a href="Regularization_(mathematics)" title="wikilink">regularized</a> regression method that <a href="Linear_combination" title="wikilink">linearly combines</a> the <a href="Taxicab_geometry" title="wikilink">L1</a> and <a href="Norm_(mathematics)#p-norm" title="wikilink">L2</a> penalties of the <a href="Least_squares#Lasso_method" title="wikilink"> lasso</a> and <a href="Tikhonov_regularization" title="wikilink"> ridge</a> methods.</p>
<h2 id="specification">Specification</h2>

<p>The elastic net method overcomes the limitations of the <a href="Least_squares#Lasso_method" title="wikilink"> LASSO (least absolute shrinkage and selection operator)</a> method which uses a penalty function based on</p>

<p>

<math display="block" id="Elastic_net_regularization:0">
 <semantics>
  <mrow>
   <mrow>
    <msub>
     <mrow>
      <mo>‚à•</mo>
      <mi>Œ≤</mi>
      <mo>‚à•</mo>
     </mrow>
     <mn>1</mn>
    </msub>
    <mo>=</mo>
    <mrow>
     <mstyle displaystyle="false">
      <msubsup>
       <mo largeop="true" symmetric="true">‚àë</mo>
       <mrow>
        <mi>j</mi>
        <mo>=</mo>
        <mn>1</mn>
       </mrow>
       <mi>p</mi>
      </msubsup>
     </mstyle>
     <mrow>
      <mo stretchy="false">|</mo>
      <msub>
       <mi>Œ≤</mi>
       <mi>j</mi>
      </msub>
      <mo stretchy="false">|</mo>
     </mrow>
    </mrow>
   </mrow>
   <mo>.</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <apply>
      <csymbol cd="latexml">norm</csymbol>
      <ci>Œ≤</ci>
     </apply>
     <cn type="integer">1</cn>
    </apply>
    <apply>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <sum></sum>
       <apply>
        <eq></eq>
        <ci>j</ci>
        <cn type="integer">1</cn>
       </apply>
      </apply>
      <ci>p</ci>
     </apply>
     <apply>
      <abs></abs>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>Œ≤</ci>
       <ci>j</ci>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \|\beta\|_{1}=\textstyle\sum_{j=1}^{p}|\beta_{j}|.
  </annotation>
 </semantics>
</math>

 Use of this penalty function has several limitations.<a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a> For example, in the "large <em>p</em>, small <em>n</em>" case (high-dimensional data with few examples), the LASSO selects at most n variables before it saturates. Also if there is a group of highly correlated variables, then the LASSO tends to select one variable from a group and ignore the others. To overcome these limitations, the elastic net adds a quadratic part to the penalty (

<math display="inline" id="Elastic_net_regularization:1">
 <semantics>
  <msup>
   <mrow>
    <mo>‚à•</mo>
    <mi>Œ≤</mi>
    <mo>‚à•</mo>
   </mrow>
   <mn>2</mn>
  </msup>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">superscript</csymbol>
    <apply>
     <csymbol cd="latexml">norm</csymbol>
     <ci>Œ≤</ci>
    </apply>
    <cn type="integer">2</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \|\beta\|^{2}
  </annotation>
 </semantics>
</math>

), which when used alone is <a href="ridge_regression" title="wikilink">ridge regression</a> (known also as <a href="Tikhonov_regularization" title="wikilink">Tikhonov regularization</a>). The estimates from the elastic net method are defined by</p>

<p>

<math display="block" id="Elastic_net_regularization:2">
 <semantics>
  <mrow>
   <mrow>
    <mover accent="true">
     <mi>Œ≤</mi>
     <mo stretchy="false">^</mo>
    </mover>
    <mo>=</mo>
    <mrow>
     <munder accentunder="true">
      <mo>argmin</mo>
      <mo>ùõΩ</mo>
     </munder>
     <mrow>
      <mo stretchy="false">(</mo>
      <mrow>
       <msup>
        <mrow>
         <mo>‚à•</mo>
         <mrow>
          <mi>y</mi>
          <mo>-</mo>
          <mrow>
           <mi>X</mi>
           <mi>Œ≤</mi>
          </mrow>
         </mrow>
         <mo>‚à•</mo>
        </mrow>
        <mn>2</mn>
       </msup>
       <mo>+</mo>
       <mrow>
        <msub>
         <mi>Œª</mi>
         <mn>2</mn>
        </msub>
        <msup>
         <mrow>
          <mo>‚à•</mo>
          <mi>Œ≤</mi>
          <mo>‚à•</mo>
         </mrow>
         <mn>2</mn>
        </msup>
       </mrow>
       <mo>+</mo>
       <mrow>
        <msub>
         <mi>Œª</mi>
         <mn>1</mn>
        </msub>
        <msub>
         <mrow>
          <mo>‚à•</mo>
          <mi>Œ≤</mi>
          <mo>‚à•</mo>
         </mrow>
         <mn>1</mn>
        </msub>
       </mrow>
      </mrow>
      <mo stretchy="false">)</mo>
     </mrow>
    </mrow>
   </mrow>
   <mo>.</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <ci>normal-^</ci>
     <ci>Œ≤</ci>
    </apply>
    <apply>
     <times></times>
     <apply>
      <ci>Œ≤</ci>
      <ci>argmin</ci>
     </apply>
     <apply>
      <plus></plus>
      <apply>
       <csymbol cd="ambiguous">superscript</csymbol>
       <apply>
        <csymbol cd="latexml">norm</csymbol>
        <apply>
         <minus></minus>
         <ci>y</ci>
         <apply>
          <times></times>
          <ci>X</ci>
          <ci>Œ≤</ci>
         </apply>
        </apply>
       </apply>
       <cn type="integer">2</cn>
      </apply>
      <apply>
       <times></times>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <ci>Œª</ci>
        <cn type="integer">2</cn>
       </apply>
       <apply>
        <csymbol cd="ambiguous">superscript</csymbol>
        <apply>
         <csymbol cd="latexml">norm</csymbol>
         <ci>Œ≤</ci>
        </apply>
        <cn type="integer">2</cn>
       </apply>
      </apply>
      <apply>
       <times></times>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <ci>Œª</ci>
        <cn type="integer">1</cn>
       </apply>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <apply>
         <csymbol cd="latexml">norm</csymbol>
         <ci>Œ≤</ci>
        </apply>
        <cn type="integer">1</cn>
       </apply>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \hat{\beta}=\underset{\beta}{\operatorname{argmin}}(\|y-X\beta\|^{2}+\lambda_{%
2}\|\beta\|^{2}+\lambda_{1}\|\beta\|_{1}).
  </annotation>
 </semantics>
</math>

</p>

<p>As a result, the elastic net method includes the LASSO and ridge regression: in other words, each of them is a special case where 

<math display="inline" id="Elastic_net_regularization:3">
 <semantics>
  <mrow>
   <mrow>
    <msub>
     <mi>Œª</mi>
     <mn>1</mn>
    </msub>
    <mo>=</mo>
    <mi>Œª</mi>
   </mrow>
   <mo>,</mo>
   <mrow>
    <msub>
     <mi>Œª</mi>
     <mn>2</mn>
    </msub>
    <mo>=</mo>
    <mn>0</mn>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">formulae-sequence</csymbol>
    <apply>
     <eq></eq>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>Œª</ci>
      <cn type="integer">1</cn>
     </apply>
     <ci>Œª</ci>
    </apply>
    <apply>
     <eq></eq>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>Œª</ci>
      <cn type="integer">2</cn>
     </apply>
     <cn type="integer">0</cn>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \lambda_{1}=\lambda,\lambda_{2}=0
  </annotation>
 </semantics>
</math>


 or 

<math display="inline" id="Elastic_net_regularization:4">
 <semantics>
  <mrow>
   <mrow>
    <msub>
     <mi>Œª</mi>
     <mn>1</mn>
    </msub>
    <mo>=</mo>
    <mn>0</mn>
   </mrow>
   <mo>,</mo>
   <mrow>
    <msub>
     <mi>Œª</mi>
     <mn>2</mn>
    </msub>
    <mo>=</mo>
    <mi>Œª</mi>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">formulae-sequence</csymbol>
    <apply>
     <eq></eq>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>Œª</ci>
      <cn type="integer">1</cn>
     </apply>
     <cn type="integer">0</cn>
    </apply>
    <apply>
     <eq></eq>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>Œª</ci>
      <cn type="integer">2</cn>
     </apply>
     <ci>Œª</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \lambda_{1}=0,\lambda_{2}=\lambda
  </annotation>
 </semantics>
</math>

. Meanwhile, the naive version of elastic net method finds an estimator in a two-stage procedure : first for each fixed 

<math display="inline" id="Elastic_net_regularization:5">
 <semantics>
  <msub>
   <mi>Œª</mi>
   <mn>2</mn>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>Œª</ci>
    <cn type="integer">2</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \lambda_{2}
  </annotation>
 </semantics>
</math>

 it finds the ridge regression coefficients, and then does a LASSO type shrinkage. This kind of estimation incurs a double amount of shrinkage, which leads to increased bias and poor predictions. To improve the prediction performance, the authors rescale the coefficients of the naive version of elastic net by multiplying the estimated coefficients by 

<math display="inline" id="Elastic_net_regularization:6">
 <semantics>
  <mrow>
   <mo stretchy="false">(</mo>
   <mrow>
    <mn>1</mn>
    <mo>+</mo>
    <msub>
     <mi>Œª</mi>
     <mn>2</mn>
    </msub>
   </mrow>
   <mo stretchy="false">)</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <plus></plus>
    <cn type="integer">1</cn>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>Œª</ci>
     <cn type="integer">2</cn>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   (1+\lambda_{2})
  </annotation>
 </semantics>
</math>

.<a class="footnoteRef" href="#fn2" id="fnref2"><sup>2</sup></a></p>
<h2 id="software">Software</h2>
<ul>
<li>"Glmnet: Lasso and elastic-net regularized generalized linear models" is software which is implemented as an <a href="R_(programming_language)" title="wikilink">R</a> source package.<a class="footnoteRef" href="#fn3" id="fnref3"><sup>3</sup></a><a class="footnoteRef" href="#fn4" id="fnref4"><sup>4</sup></a> This includes fast algorithms for estimation of generalized linear models with ‚Ñì<sub>1</sub> (the lasso), ‚Ñì<sub>2</sub> (ridge regression) and mixtures of the two penalties (the elastic net) using cyclical coordinate descent, computed along a regularization path.</li>
<li><a href="JMP_(statistical_software)" title="wikilink">JMP Pro 11</a> includes elastic net regularization, using the Generalized Regression personality with Fit Model.</li>
<li>"pensim: Simulation of high-dimensional data and parallelized repeated penalized regression" implements an alternate, parallelised "2D" tuning method of the ‚Ñì parameters, a method claimed to result in improved prediction accuracy.<a class="footnoteRef" href="#fn5" id="fnref5"><sup>5</sup></a><a class="footnoteRef" href="#fn6" id="fnref6"><sup>6</sup></a></li>
<li><a class="uri" href="scikit-learn" title="wikilink">scikit-learn</a> includes linear regression, <a href="logistic_regression" title="wikilink">logistic regression</a> and linear <a href="support_vector_machine" title="wikilink">support vector machines</a> with elastic net regularization.</li>
</ul>
<h2 id="references">References</h2>
<h2 id="external-links">External links</h2>
<ul>
<li><a href="http://www.stanford.edu/~hastie/TALKS/enet_talk.pdf"></a><a class="uri" href="http://www.stanford.edu/~hastie/TALKS/enet_talk.pdf">http://www.stanford.edu/~hastie/TALKS/enet_talk.pdf</a></li>
</ul>

<p>"</p>

<p><a href="Category:Regression_analysis" title="wikilink">Category:Regression analysis</a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1"><a href="#fnref1">‚Ü©</a></li>
<li id="fn2"></li>
<li id="fn3"><a href="#fnref3">‚Ü©</a></li>
<li id="fn4"><a class="uri" href="http://cran.r-project.org/web/packages/glmnet/index.html">http://cran.r-project.org/web/packages/glmnet/index.html</a><a href="#fnref4">‚Ü©</a></li>
<li id="fn5"><a href="#fnref5">‚Ü©</a></li>
<li id="fn6"><a class="uri" href="http://cran.r-project.org/web/packages/pensim/index.html">http://cran.r-project.org/web/packages/pensim/index.html</a><a href="#fnref6">‚Ü©</a></li>
</ol>
</section>
</body>
</html>
