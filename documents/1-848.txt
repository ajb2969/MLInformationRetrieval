   Product (mathematics)      Product (mathematics)   In mathematics , a product is the result of multiplying , or an expression that identifies factors to be multiplied. Thus, for instance, 6 is the product of 2 and 3 (the result of multiplication), and    x  ⋅   (   2  +  x   )      normal-⋅  x    2  x     x\cdot(2+x)   is the product of   x   x   x   and    (   2  +  x   )      2  x    (2+x)   (indicating that the two factors should be multiplied together).  The order in which real or complex numbers are multiplied has no bearing on the product; this is known as the commutative law of multiplication. When matrices or members of various other associative algebras are multiplied, the product usually depends on the order of the factors. Matrix multiplication, for example, and multiplication in other algebras is in general non-commutative.  Product of two numbers  Product of two natural numbers  (Figure)  3 by 4 is 12   Placing several stones into a rectangular pattern with   r   r   r   rows and   s   s   s   columns gives       r  ⋅  s   =    ∑   i  =  1   s   r   =    ∑   j  =  1   r   s          normal-⋅  r  s     superscript   subscript     i  1    s   r          superscript   subscript     j  1    r   s      r\cdot s=\sum_{i=1}^{s}r=\sum_{j=1}^{r}s     stones.  Product of two integers  Integers allow positive and negative numbers. The two numbers are multiplied just like natural numbers, except we need an additional rule for the signs:        ⋅    -    +      -    +    -      +    -    +        normal-⋅                 \begin{array}[]{|c|c c|}\hline\cdot&-&+\\
 \hline-&+&-\\
 +&-&+\\
 \hline\end{array}     In words, we have:   Minus times Minus gives Plus  Minus times Plus gives Minus  Plus times Minus gives Minus  Plus times Plus gives Plus   Product of two fractions  Two fractions can be multiplied by multiplying their numerators and denominators:        z  n   ⋅    z  ′    n  ′     =    z  ⋅   z  ′     n  ⋅   n  ′          normal-⋅    z  n      superscript  z  normal-′    superscript  n  normal-′        normal-⋅  z   superscript  z  normal-′     normal-⋅  n   superscript  n  normal-′       \frac{z}{n}\cdot\frac{z^{\prime}}{n^{\prime}}=\frac{z\cdot z^{\prime}}{n\cdot n%
 ^{\prime}}     Product of two real numbers  For a rigorous definition of the product of two real numbers see Construction of the real numbers .  Product of two complex numbers  Two complex numbers can be multiplied by the distributive law and the fact that     i  2   =   -  1        superscript  normal-i  2     1     \mathrm{i}^{2}=-1   , as follows:       (   a  +    b   i    )   ⋅   (   c  +    d   i    )      normal-⋅    a    b  normal-i      c    d  normal-i      \displaystyle(a+b\,\mathrm{i})\cdot(c+d\,\mathrm{i})     Geometric meaning of complex multiplication  Complex numbers can be written in polar coordinates :       a  +    b   i    =   r  ⋅   (    cos   (  φ  )    +   i   sin   (  φ  )      )    =   r  ⋅   e   i  φ             a    b  normal-i     normal-⋅  r      φ     normal-i    φ            normal-⋅  r   superscript  normal-e    normal-i  φ        a+b\,\mathrm{i}=r\cdot(\cos(\varphi)+\mathrm{i}\sin(\varphi))=r\cdot\mathrm{e}%
 ^{\mathrm{i}\varphi}   Furthermore,       c  +    d   i    =   s  ⋅   (    cos   (  ψ  )    +   i   sin   (  ψ  )      )    =   s  ⋅   e   i  ψ             c    d  normal-i     normal-⋅  s      ψ     normal-i    ψ            normal-⋅  s   superscript  normal-e    normal-i  ψ        c+d\,\mathrm{i}=s\cdot(\cos(\psi)+\mathrm{i}\sin(\psi))=s\cdot\mathrm{e}^{%
 \mathrm{i}\psi}   , from which we obtain:        (    a  ⋅  c   -   b  ⋅  d    )   +    (    a  ⋅  d   +   b  ⋅  c    )   i    =   r  ⋅  s  ⋅   (    cos   (   φ  +  ψ   )    +   i   sin   (   φ  +  ψ   )      )    =   r  ⋅  s  ⋅   e   i   (   φ  +  ψ   )                 normal-⋅  a  c    normal-⋅  b  d         normal-⋅  a  d    normal-⋅  b  c    normal-i     normal-⋅  r  s        φ  ψ      normal-i      φ  ψ             normal-⋅  r  s   superscript  normal-e    normal-i    φ  ψ         (a\cdot c-b\cdot d)+(a\cdot d+b\cdot c)\,\mathrm{i}=r\cdot s\cdot(\cos(\varphi%
 +\psi)+\mathrm{i}\sin(\varphi+\psi))=r\cdot s\cdot\mathrm{e}^{\mathrm{i}(%
 \varphi+\psi)}     The geometric meaning is that we multiply the magnitudes and add the angles.  Product of two quaternions  The product of two quaternions can be found in the article on quaternions . However, it is interesting to note that in this case,    a  ⋅  b     normal-⋅  a  b    a\cdot b   and    b  ⋅  a     normal-⋅  b  a    b\cdot a   are different.  Product of sequences  The product operator for the product of a sequence is denoted by the capital Greek letter Pi ∏ (in analogy to the use of the capital Sigma ∑ as summation symbol). The product of a sequence consisting of only one number is just that number itself. The product of no factors at all is known as the empty product , and is equal to 1.  Further examples for commutative rings  Residue classes of integers  Residue classes in the rings      \Z   /  N    \Z         \Z  N   \Z    \Z/N\Z   can be added:        (   a  +   N   \Z     )   +   (   b  +   N   \Z     )    =   a  +  b  +   N   \Z             a    N  \Z      b    N  \Z       a  b    N  \Z      (a+N\Z)+(b+N\Z)=a+b+N\Z     and multiplied:        (   a  +   N   \Z     )   ⋅   (   b  +   N   \Z     )    =    a  ⋅  b   +   N   \Z          normal-⋅    a    N  \Z      b    N  \Z        normal-⋅  a  b     N  \Z      (a+N\Z)\cdot(b+N\Z)=a\cdot b+N\Z     Rings of functions  Functions to the real numbers can be added or multiplied by adding or multiplying their outputs:        (   f  +  g   )    (  m  )    :=    f   (  m  )    +   g   (  m  )        assign      f  g   m       f  m     g  m      (f+g)(m):=f(m)+g(m)           (   f  ⋅  g   )    (  m  )    :=     f   (  m  )    ⋅  g    (  m  )       assign     normal-⋅  f  g   m      normal-⋅    f  m   g   m     (f\cdot g)(m):=f(m)\cdot g(m)     Convolution  thumb|upright=1.5|The convolution of the square wave with itself gives the triangular function  Two functions from the reals to itself can be multiplied in another way, called the convolution .  If       ∫   -  ∞   ∞     |   f   (  t  )    |    d    t     <  ∞     and    ∫   -  ∞   ∞     |   g   (  t  )    |    d    t      <  ∞      formulae-sequence      superscript   subscript                f  t    normal-d  t          and    superscript   subscript                g  t    normal-d  t         \int\limits_{-\infty}^{\infty}|f(t)|\,\mathrm{d}\,t\;<\;\infty\quad\mbox{and }%
 \int\limits_{-\infty}^{\infty}|g(t)|\,\mathrm{d}\,t\;<\;\infty     then the integral        (   f  *  g   )    (  t  )    :=    ∫   -  ∞   ∞      f   (  τ  )    ⋅  g    (   t  -  τ   )   d  τ       assign      f  g   t     superscript   subscript             normal-⋅    f  τ   g     t  τ   normal-d  τ      (f*g)(t)\;:=\int\limits_{-\infty}^{\infty}f(\tau)\cdot g(t-\tau)\,\mathrm{d}\tau     is well defined and is called the convolution.  Under the Fourier transform , convolution becomes multiplication.  Polynomial rings  The product of two polynomials is given by the following:        (    ∑   i  =  0   n     a  i    X  i     )   ⋅   (    ∑   j  =  0   m     b  j    X  j     )    =    ∑   k  =  0    n  +  m      c  k    X  k          normal-⋅    superscript   subscript     i  0    n      subscript  a  i    superscript  X  i       superscript   subscript     j  0    m      subscript  b  j    superscript  X  j        superscript   subscript     k  0      n  m       subscript  c  k    superscript  X  k       \left(\sum_{i=0}^{n}a_{i}X^{i}\right)\cdot\left(\sum_{j=0}^{m}b_{j}X^{j}\right%
 )=\sum_{k=0}^{n+m}c_{k}X^{k}     with       c  k   =    ∑    i  +  j   =  k      a  i   ⋅   b  j          subscript  c  k     subscript       i  j   k     normal-⋅   subscript  a  i    subscript  b  j       c_{k}=\sum_{i+j=k}a_{i}\cdot b_{j}     Products in linear algebra  Scalar multiplication  By the very definition of a vector space, one can form the product of any scalar with any vector, giving a map      \R   ×  V   →  V     normal-→    \R  V   V    \R\times V\rightarrow V   .  Scalar product  A scalar product is a bilinear map:      ⋅  :  V  ×  V  →   \R      fragments  normal-⋅  normal-:  V   V  normal-→  \R    \cdot:V\times V\rightarrow\R     with the following conditions, that     v  ⋅  v   >  0       normal-⋅  v  v   0    v\cdot v>0   for all    0  ≠  v  ∈  V        0  v       V     0\not=v\in V   .  From the scalar product, one can define a norm by letting     ∥  v  ∥   :=    v  ⋅  v       assign   norm  v      normal-⋅  v  v      \|v\|:=\sqrt{v\cdot v}   .  The scalar product also allows one to define an angle between two vectors:        cos  ∠    (  v  ,  w  )    =    v  ⋅  w     ∥  v  ∥   ⋅   ∥  w  ∥             normal-∠    v  w       normal-⋅  v  w    normal-⋅   norm  v    norm  w       \cos\angle(v,w)=\frac{v\cdot w}{\|v\|\cdot\|w\|}     In   n   n   n   -dimensional Euclidean space, the standard scalar product (called the dot product ) is given by:        (    ∑   i  =  1   n     α  i    e  i     )   ⋅   (    ∑   i  =  1   n     β  i    e  i     )    =    ∑   i  =  1   n      α  i     β  i          normal-⋅    superscript   subscript     i  1    n      subscript  α  i    subscript  e  i       superscript   subscript     i  1    n      subscript  β  i    subscript  e  i        superscript   subscript     i  1    n      subscript  α  i    subscript  β  i       \left(\sum_{i=1}^{n}\alpha_{i}e_{i}\right)\cdot\left(\sum_{i=1}^{n}\beta_{i}e_%
 {i}\right)=\sum_{i=1}^{n}\alpha_{i}\,\beta_{i}     Cross product in 3-dimensional space  The cross product of two vectors in 3-dimensions is a vector perpendicular to the two factors, with length equal to the area of the parallelogram spanned by the two factors.  The cross product can also be expressed as the formal  determinant :       𝐮  ×  𝐯   =   |     𝐢    𝐣    𝐤       u  1      u   ;  2       u   ;  3         v  1      v   ;  2       v   ;  3       |         𝐮  𝐯       𝐢  𝐣  𝐤     subscript  u  1    fragments  u   subscript  normal-;  2     fragments  u   subscript  normal-;  3       subscript  v  1    fragments  v   subscript  normal-;  2     fragments  v   subscript  normal-;  3         \mathbf{u\times v}=\begin{vmatrix}\mathbf{i}&\mathbf{j}&\mathbf{k}\\
 u_{1}&u_{2}&u_{3}\\
 v_{1}&v_{2}&v_{3}\\
 \end{vmatrix}     Composition of linear mappings  A linear mapping can be defined as a function f between two vector spaces V and W with underlying field F , satisfying 1         f   (     t  1    x  1    +    t  2    x  2     )    =      t  1   f   (   x  1   )    +    t  2   f   (   x  2   )     ,   ∀   x  1      ,     x  2   ∈   V  ,   ∀   t  1      ,    t  2   ∈  𝔽     .     formulae-sequence      f       subscript  t  1    subscript  x  1       subscript  t  2    subscript  x  2            subscript  t  1   f   subscript  x  1       subscript  t  2   f   subscript  x  2      for-all   subscript  x  1       formulae-sequence     subscript  x  2    V   for-all   subscript  t  1         subscript  t  2   𝔽      f(t_{1}x_{1}+t_{2}x_{2})=t_{1}f(x_{1})+t_{2}f(x_{2}),\forall x_{1},x_{2}\in V,%
 \forall t_{1},t_{2}\in\mathbb{F}.   If one only considers finite dimensional vector spaces, then        f   (  𝐯  )    =   f   (    v  i    𝐛  𝐕    i    )    =    v  i   f   (   𝐛  𝐕    i   )    =    f   i  j     v  i    𝐛  𝐖    j     ,          f  𝐯     f     subscript  v  i    superscript   subscript  𝐛  𝐕   i             subscript  v  i   f   superscript   subscript  𝐛  𝐕   i            subscript   superscript  f  i   j    subscript  v  i    superscript   subscript  𝐛  𝐖   j       f(\mathbf{v})=f(v_{i}\mathbf{b_{V}}^{i})=v_{i}f(\mathbf{b_{V}}^{i})={f^{i}}_{j%
 }v_{i}\mathbf{b_{W}}^{j},   in which b V and b W denote the bases of V and W , and v i denotes the component of v on b V i , and Einstein summation convention is applied.  Now we consider the composition of two linear mappings between finite dimensional vector spaces. Let the linear mapping f map V to W , and let the linear mapping g map W to U . Then one can get         g  ∘  f    (  𝐯  )    =   g   (    f   i  j     v  i    𝐛  𝐖    j    )    =    g   j  k     f   i  j     v  i    𝐛  𝐔    k     .            g  f   𝐯     g     subscript   superscript  f  i   j    subscript  v  i    superscript   subscript  𝐛  𝐖   j             subscript   superscript  g  j   k    subscript   superscript  f  i   j    subscript  v  i    superscript   subscript  𝐛  𝐔   k       g\circ f(\mathbf{v})=g({f^{i}}_{j}v_{i}\mathbf{b_{W}}^{j})={g^{j}}_{k}{f^{i}}_%
 {j}v_{i}\mathbf{b_{U}}^{k}.   Or in matrix form:         g  ∘  f    (  𝐯  )    =  𝐆𝐅𝐯   ,          g  f   𝐯   𝐆𝐅𝐯    g\circ f(\mathbf{v})=\mathbf{G}\mathbf{F}\mathbf{v},   in which the i -row, j -column element of F , denoted by F ij , is f j i , and G ij =g j i .  The composition of more than two linear mappings can be similarly represented by a chain of matrix multiplication.  Product of two matrices  Given two matrices      A  =    (   a   i  ,  j    )     i  =   1  …  s    ;   j  =   1  …  r      ∈    \R    s  ×  r          A   subscript   subscript  a   i  j     formulae-sequence    i    1  normal-…  s      j    1  normal-…  r            superscript  \R    s  r       A=(a_{i,j})_{i=1\ldots s;j=1\ldots r}\in\R^{s\times r}   and    B  =    (   b   j  ,  k    )     j  =   1  …  r    ;   k  =   1  …  t      ∈    \R    r  ×  t          B   subscript   subscript  b   j  k     formulae-sequence    j    1  normal-…  r      k    1  normal-…  t            superscript  \R    r  t       B=(b_{j,k})_{j=1\ldots r;k=1\ldots t}\in\R^{r\times t}     their product is given by       B  ⋅  A   =     (    ∑   j  =  1   r     a   i  ,  j    ⋅   b   j  ,  k      )     i  =   1  …  s    ;   k  =   1  …  t       ∈    \R    s  ×  t           normal-⋅  B  A    subscript    superscript   subscript     j  1    r    normal-⋅   subscript  a   i  j     subscript  b   j  k       formulae-sequence    i    1  normal-…  s      k    1  normal-…  t            superscript  \R    s  t       B\cdot A=\left(\sum_{j=1}^{r}a_{i,j}\cdot b_{j,k}\right)_{i=1\ldots s;k=1%
 \ldots t}\;\in\R^{s\times t}     Composition of linear functions as matrix product  There is a relationship between the composition of linear functions and the product of two matrices. To see this, let r = dim(U), s = dim(V) and t = dim(W) be the (finite) dimensions of vector spaces U, V und W. Let    𝒰  =   {   u  1   ,   …   u  r    }       𝒰    subscript  u  1     normal-…   subscript  u  r       \mathcal{U}=\{u_{1},\ldots u_{r}\}   be a basis von U,    𝒱  =   {   v  1   ,   …   v  s    }       𝒱    subscript  v  1     normal-…   subscript  v  s       \mathcal{V}=\{v_{1},\ldots v_{s}\}   be a basis of V und    𝒲  =   {   w  1   ,   …   w  t    }       𝒲    subscript  w  1     normal-…   subscript  w  t       \mathcal{W}=\{w_{1},\ldots w_{t}\}   be a basis of W. In terms of this basis, let    A  =    M  𝒱  𝒰    (  f  )    ∈    \R    s  ×  r          A     subscript   superscript  M  𝒰   𝒱   f         superscript  \R    s  r       A=M^{\mathcal{U}}_{\mathcal{V}}(f)\in\R^{s\times r}   be the matrix representing f : U → V and    B  =    M  𝒲  𝒱    (  g  )    ∈    \R    r  ×  t          B     subscript   superscript  M  𝒱   𝒲   g         superscript  \R    r  t       B=M^{\mathcal{V}}_{\mathcal{W}}(g)\in\R^{r\times t}   be the matrix representing g : V → W. Then       B  ⋅  A   =    M  𝒲  𝒰    (   g  ∘  f   )    ∈    \R    s  ×  t           normal-⋅  B  A      subscript   superscript  M  𝒰   𝒲     g  f          superscript  \R    s  t       B\cdot A=M^{\mathcal{U}}_{\mathcal{W}}(g\circ f)\in\R^{s\times t}     is the matrix representing     g  ∘  f   :   U  →  W      normal-:    g  f    normal-→  U  W     g\circ f:U\rightarrow W   .  In other words: the matrix product is the description in coordinates of the composition of linear functions.  Tensor product of vector spaces  Given two finite dimensional vector spaces V and W , the tensor product of them can be defined as a (2,0)-tensor satisfying:          V  ⊗  W    (  v  ,  m  )    =   V   (  v  )   W   (  w  )     ,     ∀  v   ∈   V  *    ,    ∀  w   ∈   W  *      ,     formulae-sequence       tensor-product  V  W    v  m      V  v  W  w     formulae-sequence     for-all  v    superscript  V        for-all  w    superscript  W        V\otimes W(v,m)=V(v)W(w),\forall v\in V^{*},\forall w\in W^{*},   where V * and W * denote the dual spaces of V and W . 2  Set theoretical product  In set theory, a Cartesian product is a mathematical operation which returns a set (or product set ) from multiple sets. That is, for sets A and B , the Cartesian product  is the set of all ordered pairs where  and . 3  Empty product  The empty product has the value of 1 (the identity element of multiplication) just like the empty sum has the value of 0 (the identity element of addition).  Products in category theory  It is often possible to form the product of two (or more) mathematical objects to form another object of the same kind. Such products are generically called internal products , as they can be described by the generic notion of a monoidal category . Examples include:   the Cartesian product of sets,  the product of groups , and also the semidirect product , knit product and wreath product ,  the free product of groups  the product of rings ,  the product of ideals ,  the product of topological spaces ,  the Wick product of random variables .  the cap , cup and slant product in algebraic topology.  the smash product and wedge sum (sometimes called the wedge product) in homotopy.   For the general treatment of the concept of a product, see product (category theory) , which describes how to combine two objects of some kind to create an object, possibly of a different kind. But also, in category theory, one has:   the fiber product or pullback,  the product category , a category that is the product of categories.  the ultraproduct , in model theory .   Other products   Hadamard product ,  Kronecker product .  The product of tensors :  Wedge product or exterior product  Interior product  Outer product  Tensor product   A function's product integral (as a continuous equivalent to the product of a sequence or the multiplicative version of the (normal/standard/additive) integral. The product integral is also known as "continuous product" or "multiplical".  Complex multiplication , a theory of elliptic curves.   See also   Pi (letter)  Iterated binary operation   Notes  References  External links   Product on Wolfram Mathworld    "  Category:Multiplication     ↩  ↩  ↩     