   Multi-scale approaches      Multi-scale approaches   The scale space representation of a signal obtained by Gaussian smoothing satisfies a number of special properties, scale-space axioms , which make it into a special form of multi-scale representation. There are, however, also other types of "multi-scale approaches" in the areas of computer vision , image processing and signal processing , in particular the notion of wavelets . The purpose of this article is to describe a few of these approaches:  Scale-space theory for one-dimensional signals  For one-dimensional signals , there exists quite a well-developed theory for continuous and discrete kernels that guarantee that new local extrema or zero-crossings cannot be created by a convolution operation. 1 For continuous signals , it holds that all scale-space kernels can be decomposed into the following sets of primitive smoothing kernels:   the Gaussian kernel      g   (  x  ,  t  )    =    1    2  π  t      exp   (   -     x  2   /  2   t    )           g   x  t        1      2  π  t              superscript  x  2   2   t        g(x,t)=\frac{1}{\sqrt{2\pi t}}\exp({-x^{2}/2t})   where    t  >  0      t  0    t>0   ,  truncated exponential kernels (filters with one real pole in the s -plane):          h   (  x  )    =   exp   (   -   a  x    )          h  x         a  x       h(x)=\exp({-ax})   if    x  ≥  0      x  0    x\geq 0   and 0 otherwise where    a  >  0      a  0    a>0          h   (  x  )    =   exp   (   b  x   )          h  x       b  x      h(x)=\exp({bx})   if    x  ≤  0      x  0    x\leq 0   and 0 otherwise where    b  >  0      b  0    b>0   ,      translations,  rescalings.   For discrete signals , we can, up to trivial translations and rescalings, decompose any discrete scale-space kernel into the following primitive operations:   the discrete Gaussian kernel          T   (  n  ,  t  )    =    I  n    (   α  t   )          T   n  t       subscript  I  n     α  t      T(n,t)=I_{n}(\alpha t)   where     α  ,  t   >  0       α  t   0    \alpha,t>0   where    I  n     subscript  I  n    I_{n}   are the modified Bessel functions of integer order,      generalized binomial kernels corresponding to linear smoothing of the form         f   o  u  t     (  x  )    =    p   f   i  n     (  x  )    +   q   f   i  n     (   x  -  1   )            subscript  f    o  u  t    x       p   subscript  f    i  n    x     q   subscript  f    i  n      x  1       f_{out}(x)=pf_{in}(x)+qf_{in}(x-1)   where     p  ,  q   >  0       p  q   0    p,q>0           f   o  u  t     (  x  )    =    p   f   i  n     (  x  )    +   q   f   i  n     (   x  +  1   )            subscript  f    o  u  t    x       p   subscript  f    i  n    x     q   subscript  f    i  n      x  1       f_{out}(x)=pf_{in}(x)+qf_{in}(x+1)   where     p  ,  q   >  0       p  q   0    p,q>0   ,   first-order recursive filters corresponding to linear smoothing of the form         f   o  u  t     (  x  )    =     f   i  n     (  x  )    +   α   f   o  u  t     (   x  -  1   )            subscript  f    o  u  t    x        subscript  f    i  n    x     α   subscript  f    o  u  t      x  1       f_{out}(x)=f_{in}(x)+\alpha f_{out}(x-1)   where    α  >  0      α  0    \alpha>0           f   o  u  t     (  x  )    =     f   i  n     (  x  )    +   β   f   o  u  t     (   x  +  1   )            subscript  f    o  u  t    x        subscript  f    i  n    x     β   subscript  f    o  u  t      x  1       f_{out}(x)=f_{in}(x)+\beta f_{out}(x+1)   where    β  >  0      β  0    \beta>0   ,   the one-sided Poisson kernel        p   (  n  ,  t  )    =    e   -  t      t  n    n  !           p   n  t       superscript  e    t       superscript  t  n     n       p(n,t)=e^{-t}\frac{t^{n}}{n!}   for    n  ≥  0      n  0    n\geq 0   where    t  ≥  0      t  0    t\geq 0          p   (  n  ,  t  )    =    e   -  t      t   -  n      (   -  n   )   !           p   n  t       superscript  e    t       superscript  t    n        n        p(n,t)=e^{-t}\frac{t^{-n}}{(-n)!}   for    n  ≤  0      n  0    n\leq 0   where    t  ≥  0      t  0    t\geq 0   .  From this classification, it is apparent that it we require a continuous semi-group structure, there are only three classes of scale-space kernels with a continuous scale parameter; the Gaussian kernel which forms the scale-space of continuous signals, the discrete Gaussian kernel which forms the scale-space of discrete signals and the time-causal Poisson kernel that forms a temporal scale-space over discrete time. If we on the other hand sacrifice the continuous semi-group structure, there are more options:  For discrete signals, the use of generalized binomial kernels provides a formal basis for defining the smoothing operation in a pyramid. For temporal data, the one-sided truncated exponential kernels and the first-order recursive filters provide a way to define time-causal scale-spaces  2 3 that allow for efficient numerical implementation and respect causality over time without access to the future. The first-order recursive filters also provide a framework for defining recursive approximations to the Gaussian kernel that in a weaker sense preserve some of the scale-space properties. 4 5  See also   Scale space  Scale space implementation  Scale-space segmentation   References    "  Category:Image processing  Category:Computer vision     Lindeberg, T., "Scale-space for discrete signals," PAMI(12), No. 3, March 1990, pp. 234-254. ↩  Richard F. Lyon. "Speech recognition in scale space," Proc. of 1987 ICASSP. San Diego, March, pp. 29.3.14, 1987. ↩  Lindeberg, T. and Fagerstrom, F.: Scale-space with causal time direction, Proc. 4th European Conference on Computer Vision, Cambridge, England, April 1996. Springer-Verlag LNCS Vol 1064, pages 229--240. ↩  Young, I.I., van Vliet, L.J.: Recursive implementation of the Gaussian filter, Signal Processing, vol. 44, no. 2, 1995, 139-151. ↩  Deriche, R: Recursively implementing the Gaussian and its derivatives, INRIA Research Report 1893, 1993. ↩     