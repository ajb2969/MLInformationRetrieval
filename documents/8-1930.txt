   Dvoretzky‚ÄìKiefer‚ÄìWolfowitz inequality      Dvoretzky‚ÄìKiefer‚ÄìWolfowitz inequality   In the theory of probability and statistics , the Dvoretzky‚ÄìKiefer‚ÄìWolfowitz inequality predicts how close an empirically determined distribution function will be to the distribution function from which the empirical samples are drawn. It is named after Aryeh Dvoretzky , Jack Kiefer , and Jacob Wolfowitz , who in 1956 proved 1 the inequality with an unspecified multiplicative constant C in front of the exponent on the right-hand side. In¬†1990, Pascal Massart proved the inequality with the sharp constant C =¬†1, 2 confirming a conjecture due to Birnbaum and McCarty.  The DKW inequality  Given a natural number n , let X 1 , X 2 , ‚Ä¶, X n be real-valued independent and identically distributed  random variables with distribution function  F (¬∑). Let F n denote the associated empirical distribution function defined by          F  n    (  x  )    =    1  n     ‚àë   i  =  1   n    ùüè   {   X  i   ‚â§  x  }       ,   x  ‚àà  ‚Ñù    .     formulae-sequence       subscript  F  n   x       1  n     superscript   subscript     i  1    n    subscript  1   fragments  normal-{   subscript  X  i    x  normal-}         x  ‚Ñù     F_{n}(x)=\frac{1}{n}\sum_{i=1}^{n}\mathbf{1}_{\{X_{i}\leq x\}},\qquad x\in%
 \mathbb{R}.     The Dvoretzky‚ÄìKiefer‚ÄìWolfowitz inequality bounds the probability that the random function  F n differs from F by more than a given constant Œµ >¬†0 anywhere on the real line. More precisely, there is the one-sided estimate         Pr   (     sup   x  ‚àà  ‚Ñù     (     F  n    (  x  )    -   F   (  x  )     )    >  Œµ   )    ‚â§   e   -   2  n   Œµ  2         for every  Œµ   ‚â•      1   2  n      ln  2       ,     formulae-sequence     Pr      subscript  supremum    x  ‚Ñù         subscript  F  n   x     F  x     Œµ     superscript  e      2  n   superscript  Œµ  2           for every  Œµ         1    2  n      2        \Pr\Bigl(\sup_{x\in\mathbb{R}}\bigl(F_{n}(x)-F(x)\bigr)>\varepsilon\Bigr)\leq e%
 ^{-2n\varepsilon^{2}}\qquad\text{for every }\varepsilon\geq\sqrt{\tfrac{1}{2n}%
 \ln 2},     which also implies a two-sided estimate 3        Pr   (     sup   x  ‚àà  ‚Ñù     |     F  n    (  x  )    -   F   (  x  )     |    >  Œµ   )    ‚â§   2   e   -   2  n   Œµ  2          for every  Œµ   >  0.      formulae-sequence     Pr      subscript  supremum    x  ‚Ñù           subscript  F  n   x     F  x      Œµ      2   superscript  e      2  n   superscript  Œµ  2            for every  Œµ   0.     \Pr\Bigl(\sup_{x\in\mathbb{R}}|F_{n}(x)-F(x)|>\varepsilon\Bigr)\leq 2e^{-2n%
 \varepsilon^{2}}\qquad\text{for every }\varepsilon>0.     This strengthens the Glivenko‚ÄìCantelli theorem by quantifying the rate of convergence as n tends to infinity. It also estimates the tail probability of the Kolmogorov‚ÄìSmirnov statistic . The inequalities above follow from the case where F corresponds to be the uniform distribution on [0,1] in view of the fact 4 that F n has the same distributions as G n ( F ) where G n is the empirical distribution of U 1 , U 2 , ‚Ä¶, U n where these are independent and Uniform(0,1), and noting that         sup   x  ‚àà  ‚Ñù     |     F  n    (  x  )    -   F   (  x  )     |     =  d     sup   x  ‚àà  ‚Ñù     |     G  n    (   F   (  x  )    )    -   F   (  x  )     |    ‚â§    sup   0  ‚â§  t  ‚â§  1     |     G  n    (  t  )    -  t   |     ,        superscript   d     subscript  supremum    x  ‚Ñù           subscript  F  n   x     F  x        subscript  supremum    x  ‚Ñù           subscript  G  n     F  x      F  x             subscript  supremum      0  t       1            subscript  G  n   t   t        \sup_{x\in\mathbb{R}}|F_{n}(x)-F(x)|\stackrel{d}{=}\sup_{x\in\mathbb{R}}|G_{n}%
 (F(x))-F(x)|\leq\sup_{0\leq t\leq 1}|G_{n}(t)-t|,   with equality if and only if F is continuous.  References    "  Category:Asymptotic statistical theory  Category:Statistical inequalities  Category:Empirical process     ‚Ü©  ‚Ü©  ‚Ü©  ‚Ü©   