   F-test of equality of variances      F-test of equality of variances   In statistics, an F -test for the null hypothesis that two normal populations have the same variance is sometimes used, although it needs to be used with caution as it can be sensitive to the assumption that the variables have this distribution.  Notionally, any F-test can be regarded as a comparison of two variances, but the specific case being discussed in this article is that of two populations, where the test statistic used is the ratio of two sample variances . This particular situation is of importance in mathematical statistics since it provides a basic exemplar case in which the F-distribution can be derived. 1 For application in applied statistics , there is concern that the test is so sensitive to the assumption of normality that it would be inadvisable to use it as a routine test for the equality of variances. In other words, this is a case where "approximate normality" (which in similar contexts would often be justified using the central limit theorem ), is not good enough to make the test procedure approximately valid to an acceptable degree.  The test  Let X 1 , ..., X n and Y 1 , ..., Y m be independent and identically distributed samples from two populations which each have a normal distribution . The expected values for the two populations can be different, and the hypothesis to be tested is that the variances are equal. Let       X  ¯   =    1  n     ∑   i  =  1   n     X  i   and   Y  ¯      =    1  m     ∑   i  =  1   m    Y  i            normal-¯  X       1  n     superscript   subscript     i  1    n      subscript  X  i   and   normal-¯  Y               1  m     superscript   subscript     i  1    m    subscript  Y  i        \overline{X}=\frac{1}{n}\sum_{i=1}^{n}X_{i}\text{ and }\overline{Y}=\frac{1}{m%
 }\sum_{i=1}^{m}Y_{i}     be the sample means . Let       S  X  2   =    1   n  -  1      ∑   i  =  1   n      (    X  i   -   X  ¯    )   2   and   S  Y  2      =    1   m  -  1      ∑   i  =  1   m     (    Y  i   -   Y  ¯    )   2            superscript   subscript  S  X   2       1    n  1      superscript   subscript     i  1    n      superscript     subscript  X  i    normal-¯  X    2   and   superscript   subscript  S  Y   2               1    m  1      superscript   subscript     i  1    m    superscript     subscript  Y  i    normal-¯  Y    2        S_{X}^{2}=\frac{1}{n-1}\sum_{i=1}^{n}\left(X_{i}-\overline{X}\right)^{2}\text{%
  and }S_{Y}^{2}=\frac{1}{m-1}\sum_{i=1}^{m}\left(Y_{i}-\overline{Y}\right)^{2}     be the sample variances . Then the test statistic      F  =    S  X  2    S  Y  2        F     superscript   subscript  S  X   2    superscript   subscript  S  Y   2      F=\frac{S_{X}^{2}}{S_{Y}^{2}}     has an F-distribution with n − 1 and m − 1 degrees of freedom if the null hypothesis of equality of variances is true. Otherwise it has a non-central F-distribution. The null hypothesis is rejected if F is either too large or too small.  Properties  This F-test is known to be extremely sensitive to non-normality , 2 3 so Levene's test , Bartlett's test , or the Brown–Forsythe test are better tests for testing the equality of two variances. (However, all of these tests create experiment-wise type I error inflations when conducted as a test of the assumption of homoscedasticity prior to a test of effects. 4 ) F-tests for the equality of variances can be used in practice, with care, particularly where a quick check is required, and subject to associated diagnostic checking: practical text-books 5 suggest both graphical and formal checks of the assumption.  F-tests are used for other statistical tests of hypotheses , such as testing for differences in means in three or more groups, or in factorial layouts. These F-tests are generally not robust when there are violations of the assumption that each population follows the normal distribution , particularly for small alpha levels and unbalanced layouts. 6 However, for large alpha levels (e.g., at least 0.05) and balanced layouts, the F-test is relatively robust, although (if the normality assumption does not hold) it suffers from a loss in comparative statistical power as compared with non-parametric counterparts.  Generalization  The immediate generalization of the problem outlined above is to situations where there are more than two groups or populations, and the hypothesis is that all of the variances are equal. This is the problem treated by Hartley's test and Bartlett's test .  See also   Goldfeld–Quandt test  Levene's test   References  "  Category:Statistical ratios  Category:Statistical tests     Johnson, N.L., Kotz, S., Balakrishnan, N. (1995) Continuous Univariate Distributions, Volume 2 , Wiley. ISBN 0-471-58494-0 (Section 27.1) ↩  ↩  ↩  Sawilowsky, S. (2002). "Fermat, Schubert, Einstein, and Behrens–Fisher:The Probable Difference Between Two Means When σ 1 2 ≠ σ 2 2 " , Journal of Modern Applied Statistical Methods , 1 (2), 461–472. ↩  Rees, D.G. (2001) Essential Statistics (4th Edition) , Chapman & Hall/CRC, ISBN 1-58488-007-4. Section 10.15 ↩  ↩     