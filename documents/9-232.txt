   Series acceleration      Series acceleration   In mathematics , series acceleration is one of a collection of sequence transformations for improving the rate of convergence of a series . Techniques for series acceleration are often applied in numerical analysis , where they are used to improve the speed of numerical integration . Series acceleration techniques may also be used, for example, to obtain a variety of identities on special functions . Thus, the Euler transform applied to the hypergeometric series gives some of the classic, well-known hypergeometric series identities.  Definition  Given a sequence      S  =    {   s  n   }    n  ‚àà  ùí©        S   subscript    subscript  s  n      n  ùí©      S=\{s_{n}\}_{n\in\mathcal{N}}     having a limit         lim   n  ‚Üí  ‚àû     s  n    =  ‚Ñì   ,        subscript    normal-‚Üí  n      subscript  s  n    normal-‚Ñì    \lim_{n\to\infty}s_{n}=\ell,     an accelerated series is a second sequence       S  ‚Ä≤   =    {   s  n  ‚Ä≤   }    n  ‚àà  ùí©         superscript  S  normal-‚Ä≤    subscript    subscript   superscript  s  normal-‚Ä≤   n      n  ùí©      S^{\prime}=\{s^{\prime}_{n}\}_{n\in\mathcal{N}}     which converges faster to   ‚Ñì   normal-‚Ñì   \ell   than the original sequence, in the sense that        lim   n  ‚Üí  ‚àû       s  n  ‚Ä≤   -  ‚Ñì     s  n   -  ‚Ñì     =  0.        subscript    normal-‚Üí  n          subscript   superscript  s  normal-‚Ä≤   n   normal-‚Ñì      subscript  s  n   normal-‚Ñì     0.    \lim_{n\to\infty}\frac{s^{\prime}_{n}-\ell}{s_{n}-\ell}=0.     If the original sequence is divergent , the sequence transformation acts as an extrapolation method to the antilimit    ‚Ñì   normal-‚Ñì   \ell   .  The mappings from the original to the transformed series may be linear (as defined in the article sequence transformations ), or non-linear. In general, the non-linear sequence transformations tend to be more powerful.  Overview  Two classical techniques for series acceleration are Euler's transformation of series 1 and Kummer's transformation of series . 2 A variety of much more rapidly convergent and special-case tools have been developed in the 20th century, including Richardson extrapolation , introduced by Lewis Fry Richardson in the early 20th century but also known and used by Katahiro Takebe in 1722, the Aitken delta-squared process , introduced by Alexander Aitken in 1926 but also known and used by Takakazu Seki in the 18th century, the epsilon algorithm given by Peter Wynn in 1956, the Levin u-transform , and the Wilf-Zeilberger-Ekhad method or WZ method .  For alternating series, several powerful techniques, offering convergence rates from    5.828   -  n      superscript  5.828    n     5.828^{-n}   all the way to    17.93   -  n      superscript  17.93    n     17.93^{-n}   for a summation of   n   n   n   terms, are described by Cohen et al. . 3  Euler's transform  A basic example of a linear sequence transformation , offering improved convergence, is Euler's transform. It is intended to be applied to an alternating series; it is given by        ‚àë   n  =  0   ‚àû      (   -  1   )   n    a  n     =    ‚àë   n  =  0   ‚àû      (   -  1   )   n      Œî  n    a  0     2   n  +  1             superscript   subscript     n  0         superscript    1   n    subscript  a  n       superscript   subscript     n  0         superscript    1   n        superscript  normal-Œî  n    subscript  a  0     superscript  2    n  1         \sum_{n=0}^{\infty}(-1)^{n}a_{n}=\sum_{n=0}^{\infty}(-1)^{n}\frac{\Delta^{n}a_%
 {0}}{2^{n+1}}     where   Œî   normal-Œî   \Delta   is the forward difference operator :         Œî  n    a  0    =    ‚àë   k  =  0   n      (   -  1   )   k    (     n      k     )    a   n  -  k       .         superscript  normal-Œî  n    subscript  a  0      superscript   subscript     k  0    n      superscript    1   k    binomial  n  k    subscript  a    n  k        \Delta^{n}a_{0}=\sum_{k=0}^{n}(-1)^{k}{n\choose k}a_{n-k}.     If the original series, on the left hand side, is only slowly converging, the forward differences will tend to become small quite rapidly; the additional power of two further improves the rate at which the right hand side converges.  A particularly efficient numerical implementation of the Euler transform is the van Wijngaarden transformation . 4  Conformal mappings  A series   S =     ‚àë   n  =  0   ‚àû    a  n       superscript   subscript     n  0       subscript  a  n     \sum_{n=0}^{\infty}a_{n}      can be written as f(1), where the function f(z) is defined as       f   (  z  )    =    ‚àë   n  =  0   ‚àû     a  n    z  n           f  z     superscript   subscript     n  0         subscript  a  n    superscript  z  n       f(z)=\sum_{n=0}^{\infty}a_{n}z^{n}     The function f(z) can have singularities in the complex plane (branch point singularities, poles or essential singularities), which limit the radius of convergence of the series. If the point z = 1 is close to or on the boundary of the disk of convergence, the series for S will converge very slowly. One can then improve the convergence of the series by means of a conformal mapping that moves the singularities such that the point that is mapped to z = 1, ends up deeper in the new disk of convergence.  The conformal transform    z  =   Œ¶   (  w  )        z    normal-Œ¶  w     z=\Phi(w)   needs to be chosen such that     Œ¶   (  0  )    =  0        normal-Œ¶  0   0    \Phi(0)=0   , and one usually chooses a function that has a finite derivative at w = 0. One can assume that     Œ¶   (  1  )    =  1        normal-Œ¶  1   1    \Phi(1)=1   without loss of generality, as one can always rescale w to redefine   Œ¶   normal-Œ¶   \Phi   . We then consider the function       g   (  w  )    =   f   (   Œ¶   (  w  )    )          g  w     f    normal-Œ¶  w      g(w)=f\left(\Phi(w)\right)     Since     Œ¶   (  1  )    =  1        normal-Œ¶  1   1    \Phi(1)=1   , we have f(1) = g(1). We can obtain the series expansion of g(w) by putting    z  =   Œ¶   (  w  )        z    normal-Œ¶  w     z=\Phi(w)   in the series expansion of f(z) because     Œ¶   (  0  )    =  0        normal-Œ¶  0   0    \Phi(0)=0   ; the first n terms of the series expansion for f(z) will yield the first n terms of the series expansion for g(w) if      Œ¶  ‚Ä≤    (  0  )    ‚â†  0         superscript  normal-Œ¶  normal-‚Ä≤   0   0    \Phi^{\prime}(0)\neq 0   . Putting w = 1 in that series expansion will thus yield a series such that if it converges, it will converge to the same value as the original series.  Non-linear sequence transformations  Examples of such nonlinear sequence transformations are Pad√© approximants , the Shanks transformation , and Levin-type sequence transformations .  Especially nonlinear sequence transformations often provide powerful numerical methods for the summation of divergent series or asymptotic series that arise for instance in perturbation theory , and may be used as highly effective extrapolation methods .  Aitken method    Main article: Aitken's delta-squared process      A simple nonlinear sequence transformation is the Aitken extrapolation or delta-squared method,      ùî∏  :   S  ‚Üí   S  ‚Ä≤   =   ùî∏   (  S  )    =    (   s  n  ‚Ä≤   )    n  ‚àà  ùí©        normal-:  ùî∏     normal-‚Üí  S   superscript  S  normal-‚Ä≤          ùî∏  S         subscript   subscript   superscript  s  normal-‚Ä≤   n     n  ùí©        \mathbb{A}:S\to S^{\prime}=\mathbb{A}(S)={(s^{\prime}_{n})}_{n\in\mathcal{N}}     defined by        s  n  ‚Ä≤   =    s   n  +  2    -     (    s   n  +  2    -   s   n  +  1     )   2      s   n  +  2    -   2   s   n  +  1      +   s  n       .       subscript   superscript  s  normal-‚Ä≤   n      subscript  s    n  2       superscript     subscript  s    n  2     subscript  s    n  1     2        subscript  s    n  2      2   subscript  s    n  1       subscript  s  n        s^{\prime}_{n}=s_{n+2}-\frac{(s_{n+2}-s_{n+1})^{2}}{s_{n+2}-2s_{n+1}+s_{n}}.     This transformation is commonly used to improve the rate of convergence of a slowly converging sequence; heuristically, it eliminates the largest part of the absolute error .  See also   Minimum polynomial extrapolation  Van Wijngaarden transformation   References     C. Brezinski and M. Redivo Zaglia, Extrapolation Methods. Theory and Practice , North-Holland, 1991.  G. A. Baker, Jr. and P. Graves-Morris, Pad√© Approximants , Cambridge U.P., 1996.   Herbert H. H. Homeier, Scalar Levin-Type Sequence Transformations , Journal of Computational and Applied Mathematics, vol. 122, no. 1-2, p 81 (2000). , .   "  Category:Numerical analysis  Category:Asymptotic analysis  Category:Summability methods  Category:Perturbation theory     ‚Ü©  ‚Ü©  Henri Cohen , Fernando Rodriguez Villegas, and Don Zagier , " Convergence Acceleration of Alternating Series ", Experimental Mathematics , 9 :1 (2000) page 3. ‚Ü©  William H. Press, et al. , Numerical Recipes in C , (1987) Cambridge University Press, ISBN 0-521-43108-5 (See section 5.1). ‚Ü©     