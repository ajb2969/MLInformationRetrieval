   Jack function      Jack function   In mathematics , the Jack function , introduced by Henry Jack , is a homogeneous , symmetric  polynomial which generalizes the Schur and zonal polynomials, and is in turn generalized by the Heckman–Opdam polynomials and Macdonald polynomials .  Definition  The Jack function     J  κ   (  α  )     (   x  1   ,   x  2   ,  …  ,   x  m   )        superscript   subscript  J  κ   α     subscript  x  1    subscript  x  2   normal-…   subscript  x  m      J_{\kappa}^{(\alpha)}(x_{1},x_{2},\ldots,x_{m})   of integer partition    κ   κ   \kappa   , parameter   α   α   \alpha   and arguments      x  1   ,   x  2   ,  …   ,      subscript  x  1    subscript  x  2   normal-…    x_{1},x_{2},\ldots,   can be recursively defined as follows:   For m =1 :         J  k   (  α  )     (   x  1   )    =    x  1  k    (   1  +  α   )   ⋯   (   1  +    (   k  -  1   )   α    )           superscript   subscript  J  k   α    subscript  x  1       superscript   subscript  x  1   k     1  α   normal-⋯    1      k  1   α       J_{k}^{(\alpha)}(x_{1})=x_{1}^{k}(1+\alpha)\cdots(1+(k-1)\alpha)      For m >1:          J  κ   (  α  )     (   x  1   ,   x  2   ,  …  ,   x  m   )    =    ∑  μ     J  μ   (  α  )     (   x  1   ,   x  2   ,  …  ,   x   m  -  1    )    x  m   |   κ  /  μ   |     β   κ  μ       ,         superscript   subscript  J  κ   α     subscript  x  1    subscript  x  2   normal-…   subscript  x  m       subscript   μ      superscript   subscript  J  μ   α     subscript  x  1    subscript  x  2   normal-…   subscript  x    m  1      superscript   subscript  x  m       κ  μ      subscript  β    κ  μ        J_{\kappa}^{(\alpha)}(x_{1},x_{2},\ldots,x_{m})=\sum_{\mu}J_{\mu}^{(\alpha)}(x%
 _{1},x_{2},\ldots,x_{m-1})x_{m}^{|\kappa/\mu|}\beta_{\kappa\mu},     where the summation is over all partitions   μ   μ   \mu   such that the skew partition     κ  /  μ      κ  μ    \kappa/\mu   is a horizontal strip , namely       κ  1   ≥   μ  1   ≥   κ  2   ≥   μ  2   ≥  ⋯  ≥   κ   n  -  1    ≥   μ   n  -  1    ≥   κ  n          subscript  κ  1    subscript  μ  1         subscript  κ  2         subscript  μ  2        normal-⋯        subscript  κ    n  1          subscript  μ    n  1          subscript  κ  n      \kappa_{1}\geq\mu_{1}\geq\kappa_{2}\geq\mu_{2}\geq\cdots\geq\kappa_{n-1}\geq%
 \mu_{n-1}\geq\kappa_{n}   (    μ  n     subscript  μ  n    \mu_{n}   must be zero or otherwise      J  μ    (   x  1   ,  …  ,   x   n  -  1    )    =  0         subscript  J  μ     subscript  x  1   normal-…   subscript  x    n  1      0    J_{\mu}(x_{1},\ldots,x_{n-1})=0   ) and        β   κ  μ    =     ∏    (  i  ,  j  )   ∈  κ      B   κ  μ   κ    (  i  ,  j  )       ∏    (  i  ,  j  )   ∈  μ      B   κ  μ   μ    (  i  ,  j  )       ,       subscript  β    κ  μ        subscript  product     i  j   κ       superscript   subscript  B    κ  μ    κ    i  j       subscript  product     i  j   μ       superscript   subscript  B    κ  μ    μ    i  j        \beta_{\kappa\mu}=\frac{\prod_{(i,j)\in\kappa}B_{\kappa\mu}^{\kappa}(i,j)}{%
 \prod_{(i,j)\in\mu}B_{\kappa\mu}^{\mu}(i,j)},     where     B   κ  μ   ν    (  i  ,  j  )        superscript   subscript  B    κ  μ    ν    i  j     B_{\kappa\mu}^{\nu}(i,j)   equals      κ  j  ′   -  i   +   α   (     κ  i   -  j   +  1   )           superscript   subscript  κ  j   normal-′   i     α       subscript  κ  i   j   1      \kappa_{j}^{\prime}-i+\alpha(\kappa_{i}-j+1)   if     κ  j  ′   =   μ  j  ′        superscript   subscript  κ  j   normal-′    superscript   subscript  μ  j   normal-′     \kappa_{j}^{\prime}=\mu_{j}^{\prime}   and      κ  j  ′   -  i   +  1  +   α   (    κ  i   -  j   )           superscript   subscript  κ  j   normal-′   i   1    α     subscript  κ  i   j      \kappa_{j}^{\prime}-i+1+\alpha(\kappa_{i}-j)   otherwise. The expressions    κ  ′     superscript  κ  normal-′    \kappa^{\prime}   and    μ  ′     superscript  μ  normal-′    \mu^{\prime}   refer to the conjugate partitions of   κ   κ   \kappa   and   μ   μ   \mu   , respectively. The notation     (  i  ,  j  )   ∈  κ       i  j   κ    (i,j)\in\kappa   means that the product is taken over all coordinates    (  i  ,  j  )     i  j    (i,j)   of boxes in the Young diagram of the partition   κ   κ   \kappa   .  Combinatorial formula  In 1997, F. Knop and S. Sahi  gave a purely combinatorial formula for the Jack polynomials    J  μ   (  α  )      superscript   subscript  J  μ   α    J_{\mu}^{(\alpha)}   in n variables:       J  μ   (  α  )    =    ∑  T     d  T    (  α  )     ∏   s  ∈  T     x   T   (  s  )             superscript   subscript  J  μ   α     subscript   T      subscript  d  T   α    subscript  product    s  T     subscript  x    T  s         J_{\mu}^{(\alpha)}=\sum_{T}d_{T}(\alpha)\prod_{s\in T}x_{T(s)}   . The sum is taken over all admissible tableaux of shape   λ   λ   \lambda   , and      d  T    (  α  )    =    ∏   s  ∈   T  critical       d  λ    (  α  )    (  s  )            subscript  d  T   α     subscript  product    s    T  critical        subscript  d  λ   α  s      d_{T}(\alpha)=\prod_{s\in T\text{ critical}}d_{\lambda}(\alpha)(s)   with      d  λ    (  α  )    (  s  )    =    α   (     a  λ    (  s  )    +  1   )    +   (     l  λ    (  s  )    +  1   )           subscript  d  λ   α  s       α       subscript  a  λ   s   1         subscript  l  λ   s   1      d_{\lambda}(\alpha)(s)=\alpha(a_{\lambda}(s)+1)+(l_{\lambda}(s)+1)   .  An admissible tableau of shape   λ   λ   \lambda   is a filling of the Young diagram   λ   λ   \lambda   with numbers 1,2,…, n such that for any box ( i , j ) in the tableau,   T ( i , j ) ≠ T ('' i ', j'') whenever i' > i.  T ( i , j ) ≠ T ('' i ', j''-1) whenever j>1 and i' < i.   A box    s  =   (  i  ,  j  )   ∈  λ        s   i  j        λ     s=(i,j)\in\lambda   is critical for the tableau T if j >1 and     T   (  i  ,  j  )    =   T   (  i  ,   j  -  1   )          T   i  j      T   i    j  1       T(i,j)=T(i,j-1)   .  This result can be seen as a special case of the more general combinatorial formula for Macdonald polynomials .  C normalization  The Jack functions form an orthogonal basis in a space of symmetric polynomials, with inner product:      j  κ   =    ∏    (  i  ,  j  )   ∈  κ      (     κ  j  ′   -  i   +   α   (     κ  i   -  j   +  1   )     )    (     κ  j  ′   -  i   +  1  +   α   (    κ  i   -  j   )     )      .       subscript  j  κ     subscript  product     i  j   κ           superscript   subscript  κ  j   normal-′   i     α       subscript  κ  i   j   1          superscript   subscript  κ  j   normal-′   i   1    α     subscript  κ  i   j         j_{\kappa}=\prod_{(i,j)\in\kappa}(\kappa_{j}^{\prime}-i+\alpha(\kappa_{i}-j+1)%
 )(\kappa_{j}^{\prime}-i+1+\alpha(\kappa_{i}-j)).   where      α  =   2  ,    C  κ   (  2  )     (   x  1   ,   x  2   ,  …  ,   x  n   )         α   2     superscript   subscript  C  κ   2     subscript  x  1    subscript  x  2   normal-…   subscript  x  n        \alpha=2,\;C_{\kappa}^{(2)}(x_{1},x_{2},\ldots,x_{n})     For     C  κ    (   x  1   ,   x  2   ,  …  ,   x  n   )        subscript  C  κ     subscript  x  1    subscript  x  2   normal-…   subscript  x  n      C_{\kappa}(x_{1},x_{2},\ldots,x_{n})   denoted often as just     J  λ   =    H  λ  ′    P  λ         subscript  J  λ      subscript   superscript  H  normal-′   λ    subscript  P  λ      J_{\lambda}=H^{\prime}_{\lambda}P_{\lambda}   is known as the Zonal polynomial .  P normalization  The P normalization is given by the identity     H  λ  ′   =    ∏   s  ∈  λ     (    α   a  λ    (  s  )    +    l  λ    (  s  )    +  1   )         subscript   superscript  H  normal-′   λ     subscript  product    s  λ        α   subscript  a  λ   s      subscript  l  λ   s   1      H^{\prime}_{\lambda}=\prod_{s\in\lambda}(\alpha a_{\lambda}(s)+l_{\lambda}(s)+1)   , where    a  λ     subscript  a  λ    a_{\lambda}   and    l  λ     subscript  l  λ    l_{\lambda}   and    α  =  1      α  1    \alpha=1   denotes the arm and leg length respectively. Therefore, for    P  λ     subscript  P  λ    P_{\lambda}   ,    P  λ     subscript  P  λ    P_{\lambda}   is the usual Schur function.  Similar to Schur polynomials,   α   α   \alpha   can be expressed as a sum over Young tableaux. However, one need to add an extra weight to each tableau that depends on the parameter    P  λ     subscript  P  λ    P_{\lambda}   .  Thus, a formula  for the Jack function     P  λ   =    ∑  T     ψ  T    (  α  )     ∏   s  ∈  λ     x   T   (  s  )             subscript  P  λ     subscript   T      subscript  ψ  T   α    subscript  product    s  λ     subscript  x    T  s         P_{\lambda}=\sum_{T}\psi_{T}(\alpha)\prod_{s\in\lambda}x_{T(s)}   is given by     λ   λ   \lambda     where the sum is taken over all tableaux of shape    T   (  s  )       T  s    T(s)   , and     ψ  T    (  α  )        subscript  ψ  T   α    \psi_{T}(\alpha)   denotes the entry in box s of T .  The weight   λ   λ   \lambda   can be defined in the following fashion: Each tableau T of shape    ∅  =   ν  1   →   ν  2   →  …  →   ν  n   =  λ          subscript  ν  1     normal-→     subscript  ν  2     normal-→    normal-…    normal-→     subscript  ν  n        λ     \emptyset=\nu_{1}\to\nu_{2}\to\dots\to\nu_{n}=\lambda   can be interpreted as a sequence of partitions     ν   i  +  1    /   ν  i        subscript  ν    i  1     subscript  ν  i     \nu_{i+1}/\nu_{i}   where      ψ  T    (  α  )    =    ∏  i     ψ    ν   i  +  1    /   ν  i      (  α  )            subscript  ψ  T   α     subscript  product  i      subscript  ψ     subscript  ν    i  1     subscript  ν  i     α      \psi_{T}(\alpha)=\prod_{i}\psi_{\nu_{i+1}/\nu_{i}}(\alpha)   defines the skew shape with content i in T . Then      ψ   λ  /  μ     (  α  )    =    ∏   s  ∈    R   λ  /  μ    -   C   λ  /  μ          (    α   a  μ    (  s  )    +    l  μ    (  s  )    +  1   )    (    α   a  μ    (  s  )    +    l  μ    (  s  )    +  α   )      (    α   a  λ    (  s  )    +    l  λ    (  s  )    +  α   )    (    α   a  λ    (  s  )    +    l  λ    (  s  )    +  1   )             subscript  ψ    λ  μ    α     subscript  product    s     subscript  R    λ  μ     subscript  C    λ  μ               α   subscript  a  μ   s      subscript  l  μ   s   1       α   subscript  a  μ   s      subscript  l  μ   s   α          α   subscript  a  λ   s      subscript  l  λ   s   α       α   subscript  a  λ   s      subscript  l  λ   s   1        \psi_{\lambda/\mu}(\alpha)=\prod_{s\in R_{\lambda/\mu}-C_{\lambda/\mu}}\frac{(%
 \alpha a_{\mu}(s)+l_{\mu}(s)+1)}{(\alpha a_{\mu}(s)+l_{\mu}(s)+\alpha)}\frac{(%
 \alpha a_{\lambda}(s)+l_{\lambda}(s)+\alpha)}{(\alpha a_{\lambda}(s)+l_{%
 \lambda}(s)+1)}   where     λ   λ   \lambda   and the product is taken only over all boxes s in    λ  /  μ      λ  μ    \lambda/\mu   such that s has a box from    α  =  1      α  1    \alpha=1   in the same row, but not in the same column.  Connection with the Schur polynomial  When       J  κ   (  1  )     (   x  1   ,   x  2   ,  …  ,   x  n   )    =    H  κ    s  κ    (   x  1   ,   x  2   ,  …  ,   x  n   )     ,         subscript   superscript  J  1   κ     subscript  x  1    subscript  x  2   normal-…   subscript  x  n        subscript  H  κ    subscript  s  κ     subscript  x  1    subscript  x  2   normal-…   subscript  x  n       J^{(1)}_{\kappa}(x_{1},x_{2},\ldots,x_{n})=H_{\kappa}s_{\kappa}(x_{1},x_{2},%
 \ldots,x_{n}),   the Jack function is a scalar multiple of the Schur polynomial       H  κ   =    ∏    (  i  ,  j  )   ∈  κ      h  κ    (  i  ,  j  )     =    ∏    (  i  ,  j  )   ∈  κ     (      κ  i   +   κ  j  ′    -  i  -  j   +  1   )           subscript  H  κ     subscript  product     i  j   κ       subscript  h  κ    i  j            subscript  product     i  j   κ           subscript  κ  i    superscript   subscript  κ  j   normal-′    i  j   1       H_{\kappa}=\prod_{(i,j)\in\kappa}h_{\kappa}(i,j)=\prod_{(i,j)\in\kappa}(\kappa%
 _{i}+\kappa_{j}^{\prime}-i-j+1)   where     κ   κ   \kappa   is the product of all hook lengths of       J  κ   (  α  )     (   x  1   ,   x  2   ,  …  ,   x  m   )    =  0   ,    if   κ   m  +  1     >  0.      formulae-sequence       superscript   subscript  J  κ   α     subscript  x  1    subscript  x  2   normal-…   subscript  x  m     0       if   subscript  κ    m  1     0.     J_{\kappa}^{(\alpha)}(x_{1},x_{2},\ldots,x_{m})=0,\mbox{ if }\kappa_{m+1}>0.   .  Properties  If the partition has more parts than the number of variables, then the Jack function is 0:     X   X   X     Matrix argument  In some texts, especially in random matrix theory, authors have found it more convenient to use a matrix argument in the Jack function. The connection is simple. If     x  1   ,   x  2   ,  …  ,   x  m       subscript  x  1    subscript  x  2   normal-…   subscript  x  m     x_{1},x_{2},\ldots,x_{m}   is a matrix with eigenvalues       J  κ   (  α  )     (  X  )    =    J  κ   (  α  )     (   x  1   ,   x  2   ,  …  ,   x  m   )     .         superscript   subscript  J  κ   α   X      superscript   subscript  J  κ   α     subscript  x  1    subscript  x  2   normal-…   subscript  x  m       J_{\kappa}^{(\alpha)}(X)=J_{\kappa}^{(\alpha)}(x_{1},x_{2},\ldots,x_{m}).   , then  $$J_\kappa^{(\alpha )}(X)=J_\kappa^{(\alpha )}(x_1,x_2,\ldots,x_m).$$  References    .   .     .   External links   Software for computing the Jack function by Plamen Koev and Alan Edelman.  MOPS: Multivariate Orthogonal Polynomials (symbolically) (Maple Package)  SAGE documentation for Jack Symmetric Functions   "  Category:Orthogonal polynomials  Category:Special functions  Category:Symmetric functions   