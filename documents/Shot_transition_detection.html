<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="544">Shot transition detection</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>Shot transition detection</h1>
<hr/>

<p>'''Shot transition detection ''' (or simply <em>shot detection</em>) also called <strong>cut detection</strong> is a field of research of <a href="video_processing" title="wikilink">video processing</a>. Its subject is the automated detection of transitions between <a href="Shot_(filmmaking)" title="wikilink"><em>shots</em></a> in <a href="digital_video" title="wikilink">digital video</a> with the purpose of temporal segmentation of videos.</p>
<h2 id="use">Use</h2>

<p>Shot transition detection is used to split up a film into basic temporal units called <a href="Shot_(filmmaking)" title="wikilink"><em>shots</em></a>; a <em>shot</em> is a series of interrelated consecutive pictures taken contiguously by a single camera and representing a continuous action in time and space.</p>

<p>This operation is of great use in software for post-production of videos. It is also a fundamental step of automated indexing and content-based video retrieval or summarization applications which provide an efficient access to huge video archives, e.g. an application may choose a representative picture from each scene to create a visual overview of the whole film and, by processing such indexes, a search engine can process search items like "show me all films where there's a scene with a lion in it."</p>

<p>Generally speaking, cut detection can do nothing that a human editor couldn't do manually, but it saves a lot of time. Furthermore, due to the increase in the use of digital video and, consequently, in the importance of the aforementioned indexing applications, the automatic cut detection is very important nowadays.</p>
<h2 id="basic-technical-terms">Basic technical terms</h2>

<p>  In simple terms cut detection is about finding the positions in a video in that one scene is replaced by another one with different visual content. Technically speaking the following terms are used:</p>

<p>A digital video consists of <strong>frames</strong> that are presented to the viewer's eye in rapid succession to create the impression of movement. "Digital" in this context means both that a single frame consists of <a href="pixel" title="wikilink">pixels</a> and the data is present as <a href="binary_data" title="wikilink">binary data</a>, such that it can be processed with a computer. Each frame within a digital video can be uniquely identified by its <strong>frame index</strong>, a serial number.</p>

<p>A <strong>shot</strong> is a sequence of frames shot uninterruptedly by one camera. There are several <a href="film_transition" title="wikilink">film transitions</a> usually used in film editing to juxtapose adjacent shots; In the context of shot transition detection they are usually group into two types:</p>
<ul>
<li><strong>Abrupt Transitions</strong> - This is a sudden transition from one shot to another, i. e. one frame belongs to the first shot, the next frame belongs to the second shot. They are also known as hard cuts or simply cuts.</li>
<li><strong>Gradual Transitions</strong> - In this kind of transitions the two shots are combined using chromatic, spatial or spatial-chromatic effects which gradually replace one shot by another. These are also often known as soft transitions and can be of various types, e.g., <a href="Wipe_(transition)" title="wikilink">wipes</a>, <a href="Dissolve_(filmmaking)" title="wikilink">dissolves</a>, <a href="Fade_(filmmaking)" title="wikilink">fades</a>...</li>
</ul>

<p>"Detecting a cut" means that the position of a cut is gained; more precisely a hard cut is gained as "hard cut between frame i and frame i+1", a soft cut as "soft cut from frame i to frame j".</p>

<p>A transition that is detected correctly is called a <strong>hit</strong>, a cut that is there but was not detected is called a <strong>missed hit</strong> and a position in that the software assumes a cut, but where actually no cut is present, is called a <strong>false hit</strong>.</p>

<p><em>An introduction to film editing and an exhaustive list of shot transition techniques can be found at <a href="film_editing" title="wikilink">film editing</a>.</em></p>
<h2 id="vastness-of-the-problem">Vastness of the problem</h2>

<p>Although cut detection appears to be a simple task for a human being, it is a non-trivial task for computers. Cut detection would be a trivial problem if each frame of a video was enriched with additional information about <em>when</em> and <em>by which camera</em> it was taken. Possibly no algorithm for cut detection will ever be able to detect all cuts with certainty, unless it is provided with powerful artificial intelligence. </p>

<p>While most algorithms achieve good results with hard cuts, many fail with recognizing soft cuts. Hard cuts usually go together with sudden and extensive changes in the visual content while soft cuts feature slow and gradual changes. A human being can compensate this lack of visual diversity with understanding the meaning of a scene. While a computer assumes a black line wiping a shot away to be "just another regular object moving slowly through the on-going scene", a person understands that the scene ends and is replaced by a black screen.</p>
<h2 id="methods">Methods</h2>

<p>Each method for cut detection works on a two-phase-principle:</p>
<ol>
<li><strong>Scoring</strong> - Each pair of consecutive frames of a digital video is given a certain score that represents the similarity/dissimilarity between these two frames.</li>
<li><strong>Decision</strong> - All scores calculated previously are evaluated and a cut is detected if the score is considered high.</li>
</ol>

<p>This principle is error prone. First, because even minor exceedings of the threshold value produce a hit, it must be ensured that phase one scatters values widely to maximize the average difference between the score for "cut" and "no cut". Second, the threshold must be chosen with care; usually useful values can be gained with statistical methods. </p>
<h3 id="scoring">Scoring</h3>

<p>There are many possible scores used to access the differences in the visual content; some of the most common are:</p>
<ul>
<li><strong><a href="Sum_of_absolute_differences" title="wikilink">Sum of absolute differences</a> (SAD).</strong> This is both the most obvious and most simple algorithm of all: The two consecutive frames are compared <a class="uri" href="pixel" title="wikilink">pixel</a> by pixel, summing up the <a href="absolute_value" title="wikilink">absolute values</a> of the differences of each two corresponding pixels. The result is a positive number that is used as the score. SAD reacts very sensitively to even minor changes within a scene: fast movements of the camera, explosions or the simple switching on of a light in a previously dark scene result in false hits. On the other hand, SAD hardly reacts to soft cuts at all. Yet, SAD is used often to produce a basic set of "possible hits" as it detects all visible hard cuts with utmost probability.</li>
<li><strong>Histogram differences (HD).</strong> Histogram differences is very similar to Sum of absolute differences. The difference is that HD computes the difference between the <a href="histogram" title="wikilink">histograms</a> of two consecutive frames; a histogram is a table that contains for each color within a frame the number of pixels that are shaded in that color. HD is not as sensitive to minor changes within a scene as SAD and thus produces less false hits. One major problem of HD is that two images can have exactly the same histograms while the shown content differs extremely, e. g. a picture of the sea and a beach can have the same histogram as one of a corn field and the sky. HD offers no guarantee that it recognizes hard cuts.</li>
<li><strong>Edge change ratio (ECR).</strong> The ECR attempts to compare the actual content of two frames. It transforms both frames to <em>edge pictures</em>, i. e. it extracts the probable outlines of objects within the pictures (see <a href="edge_detection" title="wikilink">edge detection</a> for details). Afterwards it compares these edge pictures using <a href="Dilation_(morphology)" title="wikilink">dilatation</a> to compute a probability that the second frame contains the same objects as the first frame. The ECR is one of the best performing algorithms for scoring. It reacts very sensitively to hard cuts and can detect many soft cuts by nature. In its basic form even ECR cannot detect soft cuts such as <a href="wipe_(transition)" title="wikilink">wipes</a> as it considers the fading-in objects as regular objects moving through the scene. Yet, ECR can be extended manually to recognize special forms of soft cuts.</li>
</ul>

<p>Finally, a combination of two or more of these scores can improve the performance.</p>
<h3 id="decision">Decision</h3>

<p>Also in the decision phase various approaches are usually used:</p>
<ul>
<li><strong>Fixed Threshold</strong> – In this approach, the scores are compared to a threshold which was set previously and if the score is higher than the threshold a cut is declared.</li>
<li><strong>Adaptive Threshold</strong> – In this approach, the scores are compared to a threshold which considers various scores in the video to adapt the threshold to the properties of the current video. Like in the previous case, if the score is higher than the corresponding threshold a cut is declared.</li>
<li><strong><a href="Machine_Learning" title="wikilink">Machine Learning</a></strong> - Machine learning techniques can be applied also to the decision process.</li>
</ul>
<h2 id="cost">Cost</h2>

<p>All of the above algorithms complete in O(n) — that is to say they run in linear time — where <em>n</em> is the number of frames in the input video. The algorithms differ in a constant factor that is determined mostly by the <a href="image_resolution" title="wikilink">image resolution</a> of the video.</p>
<h2 id="measures-for-quality">Measures for quality</h2>

<p>Usually the following three measures are used to measure the quality of a cut detection algorithm:</p>
<ul>
<li><strong><a href="Recall_(information_retrieval)" title="wikilink">Recall</a></strong> is the probability that an existing cut will be detected:</li>
</ul>
<center>

<p>

<math display="inline" id="Shot_transition_detection:0">
 <semantics>
  <mrow>
   <mi>V</mi>
   <mo>=</mo>
   <mfrac>
    <mi>C</mi>
    <mrow>
     <mi>C</mi>
     <mo>+</mo>
     <mi>M</mi>
    </mrow>
   </mfrac>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <ci>V</ci>
    <apply>
     <divide></divide>
     <ci>C</ci>
     <apply>
      <plus></plus>
      <ci>C</ci>
      <ci>M</ci>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   V={C\over C+M}
  </annotation>
 </semantics>
</math>

</p>
</center>
<ul>
<li><strong><a href="Precision_(information_retrieval)" title="wikilink">Precision</a></strong> is the probability that an assumed cut in fact a cut:</li>
</ul>
<center>

<p>

<math display="inline" id="Shot_transition_detection:1">
 <semantics>
  <mrow>
   <mi>P</mi>
   <mo>=</mo>
   <mfrac>
    <mi>C</mi>
    <mrow>
     <mi>C</mi>
     <mo>+</mo>
     <mi>F</mi>
    </mrow>
   </mfrac>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <ci>P</ci>
    <apply>
     <divide></divide>
     <ci>C</ci>
     <apply>
      <plus></plus>
      <ci>C</ci>
      <ci>F</ci>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   P={C\over C+F}
  </annotation>
 </semantics>
</math>

</p>
</center>
<ul>
<li><strong><a href="F1_score" title="wikilink">F1</a></strong> is a combined measure that results in high value if, and only if, both precision <em>and</em> recall result in high values:</li>
</ul>
<center>

<p>

<math display="inline" id="Shot_transition_detection:2">
 <semantics>
  <mrow>
   <mrow>
    <mi>F</mi>
    <mn>1</mn>
   </mrow>
   <mo>=</mo>
   <mfrac>
    <mrow>
     <mn>2</mn>
     <mo>*</mo>
     <mi>P</mi>
     <mo>*</mo>
     <mi>V</mi>
    </mrow>
    <mrow>
     <mi>P</mi>
     <mo>+</mo>
     <mi>V</mi>
    </mrow>
   </mfrac>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <times></times>
     <ci>F</ci>
     <cn type="integer">1</cn>
    </apply>
    <apply>
     <divide></divide>
     <apply>
      <times></times>
      <cn type="integer">2</cn>
      <ci>P</ci>
      <ci>V</ci>
     </apply>
     <apply>
      <plus></plus>
      <ci>P</ci>
      <ci>V</ci>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   F1={2*P*V\over P+V}
  </annotation>
 </semantics>
</math>

</p>
</center>

<p><br/>
The symbols stand for: <strong>C</strong>, the number of correctly detected cuts ("<strong>c</strong>orrect hits"), <strong>M</strong>, the number of not detected cuts ("<strong>m</strong>issed hits") and <strong>F</strong>, the number of falsely detected cuts ("<strong>f</strong>alse hits"). All of these measures are mathematical measures, i. e. they deliver values in between 0 and 1. The basic rule is: the higher the value, the better performs the algorithm.</p>

<p>"</p>

<p><a href="Category:Video_processing" title="wikilink">Category:Video processing</a></p>
</body>
</html>
