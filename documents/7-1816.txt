   Hamilton's principle      Hamilton's principle   In physics , Hamilton's principle is William Rowan Hamilton 's formulation of the principle of stationary action (see that article for historical formulations). It states that the dynamics of a physical system is determined by a variational problem for a functional based on a single function, the Lagrangian , which contains all physical information concerning the system and the forces acting on it. The variational problem is equivalent to and allows for the derivation of the differential  equations of motion of the physical system. Although formulated originally for classical mechanics , Hamilton's principle also applies to classical fields such as the electromagnetic and gravitational  fields , and has even been extended to quantum mechanics , quantum field theory and criticality theories.  (Figure)  "250px"|Illustration of the variation in a generalized coordinate  q between times t 1 and t 2 .   Mathematical formulation  Hamilton's principle states that the true evolution q ( t ) of a system described by N  generalized coordinates  q = ( q 1 , q 2 , ..., q N ) between two specified states q 1 = q ( t 1 ) and q 2 = q ( t 2 ) at two specified times t 1 and t 2 is a stationary point (a point where the variation is zero), of the action  functional       𝒮   [  𝐪  ]      =  def      ∫   t  1    t  2     L   (   𝐪   (  t  )    ,    𝐪  ˙    (  t  )    ,  t  )   d  t        superscript   def     𝒮   delimited-[]  𝐪      superscript   subscript    subscript  t  1     subscript  t  2      L     𝐪  t      normal-˙  𝐪   t   t   d  t      \mathcal{S}[\mathbf{q}]\ \stackrel{\mathrm{def}}{=}\ \int_{t_{1}}^{t_{2}}L(%
 \mathbf{q}(t),\dot{\mathbf{q}}(t),t)\,dt     where    L   (  𝐪  ,   𝐪  ˙   ,  t  )       L   𝐪   normal-˙  𝐪   t     L(\mathbf{q},\dot{\mathbf{q}},t)   is the Lagrangian  function for the system. In other words, any first-order perturbation of the true evolution results in (at most) second-order changes in   𝒮   𝒮   \mathcal{S}   . The action   𝒮   𝒮   \mathcal{S}   is a functional , i.e., something that takes as its input a function and returns a single number, a scalar . In terms of functional analysis , Hamilton's principle states that the true evolution of a physical system is a solution of the functional equation  {\delta \mathbf{q}(t)}=0  |border=2 |border colour = #50C878 |background colour = #ECFCF4}}  Euler–Lagrange equations derived from the action integral  Requiring that the true trajectory q ( t ) be a stationary point of the action functional   𝒮   𝒮   \mathcal{S}   is equivalent to a set of differential equations for q ( t ) (the Euler–Lagrange equations ), which may be derived as follows.  Let q ( t ) represent the true evolution of the system between two specified states q 1 = q ( t 1 ) and q 2 = q ( t 2 ) at two specified times t 1 and t 2 , and let ε ( t ) be a small perturbation that is zero at the endpoints of the trajectory       𝜺   (   t  1   )    =   𝜺   (   t  2   )     =  def   0          𝜺   subscript  t  1      𝜺   subscript  t  2       superscript   def     0     \boldsymbol{\varepsilon}(t_{1})=\boldsymbol{\varepsilon}(t_{2})\ \stackrel{%
 \mathrm{def}}{=}\ 0     To first order in the perturbation ε ( t ), the change in the action functional    δ  𝒮      δ  𝒮    \delta\mathcal{S}   would be       δ  𝒮   =     ∫   t  1    t  2       [    L   (   𝐪  +  𝜺   ,    𝐪  ˙   +   𝜺  ˙    )    -   L   (  𝐪  ,   𝐪  ˙   )     ]   d  t    =     ∫   t  1    t  2       (    𝜺  ⋅    ∂  L    ∂  𝐪     +    𝜺  ˙   ⋅    ∂  L    ∂   𝐪  ˙       )   d  t            δ  𝒮     superscript   subscript    subscript  t  1     subscript  t  2       delimited-[]      L     𝐪  𝜺      normal-˙  𝐪    normal-˙  𝜺        L   𝐪   normal-˙  𝐪       d  t           superscript   subscript    subscript  t  1     subscript  t  2         normal-⋅  𝜺      L     𝐪      normal-⋅   normal-˙  𝜺       L      normal-˙  𝐪       d  t       \delta\mathcal{S}=\int_{t_{1}}^{t_{2}}\;\left[L(\mathbf{q}+\boldsymbol{%
 \varepsilon},\dot{\mathbf{q}}+\dot{\boldsymbol{\varepsilon}})-L(\mathbf{q},%
 \dot{\mathbf{q}})\right]dt=\int_{t_{1}}^{t_{2}}\;\left(\boldsymbol{\varepsilon%
 }\cdot\frac{\partial L}{\partial\mathbf{q}}+\dot{\boldsymbol{\varepsilon}}%
 \cdot\frac{\partial L}{\partial\dot{\mathbf{q}}}\right)\,dt     where we have expanded the Lagrangian  L to first order in the perturbation ε ( t ).  Applying integration by parts to the last term results in       δ  𝒮   =     [   𝜺  ⋅    ∂  L    ∂   𝐪  ˙      ]    t  1    t  2    +     ∫   t  1    t  2       (    𝜺  ⋅    ∂  L    ∂  𝐪     -    𝜺  ⋅   d   d  t       ∂  L    ∂   𝐪  ˙       )   d  t           δ  𝒮      superscript   subscript   delimited-[]   normal-⋅  𝜺      L      normal-˙  𝐪        subscript  t  1     subscript  t  2      superscript   subscript    subscript  t  1     subscript  t  2         normal-⋅  𝜺      L     𝐪        normal-⋅  𝜺    d    d  t         L      normal-˙  𝐪       d  t       \delta\mathcal{S}=\left[\boldsymbol{\varepsilon}\cdot\frac{\partial L}{%
 \partial\dot{\mathbf{q}}}\right]_{t_{1}}^{t_{2}}+\int_{t_{1}}^{t_{2}}\;\left(%
 \boldsymbol{\varepsilon}\cdot\frac{\partial L}{\partial\mathbf{q}}-\boldsymbol%
 {\varepsilon}\cdot\frac{d}{dt}\frac{\partial L}{\partial\dot{\mathbf{q}}}%
 \right)\,dt     The boundary conditions     𝜺   (   t  1   )    =   𝜺   (   t  2   )     =  def   0          𝜺   subscript  t  1      𝜺   subscript  t  2       superscript   def     0     \boldsymbol{\varepsilon}(t_{1})=\boldsymbol{\varepsilon}(t_{2})\ \stackrel{%
 \mathrm{def}}{=}\ 0   causes the first term to vanish       δ  𝒮   =     ∫   t  1    t  2       𝜺  ⋅   (     ∂  L    ∂  𝐪    -    d   d  t      ∂  L    ∂   𝐪  ˙       )    d  t          δ  𝒮     superscript   subscript    subscript  t  1     subscript  t  2       normal-⋅  𝜺        L     𝐪        d    d  t        L      normal-˙  𝐪        d  t      \delta\mathcal{S}=\int_{t_{1}}^{t_{2}}\;\boldsymbol{\varepsilon}\cdot\left(%
 \frac{\partial L}{\partial\mathbf{q}}-\frac{d}{dt}\frac{\partial L}{\partial%
 \dot{\mathbf{q}}}\right)\,dt     Hamilton's principle requires that this first-order change    δ  𝒮      δ  𝒮    \delta\mathcal{S}   is zero for all possible perturbations ε ( t ), i.e., the true path is a stationary point of the action functional   𝒮   𝒮   \mathcal{S}   (either a minimum, maximum or saddle point). This requirement can be satisfied if and only if  - \frac{d}{dt}\frac{\partial L}{\partial \dot{\mathbf{q}}} = 0 |border=2 |border colour = #0073CF |background colour=#F5FFFA}}  These equations are called the Euler–Lagrange equations for the variational problem.  Canonical momenta and constants of motion  The conjugate momentum  p k for a generalized coordinate q k is defined by the equation        p  k      =  def      ∂  L    ∂    q  ˙   k         superscript   def    subscript  p  k       L      subscript   normal-˙  q   k       p_{k}\ \stackrel{\mathrm{def}}{=}\ \frac{\partial L}{\partial\dot{q}_{k}}   .  An important special case of the Euler–Lagrange equation occurs when L does not contain a generalized coordinate q k explicitly,          ∂  L    ∂   q  k     =   0  ⇒        d   d  t      ∂  L    ∂    q  ˙   k      =   0  ⇒       d   p  k     d  t    =   0      ,     formulae-sequence        L      subscript  q  k      0  normal-⇒     formulae-sequence        d    d  t        L      subscript   normal-˙  q   k       0  normal-⇒          d   subscript  p  k      d  t    0      \frac{\partial L}{\partial q_{k}}=0\quad\Rightarrow\quad\frac{d}{dt}\frac{%
 \partial L}{\partial\dot{q}_{k}}=0\quad\Rightarrow\quad\frac{dp_{k}}{dt}=0\,,     that is, the conjugate momentum is a constant of the motion .  In such cases, the coordinate q k is called a cyclic coordinate . For example, if we use polar coordinates t, r, θ to describe the planar motion of a particle, and if L does not depend on θ , the conjugate momentum is the conserved angular momentum.  Example: Free particle in polar coordinates  Trivial examples help to appreciate the use of the action principle via the Euler–Lagrange equations. A free particle (mass m and velocity v ) in Euclidean space moves in a straight line. Using the Euler–Lagrange equations, this can be shown in polar coordinates as follows. In the absence of a potential, the Lagrangian is simply equal to the kinetic energy      L  =    1  2   m   v  2    =    1  2   m   (     x  ˙   2   +    y  ˙   2    )          L      1  2   m   superscript  v  2             1  2   m     superscript   normal-˙  x   2    superscript   normal-˙  y   2        L=\frac{1}{2}mv^{2}=\frac{1}{2}m\left(\dot{x}^{2}+\dot{y}^{2}\right)   in orthonormal ( x , y ) coordinates, where the dot represents differentiation with respect to the curve parameter (usually the time, t ). Therefore, upon application of the Euler–Lagrange equations,          d   d  t     (    ∂  L    ∂   x  ˙     )    -    ∂  L    ∂  x     =   0  ⇒      m   x  ¨    =  0      formulae-sequence          d    d  t        L      normal-˙  x          L     x      0  normal-⇒        m   normal-¨  x    0     \frac{d}{dt}\left(\frac{\partial L}{\partial\dot{x}}\right)-\frac{\partial L}{%
 \partial x}=0\qquad\Rightarrow\qquad m\ddot{x}=0     And likewise for y . Thus the Euler–Lagrange formulation can be used to derive Newton's laws.  In polar coordinates ( r , φ) the kinetic energy and hence the Lagrangian becomes       L  =    1  2   m   (     r  ˙   2   +    r  2     φ  ˙   2     )     .      L      1  2   m     superscript   normal-˙  r   2      superscript  r  2    superscript   normal-˙  φ   2        L=\frac{1}{2}m\left(\dot{r}^{2}+r^{2}\dot{\varphi}^{2}\right).     The radial r and φ components of the Euler–Lagrange equations become, respectively          d   d  t     (    ∂  L    ∂   r  ˙     )    -    ∂  L    ∂  r     =   0  ⇒       r  ¨   -   r    φ  ˙   2     =  0      formulae-sequence          d    d  t        L      normal-˙  r          L     r      0  normal-⇒         normal-¨  r     r   superscript   normal-˙  φ   2     0     \frac{d}{dt}\left(\frac{\partial L}{\partial\dot{r}}\right)-\frac{\partial L}{%
 \partial r}=0\qquad\Rightarrow\qquad\ddot{r}-r\dot{\varphi}^{2}=0             d   d  t     (    ∂  L    ∂   φ  ˙     )    -    ∂  L    ∂  φ     =   0  ⇒       φ  ¨   +    2  r    r  ˙    φ  ˙     =  0.      formulae-sequence          d    d  t        L      normal-˙  φ          L     φ      0  normal-⇒         normal-¨  φ       2  r    normal-˙  r    normal-˙  φ     0.     \frac{d}{dt}\left(\frac{\partial L}{\partial\dot{\varphi}}\right)-\frac{%
 \partial L}{\partial\varphi}=0\qquad\Rightarrow\qquad\ddot{\varphi}+\frac{2}{r%
 }\dot{r}\dot{\varphi}=0.     The solution of these two equations is given by      r  =      (    a  t   +  b   )   2   +   c  2         r       superscript      a  t   b   2    superscript  c  2       r=\sqrt{(at+b)^{2}+c^{2}}         φ  =     tan   -  1     (     a  t   +  b   c   )    +  d       φ      superscript     1          a  t   b   c    d     \varphi=\tan^{-1}\left(\frac{at+b}{c}\right)+d     for a set of constants a, b, c, d determined by initial conditions. Thus, indeed, the solution is a straight line given in polar coordinates: a is the velocity, c is the distance of the closest approach to the origin, and d is the angle of motion.  Hamilton's principle applied to deformable bodies  Hamilton's principle is an important variational principle in elastodynamics . As opposed to a system composed of rigid bodies, deformable bodies have an infinite number of degrees of freedom and occupy continuous regions of space; consequently, the state of the system is described by using continuous functions of space and time. The extended Hamilton Principle for such bodies is given by        ∫   t  1    t  2      [     δ   W  e    +   δ  T    -   δ  U    ]   d  t    =  0        superscript   subscript     t  1      t  2       delimited-[]        δ   subscript  W  e      δ  T      δ  U     d  t    0    \int_{t1}^{t2}\left[\delta W_{e}+\delta T-\delta U\right]dt=0     where T is the kinetic energy, U is the elastic energy, W e is the work done by external loads on the body, and t 1 , t 2 the initial and final times. If the system is conservative, the work done by external forces may be derived from a scalar potential V . In this case,       δ    ∫   t  1    t  2      [   T  -   (   U  +  V   )    ]   d  t     =  0.        δ    superscript   subscript     t  1      t  2       delimited-[]    T    U  V     d  t     0.    \delta\int_{t1}^{t2}\left[T-(U+V)\right]dt=0.     This is called Hamilton's principle and it is invariant under coordinate transformations.  Comparison with Maupertuis' principle  Hamilton's principle and Maupertuis' principle are occasionally confused and both have been called (incorrectly) the principle of least action . They differ in three important ways:   their definition of the action ...    Maupertuis' principle uses an integral over the generalized coordinates known as the abbreviated action        𝒮  0      =  def     ∫    𝐩  ⋅  d   𝐪        superscript   def    subscript  𝒮  0        normal-⋅  𝐩  d   𝐪      \mathcal{S}_{0}\ \stackrel{\mathrm{def}}{=}\ \int\mathbf{p}\cdot d\mathbf{q}      where p = ( p 1 , p 2 , ..., p N ) are the conjugate momenta defined above. By contrast, Hamilton's principle uses   𝒮   𝒮   \mathcal{S}   , the integral of the Lagrangian over time .    the solution that they determine...    Hamilton's principle determines the trajectory q ( t ) as a function of time, whereas Maupertuis' principle determines only the shape of the trajectory in the generalized coordinates. For example, Maupertuis' principle determines the shape of the ellipse on which a particle moves under the influence of an inverse-square central force such as gravity , but does not describe per se how the particle moves along that trajectory. (However, this time parameterization may be determined from the trajectory itself in subsequent calculations using the conservation of energy ). By contrast, Hamilton's principle directly specifies the motion along the ellipse as a function of time.    ...and the constraints on the variation.    Maupertuis' principle requires that the two endpoint states q 1 and q 2 be given and that energy be conserved along every trajectory (same energy for each trajectory). This forces the endpoint times to be varied as well. By contrast, Hamilton's principle does not require the conservation of energy, but does require that the endpoint times t 1 and t 2 be specified as well as the endpoint states q 1 and q 2 .   Action principle for fields  Classical field theory  The action principle can be extended to obtain the equations of motion for fields , such as the electromagnetic field or gravity .  The Einstein equation utilizes the Einstein–Hilbert action as constrained by a variational principle .  The path of a body in a gravitational field (i.e. free fall in space time, a so called geodesic) can be found using the action principle.  Quantum mechanics and quantum field theory  In quantum mechanics , the system does not follow a single path whose action is stationary, but the behavior of the system depends on all imaginable paths and the value of their action. The action corresponding to the various paths is used to calculate the path integral , that gives the probability amplitudes of the various outcomes.  Although equivalent in classical mechanics with Newton's laws , the action principle is better suited for generalizations and plays an important role in modern physics. Indeed, this principle is one of the great generalizations in physical science. In particular, it is fully appreciated and best understood within quantum mechanics . Richard Feynman 's path integral formulation of quantum mechanics is based on a stationary-action principle, using path integrals. Maxwell's equations can be derived as conditions of stationary action.  See also   Analytical mechanics  Configuration space  Hamilton–Jacobi equation  Phase space  Geodesics as Hamiltonian flows   References   W.R. Hamilton, "On a General Method in Dynamics.", Philosophical Transaction of the Royal Society  Part II (1834) pp. 247–308 ; Part I (1835) pp. 95–144 . ( From the collection Sir William Rowan Hamilton (1805–1865): Mathematical Papers edited by David R. Wilkins, School of Mathematics, Trinity College, Dublin 2, Ireland. (2000); also reviewed as On a General Method in Dynamics )    Goldstein H. (1980) Classical Mechanics , 2nd ed., Addison Wesley, pp. 35–69.    Landau LD and Lifshitz EM (1976) Mechanics , 3rd. ed., Pergamon Press. ISBN 0-08-021022-8 (hardcover) and ISBN 0-08-029141-4 (softcover), pp. 2–4.    Arnold VI. (1989) Mathematical Methods of Classical Mechanics , 2nd ed., Springer Verlag, pp. 59–61.    Cassel, Kevin W.: Variational Methods with Applications in Science and Engineering, Cambridge University Press, 2013.   "  Category:Lagrangian mechanics  Category:Calculus of variations  Category:Principles   