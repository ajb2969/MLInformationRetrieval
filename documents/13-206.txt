   Capelli's identity      Capelli's identity   In mathematics , Capelli's identity , named after , is an analogue of the formula det( AB ) = det( A ) det( B ), for certain matrices with noncommuting entries, related to the representation theory of the Lie algebra     𝔤   𝔩  n       𝔤   subscript  𝔩  n     \mathfrak{gl}_{n}   . It can be used to relate an invariant ƒ to the invariant Ω ƒ , where Ω is Cayley's Ω process .  Statement  Suppose that x ij for i , j = 1,..., n are commuting variables. Write E ij for the polarization operator        E   i  j    =    ∑   a  =  1   n     x   i  a     ∂   ∂   x   j  a         .       subscript  E    i  j      superscript   subscript     a  1    n      subscript  x    i  a          subscript  x    j  a          E_{ij}=\sum_{a=1}^{n}x_{ia}\frac{\partial}{\partial x_{ja}}.     The Capelli identity states that the following differential operators, expressed as determinants, are equal:        |        E  11   +  n   -  1     ⋯     E   ;   1  ,   n  -  1         E   1  n        ⋮    ⋱    ⋮    ⋮       E    n  -  1   ,  1      ⋯      E    n  -  1   ,   n  -  1     +  1      E   ;    n  -  1   ,  n          E   n  1      ⋯     E   n  ,   n  -  1         E   n  n    +  0      |   =    |      x  11     ⋯     x   1  n        ⋮    ⋱    ⋮       x   n  1      ⋯     x   n  n       |    |       ∂   ∂   x  11        ⋯      ∂   ∂   x   1  n           ⋮    ⋱    ⋮        ∂   ∂   x   n  1         ⋯      ∂   ∂   x   n  n          |     .               subscript  E  11   n   1   normal-⋯   fragments  E   subscript  normal-;   1    n  1       subscript  E    1  n      normal-⋮  normal-⋱  normal-⋮  normal-⋮     subscript  E     n  1   1    normal-⋯     subscript  E     n  1     n  1     1    fragments  E   subscript  normal-;     n  1   n        subscript  E    n  1    normal-⋯   subscript  E   n    n  1        subscript  E    n  n    0             subscript  x  11   normal-⋯   subscript  x    1  n      normal-⋮  normal-⋱  normal-⋮     subscript  x    n  1    normal-⋯   subscript  x    n  n                 subscript  x  11     normal-⋯        subscript  x    1  n        normal-⋮  normal-⋱  normal-⋮          subscript  x    n  1      normal-⋯        subscript  x    n  n            \begin{vmatrix}E_{11}+n-1&\cdots&E_{1,n-1}&E_{1n}\\
 \vdots&\ddots&\vdots&\vdots\\
 E_{n-1,1}&\cdots&E_{n-1,n-1}+1&E_{n-1,n}\\
 E_{n1}&\cdots&E_{n,n-1}&E_{nn}+0\end{vmatrix}=\begin{vmatrix}x_{11}&\cdots&x_{%
 1n}\\
 \vdots&\ddots&\vdots\\
 x_{n1}&\cdots&x_{nn}\end{vmatrix}\begin{vmatrix}\frac{\partial}{\partial x_{11%
 }}&\cdots&\frac{\partial}{\partial x_{1n}}\\
 \vdots&\ddots&\vdots\\
 \frac{\partial}{\partial x_{n1}}&\cdots&\frac{\partial}{\partial x_{nn}}\end{%
 vmatrix}.     Both sides are differential operators. The determinant on the left has non-commuting entries, and is expanded with all terms preserving their "left to right" order. Such a determinant is often called a column-determinant , since it can be obtained by the column expansion of the determinant starting from the first column. It can be formally written as        det   (  A  )    =    ∑   σ  ∈   S  n       sgn   (  σ  )     A    σ   (  1  )    ,  1     A    σ   (  2  )    ,  2    ⋯   A    σ   (  n  )    ,  n       ,        A     subscript     σ   subscript  S  n        sgn  σ    subscript  A     σ  1   1     subscript  A     σ  2   2    normal-⋯   subscript  A     σ  n   n        \det(A)=\sum_{\sigma\in S_{n}}\operatorname{sgn}(\sigma)A_{\sigma(1),1}A_{%
 \sigma(2),2}\cdots A_{\sigma(n),n},     where in the product first come the elements from the first column, then from the second and so on. The determinant on the far right is Cayley's omega process , and the one on the left is the Capelli determinant.  The operators E ij can be written in a matrix form:       E  =   X   D  t     ,      E    X   superscript  D  t      E=XD^{t},     where    E  ,  X  ,  D     E  X  D    E,X,D   are matrices with elements E ij , x ij ,    ∂   ∂   x   i  j             subscript  x    i  j       \frac{\partial}{\partial x_{ij}}   respectively. If all elements in these matrices would be commutative then clearly     det   (  E  )    =   det    (  X  )    det   (   D  t   )            E       X     superscript  D  t        \det(E)=\det(X)\det(D^{t})   . The Capelli identity shows that despite noncommutativity there exists a "quantization" of the formula above. The only price for the noncommutivity is a small correction     (   n  -  i   )    δ   i  j          n  i    subscript  δ    i  j      (n-i)\delta_{ij}   on the left hand side. For generic noncommutative matrices formulas like       det   (   A  B   )    =   det    (  A  )    det   (  B  )              A  B        A    B       \det(AB)=\det(A)\det(B)   do not exist, and the notion of the 'determinant' itself does not make sense for generic noncommutative matrices. That is why the Capelli identity still holds some mystery, despite many proofs offered for it. A very short proof does not seem to exist. Direct verification of the statement can be given as an exercise for ''n' = 2, but is already long for n = 3.  Relations with representation theory  Consider the following slightly more general context. Suppose that   n   n   n   and   m   m   m   are two integers and    x   i  j      subscript  x    i  j     x_{ij}   for     i  =   1  ,  …  ,  n    ,   j  =   1  ,  …  ,  m       formulae-sequence    i   1  normal-…  n      j   1  normal-…  m      i=1,\dots,n,\ j=1,\dots,m   , be commuting variables. Redefine    E   i  j      subscript  E    i  j     E_{ij}   by almost the same formula:        E   i  j    =    ∑   a  =  1   m     x   i  a     ∂   ∂   x   j  a         .       subscript  E    i  j      superscript   subscript     a  1    m      subscript  x    i  a          subscript  x    j  a          E_{ij}=\sum_{a=1}^{m}x_{ia}\frac{\partial}{\partial x_{ja}}.     with the only difference that summation index   a   a   a   ranges from   1   1   1   to   m   m   m   . One can easily see that such operators satisfy the commutation relations:       [   E   i  j    ,   E   k  l    ]   =   δ   j  k     E   i  l    -   δ   i  l     E   k  j    .     fragments   fragments  normal-[   subscript  E    i  j    normal-,   subscript  E    k  l    normal-]     subscript  δ    j  k     subscript  E    i  l      subscript  δ    i  l     subscript  E    k  j    normal-.  italic-    [E_{ij},E_{kl}]=\delta_{jk}E_{il}-\delta_{il}E_{kj}.~{}~{}~{}~{}~{}~{}~{}~{}~{}     Here    [  a  ,  b  ]     a  b    [a,b]   denotes the commutator      a  b   -   b  a         a  b     b  a     ab-ba   . These are the same commutation relations which are satisfied by the matrices    e   i  j      subscript  e    i  j     e_{ij}   which have zeros everywhere except the position    (  i  ,  j  )     i  j    (i,j)   , where 1 stands. (    e   i  j      subscript  e    i  j     e_{ij}   are sometimes called matrix units ). Hence we conclude that the correspondence    π  :    e   i  j    ↦   E   i  j        normal-:  π   maps-to   subscript  e    i  j     subscript  E    i  j       \pi:e_{ij}\mapsto E_{ij}   defines a representation of the Lie algebra     𝔤   𝔩  n       𝔤   subscript  𝔩  n     \mathfrak{gl}_{n}   in the vector space of polynomials of    x   i  j      subscript  x    i  j     x_{ij}   .  ===Case m = 1 and representation S k C n ===  It is especially instructive to consider the special case m = 1; in this case we have x i1 , which is abbreviated as x i :        E   i  j    =    x  i    ∂   ∂   x  j       .       subscript  E    i  j       subscript  x  i         subscript  x  j        E_{ij}=x_{i}\frac{\partial}{\partial x_{j}}.     In particular, for the polynomials of the first degree it is seen that:       E   i  j     x  k   =   δ   j  k     x  i   .     fragments   subscript  E    i  j     subscript  x  k     subscript  δ    j  k     subscript  x  i   normal-.  italic-    E_{ij}x_{k}=\delta_{jk}x_{i}.~{}~{}~{}~{}~{}~{}~{}~{}~{}~{}~{}~{}~{}~{}     Hence the action of    E   i  j      subscript  E    i  j     E_{ij}   restricted to the space of first-order polynomials is exactly the same as the action of matrix units     e   i  j      subscript  e    i  j     e_{ij}   on vectors in    ℂ  n     superscript  ℂ  n    \mathbb{C}^{n}   . So, from the representation theory point of view, the subspace of polynomials of first degree is a subrepresentation of the Lie algebra    𝔤   𝔩  n       𝔤   subscript  𝔩  n     \mathfrak{gl}_{n}   , which we identified with the standard representation in    ℂ  n     superscript  ℂ  n    \mathbb{C}^{n}   . Going further, it is seen that the differential operators    E   i  j      subscript  E    i  j     E_{ij}   preserve the degree of the polynomials, and hence the polynomials of each fixed degree form a subrepresentation of the Lie algebra    𝔤   𝔩  n       𝔤   subscript  𝔩  n     \mathfrak{gl}_{n}   . One can see further that the space of homogeneous polynomials of degree k can be identified with the symmetric tensor power     S  k    ℂ  n        superscript  S  k    superscript  ℂ  n     S^{k}\mathbb{C}^{n}   of the standard representation    ℂ  n     superscript  ℂ  n    \mathbb{C}^{n}   .  One can also easily identify the highest weight structure of these representations. The monomial    x  1  k     subscript   superscript  x  k   1    x^{k}_{1}   is a highest weight vector , indeed      E   i  j     x  1  k    =  0         subscript  E    i  j     subscript   superscript  x  k   1    0    E_{ij}x^{k}_{1}=0   for i E_{ii} x^k_1= k \delta_{i1}x^k_1.  Such representation is sometimes called bosonic representation of    𝔤   𝔩  n       𝔤   subscript  𝔩  n     \mathfrak{gl}_{n}   . Similar formulas     E   i  j    =    ψ  i    ∂   ∂   ψ  j           subscript  E    i  j       subscript  ψ  i         subscript  ψ  j        E_{ij}=\psi_{i}\frac{\partial}{\partial\psi_{j}}   define the so-called fermionic representation, here    ψ  i     subscript  ψ  i    \psi_{i}   are anti-commuting variables. Again polynomials of k -th degree form an irreducible subrepresentation which is isomorphic to     Λ  k    ℂ  n        superscript  normal-Λ  k    superscript  ℂ  n     \Lambda^{k}\mathbb{C}^{n}   i.e. anti-symmetric tensor power of    ℂ  n     superscript  ℂ  n    \mathbb{C}^{n}   . Highest weight of such representation is (0, ..., 0, 1, 0, ..., 0). These representations for k = 1, ..., n are fundamental representations of    𝔤   𝔩  n       𝔤   subscript  𝔩  n     \mathfrak{gl}_{n}   .  ==== Capelli identity for m = 1 ====  Let us return to the Capelli identity. One can prove the following:        det   (   E  +    (   n  -  i   )    δ   i  j      )    =  0   ,   n  >  1      formulae-sequence        E      n  i    subscript  δ    i  j       0     n  1     \det(E+(n-i)\delta_{ij})=0,\qquad n>1     the motivation for this equality is the following: consider     E   i  j   c   =    x  i    p  j         subscript   superscript  E  c     i  j       subscript  x  i    subscript  p  j      E^{c}_{ij}=x_{i}p_{j}   for some commuting variables     x  i   ,   p  j       subscript  x  i    subscript  p  j     x_{i},p_{j}   . The matrix    E  c     superscript  E  c    E^{c}   is of rank one and hence its determinant is equal to zero. Elements of matrix   E   E   E   are defined by the similar formulas, however, its elements do not commute. The Capelli identity shows that the commutative identity     det   (   E  c   )    =  0         superscript  E  c    0    \det(E^{c})=0   can be preserved for the small price of correcting matrix   E   E   E   by     (   n  -  i   )    δ   i  j          n  i    subscript  δ    i  j      (n-i)\delta_{ij}   .  Let us also mention that similar identity can be given for the characteristic polynomial:        det   (   t  +  E  +    (   n  -  i   )    δ   i  j      )    =    t   [  n  ]    +   Tr   (  E  )    t   [   n  -  1   ]       ,          t  E      n  i    subscript  δ    i  j          superscript  t   delimited-[]  n      Tr  E   superscript  t   delimited-[]    n  1         \det(t+E+(n-i)\delta_{ij})=t^{[n]}+\mathrm{Tr}(E)t^{[n-1]},~{}~{}~{}~{}     where     t   [  k  ]    =   t   (   t  +  1   )   ⋯   (    t  +  k   -  1   )         superscript  t   delimited-[]  k      t    t  1   normal-⋯      t  k   1      t^{[k]}=t(t+1)\cdots(t+k-1)   . The commutative counterpart of this is a simple fact that for rank = 1 matrices the characteristic polynomial contains only the first and the second coefficients.  Let us consider an example for n = 2.       |      t  +   E  11   +  1      E  12        E  21      t  +   E  22       |   =   |      t  +    x  1    ∂  1    +  1       x  1    ∂  2          x  2    ∂  1       t  +    x  2    ∂  2        |             t   subscript  E  11   1    subscript  E  12      subscript  E  21     t   subscript  E  22             t     subscript  x  1    subscript   1    1      subscript  x  1    subscript   2         subscript  x  2    subscript   1      t     subscript  x  2    subscript   2          \displaystyle\begin{vmatrix}t+E_{11}+1&E_{12}\\
 E_{21}&t+E_{22}\end{vmatrix}=\begin{vmatrix}t+x_{1}\partial_{1}+1&x_{1}%
 \partial_{2}\\
 x_{2}\partial_{1}&t+x_{2}\partial_{2}\end{vmatrix}     Using         ∂  1    x  1    =     x  1    ∂  1    +  1    ,      ∂  1    x  2    =    x  2    ∂  1     ,     x  1    x  2    =    x  2     x  1          formulae-sequence      subscript   1    subscript  x  1         subscript  x  1    subscript   1    1     formulae-sequence      subscript   1    subscript  x  2       subscript  x  2    subscript   1          subscript  x  1    subscript  x  2       subscript  x  2    subscript  x  1        \partial_{1}x_{1}=x_{1}\partial_{1}+1,\partial_{1}x_{2}=x_{2}\partial_{1},x_{1%
 }x_{2}=x_{2}x_{1}\,     we see that this is equal to:         t    (   t  +  1   )    +   t   (     x  1    ∂  1    +    x  2    ∂  2     )    +    x  2    x  1     ∂  1    ∂  2     +    x  2    ∂  2     -    x  2    x  1     ∂  1    ∂  2     -    x  2    ∂  2            t    t  1      t       subscript  x  1    subscript   1       subscript  x  2    subscript   2         subscript  x  2    subscript  x  1     subscript   1    subscript   2        subscript  x  2    subscript   2        subscript  x  2    subscript  x  1     subscript   1    subscript   2        subscript  x  2    subscript   2      \displaystyle{}\quad t(t+1)+t(x_{1}\partial_{1}+x_{2}\partial_{2})+x_{2}x_{1}%
 \partial_{1}\partial_{2}+x_{2}\partial_{2}-x_{2}x_{1}\partial_{1}\partial_{2}-%
 x_{2}\partial_{2}     The universal enveloping algebra    U   (   𝔤   𝔩  n    )       U    𝔤   subscript  𝔩  n      U(\mathfrak{gl}_{n})   and its center  An interesting property of the Capelli determinant is that it commutes with all operators E ij , that is the commutator      [   E   i  j    ,   det   (   E  +    (   n  -  i   )    δ   i  j      )    ]   =  0        subscript  E    i  j        E      n  i    subscript  δ    i  j        0    [E_{ij},\det(E+(n-i)\delta_{ij})]=0   is equal to zero. It can be generalized:  Consider any elements E ij in any ring, such that they satisfy the commutation relation     [   E   i  j    ,   E   k  l    ]   =     δ   j  k     E   i  l     -    δ   i  l     E   k  j            subscript  E    i  j     subscript  E    k  l          subscript  δ    j  k     subscript  E    i  l        subscript  δ    i  l     subscript  E    k  j        [E_{ij},E_{kl}]=\delta_{jk}E_{il}-\delta_{il}E_{kj}   , (so they can be differential operators above, matrix units e ij or any other elements) define elements C k as follows:        det   (   t  +  E  +    (   n  -  i   )    δ   i  j      )    =    t   [  n  ]    +    ∑   k  =    n  -  1   ,  …  ,  0       t   [  k  ]     C  k       ,          t  E      n  i    subscript  δ    i  j          superscript  t   delimited-[]  n      subscript     k     n  1   normal-…  0        superscript  t   delimited-[]  k     subscript  C  k        \det(t+E+(n-i)\delta_{ij})=t^{[n]}+\sum_{k=n-1,\dots,0}t^{[k]}C_{k},~{}~{}~{}~%
 {}~{}     where      t   [  k  ]    =   t   (   t  +  1   )   ⋯   (    t  +  k   -  1   )     ,       superscript  t   delimited-[]  k      t    t  1   normal-⋯      t  k   1      t^{[k]}=t(t+1)\cdots(t+k-1),     then:   elements C k commute with all elements E ij    elements C k can be given by the formulas similar to the commutative case:       U   (   𝔤   𝔩  n    )       U    𝔤   subscript  𝔩  n      U(\mathfrak{gl}_{n})   . In particular element C 0 is the Capelli determinant considered above.  These statements are interrelated with the Capelli identity, as will be discussed below, and similarly to it the direct few lines short proof does not seem to exist, despite the simplicity of the formulation.  The universal enveloping algebra       [   E   i  j    ,   E   k  l    ]   =     δ   j  k     E   i  l     -    δ   i  l     E   k  j            subscript  E    i  j     subscript  E    k  l          subscript  δ    j  k     subscript  E    i  l        subscript  δ    i  l     subscript  E    k  j        [E_{ij},E_{kl}]=\delta_{jk}E_{il}-\delta_{il}E_{kj}     can defined as an algebra generated by   E ij    subject to the relations      U   (   𝔤   𝔩  n    )       U    𝔤   subscript  𝔩  n      U(\mathfrak{gl}_{n})     alone. The proposition above shows that elements C k belong to the center of    U   (   𝔤   𝔩  n    )       U    𝔤   subscript  𝔩  n      U(\mathfrak{gl}_{n})   . It can be shown that they actually are free generators of the center of     |      t  +   E  11   +  1      E  12        E  21      t  +   E  22       |           t   subscript  E  11   1    subscript  E  12      subscript  E  21     t   subscript  E  22        \displaystyle{}\quad\begin{vmatrix}t+E_{11}+1&E_{12}\\
 E_{21}&t+E_{22}\end{vmatrix}   . They are sometimes called Capelli generators . The Capelli identities for them will be discussed below.  Consider an example for n = 2.      (    E  11   +   E  22    )       subscript  E  11    subscript  E  22     (E_{11}+E_{22})     It is immediate to check that element    E   i  j      subscript  E    i  j     E_{ij}   commute with    E   i  j      subscript  E    i  j     E_{ij}   . (It corresponds to an obvious fact that the identity matrix commute with all other matrices). More instructive is to check commutativity of the second element with    E  12     subscript  E  12    E_{12}   . Let us do it for    [   E  12   ,      E  11    E  22    -    E  21    E  12     +   E  22    ]      subscript  E  12          subscript  E  11    subscript  E  22       subscript  E  21    subscript  E  12      subscript  E  22      [E_{12},E_{11}E_{22}-E_{21}E_{12}+E_{22}]   :       =       [   E  12   ,   E  11   ]    E  22    +    E  11    [   E  12   ,   E  22   ]     -    [   E  12   ,   E  21   ]    E  12    -    E  21    [   E  12   ,   E  12   ]     +   [   E  12   ,   E  22   ]        absent            subscript  E  12    subscript  E  11     subscript  E  22       subscript  E  11     subscript  E  12    subscript  E  22          subscript  E  12    subscript  E  21     subscript  E  12       subscript  E  21     subscript  E  12    subscript  E  12        subscript  E  12    subscript  E  22       =[E_{12},E_{11}]E_{22}+E_{11}[E_{12},E_{22}]-[E_{12},E_{21}]E_{12}-E_{21}[E_{1%
 2},E_{12}]+[E_{12},E_{22}]          =      -    E  12    E  22     +    E  11    E  12     -    (    E  11   -   E  22    )    E  12    -  0   +   E  12        absent             subscript  E  12    subscript  E  22        subscript  E  11    subscript  E  12          subscript  E  11    subscript  E  22     subscript  E  12    0    subscript  E  12      =-E_{12}E_{22}+E_{11}E_{12}-(E_{11}-E_{22})E_{12}-0+E_{12}          =    -    E  12    E  22     +    E  22    E  12    +   E  12    =    -   E  12    +   E  12    =  0.        absent         subscript  E  12    subscript  E  22        subscript  E  22    subscript  E  12     subscript  E  12              subscript  E  12     subscript  E  12         0.     =-E_{12}E_{22}+E_{22}E_{12}+E_{12}=-E_{12}+E_{12}=0.           E  11    E  22    -    E  21    E  12           subscript  E  11    subscript  E  22       subscript  E  21    subscript  E  12      E_{11}E_{22}-E_{21}E_{12}     We see that the naive determinant    E  12     subscript  E  12    E_{12}   will not commute with    +   E  22        subscript  E  22     +E_{22}   and the Capelli's correction      E   i  j    =    ∑   a  =  1   m     x   i  a     ∂   ∂   x   j  a         ,       subscript  E    i  j      superscript   subscript     a  1    m      subscript  x    i  a          subscript  x    j  a          E_{ij}=\sum_{a=1}^{m}x_{ia}\frac{\partial}{\partial x_{ja}},   is essential to ensure the centrality.  General m and dual pairs  Let us return to the general case:      E  =   X   D  t        E    X   superscript  D  t      E=XD^{t}   for arbitrary n and m . Definition of operators E ij can be written in a matrix form   E   E   E   , where    n  ×  n      n  n    n\times n   is    E   i  j      subscript  E    i  j     E_{ij}   matrix with elements   X   X   X   ;    n  ×  m      n  m    n\times m   is    x   i  j      subscript  x    i  j     x_{ij}   matrix with elements   D   D   D   ;    n  ×  m      n  m    n\times m   is    ∂   ∂   x   i  j             subscript  x    i  j       \frac{\partial}{\partial x_{ij}}   matrix with elements    E  →   (   E  +    (   n  -  i   )    δ   i  j      )      normal-→  E    E      n  i    subscript  δ    i  j        E\rightarrow(E+(n-i)\delta_{ij})   .  Capelli–Cauchy–Binet identities  For general m matrix E is given as product of the two rectangular matrices: X and transpose to D . If all elements of these matrices would commute then one knows that the determinant of E can be expressed by the so-called Cauchy–Binet formula via minors of X and D . An analogue of this formula also exists for matrix E again for the same mild price of the correction      det   (   t  +  E  +    (   n  -  i   )    δ   i  j      )    =    t   [  n  ]    +    ∑   k  =    n  -  1   ,  …  ,  0       t   [  k  ]      ∑   I  ,  J     det    (   X   I  J    )    det   (   D   J  I   t   )           ,          t  E      n  i    subscript  δ    i  j          superscript  t   delimited-[]  n      subscript     k     n  1   normal-…  0        superscript  t   delimited-[]  k      subscript    I  J         subscript  X    I  J       subscript   superscript  D  t     J  I             \det(t+E+(n-i)\delta_{ij})=t^{[n]}+\sum_{k=n-1,\dots,0}t^{[k]}\sum_{I,J}\det(X%
 _{IJ})\det(D^{t}_{JI}),   :      E   i  j      subscript  E    i  j     E_{ij}   ; if m=n we return to the identity above.  Let us also mention that similar to the commutative case (see Cauchy–Binet for minors ), one can express not only the determinant of E , but also its minors via minors of X and D :        E   i  j     x   k  l     =    x   i  l     δ   j  k            subscript  E    i  j     subscript  x    k  l        subscript  x    i  l     subscript  δ    j  k       E_{ij}x_{kl}=x_{il}\delta_{jk}   denotes a submatrix of M formed by the elements M k a l b . Pay attention that the Capelli correction now contains s , not n as in previous formula. Note that for s=1 , the correction ( s − i ) disappears and we get just the definition of E as a product of X and transpose to D . Let us also mention that for generic K,L corresponding minors do not commute with all elements E ij , so the Capelli identity exists not only for central elements.  As a corollary of this formula and the one for the characteristic polynomial in the previous section let us mention the following:       ℂ  n   ⊕  ⋯  ⊕   ℂ  n      direct-sum   superscript  ℂ  n   normal-⋯   superscript  ℂ  n     \mathbb{C}^{n}\oplus\cdots\oplus\mathbb{C}^{n}     where    x   i  l      subscript  x    i  l     x_{il}   at the left hand side and t [n] instead of t n at the right hand side.  Relation to dual pairs  Modern interest in these identities has been much stimulated by Roger Howe who considered them in his theory of reductive dual pairs (also known as Howe duality). To make the first contact with these ideas, let us look more precisely on operators       ℂ  n   ⊕  ⋯  ⊕   ℂ  n    =    ℂ  n   ⊗   ℂ  m     .       direct-sum   superscript  ℂ  n   normal-⋯   superscript  ℂ  n     tensor-product   superscript  ℂ  n    superscript  ℂ  m      \mathbb{C}^{n}\oplus\cdots\oplus\mathbb{C}^{n}=\mathbb{C}^{n}\otimes\mathbb{C}%
 ^{m}.   . Such operators preserve the degree of polynomials. Let us look at the polynomials of degree 1      E   i  j   dual   =    ∑   a  =  1   n     x   a  i     ∂   ∂   x   a  j         .       superscript   subscript  E    i  j    dual     superscript   subscript     a  1    n      subscript  x    a  i          subscript  x    a  j          E_{ij}^{\text{dual}}=\sum_{a=1}^{n}x_{ai}\frac{\partial}{\partial x_{aj}}.   , we see that index l is preserved. One can see that from the representation theory point of view polynomials of the first degree can be identified with direct sum of the representations    E   i  j      subscript  E    i  j     E_{ij}   , here l -th subspace ( l=1...m ) is spanned by    i  ↔  j     normal-↔  i  j    i\leftrightarrow j   , i = 1, ..., n . Let us give another look on this vector space:      E   i  j   dual     superscript   subscript  E    i  j    dual    E_{ij}^{\text{dual}}     Such point of view gives the first hint of symmetry between m and n . To deepen this idea let us consider:      𝔤   𝔩  m       𝔤   subscript  𝔩  m     \mathfrak{gl}_{m}     These operators are given by the same formulas as    E   i  j   dual     superscript   subscript  E    i  j    dual    E_{ij}^{\text{dual}}   modula renumeration    E   k  l      subscript  E    k  l     E_{kl}   , hence by the same arguments we can deduce that      G   L  n    ×  G    L  m           G   subscript  L  n    G    subscript  L  m     GL_{n}\times GL_{m}   form a representation of the Lie algebra      ℂ  n   ⊗   ℂ  m      tensor-product   superscript  ℂ  n    superscript  ℂ  m     \mathbb{C}^{n}\otimes\mathbb{C}^{m}   in the vector space of polynomials of x ij . Before going further we can mention the following property: differential operators      𝔤   𝔩  n    ×  𝔤    𝔩  m           𝔤   subscript  𝔩  n    𝔤    subscript  𝔩  m     \mathfrak{gl}_{n}\times\mathfrak{gl}_{m}   commute with differential operators     E   i  j       subscript  E    i  j     E_{ij}~{}~{}~{}~{}   .  The Lie group    E   i  j   dual     superscript   subscript  E    i  j    dual    E_{ij}^{\text{dual}}   acts on the vector space     E   i  j       subscript  E    i  j     E_{ij}~{}~{}~{}~{}   in a natural way. One can show that the corresponding action of Lie algebra    E   i  j   dual     superscript   subscript  E    i  j    dual    E_{ij}^{\text{dual}}   is given by the differential operators    G   L  n       G   subscript  L  n     GL_{n}   and    G   L  m       G   subscript  L  m     GL_{m}   respectively. This explains the commutativity of these operators.  The following deeper properties actually hold true:   The only differential operators which commute with      ℂ   [   x   i  j    ]    =   S   (    ℂ  n   ⊗   ℂ  m    )    =    ∑  D     ρ  n  D   ⊗   ρ  m   D  ′       .          ℂ   delimited-[]   subscript  x    i  j        S   tensor-product   superscript  ℂ  n    superscript  ℂ  m            subscript   D    tensor-product   superscript   subscript  ρ  n   D    superscript   subscript  ρ  m    superscript  D  normal-′         \mathbb{C}[x_{ij}]=S(\mathbb{C}^{n}\otimes\mathbb{C}^{m})=\sum_{D}\rho_{n}^{D}%
 \otimes\rho_{m}^{D^{\prime}}.   are polynomials in    ρ  D     superscript  ρ  D    \rho^{D}   , and vice versa.    Decomposition of the vector space of polynomials into a direct sum of tensor products of irreducible representations of   D   D   {D}   and    D  ′     superscript  D  normal-′    {D^{\prime}}   can be given as follows:         G   L  n    ×  G    L  m           G   subscript  L  n    G    subscript  L  m     GL_{n}\times GL_{m}     The summands are indexed by the Young diagrams  D , and representations    𝔤   𝔩  n       𝔤   subscript  𝔩  n     \mathfrak{gl}_{n}   are mutually non-isomorphic. And diagram     X  =   |      x  11      x  12      x  13     ⋯     x   1  n         x  12      x  22      x  23     ⋯     x   2  n         x  13      x  23      x  33     ⋯     x   3  n        ⋮    ⋮    ⋮    ⋱    ⋮       x   1  n       x   2  n       x   3  n      ⋯     x   n  n       |    ,   D  =   |      2    ∂   ∂   x  11           ∂   ∂   x  12          ∂   ∂   x  13        ⋯      ∂   ∂   x   1  n             ∂   ∂   x  12         2    ∂   ∂   x  22           ∂   ∂   x  23        ⋯      ∂   ∂   x   2  n             ∂   ∂   x  13          ∂   ∂   x  23         2    ∂   ∂   x  33         ⋯      ∂   ∂   x   3  n           ⋮    ⋮    ⋮    ⋱    ⋮        ∂   ∂   x   1  n           ∂   ∂   x   2  n           ∂   ∂   x   3  n         ⋯     2    ∂   ∂   x   n  n           |       formulae-sequence    X       subscript  x  11    subscript  x  12    subscript  x  13   normal-⋯   subscript  x    1  n       subscript  x  12    subscript  x  22    subscript  x  23   normal-⋯   subscript  x    2  n       subscript  x  13    subscript  x  23    subscript  x  33   normal-⋯   subscript  x    3  n      normal-⋮  normal-⋮  normal-⋮  normal-⋱  normal-⋮     subscript  x    1  n     subscript  x    2  n     subscript  x    3  n    normal-⋯   subscript  x    n  n          D        2        subscript  x  11            subscript  x  12           subscript  x  13     normal-⋯        subscript  x    1  n              subscript  x  12       2        subscript  x  22            subscript  x  23     normal-⋯        subscript  x    2  n              subscript  x  13           subscript  x  23       2        subscript  x  33      normal-⋯        subscript  x    3  n        normal-⋮  normal-⋮  normal-⋮  normal-⋱  normal-⋮          subscript  x    1  n            subscript  x    2  n            subscript  x    3  n      normal-⋯    2        subscript  x    n  n             X=\begin{vmatrix}x_{11}&x_{12}&x_{13}&\cdots&x_{1n}\\
 x_{12}&x_{22}&x_{23}&\cdots&x_{2n}\\
 x_{13}&x_{23}&x_{33}&\cdots&x_{3n}\\
 \vdots&\vdots&\vdots&\ddots&\vdots\\
 x_{1n}&x_{2n}&x_{3n}&\cdots&x_{nn}\end{vmatrix},D=\begin{vmatrix}2\frac{%
 \partial}{\partial x_{11}}&\frac{\partial}{\partial x_{12}}&\frac{\partial}{%
 \partial x_{13}}&\cdots&\frac{\partial}{\partial x_{1n}}\\
 \frac{\partial}{\partial x_{12}}&2\frac{\partial}{\partial x_{22}}&\frac{%
 \partial}{\partial x_{23}}&\cdots&\frac{\partial}{\partial x_{2n}}\\
 \frac{\partial}{\partial x_{13}}&\frac{\partial}{\partial x_{23}}&2\frac{%
 \partial}{\partial x_{33}}&\cdots&\frac{\partial}{\partial x_{3n}}\\
 \vdots&\vdots&\vdots&\ddots&\vdots\\
 \frac{\partial}{\partial x_{1n}}&\frac{\partial}{\partial x_{2n}}&\frac{%
 \partial}{\partial x_{3n}}&\cdots&2\frac{\partial}{\partial x_{nn}}\end{vmatrix}   determine     det   (    X  D   +    (   n  -  i   )    δ   i  j      )    =   det    (  X  )    det   (  D  )                X  D       n  i    subscript  δ    i  j           X    D       \det(XD+(n-i)\delta_{ij})=\det(X)\det(D)\,   and vice versa.   In particular the representation of the big group      X  =   |     0     x  12      x  13     ⋯     x   1  n         -   x  12      0     x  23     ⋯     x   2  n         -   x  13       -   x  23      0    ⋯     x   3  n        ⋮    ⋮    ⋮    ⋱    ⋮       -   x   1  n        -   x   2  n        -   x   3  n       ⋯    0     |    ,   D  =   |     0      ∂   ∂   x  12          ∂   ∂   x  13        ⋯      ∂   ∂   x   1  n            -    ∂   ∂   x  12         0      ∂   ∂   x  23        ⋯      ∂   ∂   x   2  n            -    ∂   ∂   x  13          -    ∂   ∂   x  23         0    ⋯      ∂   ∂   x   3  n           ⋮    ⋮    ⋮    ⋱    ⋮       -    ∂   ∂   x   1  n           -    ∂   ∂   x   2  n           -    ∂   ∂   x   3  n          ⋯    0     |     .     formulae-sequence    X      0   subscript  x  12    subscript  x  13   normal-⋯   subscript  x    1  n         subscript  x  12    0   subscript  x  23   normal-⋯   subscript  x    2  n         subscript  x  13       subscript  x  23    0  normal-⋯   subscript  x    3  n      normal-⋮  normal-⋮  normal-⋮  normal-⋱  normal-⋮       subscript  x    1  n        subscript  x    2  n        subscript  x    3  n     normal-⋯  0        D      0        subscript  x  12           subscript  x  13     normal-⋯        subscript  x    1  n                subscript  x  12      0        subscript  x  23     normal-⋯        subscript  x    2  n                subscript  x  13              subscript  x  23      0  normal-⋯        subscript  x    3  n        normal-⋮  normal-⋮  normal-⋮  normal-⋱  normal-⋮            subscript  x    1  n               subscript  x    2  n               subscript  x    3  n       normal-⋯  0        X=\begin{vmatrix}0&x_{12}&x_{13}&\cdots&x_{1n}\\
 -x_{12}&0&x_{23}&\cdots&x_{2n}\\
 -x_{13}&-x_{23}&0&\cdots&x_{3n}\\
 \vdots&\vdots&\vdots&\ddots&\vdots\\
 -x_{1n}&-x_{2n}&-x_{3n}&\cdots&0\end{vmatrix},D=\begin{vmatrix}0&\frac{%
 \partial}{\partial x_{12}}&\frac{\partial}{\partial x_{13}}&\cdots&\frac{%
 \partial}{\partial x_{1n}}\\
 -\frac{\partial}{\partial x_{12}}&0&\frac{\partial}{\partial x_{23}}&\cdots&%
 \frac{\partial}{\partial x_{2n}}\\
 -\frac{\partial}{\partial x_{13}}&-\frac{\partial}{\partial x_{23}}&0&\cdots&%
 \frac{\partial}{\partial x_{3n}}\\
 \vdots&\vdots&\vdots&\ddots&\vdots\\
 -\frac{\partial}{\partial x_{1n}}&-\frac{\partial}{\partial x_{2n}}&-\frac{%
 \partial}{\partial x_{3n}}&\cdots&0\end{vmatrix}.   is multiplicity free, that is each irreducible representation occurs only one time.   One easily observe the strong similarity to Schur–Weyl duality .  Generalizations  Much work have been done on the identity and its generalizations. Approximately two dozens of mathematicians and physicists contributed to the subject, to name a few: R. Howe , B. Kostant 1 2  Fields medalist  A. Okounkov 3 4  A. Sokal , 5  D. Zeilberger . 6  It seems historically the first generalizations were obtained by Herbert Westren Turnbull in 1948, 7 who found the generalization for the case of symmetric matrices (see 8 9 for modern treatments).  The other generalizations can be divided into several patterns. Most of them are based on the Lie algebra point of view. Such generalizations consist of changing Lie algebra      det   (    X  D   +    (   n  -  i   )    δ   i  j      )    =   det    (  X  )    det   (  D  )       .            X  D       n  i    subscript  δ    i  j           X    D       \det(XD+(n-i)\delta_{ij})=\det(X)\det(D).\,   to simple Lie algebras  10 and their super 11 12  (q) , 13 14 and current versions. 15 As well as identity can be generalized for different reductive dual pairs . 16 17 And finally one can consider not only the determinant of the matrix E, but its permanent, 18 trace of its powers and immanants. 19 20 21 22 Let us mention few more papers; 23 24 25  26  27  28  29 still the list of references is incomplete. It has been believed for quite a long time that the identity is intimately related with semi-simple Lie algebras. Surprisingly a new purely algebraic generalization of the identity have been found in 2008 30 by S. Caracciolo, A. Sportiello, A. D. Sokal which has nothing to do with any Lie algebras.  Turnbull's identity for symmetric matrices  Consider symmetric matrices        [   M   i  j    ,   Y   k  l    ]   =   -    δ   j  k     Q   i  l             subscript  M    i  j     subscript  Y    k  l          subscript  δ    j  k     subscript  Q    i  l        [M_{ij},Y_{kl}]=-\delta_{jk}Q_{il}~{}~{}~{}~{}~{}     Herbert Westren Turnbull 31 in 1948 discovered the following identity:      det   (  M  Y  +   Q   diag   (  n  -  1  ,  n  -  2  ,  …  ,  1  ,  0  )   )   =  det   (  M  )   det   (  Y  )   .     fragments    fragments  normal-(  M  Y   Q  diag   fragments  normal-(  n   1  normal-,  n   2  normal-,  normal-…  normal-,  1  normal-,  0  normal-)   normal-)      fragments  normal-(  M  normal-)     fragments  normal-(  Y  normal-)   normal-.  italic-    \det(MY+Q\,\mathrm{diag}(n-1,n-2,\dots,1,0))=\det(M)\det(Y).~{}~{}~{}~{}~{}~{}%
 ~{}     Combinatorial proof can be found in the paper, 32 another proof and amusing generalizations in the paper, 33 see also discussion below.  The Howe–Umeda–Kostant–Sahi identity for antisymmetric matrices  Consider antisymmetric matrices       ∂   ∂   x   i  j      +    f   i  j     (   x  11   ,  …  ,   x   k  l    ,  …  )              subscript  x    i  j         subscript  f    i  j      subscript  x  11   normal-…   subscript  x    k  l    normal-…      \frac{\partial}{\partial x_{ij}}+f_{ij}(x_{11},\dots,x_{kl},\dots)     Then      x   i  j      subscript  x    i  j     x_{ij}     The Caracciolo–Sportiello–Sokal identity for Manin matrices  Consider two matrices M and Y over some associative ring which satisfy the following condition      ∂   i  j      subscript     i  j     \partial_{ij}     for some elements Q il . Or ”in words”: elements in j -th column of M commute with elements in k -th row of Y unless j = k , and in this case commutator of the elements M ik and Y kl depends only on i , l , but does not depend on k .  Assume that M is a Manin matrix (the simplest example is the matrix with commuting elements).  Then for the square matrix case      det   (    ∂   ∂  z    -  A  -   X   1   z  -  B     D  t     )             subscript   z    A    X    1    z  B     superscript  D  t       \det\left(\frac{\partial}{\partial_{z}}-A-X\frac{1}{z-B}D^{t}\right)     Here Q is a matrix with elements Q il , and diag( n − 1, n − 2, ..., 1, 0) means the diagonal matrix with the elements n − 1, n − 2, ..., 1, 0 on the diagonal.  See 34 proposition 1.2' formula (1.15) page 4, our Y is transpose to their B .  Obviously the original Cappeli's identity the particular case of this identity. Moreover from this identity one can see that in the original Capelli's identity one can consider elements       =   det   Put all  x  and  z  on the left, while all derivations on the right   calculate as if all commute       absent   subscript   superscript   calculate as if all commute     Put all  x  and  z  on the left, while all derivations on the right      ={\det}^{\text{calculate as if all commute}}_{\text{Put all }x\text{ and }z%
 \text{ on the left, while all derivations on the right}}     for arbitrary functions f ij and the identity still will be true.  The Mukhin–Tarasov–Varchenko identity and the Gaudin model  Statement  Consider matrices X and D as in Capelli's identity, i.e. with elements    (    ∂   ∂  z    -  A  -   X   1   z  -  B     D  t     )          subscript   z    A    X    1    z  B     superscript  D  t      \left(\frac{\partial}{\partial_{z}}-A-X\frac{1}{z-B}D^{t}\right)   and     L   (  z  )    =   A  +   X   1   z  -  B     D  t           L  z     A    X    1    z  B     superscript  D  t       L(z)=A+X\frac{1}{z-B}D^{t}   at position ( ij ).  Let z be another formal variable (commuting with x ). Let A and B be some matrices which elements are complex numbers.        det   (    ∂   ∂  z    -   L   (  z  )     )    =    ∑   i  =  0   n     H  i    (  z  )     (   ∂   ∂  z    )   i      .              subscript   z      L  z       superscript   subscript     i  0    n      subscript  H  i   z   superscript      subscript   z    i       \det\left(\frac{\partial}{\partial_{z}}-L(z)\right)=\sum_{i=0}^{n}H_{i}(z)%
 \left(\frac{\partial}{\partial_{z}}\right)^{i}.           [    H  i    (  z  )    ,    H  j    (  w  )    ]   =  0   ,          subscript  H  i   z      subscript  H  j   w    0    [H_{i}(z),H_{j}(w)]=0,~{}~{}~{}~{}~{}~{}~{}~{}           perm   (     X  t   D   -    (   n  -  i   )    δ   i  j      )    =    perm   Put all  x  on the left, with all derivations on the right   Calculate as if all commute    (    X  t   D   )     .        perm       superscript  X  t   D       n  i    subscript  δ    i  j          subscript   superscript  perm  Calculate as if all commute     Put all  x  on the left, with all derivations on the right       superscript  X  t   D      \mathrm{perm}(X^{t}D-(n-i)\delta_{ij})=\mathrm{perm}^{\text{Calculate as if %
 all commute}}_{\text{Put all }x\text{ on the left, with all derivations on the%
  right}}(X^{t}D).     Here the first determinant is understood (as always) as column-determinant of a matrix with non-commutative entries. The determinant on the right is calculated as if all the elements commute, and putting all x and z on the left, while derivations on the right. (Such recipe is called a Wick ordering in the quantum mechanics ).  The Gaudin quantum integrable system and Talalaev's theorem  The matrix  $$L(z) =  A  + X \frac{1}{z-B} D^t$$  is a Lax matrix for the Gaudin quantum integrable spin chain system. D. Talalaev solved the long-standing problem of the explicit solution for the full set of the quantum commuting conservation laws for the Gaudin model, discovering the following theorem.  Consider  $$\det\left(\frac{\partial}{\partial_z} - L(z) \right) =\sum_{i=0}^n H_i(z) \left(\frac{\partial}{\partial_z}\right)^i.$$  Then for all i,j,z,w  $$[ H_i(z), H_j(w) ]= 0, ~~~~~~~~$$ i.e. H i ( z ) are generating functions in z for the differential operators in x which all commute. So they provide quantum commuting conservation laws for the Gaudin model.  Permanents, immanants, traces – "higher Capelli identities"  The original Capelli identity is a statement about determinants. Later, analogous identities were found for permanents , immanants and traces. Based on the combinatorial approach paper by S.G. Williamson 35 was one of the first results in this direction.  Turnbull's identity for permanents of antisymmetric matrices  Consider the antisymmetric matrices X and D with elements x ij and corresponding derivations, as in the case of the HUKS identity above.  Then  $$\mathrm{perm}(X^tD -(n-i)\delta_{ij}) = \mathrm{perm}^\text{Calculate as  if all commute}_{\text{Put all }x\text{ on the left, with all derivations on the right}}
 ( X^t D).$$  Let us cite: 36 "...is stated without proof at the end of Turnbull’s paper". The authors themselves follow Turnbull – at the very end of their paper they write:  "Since the proof of this last identity is very similar to the proof of Turnbull’s symmetric analog (with a slight twist), we leave it as an instructive and pleasant exercise for the reader.".  The identity is deeply analyzed in paper . 37  References  Further reading         "  Category:Invariant theory  Category:Mathematical identities  Category:Representation theory of Lie groups  Category:Lie algebras  Category:Determinants     ↩  ↩  ↩  ↩  ↩  ↩  ↩    ↩  ↩  ↩  ↩  ↩  ↩  ↩  ↩  ↩    ↩  ↩  ↩  ↩  ↩  ↩  ↩  ↩  ↩       ↩   ↩     