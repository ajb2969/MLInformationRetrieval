<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="161">Pachinko allocation</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>Pachinko allocation</h1>
<hr/>

<p>In <a href="machine_learning" title="wikilink">machine learning</a> and <a href="natural_language_processing" title="wikilink">natural language processing</a>, the <strong>pachinko allocation model (PAM)</strong> is a <a href="topic_model" title="wikilink">topic model</a>. Topic models are a suite of algorithms to uncover the hidden thematic structure of a collection of documents. <a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a> The algorithm improves upon earlier topic models such as <a href="latent_Dirichlet_allocation" title="wikilink">latent Dirichlet allocation</a> (LDA) by modeling correlations between topics in addition to the word correlations which constitute topics. PAM provides more Ô¨Çexibility and greater expressive power than latent Dirichlet allocation.<a class="footnoteRef" href="#fn2" id="fnref2"><sup>2</sup></a> While first described and implemented in the context of natural language processing, the algorithm may have applications in other fields such as <a class="uri" href="bioinformatics" title="wikilink">bioinformatics</a>. The model is named for <a class="uri" href="pachinko" title="wikilink">pachinko</a> machines‚Äîa game popular in Japan, in which metal balls bounce down around a complex collection of pins until they land in various bins at the bottom.<a class="footnoteRef" href="#fn3" id="fnref3"><sup>3</sup></a></p>
<h2 id="history">History</h2>

<p>Pachinko allocation was first described by Wei Li and <a href="Andrew_McCallum" title="wikilink">Andrew McCallum</a> in 2006.<a class="footnoteRef" href="#fn4" id="fnref4"><sup>4</sup></a> The idea was extended with hierarchical Pachinko allocation by Li, McCallum, and David Mimno in 2007.<a class="footnoteRef" href="#fn5" id="fnref5"><sup>5</sup></a> In 2007, McCallum and his colleagues proposed a nonparametric Bayesian prior for PAM based on a variant of the hierarchical Dirichlet process (HDP).<a class="footnoteRef" href="#fn6" id="fnref6"><sup>6</sup></a> The algorithm has been implemented in the <a href="Mallet_(software_project)" title="wikilink">MALLET</a> software package published by McCallum's group at the <a href="University_of_Massachusetts_Amherst" title="wikilink">University of Massachusetts Amherst</a>.</p>
<h2 id="model">Model</h2>

<p>PAM connects words in V and topics in T with an arbitrary Directed Acyclic Graph (DAG), where topic nodes occupy the interior levels and the leaves are words.</p>

<p>The probability of generating a whole corpus is the product of the probability for every document:</p>

<p>

<math display="inline" id="Pachinko_allocation:0">
 <semantics>
  <mrow>
   <mi>P</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <mi>ùêÉ</mi>
    <mo stretchy="false">|</mo>
    <mi>Œ±</mi>
    <mo stretchy="false">)</mo>
   </mrow>
   <mo>=</mo>
   <msub>
    <mo largeop="true" symmetric="true">‚àè</mo>
    <mi>d</mi>
   </msub>
   <mi>P</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <mi>d</mi>
    <mo stretchy="false">|</mo>
    <mi>Œ±</mi>
    <mo stretchy="false">)</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <cerror>
    <csymbol cd="ambiguous">fragments</csymbol>
    <csymbol cd="unknown">P</csymbol>
    <cerror>
     <csymbol cd="ambiguous">fragments</csymbol>
     <ci>normal-(</ci>
     <csymbol cd="unknown">D</csymbol>
     <ci>normal-|</ci>
     <csymbol cd="unknown">Œ±</csymbol>
     <ci>normal-)</ci>
    </cerror>
    <eq></eq>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <csymbol cd="latexml">product</csymbol>
     <ci>d</ci>
    </apply>
    <csymbol cd="unknown">P</csymbol>
    <cerror>
     <csymbol cd="ambiguous">fragments</csymbol>
     <ci>normal-(</ci>
     <csymbol cd="unknown">d</csymbol>
     <ci>normal-|</ci>
     <csymbol cd="unknown">Œ±</csymbol>
     <ci>normal-)</ci>
    </cerror>
   </cerror>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   P(\mathbf{D}|\alpha)=\prod_{d}P(d|\alpha)
  </annotation>
 </semantics>
</math>

</p>
<h2 id="see-also">See also</h2>
<ul>
<li><a href="Probabilistic_latent_semantic_indexing" title="wikilink">Probabilistic latent semantic indexing</a> (PLSI), an early topic model from Thomas Hofmann in 1999.<a class="footnoteRef" href="#fn7" id="fnref7"><sup>7</sup></a></li>
<li><a href="Latent_Dirichlet_allocation" title="wikilink">Latent Dirichlet allocation</a>, a generalization of PLSI developed by <a href="David_Blei" title="wikilink">David Blei</a>, <a href="Andrew_Ng" title="wikilink">Andrew Ng</a>, and <a href="Michael_I._Jordan" title="wikilink">Michael Jordan</a> in 2002, allowing documents to have a mixture of topics.<a class="footnoteRef" href="#fn8" id="fnref8"><sup>8</sup></a></li>
<li><a href="Mallet_(software_project)" title="wikilink">MALLET</a>, an open-source Java library that implements Pachinko allocation.</li>
</ul>
<h2 id="references">References</h2>
<h2 id="external-links">External links</h2>
<ul>
<li><a href="http://videolectures.net/icml07_mimno_moht/">Mixtures of Hierarchical Topics with Pachinko Allocation</a>, a video recording of David Mimno presenting HPAM in 2007.</li>
</ul>

<p>"</p>

<p><a href="Category:Statistical_natural_language_processing" title="wikilink">Category:Statistical natural language processing</a> <a href="Category:Latent_variable_models" title="wikilink">Category:Latent variable models</a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1"><a href="#fnref1">‚Ü©</a></li>
<li id="fn2"><a href="#fnref2">‚Ü©</a></li>
<li id="fn3"></li>
<li id="fn4"><a href="#fnref4">‚Ü©</a></li>
<li id="fn5"><a href="#fnref5">‚Ü©</a></li>
<li id="fn6"></li>
<li id="fn7"><a href="#fnref7">‚Ü©</a></li>
<li id="fn8"><a href="#fnref8">‚Ü©</a></li>
</ol>
</section>
</body>
</html>
