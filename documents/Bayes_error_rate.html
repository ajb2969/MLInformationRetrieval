<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="124">Bayes error rate</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>Bayes error rate</h1>
<hr/>

<p>In <a href="statistical_classification" title="wikilink">statistical classification</a>, the <strong>Bayes error rate</strong> is the lowest possible error rate for a given class of classifier.<a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a><a class="footnoteRef" href="#fn2" id="fnref2"><sup>2</sup></a></p>

<p>A number of approaches to the estimation of the Bayes error rate exist. One method seeks to obtain analytical bounds which are inherently dependent on distribution parameters, and hence difficult to estimate. Another approach focuses on class densities, while yet another method combines and compares various classifiers.<a class="footnoteRef" href="#fn3" id="fnref3"><sup>3</sup></a></p>

<p>The Bayes error rate finds important use in the study of patterns and <a href="machine_learning" title="wikilink">machine learning</a> techniques.</p>
<h2 id="error-determination">Error determination</h2>

<p>In terms of machine learning and pattern classification, the data set can be discretely divided into 2 or more classes. Each element of the dataset is called an <em>instance</em> and the class it belongs to is called the <em>label</em>. The Bayes error rate of the dataset classifier is the probability of the classifier to incorrectly classify an instance. For a <a href="multiclass_classifier" title="wikilink">multiclass classifier</a>, the Bayes error rate may be calculated as follows:</p>

<p>

<math display="block" id="Bayes_error_rate:0">
 <semantics>
  <mrow>
   <mi>p</mi>
   <mo>=</mo>
   <munder>
    <mo largeop="true" movablelimits="false" symmetric="true">∑</mo>
    <mrow>
     <msub>
      <mi>C</mi>
      <mi>i</mi>
     </msub>
     <mo>≠</mo>
     <msub>
      <mi>C</mi>
      <mtext>max</mtext>
     </msub>
    </mrow>
   </munder>
   <mstyle displaystyle="false">
    <munder>
     <mo largeop="true" movablelimits="false" symmetric="true">∫</mo>
     <mrow>
      <mi>x</mi>
      <mo>∈</mo>
      <msub>
       <mi>H</mi>
       <mi>i</mi>
      </msub>
     </mrow>
    </munder>
   </mstyle>
   <mi>P</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <mi>x</mi>
    <mo stretchy="false">|</mo>
    <msub>
     <mi>C</mi>
     <mi>i</mi>
    </msub>
    <mo stretchy="false">)</mo>
   </mrow>
   <mi>p</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <msub>
     <mi>C</mi>
     <mi>i</mi>
    </msub>
    <mo rspace="4.2pt" stretchy="false">)</mo>
   </mrow>
   <mi>d</mi>
   <mi>x</mi>
   <mo>,</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <cerror>
    <csymbol cd="ambiguous">fragments</csymbol>
    <csymbol cd="unknown">p</csymbol>
    <eq></eq>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <sum></sum>
     <apply>
      <neq></neq>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>C</ci>
       <ci>i</ci>
      </apply>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>C</ci>
       <mtext>max</mtext>
      </apply>
     </apply>
    </apply>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <int></int>
     <apply>
      <in></in>
      <ci>x</ci>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>H</ci>
       <ci>i</ci>
      </apply>
     </apply>
    </apply>
    <csymbol cd="unknown">P</csymbol>
    <cerror>
     <csymbol cd="ambiguous">fragments</csymbol>
     <ci>normal-(</ci>
     <csymbol cd="unknown">x</csymbol>
     <ci>normal-|</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>C</ci>
      <ci>i</ci>
     </apply>
     <ci>normal-)</ci>
    </cerror>
    <csymbol cd="unknown">p</csymbol>
    <cerror>
     <csymbol cd="ambiguous">fragments</csymbol>
     <ci>normal-(</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>C</ci>
      <ci>i</ci>
     </apply>
     <ci>normal-)</ci>
    </cerror>
    <csymbol cd="unknown">d</csymbol>
    <csymbol cd="unknown">x</csymbol>
    <ci>normal-,</ci>
   </cerror>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   p=\sum_{C_{i}\neq C_{\text{max}}}\textstyle\int\limits_{x\in H_{i}}P(x|C_{i})p%
(C_{i})\,dx,
  </annotation>
 </semantics>
</math>

</p>

<p>where <em>x</em> is an instance, <em>C<sub>i</sub></em> is a class into which an instance is classified, <em>H<sub>i</sub></em> is the area/region that a classifier function <em>h</em> classifies as <em>C<sub>i</sub></em>.</p>

<p>A Bayes error is non-zero if the distributions of the instances overlap, i.e. a certain instance <em>x</em> can have more than one label.</p>
<h2 id="see-also">See also</h2>
<ul>
<li><a href="Naive_Bayes_classifier" title="wikilink">Naive Bayes classifier</a></li>
</ul>
<h2 id="references">References</h2>

<p>"</p>

<p><a href="Category:Statistical_classification" title="wikilink">Category:Statistical classification</a> <a href="Category:Bayesian_statistics" title="wikilink">Error rate</a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1">Fukunaga, Keinosuke (1990) <em>Introduction to Statistical Pattern Recognition</em> by ISBN 0122698517 pages 3 and 97<a href="#fnref1">↩</a></li>
<li id="fn2">K. Tumer, K. (1996) "Estimating the Bayes error rate through classifier combining" in <em>Proceedings of the 13th International Conference on Pattern Recognition</em>, Volume 2, 695–699<a href="#fnref2">↩</a></li>
<li id="fn3"></li>
</ol>
</section>
</body>
</html>
