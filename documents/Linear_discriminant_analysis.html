<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="692">Linear discriminant analysis</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>Linear discriminant analysis</h1>
<hr/>

<p><strong>Linear discriminant analysis</strong> (<strong>LDA</strong>) is a generalization of <strong>Fisher's linear discriminant</strong>, a method used in <a class="uri" href="statistics" title="wikilink">statistics</a>, <a href="pattern_recognition" title="wikilink">pattern recognition</a> and <a href="machine_learning" title="wikilink">machine learning</a> to find a <a href="linear_combination" title="wikilink">linear combination</a> of <a href="Features_(pattern_recognition)" title="wikilink">features</a> that characterizes or separates two or more classes of objects or events. The resulting combination may be used as a <a href="linear_classifier" title="wikilink">linear classifier</a>, or, more commonly, for <a href="dimensionality_reduction" title="wikilink">dimensionality reduction</a> before later <a href="statistical_classification" title="wikilink">classification</a>.</p>

<p>LDA is closely related to <a href="analysis_of_variance" title="wikilink">analysis of variance</a> (ANOVA) and <a href="regression_analysis" title="wikilink">regression analysis</a>, which also attempt to express one <a href="dependent_variable" title="wikilink">dependent variable</a> as a linear combination of other features or measurements.<a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a><a class="footnoteRef" href="#fn2" id="fnref2"><sup>2</sup></a> However, ANOVA uses <a href="categorical_variable" title="wikilink">categorical</a> <a href="independent_variables" title="wikilink">independent variables</a> and a <a href="continuous_variable" title="wikilink">continuous</a> <a href="dependent_variable" title="wikilink">dependent variable</a>, whereas discriminant analysis has continuous <a href="independent_variables" title="wikilink">independent variables</a> and a categorical dependent variable (<em>i.e.</em> the class label).<a class="footnoteRef" href="#fn3" id="fnref3"><sup>3</sup></a> <a href="Logistic_regression" title="wikilink">Logistic regression</a> and <a href="probit_regression" title="wikilink">probit regression</a> are more similar to LDA than ANOVA is, as they also explain a categorical variable by the values of continuous independent variables. These other methods are preferable in applications where it is not reasonable to assume that the independent variables are normally distributed, which is a fundamental assumption of the LDA method.</p>

<p>LDA is also closely related to <a href="principal_component_analysis" title="wikilink">principal component analysis</a> (PCA) and <a href="factor_analysis" title="wikilink">factor analysis</a> in that they both look for linear combinations of variables which best explain the data.<a class="footnoteRef" href="#fn4" id="fnref4"><sup>4</sup></a> LDA explicitly attempts to model the difference between the classes of data. PCA on the other hand does not take into account any difference in class, and factor analysis builds the feature combinations based on differences rather than similarities. Discriminant analysis is also different from factor analysis in that it is not an interdependence technique: a distinction between independent variables and dependent variables (also called criterion variables) must be made.</p>

<p>LDA works when the measurements made on independent variables for each observation are continuous quantities. When dealing with categorical independent variables, the equivalent technique is <a href="discriminant_correspondence_analysis" title="wikilink">discriminant correspondence analysis</a>.<a class="footnoteRef" href="#fn5" id="fnref5"><sup>5</sup></a><a class="footnoteRef" href="#fn6" id="fnref6"><sup>6</sup></a></p>
<h2 id="lda-for-two-classes">LDA for two classes</h2>

<p>Consider a set of observations 

<math display="inline" id="Linear_discriminant_analysis:0">
 <semantics>
  <mover accent="true">
   <mi>x</mi>
   <mo stretchy="false">→</mo>
  </mover>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <ci>normal-→</ci>
    <ci>x</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   {\vec{x}}
  </annotation>
 </semantics>
</math>

 (also called features, attributes, variables or measurements) for each sample of an object or event with known class <em>y</em>. This set of samples is called the <a href="training_set" title="wikilink">training set</a>. The classification problem is then to find a good predictor for the class <em>y</em> of any sample of the same distribution (not necessarily from the training set) given only an observation 

<math display="inline" id="Linear_discriminant_analysis:1">
 <semantics>
  <mover accent="true">
   <mi>x</mi>
   <mo stretchy="false">→</mo>
  </mover>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <ci>normal-→</ci>
    <ci>x</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \vec{x}
  </annotation>
 </semantics>
</math>

.<a class="footnoteRef" href="#fn7" id="fnref7"><sup>7</sup></a></p>

<p>LDA approaches the problem by assuming that the conditional <a href="probability_density_function" title="wikilink">probability density functions</a> 

<math display="inline" id="Linear_discriminant_analysis:2">
 <semantics>
  <mrow>
   <mi>p</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <mover accent="true">
     <mi>x</mi>
     <mo stretchy="false">→</mo>
    </mover>
    <mo stretchy="false">|</mo>
    <mi>y</mi>
    <mo>=</mo>
    <mn>0</mn>
    <mo stretchy="false">)</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <cerror>
    <csymbol cd="ambiguous">fragments</csymbol>
    <csymbol cd="unknown">p</csymbol>
    <cerror>
     <csymbol cd="ambiguous">fragments</csymbol>
     <ci>normal-(</ci>
     <apply>
      <ci>normal-→</ci>
      <ci>x</ci>
     </apply>
     <ci>normal-|</ci>
     <csymbol cd="unknown">y</csymbol>
     <eq></eq>
     <cn type="integer">0</cn>
     <ci>normal-)</ci>
    </cerror>
   </cerror>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   p(\vec{x}|y=0)
  </annotation>
 </semantics>
</math>

 and 

<math display="inline" id="Linear_discriminant_analysis:3">
 <semantics>
  <mrow>
   <mi>p</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <mover accent="true">
     <mi>x</mi>
     <mo stretchy="false">→</mo>
    </mover>
    <mo stretchy="false">|</mo>
    <mi>y</mi>
    <mo>=</mo>
    <mn>1</mn>
    <mo stretchy="false">)</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <cerror>
    <csymbol cd="ambiguous">fragments</csymbol>
    <csymbol cd="unknown">p</csymbol>
    <cerror>
     <csymbol cd="ambiguous">fragments</csymbol>
     <ci>normal-(</ci>
     <apply>
      <ci>normal-→</ci>
      <ci>x</ci>
     </apply>
     <ci>normal-|</ci>
     <csymbol cd="unknown">y</csymbol>
     <eq></eq>
     <cn type="integer">1</cn>
     <ci>normal-)</ci>
    </cerror>
   </cerror>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   p(\vec{x}|y=1)
  </annotation>
 </semantics>
</math>


 are both <a href="Multivariate_normal_distribution" title="wikilink">normally distributed</a> with mean and <a class="uri" href="covariance" title="wikilink">covariance</a> parameters 

<math display="inline" id="Linear_discriminant_analysis:4">
 <semantics>
  <mrow>
   <mo>(</mo>
   <msub>
    <mover accent="true">
     <mi>μ</mi>
     <mo stretchy="false">→</mo>
    </mover>
    <mn>0</mn>
   </msub>
   <mo>,</mo>
   <msub>
    <mi mathvariant="normal">Σ</mi>
    <mn>0</mn>
   </msub>
   <mo>)</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <interval closure="open">
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <apply>
      <ci>normal-→</ci>
      <ci>μ</ci>
     </apply>
     <cn type="integer">0</cn>
    </apply>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>normal-Σ</ci>
     <cn type="integer">0</cn>
    </apply>
   </interval>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \left(\vec{\mu}_{0},\Sigma_{0}\right)
  </annotation>
 </semantics>
</math>

 and 

<math display="inline" id="Linear_discriminant_analysis:5">
 <semantics>
  <mrow>
   <mo>(</mo>
   <msub>
    <mover accent="true">
     <mi>μ</mi>
     <mo stretchy="false">→</mo>
    </mover>
    <mn>1</mn>
   </msub>
   <mo>,</mo>
   <msub>
    <mi mathvariant="normal">Σ</mi>
    <mn>1</mn>
   </msub>
   <mo>)</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <interval closure="open">
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <apply>
      <ci>normal-→</ci>
      <ci>μ</ci>
     </apply>
     <cn type="integer">1</cn>
    </apply>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>normal-Σ</ci>
     <cn type="integer">1</cn>
    </apply>
   </interval>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \left(\vec{\mu}_{1},\Sigma_{1}\right)
  </annotation>
 </semantics>
</math>

, respectively. Under this assumption, the Bayes optimal solution is to predict points as being from the second class if the log of the likelihood ratios is below some threshold T, so that;</p>

<p>

<math display="block" id="Linear_discriminant_analysis:6">
 <semantics>
  <mrow>
   <mrow>
    <mrow>
     <mrow>
      <msup>
       <mrow>
        <mo stretchy="false">(</mo>
        <mrow>
         <mover accent="true">
          <mi>x</mi>
          <mo stretchy="false">→</mo>
         </mover>
         <mo>-</mo>
         <msub>
          <mover accent="true">
           <mi>μ</mi>
           <mo stretchy="false">→</mo>
          </mover>
          <mn>0</mn>
         </msub>
        </mrow>
        <mo stretchy="false">)</mo>
       </mrow>
       <mi>T</mi>
      </msup>
      <msubsup>
       <mi mathvariant="normal">Σ</mi>
       <mn>0</mn>
       <mrow>
        <mo>-</mo>
        <mn>1</mn>
       </mrow>
      </msubsup>
      <mrow>
       <mo stretchy="false">(</mo>
       <mrow>
        <mover accent="true">
         <mi>x</mi>
         <mo stretchy="false">→</mo>
        </mover>
        <mo>-</mo>
        <msub>
         <mover accent="true">
          <mi>μ</mi>
          <mo stretchy="false">→</mo>
         </mover>
         <mn>0</mn>
        </msub>
       </mrow>
       <mo stretchy="false">)</mo>
      </mrow>
     </mrow>
     <mo>+</mo>
     <mrow>
      <mi>ln</mi>
      <mrow>
       <mo stretchy="false">|</mo>
       <msub>
        <mi mathvariant="normal">Σ</mi>
        <mn>0</mn>
       </msub>
       <mo stretchy="false">|</mo>
      </mrow>
     </mrow>
    </mrow>
    <mo>-</mo>
    <mrow>
     <msup>
      <mrow>
       <mo stretchy="false">(</mo>
       <mrow>
        <mover accent="true">
         <mi>x</mi>
         <mo stretchy="false">→</mo>
        </mover>
        <mo>-</mo>
        <msub>
         <mover accent="true">
          <mi>μ</mi>
          <mo stretchy="false">→</mo>
         </mover>
         <mn>1</mn>
        </msub>
       </mrow>
       <mo stretchy="false">)</mo>
      </mrow>
      <mi>T</mi>
     </msup>
     <msubsup>
      <mi mathvariant="normal">Σ</mi>
      <mn>1</mn>
      <mrow>
       <mo>-</mo>
       <mn>1</mn>
      </mrow>
     </msubsup>
     <mrow>
      <mo stretchy="false">(</mo>
      <mrow>
       <mover accent="true">
        <mi>x</mi>
        <mo stretchy="false">→</mo>
       </mover>
       <mo>-</mo>
       <msub>
        <mover accent="true">
         <mi>μ</mi>
         <mo stretchy="false">→</mo>
        </mover>
        <mn>1</mn>
       </msub>
      </mrow>
      <mo stretchy="false">)</mo>
     </mrow>
    </mrow>
    <mo>-</mo>
    <mrow>
     <mi>ln</mi>
     <mrow>
      <mo stretchy="false">|</mo>
      <msub>
       <mi mathvariant="normal">Σ</mi>
       <mn>1</mn>
      </msub>
      <mo rspace="7.5pt" stretchy="false">|</mo>
     </mrow>
    </mrow>
   </mrow>
   <mo rspace="7.5pt"><</mo>
   <mi>T</mi>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <lt></lt>
    <apply>
     <minus></minus>
     <apply>
      <plus></plus>
      <apply>
       <times></times>
       <apply>
        <csymbol cd="ambiguous">superscript</csymbol>
        <apply>
         <minus></minus>
         <apply>
          <ci>normal-→</ci>
          <ci>x</ci>
         </apply>
         <apply>
          <csymbol cd="ambiguous">subscript</csymbol>
          <apply>
           <ci>normal-→</ci>
           <ci>μ</ci>
          </apply>
          <cn type="integer">0</cn>
         </apply>
        </apply>
        <ci>T</ci>
       </apply>
       <apply>
        <csymbol cd="ambiguous">superscript</csymbol>
        <apply>
         <csymbol cd="ambiguous">subscript</csymbol>
         <ci>normal-Σ</ci>
         <cn type="integer">0</cn>
        </apply>
        <apply>
         <minus></minus>
         <cn type="integer">1</cn>
        </apply>
       </apply>
       <apply>
        <minus></minus>
        <apply>
         <ci>normal-→</ci>
         <ci>x</ci>
        </apply>
        <apply>
         <csymbol cd="ambiguous">subscript</csymbol>
         <apply>
          <ci>normal-→</ci>
          <ci>μ</ci>
         </apply>
         <cn type="integer">0</cn>
        </apply>
       </apply>
      </apply>
      <apply>
       <ln></ln>
       <apply>
        <abs></abs>
        <apply>
         <csymbol cd="ambiguous">subscript</csymbol>
         <ci>normal-Σ</ci>
         <cn type="integer">0</cn>
        </apply>
       </apply>
      </apply>
     </apply>
     <apply>
      <times></times>
      <apply>
       <csymbol cd="ambiguous">superscript</csymbol>
       <apply>
        <minus></minus>
        <apply>
         <ci>normal-→</ci>
         <ci>x</ci>
        </apply>
        <apply>
         <csymbol cd="ambiguous">subscript</csymbol>
         <apply>
          <ci>normal-→</ci>
          <ci>μ</ci>
         </apply>
         <cn type="integer">1</cn>
        </apply>
       </apply>
       <ci>T</ci>
      </apply>
      <apply>
       <csymbol cd="ambiguous">superscript</csymbol>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <ci>normal-Σ</ci>
        <cn type="integer">1</cn>
       </apply>
       <apply>
        <minus></minus>
        <cn type="integer">1</cn>
       </apply>
      </apply>
      <apply>
       <minus></minus>
       <apply>
        <ci>normal-→</ci>
        <ci>x</ci>
       </apply>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <apply>
         <ci>normal-→</ci>
         <ci>μ</ci>
        </apply>
        <cn type="integer">1</cn>
       </apply>
      </apply>
     </apply>
     <apply>
      <ln></ln>
      <apply>
       <abs></abs>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <ci>normal-Σ</ci>
        <cn type="integer">1</cn>
       </apply>
      </apply>
     </apply>
    </apply>
    <ci>T</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   (\vec{x}-\vec{\mu}_{0})^{T}\Sigma_{0}^{-1}(\vec{x}-\vec{\mu}_{0})+\ln|\Sigma_{%
0}|-(\vec{x}-\vec{\mu}_{1})^{T}\Sigma_{1}^{-1}(\vec{x}-\vec{\mu}_{1})-\ln|%
\Sigma_{1}|\ <\ T
  </annotation>
 </semantics>
</math>

</p>

<p>Without any further assumptions, the resulting classifier is referred to as QDA (<a href="quadratic_classifier" title="wikilink">quadratic discriminant analysis</a>).</p>

<p>LDA instead makes the additional simplifying <a href="homoscedastic" title="wikilink">homoscedasticity</a> assumption (<em>i.e.</em> that the class covariances are identical, so 

<math display="inline" id="Linear_discriminant_analysis:7">
 <semantics>
  <mrow>
   <msub>
    <mi mathvariant="normal">Σ</mi>
    <mn>0</mn>
   </msub>
   <mo>=</mo>
   <msub>
    <mi mathvariant="normal">Σ</mi>
    <mn>1</mn>
   </msub>
   <mo>=</mo>
   <mi mathvariant="normal">Σ</mi>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <and></and>
    <apply>
     <eq></eq>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>normal-Σ</ci>
      <cn type="integer">0</cn>
     </apply>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>normal-Σ</ci>
      <cn type="integer">1</cn>
     </apply>
    </apply>
    <apply>
     <eq></eq>
     <share href="#.cmml">
     </share>
     <ci>normal-Σ</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \Sigma_{0}=\Sigma_{1}=\Sigma
  </annotation>
 </semantics>
</math>

) and that the covariances have full rank. In this case, several terms cancel:</p>

<p>

<math display="block" id="Linear_discriminant_analysis:8">
 <semantics>
  <mrow>
   <mrow>
    <msup>
     <mover accent="true">
      <mi>x</mi>
      <mo stretchy="false">→</mo>
     </mover>
     <mi>T</mi>
    </msup>
    <msubsup>
     <mi mathvariant="normal">Σ</mi>
     <mn>0</mn>
     <mrow>
      <mo>-</mo>
      <mn>1</mn>
     </mrow>
    </msubsup>
    <mover accent="true">
     <mi>x</mi>
     <mo stretchy="false">→</mo>
    </mover>
   </mrow>
   <mo>=</mo>
   <mrow>
    <msup>
     <mover accent="true">
      <mi>x</mi>
      <mo stretchy="false">→</mo>
     </mover>
     <mi>T</mi>
    </msup>
    <msubsup>
     <mi mathvariant="normal">Σ</mi>
     <mn>1</mn>
     <mrow>
      <mo>-</mo>
      <mn>1</mn>
     </mrow>
    </msubsup>
    <mover accent="true">
     <mi>x</mi>
     <mo stretchy="false">→</mo>
    </mover>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <times></times>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <apply>
       <ci>normal-→</ci>
       <ci>x</ci>
      </apply>
      <ci>T</ci>
     </apply>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>normal-Σ</ci>
       <cn type="integer">0</cn>
      </apply>
      <apply>
       <minus></minus>
       <cn type="integer">1</cn>
      </apply>
     </apply>
     <apply>
      <ci>normal-→</ci>
      <ci>x</ci>
     </apply>
    </apply>
    <apply>
     <times></times>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <apply>
       <ci>normal-→</ci>
       <ci>x</ci>
      </apply>
      <ci>T</ci>
     </apply>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>normal-Σ</ci>
       <cn type="integer">1</cn>
      </apply>
      <apply>
       <minus></minus>
       <cn type="integer">1</cn>
      </apply>
     </apply>
     <apply>
      <ci>normal-→</ci>
      <ci>x</ci>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   {\vec{x}}^{T}\Sigma_{0}^{-1}\vec{x}={\vec{x}}^{T}\Sigma_{1}^{-1}\vec{x}
  </annotation>
 </semantics>
</math>

</p>

<p>

<math display="block" id="Linear_discriminant_analysis:9">
 <semantics>
  <mrow>
   <mrow>
    <msup>
     <mover accent="true">
      <mi>x</mi>
      <mo stretchy="false">→</mo>
     </mover>
     <mi>T</mi>
    </msup>
    <mmultiscripts>
     <mi mathvariant="normal">Σ</mi>
     <mi>i</mi>
     <none></none>
     <none></none>
     <mrow>
      <mo>-</mo>
      <mn>1</mn>
     </mrow>
    </mmultiscripts>
    <mover accent="true">
     <msub>
      <mi>μ</mi>
      <mi>i</mi>
     </msub>
     <mo stretchy="false">→</mo>
    </mover>
   </mrow>
   <mo>=</mo>
   <mrow>
    <msup>
     <mover accent="true">
      <msub>
       <mi>μ</mi>
       <mi>i</mi>
      </msub>
      <mo stretchy="false">→</mo>
     </mover>
     <mi>T</mi>
    </msup>
    <mmultiscripts>
     <mi mathvariant="normal">Σ</mi>
     <mi>i</mi>
     <none></none>
     <none></none>
     <mrow>
      <mo>-</mo>
      <mn>1</mn>
     </mrow>
    </mmultiscripts>
    <mover accent="true">
     <mi>x</mi>
     <mo stretchy="false">→</mo>
    </mover>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <times></times>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <apply>
       <ci>normal-→</ci>
       <ci>x</ci>
      </apply>
      <ci>T</ci>
     </apply>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>normal-Σ</ci>
       <ci>i</ci>
      </apply>
      <apply>
       <minus></minus>
       <cn type="integer">1</cn>
      </apply>
     </apply>
     <apply>
      <ci>normal-→</ci>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>μ</ci>
       <ci>i</ci>
      </apply>
     </apply>
    </apply>
    <apply>
     <times></times>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <apply>
       <ci>normal-→</ci>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <ci>μ</ci>
        <ci>i</ci>
       </apply>
      </apply>
      <ci>T</ci>
     </apply>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>normal-Σ</ci>
       <ci>i</ci>
      </apply>
      <apply>
       <minus></minus>
       <cn type="integer">1</cn>
      </apply>
     </apply>
     <apply>
      <ci>normal-→</ci>
      <ci>x</ci>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   {\vec{x}}^{T}{\Sigma_{i}}^{-1}\vec{\mu_{i}}={\vec{\mu_{i}}}^{T}{\Sigma_{i}}^{-%
1}\vec{x}
  </annotation>
 </semantics>
</math>

 because 

<math display="inline" id="Linear_discriminant_analysis:10">
 <semantics>
  <msub>
   <mi mathvariant="normal">Σ</mi>
   <mi>i</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>normal-Σ</ci>
    <ci>i</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \Sigma_{i}
  </annotation>
 </semantics>
</math>

 is <a href="Hermitian_matrix" title="wikilink">Hermitian</a></p>

<p>and the above decision criterion becomes a threshold on the <a href="dot_product" title="wikilink">dot product</a></p>

<p>

<math display="block" id="Linear_discriminant_analysis:11">
 <semantics>
  <mrow>
   <mrow>
    <mover accent="true">
     <mi>w</mi>
     <mo stretchy="false">→</mo>
    </mover>
    <mo>⋅</mo>
    <mover accent="true">
     <mi>x</mi>
     <mo stretchy="false">→</mo>
    </mover>
   </mrow>
   <mo>></mo>
   <mi>c</mi>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <gt></gt>
    <apply>
     <ci>normal-⋅</ci>
     <apply>
      <ci>normal-→</ci>
      <ci>w</ci>
     </apply>
     <apply>
      <ci>normal-→</ci>
      <ci>x</ci>
     </apply>
    </apply>
    <ci>c</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \vec{w}\cdot\vec{x}>c
  </annotation>
 </semantics>
</math>

</p>

<p>for some threshold constant <em>c</em>, w h e r e</p>

<p>

<math display="block" id="Linear_discriminant_analysis:12">
 <semantics>
  <mrow>
   <mover accent="true">
    <mi>w</mi>
    <mo stretchy="false">→</mo>
   </mover>
   <mo>=</mo>
   <mrow>
    <msup>
     <mi mathvariant="normal">Σ</mi>
     <mrow>
      <mo>-</mo>
      <mn>1</mn>
     </mrow>
    </msup>
    <mrow>
     <mo stretchy="false">(</mo>
     <mrow>
      <msub>
       <mover accent="true">
        <mi>μ</mi>
        <mo stretchy="false">→</mo>
       </mover>
       <mn>1</mn>
      </msub>
      <mo>-</mo>
      <msub>
       <mover accent="true">
        <mi>μ</mi>
        <mo stretchy="false">→</mo>
       </mover>
       <mn>0</mn>
      </msub>
     </mrow>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <ci>normal-→</ci>
     <ci>w</ci>
    </apply>
    <apply>
     <times></times>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <ci>normal-Σ</ci>
      <apply>
       <minus></minus>
       <cn type="integer">1</cn>
      </apply>
     </apply>
     <apply>
      <minus></minus>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <apply>
        <ci>normal-→</ci>
        <ci>μ</ci>
       </apply>
       <cn type="integer">1</cn>
      </apply>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <apply>
        <ci>normal-→</ci>
        <ci>μ</ci>
       </apply>
       <cn type="integer">0</cn>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \vec{w}=\Sigma^{-1}(\vec{\mu}_{1}-\vec{\mu}_{0})
  </annotation>
 </semantics>
</math>

</p>

<p>

<math display="block" id="Linear_discriminant_analysis:13">
 <semantics>
  <mrow>
   <mi>c</mi>
   <mo>=</mo>
   <mrow>
    <mfrac>
     <mn>1</mn>
     <mn>2</mn>
    </mfrac>
    <mrow>
     <mo stretchy="false">(</mo>
     <mrow>
      <mrow>
       <mi>T</mi>
       <mo>-</mo>
       <mrow>
        <msup>
         <mover accent="true">
          <msub>
           <mi>μ</mi>
           <mn>0</mn>
          </msub>
          <mo stretchy="false">→</mo>
         </mover>
         <mi>T</mi>
        </msup>
        <msubsup>
         <mi mathvariant="normal">Σ</mi>
         <mn>0</mn>
         <mrow>
          <mo>-</mo>
          <mn>1</mn>
         </mrow>
        </msubsup>
        <mover accent="true">
         <msub>
          <mi>μ</mi>
          <mn>0</mn>
         </msub>
         <mo stretchy="false">→</mo>
        </mover>
       </mrow>
      </mrow>
      <mo>+</mo>
      <mrow>
       <msup>
        <mover accent="true">
         <msub>
          <mi>μ</mi>
          <mn>1</mn>
         </msub>
         <mo stretchy="false">→</mo>
        </mover>
        <mi>T</mi>
       </msup>
       <msubsup>
        <mi mathvariant="normal">Σ</mi>
        <mn>1</mn>
        <mrow>
         <mo>-</mo>
         <mn>1</mn>
        </mrow>
       </msubsup>
       <mover accent="true">
        <msub>
         <mi>μ</mi>
         <mn>1</mn>
        </msub>
        <mo stretchy="false">→</mo>
       </mover>
      </mrow>
     </mrow>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <ci>c</ci>
    <apply>
     <times></times>
     <apply>
      <divide></divide>
      <cn type="integer">1</cn>
      <cn type="integer">2</cn>
     </apply>
     <apply>
      <plus></plus>
      <apply>
       <minus></minus>
       <ci>T</ci>
       <apply>
        <times></times>
        <apply>
         <csymbol cd="ambiguous">superscript</csymbol>
         <apply>
          <ci>normal-→</ci>
          <apply>
           <csymbol cd="ambiguous">subscript</csymbol>
           <ci>μ</ci>
           <cn type="integer">0</cn>
          </apply>
         </apply>
         <ci>T</ci>
        </apply>
        <apply>
         <csymbol cd="ambiguous">superscript</csymbol>
         <apply>
          <csymbol cd="ambiguous">subscript</csymbol>
          <ci>normal-Σ</ci>
          <cn type="integer">0</cn>
         </apply>
         <apply>
          <minus></minus>
          <cn type="integer">1</cn>
         </apply>
        </apply>
        <apply>
         <ci>normal-→</ci>
         <apply>
          <csymbol cd="ambiguous">subscript</csymbol>
          <ci>μ</ci>
          <cn type="integer">0</cn>
         </apply>
        </apply>
       </apply>
      </apply>
      <apply>
       <times></times>
       <apply>
        <csymbol cd="ambiguous">superscript</csymbol>
        <apply>
         <ci>normal-→</ci>
         <apply>
          <csymbol cd="ambiguous">subscript</csymbol>
          <ci>μ</ci>
          <cn type="integer">1</cn>
         </apply>
        </apply>
        <ci>T</ci>
       </apply>
       <apply>
        <csymbol cd="ambiguous">superscript</csymbol>
        <apply>
         <csymbol cd="ambiguous">subscript</csymbol>
         <ci>normal-Σ</ci>
         <cn type="integer">1</cn>
        </apply>
        <apply>
         <minus></minus>
         <cn type="integer">1</cn>
        </apply>
       </apply>
       <apply>
        <ci>normal-→</ci>
        <apply>
         <csymbol cd="ambiguous">subscript</csymbol>
         <ci>μ</ci>
         <cn type="integer">1</cn>
        </apply>
       </apply>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   c=\frac{1}{2}(T-{\vec{\mu_{0}}}^{T}\Sigma_{0}^{-1}{\vec{\mu_{0}}}+{\vec{\mu_{1%
}}}^{T}\Sigma_{1}^{-1}{\vec{\mu_{1}}})
  </annotation>
 </semantics>
</math>

</p>

<p>This means that the criterion of an input 

<math display="inline" id="Linear_discriminant_analysis:14">
 <semantics>
  <mover accent="true">
   <mi>x</mi>
   <mo stretchy="false">→</mo>
  </mover>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <ci>normal-→</ci>
    <ci>x</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \vec{x}
  </annotation>
 </semantics>
</math>

 being in a class <em>y</em> is purely a function of this linear combination of the known observations.</p>

<p>It is often useful to see this conclusion in geometrical terms: the criterion of an input 

<math display="inline" id="Linear_discriminant_analysis:15">
 <semantics>
  <mover accent="true">
   <mi>x</mi>
   <mo stretchy="false">→</mo>
  </mover>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <ci>normal-→</ci>
    <ci>x</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \vec{x}
  </annotation>
 </semantics>
</math>

 being in a class <em>y</em> is purely a function of projection of multidimensional-space point 

<math display="inline" id="Linear_discriminant_analysis:16">
 <semantics>
  <mover accent="true">
   <mi>x</mi>
   <mo stretchy="false">→</mo>
  </mover>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <ci>normal-→</ci>
    <ci>x</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \vec{x}
  </annotation>
 </semantics>
</math>

 onto vector 

<math display="inline" id="Linear_discriminant_analysis:17">
 <semantics>
  <mover accent="true">
   <mi>w</mi>
   <mo stretchy="false">→</mo>
  </mover>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <ci>normal-→</ci>
    <ci>w</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \vec{w}
  </annotation>
 </semantics>
</math>

 (thus, we only consider its direction). In other words, the observation belongs to <em>y</em> if corresponding 

<math display="inline" id="Linear_discriminant_analysis:18">
 <semantics>
  <mover accent="true">
   <mi>x</mi>
   <mo stretchy="false">→</mo>
  </mover>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <ci>normal-→</ci>
    <ci>x</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \vec{x}
  </annotation>
 </semantics>
</math>


 is located on a certain side of a hyperplane perpendicular to 

<math display="inline" id="Linear_discriminant_analysis:19">
 <semantics>
  <mover accent="true">
   <mi>w</mi>
   <mo stretchy="false">→</mo>
  </mover>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <ci>normal-→</ci>
    <ci>w</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \vec{w}
  </annotation>
 </semantics>
</math>

. The location of the plane is defined by the threshold c.</p>
<h2 id="canonical-discriminant-analysis-for-k-classes">Canonical discriminant analysis for <em>k</em> classes</h2>

<p>Canonical discriminant analysis (CDA) finds axes (<em>k</em> - 1 <a href="canonical_coordinates" title="wikilink">canonical coordinates</a>, <em>k</em> being the number of classes) that best separate the categories. These linear functions are uncorrelated and define, in effect, an optimal <em>k</em> − 1 space through the <em>n</em>-dimensional cloud of data that best separates (the projections in that space of) the k groups. See “<a href="#Multiclass_LDA" title="wikilink">Multiclass LDA</a>” for details below.</p>
<h2 id="fishers-linear-discriminant">Fisher's linear discriminant</h2>

<p>The terms <em>Fisher's linear discriminant</em> and <em>LDA</em> are often used interchangeably, although <a href="Ronald_A._Fisher" title="wikilink">Fisher's</a> original article<a class="footnoteRef" href="#fn8" id="fnref8"><sup>8</sup></a> actually describes a slightly different discriminant, which does not make some of the assumptions of LDA such as <a href="normal_distribution" title="wikilink">normally distributed</a> classes or equal class <a href="covariance" title="wikilink">covariances</a>.</p>

<p>Suppose two classes of observations have <a href="mean" title="wikilink">means</a> 

<math display="inline" id="Linear_discriminant_analysis:20">
 <semantics>
  <mrow>
   <msub>
    <mover accent="true">
     <mi>μ</mi>
     <mo stretchy="false">→</mo>
    </mover>
    <mn>0</mn>
   </msub>
   <mo>,</mo>
   <msub>
    <mover accent="true">
     <mi>μ</mi>
     <mo stretchy="false">→</mo>
    </mover>
    <mn>1</mn>
   </msub>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <list>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <apply>
      <ci>normal-→</ci>
      <ci>μ</ci>
     </apply>
     <cn type="integer">0</cn>
    </apply>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <apply>
      <ci>normal-→</ci>
      <ci>μ</ci>
     </apply>
     <cn type="integer">1</cn>
    </apply>
   </list>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \vec{\mu}_{0},\vec{\mu}_{1}
  </annotation>
 </semantics>
</math>

 and covariances 

<math display="inline" id="Linear_discriminant_analysis:21">
 <semantics>
  <mrow>
   <msub>
    <mi mathvariant="normal">Σ</mi>
    <mn>0</mn>
   </msub>
   <mo>,</mo>
   <msub>
    <mi mathvariant="normal">Σ</mi>
    <mn>1</mn>
   </msub>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <list>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>normal-Σ</ci>
     <cn type="integer">0</cn>
    </apply>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>normal-Σ</ci>
     <cn type="integer">1</cn>
    </apply>
   </list>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \Sigma_{0},\Sigma_{1}
  </annotation>
 </semantics>
</math>

. Then the linear combination of features 

<math display="inline" id="Linear_discriminant_analysis:22">
 <semantics>
  <mrow>
   <mover accent="true">
    <mi>w</mi>
    <mo stretchy="false">→</mo>
   </mover>
   <mo>⋅</mo>
   <mover accent="true">
    <mi>x</mi>
    <mo stretchy="false">→</mo>
   </mover>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <ci>normal-⋅</ci>
    <apply>
     <ci>normal-→</ci>
     <ci>w</ci>
    </apply>
    <apply>
     <ci>normal-→</ci>
     <ci>x</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \vec{w}\cdot\vec{x}
  </annotation>
 </semantics>
</math>

 will have <a href="mean" title="wikilink">means</a> 

<math display="inline" id="Linear_discriminant_analysis:23">
 <semantics>
  <mrow>
   <mover accent="true">
    <mi>w</mi>
    <mo stretchy="false">→</mo>
   </mover>
   <mo>⋅</mo>
   <msub>
    <mover accent="true">
     <mi>μ</mi>
     <mo stretchy="false">→</mo>
    </mover>
    <mi>i</mi>
   </msub>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <ci>normal-⋅</ci>
    <apply>
     <ci>normal-→</ci>
     <ci>w</ci>
    </apply>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <apply>
      <ci>normal-→</ci>
      <ci>μ</ci>
     </apply>
     <ci>i</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \vec{w}\cdot\vec{\mu}_{i}
  </annotation>
 </semantics>
</math>


 and <a href="variance" title="wikilink">variances</a> 

<math display="inline" id="Linear_discriminant_analysis:24">
 <semantics>
  <mrow>
   <msup>
    <mover accent="true">
     <mi>w</mi>
     <mo stretchy="false">→</mo>
    </mover>
    <mi>T</mi>
   </msup>
   <msub>
    <mi mathvariant="normal">Σ</mi>
    <mi>i</mi>
   </msub>
   <mover accent="true">
    <mi>w</mi>
    <mo stretchy="false">→</mo>
   </mover>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <apply>
     <csymbol cd="ambiguous">superscript</csymbol>
     <apply>
      <ci>normal-→</ci>
      <ci>w</ci>
     </apply>
     <ci>T</ci>
    </apply>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>normal-Σ</ci>
     <ci>i</ci>
    </apply>
    <apply>
     <ci>normal-→</ci>
     <ci>w</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \vec{w}^{T}\Sigma_{i}\vec{w}
  </annotation>
 </semantics>
</math>

 for 

<math display="inline" id="Linear_discriminant_analysis:25">
 <semantics>
  <mrow>
   <mi>i</mi>
   <mo>=</mo>
   <mrow>
    <mn>0</mn>
    <mo>,</mo>
    <mn>1</mn>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <ci>i</ci>
    <list>
     <cn type="integer">0</cn>
     <cn type="integer">1</cn>
    </list>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   i=0,1
  </annotation>
 </semantics>
</math>

. Fisher defined the separation between these two <a href="probability_distribution" title="wikilink">distributions</a> to be the ratio of the variance between the classes to the variance within the classes:</p>

<p>

<math display="block" id="Linear_discriminant_analysis:26">
 <semantics>
  <mrow>
   <mi>S</mi>
   <mo>=</mo>
   <mfrac>
    <msubsup>
     <mi>σ</mi>
     <mtext>between</mtext>
     <mn>2</mn>
    </msubsup>
    <msubsup>
     <mi>σ</mi>
     <mtext>within</mtext>
     <mn>2</mn>
    </msubsup>
   </mfrac>
   <mo>=</mo>
   <mfrac>
    <msup>
     <mrow>
      <mo stretchy="false">(</mo>
      <mrow>
       <mrow>
        <mover accent="true">
         <mi>w</mi>
         <mo stretchy="false">→</mo>
        </mover>
        <mo>⋅</mo>
        <msub>
         <mover accent="true">
          <mi>μ</mi>
          <mo stretchy="false">→</mo>
         </mover>
         <mn>1</mn>
        </msub>
       </mrow>
       <mo>-</mo>
       <mrow>
        <mover accent="true">
         <mi>w</mi>
         <mo stretchy="false">→</mo>
        </mover>
        <mo>⋅</mo>
        <msub>
         <mover accent="true">
          <mi>μ</mi>
          <mo stretchy="false">→</mo>
         </mover>
         <mn>0</mn>
        </msub>
       </mrow>
      </mrow>
      <mo stretchy="false">)</mo>
     </mrow>
     <mn>2</mn>
    </msup>
    <mrow>
     <mrow>
      <msup>
       <mover accent="true">
        <mi>w</mi>
        <mo stretchy="false">→</mo>
       </mover>
       <mi>T</mi>
      </msup>
      <msub>
       <mi mathvariant="normal">Σ</mi>
       <mn>1</mn>
      </msub>
      <mover accent="true">
       <mi>w</mi>
       <mo stretchy="false">→</mo>
      </mover>
     </mrow>
     <mo>+</mo>
     <mrow>
      <msup>
       <mover accent="true">
        <mi>w</mi>
        <mo stretchy="false">→</mo>
       </mover>
       <mi>T</mi>
      </msup>
      <msub>
       <mi mathvariant="normal">Σ</mi>
       <mn>0</mn>
      </msub>
      <mover accent="true">
       <mi>w</mi>
       <mo stretchy="false">→</mo>
      </mover>
     </mrow>
    </mrow>
   </mfrac>
   <mo>=</mo>
   <mfrac>
    <msup>
     <mrow>
      <mo stretchy="false">(</mo>
      <mrow>
       <mover accent="true">
        <mi>w</mi>
        <mo stretchy="false">→</mo>
       </mover>
       <mo>⋅</mo>
       <mrow>
        <mo stretchy="false">(</mo>
        <mrow>
         <msub>
          <mover accent="true">
           <mi>μ</mi>
           <mo stretchy="false">→</mo>
          </mover>
          <mn>1</mn>
         </msub>
         <mo>-</mo>
         <msub>
          <mover accent="true">
           <mi>μ</mi>
           <mo stretchy="false">→</mo>
          </mover>
          <mn>0</mn>
         </msub>
        </mrow>
        <mo stretchy="false">)</mo>
       </mrow>
      </mrow>
      <mo stretchy="false">)</mo>
     </mrow>
     <mn>2</mn>
    </msup>
    <mrow>
     <msup>
      <mover accent="true">
       <mi>w</mi>
       <mo stretchy="false">→</mo>
      </mover>
      <mi>T</mi>
     </msup>
     <mrow>
      <mo stretchy="false">(</mo>
      <mrow>
       <msub>
        <mi mathvariant="normal">Σ</mi>
        <mn>0</mn>
       </msub>
       <mo>+</mo>
       <msub>
        <mi mathvariant="normal">Σ</mi>
        <mn>1</mn>
       </msub>
      </mrow>
      <mo stretchy="false">)</mo>
     </mrow>
     <mover accent="true">
      <mi>w</mi>
      <mo stretchy="false">→</mo>
     </mover>
    </mrow>
   </mfrac>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <and></and>
    <apply>
     <eq></eq>
     <ci>S</ci>
     <apply>
      <divide></divide>
      <apply>
       <csymbol cd="ambiguous">superscript</csymbol>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <ci>σ</ci>
        <mtext>between</mtext>
       </apply>
       <cn type="integer">2</cn>
      </apply>
      <apply>
       <csymbol cd="ambiguous">superscript</csymbol>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <ci>σ</ci>
        <mtext>within</mtext>
       </apply>
       <cn type="integer">2</cn>
      </apply>
     </apply>
    </apply>
    <apply>
     <eq></eq>
     <share href="#.cmml">
     </share>
     <apply>
      <divide></divide>
      <apply>
       <csymbol cd="ambiguous">superscript</csymbol>
       <apply>
        <minus></minus>
        <apply>
         <ci>normal-⋅</ci>
         <apply>
          <ci>normal-→</ci>
          <ci>w</ci>
         </apply>
         <apply>
          <csymbol cd="ambiguous">subscript</csymbol>
          <apply>
           <ci>normal-→</ci>
           <ci>μ</ci>
          </apply>
          <cn type="integer">1</cn>
         </apply>
        </apply>
        <apply>
         <ci>normal-⋅</ci>
         <apply>
          <ci>normal-→</ci>
          <ci>w</ci>
         </apply>
         <apply>
          <csymbol cd="ambiguous">subscript</csymbol>
          <apply>
           <ci>normal-→</ci>
           <ci>μ</ci>
          </apply>
          <cn type="integer">0</cn>
         </apply>
        </apply>
       </apply>
       <cn type="integer">2</cn>
      </apply>
      <apply>
       <plus></plus>
       <apply>
        <times></times>
        <apply>
         <csymbol cd="ambiguous">superscript</csymbol>
         <apply>
          <ci>normal-→</ci>
          <ci>w</ci>
         </apply>
         <ci>T</ci>
        </apply>
        <apply>
         <csymbol cd="ambiguous">subscript</csymbol>
         <ci>normal-Σ</ci>
         <cn type="integer">1</cn>
        </apply>
        <apply>
         <ci>normal-→</ci>
         <ci>w</ci>
        </apply>
       </apply>
       <apply>
        <times></times>
        <apply>
         <csymbol cd="ambiguous">superscript</csymbol>
         <apply>
          <ci>normal-→</ci>
          <ci>w</ci>
         </apply>
         <ci>T</ci>
        </apply>
        <apply>
         <csymbol cd="ambiguous">subscript</csymbol>
         <ci>normal-Σ</ci>
         <cn type="integer">0</cn>
        </apply>
        <apply>
         <ci>normal-→</ci>
         <ci>w</ci>
        </apply>
       </apply>
      </apply>
     </apply>
    </apply>
    <apply>
     <eq></eq>
     <share href="#.cmml">
     </share>
     <apply>
      <divide></divide>
      <apply>
       <csymbol cd="ambiguous">superscript</csymbol>
       <apply>
        <ci>normal-⋅</ci>
        <apply>
         <ci>normal-→</ci>
         <ci>w</ci>
        </apply>
        <apply>
         <minus></minus>
         <apply>
          <csymbol cd="ambiguous">subscript</csymbol>
          <apply>
           <ci>normal-→</ci>
           <ci>μ</ci>
          </apply>
          <cn type="integer">1</cn>
         </apply>
         <apply>
          <csymbol cd="ambiguous">subscript</csymbol>
          <apply>
           <ci>normal-→</ci>
           <ci>μ</ci>
          </apply>
          <cn type="integer">0</cn>
         </apply>
        </apply>
       </apply>
       <cn type="integer">2</cn>
      </apply>
      <apply>
       <times></times>
       <apply>
        <csymbol cd="ambiguous">superscript</csymbol>
        <apply>
         <ci>normal-→</ci>
         <ci>w</ci>
        </apply>
        <ci>T</ci>
       </apply>
       <apply>
        <plus></plus>
        <apply>
         <csymbol cd="ambiguous">subscript</csymbol>
         <ci>normal-Σ</ci>
         <cn type="integer">0</cn>
        </apply>
        <apply>
         <csymbol cd="ambiguous">subscript</csymbol>
         <ci>normal-Σ</ci>
         <cn type="integer">1</cn>
        </apply>
       </apply>
       <apply>
        <ci>normal-→</ci>
        <ci>w</ci>
       </apply>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   S=\frac{\sigma_{\text{between}}^{2}}{\sigma_{\text{within}}^{2}}=\frac{(\vec{w%
}\cdot\vec{\mu}_{1}-\vec{w}\cdot\vec{\mu}_{0})^{2}}{\vec{w}^{T}\Sigma_{1}\vec{%
w}+\vec{w}^{T}\Sigma_{0}\vec{w}}=\frac{(\vec{w}\cdot(\vec{\mu}_{1}-\vec{\mu}_{%
0}))^{2}}{\vec{w}^{T}(\Sigma_{0}+\Sigma_{1})\vec{w}}
  </annotation>
 </semantics>
</math>

</p>

<p>This measure is, in some sense, a measure of the <a href="signal-to-noise_ratio" title="wikilink">signal-to-noise ratio</a> for the class labelling. It can be shown that the maximum separation occurs when</p>

<p>

<math display="block" id="Linear_discriminant_analysis:27">
 <semantics>
  <mrow>
   <mover accent="true">
    <mi>w</mi>
    <mo stretchy="false">→</mo>
   </mover>
   <mo>∝</mo>
   <mrow>
    <msup>
     <mrow>
      <mo stretchy="false">(</mo>
      <mrow>
       <msub>
        <mi mathvariant="normal">Σ</mi>
        <mn>0</mn>
       </msub>
       <mo>+</mo>
       <msub>
        <mi mathvariant="normal">Σ</mi>
        <mn>1</mn>
       </msub>
      </mrow>
      <mo stretchy="false">)</mo>
     </mrow>
     <mrow>
      <mo>-</mo>
      <mn>1</mn>
     </mrow>
    </msup>
    <mrow>
     <mo stretchy="false">(</mo>
     <mrow>
      <msub>
       <mover accent="true">
        <mi>μ</mi>
        <mo stretchy="false">→</mo>
       </mover>
       <mn>1</mn>
      </msub>
      <mo>-</mo>
      <msub>
       <mover accent="true">
        <mi>μ</mi>
        <mo stretchy="false">→</mo>
       </mover>
       <mn>0</mn>
      </msub>
     </mrow>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="latexml">proportional-to</csymbol>
    <apply>
     <ci>normal-→</ci>
     <ci>w</ci>
    </apply>
    <apply>
     <times></times>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <apply>
       <plus></plus>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <ci>normal-Σ</ci>
        <cn type="integer">0</cn>
       </apply>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <ci>normal-Σ</ci>
        <cn type="integer">1</cn>
       </apply>
      </apply>
      <apply>
       <minus></minus>
       <cn type="integer">1</cn>
      </apply>
     </apply>
     <apply>
      <minus></minus>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <apply>
        <ci>normal-→</ci>
        <ci>μ</ci>
       </apply>
       <cn type="integer">1</cn>
      </apply>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <apply>
        <ci>normal-→</ci>
        <ci>μ</ci>
       </apply>
       <cn type="integer">0</cn>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \vec{w}\propto(\Sigma_{0}+\Sigma_{1})^{-1}(\vec{\mu}_{1}-\vec{\mu}_{0})
  </annotation>
 </semantics>
</math>

</p>

<p>When the assumptions of LDA are satisfied, the above equation is equivalent to LDA.</p>

<p>Be sure to note that the vector 

<math display="inline" id="Linear_discriminant_analysis:28">
 <semantics>
  <mover accent="true">
   <mi>w</mi>
   <mo stretchy="false">→</mo>
  </mover>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <ci>normal-→</ci>
    <ci>w</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \vec{w}
  </annotation>
 </semantics>
</math>


 is the <a href="surface_normal" title="wikilink">normal</a> to the discriminant <a class="uri" href="hyperplane" title="wikilink">hyperplane</a>. As an example, in a two dimensional problem, the line that best divides the two groups is perpendicular to 

<math display="inline" id="Linear_discriminant_analysis:29">
 <semantics>
  <mover accent="true">
   <mi>w</mi>
   <mo stretchy="false">→</mo>
  </mover>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <ci>normal-→</ci>
    <ci>w</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \vec{w}
  </annotation>
 </semantics>
</math>

.</p>

<p>Generally, the data points to be discriminated are projected onto 

<math display="inline" id="Linear_discriminant_analysis:30">
 <semantics>
  <mover accent="true">
   <mi>w</mi>
   <mo stretchy="false">→</mo>
  </mover>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <ci>normal-→</ci>
    <ci>w</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \vec{w}
  </annotation>
 </semantics>
</math>

; then the threshold that best separates the data is chosen from analysis of the one-dimensional distribution. There is no general rule for the threshold. However, if projections of points from both classes exhibit approximately the same distributions, a good choice would be the hyperplane between projections of the two means, 

<math display="inline" id="Linear_discriminant_analysis:31">
 <semantics>
  <mrow>
   <mover accent="true">
    <mi>w</mi>
    <mo stretchy="false">→</mo>
   </mover>
   <mo>⋅</mo>
   <msub>
    <mover accent="true">
     <mi>μ</mi>
     <mo stretchy="false">→</mo>
    </mover>
    <mn>0</mn>
   </msub>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <ci>normal-⋅</ci>
    <apply>
     <ci>normal-→</ci>
     <ci>w</ci>
    </apply>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <apply>
      <ci>normal-→</ci>
      <ci>μ</ci>
     </apply>
     <cn type="integer">0</cn>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \vec{w}\cdot\vec{\mu}_{0}
  </annotation>
 </semantics>
</math>

 and 

<math display="inline" id="Linear_discriminant_analysis:32">
 <semantics>
  <mrow>
   <mover accent="true">
    <mi>w</mi>
    <mo stretchy="false">→</mo>
   </mover>
   <mo>⋅</mo>
   <msub>
    <mover accent="true">
     <mi>μ</mi>
     <mo stretchy="false">→</mo>
    </mover>
    <mn>1</mn>
   </msub>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <ci>normal-⋅</ci>
    <apply>
     <ci>normal-→</ci>
     <ci>w</ci>
    </apply>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <apply>
      <ci>normal-→</ci>
      <ci>μ</ci>
     </apply>
     <cn type="integer">1</cn>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \vec{w}\cdot\vec{\mu}_{1}
  </annotation>
 </semantics>
</math>

. In this case the parameter c in threshold condition 

<math display="inline" id="Linear_discriminant_analysis:33">
 <semantics>
  <mrow>
   <mrow>
    <mover accent="true">
     <mi>w</mi>
     <mo stretchy="false">→</mo>
    </mover>
    <mo>⋅</mo>
    <mover accent="true">
     <mi>x</mi>
     <mo stretchy="false">→</mo>
    </mover>
   </mrow>
   <mo>></mo>
   <mi>c</mi>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <gt></gt>
    <apply>
     <ci>normal-⋅</ci>
     <apply>
      <ci>normal-→</ci>
      <ci>w</ci>
     </apply>
     <apply>
      <ci>normal-→</ci>
      <ci>x</ci>
     </apply>
    </apply>
    <ci>c</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \vec{w}\cdot\vec{x}>c
  </annotation>
 </semantics>
</math>


 can be found explicitly:</p>

<p>

<math display="block" id="Linear_discriminant_analysis:34">
 <semantics>
  <mrow>
   <mi>c</mi>
   <mo>=</mo>
   <mrow>
    <mrow>
     <mover accent="true">
      <mi>w</mi>
      <mo stretchy="false">→</mo>
     </mover>
     <mo>⋅</mo>
     <mfrac>
      <mn>1</mn>
      <mn>2</mn>
     </mfrac>
    </mrow>
    <mrow>
     <mo stretchy="false">(</mo>
     <mrow>
      <msub>
       <mover accent="true">
        <mi>μ</mi>
        <mo stretchy="false">→</mo>
       </mover>
       <mn>0</mn>
      </msub>
      <mo>+</mo>
      <msub>
       <mover accent="true">
        <mi>μ</mi>
        <mo stretchy="false">→</mo>
       </mover>
       <mn>1</mn>
      </msub>
     </mrow>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
   <mo>=</mo>
   <mrow>
    <mrow>
     <mfrac>
      <mn>1</mn>
      <mn>2</mn>
     </mfrac>
     <msubsup>
      <mover accent="true">
       <mi>μ</mi>
       <mo stretchy="false">→</mo>
      </mover>
      <mn>1</mn>
      <mi>t</mi>
     </msubsup>
     <msup>
      <mi mathvariant="normal">Σ</mi>
      <mrow>
       <mo>-</mo>
       <mn>1</mn>
      </mrow>
     </msup>
     <msub>
      <mover accent="true">
       <mi>μ</mi>
       <mo stretchy="false">→</mo>
      </mover>
      <mn>1</mn>
     </msub>
    </mrow>
    <mo>-</mo>
    <mrow>
     <mfrac>
      <mn>1</mn>
      <mn>2</mn>
     </mfrac>
     <msubsup>
      <mover accent="true">
       <mi>μ</mi>
       <mo stretchy="false">→</mo>
      </mover>
      <mn>0</mn>
      <mi>t</mi>
     </msubsup>
     <msup>
      <mi mathvariant="normal">Σ</mi>
      <mrow>
       <mo>-</mo>
       <mn>1</mn>
      </mrow>
     </msup>
     <msub>
      <mover accent="true">
       <mi>μ</mi>
       <mo stretchy="false">→</mo>
      </mover>
      <mn>0</mn>
     </msub>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <and></and>
    <apply>
     <eq></eq>
     <ci>c</ci>
     <apply>
      <times></times>
      <apply>
       <ci>normal-⋅</ci>
       <apply>
        <ci>normal-→</ci>
        <ci>w</ci>
       </apply>
       <apply>
        <divide></divide>
        <cn type="integer">1</cn>
        <cn type="integer">2</cn>
       </apply>
      </apply>
      <apply>
       <plus></plus>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <apply>
         <ci>normal-→</ci>
         <ci>μ</ci>
        </apply>
        <cn type="integer">0</cn>
       </apply>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <apply>
         <ci>normal-→</ci>
         <ci>μ</ci>
        </apply>
        <cn type="integer">1</cn>
       </apply>
      </apply>
     </apply>
    </apply>
    <apply>
     <eq></eq>
     <share href="#.cmml">
     </share>
     <apply>
      <minus></minus>
      <apply>
       <times></times>
       <apply>
        <divide></divide>
        <cn type="integer">1</cn>
        <cn type="integer">2</cn>
       </apply>
       <apply>
        <csymbol cd="ambiguous">superscript</csymbol>
        <apply>
         <csymbol cd="ambiguous">subscript</csymbol>
         <apply>
          <ci>normal-→</ci>
          <ci>μ</ci>
         </apply>
         <cn type="integer">1</cn>
        </apply>
        <ci>t</ci>
       </apply>
       <apply>
        <csymbol cd="ambiguous">superscript</csymbol>
        <ci>normal-Σ</ci>
        <apply>
         <minus></minus>
         <cn type="integer">1</cn>
        </apply>
       </apply>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <apply>
         <ci>normal-→</ci>
         <ci>μ</ci>
        </apply>
        <cn type="integer">1</cn>
       </apply>
      </apply>
      <apply>
       <times></times>
       <apply>
        <divide></divide>
        <cn type="integer">1</cn>
        <cn type="integer">2</cn>
       </apply>
       <apply>
        <csymbol cd="ambiguous">superscript</csymbol>
        <apply>
         <csymbol cd="ambiguous">subscript</csymbol>
         <apply>
          <ci>normal-→</ci>
          <ci>μ</ci>
         </apply>
         <cn type="integer">0</cn>
        </apply>
        <ci>t</ci>
       </apply>
       <apply>
        <csymbol cd="ambiguous">superscript</csymbol>
        <ci>normal-Σ</ci>
        <apply>
         <minus></minus>
         <cn type="integer">1</cn>
        </apply>
       </apply>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <apply>
         <ci>normal-→</ci>
         <ci>μ</ci>
        </apply>
        <cn type="integer">0</cn>
       </apply>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   c=\vec{w}\cdot\frac{1}{2}(\vec{\mu}_{0}+\vec{\mu}_{1})=\frac{1}{2}\vec{\mu}_{1%
}^{t}\Sigma^{-1}\vec{\mu}_{1}-\frac{1}{2}\vec{\mu}_{0}^{t}\Sigma^{-1}\vec{\mu}%
_{0}
  </annotation>
 </semantics>
</math>

.</p>

<p><a href="Otsu's_Method" title="wikilink">Otsu's Method</a> is related to Fisher's linear discriminant, and was created to binarize the histogram of pixels in a grayscale image by optimally picking the black/white threshold that minimizes intra-class variance and maximizes inter-class variance within/between grayscales assigned to black and white pixel classes.</p>
<h2 id="multiclass-lda">Multiclass LDA</h2>

<p>In the case where there are more than two classes, the analysis used in the derivation of the Fisher discriminant can be extended to find a <a href="Linear_subspace" title="wikilink">subspace</a> which appears to contain all of the class variability. This generalization is due to <a href="Calyampudi_Radhakrishna_Rao" title="wikilink">C.R. Rao</a>.<a class="footnoteRef" href="#fn9" id="fnref9"><sup>9</sup></a> Suppose that each of C classes has a mean 

<math display="inline" id="Linear_discriminant_analysis:35">
 <semantics>
  <msub>
   <mi>μ</mi>
   <mi>i</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>μ</ci>
    <ci>i</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \mu_{i}
  </annotation>
 </semantics>
</math>

 and the same covariance 

<math display="inline" id="Linear_discriminant_analysis:36">
 <semantics>
  <mi mathvariant="normal">Σ</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>normal-Σ</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \Sigma
  </annotation>
 </semantics>
</math>

. Then the scatter between class variability may be defined by the sample covariance of the class means</p>

<p>

<math display="block" id="Linear_discriminant_analysis:37">
 <semantics>
  <mrow>
   <msub>
    <mi mathvariant="normal">Σ</mi>
    <mi>b</mi>
   </msub>
   <mo>=</mo>
   <mrow>
    <mfrac>
     <mn>1</mn>
     <mi>C</mi>
    </mfrac>
    <mrow>
     <munderover>
      <mo largeop="true" movablelimits="false" symmetric="true">∑</mo>
      <mrow>
       <mi>i</mi>
       <mo>=</mo>
       <mn>1</mn>
      </mrow>
      <mi>C</mi>
     </munderover>
     <mrow>
      <mrow>
       <mo stretchy="false">(</mo>
       <mrow>
        <msub>
         <mi>μ</mi>
         <mi>i</mi>
        </msub>
        <mo>-</mo>
        <mi>μ</mi>
       </mrow>
       <mo stretchy="false">)</mo>
      </mrow>
      <msup>
       <mrow>
        <mo stretchy="false">(</mo>
        <mrow>
         <msub>
          <mi>μ</mi>
          <mi>i</mi>
         </msub>
         <mo>-</mo>
         <mi>μ</mi>
        </mrow>
        <mo stretchy="false">)</mo>
       </mrow>
       <mi>T</mi>
      </msup>
     </mrow>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>normal-Σ</ci>
     <ci>b</ci>
    </apply>
    <apply>
     <times></times>
     <apply>
      <divide></divide>
      <cn type="integer">1</cn>
      <ci>C</ci>
     </apply>
     <apply>
      <apply>
       <csymbol cd="ambiguous">superscript</csymbol>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <sum></sum>
        <apply>
         <eq></eq>
         <ci>i</ci>
         <cn type="integer">1</cn>
        </apply>
       </apply>
       <ci>C</ci>
      </apply>
      <apply>
       <times></times>
       <apply>
        <minus></minus>
        <apply>
         <csymbol cd="ambiguous">subscript</csymbol>
         <ci>μ</ci>
         <ci>i</ci>
        </apply>
        <ci>μ</ci>
       </apply>
       <apply>
        <csymbol cd="ambiguous">superscript</csymbol>
        <apply>
         <minus></minus>
         <apply>
          <csymbol cd="ambiguous">subscript</csymbol>
          <ci>μ</ci>
          <ci>i</ci>
         </apply>
         <ci>μ</ci>
        </apply>
        <ci>T</ci>
       </apply>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \Sigma_{b}=\frac{1}{C}\sum_{i=1}^{C}(\mu_{i}-\mu)(\mu_{i}-\mu)^{T}
  </annotation>
 </semantics>
</math>

</p>

<p>where 

<math display="inline" id="Linear_discriminant_analysis:38">
 <semantics>
  <mi>μ</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>μ</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \mu
  </annotation>
 </semantics>
</math>


 is the mean of the class means. The class separation in a direction 

<math display="inline" id="Linear_discriminant_analysis:39">
 <semantics>
  <mover accent="true">
   <mi>w</mi>
   <mo stretchy="false">→</mo>
  </mover>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <ci>normal-→</ci>
    <ci>w</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \vec{w}
  </annotation>
 </semantics>
</math>

 in this case will be given by</p>

<p>

<math display="block" id="Linear_discriminant_analysis:40">
 <semantics>
  <mrow>
   <mi>S</mi>
   <mo>=</mo>
   <mfrac>
    <mrow>
     <msup>
      <mover accent="true">
       <mi>w</mi>
       <mo stretchy="false">→</mo>
      </mover>
      <mi>T</mi>
     </msup>
     <msub>
      <mi mathvariant="normal">Σ</mi>
      <mi>b</mi>
     </msub>
     <mover accent="true">
      <mi>w</mi>
      <mo stretchy="false">→</mo>
     </mover>
    </mrow>
    <mrow>
     <msup>
      <mover accent="true">
       <mi>w</mi>
       <mo stretchy="false">→</mo>
      </mover>
      <mi>T</mi>
     </msup>
     <mi mathvariant="normal">Σ</mi>
     <mover accent="true">
      <mi>w</mi>
      <mo stretchy="false">→</mo>
     </mover>
    </mrow>
   </mfrac>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <ci>S</ci>
    <apply>
     <divide></divide>
     <apply>
      <times></times>
      <apply>
       <csymbol cd="ambiguous">superscript</csymbol>
       <apply>
        <ci>normal-→</ci>
        <ci>w</ci>
       </apply>
       <ci>T</ci>
      </apply>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>normal-Σ</ci>
       <ci>b</ci>
      </apply>
      <apply>
       <ci>normal-→</ci>
       <ci>w</ci>
      </apply>
     </apply>
     <apply>
      <times></times>
      <apply>
       <csymbol cd="ambiguous">superscript</csymbol>
       <apply>
        <ci>normal-→</ci>
        <ci>w</ci>
       </apply>
       <ci>T</ci>
      </apply>
      <ci>normal-Σ</ci>
      <apply>
       <ci>normal-→</ci>
       <ci>w</ci>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   S=\frac{\vec{w}^{T}\Sigma_{b}\vec{w}}{\vec{w}^{T}\Sigma\vec{w}}
  </annotation>
 </semantics>
</math>

</p>

<p>This means that when 

<math display="inline" id="Linear_discriminant_analysis:41">
 <semantics>
  <mover accent="true">
   <mi>w</mi>
   <mo stretchy="false">→</mo>
  </mover>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <ci>normal-→</ci>
    <ci>w</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \vec{w}
  </annotation>
 </semantics>
</math>

 is an <a class="uri" href="eigenvector" title="wikilink">eigenvector</a> of 

<math display="inline" id="Linear_discriminant_analysis:42">
 <semantics>
  <mrow>
   <msup>
    <mi mathvariant="normal">Σ</mi>
    <mrow>
     <mo>-</mo>
     <mn>1</mn>
    </mrow>
   </msup>
   <msub>
    <mi mathvariant="normal">Σ</mi>
    <mi>b</mi>
   </msub>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <apply>
     <csymbol cd="ambiguous">superscript</csymbol>
     <ci>normal-Σ</ci>
     <apply>
      <minus></minus>
      <cn type="integer">1</cn>
     </apply>
    </apply>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>normal-Σ</ci>
     <ci>b</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \Sigma^{-1}\Sigma_{b}
  </annotation>
 </semantics>
</math>

 the separation will be equal to the corresponding <a class="uri" href="eigenvalue" title="wikilink">eigenvalue</a>.</p>

<p>If 

<math display="inline" id="Linear_discriminant_analysis:43">
 <semantics>
  <mrow>
   <msup>
    <mi mathvariant="normal">Σ</mi>
    <mrow>
     <mo>-</mo>
     <mn>1</mn>
    </mrow>
   </msup>
   <msub>
    <mi mathvariant="normal">Σ</mi>
    <mi>b</mi>
   </msub>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <apply>
     <csymbol cd="ambiguous">superscript</csymbol>
     <ci>normal-Σ</ci>
     <apply>
      <minus></minus>
      <cn type="integer">1</cn>
     </apply>
    </apply>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>normal-Σ</ci>
     <ci>b</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \Sigma^{-1}\Sigma_{b}
  </annotation>
 </semantics>
</math>


 is diagonalizable, the variability between features will be contained in the subspace spanned by the eigenvectors corresponding to the <em>C</em> − 1 largest eigenvalues (since 

<math display="inline" id="Linear_discriminant_analysis:44">
 <semantics>
  <msub>
   <mi mathvariant="normal">Σ</mi>
   <mi>b</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>normal-Σ</ci>
    <ci>b</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \Sigma_{b}
  </annotation>
 </semantics>
</math>

 is of rank <em>C</em> − 1 at most). These eigenvectors are primarily used in feature reduction, as in PCA. The eigenvectors corresponding to the smaller eigenvalues will tend to be very sensitive to the exact choice of training data, and it is often necessary to use regularisation as described in the next section.</p>

<p>If classification is required, instead of <a href="dimension_reduction" title="wikilink">dimension reduction</a>, there are a number of alternative techniques available. For instance, the classes may be partitioned, and a standard Fisher discriminant or LDA used to classify each partition. A common example of this is "one against the rest" where the points from one class are put in one group, and everything else in the other, and then LDA applied. This will result in C classifiers, whose results are combined. Another common method is pairwise classification, where a new classifier is created for each pair of classes (giving <em>C</em>(<em>C</em> − 1)/2 classifiers in total), with the individual classifiers combined to produce a final classification.</p>
<h2 id="practical-use">Practical use</h2>

<p>In practice, the class means and covariances are not known. They can, however, be estimated from the training set. Either the <a href="maximum_likelihood_estimation" title="wikilink">maximum likelihood estimate</a> or the <a href="maximum_a_posteriori" title="wikilink">maximum a posteriori</a> estimate may be used in place of the exact value in the above equations. Although the estimates of the covariance may be considered optimal in some sense, this does not mean that the resulting discriminant obtained by substituting these values is optimal in any sense, even if the assumption of normally distributed classes is correct.</p>

<p>Another complication in applying LDA and Fisher's discriminant to real data occurs when the number of measurements of each sample exceeds the number of samples in each class.<a class="footnoteRef" href="#fn10" id="fnref10"><sup>10</sup></a> In this case, the covariance estimates do not have full rank, and so cannot be inverted. There are a number of ways to deal with this. One is to use a <a href="pseudo_inverse" title="wikilink">pseudo inverse</a> instead of the usual matrix inverse in the above formulae. However, better numeric stability may be achieved by first projecting the problem onto the subspace spanned by 

<math display="inline" id="Linear_discriminant_analysis:45">
 <semantics>
  <msub>
   <mi mathvariant="normal">Σ</mi>
   <mi>b</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>normal-Σ</ci>
    <ci>b</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \Sigma_{b}
  </annotation>
 </semantics>
</math>

.<a class="footnoteRef" href="#fn11" id="fnref11"><sup>11</sup></a> Another strategy to deal with small sample size is to use a <a href="shrinkage_estimator" title="wikilink">shrinkage estimator</a> of the covariance matrix, which can be expressed mathematically as</p>

<p>

<math display="block" id="Linear_discriminant_analysis:46">
 <semantics>
  <mrow>
   <mi mathvariant="normal">Σ</mi>
   <mo>=</mo>
   <mrow>
    <mrow>
     <mrow>
      <mo stretchy="false">(</mo>
      <mrow>
       <mn>1</mn>
       <mo>-</mo>
       <mi>λ</mi>
      </mrow>
      <mo stretchy="false">)</mo>
     </mrow>
     <mi mathvariant="normal">Σ</mi>
    </mrow>
    <mo>+</mo>
    <mrow>
     <mi>λ</mi>
     <mpadded width="+1.7pt">
      <mi>I</mi>
     </mpadded>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <ci>normal-Σ</ci>
    <apply>
     <plus></plus>
     <apply>
      <times></times>
      <apply>
       <minus></minus>
       <cn type="integer">1</cn>
       <ci>λ</ci>
      </apply>
      <ci>normal-Σ</ci>
     </apply>
     <apply>
      <times></times>
      <ci>λ</ci>
      <ci>I</ci>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \Sigma=(1-\lambda)\Sigma+\lambda I\,
  </annotation>
 </semantics>
</math>

</p>

<p>where 

<math display="inline" id="Linear_discriminant_analysis:47">
 <semantics>
  <mi>I</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>I</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   I
  </annotation>
 </semantics>
</math>

 is the identity matrix, and 

<math display="inline" id="Linear_discriminant_analysis:48">
 <semantics>
  <mi>λ</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>λ</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \lambda
  </annotation>
 </semantics>
</math>


 is the <em>shrinkage intensity</em> or <em>regularisation parameter</em>. This leads to the framework of regularized discriminant analysis<a class="footnoteRef" href="#fn12" id="fnref12"><sup>12</sup></a> or shrinkage discriminant analysis.<a class="footnoteRef" href="#fn13" id="fnref13"><sup>13</sup></a></p>

<p>Also, in many practical cases linear discriminants are not suitable. LDA and Fisher's discriminant can be extended for use in non-linear classification via the <a href="kernel_trick" title="wikilink">kernel trick</a>. Here, the original observations are effectively mapped into a higher dimensional non-linear space. Linear classification in this non-linear space is then equivalent to non-linear classification in the original space. The most commonly used example of this is the <a href="Kernel_Fisher_discriminant_analysis" title="wikilink">kernel Fisher discriminant</a>.</p>

<p>LDA can be generalized to <a href="multiple_discriminant_analysis" title="wikilink">multiple discriminant analysis</a>, where <em>c</em> becomes a <a href="categorical_variable" title="wikilink">categorical variable</a> with <em>N</em> possible states, instead of only two. Analogously, if the class-conditional densities 

<math display="inline" id="Linear_discriminant_analysis:49">
 <semantics>
  <mrow>
   <mi>p</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <mover accent="true">
     <mi>x</mi>
     <mo stretchy="false">→</mo>
    </mover>
    <mo stretchy="false">|</mo>
    <mi>c</mi>
    <mo>=</mo>
    <mi>i</mi>
    <mo stretchy="false">)</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <cerror>
    <csymbol cd="ambiguous">fragments</csymbol>
    <csymbol cd="unknown">p</csymbol>
    <cerror>
     <csymbol cd="ambiguous">fragments</csymbol>
     <ci>normal-(</ci>
     <apply>
      <ci>normal-→</ci>
      <ci>x</ci>
     </apply>
     <ci>normal-|</ci>
     <csymbol cd="unknown">c</csymbol>
     <eq></eq>
     <csymbol cd="unknown">i</csymbol>
     <ci>normal-)</ci>
    </cerror>
   </cerror>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   p(\vec{x}|c=i)
  </annotation>
 </semantics>
</math>

 are normal with shared covariances, the <a href="sufficient_statistic" title="wikilink">sufficient statistic</a> for 

<math display="inline" id="Linear_discriminant_analysis:50">
 <semantics>
  <mrow>
   <mi>P</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <mi>c</mi>
    <mo stretchy="false">|</mo>
    <mover accent="true">
     <mi>x</mi>
     <mo stretchy="false">→</mo>
    </mover>
    <mo stretchy="false">)</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <cerror>
    <csymbol cd="ambiguous">fragments</csymbol>
    <csymbol cd="unknown">P</csymbol>
    <cerror>
     <csymbol cd="ambiguous">fragments</csymbol>
     <ci>normal-(</ci>
     <csymbol cd="unknown">c</csymbol>
     <ci>normal-|</ci>
     <apply>
      <ci>normal-→</ci>
      <ci>x</ci>
     </apply>
     <ci>normal-)</ci>
    </cerror>
   </cerror>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   P(c|\vec{x})
  </annotation>
 </semantics>
</math>

 are the values of <em>N</em> projections, which are the <a href="Linear_subspace" title="wikilink">subspace</a> spanned by the <em>N</em> means, <a href="affine_transformation" title="wikilink">affine projected</a> by the inverse covariance matrix. These projections can be found by solving a <a href="Eigenvalue,_eigenvector_and_eigenspace#generalized_eigenvalue_problem" title="wikilink">generalized eigenvalue problem</a>, where the numerator is the covariance matrix formed by treating the means as the samples, and the denominator is the shared covariance matrix.</p>
<h2 id="applications">Applications</h2>

<p>In addition to the examples given below, LDA is applied in <a href="positioning_(marketing)" title="wikilink">positioning</a> and <a href="product_management" title="wikilink">product management</a>.</p>
<h3 id="bankruptcy-prediction">Bankruptcy prediction</h3>

<p>In <a href="bankruptcy_prediction" title="wikilink">bankruptcy prediction</a> based on accounting ratios and other financial variables, linear discriminant analysis was the first statistical method applied to systematically explain which firms entered bankruptcy vs. survived. Despite limitations including known nonconformance of accounting ratios to the normal distribution assumptions of LDA, <a href="Edward_Altman" title="wikilink">Edward Altman</a>'s <a href="Z-Score_Financial_Analysis_Tool" title="wikilink">1968 model</a> is still a leading model in practical applications.</p>
<h3 id="face-recognition">Face recognition</h3>

<p>In computerised <a href="Facial_recognition_system" title="wikilink">face recognition</a>, each face is represented by a large number of pixel values. Linear discriminant analysis is primarily used here to reduce the number of features to a more manageable number before classification. Each of the new dimensions is a linear combination of pixel values, which form a template. The linear combinations obtained using Fisher's linear discriminant are called <em>Fisher faces</em>, while those obtained using the related <a href="principal_component_analysis" title="wikilink">principal component analysis</a> are called <em><a class="uri" href="eigenfaces" title="wikilink">eigenfaces</a></em>.</p>
<h3 id="marketing">Marketing</h3>

<p>In <a class="uri" href="marketing" title="wikilink">marketing</a>, discriminant analysis was once often used to determine the factors which distinguish different types of customers and/or products on the basis of surveys or other forms of collected data. <a href="Logistic_regression" title="wikilink">Logistic regression</a> or other methods are now more commonly used. The use of discriminant analysis in marketing can be described by the following steps:</p>
<ol>
<li>Formulate the problem and gather data — Identify the <a href="Social_salience" title="wikilink">salient</a> attributes consumers use to evaluate products in this category — Use <a href="quantitative_marketing_research" title="wikilink">quantitative marketing research</a> techniques (such as <a href="statistical_survey" title="wikilink">surveys</a>) to collect data from a sample of potential customers concerning their ratings of all the product attributes. The data collection stage is usually done by marketing research professionals. Survey questions ask the respondent to rate a product from one to five (or 1 to 7, or 1 to 10) on a range of attributes chosen by the researcher. Anywhere from five to twenty attributes are chosen. They could include things like: ease of use, weight, accuracy, durability, colourfulness, price, or size. The attributes chosen will vary depending on the product being studied. The same question is asked about all the products in the study. The data for multiple products is codified and input into a statistical program such as <a href="R_language" title="wikilink">R</a>, <a class="uri" href="SPSS" title="wikilink">SPSS</a> or <a href="SAS_programming_language" title="wikilink">SAS</a>. (This step is the same as in Factor analysis).</li>
<li>Estimate the Discriminant Function Coefficients and determine the statistical significance and validity — Choose the appropriate discriminant analysis method. The direct method involves estimating the discriminant function so that all the predictors are assessed simultaneously. The stepwise method enters the predictors sequentially. The two-group method should be used when the dependent variable has two categories or states. The multiple discriminant method is used when the dependent variable has three or more categorical states. Use <a href="Wilks'_lambda_distribution" title="wikilink">Wilks’s Lambda</a> to test for significance in SPSS or F stat in SAS. The most common method used to test validity is to split the sample into an estimation or analysis sample, and a validation or holdout sample. The estimation sample is used in constructing the discriminant function. The validation sample is used to construct a classification matrix which contains the number of correctly classified and incorrectly classified cases. The percentage of correctly classified cases is called the hit ratio.</li>
<li>Plot the results on a two dimensional map, define the dimensions, and interpret the results. The statistical program (or a related module) will map the results. The map will plot each product (usually in two-dimensional space). The distance of products to each other indicate either how different they are. The dimensions must be labelled by the researcher. This requires subjective judgement and is often very challenging. See <a href="perceptual_mapping" title="wikilink">perceptual mapping</a>.</li>
</ol>
<h3 id="biomedical-studies">Biomedical studies</h3>

<p>The main application of discriminant analysis in medicine is the assessment of severity state of a patient and prognosis of disease outcome. For example, during retrospective analysis, patients are divided into groups according to severity of disease – mild, moderate and severe form. Then results of clinical and laboratory analyses are studied in order to reveal variables which are statistically different in studied groups. Using these variables, discriminant functions are built which help to objectively classify disease in a future patient into mild, moderate or severe form.</p>

<p>In biology, similar principles are used in order to classify and define groups of different biological objects, for example, to define phage types of Salmonella enteritidis based on Fourier transform infrared spectra,<a class="footnoteRef" href="#fn14" id="fnref14"><sup>14</sup></a> to detect animal source of Escherichia coli studying its virulence factors<a class="footnoteRef" href="#fn15" id="fnref15"><sup>15</sup></a> etc.</p>
<h3 id="earth-science">Earth Science</h3>

<p>This method can be used to separate the alteration zones. For example, when different data from various zones are available, discriminate analysis can find the pattern within the data and classify the them effectively <a class="footnoteRef" href="#fn16" id="fnref16"><sup>16</sup></a></p>
<h2 id="see-also">See also</h2>
<ul>
<li><a href="Data_mining" title="wikilink">Data mining</a></li>
<li><a href="Decision_tree_learning" title="wikilink">Decision tree learning</a></li>
<li><a href="Factor_analysis" title="wikilink">Factor analysis</a></li>
<li><a href="Kernel_Fisher_discriminant_analysis" title="wikilink">Kernel Fisher discriminant analysis</a></li>
<li><a class="uri" href="Logit" title="wikilink">Logit</a> (for <a href="logistic_regression" title="wikilink">logistic regression</a>)</li>
<li><a href="Multidimensional_scaling" title="wikilink">Multidimensional scaling</a></li>
<li><a href="Multilinear_subspace_learning" title="wikilink">Multilinear subspace learning</a></li>
<li><a href="Pattern_recognition" title="wikilink">Pattern recognition</a></li>
<li><a class="uri" href="Perceptron" title="wikilink">Perceptron</a></li>
<li><a href="Preference_regression" title="wikilink">Preference regression</a></li>
<li><a href="Quadratic_classifier" title="wikilink">Quadratic classifier</a></li>
</ul>
<h2 id="references">References</h2>
<h2 id="further-reading">Further reading</h2>
<ul>
<li></li>
<li></li>
<li></li>
</ul>
<h2 id="external-links">External links</h2>
<ul>
<li><a href="http://www.alglib.net/dataanalysis/lineardiscriminantanalysis.php">ALGLIB</a> contains open-source LDA implementation in C# / C++ / Pascal / VBA.</li>
<li><a href="http://www.psychometrica.de/lds.html">Psychometrica.de</a> open-source LDA implementation in Java</li>
<li><a href="http://people.revoledu.com/kardi/tutorial/LDA/index.html">LDA tutorial using MS Excel</a></li>
<li><a href="http://www.biostat.katerynakon.in.ua/en/prognosis/discriminant-analysis.html">Biomedical statistics. Discriminant analysis</a></li>
</ul>

<p>"</p>

<p><a href="Category:Multivariate_statistics" title="wikilink">Category:Multivariate statistics</a> <a href="Category:Statistical_classification" title="wikilink">Category:Statistical classification</a> <a href="Category:Classification_algorithms" title="wikilink">Category:Classification algorithms</a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1"><a href="#fnref1">↩</a></li>
<li id="fn2"><a href="#fnref2">↩</a></li>
<li id="fn3">Analyzing Quantitative Data: An Introduction for Social Researchers, Debra Wetcher-Hendricks, p.288<a href="#fnref3">↩</a></li>
<li id="fn4"><a href="#fnref4">↩</a></li>
<li id="fn5">Abdi, H. (2007) <a href="http://www.utdallas.edu/~herve/Abdi-DCA2007-pretty.pdf">"Discriminant correspondence analysis."</a> In: N.J. Salkind (Ed.): <em>Encyclopedia of Measurement and Statistic</em>. Thousand Oaks (CA): Sage. pp. 270–275.<a href="#fnref5">↩</a></li>
<li id="fn6">Perriere, G.; &amp; Thioulouse, J. (2003). "Use of Correspondence Discriminant Analysis to predict the subcellular location of bacterial proteins", <em>Computer Methods and Programs in Biomedicine</em>, 70, 99–105.<a href="#fnref6">↩</a></li>
<li id="fn7"><a href="#fnref7">↩</a></li>
<li id="fn8">Fisher, 1936.<a href="#fnref8">↩</a></li>
<li id="fn9"><a href="#fnref9">↩</a></li>
<li id="fn10"></li>
<li id="fn11">Yu, H.; Yang, J. (2001). "A direct LDA algorithm for high-dimensional data — with application to face recognition", <em>Pattern Recognition</em>, 34 (10), 2067–2069<a href="#fnref11">↩</a></li>
<li id="fn12"><a href="#fnref12">↩</a></li>
<li id="fn13">Ahdesmäki, M.; Strimmer K. (2010) <a href="http://projecteuclid.org/euclid.aoas/1273584465">"Feature selection in omics prediction problems using cat scores and false nondiscovery rate control"</a>, <em>Annals of Applied Statistics</em>, 4 (1), 503–519.<a href="#fnref13">↩</a></li>
<li id="fn14">Preisner O, Guiomar R, Machado J, Menezes JC, Lopes JA. Application of Fourier transform infrared spectroscopy and chemometrics for differentiation of Salmonella enterica serovar Enteritidis phage types. Appl Environ Microbiol. 2010;76(11):3538–3544.<a href="#fnref14">↩</a></li>
<li id="fn15">David DE, Lynne AM, Han J, Foley SL. Evaluation of virulence factor profiling in the characterization of veterinary Escherichia coli isolates. Appl Environ Microbiol. 2010;76(22):7509–7513.<a href="#fnref15">↩</a></li>
<li id="fn16">Tahmasebi, P., Hezarkhani, A., &amp; Mortazavi, M. (2010). <a href="http://ajbasweb.com/old/ajbas/2010/564-576.pdf">Application of discriminant analysis for alteration separation</a>; sungun copper deposit, East Azerbaijan, Iran. Australian Journal of Basic and Applied Sciences, 6(4), 564-576.<a href="#fnref16">↩</a></li>
</ol>
</section>
</body>
</html>
