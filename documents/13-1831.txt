   LOBPCG      LOBPCG   Locally Optimal Block Preconditioned Conjugate Gradient ( LOBPCG ) is a matrix-free method for finding the largest (or smallest) eigenvalues and the corresponding eigenvectors of a symmetric positive definite generalized eigenvalue problem        A  x   =   λ  B  x    ,        A  x     λ  B  x     Ax=\lambda Bx,     for a given pair    (  A  ,  B  )     A  B    (A,B)   of complex Hermitian or real symmetric matrices, where the matrix   B   B   B   is also assumed positive-definite .  Algorithm  The method performs an iterative maximization (or minimization) of the generalized Rayleigh quotient        ρ   (  x  )    :=   ρ   (  A  ,  B  ;  x  )    :=     x  T   A  x     x  T   B  x     ,       assign    ρ  x     ρ   A  B  x      assign         superscript  x  T   A  x      superscript  x  T   B  x       \rho(x):=\rho(A,B;x):=\frac{x^{T}Ax}{x^{T}Bx},     which results in finding largest (or smallest) eigenpairs of      A  x   =   λ  B  x    .        A  x     λ  B  x     Ax=\lambda Bx.     The direction of the steepest ascent, which is the gradient , of the generalized Rayleigh quotient is positively proportional to the vector       r  :=    A  x   -   ρ   (  x  )   B  x     ,     assign  r      A  x     ρ  x  B  x      r:=Ax-\rho(x)Bx,     called the eigenvector residual . If a preconditioner    T   T   T   is available, it is applied to the residual giving vector       w  :=   T  r    ,     assign  w    T  r     w:=Tr,     called the preconditioned residual. Without preconditioning, we set    T  :=  I     assign  T  I    T:=I   and so     w  :=  r   ,     assign  w  r    w:=r,   . An iterative method        x   i  +  1    :=    x  i   +    α  i   T   (    A   x  i    -   ρ   (   x  i   )   B   x  i     )      ,     assign   superscript  x    i  1       superscript  x  i      superscript  α  i   T      A   superscript  x  i      ρ   superscript  x  i   B   superscript  x  i         x^{i+1}:=x^{i}+\alpha^{i}T(Ax^{i}-\rho(x^{i})Bx^{i}),     or, in short,        x   i  +  1    :=    x  i   +    α  i    w  i      ,     assign   superscript  x    i  1       superscript  x  i      superscript  α  i    superscript  w  i       x^{i+1}:=x^{i}+\alpha^{i}w^{i},\,           w  i   :=   T   r  i     ,     assign   superscript  w  i     T   superscript  r  i      w^{i}:=Tr^{i},\,           r  i   :=    A   x  i    -   ρ   (   x  i   )   B   x  i      ,     assign   superscript  r  i       A   superscript  x  i      ρ   superscript  x  i   B   superscript  x  i       r^{i}:=Ax^{i}-\rho(x^{i})Bx^{i},     is known as preconditioned steepest ascent (or descent), where the scalar    α  i     superscript  α  i    \alpha^{i}   is called the step size. The optimal step size can be determined by maximizing the Rayleigh quotient, i.e.,       x   i  +  1    :=    arg    max   y  ∈   s  p  a  n   {   x  i   ,   w  i   }      ρ     (  y  )       assign   superscript  x    i  1          subscript     y    s  p  a  n    superscript  x  i    superscript  w  i       ρ    y     x^{i+1}:=\arg\max_{y\in span\{x^{i},w^{i}\}}\rho(y)     (or    arg  min         \arg\min   in case of minimizing), in which case the method is called locally optimal. To further accelerate the convergence of the locally optimal preconditioned steepest ascent (or descent), one can add one extra vector to the two-term recurrence relation to make it three-term:       x   i  +  1    :=    arg    max   y  ∈   s  p  a  n   {   x  i   ,   w  i   ,   x   i  -  1    }      ρ     (  y  )       assign   superscript  x    i  1          subscript     y    s  p  a  n    superscript  x  i    superscript  w  i    superscript  x    i  1        ρ    y     x^{i+1}:=\arg\max_{y\in span\{x^{i},w^{i},x^{i-1}\}}\rho(y)     (use    arg  min         \arg\min   in case of minimizing). The maximization/minimization of the Rayleigh quotient in a 3-dimensional subspace can be performed numerically by the Rayleigh–Ritz method . As the iterations converge, the vectors    x  i     superscript  x  i    x^{i}   and    x   i  -  1      superscript  x    i  1     x^{i-1}   become nearly linearly dependent, making the Rayleigh–Ritz method numerically unstable in the presence of round-off errors. It is possible to substitute the vector    x   i  -  1      superscript  x    i  1     x^{i-1}   with an explicitly computed difference     p  i   =    x   i  -  1    -   x  i         superscript  p  i      superscript  x    i  1     superscript  x  i      p^{i}=x^{i-1}-x^{i}   making the Rayleigh–Ritz method more stable; see. 1  This is a single-vector version of the LOBPCG method. It is one of possible generalization of the preconditioned  conjugate gradient linear solvers to the case of symmetric eigenvalue problems. Even in the trivial case    T  =  I      T  I    T=I   and    B  =  I      B  I    B=I   the resulting approximation with    i  >  3      i  3    i>3   will be different from that obtained by the Lanczos algorithm , although both approximations will belong to the same Krylov subspace .  Iterating several approximate eigenvectors together in a block in a similar locally optimal fashion, gives the full block version of the LOBPCG. It allows robust computation of eigenvectors corresponding to nearly-multiple eigenvalues.  Implementations  LOBPCG's inventor, Andrew Knyazev , published an implementation called Block Locally Optimal Preconditioned Eigenvalue Xolvers (BLOPEX) with interfaces to PETSc and hypre . 2 Other implementations are available in Octave , MATLAB , ABINIT (including CUDA version), Octopus (software) , PESCAN , Anasazi ( Trilinos ), SciPy , NGSolve , NVIDIA AmgX, and PYFEMax .  Applications  LOBPCG has been successfully used for multi-billion size matrices by Gordon Bell Prize finalists, on the Earth Simulator  supercomputer in Japan. 3 4  References    External links   LOBPCG code in MATLAB  LOBPCG code in Octave  LOBPCG code in SciPy  LOBPCG code in Java at Google Code  LOBPCG in Block Locally Optimal Preconditioned Eigenvalue Xolvers (BLOPEX) at Bitbucket  LOBPCG in Block Locally Optimal Preconditioned Eigenvalue Xolvers (BLOPEX) at Google Code (retiring)   "  Category:Numerical linear algebra  Category:Scientific simulation software     ↩  ↩  ↩  ↩     