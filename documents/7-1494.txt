   Inside–outside algorithm      Inside–outside algorithm   In computer science , the inside–outside algorithm is a way of re-estimating production probabilities in a probabilistic context-free grammar . It was introduced James K. Baker in 1979 as a generalization of the forward–backward algorithm for parameter estimation on hidden Markov models to stochastic context-free grammars . It is used to compute expectations, for example as part of the expectation–maximization algorithm (an unsupervised learning algorithm).  Inside and outside probabilities  The inside probability     β  j    (  p  ,  q  )        subscript  β  j    p  q     \beta_{j}(p,q)   is the total probability of generating words     w  p   ⋯   w  q        subscript  w  p   normal-⋯   subscript  w  q     w_{p}\cdots w_{q}   , given the root nonterminal    N  j     superscript  N  j    N^{j}   and a grammar   G   G   G   : 1       β  j    (  p  ,  q  )   =  P   (   w   p  q    |   N   p  q   j   ,  G  )      fragments   subscript  β  j    fragments  normal-(  p  normal-,  q  normal-)    P   fragments  normal-(   subscript  w    p  q    normal-|   subscript   superscript  N  j     p  q    normal-,  G  normal-)     \beta_{j}(p,q)=P(w_{pq}|N^{j}_{pq},G)     The outside probability     α  j    (  p  ,  q  )        subscript  α  j    p  q     \alpha_{j}(p,q)   is the total probability of beginning with the start symbol    N  1     superscript  N  1    N^{1}   and generating the nonterminal    N   p  q   j     subscript   superscript  N  j     p  q     N^{j}_{pq}   and all the words outside     w  p   ⋯   w  q        subscript  w  p   normal-⋯   subscript  w  q     w_{p}\cdots w_{q}   , given a grammar   G   G   G   : 2       α  j    (  p  ,  q  )   =  P   (   w   1   (   p  -  1   )     ,   N   p  q   j   ,   w    (   q  +  1   )   m    |  G  )      fragments   subscript  α  j    fragments  normal-(  p  normal-,  q  normal-)    P   fragments  normal-(   subscript  w    1    p  1     normal-,   subscript   superscript  N  j     p  q    normal-,   subscript  w      q  1   m    normal-|  G  normal-)     \alpha_{j}(p,q)=P(w_{1(p-1)},N^{j}_{pq},w_{(q+1)m}|G)     Computing Inside probabilities  Base Case:       β  j    (  p  ,  p  )   =  P   (   w  p   |   N  j   ,  G  )      fragments   subscript  β  j    fragments  normal-(  p  normal-,  p  normal-)    P   fragments  normal-(   subscript  w  p   normal-|   superscript  N  j   normal-,  G  normal-)     \beta_{j}(p,p)=P(w_{p}|N^{j},G)     General Case:  Suppose there is a rule     N  j   →    N  r    N  s       normal-→   subscript  N  j      subscript  N  r    subscript  N  s      N_{j}\rightarrow N_{r}N_{s}   in the grammar, then the probability of generating     w  p   ⋯   w  q        subscript  w  p   normal-⋯   subscript  w  q     w_{p}\cdots w_{q}   starting with a subtree rooted at    N  j     subscript  N  j    N_{j}   is:       ∑   k  =  p    k  =   q  -  1     P   (   N  j   →   N  r    N  s   )    β  r    (  p  ,  k  )    β  s    (  k  +  1  ,  q  )      fragments   superscript   subscript     k  p      k    q  1     P   fragments  normal-(   subscript  N  j   normal-→   subscript  N  r    subscript  N  s   normal-)    subscript  β  r    fragments  normal-(  p  normal-,  k  normal-)    subscript  β  s    fragments  normal-(  k   1  normal-,  q  normal-)     \sum_{k=p}^{k=q-1}P(N_{j}\rightarrow N_{r}N_{s})\beta_{r}(p,k)\beta_{s}(k+1,q)     The inside probability     β  j    (  p  ,  q  )        subscript  β  j    p  q     \beta_{j}(p,q)   is just the sum over all such possible rules:       β  j    (  p  ,  q  )   =   ∑    N  r   ,   N  s      ∑   k  =  p    k  =   q  -  1     P   (   N  j   →   N  r    N  s   )    β  r    (  p  ,  k  )    β  s    (  k  +  1  ,  q  )      fragments   subscript  β  j    fragments  normal-(  p  normal-,  q  normal-)     subscript     subscript  N  r    subscript  N  s      superscript   subscript     k  p      k    q  1     P   fragments  normal-(   subscript  N  j   normal-→   subscript  N  r    subscript  N  s   normal-)    subscript  β  r    fragments  normal-(  p  normal-,  k  normal-)    subscript  β  s    fragments  normal-(  k   1  normal-,  q  normal-)     \beta_{j}(p,q)=\sum_{N_{r},N_{s}}\sum_{k=p}^{k=q-1}P(N_{j}\rightarrow N_{r}N_{%
 s})\beta_{r}(p,k)\beta_{s}(k+1,q)     Computing Outside probabilities  Base Case:        α  j    (  1  ,  n  )    =   {     1      if  j   =  1       0    otherwise             subscript  α  j    1  n     cases  1      if  j   1   0  otherwise     \alpha_{j}(1,n)=\begin{cases}1&\mbox{if }j=1\\
 0&\mbox{otherwise}\end{cases}     Here the start symbol is    N  1     subscript  N  1    N_{1}   .  References   J. Baker (1979): Trainable grammars for speech recognition. In J. J. Wolf and D. H. Klatt, editors, Speech communication papers presented at the 97th meeting of the Acoustical Society of America , pages 547–550, Cambridge, MA, June 1979. MIT.  Karim Lari , Steve J. Young (1990): The estimation of stochastic context-free grammars using the inside–outside algorithm. Computer Speech and Language , 4:35–56.  Karim Lari , Steve J. Young (1991): Applications of stochastic context-free grammars using the Inside–Outside algorithm. Computer Speech and Language , 5:237–257.  Fernando Pereira, Yves Schabes (1992): Inside–outside reestimation from partially bracketed corpora. Proceedings of the 30th annual meeting on Association for Computational Linguistics, Association for Computational Linguistics , 128–135.   External links   Inside-outside algorithm - Fei Xia  The Inside-Outside Algorithm - Michael Collins   "  Category:Parsing algorithms     ↩      