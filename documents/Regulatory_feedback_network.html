<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="1365">Regulatory feedback network</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>Regulatory feedback network</h1>
<hr/>

<p><strong>Regulatory Feedback Networks</strong> describe a class of neural networks related to <strong>Virtual Lateral Inhibition</strong> (named to distinguish it from <a href="lateral_inhibition" title="wikilink">lateral inhibition</a>) that perform inference using <a href="negative_feedback" title="wikilink">negative feedback</a>.<ref>J. Reggia, “Virtual lateral inhibition in parallel</ref></p>

<p><code>activation models of associative memory,” in Proc. 9th International </code></p>

<p>Joint Conference on Artificial Intelligence., Aug. 1985, pp. 244-248.<a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a><a class="footnoteRef" href="#fn2" id="fnref2"><sup>2</sup></a> The feedback is implemented during recognition and during recognition connectivity parameters are not changed. Thus this is completely separate from learning/training (e.g. <a href="supervised_learning" title="wikilink">supervised learning</a> or <a href="unsupervised_learning" title="wikilink">unsupervised learning</a>). This is also different from models of <a href="attentional_shift" title="wikilink">spatial attention</a>. Instead, these networks determine the relevance of inputs through a "conservation of information principle".</p>
<h2 id="how-the-network-functions">How the network functions</h2>

<p>The computational basis of conservation of information is that an input should not pass more information than is justified to the next layer. Thus inputs are regulated by the outputs they activate. Subsequently, each input’s contribution (i.e. <a href="http://www.scholarpedia.org/article/Visual_salience">salience</a>) is adjusted through feedback regulation by its associated outputs. The amplitudes of the adjusted inputs are propagated to the output layer. A new salience is re-evaluated based on the new output activity (through feedback). This can be iterated until the networks reach steady state.<a class="footnoteRef" href="#fn3" id="fnref3"><sup>3</sup></a> At every step, the role of salience is</p>

<p><code>to maintain the relation where: the total activity of outputs connected</code><br/>
<code>to an input will be equivalent to the input’s amplitude.</code><a class="footnoteRef" href="#fn4" id="fnref4"><sup>4</sup></a><a class="footnoteRef" href="#fn5" id="fnref5"><sup>5</sup></a></p>
<h2 id="how-the-network-is-used">How the network is used</h2>

<p>These networks are best suited for nodes with binary connections.<a class="footnoteRef" href="#fn6" id="fnref6"><sup>6</sup></a><a class="footnoteRef" href="#fn7" id="fnref7"><sup>7</sup></a><a class="footnoteRef" href="#fn8" id="fnref8"><sup>8</sup></a> Instead of weights determining the relevance of connections, input salience is adjusted at the time of recognition. For example, a node representing car may connect to features wheels, door, and bumper. A node representing bicycle may connect to features wheels, pedals, and chain. Given wheels, the network will determine how relevant the wheels are to either the bicycle or car nodes during recognition.</p>
<h2 id="benefitscosts">Benefits/costs</h2>

<p>This model displays unparalleled performance given simultaneous patterns, addressing <a href="Curse_of_dimensionality" title="wikilink">combinatorial explosions</a> associated with simultaneous patterns.<a class="footnoteRef" href="#fn9" id="fnref9"><sup>9</sup></a><a class="footnoteRef" href="#fn10" id="fnref10"><sup>10</sup></a></p>

<p>The model can also generate solutions composed of multiple output nodes with minimal overlap.<a class="footnoteRef" href="#fn11" id="fnref11"><sup>11</sup></a><a class="footnoteRef" href="#fn12" id="fnref12"><sup>12</sup></a> This property groups patterns together in a manner that suggests a way out of a fundamental recognition conundrum called the <a href="binding_problem" title="wikilink">binding problem</a> ('unity of perception' version).</p>

<p>In contrast to conventional neural networks or machine learning methods these networks cannot be guaranteed to be able to capture any arbitrary pattern. However for the patterns they can capture, they show these properties.</p>
<h2 id="implementation">Implementation</h2>

<p>Suppose there are <a href="Fuzzy_logic" title="wikilink">fuzzy-type</a> input features 

<math display="inline" id="Regulatory_feedback_network:0">
 <semantics>
  <mi>x</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>x</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   x
  </annotation>
 </semantics>
</math>

 and output nodes 

<math display="inline" id="Regulatory_feedback_network:1">
 <semantics>
  <mi>y</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>y</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   y
  </annotation>
 </semantics>
</math>

. Each output node 

<math display="inline" id="Regulatory_feedback_network:2">
 <semantics>
  <msub>
   <mi>y</mi>
   <mi>j</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>y</ci>
    <ci>j</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   y_{j}
  </annotation>
 </semantics>
</math>

 is defined by set of feedforward binary connections 

<math display="inline" id="Regulatory_feedback_network:3">
 <semantics>
  <mrow>
   <mi>F</mi>
   <msub>
    <mi>F</mi>
    <mi>j</mi>
   </msub>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <ci>F</ci>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>F</ci>
     <ci>j</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   FF_{j}
  </annotation>
 </semantics>
</math>

 from 

<math display="inline" id="Regulatory_feedback_network:4">
 <semantics>
  <mi>x</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>x</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   x
  </annotation>
 </semantics>
</math>

's. It also has a set of symmetrical feedback connections 

<math display="inline" id="Regulatory_feedback_network:5">
 <semantics>
  <mrow>
   <mi>F</mi>
   <mi>B</mi>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <ci>F</ci>
    <ci>B</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   FB
  </annotation>
 </semantics>
</math>

 that implement <a href="negative_feedback" title="wikilink">negative feedback</a>. Due to the symmetry each member of 

<math display="inline" id="Regulatory_feedback_network:6">
 <semantics>
  <mrow>
   <mi>F</mi>
   <msub>
    <mi>F</mi>
    <mi>j</mi>
   </msub>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <ci>F</ci>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>F</ci>
     <ci>j</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   FF_{j}
  </annotation>
 </semantics>
</math>

 (a connection from input to output) has a corresponding member in 

<math display="inline" id="Regulatory_feedback_network:7">
 <semantics>
  <mrow>
   <mi>F</mi>
   <mi>B</mi>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <ci>F</ci>
    <ci>B</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   FB
  </annotation>
 </semantics>
</math>

 (a connection from the same output to same input) that returns and inhibits the input. Lets label 

<math display="inline" id="Regulatory_feedback_network:8">
 <semantics>
  <mrow>
   <mi>F</mi>
   <msub>
    <mi>B</mi>
    <mi>i</mi>
   </msub>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <ci>F</ci>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>B</ci>
     <ci>i</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   FB_{i}
  </annotation>
 </semantics>
</math>

 the set of connections that return to an 

<math display="inline" id="Regulatory_feedback_network:9">
 <semantics>
  <msub>
   <mi>x</mi>
   <mi>i</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>x</ci>
    <ci>i</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   x_{i}
  </annotation>
 </semantics>
</math>

. 

<math display="inline" id="Regulatory_feedback_network:10">
 <semantics>
  <mrow>
   <mo stretchy="false">|</mo>
   <mrow>
    <mi>F</mi>
    <msub>
     <mi>F</mi>
     <mi>j</mi>
    </msub>
   </mrow>
   <mo stretchy="false">|</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <abs></abs>
    <apply>
     <times></times>
     <ci>F</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>F</ci>
      <ci>j</ci>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   |FF_{j}|
  </annotation>
 </semantics>
</math>

 is the number of connections to 

<math display="inline" id="Regulatory_feedback_network:11">
 <semantics>
  <msub>
   <mi>y</mi>
   <mi>j</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>y</ci>
    <ci>j</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   y_{j}
  </annotation>
 </semantics>
</math>

. Lets label 

<math display="inline" id="Regulatory_feedback_network:12">
 <semantics>
  <msub>
   <mi>s</mi>
   <mi>i</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>s</ci>
    <ci>i</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   s_{i}
  </annotation>
 </semantics>
</math>

 the salience of input 

<math display="inline" id="Regulatory_feedback_network:13">
 <semantics>
  <msub>
   <mi>x</mi>
   <mi>i</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>x</ci>
    <ci>i</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   x_{i}
  </annotation>
 </semantics>
</math>

. Then the activity of</p>

<p><code>the output node is determined by:</code></p>

<p>

<math display="inline" id="Regulatory_feedback_network:14">
 <semantics>
  <mrow>
   <mrow>
    <msub>
     <mi>y</mi>
     <mi>j</mi>
    </msub>
    <mrow>
     <mo stretchy="false">(</mo>
     <mrow>
      <mi>t</mi>
      <mo>+</mo>
      <mrow>
       <mi mathvariant="normal">Δ</mi>
       <mi>t</mi>
      </mrow>
     </mrow>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
   <mo>=</mo>
   <mrow>
    <mfrac>
     <mrow>
      <msub>
       <mi>y</mi>
       <mi>j</mi>
      </msub>
      <mrow>
       <mo stretchy="false">(</mo>
       <mi>t</mi>
       <mo stretchy="false">)</mo>
      </mrow>
     </mrow>
     <mrow>
      <mo stretchy="false">|</mo>
      <mrow>
       <mi>F</mi>
       <msub>
        <mi>F</mi>
        <mi>j</mi>
       </msub>
      </mrow>
      <mo stretchy="false">|</mo>
     </mrow>
    </mfrac>
    <mrow>
     <msub>
      <mo largeop="true" symmetric="true">∑</mo>
      <mrow>
       <mi>k</mi>
       <mo>∈</mo>
       <mrow>
        <mi>F</mi>
        <msub>
         <mi>F</mi>
         <mi>j</mi>
        </msub>
       </mrow>
      </mrow>
     </msub>
     <msub>
      <mi>s</mi>
      <mi>k</mi>
     </msub>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <times></times>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>y</ci>
      <ci>j</ci>
     </apply>
     <apply>
      <plus></plus>
      <ci>t</ci>
      <apply>
       <times></times>
       <ci>normal-Δ</ci>
       <ci>t</ci>
      </apply>
     </apply>
    </apply>
    <apply>
     <times></times>
     <apply>
      <divide></divide>
      <apply>
       <times></times>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <ci>y</ci>
        <ci>j</ci>
       </apply>
       <ci>t</ci>
      </apply>
      <apply>
       <abs></abs>
       <apply>
        <times></times>
        <ci>F</ci>
        <apply>
         <csymbol cd="ambiguous">subscript</csymbol>
         <ci>F</ci>
         <ci>j</ci>
        </apply>
       </apply>
      </apply>
     </apply>
     <apply>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <sum></sum>
       <apply>
        <in></in>
        <ci>k</ci>
        <apply>
         <times></times>
         <ci>F</ci>
         <apply>
          <csymbol cd="ambiguous">subscript</csymbol>
          <ci>F</ci>
          <ci>j</ci>
         </apply>
        </apply>
       </apply>
      </apply>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>s</ci>
       <ci>k</ci>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   y_{j}(t+\Delta t)=\frac{y_{j}(t)}{|FF_{j}|}\sum_{k\in FF_{j}}s_{k}
  </annotation>
 </semantics>
</math>

.<br/>
The salience value 

<math display="inline" id="Regulatory_feedback_network:15">
 <semantics>
  <msub>
   <mi>s</mi>
   <mi>i</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>s</ci>
    <ci>i</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   s_{i}
  </annotation>
 </semantics>
</math>

 of a given 

<math display="inline" id="Regulatory_feedback_network:16">
 <semantics>
  <msub>
   <mi>x</mi>
   <mi>i</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>x</ci>
    <ci>i</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   x_{i}
  </annotation>
 </semantics>
</math>

 is determined by:<br/>


<math display="inline" id="Regulatory_feedback_network:17">
 <semantics>
  <mrow>
   <msub>
    <mi>s</mi>
    <mi>i</mi>
   </msub>
   <mo>=</mo>
   <mfrac>
    <msub>
     <mi>x</mi>
     <mi>i</mi>
    </msub>
    <mrow>
     <mstyle displaystyle="false">
      <msub>
       <mo largeop="true" symmetric="true">∑</mo>
       <mrow>
        <mi>r</mi>
        <mo>∈</mo>
        <mrow>
         <mi>F</mi>
         <msub>
          <mi>B</mi>
          <mi>i</mi>
         </msub>
        </mrow>
       </mrow>
      </msub>
     </mstyle>
     <mrow>
      <msub>
       <mi>y</mi>
       <mi>r</mi>
      </msub>
      <mrow>
       <mo stretchy="false">(</mo>
       <mi>t</mi>
       <mo stretchy="false">)</mo>
      </mrow>
     </mrow>
    </mrow>
   </mfrac>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>s</ci>
     <ci>i</ci>
    </apply>
    <apply>
     <divide></divide>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>x</ci>
      <ci>i</ci>
     </apply>
     <apply>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <sum></sum>
       <apply>
        <in></in>
        <ci>r</ci>
        <apply>
         <times></times>
         <ci>F</ci>
         <apply>
          <csymbol cd="ambiguous">subscript</csymbol>
          <ci>B</ci>
          <ci>i</ci>
         </apply>
        </apply>
       </apply>
      </apply>
      <apply>
       <times></times>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <ci>y</ci>
        <ci>r</ci>
       </apply>
       <ci>t</ci>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   s_{i}=\frac{x_{i}}{\sum_{r\in{FB_{i}}}y_{r}(t)}
  </annotation>
 </semantics>
</math>

.<br/>
These equations can be iterated until the network reaches steady state.</p>
<h2 id="see-also">See also</h2>
<ul>
<li><a href="Visual_perception" title="wikilink">Visual perception</a></li>
<li><a href="Visual_Object_Recognition_in_Cognitive_Neuroscience" title="wikilink">Visual Object Recognition in Cognitive Neuroscience</a></li>
<li><a href="Bag_of_words_model_in_computer_vision" title="wikilink">Bag of words model in computer vision</a></li>
<li><a href="Computational_neuroscience" title="wikilink">Computational neuroscience</a></li>
</ul>
<h2 id="references">References</h2>
<references>
</references>

<p>"</p>

<p><a href="Category:Control_theory" title="wikilink">Category:Control theory</a> <a href="Category:Computational_neuroscience" title="wikilink">Category:Computational neuroscience</a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1">Mcfadden, F. E. (1995). "Convergence of Competitive Activation Models Based on Virtual Lateral Inhibition." Neural Networks 8(6): 865-875.<a href="#fnref1">↩</a></li>
<li id="fn2">Achler, T. (2002). Input Shunt Networks. Neurocomputing, 44, 249-255.<a href="#fnref2">↩</a></li>
<li id="fn3"></li>
<li id="fn4"></li>
<li id="fn5"><code>Achler</code> <code>T.,</code> <code>Amir</code> <code>E.,</code> <code>“Input</code> <code>Feedback</code> <code>Networks:</code> <code>Classification</code> <code>and</code> <code>Inference</code> <code>Based</code> <code>on</code> <code>Network</code> <code>Structure”</code> <code>Artificial</code> <code>General</code> <code>Intelligence</code> <code>2008</code> <a href="http://reason.cs.uiuc.edu/tsvi/AGI.pdf"><code>pdf</code></a><a href="#fnref5">↩</a></li>
<li id="fn6"></li>
<li id="fn7"></li>
<li id="fn8">Achler T., Omar C., Amir E., “Shedding Weights: More With Less”, IEEE Proc. International Joint Conference on Neural Networks, 2008 <a href="http://reason.cs.uiuc.edu/tsvi/IJCNN.pdf">pdf</a><a href="#fnref8">↩</a></li>
<li id="fn9"></li>
<li id="fn10">Achler T., Vural C., Amir, E., "Counting with Biologically Inspired Regulatory Feedback Networks”, IEEE Proc. International Joint Conference on Neural Networks, 2009 <a href="http://reason.cs.uiuc.edu/tsvi/counting.pdf">pdf</a><a href="#fnref10">↩</a></li>
<li id="fn11"></li>
<li id="fn12">Achler T., “Using Non-Oscillatory Dynamics to Disambiguate Simultaneous Patterns”, IEEE Proc. International Joint Conference on Neural Networks, 2009 <a href="http://reason.cs.uiuc.edu/tsvi/Dynamics%20for%20Disambiguation%20IJCNN%202009.pdf">pdf</a><a href="#fnref12">↩</a></li>
</ol>
</section>
</body>
</html>
