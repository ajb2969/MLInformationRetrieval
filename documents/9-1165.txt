   Variable-order Markov model      Variable-order Markov model   In stochastic processes , Variable-order Markov (VOM) models are an important class of models that extend the well known Markov chain models. In contrast to the Markov chain models, where each random variable in a sequence with a Markov property depends on a fixed number of random variables, in VOM models this number of conditioning random variables may vary based on the specific observed realization.  This realization sequence is often called the context ; therefore the VOM models are also called context trees . 1 The flexibility in the number of conditioning random variables turns out to be of real advantage for many applications, such as statistical analysis , classification and prediction . 2 3 4  Example  Consider for example a sequence of random variables , each of which takes a value from the ternary alphabet { a , b , c }. Specifically, consider the string aaabcaaabcaaabcaaabc...aaabc constructed from infinite concatenations of the sub-string aaabc .  The VOM model of maximal order 2 can approximate the above string using only the following five conditional probability components: {Pr( a | aa ) = 0.5, Pr( b | aa ) = 0.5, Pr( c | b ) = 1.0, Pr( a | c )= 1.0, Pr( a | ca )= 1.0}.  In this example, Pr( c | ab ) = Pr( c | b ) = 1.0; therefore, the shorter context b is sufficient to determine the next character. Similarly, the VOM model of maximal order 3 can generate the string exactly using only five conditional probability components, which are all equal to 1.0.  To construct the Markov chain of order 1 for the next character in that string, one must estimate the following 9 conditional probability components: {Pr( a | a ), Pr( a | b ), Pr( a | c ), Pr( b | a ), Pr( b | b ), Pr( b | c ), Pr( c | a ), Pr( c | b ), Pr( c | c )}. To construct the Markov chain of order 2 for the next character, one must estimate 27 conditional probability components: {Pr( a | aa ), Pr( a | ab ), ..., Pr( c | cc )}. And to construct the Markov chain of order three for the next character one must estimate the following 81 conditional probability components: {Pr( a | aaa ), Pr( a | aab ), ..., Pr( c | ccc )}.  In practical settings there is seldom sufficient data to accurately estimate the exponentially increasing number of conditional probability components as the order of the Markov chain increases.  The variable-order Markov model assumes that in realistic settings, there are certain realizations of states (represented by contexts) in which some past states are independent from the future states; accordingly, "a great reduction in the number of model parameters can be achieved." 5  Definition  Let   A   A   A   be a state space (finite alphabet ) of size |A|.  Consider a sequence with the Markov property      x  1  n   =    x  1    x  2   …   x  n         superscript   subscript  x  1   n      subscript  x  1    subscript  x  2   normal-…   subscript  x  n      x_{1}^{n}=x_{1}x_{2}\dots x_{n}   of   n   n   n   realizations of random variables , where     x  i   ∈  A       subscript  x  i   A    x_{i}\in A   is the state (symbol) at position   i   i   i   1≤   i   i   i   ≤   n   n   n   , and the concatenation of states    x  i     subscript  x  i    x_{i}   and    x   i  +  1      subscript  x    i  1     x_{i+1}   is denoted by     x  i    x   i  +  1         subscript  x  i    subscript  x    i  1      x_{i}x_{i+1}   .  Given a training set of observed states,    x  1  n     superscript   subscript  x  1   n    x_{1}^{n}   , the construction algorithm of the VOM models 6 7 8 learns a model   P   P   P   that provides a probability assignment for each state in the sequence given its past (previously observed symbols) or future states.  Specifically, the learner generates a conditional probability distribution     P   (   x  i   |  s  )      fragments  P   fragments  normal-(   subscript  x  i   normal-|  s  normal-)     P(x_{i}|s)   for a symbol     x  i   ∈  A       subscript  x  i   A    x_{i}\in A   given a context    s  ∈   A  *       s   superscript  A      s\in A^{*}   , where the * sign represents a sequence of states of any length, including the empty context.  VOM models attempt to estimate conditional distributions of the form    P   (   x  i   |  s  )      fragments  P   fragments  normal-(   subscript  x  i   normal-|  s  normal-)     P(x_{i}|s)   where the context length |   s   s   s   |≤   D   D   D   varies depending on the available statistics. In contrast, conventional Markov models attempt to estimate these conditional distributions by assuming a fixed contexts' length |   s   s   s   |=   D   D   D   and, hence, can be considered as special cases of the VOM models.  Effectively, for a given training sequence, the VOM models are found to obtain better model parameterization than the fixed-order Markov models that leads to a better variance -bias tradeoff of the learned models. 9 10 11  Application areas  Various efficient algorithms have been devised for estimating the parameters of the VOM model. 12  VOM models have been successfully applied to areas such as machine learning , information theory and bioinformatics , including specific applications such as coding and data compression , 13 document compression, 14 classification and identification of DNA and protein sequences , 15  1 16  statistical process control , 17  spam filtering , 18  haplotyping 19 and others.  See also   Examples of Markov chains  Variable order Bayesian network  Markov process  Markov chain Monte Carlo  Semi-Markov process  Artificial intelligence   References  "  Category:Markov models     ↩  ↩  ↩  ↩            ↩    ↩  Browning, Sharon R. "Multilocus association mapping using variable-length Markov chains." The American Journal of Human Genetics 78.6 (2006): 903-913. ↩     