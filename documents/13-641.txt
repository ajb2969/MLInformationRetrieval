   Antithetic variates      Antithetic variates   In statistics , the antithetic variates method is a variance reduction technique used in Monte Carlo methods . Considering that the error reduction in the simulated signal (using Monte Carlo methods ) has a square root  convergence , a very large number of sample paths is required to obtain an accurate result. The antithetic variates method reduces the variance of the simulation results.  Underlying principle  The antithetic variates technique consists, for every sample path obtained, in taking its antithetic path — that is given a path    {   ε  1   ,  …  ,   ε  M   }      subscript  ε  1   normal-…   subscript  ε  M     \{\varepsilon_{1},\dots,\varepsilon_{M}\}   to also take    {   -   ε  1    ,  …  ,   -   ε  M    }        subscript  ε  1    normal-…     subscript  ε  M      \{-\varepsilon_{1},\dots,-\varepsilon_{M}\}   . The advantage of this technique is twofold: it reduces the number of normal samples to be taken to generate N paths, and it reduces the variance of the sample paths, improving the accuracy.  Suppose that we would like to estimate      θ  =   E   (   h   (  X  )    )    =   E   (  Y  )          θ    normal-E    h  X           normal-E  Y      \theta=\mathrm{E}(h(X))=\mathrm{E}(Y)\,     For that we have generated two samples       Y  1   and    Y  2         subscript  Y  1   and   subscript  Y  2     Y_{1}\text{ and }Y_{2}\,     An unbiased estimate of   θ   θ   {\theta}   is given by        θ  ^   =      θ  ^   1   +    θ  ^   2    2    .       normal-^  θ        subscript   normal-^  θ   1    subscript   normal-^  θ   2    2     \hat{\theta}=\frac{\hat{\theta}_{1}+\hat{\theta}_{2}}{2}.     And       Var   (   θ  ^   )    =     Var   (   Y  1   )    +   Var   (   Y  2   )    +   2  Cov   (   Y  1   ,   Y  2   )     4         Var   normal-^  θ          Var   subscript  Y  1      Var   subscript  Y  2      2  Cov    subscript  Y  1    subscript  Y  2      4     \text{Var}(\hat{\theta})=\frac{\text{Var}(Y_{1})+\text{Var}(Y_{2})+2\text{Cov}%
 (Y_{1},Y_{2})}{4}     In the case where Y 1 and Y 2 are independently and identically distributed , the covariance is zero and     Var   (   Y  1   )    =   Var   (   Y  2   )          Var   subscript  Y  1      Var   subscript  Y  2      \text{Var}(Y_{1})=\text{Var}(Y_{2})   , therefore        Var   (   θ  ^   )    =    Var   (   Y  1   )    2   =    Var   (   Y  2   )    2    .          Var   normal-^  θ        Var   subscript  Y  1    2            Var   subscript  Y  2    2      \text{Var}(\hat{\theta})=\frac{\text{Var}(Y_{1})}{2}=\frac{\text{Var}(Y_{2})}{%
 2}.     The antithetic variates technique consists in this case of choosing the second sample in such a way that    Y  1     subscript  Y  1    Y_{1}   and    Y  2     subscript  Y  2    Y_{2}   are not iid anymore and    C  o  v   (   Y  1   ,   Y  2   )       C  o  v    subscript  Y  1    subscript  Y  2      Cov(Y_{1},Y_{2})   is negative. As a result,    Var   (   θ  ^   )       Var   normal-^  θ     \text{Var}(\hat{\theta})   is reduced and is smaller than the previous normal variance       Var   (   Y  1   )    2   =    Var   (   Y  2   )    2           Var   subscript  Y  1    2       Var   subscript  Y  2    2     \frac{\text{Var}(Y_{1})}{2}=\frac{\text{Var}(Y_{2})}{2}   .  Example 1  If the law of the variable X follows a uniform distribution along [0, 1], the first sample will be     u  1   ,  …  ,   u  n       subscript  u  1   normal-…   subscript  u  n     u_{1},\ldots,u_{n}   , where, for any given i ,    u  i     subscript  u  i    u_{i}   is obtained from U (0, 1). The second sample is built from     u  1  ′   ,  …  ,   u  n  ′       subscript   superscript  u  normal-′   1   normal-…   subscript   superscript  u  normal-′   n     u^{\prime}_{1},\ldots,u^{\prime}_{n}   , where, for any given i      u  i  ′   =   1  -   u  i         subscript   superscript  u  normal-′   i     1   subscript  u  i      u^{\prime}_{i}=1-u_{i}   . If the set    u  1     subscript  u  1    u_{1}   is uniform along [0, 1], so are    u  i  ′     subscript   superscript  u  normal-′   i    u^{\prime}_{i}   . Furthermore, covariance is negative, allowing for initial variance reduction.  Example 2: integral calculation  We would like to estimate       I  =    ∫  0  1      1   1  +  x     d  x     .      I    superscript   subscript   0   1       1    1  x    normal-d  x      I=\int_{0}^{1}\frac{1}{1+x}\,\mathrm{d}x.     The exact result is    I  =   ln  2   ≈  0.69314718        I    2        0.69314718     I=\ln 2\approx 0.69314718   . This integral can be seen as the expected value of    f   (  U  )       f  U    f(U)   , where       f   (  x  )    =   1   1  +  x          f  x     1    1  x      f(x)=\frac{1}{1+x}     and U follows a uniform distribution [0, 1].  The following table compares the classical Monte Carlo estimate (sample size: 2 n , where n = 1500) to the antithetic variates estimate (sample size: n , completed with the transformed sample 1 − u i ):         Estimate   Variance     Classical Estimate   0.69365   0.02005     ''Antithetic Variates ''   0.69399   0.00063       The use of the antithetic variates method to estimate the result shows an important variance reduction.  "  Category:Variance reduction  Category:Computational statistics  Category:Monte Carlo methods   