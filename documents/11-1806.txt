   Tweedie distribution      Tweedie distribution   In probability and statistics , the Tweedie distributions are a family of probability distributions which include the purely continuous normal and gamma distributions, the purely discrete scaled Poisson distribution , and the class of mixed compound Poisson–gamma distributions which have positive mass at zero, but are otherwise continuous. 1 For any random variable  Y that obeys a Tweedie distribution, the variance var( Y ) relates to the mean E( Y ) by the power law,         var    (  Y  )    =   a    [    E    (  Y  )    ]   p     ,        var  Y     a   superscript   delimited-[]    E  Y    p      \text{var}\,(Y)=a[\text{E}\,(Y)]^{p},     where a and p are positive constants.  The Tweedie distributions were named by Bent Jørgensen 2 after Maurice Tweedie , a statistician and medical physicist at the University of Liverpool , UK, who presented the first thorough study of these distributions in 1984. 3 4  Examples  The Tweedie distributions include a number of familiar distributions as well as some unusual ones, each being specified by the domain of the index parameter. We have the   normal distribution , p = 0,    Poisson distribution , p = 1,    compound Poisson–gamma distribution, 1 < p < 2,    gamma distribution , p = 2,    positive stable distributions , 2 < p < 3,    inverse Gaussian distribution , p = 3,    positive stable distributions, p > 3, and    extreme stable distributions, p = .   For 0  The term exponential dispersion model refers to the exponential form that these models take, evident from the canonical equation used to describe the distribution P λ,θ of the random variable Z on the measurable sets  A ,       P   λ  ,  θ     (  Z  ∈  A  )   =   ∫  A   exp   [  θ  ⋅  z  -  λ  κ   (  θ  )   ]   ⋅    ν  λ     (  d  z  )   ,     fragments   subscript  P   λ  θ     fragments  normal-(  Z   A  normal-)     subscript   A     fragments  normal-[  θ  normal-⋅  z   λ  κ   fragments  normal-(  θ  normal-)   normal-]   normal-⋅   subscript  ν  λ    fragments  normal-(  d  z  normal-)   normal-,    P_{\lambda,\theta}(Z\in A)=\int_{A}\exp[\theta\cdot z-\lambda\kappa(\theta)]%
 \cdot\nu_{\lambda}\,(dz),     with the interrelated measures  ν λ . θ is the canonical parameter ; the cumulant function is        κ   (  θ  )    =    λ   -  1    log   ∫     e   θ  z    ⋅    ν  λ      (   d  z   )       ;        κ  θ      superscript  λ    1          normal-⋅   superscript  e    θ  z     subscript  ν  λ      d  z        \kappa(\theta)=\lambda^{-1}\log\int e^{\theta z}\cdot\nu_{\lambda}\,(dz);     λ is the index parameter; and z the canonical statistic. This equation represents a family of exponential dispersion models ED * ( θ , λ ) that are completely determined by the parameters θ and λ and the cumulant function.  Additive exponential dispersion models  The models just described are additive models with the property that the distribution of the sum of independent random variables,        Z  +   =    Z  1   +  ⋯  +   Z  n     ,       subscript  Z       subscript  Z  1   normal-⋯   subscript  Z  n      Z_{+}=Z_{1}+\cdots+Z_{n},     for which Z i ~ ED * ( θ , λ i ) with fixed θ and various λ are members of the family of distributions with the same θ ,        Z  +   ∼   E   D  *    (  θ  ,    λ  1   +  ⋯  +   λ  n    )     .     similar-to   subscript  Z      E   superscript  D     θ     subscript  λ  1   normal-⋯   subscript  λ  n        Z_{+}\sim ED^{*}(\theta,\lambda_{1}+\cdots+\lambda_{n}).     Reproductive exponential dispersion models  A second class of exponential dispersion models exists designated by the random variable       Y  =   Z  /  λ   ∼   E  D   (  μ  ,   σ  2   )     ,        Y    Z  λ     similar-to      E  D   μ   superscript  σ  2        Y=Z/\lambda\sim ED(\mu,\sigma^{2}),     where σ 2 = 1/ λ , known as reproductive exponential dispersion models. They have the property that for n independent random variables Y i ~ ED( μ , σ 2 / w i ), with weighting factors w i and       w  =    ∑   i  =  1   n    w  i     ,      w    superscript   subscript     i  1    n    subscript  w  i      w=\sum_{i=1}^{n}w_{i},     a weighted average of the variables gives,         w   -  1      ∑   i  =  1   n     w  i    Y  i      ∼   E  D   (  μ  ,    σ  2   /  w   )     .     similar-to     superscript  w    1      superscript   subscript     i  1    n      subscript  w  i    subscript  Y  i        E  D   μ     superscript  σ  2   w       w^{-1}\sum_{i=1}^{n}w_{i}Y_{i}\sim ED(\mu,\sigma^{2}/w).     For reproductive models the weighted average of independent random variables with fixed μ and σ 2 and various values for w i is a member of the family of distributions with same μ and σ 2 .  The Tweedie exponential dispersion models are both additive and reproductive; we thus have the duality transformation       Y  ↦  Z  =   Y  /   σ  2     .       maps-to  Y  Z         Y   superscript  σ  2       Y\mapsto Z=Y/\sigma^{2}.     Scale invariance  A third property of the Tweedie models is that they are scale invariant : For a reproductive exponential dispersion model ED( μ , σ 2 ) and any positive constant c we have the property of closure under scale transformation,        c  E  D   (  μ  ,   σ  2   )    =   E  D   (   c  μ   ,    c   2  -  p     σ  2    )     ,        c  E  D   μ   superscript  σ  2       E  D     c  μ      superscript  c    2  p     superscript  σ  2        cED(\mu,\sigma^{2})=ED(c\mu,c^{2-p}\sigma^{2}),     where the index parameter p is a real-valued unitless constant. With this transformation the new variable Y’ = cY belongs to the family of distributions with fixed μ and σ 2 but different values of c .  The Tweedie power variance function  To define the variance function for exponential dispersion models we make use of the mean value mapping, the relationship between the canonical parameter θ and the mean μ . It is define by the function        τ   (  θ  )    =    κ  ′    (  θ  )    =  μ   .          τ  θ      superscript  κ  normal-′   θ        μ     \tau(\theta)=\kappa^{\prime}(\theta)=\mu.     The variance function  V ( μ ) is constructed from the mean value mapping,        V   (  μ  )    =    τ  ′    [    τ   -  1     (  μ  )    ]     .        V  μ      superscript  τ  normal-′    delimited-[]     superscript  τ    1    μ       V(\mu)=\tau^{\prime}[\tau^{-1}(\mu)].     Here the minus exponent in τ −1 ( μ ) denotes an inverse function rather than a reciprocal. The mean and variance of an additive random variable is then E( Z ) = λμ and var( Z )=λV( μ ).  Scale invariance implies that the variance function obeys the relationship V ( μ ) = μ p . 5  The Tweedie cumulant generating functions  The properties of exponential dispersion models give us two differential equations . 6 The first relates the mean value mapping and the variance function to each other,          ∂   τ   -  1      (  μ  )     ∂  μ    =   1   V   (  μ  )      .             superscript  τ    1     μ     μ      1    V  μ      \frac{\partial\tau^{-1}(\mu)}{\partial\mu}=\frac{1}{V(\mu)}.     The second shows how the mean value mapping is related to the cumulant function ,          ∂  κ    (  θ  )     ∂  θ    =   τ   (  θ  )     .            κ   θ     θ      τ  θ     \frac{\partial\kappa(\theta)}{\partial\theta}=\tau(\theta).     These equations can be solved to obtain the cumulant function for different cases of the Tweedie models. A cumulant generating function (CGF) may then be obtained from the cumulant function. The additive CGF is generally specified by the equation         K  *    (  s  )    =   log   [   E   (   e   s  Z    )    ]    =   λ   [    κ   (   θ  +  s   )    -   κ   (  θ  )     ]     ,           superscript  K    s       E   superscript  e    s  Z             λ   delimited-[]      κ    θ  s      κ  θ         K^{*}(s)=\log[\text{E}(e^{sZ})]=\lambda[\kappa(\theta+s)-\kappa(\theta)],     and the reproductive CGF by        K   (  s  )    =   log   [   E   (   e   s  Y    )    ]    =   λ   [    κ   (   θ  +   s  /  λ    )    -   κ   (  θ  )     ]     ,          K  s       E   superscript  e    s  Y             λ   delimited-[]      κ    θ    s  λ       κ  θ         K(s)=\log[\text{E}(e^{sY})]=\lambda[\kappa(\theta+s/\lambda)-\kappa(\theta)],     where s is the generating function variable.  The cumulant functions for specific values of the index parameter p are 7        κ  p    (  θ  )    =   {        α  -  1   α     (   θ   α  -  1    )   α         p   ≠   1  ,  2    ,        -   log   (   -  θ   )          p   =  2   ,        e  θ        p   =  1   ,              subscript  κ  p   θ    cases        α  1   α    superscript    θ    α  1    α      p   1  2          θ       p  2    superscript  e  θ     p  1      \kappa_{p}(\theta)=\begin{cases}\dfrac{\alpha-1}{\alpha}\left(\dfrac{\theta}{%
 \alpha-1}\right)^{\alpha}&\quad p\neq 1,2,\\
 -\log(-\theta)&\quad p=2,\\
 e^{\theta}&\quad p=1,\end{cases}     where α is the Tweedie exponent       α  =    p  -  2    p  -  1     .      α      p  2     p  1      \alpha=\dfrac{p-2}{p-1}.     For the additive Tweedie models the CGFs take the form,        K  p  *    (  s  ;  θ  ,  λ  )    =   {      λ   κ  p    (  θ  )    [     (   1  +   s  /  θ    )   α   -  1   ]         p   ≠   1  ,  2    ,        -   λ   log   (   1  +   s  /  θ    )           p   =  2   ,        λ   e  θ    (    e  s   -  1   )         p   =  1   ,              subscript   superscript  K    p    s  θ  λ     cases    λ   subscript  κ  p   θ   delimited-[]     superscript    1    s  θ    α   1       p   1  2        λ      1    s  θ         p  2     λ   superscript  e  θ      superscript  e  s   1      p  1      K^{*}_{p}(s;\theta,\lambda)=\begin{cases}\lambda\kappa_{p}(\theta)[(1+s/\theta%
 )^{\alpha}-1]&\quad p\neq 1,2,\\
 -\lambda\log(1+s/\theta)&\quad p=2,\\
 \lambda e^{\theta}(e^{s}-1)&\quad p=1,\end{cases}     and for the reproductive models,        K  p    (  s  ;  θ  ,  λ  )    =   {      λ   κ  p    (  θ  )    {     [   1  +   s  /   (   θ  λ   )     ]   α   -  1   }         p   ≠   1  ,  2    ,        -   λ   log   [   1  +   s  /   (   θ  λ   )     ]           p   =  2   ,        λ   e  θ    (    e   s  /  λ    -  1   )        p   =  1.              subscript  K  p    s  θ  λ     cases    λ   subscript  κ  p   θ      superscript   delimited-[]    1    s    θ  λ      α   1       p   1  2        λ      1    s    θ  λ          p  2     λ   superscript  e  θ      superscript  e    s  λ    1      p  1.      K_{p}(s;\theta,\lambda)=\begin{cases}\lambda\kappa_{p}(\theta)\left\{[1+s/(%
 \theta\lambda)]^{\alpha}-1\right\}&\quad p\neq 1,2,\\
 -\lambda\log[1+s/(\theta\lambda)]&\quad p=2,\\
 \lambda e^{\theta}(e^{s/\lambda}-1)&\quad p=1.\end{cases}     The additive and reproductive Tweedie models are conventionally denoted by the symbols Tw * p ( θ , λ ) and Tw p ( θ , σ 2 ), respectively.  The first and second derivatives of the CGFs, with s = 0, yields the mean and variance, respectively. One can thus confirm that for the additive models the variance relates to the mean by the power law,        var   (  Z  )    ∝   E    (  Z  )   p     .     proportional-to    var  Z     normal-E   superscript  Z  p      \mathrm{var}(Z)\propto\mathrm{E}(Z)^{p}.     The Tweedie convergence theorem  The Tweedie exponential dispersion models are fundamental in statistical theory consequent to their roles as foci of convergence for a wide range of statistical processes. Jørgensen et al proved a theorem that specifies the asymptotic behaviour of variance functions known as the Tweedie convergence theorem". 8 This theorem, in technical terms, is stated thus: 9 The unit variance function is regular of order p at zero (or infinity) provided that V ( μ ) ~ c 0 μ p for μ as it approaches zero (or infinity) for all real values of p and c 0 > 0. Then for a unit variance function regular of order p at either zero or infinity and for       p  ∉   (  0  ,  1  )    ,      p   0  1     p\notin(0,1),     for any    μ  >  0      μ  0    \mu>0   , and     σ  2   >  0       superscript  σ  2   0    \sigma^{2}>0   we have        c   -  1    E  D   (   c  μ   ,    σ  2    c   2  -  p     )    →   T   w  p    (  μ  ,    c  0    σ  2    )       normal-→     superscript  c    1    E  D     c  μ      superscript  σ  2    superscript  c    2  p         T   subscript  w  p    μ     subscript  c  0    superscript  σ  2        c^{-1}ED(c\mu,\sigma^{2}c^{2-p})\rightarrow Tw_{p}(\mu,c_{0}\sigma^{2})     as    c  ↓  0     normal-↓  c  0    c\downarrow 0   or    c  →  ∞     normal-→  c     c\rightarrow\infty   , respectively, where the convergence is through values of c such that cμ is in the domain of θ and c p −2 / σ 2 is in the domain of λ . The model must be infinitely divisible as c 2− p approaches infinity. 10  In nontechnical terms this theorem implies that any exponential dispersion model that asymptotically manifests a variance-to-mean power law is required to have a variance function that comes within the domain of attraction of a Tweedie model. Almost all distribution functions with finite cumulant generating functions qualify as exponential dispersion models and most exponential dispersion models manifest variance functions of this form. Hence many probability distributions have variance functions that express this asymptotic behavior, and the Tweedie distributions become foci of convergence for a wide range of data types. 11  The Tweedie models and Taylor’s power law  Taylor's law is an empirical law in ecology that relates the variance of the number of individuals of a species per unit area of habitat to the corresponding mean by a power-law relationship. 12 For the population count Y with mean µ and variance var( Y ), Taylor’s law is written,         var    (  Y  )    =   a   μ  p     ,        var  Y     a   superscript  μ  p      \text{var}\,(Y)=a\mu^{p},     where a and p are both positive constants. Since L. R. Taylor described this law in 1961 there have been many different explanations offered to explain it, ranging from animal behavior, 13 a random walk model, 14 a stochastic birth, death, immigration and emigration model , 15 to a consequence of equilibrium and non-equilibrium statistical mechanics . 16 No consensus exists as to an explanation for this model.  Since Taylor’s law is mathematically identical to the variance-to-mean power law that characterizes the Tweedie models, it seemed reasonable to use these models and the Tweedie convergence theorem to explain the observed clustering of animals and plants associated with Taylor’s law. 17 18 The majority of the observed values for the power-law exponent p have fallen in the interval (1,2) and so the Tweedie compound Poisson–gamma distribution would seem applicable. Comparison of the empirical distribution function to the theoretical compound Poisson–gamma distribution has provided a means to verify consistency of this hypothesis. 19  Whereas conventional models for Taylor’s law have tended to involve ad hoc animal behavioral or population dynamic assumptions, the Tweedie convergence theorem would imply that Taylor’s law results from a general mathematical convergence effect much as how the central limit theorem governs the convergence behavior of certain types of random data. Indeed, any mathematical model, approximation or simulation that is designed to yield Taylor’s law (on the basis of this theorem) is required to converge to the form of the Tweedie models. 20  Tweedie convergence and 1/ f noise  Pink noise , or 1/ f noise, refers to a pattern of noise characterized by a power-law relationship between its intensities S ( f ) at different frequencies f ,        S   (  f  )    ∝   1  /   f  γ     ,     proportional-to    S  f     1   superscript  f  γ      S(f)\propto 1/f^{\gamma},     where the dimensionless exponent γ ∈ [0,1]. It is found within a diverse number of natural processes. 21 Many different explanations for 1/ f noise exist, a widely held hypothesis is based on Self-organized criticality where dynamical systems close to a critical point are thought to manifest scale-invariant spatial and/or temporal behavior.  In this subsection a mathematical connection between 1/ f noise and the Tweedie variance-to-mean power law will be described. To begin, we first need to introduce self-similar processes : For the sequence of numbers      Y  =   (   Y  i   :  i  =  0  ,  1  ,  2  ,  …  ,  N  )      fragments  Y    fragments  normal-(   subscript  Y  i   normal-:  i   0  normal-,  1  normal-,  2  normal-,  normal-…  normal-,  N  normal-)     Y=(Y_{i}:i=0,1,2,\ldots,N)     with mean        μ  ^   =   E   (   Y  i   )     ,       normal-^  μ     E   subscript  Y  i      \hat{\mu}=\text{E}(Y_{i}),     deviations        y  i   =    Y  i   -   μ  ^     ,       subscript  y  i      subscript  Y  i    normal-^  μ      y_{i}=Y_{i}-\hat{\mu},     variance         σ  ^   2   =   E   (   y  i  2   )     ,       superscript   normal-^  σ   2     E   superscript   subscript  y  i   2      \hat{\sigma}^{2}=\text{E}(y_{i}^{2}),     and autocorrelation function       r   (  k  )    =     E   (   y  i   ,   y   i  +  k    )    /  E    (   y  i  2   )          r  k         E    subscript  y  i    subscript  y    i  k      E    superscript   subscript  y  i   2      r(k)=\text{E}(y_{i},y_{i+k})/\text{E}(y_{i}^{2})     with lag k , if the autocorrelation of this sequence has the long range behavior       r   (  k  )    ∼    k   -  d    L   (  k  )       similar-to    r  k      superscript  k    d    L  k     r(k)\sim k^{-d}L(k)     as k and where L ( k ) is a slowly varying function at large values of k , this sequence is called a self-similar process. 22  The method of expanding bins can be used to analyze self-similar processes. Consider a set of equal-sized non-overlapping bins that divides the original sequence of N elements into groups of m equal-sized segments ( N/m is integer) so that new reproductive sequences, based on the mean values, can be defined:        Y  i   (  m  )    =    (    Y     i  m   -  m   +  1    +  ⋯  +   Y   i  m     )   /  m    .       superscript   subscript  Y  i   m        subscript  Y        i  m   m   1    normal-⋯   subscript  Y    i  m     m     Y_{i}^{(m)}=(Y_{im-m+1}+\cdots+Y_{im})/m.     The variance determined from this sequence will scale as the bin size changes such that       var   [   Y   (  m  )    ]    =     σ  ^   2    m   -  d           var   delimited-[]   superscript  Y  m        superscript   normal-^  σ   2    superscript  m    d       \text{var}[Y^{(m)}]=\hat{\sigma}^{2}m^{-d}     if and only if the autocorrelation has the limiting form 23        lim   k  →  ∞      r   (  k  )    /   k   -  d      =     (   2  -  d   )    (   1  -  d   )    /  2.         subscript    normal-→  k         r  k    superscript  k    d            2  d     1  d    2.     \lim_{k\to\infty}r(k)/k^{-d}=(2-d)(1-d)/2.     One can also construct a set of corresponding additive sequences        Z  i   (  m  )    =   m   Y  i   (  m  )      ,       superscript   subscript  Z  i   m     m   superscript   subscript  Y  i   m      Z_{i}^{(m)}=mY_{i}^{(m)},     based on the expanding bins,        Z  i   (  m  )    =   (    Y     i  m   -  m   +  1    +  ⋯  +   Y   i  m     )    .       superscript   subscript  Z  i   m      subscript  Y        i  m   m   1    normal-⋯   subscript  Y    i  m       Z_{i}^{(m)}=(Y_{im-m+1}+\cdots+Y_{im}).     Provided the autocorrelation function exhibits the same behavior, the additive sequences will obey the relationship       var   [   Z  i   (  m  )    ]    =    m  2   var   [   Y   (  m  )    ]    =    (     σ  ^   2   /    μ  ^    2  -  d     )   E    [   Z  i   (  m  )    ]    2  -  d             var   delimited-[]   superscript   subscript  Z  i   m        superscript  m  2   var   delimited-[]   superscript  Y  m               superscript   normal-^  σ   2    superscript   normal-^  μ     2  d     E   superscript   delimited-[]   superscript   subscript  Z  i   m      2  d        \text{var}[Z_{i}^{(m)}]=m^{2}\text{var}[Y^{(m)}]=(\hat{\sigma}^{2}/\hat{\mu}^{%
 2-d})\text{E}[Z_{i}^{(m)}]^{2-d}     Since    μ  ^     normal-^  μ    \hat{\mu}   and     σ  ^   2     superscript   normal-^  σ   2    \hat{\sigma}^{2}   are constants this relationship constitutes a variance-to-mean power law, with p = 2 - d . 24 25  The biconditional relationship above between the variance-to-mean power law and power law autocorrelation function, and the Wiener–Khinchin theorem 26 imply that any sequence that exhibits a variance-to-mean power law by the method of expanding bins will also manifest 1/ f noise, and vice versa. Moreover, the Tweedie convergence theorem, by virtue of its central limit-like effect of generating distributions that manifest variance-to-mean power functions, will also generate processes that manifest 1/ f noise. 27 The Tweedie convergence theorem thus allows provides an alternative explanation for the origin of 1/ f noise, based its central limit-like effect.  Much as the central limit theorem requires certain kinds of random processes to have as a focus of their convergence the Gaussian distribution and thus express white noise , the Tweedie convergence theorem requires certain non-Gaussian processes to have as a focus of convergence the Tweedie distributions that express 1/ f noise. 28  The Tweedie models and multifractality  From the properties of self-similar processes, the power-law exponent p = 2 - d is related to the Hurst exponent  H and the fractal dimension  D by 29      D  =   2  -  H   =   2  -   p  /  2.          D    2  H          2    p  2.       D=2-H=2-p/2.     A one-dimensional data sequence of self-similar data may demonstrate a variance-to-mean power law with local variations in the value of p and hence in the value of D . When fractal structures manifest local variations in fractal dimension, they are said to be multifractals . Examples of data sequences that exhibit local variations in p like this include the eigenvalue deviations of the Gaussian Orthogonal and Unitary Ensembles . 30 The Tweedie compound Poisson–gamma distribution has served to model multifractality based on local variations in the Tweedie exponent α . Consequently, in conjunction with the variation of α , the Tweedie convergence theorem can be viewed as having a role in the genesis of such multifractals.  The variation of α has been found to obey the asymmetric Laplace distribution in certain cases. 31 This distribution has been shown to be a member of the family of geometric Tweedie models, 32 that manifest as limiting distributions in a convergence theorem for geometric dispersion models.  Applications  Regional organ blood flow  Regional organ blood flow has been traditionally assessed by the injection of radiolabelled  polyethylene microspheres into the arterial circulation of animals, of a size that they become entrapped within the microcirculation of organs. The organ to be assessed is then divided into equal-sized cubes and the amount of radiolabel within each cube is evaluated by liquid scintillation counting and recorded. The amount of radioactivity within each cube is taken to reflect the blood flow through that sample at the time of injection. It is possible to evaluate adjacent cubes from an organ in order to additively determine the blood flow through larger regions. Through the work of J B Bassingthwaighte and others an empirical power law has been derived between the relative dispersion of blood flow of tissue samples ( RD = standard deviation/mean) of mass m relative to reference-sized samples: 33       R  D   (  m  )    =   R  D   (   m  ref   )     (   m   m  ref    )    1  -   D  s            R  D  m     R  D   subscript  m  ref    superscript    m   subscript  m  ref      1   subscript  D  s        RD(m)=RD(m_{\text{ref}})\left(\frac{m}{m_{\text{ref}}}\right)^{1-D_{s}}     This power law exponent D s has been called a fractal dimension. Bassingthwaighte’s power law can be shown to directly relate to the variance-to-mean power law. Regional organ blood flow can thus be modelled by the Tweedie compound Poisson–gamma distribution., 34 In this model tissue sample could be considered to contain a random (Poisson) distributed number of entrapment sites, each with gamma distributed blood flow. Blood flow at this microcirculatory level has been observed to obey a gamma distribution, 35 thus providing support for this hypothesis.  Cancer metastasis  The "experimental cancer metastasis assay" 36 has some resemblance to the above method to measure regional blood flow. Groups of syngeneic and age matched mice are given intravenous injections of equal-sized aliquots of suspensions of cloned cancer cells and then after a set period of time their lungs are removed and the number of cancer metastases enumerated within each pair of lungs. If other groups of mice are injected with different cancer cell clones then the number of metastases per group will differ in accordance with the metastatic potentials of the clones. It has been long recognized that there can be considerable intraclonal variation in the numbers of metastases per mouse despite the best attempts to keep the experimental conditions within each clonal group uniform. 37 This variation is larger than would be expected on the basis of a Poisson distribution of numbers of metastases per mouse in each clone and when the variance of the number of metastases per mouse was plotted against the corresponding mean a power law was found. 38  The variance-to-mean power law for metastases was found to also hold for spontaneous murine metastases 39 and for cases series of human metastases. 40 Since hematogenous metastasis occurs in direct relationship to regional blood flow 41 and videomicroscopic studies indicate that the passage and entrapment of cancer cells within the circulation appears analogous to the microsphere experiments 42 it seemed plausible to propose that the variation in numbers of hematogenous metastases could reflect heterogeneity in regional organ blood flow. 43 The blood flow model was based on the Tweedie compound Poisson–gamma distribution, a distribution governing a continuous random variable. For that reason in the metastasis model it was assumed that blood flow was governed by that distribution and that the number of regional metastases occurred as a Poisson process for which the intensity was directly proportional to blood flow. This lead to the description of the Poisson negative binomial (PNB) distribution as a discrete equivalent to the Tweedie compound Poisson–gamma distribution. The probability generating function for the PNB distribution is       G   (  s  )    =   exp   [   λ    α  -  1   α     (   θ   α  -  1    )   α    {     (    1  -   1  θ    +   s  θ    )   α   -  1   }    ]          G  s       λ      α  1   α    superscript    θ    α  1    α       superscript      1    1  θ      s  θ    α   1        G(s)=\exp\left[\lambda\frac{\alpha-1}{\alpha}\left(\frac{\theta}{\alpha-1}%
 \right)^{\alpha}\left\{\left(1-\frac{1}{\theta}+\frac{s}{\theta}\right)^{%
 \alpha}-1\right\}\right]     The relationship between the mean and variance of the PNB distribution is then         var    (  Y  )    =    a  E    (  Y  )   b    +   E   (  Y  )      ,        var  Y       a  E   superscript  Y  b      E  Y      \text{var}\,(Y)=a\text{E}(Y)^{b}+\text{E}(Y),     which, in the range of many experimental metastasis assays, would be indistinguishable from the variance-to-mean power law. For sparse data, however, this discrete variance-to-mean relationship would behave more like that of a Poisson distribution where the variance equaled the mean.  Genomic structure and evolution  The local density of Single Nucleotide Polymorphisms (SNPs) within the human genome , as well as that of genes , appears to cluster in accord with the variance-to-mean power law and the Tweedie compound Poisson–gamma distribution. 44 45 In the case of SNPs their observed density reflects the assessment techniques, the availability of genomic sequences for analysis, and the nucleotide heterozygosity . 46 The first two factors reflect ascertainment errors inherent to the collection methods, the latter factor reflects an intrinsic property of the genome.  In the coalescent model of population genetics each genetic locus has its own unique history. Within the evolution of a population from some species some genetic loci could presumably be traced back to a relatively recent common ancestor whereas other loci might have more ancient genealogies . More ancient genomic segments would have had more time to accumulate SNPs and to experience recombination . R R Hudson has proposed a model where recombination could cause variation in the time to most common recent ancestor for different genomic segments. 47 A high recombination rate could cause a chromosome to contain a large number of small segments with less correlated genealogies.  Assuming a constant background rate of mutation the number of SNPs per genomic segment would accumulate proportionately to the time to the most recent common ancestor. Current population genetic theory would indicate that these times would be gamma distributed , on average. 48 The Tweedie compound Poisson–gamma distribution would suggest a model whereby the SNP map would consist of multiple small genomic segments with the mean number of SNPs per segment would be gamma distributed as per Hudson’s model.  The distribution of genes within the human genome also demonstrated a variance-to-mean power law, when the method of expanding bins was used to determine the corresponding variances and means. 49 Similarly the number of genes per enumerative bin was found to obey a Tweedie compound Poisson–gamma distribution. This probability distribution was deemed compatible with two different biological models: the microarrangement model where the number of genes per unit genomic length was determined by the sum of a random number of smaller genomic segments derived by random breakage and reconstruction of protochormosomes. These smaller segments would be assumed to carry on average a gamma distributed number of genes.  In the alternative gene cluster model , genes would be distributed randomly within the protochromosomes. Over large evolutionary timescales there would occur tandem duplication , mutations, insertions, deletions and rearrangements that could affect the genes through a stochastic birth, death and immigration process to yield the Tweedie compound Poisson–gamma distribution.  Both these mechanisms would implicate neutral evolutionary processes that would result in regional clustering of genes.  Random matrix theory  The Gaussian unitary ensemble (GUE) consists of complex Hermitian matrices that are invariant under unitary transformations whereas the Gaussian orthogonal ensemble (GOE) consists of real symmetric matrices invariant under orthogonal transformations . The ranked eigenvalues  E n from these random matrices obey Wigner’s semicircular distribution : For a N × N matrix the average density for eigenvalues of size E will be        ρ  ¯    (  E  )    =   {         2  N   -   E  2     /  π       |  E  |   <    2  N         0      |  E  |   >    2  N                normal-¯  ρ   E    cases          2  N    superscript  E  2     π       E       2  N     0      E       2  N        \bar{\rho}(E)=\begin{cases}\sqrt{2N-E^{2}}/\pi&\quad\left|E\right|<\sqrt{2N}\\
 0&\quad\left|E\right|>\sqrt{2N}\end{cases}     as E . Integration of the semicircular rule provides the number of eigenvalues on average less than E ,         η  ¯    (  E  )    =    1   2  π     [    E     2  N   -   E  2      +   2  N   arcsin   (   E    2  N     )     +   π  N    ]     .         normal-¯  η   E       1    2  π     delimited-[]      E        2  N    superscript  E  2        2  N      E      2  N         π  N        \bar{\eta}(E)=\frac{1}{2\pi}\left[E\sqrt{2N-E^{2}}+2N\arcsin\left(\frac{E}{%
 \sqrt{2N}}\right)+\pi N\right].     The ranked eigenvalues can be unfolded , or renormalized, with the equation        e  n   =    η  ¯    (  E  )    =    ∫   -  ∞    E  n     d   E  ′    ρ  ¯    (   E  ′   )      .         subscript  e  n      normal-¯  η   E          superscript   subscript         subscript  E  n      d   superscript  E  normal-′    normal-¯  ρ    superscript  E  normal-′        e_{n}=\bar{\eta}(E)=\int\limits_{-\infty}^{E_{n}}dE^{\prime}\bar{\rho}(E^{%
 \prime}).     This removes the trend of the sequence from the fluctuating portion. If we look at the absolute value of the difference between the actual and expected cumulative number of eigenvalues       |    D  ¯   n   |   =   |   n  -    η  ¯    (   E  n   )     |          subscript   normal-¯  D   n        n     normal-¯  η    subscript  E  n        \left|\bar{D}_{n}\right|=\left|n-\bar{\eta}(E_{n})\right|     we obtain a sequence of eigenvalue fluctuations which, using the method of expanding bins, reveals a variance-to-mean power law. 50 The eigenvalue fluctuations of both the GUE and the GOE manifest this power law with the power law exponents ranging between 1 and 2, and they similarly manifest 1/ f noise spectra. These eigenvalue fluctuations also correspond to the Tweedie compound Poisson–gamma distribution and they exhibit multifractality. 51  The distribution of prime numbers  The second Chebyshev function  ψ ( x ) is given by,       ψ   (  x  )    =    ∑     p  ^   k   ≤  x     log   p  ^     =    ∑   n  ≤  x     Λ   (  n  )             ψ  x     subscript      superscript   normal-^  p   k   x       normal-^  p            subscript     n  x      normal-Λ  n       \psi(x)=\sum_{\hat{p}^{k}\leq x}\log\hat{p}=\sum_{n\leq x}\Lambda(n)     where the summation extends over all prime powers     p  ^   k     superscript   normal-^  p   k    \hat{p}^{k}   not exceeding x , x runs over the positive real numbers, and    Λ   (  n  )       normal-Λ  n    \Lambda(n)   is the von Mangoldt function . The function ψ ( x ) is related to the prime-counting function  π ( x ), and as such provides information with regards to the distribution of prime numbers amongst the real numbers. It is asymptotic to x , a statement equivalent to the prime number theorem and it can also be shown to be related to the zeros of the Riemann zeta function located on the critical strip ρ, where the real part of the zeta zero ρ is between 0 and 1. Then ψ expressed for x greater than one can be written:        ψ  0    (  x  )    =   x  -    ∑  ρ     x  ρ   ρ    -   ln   2  π    -    1  2    ln   (   1  -   x   -  2     )             subscript  ψ  0   x     x    subscript   ρ      superscript  x  ρ   ρ        2  π        1  2       1   superscript  x    2          \psi_{0}(x)=x-\sum_{\rho}\frac{x^{\rho}}{\rho}-\ln 2\pi-\frac{1}{2}\ln(1-x^{-2})     where         ψ  0    (  x  )    =    lim   ε  →  0       ψ   (   x  -  ε   )    +   ψ   (   x  +  ε   )     2     .         subscript  ψ  0   x     subscript    normal-→  ε  0          ψ    x  ε      ψ    x  ε     2      \psi_{0}(x)=\lim_{\varepsilon\rightarrow 0}\frac{\psi(x-\varepsilon)+\psi(x+%
 \varepsilon)}{2}.     The Riemann hypothesis states that the nontrivial zeros of the Riemann zeta function all have real part ½. These zeta function zeros are related to the distribution of prime numbers . Schoenfeld 52 has shown that if the Riemann hypothesis is true then       Δ   (  x  )    =   |    ψ   (  x  )    -  x   |   <     x     log  2    (  x  )     /   (   8  π   )            normal-Δ  x         ψ  x   x               x     superscript   2   x      8  π       \Delta(x)=\left|\psi(x)-x\right|<\sqrt{x}\log^{2}(x)/(8\pi)     for all    x  >  73.2      x  73.2    x>73.2   . If we analyze the Chebyshev deviations Δ( n ) on the integers n using the method of expanding bins and plot the variance versus the mean a variance to mean power law can be demonstrated. 53 Moreover, these deviations correspond to the Tweedie compound Poisson-gamma distribution and they exhibit 1/ f noise.  Other applications  Applications of Tweedie distributions include:   actuarial studies 54 Renshaw, A. E. 1994.   Modelling the claims process in the presence of covariates. ASTIN Bulletin 24: 265–286. 55 56 57 Murphy, K. P., Brockman, M. J., and Lee,  P. K. W. (2000). Using generalized linear models to build dynamic  pricing systems. Casualty Actuarial Forum, Winter 2000. 58   assay analysis 59 60  survival analysis 61 62 63  ecology 64  analysis of alcohol consumption in British teenagers Gilchrist, R. and Drinkwater, D. 1999.   Fitting Tweedie models to data with probability of zero responses. Proceedings of the 14th International Workshop on Statistical Modelling, Graz, pp. 207–214.   medical applications Smyth, G. K. 1996.   Regression analysis of quantity data with exact zeros. Proceedings of the Second Australia--Japan Workshop on Stochastic Models  in Engineering, Technology and Management. Technology Management  Centre, University of Queensland, 572– 580.   meteorology and climatology 65 Hasan, M.M.; Dunn, P.K. (2010) "Two   Tweedie distributions that are near-optimal for modelling monthly rainfall in Australia", International Journal of Climatology ,   fisheries 66  Mertens function  67  self-organized criticality    References  Further reading   Kaas, R. (2005). "Compound Poisson distribution and GLM’s – Tweedie’s distribution" . In Proceedings of the Contact Forum "3rd Actuarial and Financial Mathematics Day" , pages 3–12. Brussels: Royal Flemish Academy of Belgium for Science and the Arts.  Ohlsson, E and Johansson, B. (2003) Exact Credibility and Tweedie Models , University of Stockholm, Research report, October 2003.    External links   Tweedie distributions. http://www.statsci.org/s/tweedie.html  Tweedie generalized linear model family. http://www.statsci.org/s/tweedief.html  Examples of use of the model. http://www.sci.usq.edu.au/staff/dunn/Datasets/tech-glms.html#Tweedie  tweeDEseq: R package for RNA-seq data analysis using the Poisson-Tweedie family of distributions. http://bioconductor.org/packages/2.9/bioc/html/tweeDEseq.html   "  continuous distributions  Category:Probability distributions  Category:Systems of probability distributions     ↩  ↩   ↩  ↩  ↩  ↩  ↩  ↩  ↩  ↩  ↩   ↩  ↩  ↩  ↩  ↩   ↩  ↩  ↩  ↩   ↩  McQuarrie DA (1976) Statistical mechanics [Harper & Row] ↩      ↩  ↩  ↩  ↩  ↩  ↩  ↩  ↩  ↩  ↩  ↩  ↩  ↩  ↩  ↩  ↩  ↩  ↩     ↩  ↩  ↩  ↩  Haberman, S., and Renshaw, A. E. 1998. Actuarial applications of generalized linear models. In Statistics in Finance, D. J. Hand and S. D. Jacka (eds), Arnold, London. ↩  Mildenhall, S. J. 1999. A systematic relationship between minimum bias and generalized linear models. 1999 Proceedings of the Casualty Actuarial Society 86: 393–487. ↩  ↩  ↩  ↩  ↩  ↩  ↩  ↩   ↩  ↩     