   Difference in differences      Difference in differences  '''Difference in differences''' (sometimes 'Difference-in-Differences', {{cite book |last=Angrist |first=J. D. |last2=Pischke |first2=J. S. |year=2008 |title=Mostly harmless econometrics: An empiricist's companion |publisher=Princeton University Press |location= |isbn=9780691120348 }} 'DID', {{cite journal |last=Abadie |first=A. |year=2005 |title=Semiparametric difference-in-differences estimators |journal=[[Review of Economic Studies]] |volume=72 |issue=1 |pages=1–19 |doi=10.1111/0034-6527.00321 }} or 'DD' {{cite journal |last=Bertrand |first=M. |last2=Duflo |first2=E. |authorlink2=Esther Duflo |last3=Mullainathan |first3=S. |year=2004 |title=How Much Should We Trust Differences-in-Differences Estimates? |journal=[[Quarterly Journal of Economics]] |volume=119 |issue=1 |pages=249–275 |doi=10.1162/003355304772839588 |jstor= }} ) is a [[statistics|statistical technique]] used in [[econometrics]]  and [[quan titative research|quantitative sociology]], which attempts to mimic an experimental research design using observational study data . It calculates the effect of a treatment (i.e., an explanatory variable or an independent variable) on an outcome (i.e., a response variable or dependent variable) by comparing the average change over time in the outcome variable for the treatment group to the average change over time for the control group. This method may be subject to certain biases ( mean reversion bias, etc.), although it is intended to eliminate some of the effect of selection bias . In contrast to a within-subjects estimate of the treatment effect (which measures differences over time) or a between-subjects estimate of the treatment effect (which measures the difference between the treatment and control groups), the DID measures the difference in the differences between the treatment and control group over time.  General definition  thumb|upright=1.3 Difference in differences requires data measured at two or more different time periods. In the example pictured, the treatment group is represented by the line P and the control group is represented by the line S. Both groups are measured on the outcome (dependent) variable at Time 1 before either group has received the treatment (i.e., the independent or explanatory variable), represented by the points P 1 and S 1 . The treatment group then receives or experiences the treatment and both groups are again measured after this at Time 2. Not all of the difference between the treatment and control groups at Time 2 (that is, the difference between P 2 and S 2 ) can be explained as being an effect of the treatment, because the treatment group and control group did not start out at the same point at Time 1. DID therefore calculates the "normal" difference in the outcome variable between the two groups (the difference that would still exist if neither group experienced the treatment), represented by the dotted line Q. (Notice that the slope from P 1 to Q is the same as the slope from S 1 to S 2 .) The treatment effect is the difference between the observed outcome and the "normal" outcome (the difference between P 2 and Q).  Formal definition  Consider the model        y   i  s  t     =    γ  s   +   λ  t   +   δ   D   s  t     +   ϵ   i  s  t          subscript  y    i  s  t       subscript  γ  s    subscript  λ  t     δ   subscript  D    s  t      subscript  ϵ    i  s  t       y_{ist}~{}=~{}\gamma_{s}+\lambda_{t}+\delta D_{st}+\epsilon_{ist}     where    y   i  s  t      subscript  y    i  s  t     y_{ist}   is the dependent variable for individual    i   i   i   , given   s   s   s   and   t   t   t   . The dimensions   s   s   s   and   t   t   t   may for example be country and time.    γ  s     subscript  γ  s    \gamma_{s}   and    λ  t     subscript  λ  t    \lambda_{t}   is then the vertical intercept for   s   s   s   and   t   t   t   respectively.    D   s  t      subscript  D    s  t     D_{st}   is a dummy variable indicating treatment status,   δ   δ   \delta   is the treatment effect, and    ϵ   i  s  t      subscript  ϵ    i  s  t     \epsilon_{ist}   is an error term .  Let         y  ¯    s  t     =    1  n     ∑   i  =  1   n    y   i  s  t           subscript   normal-¯  y     s  t        1  n     superscript   subscript     i  1    n    subscript  y    i  s  t        \overline{y}_{st}~{}=~{}\frac{1}{n}\sum_{i=1}^{n}y_{ist}   ,         γ  ¯   s    =    1  n     ∑   i  =  1   n     γ  s      =   γ  s          subscript   normal-¯  γ   s       1  n     superscript   subscript     i  1    n    subscript  γ  s           subscript  γ  s      \overline{\gamma}_{s}~{}=~{}\frac{1}{n}\sum_{i=1}^{n}\gamma_{s}~{}=~{}\gamma_{s}   ,         λ  ¯   t    =    1  n     ∑   i  =  1   n     λ  t      =   λ  t          subscript   normal-¯  λ   t       1  n     superscript   subscript     i  1    n    subscript  λ  t           subscript  λ  t      \overline{\lambda}_{t}~{}=~{}\frac{1}{n}\sum_{i=1}^{n}\lambda_{t}~{}=~{}%
 \lambda_{t}   ,         D  ¯    s  t     =    1  n     ∑   i  =  1   n     D   s  t       =   D   s  t           subscript   normal-¯  D     s  t        1  n     superscript   subscript     i  1    n    subscript  D    s  t            subscript  D    s  t       \overline{D}_{st}~{}=~{}\frac{1}{n}\sum_{i=1}^{n}D_{st}~{}=~{}D_{st}   ,         ϵ  ¯    s  t     =    1  n     ∑   i  =  1   n    ϵ   i  s  t           subscript   normal-¯  ϵ     s  t        1  n     superscript   subscript     i  1    n    subscript  ϵ    i  s  t        \overline{\epsilon}_{st}~{}=~{}\frac{1}{n}\sum_{i=1}^{n}\epsilon_{ist}   ,  and suppose for simplicity that    s  =   1  ,  2       s   1  2     s=1,2   and    t  =   1  ,  2       t   1  2     t=1,2   . Then       (     y  ¯   11   -    y  ¯   12    )   -   (     y  ¯   21   -    y  ¯   22    )          subscript   normal-¯  y   11    subscript   normal-¯  y   12       subscript   normal-¯  y   21    subscript   normal-¯  y   22      (\overline{y}_{11}-\overline{y}_{12})-(\overline{y}_{21}-\overline{y}_{22})        =    [    (    γ  1   +   λ  1   +   δ   D  11    +    ϵ  ¯   11    )   -   (    γ  1   +   λ  2   +   δ   D  12    +    ϵ  ¯   12    )    ]   -   [    (    γ  2   +   λ  1   +   δ   D  21    +    ϵ  ¯   21    )   -   (    γ  2   +   λ  2   +   δ   D  22    +    ϵ  ¯   22    )    ]        absent     delimited-[]       subscript  γ  1    subscript  λ  1     δ   subscript  D  11     subscript   normal-¯  ϵ   11       subscript  γ  1    subscript  λ  2     δ   subscript  D  12     subscript   normal-¯  ϵ   12       delimited-[]       subscript  γ  2    subscript  λ  1     δ   subscript  D  21     subscript   normal-¯  ϵ   21       subscript  γ  2    subscript  λ  2     δ   subscript  D  22     subscript   normal-¯  ϵ   22         =\left[(\gamma_{1}+\lambda_{1}+\delta D_{11}+\overline{\epsilon}_{11})-(\gamma%
 _{1}+\lambda_{2}+\delta D_{12}+\overline{\epsilon}_{12})\right]-\left[(\gamma_%
 {2}+\lambda_{1}+\delta D_{21}+\overline{\epsilon}_{21})-(\gamma_{2}+\lambda_{2%
 }+\delta D_{22}+\overline{\epsilon}_{22})\right]        =       δ   (    D  11   -   D  12    )    +   δ   (    D  22   -   D  21    )    +    ϵ  ¯   11    -    ϵ  ¯   12    +    ϵ  ¯   22    -    ϵ  ¯   21        absent            δ     subscript  D  11    subscript  D  12       δ     subscript  D  22    subscript  D  21      subscript   normal-¯  ϵ   11     subscript   normal-¯  ϵ   12     subscript   normal-¯  ϵ   22     subscript   normal-¯  ϵ   21      =\delta(D_{11}-D_{12})+\delta(D_{22}-D_{21})+\overline{\epsilon}_{11}-%
 \overline{\epsilon}_{12}+\overline{\epsilon}_{22}-\overline{\epsilon}_{21}   .  The strict exogeneity assumption then implies that       E   [    (     y  ¯   11   -    y  ¯   12    )   -   (     y  ¯   21   -    y  ¯   22    )    ]    =    δ   (    D  11   -   D  12    )    +   δ   (    D  22   -   D  21    )           E   delimited-[]       subscript   normal-¯  y   11    subscript   normal-¯  y   12       subscript   normal-¯  y   21    subscript   normal-¯  y   22           δ     subscript  D  11    subscript  D  12       δ     subscript  D  22    subscript  D  21        E\left[(\overline{y}_{11}-\overline{y}_{12})-(\overline{y}_{21}-\overline{y}_{%
 22})\right]~{}=~{}\delta(D_{11}-D_{12})+\delta(D_{22}-D_{21})   .  Without loss of generality , assume that     D  22   =  1       subscript  D  22   1    D_{22}=1   and     D  11   =   D  12   =   D  21   =  0         subscript  D  11    subscript  D  12         subscript  D  21        0     D_{11}=D_{12}=D_{21}=0   , giving the DID estimator        δ  ^    =    (     y  ¯   11   -    y  ¯   12    )   -   (     y  ¯   21   -    y  ¯   22    )         normal-^  δ        subscript   normal-¯  y   11    subscript   normal-¯  y   12       subscript   normal-¯  y   21    subscript   normal-¯  y   22       \hat{\delta}~{}=~{}(\overline{y}_{11}-\overline{y}_{12})-(\overline{y}_{21}-%
 \overline{y}_{22})   ,  which can be interpreted as the treatment effect of the treatment indicated by    D   s  t      subscript  D    s  t     D_{st}   .  Assumptions  (Figure)  Illustration of the parallel trend assumption   All the assumptions of the OLS model apply equally to DID. In addition, DID requires a parallel trend assumption . The parallel trend assumption says that     λ  2   -   λ  1        subscript  λ  2    subscript  λ  1     \lambda_{2}-\lambda_{1}   are the same in both    s  =  1      s  1    s=1   and    s  =  2      s  2    s=2   . Given that the formal definition above accurately represents reality, this assumption automatically holds. However, a model with      λ   s  t     :     λ  22   -   λ  21    ≠    λ  12   -   λ  11        normal-:   subscript  λ    s  t         subscript  λ  22    subscript  λ  21       subscript  λ  12    subscript  λ  11       \lambda_{st}~{}:~{}\lambda_{22}-\lambda_{21}\neq\lambda_{12}-\lambda_{11}   may well be more realistic.  As illustrated to the right, the treatment effect is the difference between the observed value of y and what the value of y would have been with parallel trends, had there been no treatment. The Achilles' heel of DID is when something other than the treatment changes in one group but not the other at the same time as the treatment, implying a violation of the parallel trend assumption.  To guarantee the accuracy of the DID estimate, the composition of individuals of the two groups is assumed to remain unchanged over time. When using a DID model, various issues that may compromise the results, such as autocorrelation and Ashenfelter dips , must be considered and dealt with.  Implementation  The DID method can be implemented according to the table below, where the lower right cell is the DID estimator.          y   s  t      subscript  y    s  t     y_{st}          s  =  2      s  2    s=2          s  =  1      s  1    s=1      Difference           t  =  2      t  2    t=2          y  22     subscript  y  22    y_{22}          y  12     subscript  y  12    y_{12}           y  12   -   y  22        subscript  y  12    subscript  y  22     y_{12}-y_{22}            t  =  1      t  1    t=1          y  21     subscript  y  21    y_{21}          y  11     subscript  y  11    y_{11}           y  11   -   y  21        subscript  y  11    subscript  y  21     y_{11}-y_{21}        Change        y  21   -   y  22        subscript  y  21    subscript  y  22     y_{21}-y_{22}           y  11   -   y  12        subscript  y  11    subscript  y  12     y_{11}-y_{12}           (    y  11   -   y  21    )   -   (    y  12   -   y  22    )          subscript  y  11    subscript  y  21       subscript  y  12    subscript  y  22      (y_{11}-y_{21})-(y_{12}-y_{22})        Running a regression analysis gives the same result. Consider the OLS model       y   =    β  0   +    β  1   T   +    β  2   S   +    β  3    (   T  ⋅  S   )    +  ε       y     subscript  β  0      subscript  β  1   T      subscript  β  2   S      subscript  β  3    normal-⋅  T  S    ε     y~{}=~{}\beta_{0}+\beta_{1}T+\beta_{2}S+\beta_{3}(T\cdot S)+\varepsilon     where   T   T   T   is a dummy variable for    t  =  2      t  2    t=2   , and   S   S   S   is a dummy variable for    s  =  2      s  2    s=2   . The composite variable    (   T  ⋅  S   )     normal-⋅  T  S    (T\cdot S)   is then a dummy variable indicating when    S  =  T  =  1        S  T       1     S=T=1   . Although it is not shown rigorously here, it turns out that the estimates in this model are         β  ^   0    =   (   y   |  T  =  0  ,  S  =  0  )      fragments   subscript   normal-^  β   0     fragments  normal-(  y  normal-|  T   0  normal-,  S   0  normal-)     \hat{\beta}_{0}~{}=~{}(y~{}|~{}T=0,~{}S=0)          β  ^   1    =   (   y   |  T  =  1  ,  S  =  0  )   -   (   y   |  T  =  0  ,  S  =  0  )      fragments   subscript   normal-^  β   1     fragments  normal-(  y  normal-|  T   1  normal-,  S   0  normal-)     fragments  normal-(  y  normal-|  T   0  normal-,  S   0  normal-)     \hat{\beta}_{1}~{}=~{}(y~{}|~{}T=1,~{}S=0)-(y~{}|~{}T=0,~{}S=0)          β  ^   2    =   (   y   |  T  =  0  ,  S  =  1  )   -   (   y   |  T  =  0  ,  S  =  0  )      fragments   subscript   normal-^  β   2     fragments  normal-(  y  normal-|  T   0  normal-,  S   1  normal-)     fragments  normal-(  y  normal-|  T   0  normal-,  S   0  normal-)     \hat{\beta}_{2}~{}=~{}(y~{}|~{}T=0,~{}S=1)-(y~{}|~{}T=0,~{}S=0)          β  ^   3    =   [   (   y   |  T  =  1  ,  S  =  1  )   -   (   y   |  T  =  0  ,  S  =  1  )   ]   -   [   (   y   |  T  =  1  ,  S  =  0  )   -   (   y   |  T  =  0  ,  S  =  0  )   ]      fragments   subscript   normal-^  β   3     fragments  normal-[   fragments  normal-(  y  normal-|  T   1  normal-,  S   1  normal-)     fragments  normal-(  y  normal-|  T   0  normal-,  S   1  normal-)   normal-]     fragments  normal-[   fragments  normal-(  y  normal-|  T   1  normal-,  S   0  normal-)     fragments  normal-(  y  normal-|  T   0  normal-,  S   0  normal-)   normal-]     \hat{\beta}_{3}~{}=~{}[(y~{}|~{}T=1,~{}S=1)-(y~{}|~{}T=0,~{}S=1)]-[(y~{}|~{}T=%
 1,~{}S=0)-(y~{}|~{}T=0,~{}S=0)]   ,  which is equivalent to         β  ^   3    =    (    y  11   -   y  21    )   -   (    y  12   -   y  22    )         subscript   normal-^  β   3        subscript  y  11    subscript  y  21       subscript  y  12    subscript  y  22       \hat{\beta}_{3}~{}=~{}(y_{11}-y_{21})-(y_{12}-y_{22})   .  But this is the expression for the treatment effect that was given in the formal definition and in the above table.  Card & Krueger (1994) example  Consider one of the most famous DID studies, the Card and Krueger article on minimum wage in New Jersey , published in 1994. 1 Card and Krueger compared employment in the fast food sector in New Jersey and in Pennsylvania , in February 1992 and in November 1992, after New Jersey's minimum wage rose from $4.25 to $5.05 in April 1992. Observing a change in employment in New Jersey only, before and after the treatment, would fail to control for omitted variables such as weather and macroeconomic conditions of the region. By including Pennsylvania as a control in a difference-in-differences model, any bias caused by variables common to New Jersey and Pennsylvania are implicitly controlled for, even when these variables are unobserved. Assuming that New Jersey and Pennsylvania have parallel trends over time, Pennsylvania's change in employment can be interpreted as the change New Jersey would have experienced, had they not increased the minimum wage, and vice versa. The evidence suggested that the increased minimum wage did not induce an increase in unemployment in New Jersey, as standard economic theory would suggest. The table below shows Card & Krueger's estimates of the treatment effect on employment, measured as FTEs (or Full-time equivalents) . Keeping in mind that the finding is controversial , Card and Krueger estimate that the $0.80 minimum wage increase in New Jersey lead to a 2.75 FTE increase in employment.       New Jersey   Pennsylvania   Difference       February   20.44   23.33   -2.89     November   21.03   21.17   -0.14     Change   0.59   -2.16   2.75     See also   Design of experiments  Average treatment effect   References  Further reading     External links   How Does Charitable Giving Respond to Incentives and Income? Dynamic Panel Estimates Accounting for Predictable Changes in Taxation, National Bureau of Economic Research , July 2005  T. Conley and C. Taber, "Inference with "Difference in Differences" with a Small Number of Policy Changes", National Bureau of Economic Research, July 2005  Difference in Difference Estimation , Healthcare Economist website   "  Category:Econometrics  Category:Regression analysis  Category:Design of experiments  Category:Observational study  Category:Causal inference     ↩     