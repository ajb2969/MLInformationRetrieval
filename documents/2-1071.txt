   Linear form      Linear form   In linear algebra , a linear functional or linear form (also called a one-form or covector ) is a linear map from a vector space to its field of scalars . In R n , if vectors are represented as column vectors , then linear functionals are represented as row vectors , and their action on vectors is given by the dot product , or the matrix product with the row vector on the left and the column vector on the right.  In general, if V is a vector space over a field  k , then a linear functional f is a function from V to k that is linear:       f   (    v  →   +   w  →    )    =    f   (   v  →   )    +   f   (   w  →   )           f     normal-→  v    normal-→  w         f   normal-→  v      f   normal-→  w       f(\vec{v}+\vec{w})=f(\vec{v})+f(\vec{w})   for all      v  →   ,   w  →    ∈  V        normal-→  v    normal-→  w    V    \vec{v},\vec{w}\in V          f   (   a   v  →    )    =   a  f   (   v  →   )          f    a   normal-→  v       a  f   normal-→  v      f(a\vec{v})=af(\vec{v})   for all       v  →   ∈  V   ,   a  ∈  k    .     formulae-sequence     normal-→  v   V     a  k     \vec{v}\in V,a\in k.     The set of all linear functionals from V to k , Hom k ( V , k ), forms a vector space over k with the addition of the operations of addition and scalar multiplication (defined pointwise ).  This space is called the dual space of V , or sometimes the algebraic dual space , to distinguish it from the continuous dual space .  It is often written V ∗ or V′ when the field k is understood.  Continuous linear functionals  If V is a topological vector space , the space of continuous linear functionals — the continuous dual — is often simply called the dual space.  If V is a Banach space , then so is its (continuous) dual.  To distinguish the ordinary dual space from the continuous dual space, the former is sometimes called the algebraic dual .  In finite dimensions, every linear functional is continuous, so the continuous dual is the same as the algebraic dual, although this is not true in infinite dimensions.  Examples and applications  Linear functionals in R n  Suppose that vectors in the real coordinate space R n are represented as column vectors        x  →   =   [      x  1       ⋮       x  n      ]    .       normal-→  x      subscript  x  1     normal-⋮     subscript  x  n       \vec{x}=\begin{bmatrix}x_{1}\\
 \vdots\\
 x_{n}\end{bmatrix}.     Then any linear functional can be written in these coordinates as a sum of the form:        f   (   x  →   )    =     a  1    x  1    +  ⋯  +    a  n    x  n      .        f   normal-→  x         subscript  a  1    subscript  x  1    normal-⋯     subscript  a  n    subscript  x  n       f(\vec{x})=a_{1}x_{1}+\cdots+a_{n}x_{n}.     This is just the matrix product of the row vector [ a 1 ... a n ] and the column vector    x  →     normal-→  x    \vec{x}   :        f   (   x  →   )    =    [    a  1   …   a  n    ]    [      x  1       ⋮       x  n      ]     .        f   normal-→  x       delimited-[]     subscript  a  1   normal-…   subscript  a  n        subscript  x  1     normal-⋮     subscript  x  n        f(\vec{x})=[a_{1}\dots a_{n}]\begin{bmatrix}x_{1}\\
 \vdots\\
 x_{n}\end{bmatrix}.     Integration  Linear functionals first appeared in functional analysis , the study of vector spaces of functions .  A typical example of a linear functional is integration : the linear transformation defined by the Riemann integral       I   (  f  )    =    ∫  a  b    f   (  x  )   d  x          I  f     superscript   subscript   a   b     f  x  d  x      I(f)=\int_{a}^{b}f(x)\,dx     is a linear functional from the vector space C[ a , b ] of continuous functions on the interval [ a , b ] to the real numbers.  The linearity of I follows from the standard facts about the integral:       I   (   f  +  g   )    =    ∫  a  b     (    f   (  x  )    +   g   (  x  )     )   d  x    =     ∫  a  b    f   (  x  )   d  x    +    ∫  a  b    g   (  x  )   d  x     =    I   (  f  )    +   I   (  g  )             I    f  g      superscript   subscript   a   b         f  x     g  x    d  x             superscript   subscript   a   b     f  x  d  x      superscript   subscript   a   b     g  x  d  x              I  f     I  g       I(f+g)=\int_{a}^{b}(f(x)+g(x))\,dx=\int_{a}^{b}f(x)\,dx+\int_{a}^{b}g(x)\,dx=I%
 (f)+I(g)           I   (   α  f   )    =    ∫  a  b    α  f   (  x  )   d  x    =   α    ∫  a  b    f   (  x  )   d  x     =   α  I   (  f  )     .          I    α  f      superscript   subscript   a   b     α  f  x  d  x           α    superscript   subscript   a   b     f  x  d  x            α  I  f      I(\alpha f)=\int_{a}^{b}\alpha f(x)\,dx=\alpha\int_{a}^{b}f(x)\,dx=\alpha I(f).     Evaluation  Let P n denote the vector space of real-valued polynomial functions of degree ≤ n defined on an interval [ a , b ].  If c ∈ [ a , b ], then let ev c : P n → R be the evaluation functional :         ev  c   f   =   f   (  c  )     .        subscript  ev  c   f     f  c     \operatorname{ev}_{c}f=f(c).   The mapping f → f ( c ) is linear since        (   f  +  g   )    (  c  )    =    f   (  c  )    +   g   (  c  )             f  g   c       f  c     g  c      (f+g)(c)=f(c)+g(c)            (   α  f   )    (  c  )    =   α  f   (  c  )     .          α  f   c     α  f  c     (\alpha f)(c)=\alpha f(c).     If x 0 , ..., x n are n +1 distinct points in [ a , b ], then the evaluation functionals ev x i , i =0,1,..., n form a basis of the dual space of P n .  ( proves this last fact using Lagrange interpolation .)  Application to quadrature  The integration functional I defined above defines a linear functional on the subspace  P n of polynomials of degree ≤ n .  If x 0 , …, x n are n +1 distinct points in [ a , b ], then there are coefficients a 0 , …, a n for which       I   (  f  )    =     a  0   f   (   x  0   )    +    a  1   f   (   x  1   )    +  …  +    a  n   f   (   x  n   )           I  f        subscript  a  0   f   subscript  x  0       subscript  a  1   f   subscript  x  1    normal-…     subscript  a  n   f   subscript  x  n       I(f)=a_{0}f(x_{0})+a_{1}f(x_{1})+\dots+a_{n}f(x_{n})     for all f ∈ P n .  This forms the foundation of the theory of numerical quadrature .  This follows from the fact that the linear functionals ev x i : f → f ( x i ) defined above form a basis of the dual space of P n .  Linear functionals in quantum mechanics  Linear functionals are particularly important in quantum mechanics .  Quantum mechanical systems are represented by Hilbert spaces , which are anti – isomorphic to their own dual spaces.  A state of a quantum mechanical system can be identified with a linear functional.  For more information see bra–ket notation .  Distributions  In the theory of generalized functions , certain kinds of generalized functions called distributions can be realized as linear functionals on spaces of test functions .  Properties   Any linear functional L is either trivial (equal to 0 everywhere) or surjective onto the scalar field.  Indeed, this follows since just as the image of a vector subspace under a linear transformation is a subspace, so is the image of V under L .  however, the only subspaces (i.e., k -subspaces) of k are {0} and k itself.    A linear functional is continuous if and only if its kernel is closed .    Linear functionals with the same kernel are proportional.    The absolute value of any linear functional is a seminorm on its vector space.   Visualizing linear functionals  (Figure)  Geometric interpretation of a 1-form α as a stack of hyperplanes of constant value, each corresponding to those vectors that α maps to a given scalar value shown next to it along with the "sense" of increase. The zero plane ( purple ) is through the origin.   In finite dimensions, a linear functional can be visualized in terms of its level sets .  In three dimensions, the level sets of a linear functional are a family of mutually parallel planes; in higher dimensions, they are parallel hyperplanes .  This method of visualizing linear functionals is sometimes introduced in general relativity texts, such as Gravitation by . {{-}}  Dual vectors and bilinear forms  (Figure)  Linear functionals (1-forms) α , β and their sum σ and vectors u , v , w , in 3d  Euclidean space . The number of (1-form) hyperplanes intersected by a vector equals the inner product . 1   Every non-degenerate bilinear form on a finite-dimensional vector space V gives rise to an isomorphism from V to V* . Specifically, denoting the bilinear form on V by  (for instance in Euclidean space = v • w is the dot product of v and w ), then there is a natural isomorphism     V  →   V  *    :   v  ↦   v  *       normal-:   normal-→  V   superscript  V      maps-to  v   superscript  v       V\to V^{*}:v\mapsto v^{*}   given by         v  *    (  w  )    :=   ⟨  v  ,  w  ⟩    .     assign     superscript  v    w    v  w     v^{*}(w):=\langle v,w\rangle.     The inverse isomorphism is given by      V  *   →  V   :   f  ↦   f  *       normal-:   normal-→   superscript  V    V    maps-to  f   superscript  f       V^{*}\to V:f\mapsto f^{*}   where f* is the unique element of V for which for all w ∈ V        ⟨   f  *   ,  w  ⟩   =   f   (  w  )     .        superscript  f    w     f  w     \langle f^{*},w\rangle=f(w).     The above defined vector v * ∈ V* is said to be the dual vector of v ∈ V .  In an infinite dimensional Hilbert space , analogous results hold by the Riesz representation theorem .  There is a mapping V → V* into the continuous dual space  V* .  However, this mapping is antilinear rather than linear. {{-}}  Bases in finite dimensions  Basis of the dual space in finite dimensions  Let the vector space V have a basis      e  →   1   ,    e  →   2   ,  …  ,    e  →   n       subscript   normal-→  e   1    subscript   normal-→  e   2   normal-…   subscript   normal-→  e   n     \vec{e}_{1},\vec{e}_{2},\dots,\vec{e}_{n}   , not necessarily orthogonal .  Then the dual space  V* has a basis      ω  ~   1   ,    ω  ~   2   ,  …  ,    ω  ~   n       superscript   normal-~  ω   1    superscript   normal-~  ω   2   normal-…   superscript   normal-~  ω   n     \tilde{\omega}^{1},\tilde{\omega}^{2},\dots,\tilde{\omega}^{n}   called the dual basis defined by the special property that        ω  ~   i    (    e  →   j   )   =   {     1       if   i   =  j       0        if   i   ≠  j   .          fragments   superscript   normal-~  ω   i    fragments  normal-(   subscript   normal-→  e   j   normal-)     fragments  normal-{    1      if  i   j     0      if  i   j        \tilde{\omega}^{i}(\vec{e}_{j})=\left\{\begin{matrix}1&\mathrm{if}\ i=j\\
 0&\mathrm{if}\ i\not=j.\end{matrix}\right.     Or, more succinctly,         ω  ~   i    (    e  →   j   )    =   δ  j  i          superscript   normal-~  ω   i    subscript   normal-→  e   j     subscript   superscript  δ  i   j     \tilde{\omega}^{i}(\vec{e}_{j})=\delta^{i}_{j}     where δ is the Kronecker delta .  Here the superscripts of the basis functionals are not exponents but are instead contravariant indices.  A linear functional    u  ~     normal-~  u    \tilde{u}   belonging to the dual space    V  ~     normal-~  V    \tilde{V}   can be expressed as a linear combination of basis functionals, with coefficients ("components") u i ,        u  ~   =    ∑   i  =  1   n      u  i      ω  ~   i      .       normal-~  u     superscript   subscript     i  1    n      subscript  u  i    superscript   normal-~  ω   i       \tilde{u}=\sum_{i=1}^{n}u_{i}\,\tilde{\omega}^{i}.   Then, applying the functional    u  ~     normal-~  u    \tilde{u}   to a basis vector e j yields        u  ~    (    e  →   j   )    =    ∑   i  =  1   n     (     u  i      ω  ~   i    )     e  →   j     =    ∑  i     u  i    (     ω  ~   i    (    e  →   j   )    )              normal-~  u    subscript   normal-→  e   j      superscript   subscript     i  1    n        subscript  u  i    superscript   normal-~  ω   i     subscript   normal-→  e   j            subscript   i      subscript  u  i      superscript   normal-~  ω   i    subscript   normal-→  e   j         \tilde{u}(\vec{e}_{j})=\sum_{i=1}^{n}(u_{i}\,\tilde{\omega}^{i})\vec{e}_{j}=%
 \sum_{i}u_{i}(\tilde{\omega}^{i}(\vec{e}_{j}))   due to linearity of scalar multiples of functionals and pointwise linearity of sums of functionals.  Then       u  ~    (    e  →   j   )   =   ∑  i    u  i    (    ω  ~   i    (    e  →   j   )   )   =   ∑  i    u  i    δ  i    =   j     u  j      fragments   normal-~  u    fragments  normal-(   subscript   normal-→  e   j   normal-)     subscript   i    subscript  u  i    fragments  normal-(   superscript   normal-~  ω   i    fragments  normal-(   subscript   normal-→  e   j   normal-)   normal-)     subscript   i    subscript  u  i    superscript  δ  i    subscript   j    subscript  u  j     \tilde{u}({\vec{e}}_{j})=\sum_{i}u_{i}(\tilde{\omega}^{i}({\vec{e}}_{j}))=\sum%
 _{i}u_{i}\delta^{i}{}_{j}=u_{j}   that is         u  ~    (    e  →   j   )    =   u  j    .         normal-~  u    subscript   normal-→  e   j     subscript  u  j     \tilde{u}(\vec{e}_{j})=u_{j}.   This last equation shows that an individual component of a linear functional can be extracted by applying the functional to a corresponding basis vector.  The dual basis and inner product  When the space V carries an inner product , then it is possible to write explicitly a formula for the dual basis of a given basis.  Let V have (not necessarily orthogonal) basis      e  →   1   ,  …  ,    e  →   n       subscript   normal-→  e   1   normal-…   subscript   normal-→  e   n     \vec{e}_{1},\dots,\vec{e}_{n}   .  In three dimensions ( n = 3), the dual basis can be written explicitly          ω  ~   i    (   v  →   )    =     1  2     ⟨     ∑   j  =  1   3     ∑   k  =  1   3      ε   i  j  k      (     e  →   j   ×    e  →   k    )          e  →   1   ⋅    e  →   2    ×    e  →   3     ,   v  →   ⟩     .         superscript   normal-~  ω   i    normal-→  v        1  2        superscript   subscript     j  1    3     superscript   subscript     k  1    3      superscript  ε    i  j  k       subscript   normal-→  e   j    subscript   normal-→  e   k          normal-⋅   subscript   normal-→  e   1    subscript   normal-→  e   2     subscript   normal-→  e   3      normal-→  v       \tilde{\omega}^{i}(\vec{v})={1\over 2}\,\left\langle{\sum_{j=1}^{3}\sum_{k=1}^%
 {3}\varepsilon^{ijk}\,(\vec{e}_{j}\times\vec{e}_{k})\over\vec{e}_{1}\cdot\vec{%
 e}_{2}\times\vec{e}_{3}},\vec{v}\right\rangle.   for i = 1, 2, 3, where ε is the Levi-Civita symbol and    ⟨  ,  ⟩     fragments  normal-⟨  normal-,  normal-⟩    \langle,\rangle   the inner product (or dot product ) on V .  In higher dimensions, this generalizes as follows  $$\tilde{\omega}^i(\vec{v}) = \left\langle \frac{\underset{{}^{1\le i_2 where \star$$ is the Hodge star operator .  See also   Discontinuous linear map  Positive linear functional  Bilinear form   References          "  Category:Functional analysis  Category:Linear algebra  Category:Linear operators     ↩     