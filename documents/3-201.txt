   Lehmann–Scheffé theorem      Lehmann–Scheffé theorem   In statistics , the Lehmann–Scheffé theorem is prominent in mathematical statistics, tying together the ideas of completeness, sufficiency, uniqueness, and best unbiased estimation. 1 The theorem states that any estimator which is unbiased for a given unknown quantity and that depends on the data only through a complete , sufficient statistic is the unique best unbiased estimator of that quantity. The Lehmann–Scheffé theorem is named after Erich Leo Lehmann and Henry Scheffé , given their two early papers. 2 3  If T is a complete sufficient statistic for θ and E( g ( T )) = τ ( θ ) then g ( T ) is the uniformly minimum-variance unbiased estimator (UMVUE) of τ ( θ ).  Statement  Let     X  →   =    X  1   ,   X  2   ,  …  ,   X  n         normal-→  X     subscript  X  1    subscript  X  2   normal-…   subscript  X  n      \vec{X}=X_{1},X_{2},\dots,X_{n}   be a random sample from a distribution that has p.d.f (or p.m.f in the discrete case)    f   (  x  :  θ  )      fragments  f   fragments  normal-(  x  normal-:  θ  normal-)     f(x:\theta)   where    θ  ∈  Ω      θ  normal-Ω    \theta\in\Omega   is a parameter in the parameter space. Suppose    Y  =   u   (   X  →   )        Y    u   normal-→  X      Y=u(\vec{X})   is a sufficient statistic for θ , and let    {   f  Y    (  y  :  θ  )   :  θ  ∈  Ω  }     fragments  normal-{   subscript  f  Y    fragments  normal-(  y  normal-:  θ  normal-)   normal-:  θ   Ω  normal-}    \{f_{Y}(y:\theta):\theta\in\Omega\}   be a complete family. If    ϕ  :    𝔼   [   ϕ   (  Y  )    ]    =  θ      normal-:  ϕ      𝔼   delimited-[]    ϕ  Y     θ     \phi:\mathbb{E}[\phi(Y)]=\theta   then    ϕ   (  Y  )       ϕ  Y    \phi(Y)   is the unique MVUE of θ .  Proof  By the Rao–Blackwell theorem , if   Z   Z   Z   is an unbiased estimator of θ then    ϕ   (  Y  )   :=  𝔼   [  Z  |  Y  ]      fragments  ϕ   fragments  normal-(  Y  normal-)   assign  E   fragments  normal-[  Z  normal-|  Y  normal-]     \phi(Y):=\mathbb{E}[Z|Y]   defines an unbiased estimator of θ with the property that its variance is smaller than that of   Z   Z   Z   .  Now we show that this function is unique. Suppose   W   W   W   is another candidate MVUE estimator of θ . Then again    ψ   (  Y  )   :=  𝔼   [  W  |  Y  ]      fragments  ψ   fragments  normal-(  Y  normal-)   assign  E   fragments  normal-[  W  normal-|  Y  normal-]     \psi(Y):=\mathbb{E}[W|Y]   defines an unbiased estimator of θ with the property that its variance is smaller than that of   W   W   W   . Then         𝔼   [    ϕ   (  Y  )    -   ψ   (  Y  )     ]    =  0   ,   θ  ∈  Ω    .     formulae-sequence      𝔼   delimited-[]      ϕ  Y     ψ  Y      0     θ  normal-Ω     \mathbb{E}[\phi(Y)-\psi(Y)]=0,\theta\in\Omega.     Since    {   f  Y    (  y  :  θ  )   :  θ  ∈  Ω  }     fragments  normal-{   subscript  f  Y    fragments  normal-(  y  normal-:  θ  normal-)   normal-:  θ   Ω  normal-}    \{f_{Y}(y:\theta):\theta\in\Omega\}   is a complete family        𝔼   [    ϕ   (  Y  )    -   ψ   (  Y  )     ]    =  0  ⟹    ϕ   (  y  )    -   ψ   (  y  )     =  0   ,   θ  ∈  Ω      formulae-sequence        𝔼   delimited-[]      ϕ  Y     ψ  Y      0           ϕ  y     ψ  y         0      θ  normal-Ω     \mathbb{E}[\phi(Y)-\psi(Y)]=0\implies\phi(y)-\psi(y)=0,\theta\in\Omega     and therefore the function   ϕ   ϕ   \phi   is the unique function of Y that has a smaller variance than any unbiased estimator. We conclude that    ϕ   (  Y  )       ϕ  Y    \phi(Y)   is the MVUE.  See also   Basu's theorem  Complete class theorem  Rao–Blackwell theorem   References  "  Category:Statistical theorems  Category:Estimation theory           