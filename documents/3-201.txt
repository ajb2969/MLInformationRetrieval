   Lehmannâ€“ScheffÃ© theorem      Lehmannâ€“ScheffÃ© theorem   In statistics , the Lehmannâ€“ScheffÃ© theorem is prominent in mathematical statistics, tying together the ideas of completeness, sufficiency, uniqueness, and best unbiased estimation. 1 The theorem states that any estimator which is unbiased for a given unknown quantity and that depends on the data only through a complete , sufficient statistic is the unique best unbiased estimator of that quantity. The Lehmannâ€“ScheffÃ© theorem is named after Erich Leo Lehmann and Henry ScheffÃ© , given their two early papers. 2 3  If T is a complete sufficient statistic for Î¸ and E( g ( T ))Â = Ï„ ( Î¸ ) then g ( T ) is the uniformly minimum-variance unbiased estimator (UMVUE) of Ï„ ( Î¸ ).  Statement  Let     X  â†’   =    X  1   ,   X  2   ,  â€¦  ,   X  n         normal-â†’  X     subscript  X  1    subscript  X  2   normal-â€¦   subscript  X  n      \vec{X}=X_{1},X_{2},\dots,X_{n}   be a random sample from a distribution that has p.d.f (or p.m.f in the discrete case)    f   (  x  :  Î¸  )      fragments  f   fragments  normal-(  x  normal-:  Î¸  normal-)     f(x:\theta)   where    Î¸  âˆˆ  Î©      Î¸  normal-Î©    \theta\in\Omega   is a parameter in the parameter space. Suppose    Y  =   u   (   X  â†’   )        Y    u   normal-â†’  X      Y=u(\vec{X})   is a sufficient statistic for Î¸ , and let    {   f  Y    (  y  :  Î¸  )   :  Î¸  âˆˆ  Î©  }     fragments  normal-{   subscript  f  Y    fragments  normal-(  y  normal-:  Î¸  normal-)   normal-:  Î¸   Î©  normal-}    \{f_{Y}(y:\theta):\theta\in\Omega\}   be a complete family. If    Ï•  :    ğ”¼   [   Ï•   (  Y  )    ]    =  Î¸      normal-:  Ï•      ğ”¼   delimited-[]    Ï•  Y     Î¸     \phi:\mathbb{E}[\phi(Y)]=\theta   then    Ï•   (  Y  )       Ï•  Y    \phi(Y)   is the unique MVUE of Î¸ .  Proof  By the Raoâ€“Blackwell theorem , if   Z   Z   Z   is an unbiased estimator of Î¸ then    Ï•   (  Y  )   :=  ğ”¼   [  Z  |  Y  ]      fragments  Ï•   fragments  normal-(  Y  normal-)   assign  E   fragments  normal-[  Z  normal-|  Y  normal-]     \phi(Y):=\mathbb{E}[Z|Y]   defines an unbiased estimator of Î¸ with the property that its variance is smaller than that of   Z   Z   Z   .  Now we show that this function is unique. Suppose   W   W   W   is another candidate MVUE estimator of Î¸ . Then again    Ïˆ   (  Y  )   :=  ğ”¼   [  W  |  Y  ]      fragments  Ïˆ   fragments  normal-(  Y  normal-)   assign  E   fragments  normal-[  W  normal-|  Y  normal-]     \psi(Y):=\mathbb{E}[W|Y]   defines an unbiased estimator of Î¸ with the property that its variance is smaller than that of   W   W   W   . Then         ğ”¼   [    Ï•   (  Y  )    -   Ïˆ   (  Y  )     ]    =  0   ,   Î¸  âˆˆ  Î©    .     formulae-sequence      ğ”¼   delimited-[]      Ï•  Y     Ïˆ  Y      0     Î¸  normal-Î©     \mathbb{E}[\phi(Y)-\psi(Y)]=0,\theta\in\Omega.     Since    {   f  Y    (  y  :  Î¸  )   :  Î¸  âˆˆ  Î©  }     fragments  normal-{   subscript  f  Y    fragments  normal-(  y  normal-:  Î¸  normal-)   normal-:  Î¸   Î©  normal-}    \{f_{Y}(y:\theta):\theta\in\Omega\}   is a complete family        ğ”¼   [    Ï•   (  Y  )    -   Ïˆ   (  Y  )     ]    =  0  âŸ¹    Ï•   (  y  )    -   Ïˆ   (  y  )     =  0   ,   Î¸  âˆˆ  Î©      formulae-sequence        ğ”¼   delimited-[]      Ï•  Y     Ïˆ  Y      0           Ï•  y     Ïˆ  y         0      Î¸  normal-Î©     \mathbb{E}[\phi(Y)-\psi(Y)]=0\implies\phi(y)-\psi(y)=0,\theta\in\Omega     and therefore the function   Ï•   Ï•   \phi   is the unique function of Y that has a smaller variance than any unbiased estimator. We conclude that    Ï•   (  Y  )       Ï•  Y    \phi(Y)   is the MVUE.  See also   Basu's theorem  Complete class theorem  Raoâ€“Blackwell theorem   References  "  Category:Statistical theorems  Category:Estimation theory           