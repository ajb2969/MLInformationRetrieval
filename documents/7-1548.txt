   Refinable function      Refinable function   In mathematics , in the area of wavelet analysis, a refinable function is a function which fulfils some kind of self-similarity . A function   φ   φ   \varphi   is called refinable with respect to the mask   h   h   h   if       φ   (  x  )    =   2  ⋅    ∑   k  =  0    N  -  1       h  k   ⋅  φ    (    2  ⋅  x   -  k   )            φ  x    normal-⋅  2    superscript   subscript     k  0      N  1       normal-⋅   subscript  h  k   φ      normal-⋅  2  x   k        \varphi(x)=2\cdot\sum_{k=0}^{N-1}h_{k}\cdot\varphi(2\cdot x-k)   This condition is called refinement equation , dilation equation or two-scale equation .  Using the convolution (denoted by a star, *) of a function with a discrete mask and the dilation operator   D   D   D   one can write more concisely:      φ  =    2  ⋅   D   1  /  2      (   h  *  φ   )        φ     normal-⋅  2   subscript  D    1  2       h  φ      \varphi=2\cdot D_{1/2}(h*\varphi)   It means that one obtains the function, again, if you convolve the function with a discrete mask and then scale it back. There is a similarity to iterated function systems and de Rham curves .  The operator    φ  ↦    2  ⋅   D   1  /  2      (   h  *  φ   )       maps-to  φ     normal-⋅  2   subscript  D    1  2       h  φ      \varphi\mapsto 2\cdot D_{1/2}(h*\varphi)   is linear. A refinable function is an eigenfunction of that operator. Its absolute value is not uniquely defined. That is, if   φ   φ   \varphi   is a refinable function, then for every   c   c   c   the function    c  ⋅  φ     normal-⋅  c  φ    c\cdot\varphi   is refinable, too.  These functions play a fundamental role in wavelet theory as scaling functions .  Properties  Values at integral points  A refinable function is defined only implicitly. It may also be that there are several functions which are refinable with respect to the same mask. If   φ   φ   \varphi   shall have finite support and the function values at integer arguments are wanted, then the two scale equation becomes a system of simultaneous linear equations .  Let   a   a   a   be the minimum index and   b   b   b   be the maximum index of non-zero elements of   h   h   h   , then one obtains        (      φ   (  a  )         φ   (   a  +  1   )        ⋮       φ   (  b  )       )   =    (      h  a                       h   a  +  2       h   a  +  1       h  a                 h   a  +  4       h   a  +  3       h   a  +  2       h   a  +  1       h  a          ⋱    ⋱    ⋱    ⋱    ⋱    ⋱          h  b      h   b  -  1       h   b  -  2       h   b  -  3       h   b  -  4                  h  b      h   b  -  1       h   b  -  2                        h  b      )   ⋅   (      φ   (  a  )         φ   (   a  +  1   )        ⋮       φ   (  b  )       )     .          φ  a       φ    a  1      normal-⋮      φ  b      normal-⋅     subscript  h  a   absent  absent  absent  absent  absent     subscript  h    a  2     subscript  h    a  1     subscript  h  a   absent  absent  absent     subscript  h    a  4     subscript  h    a  3     subscript  h    a  2     subscript  h    a  1     subscript  h  a   absent    normal-⋱  normal-⋱  normal-⋱  normal-⋱  normal-⋱  normal-⋱    absent   subscript  h  b    subscript  h    b  1     subscript  h    b  2     subscript  h    b  3     subscript  h    b  4      absent  absent  absent   subscript  h  b    subscript  h    b  1     subscript  h    b  2      absent  absent  absent  absent  absent   subscript  h  b         φ  a       φ    a  1      normal-⋮      φ  b        \begin{pmatrix}\varphi(a)\\
 \varphi(a+1)\\
 \vdots\\
 \varphi(b)\end{pmatrix}=\begin{pmatrix}h_{a}&&&&&\\
 h_{a+2}&h_{a+1}&h_{a}&&&\\
 h_{a+4}&h_{a+3}&h_{a+2}&h_{a+1}&h_{a}&\\
 \ddots&\ddots&\ddots&\ddots&\ddots&\ddots\\
 &h_{b}&h_{b-1}&h_{b-2}&h_{b-3}&h_{b-4}\\
 &&&h_{b}&h_{b-1}&h_{b-2}\\
 &&&&&h_{b}\end{pmatrix}\cdot\begin{pmatrix}\varphi(a)\\
 \varphi(a+1)\\
 \vdots\\
 \varphi(b)\end{pmatrix}.     Using the discretization operator, call it   Q   Q   Q   here, and the transfer matrix of   h   h   h   , named    T  h     subscript  T  h    T_{h}   , this can be written concisely as        Q  φ   =     T  h   ⋅  Q   φ    .        Q  φ      normal-⋅   subscript  T  h   Q   φ     Q\varphi=T_{h}\cdot Q\varphi.\,     This is again a fixed-point equation . But this one can now be considered as an eigenvector - eigenvalue problem. That is, a finitely supported refinable function exists only (but not necessarily), if    T  h     subscript  T  h    T_{h}   has the eigenvalue 1.  Values at dyadic points  From the values at integral points you can derive the values at dyadic points, i.e. points of the form    k  ⋅   2   -  j       normal-⋅  k   superscript  2    j      k\cdot 2^{-j}   , with    k  ∈  ℤ      k  ℤ    k\in\mathbb{Z}   and    j  ∈  ℕ      j  ℕ    j\in\mathbb{N}   .      φ  =    D   1  /  2     (   2  ⋅   (   h  *  φ   )    )        φ     subscript  D    1  2     normal-⋅  2    h  φ       \varphi=D_{1/2}(2\cdot(h*\varphi))           D  2   φ   =   2  ⋅   (   h  *  φ   )           subscript  D  2   φ    normal-⋅  2    h  φ      D_{2}\varphi=2\cdot(h*\varphi)          Q   (    D  2   φ   )    =   Q   (   2  ⋅   (   h  *  φ   )    )    =   2  ⋅   (    h  *  Q   φ   )            Q     subscript  D  2   φ      Q   normal-⋅  2    h  φ           normal-⋅  2      h  Q   φ       Q(D_{2}\varphi)=Q(2\cdot(h*\varphi))=2\cdot(h*Q\varphi)   The star denotes the convolution of a discrete filter with a function. With this step you can compute the values at points of the form    k  2      k  2    \frac{k}{2}   . By replacing iteratedly   φ   φ   \varphi   by     D  2   φ       subscript  D  2   φ    D_{2}\varphi   you get the values at all finer scales.       Q   (    D   2   j  +  1     φ   )    =   2  ⋅   (    h  *  Q    (    D   2  j    φ   )    )          Q     subscript  D   superscript  2    j  1     φ     normal-⋅  2      h  Q      subscript  D   superscript  2  j    φ       Q(D_{2^{j+1}}\varphi)=2\cdot(h*Q(D_{2^{j}}\varphi))     Convolution  If   φ   φ   \varphi   is refinable with respect to   h   h   h   , and   ψ   ψ   \psi   is refinable with respect to   g   g   g   , then    φ  *  ψ      φ  ψ    \varphi*\psi   is refinable with respect to    h  *  g      h  g    h*g   .  Differentiation  If   φ   φ   \varphi   is refinable with respect to   h   h   h   , and the derivative    φ  ′     superscript  φ  normal-′    \varphi^{\prime}   exists, then    φ  ′     superscript  φ  normal-′    \varphi^{\prime}   is refinable with respect to    2  ⋅  h     normal-⋅  2  h    2\cdot h   . This can be interpreted as a special case of the convolution property, where one of the convolution operands is a derivative of the Dirac impulse .  Integration  If   φ   φ   \varphi   is refinable with respect to   h   h   h   , and there is an antiderivative   Φ   normal-Φ   \Phi   with     Φ   (  t  )    =    ∫  0  t    φ   (  τ  )   d  τ          normal-Φ  t     superscript   subscript   0   t     φ  τ  normal-d  τ      \Phi(t)=\int_{0}^{t}\varphi(\tau)\mathrm{d}\tau   , then the antiderivative    t  ↦    Φ   (  t  )    +  c      maps-to  t      normal-Φ  t   c     t\mapsto\Phi(t)+c   is refinable with respect to mask     1  2   ⋅  h     normal-⋅    1  2   h    \frac{1}{2}\cdot h   where the constant   c   c   c   must fulfill     c  ⋅   (   1  -    ∑  j    h  j     )    =    ∑  j      h  j   ⋅  Φ    (   -  j   )          normal-⋅  c    1    subscript   j    subscript  h  j        subscript   j      normal-⋅   subscript  h  j   normal-Φ     j       c\cdot(1-\sum_{j}h_{j})=\sum_{j}h_{j}\cdot\Phi(-j)   .  If   φ   φ   \varphi   has bounded support , then we can interpret integration as convolution with the Heaviside function and apply the convolution law.  Scalar products  Computing the scalar products of two refinable functions and their translates can be broken down to the two above properties. Let   T   T   T   be the translation operator. It holds       ⟨  φ  ,    T  k   ψ   ⟩   =   ⟨   φ  *   ψ  *    ,    T  k   δ   ⟩   =    (   φ  *   ψ  *    )    (  k  )           φ     subscript  T  k   ψ       φ   superscript  ψ        subscript  T  k   δ             φ   superscript  ψ     k      \langle\varphi,T_{k}\psi\rangle=\langle\varphi*\psi^{*},T_{k}\delta\rangle=(%
 \varphi*\psi^{*})(k)   where    ψ  *     superscript  ψ     \psi^{*}   is the adjoint of   ψ   ψ   \psi   with respect to convolution , i.e.    ψ  *     superscript  ψ     \psi^{*}   is the flipped and complex conjugated version of   ψ   ψ   \psi   , i.e.      ψ  *    (  t  )    =    ψ   (   -  t   )    ¯          superscript  ψ    t    normal-¯    ψ    t       \psi^{*}(t)=\overline{\psi(-t)}   .  Because of the above property,    φ  *   ψ  *       φ   superscript  ψ      \varphi*\psi^{*}   is refinable with respect to    h  *   g  *       h   superscript  g      h*g^{*}   , and its values at integral arguments can be computed as eigenvectors of the transfer matrix. This idea can be easily generalized to integrals of products of more than two refinable functions. 1  Smoothness  A refinable function usually has a fractal shape. The design of continuous or smooth refinable functions is not obvious. Before dealing with forcing smoothness it is necessary to measure smoothness of refinable functions. Using the Villemoes machine 2 one can compute the smoothness of refinable functions in terms of Sobolev exponents .  In a first step the refinement mask   h   h   h   is divided into a filter   b   b   b   , which is a power of the smoothness factor    (  1  ,  1  )     1  1    (1,1)   (this is a binomial mask) and a rest   q   q   q   . Roughly spoken, the binomial mask   b   b   b   makes smoothness and   q   q   q   represents a fractal component, which reduces smoothness again. Now the Sobolev exponent is roughly the order of   b   b   b   minus logarithm of the spectral radius of    T   q  *   q  *       subscript  T    q   superscript  q       T_{q*q^{*}}   .  Generalization  The concept of refinable functions can be generalized to functions of more than one variable, that is functions from      \R   d   →   \R      normal-→   superscript  \R  d   \R    \R^{d}\to\R   . The most simple generalization is about tensor products . If   φ   φ   \varphi   and   ψ   ψ   \psi   are refinable with respect to   h   h   h   and   g   g   g   , respectively, then    φ  ⊗  ψ     tensor-product  φ  ψ    \varphi\otimes\psi   is refinable with respect to    h  ⊗  g     tensor-product  h  g    h\otimes g   .  The scheme can be generalized even more to different scaling factors with respect to different dimensions or even to mixing data between dimensions. 3 Instead of scaling by scalar factor like 2 the signal the coordinates are transformed by a matrix   M   M   M   of integers. In order to let the scheme work, the absolute values of all eigenvalues of   M   M   M   must be larger than one. (Maybe it also suffices that     |   det  M   |   >  1          M    1    |\det M|>1   .)  Formally the two-scale equation does not change very much:       φ   (  x  )    =    |   det  M   |   ⋅    ∑   k  ∈    \Z   d        h  k   ⋅  φ    (    M  ⋅  x   -  k   )            φ  x    normal-⋅      M      subscript     k   superscript  \Z  d        normal-⋅   subscript  h  k   φ      normal-⋅  M  x   k        \varphi(x)=|\det M|\cdot\sum_{k\in\Z^{d}}h_{k}\cdot\varphi(M\cdot x-k)         φ  =     |   det  M   |   ⋅   D   M   -  1       (   h  *  φ   )        φ     normal-⋅      M     subscript  D   superscript  M    1        h  φ      \varphi=|\det M|\cdot D_{M^{-1}}(h*\varphi)     Examples   If the definition is extended to distributions , then the Dirac impulse is refinable with respect to the unit vector   δ   δ   \delta   , that is known as Kronecker delta . The   n   n   n   -th derivative of the Dirac distribution is refinable with respect to     2  n   ⋅  δ     normal-⋅   superscript  2  n   δ    2^{n}\cdot\delta   .  The Heaviside function is refinable with respect to     1  2   ⋅  δ     normal-⋅    1  2   δ    \frac{1}{2}\cdot\delta   .  The truncated power functions with exponent   n   n   n   are refinable with respect to     1   2   n  +  1     ⋅  δ     normal-⋅    1   superscript  2    n  1     δ    \frac{1}{2^{n+1}}\cdot\delta   .  The triangular function is a refinable function.    B-spline functions with successive integral nodes are refinable, because of the convolution theorem and the refinability of the characteristic function for the interval    [  0  ,  1  )     0  1    [0,1)   (a boxcar function ).   All polynomial functions are refinable. For every refinement mask there is a polynomial that is uniquely defined up to a constant factor. For every polynomial of degree   n   n   n   there are many refinement masks that all differ by a mask of type    v  *    (  1  ,   -  1   )    n  +  1        v   superscript   1    1      n  1      v*(1,-1)^{n+1}   for any mask   v   v   v   and the convolutional power     (  1  ,   -  1   )    n  +  1      superscript   1    1      n  1     (1,-1)^{n+1}   .     A rational function    φ   φ   \varphi   is refinable if and only if it can be represented using partial fractions as     φ   (  x  )    =    ∑   i  ∈  ℤ      s  i     (   x  -  i   )   k           φ  x     subscript     i  ℤ       subscript  s  i    superscript    x  i   k       \varphi(x)=\sum_{i\in\mathbb{Z}}\frac{s_{i}}{(x-i)^{k}}   , where   k   k   k   is a positive  natural number and   s   s   s   is a real sequence with finitely many non-zero elements (a Laurent polynomial ) such that    s  |   (  s  ↑  2  )      fragments  s  normal-|   fragments  normal-(  s  normal-↑  2  normal-)     s|(s\uparrow 2)   (read     ∃   h   (  z  )     ∈     ℝ   [  z  ,   z   -  1    ]   h   (  z  )    ⋅  s    (  z  )    =   s   (   z  2   )              h  z       normal-⋅    ℝ   z   superscript  z    1     h  z   s   z          s   superscript  z  2       \exists h(z)\in\mathbb{R}[z,z^{-1}]\ h(z)\cdot s(z)=s(z^{2})   ). The Laurent polynomial     2   k  -  1    ⋅  h     normal-⋅   superscript  2    k  1    h    2^{k-1}\cdot h   is the associated refinement mask.    References  See also   Subdivision scheme   "  Category:Wavelets     ↩  ↩  ↩     