   Stochastic matrix      Stochastic matrix    ''For a matrix whose elements are stochastic, see Random matrix    In mathematics , a stochastic matrix (also termed probability matrix , transition matrix , 1  substitution matrix , or Markov matrix ) is a matrix used to describe the transitions of a Markov chain . Each of its entries is a nonnegative  real number representing a probability . It has found use in probability theory , statistics , mathematical finance and linear algebra , as well as computer science and population genetics . There are several different definitions and types of stochastic matrices:   A right stochastic matrix is a real square matrix, with each row summing to 1.    A left stochastic matrix is a real square matrix, with each column summing to 1.    A doubly stochastic matrix is a square matrix of nonnegative real numbers with each row and column summing to 1.   In the same vein, one may define stochastic vector (also called probability vector ) as a vector whose elements are nonnegative real numbers which sum to 1. Thus, each row of a right stochastic matrix (or column of a left stochastic matrix) is a stochastic vector.  A common convention in English language mathematics literature is to use row vectors of probabilities and right stochastic matrices rather than column vectors of probabilities and left stochastic matrices; this article follows that convention.  Definition and properties  A stochastic matrix describes a Markov chain     ùëø  t     subscript  ùëø  t    \boldsymbol{X}_{t}   over a finite  state space  S .  If the probability of moving from   i   i   i   to   j   j   j   in one time step is    P  r   (  j  |  i  )   =   P   i  ,  j       fragments  P  r   fragments  normal-(  j  normal-|  i  normal-)     subscript  P   i  j      Pr(j|i)=P_{i,j}   , the stochastic matrix P is given by using    P   i  ,  j      subscript  P   i  j     P_{i,j}   as the    i   t  h      superscript  i    t  h     i^{th}   row and    j   t  h      superscript  j    t  h     j^{th}   column element, e.g.,       P  =   (      p   1  ,  1       p   ;   1  ,  2       ‚Ä¶     p   ;   1  ,  j       ‚Ä¶       p   2  ,  1       p   ;   2  ,  2       ‚Ä¶     p   ;   2  ,  j       ‚Ä¶      ‚ãÆ    ‚ãÆ    ‚ã±    ‚ãÆ    ‚ã±       p   i  ,  1       p   ;   i  ,  2       ‚Ä¶     p   ;   i  ,  j       ‚Ä¶      ‚ãÆ    ‚ãÆ    ‚ã±    ‚ãÆ    ‚ã±     )    .      P     subscript  p   1  1     fragments  p   subscript  normal-;   1  2     normal-‚Ä¶   fragments  p   subscript  normal-;   1  j     normal-‚Ä¶     subscript  p   2  1     fragments  p   subscript  normal-;   2  2     normal-‚Ä¶   fragments  p   subscript  normal-;   2  j     normal-‚Ä¶    normal-‚ãÆ  normal-‚ãÆ  normal-‚ã±  normal-‚ãÆ  normal-‚ã±     subscript  p   i  1     fragments  p   subscript  normal-;   i  2     normal-‚Ä¶   fragments  p   subscript  normal-;   i  j     normal-‚Ä¶    normal-‚ãÆ  normal-‚ãÆ  normal-‚ã±  normal-‚ãÆ  normal-‚ã±      P=\left(\begin{matrix}p_{1,1}&p_{1,2}&\dots&p_{1,j}&\dots\\
 p_{2,1}&p_{2,2}&\dots&p_{2,j}&\dots\\
 \vdots&\vdots&\ddots&\vdots&\ddots\\
 p_{i,1}&p_{i,2}&\dots&p_{i,j}&\dots\\
 \vdots&\vdots&\ddots&\vdots&\ddots\end{matrix}\right).     Since the probability of transitioning from state   i   i   i   to some state must be 1, this matrix is a right stochastic matrix, so that        ‚àë  j    P   i  ,  j     =   1.         subscript   j    subscript  P   i  j     1.    \sum_{j}P_{i,j}=1.\,     The product of two right stochastic matrices is also right stochastic. In particular, the   k   k   k   -th power    P  k     superscript  P  k    P^{k}   of a right stochastic matrix   P   P   P   is also right stochastic. The probability of transitioning from   i   i   i   to   j   j   j   in two steps is then given by the     (  i  ,  j  )    t  h      superscript   i  j     t  h     (i,j)^{th}   element of the square of   P   P   P   :        (   P  2   )    i  ,  j    .     subscript   superscript  P  2    i  j     \left(P^{2}\right)_{i,j}.     In general the probability transition of going from any state to another state in a finite Markov chain given by the matrix   P   P   P   in k steps is given by    P  k     superscript  P  k    P^{k}   .  An initial distribution is given as a row vector .  A stationary probability vector   ùùÖ   ùùÖ   \boldsymbol{\pi}   is defined as a distribution, written as a row vector, that does not change under application of the transition matrix; that is, it is defined as a probability distribution on the set    {  1  ,  ‚Ä¶  ,  n  }     1  normal-‚Ä¶  n    \{1,...,n\}   which is also a row eigenvector of the probability matrix, associated with eigenvalue 1:        ùùÖ  P   =  ùùÖ   .        ùùÖ  P   ùùÖ    \boldsymbol{\pi}P=\boldsymbol{\pi}.     The right spectral radius of every right stochastic matrix is clearly at most 1. Additionally, every right stochastic matrix has an obvious column eigenvector associated to the eigenvalue 1: The vector   ùüè   1   \boldsymbol{1}   , whose coordinates are all equal to 1. As left and right eigenvalues of a square matrix are the same, every stochastic matrix has, at least, a row eigenvector associated to the eigenvalue 1 and the largest absolute value of all its eigenvalues is also 1. Finally, the Brouwer Fixed Point Theorem (applied to the compact convex set of all probability distributions of the finite set    {  1  ,  ‚Ä¶  ,  n  }     1  normal-‚Ä¶  n    \{1,...,n\}   ) implies that there is some left eigenvector which is also a stationary probability vector.  On the other hand, the Perron‚ÄìFrobenius theorem also ensures that every irreducible stochastic matrix has such a stationary vector, and that the largest absolute value of an eigenvalue is always 1. However, this theorem cannot be applied directly to such matrices because they need not be irreducible.  In general, there may be several such vectors. However, for a matrix with strictly positive entries (or, more generally, for an irreducible aperiodic stochastic matrix), this vector is unique and can be computed by observing that for any   i   i   i   we have the following limit,         lim   k  ‚Üí  ‚àû      (   P  k   )    i  ,  j     =   ùùÖ  j    ,        subscript    normal-‚Üí  k      subscript   superscript  P  k    i  j      subscript  ùùÖ  j     \lim_{k\rightarrow\infty}\left(P^{k}\right)_{i,j}=\boldsymbol{\pi}_{j},     where    ùùÖ  j     subscript  ùùÖ  j    \boldsymbol{\pi}_{j}   is the    j   t  h      superscript  j    t  h     j^{th}   element of the row vector   ùùÖ   ùùÖ   \boldsymbol{\pi}   . Among other things, this says that the long-term probability of being in a state   j   j   j   is independent of the initial state   i   i   i   . That both of these computations give the same stationary vector is a form of an ergodic theorem , which is generally true in a wide variety of dissipative dynamical systems : the system evolves, over time, to a stationary state .  Intuitively, a stochastic matrix represents a Markov chain; the application of the stochastic matrix to a probability distribution redistributes the probability mass of the original distribution while preserving its total mass. If this process is applied repeatedly, the distribution converges to a stationary distribution for the Markov chain.  Example: the cat and mouse  Suppose you have a timer and a row of five adjacent boxes, with a cat in the first box and a mouse in the fifth box at time zero. The cat and the mouse both jump to a random adjacent box when the timer advances. E.g. if the cat is in the second box and the mouse in the fourth one, the probability is one fourth that the cat will be in the first box and the mouse in the fifth after the timer advances . If the cat is in the first box and the mouse in the fifth one, the probability is one that the cat will be in box two and the mouse will be in box four after the timer advances. The cat eats the mouse if both end up in the same box, at which time the game ends. The random variable  K gives the number of time steps the mouse stays in the game.  The Markov chain that represents this game contains the following five states specified by the combination of positions (cat,mouse):   State 1: (1,3)  State 2: (1,5)  State 3: (2,4)  State 4: (3,5)  State 5: game over: (2,2), (3,3) & (4,4).   We use a stochastic matrix to represent the transition probabilities of this system (rows and columns in this matrix are indexed by the possible states listed above),       P  =   [     0    0     1  /  2     0     1  /  2       0    0    1    0    0       1  /  4      1  /  4     0     1  /  4      1  /  4       0    0     1  /  2     0     1  /  2       0    0    0    0    1     ]    .      P    0  0    1  2   0    1  2     0  0  1  0  0      1  4     1  4   0    1  4     1  4     0  0    1  2   0    1  2     0  0  0  0  1      P=\begin{bmatrix}0&0&1/2&0&1/2\\
 0&0&1&0&0\\
 1/4&1/4&0&1/4&1/4\\
 0&0&1/2&0&1/2\\
 0&0&0&0&1\end{bmatrix}.     Long-term averages  No matter what the initial state, the cat will eventually catch the mouse (with probability 1) and a stationary state œÄ = (0,0,0,0,1) is approached as a limit. To compute the long-term average or expected value of a stochastic variable Y, for each state S j and time t k there is a contribution of Y j,k ¬∑P(S=S j ,t=t k ). Survival can be treated as a binary variable with Y=1 for a surviving state and Y=0 for the terminated state. The states with Y=0 do not contribute to the long-term average.  Phase-type representation  (Figure)  The survival function of the mouse. The mouse will survive at least the first time step.   As State 5 is an absorbing state, the distribution of time to absorption is discrete phase-type distributed . Suppose the system starts in state 2, represented by the vector    [  0  ,  1  ,  0  ,  0  ,  0  ]     0  1  0  0  0    [0,1,0,0,0]   . The states where the mouse has perished don't contribute to the survival average so state five can be ignored. The initial state and transition matrix can be reduced to,      ùùâ  =   [  0  ,  1  ,  0  ,  0  ]       ùùâ   0  1  0  0     \boldsymbol{\tau}=[0,1,0,0]     and,       T  =    [     0    0     1  /  2     0      0    0    1    0       1  /  4      1  /  4     0     1  /  4       0    0     1  /  2     0     ]     ,      T    0  0    1  2   0    0  0  1  0      1  4     1  4   0    1  4     0  0    1  2   0      T=\begin{bmatrix}0&0&1/2&0\\
 0&0&1&0\\
 1/4&1/4&0&1/4\\
 0&0&1/2&0\end{bmatrix}\,,   ; and        (   I  -  T   )    -  1    ùüè   =    [     2.75      4.5      3.5      2.75     ]     ,         superscript    I  T     1    1     2.75    4.5    3.5    2.75      (I-T)^{-1}\boldsymbol{1}=\begin{bmatrix}2.75\\
 4.5\\
 3.5\\
 2.75\end{bmatrix}\,,   where   I   I   I   is the identity matrix , and   ùüè   1   \mathbf{1}   represents a column matrix of all ones that acts as a sum over states.  Since each state is occupied for one step of time the expected time of the mouse's survival is just the sum of the probability of occupation over all surviving states and steps in time,       E   [  K  ]    =   ùùâ   (   I  +  T  +   T  2   +  ‚ãØ   )   ùüè   =   ùùâ    (   I  -  T   )    -  1    ùüè   =  4.5.          E   delimited-[]  K      ùùâ    I  T   superscript  T  2   normal-‚ãØ   1          ùùâ   superscript    I  T     1    1        4.5.     E[K]=\boldsymbol{\tau}(I+T+T^{2}+\cdots)\boldsymbol{1}=\boldsymbol{\tau}(I-T)^%
 {-1}\boldsymbol{1}=4.5.     Higher order moments are given by       E   [   K   (   K  -  1   )   ‚Ä¶   (    K  -  n   +  1   )    ]    =    n  !   ùùâ    (   I  -  T   )    -  n     T   n  -  1    1‚Äâ.         E   delimited-[]    K    K  1   normal-‚Ä¶      K  n   1          n   ùùâ   superscript    I  T     n     superscript  T    n  1    1‚Äâ.     E[K(K-1)\dots(K-n+1)]=n!\boldsymbol{\tau}(I-{T})^{-n}{T}^{n-1}\mathbf{1}\,.     See also   Muirhead's inequality  Perron‚ÄìFrobenius theorem  Density matrix  Doubly stochastic matrix  Discrete phase-type distribution  Probabilistic automaton  Models of DNA evolution  Markov kernel , the equivalent of a stochastic matrix over a continuous state space   References   G. Latouche, V. Ramaswami. Introduction to Matrix Analytic Methods in Stochastic Modeling , 1st edition. Chapter 2: PH Distributions; ASA SIAM, 1999.   "  Category:Matrices  Category:Markov models     ‚Ü©     