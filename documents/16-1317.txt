


Derivative of the exponential map




Derivative of the exponential map

 In the theory of Lie groups, the exponential map is a map from the Lie algebra

 
  of a Lie group 
 
 
 
  into 
 
 
 
 . In case 
 
 
 
  is a matrix Lie group, the exponential map reduces to the matrix exponential. The exponential map, denoted 
 
 
 
 , is analytic and has as such a derivative

 
 , where 
 
 
 
  is a  path in the Lie algebra, and a closely related differential

 
 .1
The formula for 
 
 
 
  was first proved by Friedrich Schur (1891).2 It was later elaborated by Henri Poincaré (1899) in the context of the problem of expressing Lie group multiplication using Lie algebraic terms.3 It is also sometimes known as Duhamel's formula.
The formula is important both in pure and applied mathematics. It enters into proofs of theorems such as the Baker–Campbell–Hausdorff formula, and it is used frequently in physics4 for example in quantum field theory, as in the Magnus expansion in perturbation theory, and in lattice gauge theory.
Throughout, the notations 
 
 
 
  and  will be used interchangeably to denote the exponential given an argument, except when, where as noted, the notations have dedicated distinct meanings. The calculus-style notation is preferred here for better readability in equations. On the other hand, the 
 
 
 
 -style is sometimes more convenient for inline equations, and is necessary on the rare occasions when there is a real distinction to be made.
Statement
The derivative of the exponential map is given by5 }{\mathrm{ad}_{X}}\frac{dX(t)}{dt}.               (1) |cellpadding= 6 |border |border colour = #0073CF |bgcolor=#F9FFF7}}

Explanation




 
  is a  (continuously differentiable) path in the Lie algebra with derivative 
 
 
 
 . The argument 
 
 
 
  is omitted where not needed.
 is the linear transformation of the Lie algebra given by  [X, Y]}}. It is the adjoint action of a Lie algebra on itself.
The fraction  is given by its power series derived from that of 
 
 
 
  in ordinary calculus as in matrix exponentiation,6

}{\mathrm{ad}_{X}} = \sum_{k = 0}^\infty \frac{(-1)^k}{(k + 1)!}(\mathrm{ad}_X)^k. |2}}

When 
 
 
 
  is a matrix Lie group, all occurrences of the exponential are given by their power series expansion.
When 
 
 
 
  is not a matrix Lie group,  is still given by its power series , while the other occurrences of 
 
 
 
  in the complete formula do not, in general, have same power series expansion as in the matrix case. This still amounts to exactly the same formula as in the matrix case.
The formula applies to the case where 
 
 
 
  is considered as a map on matrix space over 
 
 
 
  or 
 
 
 
 , see matrix exponential. When 
 
 
 
  or 
 
 
 
 , the notions coincide precisely.

To compute the differential

 
  of 
 
 
 
  at 
 
 
 
 , , the standard recipe7


 
  is employed. With 
 
 
 
  the result8 }{\mathrm{ad}_{X}}Y|3}} follows immediately from . In particular,  TGe}} is the identity because  (since 
 
 
 
  is a vector space) and .
Proof
The proof given below assumes a matrix Lie group. This means that the exponential mapping from the Lie algebra to the matrix Lie group is given by the usual power series, i.e. matrix exponentiation. The conclusion of the proof still holds in the general case, provided each occurrence of 
 
 
 
  is correctly interpreted. See comments on the general case below.
The outline of proof makes use of the technique of differentiation with respect to 
 
 
 
  of the parametrized expression


 
  to obtain a first order differential equation for 
 
 
 
  which can then be solved by direct integration in 
 
 
 
 . The solution is then .
Lemma
 Let 

 denote the adjoint action of the group on its Lie algebra. The action is given by  AXA−1}} for 
 
 
 
 . A frequently useful relationship between 
 
 
 
  and 
 
 
 
  is given by9 Proof
 Using the product rule twice one finds,


 
  Then one observes that


 
  by  above. Integration yields


 
  Using the formal power series to expand the exponential, integrating term by term, and finally recognizing ,


 
  and the result follows. The proof, as presented here, is essentially the one given in . A proof with a more algebraic touch can be found in .10  By direct differentiation of the standard limit definition of the exponential, and exchanging the order of differentiation and limit,


 
 
  where each factor owes its place to the non-commutativity of 
 
 
 
  and 
 
 
 
 .
Divide the unit interval into 
 
 
 
  sections 
 
 
 
  and let 
 
 
 
  → ∞, 
 
 
 
 , 
 
 
 
 . It follows that


 
 
  The virtue of a formal proof like this is that it tells what the right answer must be, provided it exists. Existence needs to be proved separately in each case. 
Comments on the general case
The formula in the general case is given by11


 
  where12


 
  which formally reduces to


 
  Here the 
 
 
 
 -notation is used for the exponential mapping of the Lie algebra and the calculus-style notation in the fraction indicates the usual formal series expansion. For more information and two full proofs in the general case, see the freely available  reference.
Applications
Local behavior of the exponential map
The inverse function theorem together with the derivative of the exponential map provides information about the local behavior of 
 
 
 
 . Any  map 
 
 
 
  between vector spaces (here first considering matrix Lie groups) has a  inverse such that 
 
 
 
  is a  bijection in an open set around a point 
 
 
 
  in the domain provided  is invertible. From  it follows that this will happen precisely when



is invertible. This, in turn, happens when the eigenvalues of this operator are all nonzero. The eigenvalues of  are related to those of  as follows. If 
 
 
 
  is an analytic function of a complex variable expressed in a power series such that 
 
 
 
  for a matrix 
 
 
 
  converges, then the eigenvalues of 
 
 
 
  will be , where  are the eigenvalues of 
 
 
 
 , the double subscript is made clear below.13 In the present case with 
 
 
 
  and  adX}}, the eigenvalues of  are


 
  where the  are the eigenvalues of . Putting  0}} one sees that 
 
 
 
  is invertible precisely when



The eigenvalues of  are, in turn, related to those of 
 
 
 
 . Let the eigenvalues of 
 
 
 
  be . Fix an ordered basis  of the underlying vector space 
 
 
 
  such that 
 
 
 
  is lower triangular. Then


 
  with the remaining terms multiples of  with 
 
 
 
 . Let  be the corresponding basis for matrix space, i.e.  δikδjl}}. Order this basis such that  if 
 
 



 
  with the remaining terms multiples of . This means that  is lower triangular with its eigenvalues  λi − λj}} on the diagonal. The conclusion is that  is invertible, hence 
 
 
 
  is a local bianalytical bijection around 
 
 
 
 , when the eigenvalues of 
 
 
 
  satisfy1415



In particular, in the case of matrix Lie groups, it follows, since  is invertible, by the inverse function theorem that 
 
 
 
  is a bi-analytic bijection in a neighborhood of 
 
 
 
  in matrix space. Furthermore, by the closed subgroup theorem, 
 
 
 
 , is a bi-analytic bijection from a neighborhood of 
 
 
 
  in 
 
 
 
  to a neighborhood of 
 
 
 
 .16 The same conclusion holds for general Lie groups using the manifold version of the inverse function theorem.
It also follows from the implicit function theorem that  itself is invertible for 
 
 
 
  sufficiently small.17
Derivation of a Baker–Campbell–Hausdorff formula
If 
 
 
 
  is defined such that


 
  an expression for 
 
 
 
 , the BCH formula, can be derived from the above formula,



Its left-hand side is easy to see to equal Y. Thus,


 
  and hence, formally,1819


 
  However, using the relationship between 
 
 
 
  and 
 
 
 
  given by , it is straightforward to further see that


 
  and hence


 
  Putting this into the form of an integral in t from 0 to 1 yields,


 
  an integral formula for 
 
 
 
  that is more tractable in practice than the explicit Dynkin's series formula due to the simplicity of the series expansion of 
 
 
 
 . Note this expression consists of 
 
 
 
  and nested commutators thereof with 
 
 
 
  or 
 
 
 
 . A textbook proof along these lines can be found in  and .
Derivation of Dynkin's series formula
(Figure)
Eugene Dynkin at home in 2003. In 1947 Dynkin proved the explicit BCH series formula.20 Poincaré, Baker, Campbell and Hausdorff were mostly concerned with the existence of a bracket series, which suffices in many applications, for instance, in proving central results in the Lie correspondence.2122 Photo courtesy of the Dynkin Collection.

Dynkin's formula mentioned may also be derived analogously, starting from the parametric extension


 
  whence


 
  so that, using the above general formula,



Since, however,


 
  the last step by virtue of the Mercator series expansion, it follows that {n} (e^{\mathrm{ad}_Z} - 1)^{n-1} ~ ( X + e^{t \mathrm{ad}_{X}}Y)~,|5}} and, thus, integrating,



It is at this point evident that the qualitative statement of the BCH formula holds, namely 
 
 
 
  lies in the Lie algebra generated by 
 
 
 
  and is expressible as a series in repeated brackets (A). For each 
 
 
 
 , terms for each partition thereof are organized inside the integral . The resulting Dynkin's formula is then {k} \sum_{s \in S_{k}} \frac{1}{i_1 + j_1 + \cdots + i_k + j_k}\frac{[X^{(i_1)}Y^{(j_1)}\cdots X^{(i_k)}Y^{(j_k)}]}{i_1!j_1!\cdots i_k!j_k!}, \quad i_r,j_r \ge 0,\quad i_r + j_r > 0,\quad 1 \le r \le k. |cellpadding= 6 |border |border colour = #0073CF |bgcolor=#F9FFF7}} For a similar proof with detailed series expansions, see . For complete details, click on "show" below.
Change the summation index in  to 
 
 
 
  and expand {k + 1}\left\{(e^{\mathrm{ad}_{tX}}e^{\mathrm{ad}_{tY}} - 1)^kX + (e^{\mathrm{ad}_{tX}}e^{\mathrm{ad}_{tY}} - 1)^ke^{\mathrm{ad}_{tX}}Y\right\}|97}} in a power series. To handle the series expansions simply, consider first  log(eXeY)}}. The 
 
 
 
 -series and the 
 
 
 
 -series are given by


 
  respectively. Combining these one obtains {k}{(e^Xe^Y - I)}^k = \sum_{k = 1}^\infty \frac{(-1)^{k + 1}}{k}\left({\sum_{i = 0}^\infty \frac{X^i}{i!}\sum_{j = 0}^\infty \frac{X^j}{j!} - I)}\right)^k = \sum_{k = 1}^\infty \frac{(-1)^{k + 1}}{k} \left(\sum_{i,j \ge 0, i + j > 1}^\infty \frac{X^iY^j}{i!j!} \right)^k.|98}} This becomes {k} \sum_{s \in S_k} \frac{X^{i_1}Y^{j_1}\cdots X^{i_k}Y^{j_k}}{i_1!j_1!\cdots i_k!j_k!}, \quad i_r, j_r \ge 0, \quad i_r + j_r > 0, \quad 1 \le r \le k,        (99) |cellpadding= 6 |border |border colour = #0073CF |bgcolor=#F9FFF7}} where  is the set of all sequences  (i1, j1, …, ik, jk)}} of length 
 
 
 
 
  subject to the conditions in .
Now substitute  for  in the LHS of . Equation  then gives


 
  or, with a switch of notation, see An explicit Baker–Campbell–Hausdorff formula,



Note that the summation index for the rightmost  in the second term in  is denoted , but is not an element of a sequence . Now integrate 
 
 
 
 , using 
 
 
 
 ,



Write this as



But this equals {k + 1} \sum_{s \in S_{k+1}} \frac{1}{i_1 + j_1 + \cdots + i_k + j_k + i_{k + 1} + j_{k+1}}\frac{[X^{(i_1)}Y^{(j_1)}\cdots X^{(i_k)}Y^{(j_k)}X^{(i_{k + 1})}Y^{(j_{k+1})}]}{i_1!j_1!\cdots i_k!j_k!i_{k+1}!j_{k+1}!}, \quad i_r,j_r \ge 0,\quad i_r + j_r > 0,\quad 1 \le r \le k + 1,|100}}
using the simple observation that 
 
 
 
 
  for all 
 
 
 
 . That is, in , the leading term vanishes unless  equals 
 
 
 
  or 
 
 
 
 , corresponding to the first and second terms in the equation before it. In case  0}},  must equal 
 
 
 
 , else the term vanishes for the same reason (

 
 
  0 is not allowed). Finally, shift the index, 
 
 
 
 , {k} \sum_{s \in S_{k}} \frac{1}{i_1 + j_1 + \cdots + i_k + j_k}\frac{[X^{(i_1)}Y^{(j_1)}\cdots X^{(i_k)}Y^{(j_k)}]}{i_1!j_1!\cdots i_k!j_k!},~ i_r,j_r \ge 0,~ i_r + j_r > 0,~ 1 \le r \le k. |cellpadding= 6 |border |border colour = #0073CF |bgcolor=#F9FFF7}} This is Dynkin's formula. The striking similarity with (99) is not accidental: It reflects the Dynkin–Specht–Wever map, underpinning the original, different, derivation of the formula.23 Namely, if


 
  is expressible as a bracket series, then necessarily24  Putting observation  and theorem  together yields a concise proof of the explicit BCH formula. 
See also

Adjoint representation (ad)
Adjoint representation (Ad)
Baker-Campbell-Hausdorff formula
Exponential map
Matrix exponential
Matrix logarithm
Magnus expansion

Remarks
Notes
References


; translation from [http://books.google.com/books?id=D9ZF5O_JH2gC&pg;;=PA31&dq;=Dynkin+Yushkevich++Campbell&hl;=en&sa;=X&ei;=KdRPVNXcKY-xyATHuICYDw&ved;=0CB8Q6AEwAA#v=onepage&q;=Dynkin%20Yushkevich%20%20Campbell&f;=false Google books].

























External links




"
Category:Mathematical physics Category:Matrix theory Category:Lie groups Category:Exponentials



 Appendix on analytic functions.↩
↩
↩
↩
 Theorem 5 Section 1.2↩



A proof of the identity can be found in here. The relationship is simply that between a representation of a Lie group and that of its Lie algebra according to the Lie correspondence, since both 
 
 
 
  and 
 
 
 
  are representations with 
 
 
 
 
 .↩
See also  from which Hall's proof is taken.↩
 This is equation (1.11).↩
It holds that


 for |z - 1| 
 
 

 Here, 
 
 
 
  is the exponential generating function of


 where  are the Bernouilli numbers.↩
This is seen by choosing a basis for the underlying vector space such that 
 
 
 
 
  is triangular, the eigenvalues being the diagonal elements. Then  is triangular with diagonal elements . It follows that the eigenvalues of 
 
 
 
  are . See , Lemma 6 in section 1.2.↩
 Proposition 7, section 1.2.↩
Matrices whose eigenvalues 
 
 
 
  satisfy 
 
 

 Theorem 2.27. Actually, in Hall's setting, 
 
 
 
  is closed in 
 
 
 
  (or $GL( n , ℝ)$) by definition, so there is no closed subgroup theorem, but his proof of $exp$ being a local diffeomorphism is essentially the same as the proof of the closed subgroup theorem.↩
 Section 1.6.↩
Section 3.5.↩
 Section 1.2.↩
↩
 Chapter 2.↩
 Chapter 3.↩

 Chapter 1.12.2.↩




