   Sylvester's criterion      Sylvester's criterion   In mathematics, Sylvester‚Äôs criterion is a necessary and sufficient criterion to determine whether a Hermitian matrix is positive-definite . It is named after James Joseph Sylvester .  Sylvester's criterion states that a Hermitian matrix M is positive-definite if and only if all the following matrices have a positive determinant :   the upper left 1-by-1 corner of M ,  the upper left 2-by-2 corner of M ,  the upper left 3-by-3 corner of M ,      ‚ãÆ    normal-‚ãÆ   {}\quad\vdots     M itself.   In other words, all of the leading principal minors must be positive.  An analogous theorem holds for characterizing positive-semidefinite Hermitian matrices: a Hermitian matrix M is positive-semidefinite if and only if all principal minors of M are nonnegative. 1  Proof  The proof is only for nonsingular Hermitian matrix with coefficients in   ‚Ñù   ‚Ñù   \mathbb{R}   , therefore only for nonsingular real-symmetric matrices  Positive definite or semidefinite matrix: A symmetric matrix A whose eigenvalues are positive ( Œª >¬†0) is called positive definite , and when the eigenvalues are just nonnegative ( Œª ‚â•¬†0), A is said to be positive semidefinite .  Theorem I: A real-symmetric matrix A has nonnegative eigenvalues if and only if A can be factored as A = B T B  , and all eigenvalues are positive if and only if B is nonsingular. 2      Proof:   '''Forward implication: ''' If A ‚àà R n √ó n is symmetric, then, by the spectral theorem , there is an orthogonal matrix P such that A = PDP T , where D = diag¬†( Œª 1 , Œª 2 , . . . , Œª n ) is real diagonal matrix with entries - eigenvalues of A and P is such that its columns are the eigenvectors of A . If Œª i ‚â• 0 for each i , then D 1/2 exists, so A = PDP T = PD 1/2 D 1/2 P T = B T B for B = D 1/2 P T , and Œª i > 0 for each i if and only if B is nonsingular. Reverse implication: Conversely, if A can be factored as A = B T B , then all eigenvalues of A are nonnegative because for any eigenpair ( Œª , x ):      Œª  =     x  T   A  x     x  T   x    =     x  T    B  T   B  x     x  T   x    =     ‚à•   B  x   ‚à•   2     ‚à•  x  ‚à•   2    ‚â•  0.        Œª       superscript  x  T   A  x      superscript  x  T   x              superscript  x  T    superscript  B  T   B  x      superscript  x  T   x            superscript   norm    B  x    2    superscript   norm  x   2         0.     \lambda={\frac{x^{T}Ax}{x^{T}x}}={\frac{x^{T}B^{T}Bx}{x^{T}x}}={\frac{\|Bx\|^{%
 2}}{\|x\|^{2}}}\geq 0.        Theorem II (The Cholesky decomposition): The symmetric matrix A possesses positive pivots if and only if A can be uniquely factored as A = R T R , where R is an upper-triangular matrix with positive diagonal entries. This is known as the Cholesky decomposition of A , and R is called the Cholesky factor of A . 3      Proof:   Forward implication: If A possesses positive pivots (therefore A possesses an LU factorization: A = L ¬∑ U '), then, it has an LDU factorization A = LDU = LDL T in which D =¬†diag( u 11 , u 22 , . . . , u nn ) is the diagonal matrix containing the pivots u ii >¬†0.     ùêÄ   ùêÄ   \displaystyle\mathbf{A}   By a uniqueness property of the LDU decomposition, the symmetry of A yields: U = L T , consequently A = LDU = LDL T . Setting R = D 1/2 L T where D 1/2 = diag(      u  11    ,    u  22    ,  ‚Ä¶  ,    u  11          subscript  u  11       subscript  u  22    normal-‚Ä¶     subscript  u  11      \scriptstyle\sqrt{u_{11}},\scriptstyle\sqrt{u_{22}},\ldots,\scriptstyle\sqrt{u%
 _{11}}   ) yields the desired factorization, because A = LD 1/2 D 1/2 L T = R T R , and R is upper triangular with positive diagonal entries. Reverse implication: Conversely, if A = RR T , where R is lower triangular with a positive diagonal, then factoring the diagonal entries out of R is as follows:       ùêë  =   L  D   =    [     1    0    ‚ãØ    0        r  12   /   r  11      1    ‚ãØ    0      ‚ãÆ    ‚ãÆ       ‚ãÆ        r   1  n    /   r  11        r   2  n    /   r  22      ‚ãØ    1     ]    [      r  11     0    ‚ãØ    0      0     r  22     ‚ãØ    0      ‚ãÆ    ‚ãÆ       ‚ãÆ      0    0    ‚ãØ     r   n  n       ]     .        ùêë    L  D            1  0  normal-‚ãØ  0       subscript  r  12    subscript  r  11    1  normal-‚ãØ  0    normal-‚ãÆ  normal-‚ãÆ  absent  normal-‚ãÆ       subscript  r    1  n     subscript  r  11       subscript  r    2  n     subscript  r  22    normal-‚ãØ  1       subscript  r  11   0  normal-‚ãØ  0    0   subscript  r  22   normal-‚ãØ  0    normal-‚ãÆ  normal-‚ãÆ  absent  normal-‚ãÆ    0  0  normal-‚ãØ   subscript  r    n  n          \mathbf{R}=LD=\begin{bmatrix}1&0&\cdots&0\\
 r_{12}/r_{11}&1&\cdots&0\\
 \vdots&\vdots&&\vdots\\
 r_{1n}/r_{11}&r_{2n}/r_{22}&\cdots&1\end{bmatrix}\begin{bmatrix}r_{11}&0&%
 \cdots&0\\
 0&r_{22}&\cdots&0\\
 \vdots&\vdots&&\vdots\\
 0&0&\cdots&r_{nn}\end{bmatrix}.    R = LD , where L is lower triangular with a unit diagonal and D is the diagonal matrix whose diagonal entries are the r ii ‚Äôs. Consequently, A = LD 2 L T is the LDU factorization for A , and thus the pivots must be positive because they are the diagonal entries in D 2 .     Theorem III: Let A k be the k √ó k leading principal submatrix of A n √ó n . If A has an LU factorization A = LU , then det( A k ) = u 11 u 22 ¬∑ ¬∑ ¬∑ u kk , and the k -th pivot is u kk = det( A 1 ) = a 11 for k = 1, u kk =¬†det( A k )/det( A k ‚àí1 ) for k = 2, 3, . . . , n . 4  Combining Theorem II with Theorem III yields:  Statement I: If the symmetric matrix A can be factored as A=R T R where R is an upper-triangular matrix with positive diagonal entries, then all the pivots of A are positive (by Theorem II ), therefore all the leading principal minors of A are positive (by Theorem III ).  Statement II: If the nonsingular symmetric matrix A can be factored as    A  =    B  T   B       A     superscript  B  T   B     A=B^{T}B   , then the QR decomposition (closely related to Gram-Schmidt process ) of B ( B = QR ) yields    A  =    B  T   B   =    R  T    Q  T   Q  R   =    R  T   R         A     superscript  B  T   B           superscript  R  T    superscript  Q  T   Q  R           superscript  R  T   R      A=B^{T}B=R^{T}Q^{T}QR=R^{T}R   , where Q is orthogonal matrix and R is upper triangular matrix .  Namely Statement II requires the non-singularity of the symmetric matrix A .  Combining Theorem I with Statement I and Statement II yields:  Statement III: If the real-symmetric matrix A is positive definite then A possess factorization of the form A = B T B , where B is nonsingular ( Theorem I ), the expression A = B T B implies that A possess factorization of the form A = R T R where R is an upper-triangular matrix with positive diagonal entries ( Statement II ), therefore all the leading principal minors of A are positive ( Statement I ).  In other words, Statement III states:  Sylvester's Criterion: The real-symmetric matrix A is positive definite if and only if all the leading principal minors of A are positive.  The sufficiency and necessity conditions automatically hold because they were proven for each of the above theorems.  Notes  References    .   . See Theorem 7.2.5.   .   fr:Matrice d√©finie positive#Crit√®re de Sylvester "  Category:Articles containing proofs  Category:Matrix theory            