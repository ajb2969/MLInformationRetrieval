<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="1374">Principal curvature-based region detector</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>Principal curvature-based region detector</h1>
<hr/>

<p>The <strong>principal curvature-based region detector</strong>, also called <strong>PCBR</strong> <a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a> is a <a href="Feature_detection" title="wikilink">feature detector</a> used in the fields of <a href="computer_vision" title="wikilink">computer vision</a> and <a href="image_analysis" title="wikilink">image analysis</a>. Specifically the <strong>PCBR</strong> detector is designed for object recognition applications.</p>

<p>Local region detectors can typically be classified into two categories: <strong>intensity-based detectors</strong> and <strong>structure-based detectors</strong>.</p>
<ul>
<li><strong>Intensity-based detectors</strong> depend on analyzing local differential geometry or intensity patterns to find points or regions that satisfy some uniqueness and stability criteria. These detectors include <a href="Scale-invariant_feature_transform" title="wikilink">SIFT</a>, <a class="uri" href="Hessian-affine" title="wikilink">Hessian-affine</a>, <a class="uri" href="Harris-Affine" title="wikilink">Harris-Affine</a> and <a class="uri" href="MSER" title="wikilink">MSER</a> etc.</li>
</ul>
<ul>
<li><strong>Structure-based detectors</strong> depend on structural image features such as lines, edges, curves, etc. to define interest points or regions. These detectors include <em>edge-based region</em> (EBR) and <em>scale-invariant shape features</em> (SISF)</li>
</ul>

<p>From the detection invariance point of view, feature detectors can be divided into fixed scale detectors such as normal <em>Harris corner detector</em>, scale invariant detectors such as <a href="Scale-invariant_feature_transform" title="wikilink">SIFT</a> and affine invariant detectors such as <a class="uri" href="Hessian-affine" title="wikilink">Hessian-affine</a>.</p>

<p>The <strong>PCBR</strong> detector is a <em>structure-based</em> <em>affine-invariant</em> detector.</p>
<h2 id="why-a-new-detector">Why a new detector?</h2>

<p>In many object recognition tasks, within-class changes in pose, lighting, color, and texture can cause considerable variation in local intensities. Consequently, local intensity no longer provides a stable detection cue. As such, intensity-based interest operators (e.g., <a href="Scale-invariant_feature_transform" title="wikilink">SIFT</a>, <a class="uri" href="Harris-Affine" title="wikilink">Harris-Affine</a>)–and the object recognition systems based on them–often fail to identify discriminative features. An alternative to local intensity cues is to capture semi-local structural cues such as edges and curvilinear shapes. These structural cues tend to be more robust to intensity, color, and pose variations. As such, they provide the basis for a more stable interest operator, which in turn improves object recognition accuracy. <em>PCBR</em> detector was developed to exploit these more reliable image structural cues.</p>
<h2 id="algorithm-description">Algorithm description</h2>
<h3 id="step-1-curvilinear-structure-detections">Step 1: Curvilinear structure detections</h3>

<p>As a structure-based detector, <em>PCBR</em> does not use edges, instead, it uses curvilinear structures, also called <a href="Ridge_detection" title="wikilink">ridges</a>. Curvilinear structures detection generates a single response for both lines and edges, producing a clearer structural sketch of an image than is usually provided by the gradient magnitude image. The Steger's algorithm <a class="footnoteRef" href="#fn2" id="fnref2"><sup>2</sup></a> is modified to get the curvilinear images. As only the first step of this algorithm is used which is to calculate the principal curvature images, the principal curvature is adopted as the name of this detector. To get the principal curvature, the Hessian matrix is calculated:</p>

<p>
<math display="inline" id="Principal_curvature-based_region_detector:0">
<semantics>
<mrow>
<mrow>
<mi>H</mi>
<mrow>
<mo stretchy="false">(</mo>
<mi>𝐱</mi>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
<mo>=</mo>
<mrow>
<mo>[</mo>
<mtable>
<mtr>
<mtd columnalign="center">
<mrow>
<msub>
<mi>L</mi>
<mrow>
<mi>x</mi>
<mi>x</mi>
</mrow>
</msub>
<mrow>
<mo stretchy="false">(</mo>
<mi>𝐱</mi>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
</mtd>
<mtd columnalign="center">
<mrow>
<msub>
<mi>L</mi>
<mrow>
<mi>x</mi>
<mi>y</mi>
</mrow>
</msub>
<mrow>
<mo stretchy="false">(</mo>
<mi>𝐱</mi>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
</mtd>
</mtr>
<mtr>
<mtd columnalign="center">
<mrow>
<msub>
<mi>L</mi>
<mrow>
<mi>x</mi>
<mi>y</mi>
</mrow>
</msub>
<mrow>
<mo stretchy="false">(</mo>
<mi>𝐱</mi>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
</mtd>
<mtd columnalign="center">
<mrow>
<msub>
<mi>L</mi>
<mrow>
<mi>y</mi>
<mi>y</mi>
</mrow>
</msub>
<mrow>
<mo stretchy="false">(</mo>
<mi>𝐱</mi>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
</mtd>
</mtr>
</mtable>
<mo>]</mo>
</mrow>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<eq></eq>
<apply>
<times></times>
<ci>H</ci>
<ci>𝐱</ci>
</apply>
<matrix>
<matrixrow>
<apply>
<times></times>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>L</ci>
<apply>
<times></times>
<ci>x</ci>
<ci>x</ci>
</apply>
</apply>
<ci>𝐱</ci>
</apply>
<apply>
<times></times>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>L</ci>
<apply>
<times></times>
<ci>x</ci>
<ci>y</ci>
</apply>
</apply>
<ci>𝐱</ci>
</apply>
</matrixrow>
<matrixrow>
<apply>
<times></times>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>L</ci>
<apply>
<times></times>
<ci>x</ci>
<ci>y</ci>
</apply>
</apply>
<ci>𝐱</ci>
</apply>
<apply>
<times></times>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>L</ci>
<apply>
<times></times>
<ci>y</ci>
<ci>y</ci>
</apply>
</apply>
<ci>𝐱</ci>
</apply>
</matrixrow>
</matrix>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   H(\mathbf{x})=\begin{bmatrix}L_{xx}(\mathbf{x})&amp;L;_{xy}(\mathbf{x})\\
L_{xy}(\mathbf{x})&amp;L;_{yy}(\mathbf{x})\\
\end{bmatrix}
  </annotation>
</semantics>
</math>
</p>

<p>where 

<math display="inline" id="Principal_curvature-based_region_detector:1">
<semantics>
<mrow>
<msub>
<mi>L</mi>
<mrow>
<mi>a</mi>
<mi>a</mi>
</mrow>
</msub>
<mrow>
<mo stretchy="false">(</mo>
<mi>𝐱</mi>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<times></times>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>L</ci>
<apply>
<times></times>
<ci>a</ci>
<ci>a</ci>
</apply>
</apply>
<ci>𝐱</ci>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   L_{aa}(\mathbf{x})
  </annotation>
</semantics>
</math>

 is second partial derivative of the image evaluated at point x in the 

<math display="inline" id="Principal_curvature-based_region_detector:2">
<semantics>
<mi>a</mi>
<annotation-xml encoding="MathML-Content">
<ci>a</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   a
  </annotation>
</semantics>
</math>

 direction and 

<math display="inline" id="Principal_curvature-based_region_detector:3">
<semantics>
<mrow>
<msub>
<mi>L</mi>
<mrow>
<mi>a</mi>
<mi>b</mi>
</mrow>
</msub>
<mrow>
<mo stretchy="false">(</mo>
<mi>𝐱</mi>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<times></times>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>L</ci>
<apply>
<times></times>
<ci>a</ci>
<ci>b</ci>
</apply>
</apply>
<ci>𝐱</ci>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   L_{ab}(\mathbf{x})
  </annotation>
</semantics>
</math>

 is the mixed partial second derivative of the image evaluated at point x in the 

<math display="inline" id="Principal_curvature-based_region_detector:4">
<semantics>
<mi>a</mi>
<annotation-xml encoding="MathML-Content">
<ci>a</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   a
  </annotation>
</semantics>
</math>

 and 

<math display="inline" id="Principal_curvature-based_region_detector:5">
<semantics>
<mi>b</mi>
<annotation-xml encoding="MathML-Content">
<ci>b</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   b
  </annotation>
</semantics>
</math>

 directions. The maximum and minimum eigenvalues of this matrix form two images which correspond to white lines on black background and black lines on white background.</p>
<h3 id="step-2-seeking-characteristics-and-robustness-in-scale-space">Step 2: Seeking characteristics and robustness in scale space</h3>

<p>To make this detector scale invariance and improve the detection robustness, the process of David Lowe's <a class="footnoteRef" href="#fn3" id="fnref3"><sup>3</sup></a> <a href="Scale-invariant_feature_transform" title="wikilink">SIFT</a> detector is simulated to detect principal curvilinear structure in scale space. Local maximum images of principal curvature values are used to define regions.</p>
<h3 id="step-3-defining-regions-by-enhanced-watershed-algorithms">Step 3: Defining regions by enhanced watershed algorithms</h3>

<p>The principal curvature images are cleaned by a morphological closing and eigenvector-flow guided hysteresis thresholding. Then traditional watershed algorithm is applied on images to acquire regions.</p>
<h3 id="step-4-stable-region-selections">Step 4: Stable region selections</h3>

<p>Similar to the process of selecting stable regions via thresholding in <a class="uri" href="MSER" title="wikilink">MSER</a>,<a class="footnoteRef" href="#fn4" id="fnref4"><sup>4</sup></a> stable regions are selected across local scale changes. To achieve this, overlap error is computed across each triplet of consecutive scales. If the region overlap error is greater than 90%, only one region is kept. If the error is greater than 70% and less than 90%, all regions are kept. If overlap is less than 70%, discard these regions. These numbers are determined by the analysis of sensitivity of the <a href="Scale-invariant_feature_transform" title="wikilink">SIFT</a> descriptor.</p>
<h2 id="how-does-the-pcbr-differ">How does the PCBR differ?</h2>
<ul>
<li>It is a structure-based detector.</li>
<li>It is designed to handle within-class variance.</li>
<li>It is used when local intensity is not stable.</li>
<li>It detects a semi-local characteristic region.</li>
</ul>
<h2 id="software-packages">Software Packages</h2>

<p>Binary code of an implementation of <em>PCBR</em> can be downloaded from Tom Dietterich's webpage.<a class="footnoteRef" href="#fn5" id="fnref5"><sup>5</sup></a></p>
<h2 id="see-also">See also</h2>
<ul>
<li><a href="Scale-invariant_feature_transform" title="wikilink">SIFT</a></li>
<li><a class="uri" href="MSER" title="wikilink">MSER</a></li>
<li><a class="uri" href="Hessian-Affine" title="wikilink">Hessian-Affine</a></li>
<li><a class="uri" href="Harris-Affine" title="wikilink">Harris-Affine</a></li>
<li><a href="Scale_space" title="wikilink">Scale space</a></li>
<li><a href="Corner_detection" title="wikilink">Corner detection</a></li>
<li><a href="Blob_detection" title="wikilink">Blob detection</a></li>
<li><a href="Interest_point_detection" title="wikilink">Interest point detection</a></li>
<li><a href="Computer_vision" title="wikilink">Computer vision</a></li>
</ul>
<h2 id="references">References</h2>

<p>"</p>

<p><a href="Category:Feature_detection_(computer_vision)" title="wikilink">Category:Feature detection (computer vision)</a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1"><a href="#fnref1">↩</a></li>
<li id="fn2"><a href="#fnref2">↩</a></li>
<li id="fn3"><a href="#fnref3">↩</a></li>
<li id="fn4"><a href="#fnref4">↩</a></li>
<li id="fn5"><a href="#fnref5">↩</a></li>
</ol>
</section>
</body>
</html>
