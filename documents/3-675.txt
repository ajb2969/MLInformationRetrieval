


Levenshtein distance




Levenshtein distance

 table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
   margin: 0; padding: 0; vertical-align: baseline; border: none; }
 <style>
 table.sourceCode { width: 100%; line-height: 100%; }
 td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
 td.sourceCode { padding-left: 5px; }
 code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
 code > span.dt { color: #902000; } /* DataType */
 code > span.dv { color: #40a070; } /* DecVal */
 code > span.bn { color: #40a070; } /* BaseN */
 code > span.fl { color: #40a070; } /* Float */
 code > span.ch { color: #4070a0; } /* Char */
 code > span.st { color: #4070a0; } /* String */
 code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
 code > span.ot { color: #007020; } /* Other */
 code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
 code > span.fu { color: #06287e; } /* Function */
 code > span.er { color: #ff0000; font-weight: bold; } /* Error */
 code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
 code > span.cn { color: #880000; } /* Constant */
 code > span.sc { color: #4070a0; } /* SpecialChar */
 code > span.vs { color: #4070a0; } /* VerbatimString */
 code > span.ss { color: #bb6688; } /* SpecialString */
 code > span.im { } /* Import */
 code > span.va { color: #19177c; } /* Variable */
 code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
 code > span.op { color: #666666; } /* Operator */
 code > span.bu { } /* BuiltIn */
 code > span.ex { } /* Extension */
 code > span.pp { color: #bc7a00; } /* Preprocessor */
 code > span.at { color: #7d9029; } /* Attribute */
 code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
 code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
 code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
 code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
   



In information theory and computer science, the Levenshtein distance is a string metric for measuring the difference between two sequences. Informally, the Levenshtein distance between two words is the minimum number of single-character edits (i.e. insertions, deletions or substitutions) required to change one word into the other. It is named after Vladimir Levenshtein, who considered this distance in 1965.1
Levenshtein distance may also be referred to as edit distance, although that may also denote a larger family of distance metrics.2 It is closely related to pairwise string alignments.
Definition
Mathematically, the Levenshtein distance between two strings 
 
 
 
  (of length 
 
 
 
  and 
 
 
 
  respectively) is given by 
 
 
 
  where


 
  where 
 
 
 
  is the indicator function equal to 0 when 
 
 
 
  and equal to 1 otherwise.
Note that the first element in the minimum corresponds to deletion (from 
 
 
 
  to 
 
 
 
 ), the second to insertion and the third to match or mismatch, depending on whether the respective symbols are the same.
Example
For example, the Levenshtein distance between "kitten" and "sitting" is 3, since the following three edits change one into the other, and there is no way to do it with fewer than three edits:

kitten → sitten (substitution of "s" for "k")
sitten → sittin (substitution of "i" for "e")
sittin → sitting (insertion of "g" at the end).

Upper and lower bounds
The Levenshtein distance has several simple upper and lower bounds. These include:

It is always at least the difference of the sizes of the two strings.
It is at most the length of the longer string.
It is zero if and only if the strings are equal.
If the strings are the same size, the Hamming distance is an upper bound on the Levenshtein distance.
The Levenshtein distance between two strings is no greater than the sum of their Levenshtein distances from a third string (triangle inequality).

An example where the Levenshtein distance between two strings of the same length is strictly less than the Hamming distance is given by the pair "flaw" and "lawn". Here the Levenshtein distance equals 2 (delete "f" from the front; insert "n" at the end). The Hamming distance is 4.
Applications
In approximate string matching, the objective is to find matches for short strings in many longer texts, in situations where a small number of differences is to be expected. The short strings could come from a dictionary, for instance. Here, one of the strings is typically short, while the other is arbitrarily long. This has a wide range of applications, for instance, spell checkers, correction systems for optical character recognition, and software to assist natural language translation based on translation memory.
The Levenshtein distance can also be computed between two longer strings, but the cost to compute it, which is roughly proportional to the product of the two string lengths, makes this impractical. Thus, when used to aid in fuzzy string searching in applications such as record linkage, the compared strings are usually short to help improve speed of comparisons.
Relationship with other edit distance metrics
There are other popular measures of edit distance, which are calculated using a different set of allowable edit operations. For instance,

the Damerau–Levenshtein distance allows insertion, deletion, substitution, and the transposition of two adjacent characters;
the longest common subsequence metric allows only insertion and deletion, not substitution;
the Hamming distance allows only substitution, hence, it only applies to strings of the same length.

Edit distance is usually defined as a parameterizable metric calculated with a specific set of allowed edit operations, and each operation is assigned a cost (possibly infinite). This is further generalized by DNA sequence alignment algorithms such as the Smith–Waterman algorithm, which make an operation's cost depend on where it is applied.
Computing Levenshtein distance
Recursive
This is a straightforward, but inefficient, recursive C implementation of a LevenshteinDistance function that takes two strings, s and t, together with their lengths, and returns the Levenshtein distance between them:
// len_s and len_t are the number of characters in string s and t respectively
 int LevenshteinDistance(string s, int len_s, string t, int len_t)
 { int cost;
 
   /* base case: empty strings */
   if (len_s == 0) return len_t;
   if (len_t == 0) return len_s;
 
   /* test if last characters of the strings match */
   if (s[len_s-1] == t[len_t-1])
       cost = 0;
   else
       cost = 1;
 
   /* return minimum of delete char from s, delete char from t, and delete char from both */
   return minimum(LevenshteinDistance(s, len_s - 1, t, len_t    ) + 1,
                  LevenshteinDistance(s, len_s    , t, len_t - 1) + 1,
                  LevenshteinDistance(s, len_s - 1, t, len_t - 1) + cost);
 }
This recursive implementation is straightforward, but very inefficient, because it recomputes the Levenshtein distance of the same substrings many times.
A more efficient method would never repeat the same distance calculation. For example, the Levenshtein distance of all possible prefixes might be stored in an array d[][] where d[i][j] is the distance between the first i characters of string s and the first j characters of string t. The table is easy to construct one row at a time starting with row 0. When the entire table has been built, the desired distance is d[len_s][len_t]. While this technique is significantly faster, it will consume len_s * len_t more memory than the straightforward recursive implementation.
Iterative with full matrix







Computing the Levenshtein distance is based on the observation that if we reserve a matrix to hold the Levenshtein distances between all prefixes of the first string and all prefixes of the second, then we can compute the values in the matrix in a dynamic programming fashion, and thus find the distance between the two full strings as the last value computed.
This algorithm, an example of bottom-up dynamic programming, is discussed, with variants, in the 1974 article The String-to-string correction problem by Robert A. Wagner and Michael J. Fischer.3
This is a straightforward pseudocode implementation for a function LevenshteinDistance that takes two strings, s of length m, and t of length n, and returns the Levenshtein distance between them:
function LevenshteinDistance(char s[1..m], char t[1..n]):
   // for all i and j, d[i,j] will hold the Levenshtein distance between
   // the first i characters of s and the first j characters of t;
   // note that d has (m+1)*(n+1) values
   declare int d[0..m, 0..n]
  
   set each element in d to zero
  
   // source prefixes can be transformed into empty string by
   // dropping all characters
   for i from 1 to m:
       d[i, 0] := i
  
   // target prefixes can be reached from empty source prefix
   // by inserting every character
   for j from 1 to n:
       d[0, j] := j
  
   for j from 1 to n:
       for i from 1 to m:
           if s[i] = t[j]:
             d[i, j] := d[i-1, j-1]              // no operation required
           else:
             d[i, j] := minimum(d[i-1, j] + 1,   // a deletion
                                d[i, j-1] + 1,   // an insertion
                                d[i-1, j-1] + 1) // a substitution
  
   return d[m, n]
Note that this implementation does not fit the definition precisely: it always prefers matches, even if insertions or deletions provided a better score. This is equivalent; it can be shown that for every optimal alignment (which induces the Levenshtein distance) there is another optimal alignment that prefers matches in the sense of this implementation.4
Two examples of the resulting matrix (hovering over a number reveals the operation performed to get that number):







k

i

t

t

e

n




0

1

2

3

4

5

6



s

1


2

3

4

5

6



i

2

2


2

3

4

5



t

3

3

2


2

3

4



t

4

4

3

2


2

3



i

5

5

4

3

2


3



n

6

6

5

4

3

3




g

7

7

6

5

4

4










S

a

t

u

r

d

a

y




0

1

2

3

4

5

6

7

8



S

1




3

4

5

6

7



u

2

1

1

2


3

4

5

6



n

3

2

2

2

3


4

5

6



d

4

3

3

3

3

4


4

5



a

5

4

3

4

4

4

4


4



y

6

5

4

4

5

5

5

4





The invariant maintained throughout the algorithm is that we can transform the initial segment s[1..i] into t[1..j] using a minimum of d[i,j] operations. At the end, the bottom-right element of the array contains the answer.
Iterative with two matrix rows
It turns out that only two rows of the table are needed for the construction if one does not want to reconstruct the edited input strings (the previous row and the current row being calculated).
The Levenshtein distance may be calculated iteratively using the following algorithm:5
int LevenshteinDistance(string s, string t)
 {
     // degenerate cases
     if (s == t) return 0;
     if (s.Length == 0) return t.Length;
     if (t.Length == 0) return s.Length;
 
     // create two work vectors of integer distances
     int[] v0 = new int[t.Length + 1];
     int[] v1 = new int[t.Length + 1];
 
     // initialize v0 (the previous row of distances)
     // this row is A[0][i]: edit distance for an empty s
     // the distance is just the number of characters to delete from t
     for (int i = 0; i < v0.Length; i++)
         v0[i] = i;
 
     for (int i = 0; i < s.Length; i++)
     {
         // calculate v1 (current row distances) from the previous row v0
 
         // first element of v1 is A[i+1][0]
         //   edit distance is delete (i+1) chars from s to match empty t
         v1[0] = i + 1;
 
         // use formula to fill in the rest of the row
         for (int j = 0; j < t.Length; j++)
         {
             var cost = (s[i] == t[j]) ? 0 : 1;
             v1[j + 1] = Minimum(v1[j] + 1, v0[j + 1] + 1, v0[j] + cost);
         }
 
         // copy v1 (current row) to v0 (previous row) for next iteration
         for (int j = 0; j < v0.Length; j++)
             v0[j] = v1[j];
     }
 
     return v1[t.Length];
 }
See also

agrep
Approximate string matching
Bitap algorithm
Damerau–Levenshtein distance
diff
MinHash
Dynamic time warping
Euclidean distance
Fuzzy string searching
Hamming weight
Hirschberg's algorithm
Homology of sequences in genetics
Hunt–McIlroy algorithm
Jaccard index
Jaro–Winkler distance
Levenshtein automaton
Locality-sensitive hashing
Longest common subsequence problem
Lucene (an open source search engine that implements edit distance)
Manhattan distance
Metric space
Most frequent k characters
Needleman–Wunsch algorithm
Optimal matching algorithm
Sequence alignment
Similarity space on Numerical taxonomy
Smith–Waterman algorithm
Sørensen similarity index
String distance metric
Wagner-Fischer algorithm

References
External links

Levenshtein in PostgreSQL


"
Category:String similarity measures Category:Dynamic programming Category:Articles with example pseudocode Category:Quantitative linguistics



 Appeared in English as: 


Micro-optimisation for edit distance computation: is it valid?




