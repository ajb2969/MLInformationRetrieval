   Erasure code      Erasure code   In information theory , an erasure code is a forward error correction (FEC) code for the binary erasure channel , which transforms a message of k symbols into a longer message (code word) with n symbols such that the original message can be recovered from a subset of the n symbols. The fraction r = k / n is called the code rate , the fraction k’/k , where k’ denotes the number of symbols required for recovery, is called reception efficiency .  Optimal erasure codes  Optimal erasure codes have the property that any k out of the n code word symbols are sufficient to recover the original message (i.e., they have optimal reception efficiency). Optimal erasure codes are maximum distance separable codes (MDS codes).  Optimal codes are often costly (in terms of memory usage, CPU time, or both) when n is large. Except for very simple schemes, practical solutions usually have quadratic encoding and decoding complexity . In 2014, Lin et al. 1 gave an approach with    O   (   n   log  n    )       O    n    n      O(n\log n)   operations.  Parity check  Parity check is the special case where n = k + 1. From a set of k values     {   v  i   }    1  ≤  i  ≤  k      subscript    subscript  v  i        1  i       k      \{v_{i}\}_{1\leq i\leq k}   , a checksum is computed and appended to the k source values:        v   k  +  1    =   -    ∑   i  =  1   k    v  i      .       subscript  v    k  1        superscript   subscript     i  1    k    subscript  v  i       v_{k+1}=-\sum_{i=1}^{k}v_{i}.   The set of k + 1 values     {   v  i   }    1  ≤  i  ≤   k  +  1       subscript    subscript  v  i        1  i         k  1       \{v_{i}\}_{1\leq i\leq k+1}   is now consistent with regard to the checksum. If one of these values,    v  e     subscript  v  e    v_{e}   , is erased, it can be easily recovered by summing the remaining variables:        v  e   =   -    ∑    i  =  1   ,   i  ≠  e     k  +  1     v  i      .       subscript  v  e       superscript   subscript    formulae-sequence    i  1     i  e       k  1     subscript  v  i       v_{e}=-\sum_{i=1,i\neq e}^{k+1}v_{i}.     Polynomial oversampling  ====Example: Err-mail ( k = 2)==== In the simple case where k = 2, redundancy symbols may be created by sampling different points along the line between the two original symbols. This is pictured with a simple example, called err-mail:  Alice wants to send her telephone number (555629) to Bob using err-mail. Err-mail works just like e-mail, except   About half of all the mail gets lost. 2  Messages longer than 5 characters are illegal.  It is very expensive (similar to air-mail).   Instead of asking Bob to acknowledge the messages she sends, Alice devises the following scheme.   She breaks her telephone number up into two parts a = 555, b = 629, and sends 2 messages – " A = 555" and " B = 629" – to Bob.  She constructs a linear function,     f   (  i  )    =   a  +    (   b  -  a   )    (   i  -  1   )           f  i     a      b  a     i  1       f(i)=a+(b-a)(i-1)   , in this case     f   (  i  )    =   555  +   74   (   i  -  1   )           f  i     555    74    i  1       f(i)=555+74(i-1)   , such that     f   (  1  )    =  555        f  1   555    f(1)=555   and     f   (  2  )    =  629        f  2   629    f(2)=629   .   (Figure)  Optimal Erasure Codes1.gif    She computes the values f (3), f (4), and f (5), and then transmits three redundant messages: "C = 703", "D = 777" and "E = 851".   Bob knows that the form of f ( k ) is     f   (  i  )    =   a  +    (   b  -  a   )    (   i  -  1   )           f  i     a      b  a     i  1       f(i)=a+(b-a)(i-1)   , where a and b are the two parts of the telephone number. Now suppose Bob receives "D = 777" and "E = 851".  (Figure)  Optimal Erasure Codes2.gif   Bob can reconstruct Alice's phone number by computing the values of a and b from the values ( f (4) and f (5)) he has received. Bob can perform this procedure using any two err-mails, so the erasure code in this example has a rate of 40%.  Note that Alice cannot encode her telephone number in just one err-mail, because it contains six characters, and the maximum length of one err-mail message is five characters. If she sent her phone number in pieces, asking Bob to acknowledge receipt of each piece, at least four messages would have to be sent anyway (two from Alice, and two acknowledgments from Bob). So the erasure code in this example, which requires five messages, is quite economical.  This example is a little bit contrived. For truly generic erasure codes that work over any data set, we would need something other than the f ( i ) given.  General case  The linear construction above can be generalized to polynomial interpolation . Additionally, points are now computed over a finite field .  First we choose a finite field F with order of at least n , but usually a power of 2. The sender numbers the data symbols from 0 to k − 1 and sends them. He then constructs a (Lagrange) polynomial  p ( x ) of order k such that p ( i ) is equal to data symbol i . He then sends p ( k ), ..., p ( n − 1). The receiver can now also use polynomial interpolation to recover the lost packets, provided he receives k symbols successfully. If the order of F is less than 2 b , where b is the number of bits in a symbol, then multiple polynomials can be used.  The sender can construct symbols k to n − 1 'on the fly', i.e., distribute the workload evenly between transmission of the symbols. If the receiver wants to do his calculations 'on the fly', he can construct a new polynomial q , such that q ( i ) = p ( i ) if symbol i 0). Reducing ε can be done at the cost of CPU time. Near-optimal erasure codes trade correction capabilities for computational complexity: practical algorithms can encode and decode with linear time complexity.  Fountain codes (also known as rateless erasure codes ) are notable examples of near-optimal erasure codes . They can transform a k symbol message into a practically infinite encoded form, i.e., they can generate an arbitrary amount of redundancy symbols that can all be used for error correction. Receivers can start decoding after they have received slightly more than k encoded symbols.  Regenerating codes address the issue of rebuilding (also called repairing) lost encoded fragments from existing encoded fragments. This issue arises in distributed storage systems where communication to maintain encoded redundancy is a problem.  Examples  Near optimal erasure codes   Tornado codes  Low-density parity-check codes   Near optimal fountain (rateless erasure) codes   Online codes  LT codes  Raptor codes   Optimal erasure codes   Parity : used in RAID storage systems.  Parchive  Tahoe-LAFS includes zfec  Reed–Solomon coding  Erasure Resilient Systematic Code , an MDS code outperforming Reed–Solomon in the maximal number of redundant packets, see RS(4,2) with 2 bits or RS(9,2) with 3 bits  Regenerating Codes 3 see also 1 .  any other MDS code   Other   Spelling alphabet   See also   Forward error correction codes.   References  External links   Jerasure is a Free Software library implementing Reed-Solomon and Cauchy erasure code techniques with SIMD optimisations.  Software FEC in computer communications by Luigi Rizzo describes optimal erasure correction codes  Feclib is a near optimal extension to Luigi Rizzo's work that uses band matrices. Many parameters can be set, like the size of the width of the band and size of the finite field. It also successfully exploits the large register size of modern CPUs. How it compares to the near optimal codes mentioned above is unknown.  Coding for Distributed Storage wiki for regenerating codes and rebuilding erasure codes.   "  Category:Coding theory     Sian-Jheng Lin, Wei-Ho Chung, and Yunghsiang S. Han, "Novel polynomial basis and its application to Reed-Solomon erasure codes", The 55th Annual Symposium on Foundations of Computer Science (FOCS 2014). ↩  Some versions of this story refer to the err-mail daemon. ↩  ↩     