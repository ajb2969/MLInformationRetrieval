<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="1580">Trust region</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>Trust region</h1>
<hr/>

<p><strong>Trust region</strong> is a term used in <a href="optimization_(mathematics)" title="wikilink">mathematical optimization</a> to denote the subset of the region of the <a href="objective_function" title="wikilink">objective function</a> that is approximated using a model function (often a <a href="quadratic_function" title="wikilink">quadratic</a>). If an adequate model of the objective function is found within the trust region then the region is expanded; conversely, if the approximation is poor then the region is contracted. Trust region methods are also known as <strong>restricted step methods</strong>.</p>

<p>The fit is evaluated by comparing the ratio of expected improvement from the model approximation with the actual improvement observed in the objective function. Simple thresholding of the ratio is used as the criterion for expansion and contraction—a model function is "trusted" only in the region where it provides a reasonable approximation.</p>

<p>Trust region methods are in some sense dual to <a href="line_search" title="wikilink">line search</a> methods: trust region methods first choose a step size (the size of the trust region) and then a step direction while line search methods first choose a step direction and then a step size.</p>

<p>The earliest use of the term seems to be by Sorensen (1982).</p>
<h2 id="example">Example</h2>

<p>Conceptually, in the <a href="Levenberg–Marquardt_algorithm" title="wikilink">Levenberg–Marquardt algorithm</a>, the objective function is iteratively approximated by a <a href="quadratic_surface" title="wikilink">quadratic surface</a>, then using a linear solve, the estimate is updated. This alone may not converge nicely if the initial guess is too far from the optimum. For this reason, the algorithm instead restricts each step, preventing it from stepping "too far". It operationalizes "too far" as follows. Rather than solving 

<math display="inline" id="Trust_region:0">
 <semantics>
  <mrow>
   <mrow>
    <mi>A</mi>
    <mi mathvariant="normal">Δ</mi>
    <mi>x</mi>
   </mrow>
   <mo>=</mo>
   <mi>b</mi>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <times></times>
     <ci>A</ci>
     <ci>normal-Δ</ci>
     <ci>x</ci>
    </apply>
    <ci>b</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   A\Delta x=b
  </annotation>
 </semantics>
</math>

 for 

<math display="inline" id="Trust_region:1">
 <semantics>
  <mrow>
   <mi mathvariant="normal">Δ</mi>
   <mi>x</mi>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <ci>normal-Δ</ci>
    <ci>x</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \Delta x
  </annotation>
 </semantics>
</math>

, it solves 

<math display="inline" id="Trust_region:2">
 <semantics>
  <mrow>
   <mrow>
    <mrow>
     <mo stretchy="false">(</mo>
     <mrow>
      <mi>A</mi>
      <mo>+</mo>
      <mrow>
       <mi>λ</mi>
       <mrow>
        <mo>diag</mo>
        <mrow>
         <mo stretchy="false">(</mo>
         <mi>A</mi>
         <mo stretchy="false">)</mo>
        </mrow>
       </mrow>
      </mrow>
     </mrow>
     <mo stretchy="false">)</mo>
    </mrow>
    <mi mathvariant="normal">Δ</mi>
    <mi>x</mi>
   </mrow>
   <mo>=</mo>
   <mi>b</mi>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <times></times>
     <apply>
      <plus></plus>
      <ci>A</ci>
      <apply>
       <times></times>
       <ci>λ</ci>
       <apply>
        <ci>diag</ci>
        <ci>A</ci>
       </apply>
      </apply>
     </apply>
     <ci>normal-Δ</ci>
     <ci>x</ci>
    </apply>
    <ci>b</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   (A+\lambda\operatorname{diag}(A))\Delta x=b
  </annotation>
 </semantics>
</math>

 where 

<math display="inline" id="Trust_region:3">
 <semantics>
  <mrow>
   <mo>diag</mo>
   <mrow>
    <mo stretchy="false">(</mo>
    <mi>A</mi>
    <mo stretchy="false">)</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <ci>diag</ci>
    <ci>A</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \operatorname{diag}(A)
  </annotation>
 </semantics>
</math>

 is the diagonal matrix with the same diagonal as <em>A</em> and λ is a parameter that controls the trust-region size. Geometrically, this adds a paraboloid centered at 

<math display="inline" id="Trust_region:4">
 <semantics>
  <mrow>
   <mrow>
    <mi mathvariant="normal">Δ</mi>
    <mi>x</mi>
   </mrow>
   <mo>=</mo>
   <mn>0</mn>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <times></times>
     <ci>normal-Δ</ci>
     <ci>x</ci>
    </apply>
    <cn type="integer">0</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \Delta x=0
  </annotation>
 </semantics>
</math>

 to the <a href="quadratic_form" title="wikilink">quadratic form</a>, resulting in a smaller step.</p>

<p>The trick is to change the trust-region size (λ). At each iteration, the damped quadratic fit predicts a certain reduction in the cost function, 

<math display="inline" id="Trust_region:5">
 <semantics>
  <mrow>
   <mi mathvariant="normal">Δ</mi>
   <msub>
    <mi>f</mi>
    <mi>pred</mi>
   </msub>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <ci>normal-Δ</ci>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>f</ci>
     <ci>pred</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \Delta f_{\mathrm{pred}}
  </annotation>
 </semantics>
</math>

, which we would expect to be a smaller reduction than the true reduction. Given 

<math display="inline" id="Trust_region:6">
 <semantics>
  <mrow>
   <mi mathvariant="normal">Δ</mi>
   <mi>x</mi>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <ci>normal-Δ</ci>
    <ci>x</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \Delta x
  </annotation>
 </semantics>
</math>

 we can evaluate</p>

<p>

<math display="block" id="Trust_region:7">
 <semantics>
  <mrow>
   <mrow>
    <mi mathvariant="normal">Δ</mi>
    <msub>
     <mi>f</mi>
     <mi>actual</mi>
    </msub>
   </mrow>
   <mo>=</mo>
   <mrow>
    <mrow>
     <mi>f</mi>
     <mrow>
      <mo stretchy="false">(</mo>
      <mrow>
       <mi>x</mi>
       <mo>+</mo>
       <mrow>
        <mi mathvariant="normal">Δ</mi>
        <mi>x</mi>
       </mrow>
      </mrow>
      <mo stretchy="false">)</mo>
     </mrow>
    </mrow>
    <mo>-</mo>
    <mrow>
     <mi>f</mi>
     <mrow>
      <mo stretchy="false">(</mo>
      <mi>x</mi>
      <mo stretchy="false">)</mo>
     </mrow>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <times></times>
     <ci>normal-Δ</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>f</ci>
      <ci>actual</ci>
     </apply>
    </apply>
    <apply>
     <minus></minus>
     <apply>
      <times></times>
      <ci>f</ci>
      <apply>
       <plus></plus>
       <ci>x</ci>
       <apply>
        <times></times>
        <ci>normal-Δ</ci>
        <ci>x</ci>
       </apply>
      </apply>
     </apply>
     <apply>
      <times></times>
      <ci>f</ci>
      <ci>x</ci>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \Delta f_{\mathrm{actual}}=f(x+\Delta x)-f(x)
  </annotation>
 </semantics>
</math>

 By looking at the ratio 

<math display="inline" id="Trust_region:8">
 <semantics>
  <mrow>
   <mrow>
    <mrow>
     <mi mathvariant="normal">Δ</mi>
     <msub>
      <mi>f</mi>
      <mi>pred</mi>
     </msub>
    </mrow>
    <mo>/</mo>
    <mi mathvariant="normal">Δ</mi>
   </mrow>
   <msub>
    <mi>f</mi>
    <mi>actual</mi>
   </msub>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <apply>
     <divide></divide>
     <apply>
      <times></times>
      <ci>normal-Δ</ci>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>f</ci>
       <ci>pred</ci>
      </apply>
     </apply>
     <ci>normal-Δ</ci>
    </apply>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>f</ci>
     <ci>actual</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \Delta f_{\mathrm{pred}}/\Delta f_{\mathrm{actual}}
  </annotation>
 </semantics>
</math>

 we can adjust the trust-region size. In general, we expect 

<math display="inline" id="Trust_region:9">
 <semantics>
  <mrow>
   <mi mathvariant="normal">Δ</mi>
   <msub>
    <mi>f</mi>
    <mi>pred</mi>
   </msub>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <ci>normal-Δ</ci>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>f</ci>
     <ci>pred</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \Delta f_{\mathrm{pred}}
  </annotation>
 </semantics>
</math>

 to be a bit less than 

<math display="inline" id="Trust_region:10">
 <semantics>
  <mrow>
   <mi mathvariant="normal">Δ</mi>
   <msub>
    <mi>f</mi>
    <mi>actual</mi>
   </msub>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <ci>normal-Δ</ci>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>f</ci>
     <ci>actual</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \Delta f_{\mathrm{actual}}
  </annotation>
 </semantics>
</math>

 and so the ratio would be between, say, 0.25 and 0.5. If the ratio is more than 0.5, then we aren't damping the step much, so expand the trust region (decrease λ), and iterate. If the ratio is smaller than 0.25, then the true function is diverging "too much" from the trust-region approximation, so shrink the trust region (increase λ) and try again.</p>
<h2 id="references">References</h2>
<ul>
<li>Andrew R. Conn, Nicholas I. M. Gould, Philippe L. Toint "<a href="http://books.google.com/books?id=5kNC4fqssYQC">Trust-Region Methods (MPS-SIAM Series on Optimization)</a>".</li>
<li>Byrd, R. H, R. B. Schnabel, and G. A. Schultz. "<a href="http://epubs.siam.org/doi/abs/10.1137/0724076">A trust region algorithm for nonlinearly constrained optimization</a>", SIAM J. Numer. Anal., 24 (1987), pp. 1152–1170.</li>
<li>Sorensen, D. C.: "<a href="http://epubs.siam.org/doi/abs/10.1137/0719026">Newton’s Method with a Model Trust Region Modification</a>", SIAM J. Numer. Anal., 19(2), 409–426 (1982).</li>
<li>Yuan, Y. "<a href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.45.9964">A review of trust region algorithms for optimization</a>" in ICIAM 99: Proceedings of the Fourth International Congress on Industrial &amp; Applied Mathematics, Edinburgh, 2000 Oxford University Press, USA.</li>
<li>Yuan, Y. "<a href="http://link.springer.com/article/10.1007%2Fs10107-015-0893-2">Recent Advances in Trust Region Algorithms</a>", Math. Program.， 2015</li>
</ul>
<h2 id="external-links">External links</h2>
<ul>
<li><a href="http://www.applied-mathematics.net/optimization/optimizationIntro.html">Kranf site: Trust Region Algorithms</a></li>
</ul>

<p>"</p>

<p><a href="Category:Mathematical_optimization" title="wikilink">Category:Mathematical optimization</a> <a href="Category:Optimization_algorithms_and_methods" title="wikilink">Category:Optimization algorithms and methods</a></p>
</body>
</html>
