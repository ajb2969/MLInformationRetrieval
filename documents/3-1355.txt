   Spectral theory      Spectral theory  In [[mathematics]], '''spectral theory''' is an inclusive term for theories extending the [[eigenvector]] and [[eigenvalue]] theory of a single [[square matrix]] to a much broader theory of the structure of [[operator (mathematics)|operator]]s in a variety of [[mathematical space]]s. {{cite book |title=History of functional analysis |author=Jean Alexandre Dieudonné |url=http://books.g oogle.com/books?id=mg7r4acKgq0C&printsec;=frontcover |isbn=0-444-86148-3 |year=1981 |publisher=Elsevier}} It is a result of studies of linear algebra and the solutions of systems of linear equations and their generalizations. 1 The theory is connected to that of analytic functions because the spectral properties of an operator are related to analytic functions of the spectral parameter. 2  Mathematical background  The name spectral theory was introduced by David Hilbert in his original formulation of Hilbert space theory, which was cast in terms of quadratic forms in infinitely many variables. The original spectral theorem was therefore conceived as a version of the theorem on principal axes of an ellipsoid , in an infinite-dimensional setting. The later discovery in quantum mechanics that spectral theory could explain features of atomic spectra was therefore fortuitous.  There have been three main ways to formulate spectral theory, all of which retain their usefulness. After Hilbert's initial formulation, the later development of abstract Hilbert space and the spectral theory of a single normal operator on it did very much go in parallel with the requirements of physics ; particularly in the hands of von Neumann . 3 The further theory built on this to include Banach algebras , which can be given abstractly. This development leads to the Gelfand representation , which covers the commutative case , and further into non-commutative harmonic analysis .  The difference can be seen in making the connection with Fourier analysis . The Fourier transform on the real line is in one sense the spectral theory of differentiation  qua  differential operator . But for that to cover the phenomena one has already to deal with generalized eigenfunctions (for example, by means of a rigged Hilbert space ). On the other hand it is simple to construct a group algebra , the spectrum of which captures the Fourier transform's basic properties, and this is carried out by means of Pontryagin duality .  One can also study the spectral properties of operators on Banach spaces . For example, compact operators on Banach spaces have many spectral properties similar to that of matrices .  Physical background  The background in the physics of vibrations has been explained in this way: 4   The mathematical theory is not dependent on such physical ideas on a technical level, but there are examples of mutual influence (see for example Mark Kac 's question Can you hear the shape of a drum? ). Hilbert's adoption of the term "spectrum" has been attributed to an 1897 paper of Wilhelm Wirtinger on Hill differential equation (by Jean Dieudonné ), and it was taken up by his students during the first decade of the twentieth century, among them Erhard Schmidt and Hermann Weyl . The conceptual basis for Hilbert space was developed from Hilbert's ideas by Erhard Schmidt and Frigyes Riesz . 5 6 It was almost twenty years later, when quantum mechanics was formulated in terms of the Schrödinger equation , that the connection was made to atomic spectra ; a connection with the mathematical physics of vibration had been suspected before, as remarked by Henri Poincaré , but rejected for simple quantitative reasons, absent an explanation of the Balmer series . 7 The later discovery in quantum mechanics that spectral theory could explain features of atomic spectra was therefore fortuitous, rather than being an object of Hilbert's spectral theory.  A definition of spectrum  Consider a bounded linear transformation  T defined everywhere over a general Banach space . We form the transformation:        R  ζ   =    (    ζ  I   -  T   )    -  1     .       subscript  R  ζ    superscript      ζ  I   T     1      R_{\zeta}=\left(\zeta I-T\right)^{-1}.     Here I is the identity operator and ζ is a complex number . The inverse of an operator T , that is T −1 , is defined by:        T   T   -  1     =    T   -  1    T   =  I   .          T   superscript  T    1        superscript  T    1    T        I     TT^{-1}=T^{-1}T=I.     If the inverse exists, T is called regular . If it does not exist, T is called singular .  With these definitions, the resolvent set of T is the set of all complex numbers ζ such that R ζ exists and is bounded . This set often is denoted as ρ(T) . The spectrum of T is the set of all complex numbers ζ such that R ζ  fails to exist or is unbounded. Often the spectrum of T is denoted by σ(T) . The function R ζ for all ζ in ρ(T) (that is, wherever R ζ exists as a bounded operator) is called the resolvent of T . The spectrum of T is therefore the complement of the resolvent set of T in the complex plane. 8 Every eigenvalue of T belongs to σ(T) , but σ(T) may contain non-eigenvalues. 9  This definition applies to a Banach space, but of course other types of space exist as well, for example, topological vector spaces include Banach spaces, but can be more general. 10 11 On the other hand, Banach spaces include Hilbert spaces , and it is these spaces that find the greatest application and the richest theoretical results. 12 With suitable restrictions, much can be said about the structure of the spectra of transformations in a Hilbert space. In particular, for self-adjoint operators , the spectrum lies on the real line and (in general) is a spectral combination of a point spectrum of discrete eigenvalues and a continuous spectrum . 13  Spectral theory briefly  In functional analysis and linear algebra the spectral theorem establishes conditions under which an operator can be expressed in simple form as a sum of simpler operators. As a full rigorous presentation is not appropriate for this article, we take an approach that avoids much of the rigor and satisfaction of a formal treatment with the aim of being more comprehensible to a non-specialist.  This topic is easiest to describe by introducing the bra–ket notation of Dirac for operators. 14 15 As an example, a very particular linear operator L might be written as a dyadic product : 16 17       L  =    |   k  1   ⟩    ⟨   b  1   |     ,      L     ket   subscript  k  1     bra   subscript  b  1       L=|k_{1}\rangle\langle b_{1}|,     in terms of the "bra"     ⟨   b  1   |     bra   subscript  b  1     \langle b_{1}|    and the "ket"     |   k  1   ⟩     ket   subscript  k  1     |k_{1}\rangle    . A function f is described by a ket as     |  f  ⟩     ket  f    |f\rangle    . The function f ( x ) defined on the coordinates    (   x  1   ,   x  2   ,   x  3   ,  …  )      subscript  x  1    subscript  x  2    subscript  x  3   normal-…    (x_{1},x_{2},x_{3},\dots)   is denoted as:       f   (  x  )    =   ⟨  x  ,  f  ⟩         f  x    x  f     f(x)=\langle x,f\rangle     and the magnitude of f by:        ∥  f  ∥   2   =   ⟨  f  ,  f  ⟩   =   ∫    ⟨  f  ,  x  ⟩    ⟨  x  ,  f  ⟩   d  x    =   ∫    f  *    (  x  )   f   (  x  )   d  x           superscript   norm  f   2    f  f             f  x    x  f   d  x              superscript  f    x  f  x  d  x       \|f\|^{2}=\langle f,f\rangle=\int\langle f,x\rangle\langle x,f\rangle\,dx=\int
 f%
 ^{*}(x)f(x)\,dx     where the notation '*' denotes a complex conjugate . This inner product choice defines a very specific inner product space , restricting the generality of the arguments that follow. 18  The effect of L upon a function f is then described as:       L   |  f  ⟩    =    |   k  1   ⟩    ⟨   b  1   |  f  ⟩          L   ket  f       ket   subscript  k  1     inner-product   subscript  b  1   f      L|f\rangle=|k_{1}\rangle\langle b_{1}|f\rangle     expressing the result that the effect of L on f is to produce a new function    |   k  1   ⟩     ket   subscript  k  1     |k_{1}\rangle   multiplied by the inner product represented by    ⟨   b  1   |  f  ⟩     inner-product   subscript  b  1   f    \langle b_{1}|f\rangle   .  A more general linear operator L might be expressed as:       L  =     λ  1    |   e  1   ⟩    ⟨   f  1   |   +   λ  2    |   e  2   ⟩    ⟨   f  2   |   +   λ  3    |   e  3   ⟩    ⟨   f  3   |    +  …    ,      L       subscript  λ  1    ket   subscript  e  1     quantum-operator-product   subscript  f  1      subscript  λ  2     subscript  e  2     quantum-operator-product   subscript  f  2      subscript  λ  3     subscript  e  3     bra   subscript  f  3     normal-…     L=\lambda_{1}|e_{1}\rangle\langle f_{1}|+\lambda_{2}|e_{2}\rangle\langle f_{2}%
 |+\lambda_{3}|e_{3}\rangle\langle f_{3}|+\dots,     where the    {    λ  i    }      subscript  λ  i     \{\,\lambda_{i}\,\}   are scalars and the    {   |   e  i   ⟩   }      ket   subscript  e  i      \{\,|e_{i}\rangle\,\}   are a basis and the    {   ⟨   f  i   |   }      bra   subscript  f  i      \{\,\langle f_{i}|\,\}   a reciprocal basis for the space. The relation between the basis and the reciprocal basis is described, in part, by:       ⟨   f  i   |   e  j   ⟩   =   δ   i  j         inner-product   subscript  f  i    subscript  e  j     subscript  δ    i  j      \langle f_{i}|e_{j}\rangle=\delta_{ij}     If such a formalism applies, the    {    λ  i    }      subscript  λ  i     \{\,\lambda_{i}\,\}   are eigenvalues of L and the functions    {   |   e  i   ⟩   }      ket   subscript  e  i      \{\,|e_{i}\rangle\,\}   are eigenfunctions of L . The eigenvalues are in the spectrum of L . 19  Some natural questions are: under what circumstances does this formalism work, and for what operators L are expansions in series of other operators like this possible? Can any function f be expressed in terms of the eigenfunctions (are they a Schauder basis ) and under what circumstances does a point spectrum or a continuous spectrum arise? How do the formalisms for infinite-dimensional spaces and finite-dimensional spaces differ, or do they differ? Can these ideas be extended to a broader class of spaces? Answering such questions is the realm of spectral theory and requires considerable background in functional analysis and matrix algebra .  Resolution of the identity  This section continues in the rough and ready manner of the above section using the bra–ket notation, and glossing over the many important details of a rigorous treatment.  See discussion in Dirac's book referred to above, and  A rigorous mathematical treatment may be found in various references. 20 In particular, the dimension n of the space will be finite.  Using the bra–ket notation of the above section, the identity operator may be written as:      I  =    ∑   i  =  1   n     |   e  i   ⟩    ⟨   f  i   |         I    superscript   subscript     i  1    n      ket   subscript  e  i     bra   subscript  f  i        I=\sum_{i=1}^{n}|e_{i}\rangle\langle f_{i}|     where it is supposed as above that {    |   e  i   ⟩     ket   subscript  e  i     |e_{i}\rangle   } are a basis and the {    ⟨   f  i   |     bra   subscript  f  i     \langle f_{i}|   } a reciprocal basis for the space satisfying the relation:        ⟨   f  i   |   e  j   ⟩   =   δ   i  j     .       inner-product   subscript  f  i    subscript  e  j     subscript  δ    i  j      \langle f_{i}|e_{j}\rangle=\delta_{ij}.     This expression of the identity operation is called a representation or a resolution of the identity. 21 , 22 This formal representation satisfies the basic property of the identity:       I  k   =   I        superscript  I  k   I    I^{k}=I\,     valid for every positive integer k .  Applying the resolution of the identity to any function in the space     |  ψ  ⟩     ket  ψ    |\psi\rangle    , one obtains:       I   |  ψ  ⟩    =   |  ψ  ⟩   =    ∑   i  =  1   n     |   e  i   ⟩    ⟨   f  i   |  ψ  ⟩     =     ∑   i  =  1   n      c  i    |   e  i   ⟩             I   ket  ψ     ket  ψ          superscript   subscript     i  1    n      ket   subscript  e  i     inner-product   subscript  f  i   ψ            superscript   subscript     i  1    n      subscript  c  i    ket   subscript  e  i         I|\psi\rangle=|\psi\rangle=\sum_{i=1}^{n}|e_{i}\rangle\langle f_{i}|\psi%
 \rangle=\sum_{i=1}^{n}\ c_{i}|e_{i}\rangle     which is the generalized Fourier expansion of ψ in terms of the basis functions { e i }.  See for example,   Here      c  i   =   ⟨   f  i   |  ψ  ⟩        subscript  c  i    inner-product   subscript  f  i   ψ     c_{i}=\langle f_{i}|\psi\rangle    .  Given some operator equation of the form:       O   |  ψ  ⟩    =   |  h  ⟩         O   ket  ψ     ket  h     O|\psi\rangle=|h\rangle     with h in the space, this equation can be solved in the above basis through the formal manipulations:        O   |  ψ  ⟩    =    ∑   i  =  1   n     c  i    (   O   |   e  i   ⟩    )     =    ∑   i  =  1   n     |   e  i   ⟩    ⟨   f  i   |  h  ⟩      ,          O   ket  ψ      superscript   subscript     i  1    n      subscript  c  i     O   ket   subscript  e  i              superscript   subscript     i  1    n      ket   subscript  e  i     inner-product   subscript  f  i   h        O|\psi\rangle=\sum_{i=1}^{n}c_{i}\left(O|e_{i}\rangle\right)=\sum_{i=1}^{n}|e_%
 {i}\rangle\langle f_{i}|h\rangle,           ⟨   f  j   |  O  |  ψ  ⟩   =    ∑   i  =  1   n     c  i    ⟨   f  j   |  O  |   e  i   ⟩     =    ∑   i  =  1   n     ⟨   f  j   |   e  i   ⟩    ⟨   f  i   |  h  ⟩     =   ⟨   f  j   |  h  ⟩    ,   ∀  j      formulae-sequence       quantum-operator-product   subscript  f  j   O  ψ     superscript   subscript     i  1    n      subscript  c  i    quantum-operator-product   subscript  f  j   O   subscript  e  i             superscript   subscript     i  1    n      inner-product   subscript  f  j    subscript  e  i     inner-product   subscript  f  i   h           inner-product   subscript  f  j   h      for-all  j     \langle f_{j}|O|\psi\rangle=\sum_{i=1}^{n}c_{i}\langle f_{j}|O|e_{i}\rangle=%
 \sum_{i=1}^{n}\langle f_{j}|e_{i}\rangle\langle f_{i}|h\rangle=\langle f_{j}|h%
 \rangle,\quad\forall j     which converts the operator equation to a matrix equation determining the unknown coefficients c j in terms of the generalized Fourier coefficients    ⟨   f  j   |  h  ⟩     inner-product   subscript  f  j   h    \langle f_{j}|h\rangle   of h and the matrix elements     O   j  i    =   ⟨   f  j   |  O  |   e  i   ⟩        subscript  O    j  i     quantum-operator-product   subscript  f  j   O   subscript  e  i      O_{ji}=\langle f_{j}|O|e_{i}\rangle   of the operator O .  The role of spectral theory arises in establishing the nature and existence of the basis and the reciprocal basis. In particular, the basis might consist of the eigenfunctions of some linear operator L :        L   |   e  i   ⟩    =    λ  i    |   e  i   ⟩     ;        L   ket   subscript  e  i        subscript  λ  i    ket   subscript  e  i       L|e_{i}\rangle=\lambda_{i}|e_{i}\rangle\,;     with the { λ i } the eigenvalues of L from the spectrum of L . Then the resolution of the identity above provides the dyad expansion of L :        L  I   =  L  =    ∑   i  =  1   n    L   |   e  i   ⟩    ⟨   f  i   |     =    ∑   i  =  1   n     λ  i    |   e  i   ⟩    ⟨   f  i   |      .          L  I   L         superscript   subscript     i  1    n     L   ket   subscript  e  i     bra   subscript  f  i             superscript   subscript     i  1    n      subscript  λ  i    ket   subscript  e  i     bra   subscript  f  i         LI=L=\sum_{i=1}^{n}L|e_{i}\rangle\langle f_{i}|=\sum_{i=1}^{n}\lambda_{i}|e_{i%
 }\rangle\langle f_{i}|.     Resolvent operator  Using spectral theory, the resolvent operator R :       R  =    (    λ  I   -  L   )    -  1     ,      R   superscript      λ  I   L     1      R=(\lambda I-L)^{-1},\,     can be evaluated in terms of the eigenfunctions and eigenvalues of L , and the Green's function corresponding to L can be found.  Applying R to some arbitrary function in the space, say   φ   φ   \varphi   ,        R   |  φ  ⟩    =     (    λ  I   -  L   )    -  1     |  φ  ⟩    =    ∑   i  =  1   n     1   λ  -   λ  i      |   e  i   ⟩    ⟨   f  i   |  φ  ⟩      .          R   ket  φ       superscript      λ  I   L     1     ket  φ           superscript   subscript     i  1    n       1    λ   subscript  λ  i      ket   subscript  e  i     inner-product   subscript  f  i   φ        R|\varphi\rangle=(\lambda I-L)^{-1}|\varphi\rangle=\sum_{i=1}^{n}\frac{1}{%
 \lambda-\lambda_{i}}|e_{i}\rangle\langle f_{i}|\varphi\rangle.     This function has poles in the complex λ -plane at each eigenvalue of L . Thus, using the calculus of residues :         1   2  π  i      ∮  C    R   |  φ  ⟩   d  λ     =   -    ∑   i  =  1   n     |   e  i   ⟩    ⟨   f  i   |  φ  ⟩      =   -   |  φ  ⟩     ,            1    2  π  i      subscript  contour-integral  C     R   ket  φ   d  λ         superscript   subscript     i  1    n      ket   subscript  e  i     inner-product   subscript  f  i   φ              ket  φ       \frac{1}{2\pi i}\oint_{C}R|\varphi\rangle d\lambda=-\sum_{i=1}^{n}|e_{i}%
 \rangle\langle f_{i}|\varphi\rangle=-|\varphi\rangle,     where the line integral is over a contour C that includes all the eigenvalues of L .  Suppose our functions are defined over some coordinates { x j }, that is:        ⟨  x  ,  φ  ⟩   =   φ   (   x  1   ,   x  2   ,  …  )     .       x  φ     φ    subscript  x  1    subscript  x  2   normal-…      \langle x,\varphi\rangle=\varphi(x_{1},x_{2},...).     Introducing the notation        ⟨  x  ,  y  ⟩   =   δ   (   x  -  y   )     ,       x  y     δ    x  y      \langle x,y\rangle=\delta(x-y),     where δ(x − y) = δ(x 1 − y 1 , x 2 − y 2 , x 3 − y 3 , ...) is the Dirac delta function , 23 we can write        ⟨  x  ,  φ  ⟩   =   ∫    ⟨  x  ,  y  ⟩    ⟨  y  ,  φ  ⟩   d  y     .       x  φ        x  y    y  φ   d  y      \langle x,\varphi\rangle=\int\langle x,y\rangle\langle y,\varphi\rangle dy.     Then:      ⟨  x  ,     1   2  π  i        ∮  C       φ    λ  I   -  L     d  λ     ⟩     x      1    2  π  i      subscript  contour-integral  C       φ      λ  I   L    d  λ       \displaystyle\left\langle x,\frac{1}{2\pi i}\oint_{C}\frac{\varphi}{\lambda I-%
 L}d\lambda\right\rangle     The function G(x, y; λ) defined by:      G   (  x  ,  y  ;  λ  )       G   x  y  λ     \displaystyle G(x,y;\lambda)     is called the Green's function for operator L , and satisfies: 24         1   2  π  i      ∮  C    G   (  x  ,  y  ;  λ  )   d  λ     =   -    ∑   i  =  1   n     ⟨  x  ,   e  i   ⟩    ⟨   f  i   ,  y  ⟩      =   -   ⟨  x  ,  y  ⟩    =   -   δ   (   x  -  y   )      .            1    2  π  i      subscript  contour-integral  C     G   x  y  λ   d  λ         superscript   subscript     i  1    n      x   subscript  e  i      subscript  f  i   y              x  y             δ    x  y        \frac{1}{2\pi i}\oint_{C}G(x,y;\lambda)d\lambda=-\sum_{i=1}^{n}\langle x,e_{i}%
 \rangle\langle f_{i},y\rangle=-\langle x,y\rangle=-\delta(x-y).     Operator equations  Consider the operator equation:         (   O  -   λ  I    )    |  ψ  ⟩    =   |  h  ⟩    ;          O    λ  I     ket  ψ     ket  h     (O-\lambda I)|\psi\rangle=|h\rangle;     in terms of coordinates:        ∫    ⟨  x  ,    (   O  -   λ  I    )   y   ⟩    ⟨  y  ,  ψ  ⟩   d  y    =   h   (  x  )     .           x      O    λ  I    y     y  ψ   d  y      h  x     \int\langle x,(O-\lambda I)y\rangle\langle y,\psi\rangle dy=h(x).     A particular case is λ = 0.  The Green's function of the previous section is:        ⟨  y  ,   G   (  λ  )   z   ⟩   =   ⟨  y  ,     (   O  -   λ  I    )    -  1    z   ⟩   =   G   (  y  ,  z  ;  λ  )     ,         y    G  λ  z     y     superscript    O    λ  I      1    z           G   y  z  λ       \langle y,G(\lambda)z\rangle=\left\langle y,(O-\lambda I)^{-1}z\right\rangle=G%
 (y,z;\lambda),     and satisfies:        ∫    ⟨  x  ,    (   O  -   λ  I    )   y   ⟩    ⟨  y  ,   G   (  λ  )   z   ⟩   d  y    =   ∫    ⟨  x  ,    (   O  -   λ  I    )   y   ⟩    ⟨  y  ,     (   O  -   λ  I    )    -  1    z   ⟩   d  y    =   ⟨  x  ,  z  ⟩   =   δ   (   x  -  z   )     .             x      O    λ  I    y     y    G  λ  z    d  y         x      O    λ  I    y     y     superscript    O    λ  I      1    z    d  y          x  z          δ    x  z       \int\langle x,(O-\lambda I)y\rangle\langle y,G(\lambda)z\rangle dy=\int\langle
 x%
 ,(O-\lambda I)y\rangle\left\langle y,(O-\lambda I)^{-1}z\right\rangle dy=%
 \langle x,z\rangle=\delta(x-z).     Using this Green's function property:        ∫    ⟨  x  ,    (   O  -   λ  I    )   y   ⟩   G   (  y  ,  z  ;  λ  )   d  y    =   δ   (   x  -  z   )     .           x      O    λ  I    y    G   y  z  λ   d  y      δ    x  z      \int\langle x,(O-\lambda I)y\rangle G(y,z;\lambda)dy=\delta(x-z).     Then, multiplying both sides of this equation by h ( z ) and integrating:        ∫   d  z  h   (  z  )    ∫   d  y   ⟨  x  ,    (   O  -   λ  I    )   y   ⟩   G   (  y  ,  z  ;  λ  )       =   ∫   d  y   ⟨  x  ,    (   O  -   λ  I    )   y   ⟩    ∫   d  z  h   (  z  )   G   (  y  ,  z  ;  λ  )       =   h   (  x  )     ,            d  z  h  z      d  y   x      O    λ  I    y    G   y  z  λ           d  y   x      O    λ  I    y        d  z  h  z  G   y  z  λ              h  x      \int dzh(z)\int dy\langle x,(O-\lambda I)y\rangle G(y,z;\lambda)=\int dy%
 \langle x,(O-\lambda I)y\rangle\int dzh(z)G(y,z;\lambda)=h(x),     which suggests the solution is:        ψ   (  x  )    =   ∫   h   (  z  )   G   (  x  ,  z  ;  λ  )   d  z     .        ψ  x       h  z  G   x  z  λ   d  z      \psi(x)=\int h(z)G(x,z;\lambda)dz.     That is, the function ψ( x ) satisfying the operator equation is found if we can find the spectrum of O , and construct G , for example by using:        G   (  x  ,  z  ;  λ  )    =    ∑   i  =  1   n      e  i    (  x  )    f  i  *    (  z  )     λ  -   λ  i       .        G   x  z  λ      superscript   subscript     i  1    n        subscript  e  i   x   superscript   subscript  f  i     z     λ   subscript  λ  i        G(x,z;\lambda)=\sum_{i=1}^{n}\frac{e_{i}(x)f_{i}^{*}(z)}{\lambda-\lambda_{i}}.     There are many other ways to find G , of course.  For example, see  and  See the articles on Green's functions and on Fredholm integral equations . It must be kept in mind that the above mathematics is purely formal, and a rigorous treatment involves some pretty sophisticated mathematics, including a good background knowledge of functional analysis , Hilbert spaces , distributions and so forth. Consult these articles and the references for more detail.  Spectral theorem and Rayleigh quotient  Optimization problems may be the most useful examples about the combinatorial significance of the eigenvalues and eigenvectors in symmetric matrices, especially for the Rayleigh quotient with respect to a matrix M .  Theorem ''Let M be a symmetric matrix and let x be the non-zero vector that maximizes the Rayleigh quotient with respect to M . Then, x is an eigenvector of M with eigenvalue equal to the Rayleigh quotient . Moreover, this eigenvalue is the largest eigenvalue of M . ''  Proof Assume the spectral theorem. Let the eigenvalues of M be     λ  1   ≤   λ  2   ≤  ⋯  ≤   λ  n          subscript  λ  1    subscript  λ  2        normal-⋯        subscript  λ  n      \lambda_{1}\leq\lambda_{2}\leq\cdots\leq\lambda_{n}   . Since the {    v  i     subscript  v  i    v_{i}   } form an orthonormal basis , any vector x can be expressed in this basis as      x  =     ∑  i      v  i  T   x   v  i         x    subscript   i      superscript   subscript  v  i   T   x   subscript  v  i       x=\sum_{i}\ v_{i}^{T}xv_{i}     The way to prove this formula is pretty easy. Namely,       v  j  T     ∑  i     v  i  T   x   v  i          superscript   subscript  v  j   T     subscript   i      superscript   subscript  v  i   T   x   subscript  v  i       v_{j}^{T}\sum_{i}v_{i}^{T}xv_{i}          =    ∑  i     v  i  T   x   v  j  T    v  i         absent    subscript   i      superscript   subscript  v  i   T   x   superscript   subscript  v  j   T    subscript  v  i       =\sum_{i}v_{i}^{T}xv_{j}^{T}v_{i}          =    (    v  j  T   x   )    v  j  T    v  j        absent       superscript   subscript  v  j   T   x    superscript   subscript  v  j   T    subscript  v  j      =(v_{j}^{T}x)v_{j}^{T}v_{j}          =    v  j  T   x       absent     superscript   subscript  v  j   T   x     =v_{j}^{T}x   evaluate the Rayleigh quotient with respect to x:       x  T   M  x       superscript  x  T   M  x    x^{T}Mx          =     (    ∑  i     (    v  i  T   x   )    v  i     )   T   M   (    ∑  j     (    v  j  T   x   )    v  j     )        absent     superscript    subscript   i        superscript   subscript  v  i   T   x    subscript  v  i     T   M    subscript   j        superscript   subscript  v  j   T   x    subscript  v  j        =(\sum_{i}(v_{i}^{T}x)v_{i})^{T}M(\sum_{j}(v_{j}^{T}x)v_{j})          =    (    ∑  i     (    v  i  T   x   )    v  i  T     )    (    ∑  j     (    v  j  T   x   )    v  j    λ  j     )        absent      subscript   i        superscript   subscript  v  i   T   x    superscript   subscript  v  i   T       subscript   j        superscript   subscript  v  j   T   x    subscript  v  j    subscript  λ  j        =(\sum_{i}(v_{i}^{T}x)v_{i}^{T})(\sum_{j}(v_{j}^{T}x)v_{j}\lambda_{j})          =    ∑   i  ,  j      (    v  i  T   x   )    v  i  T    (    v  j  T   x   )    v  j    λ  j         absent    subscript    i  j         superscript   subscript  v  i   T   x    superscript   subscript  v  i   T      superscript   subscript  v  j   T   x    subscript  v  j    subscript  λ  j       =\sum_{i,j}(v_{i}^{T}x)v_{i}^{T}(v_{j}^{T}x)v_{j}\lambda_{j}          =    ∑  j     (    v  j  T   x   )    (    v  j  T   x   )    λ  j         absent    subscript   j        superscript   subscript  v  j   T   x      superscript   subscript  v  j   T   x    subscript  λ  j       =\sum_{j}(v_{j}^{T}x)(v_{j}^{T}x)\lambda_{j}          =    ∑  j      (    v  j  T   x   )   2    λ  j     ≤    λ  n     ∑  j     (    v  j  T   x   )   2           absent    subscript   j      superscript     superscript   subscript  v  j   T   x   2    subscript  λ  j             subscript  λ  n     subscript   j    superscript     superscript   subscript  v  j   T   x   2        =\sum_{j}(v_{j}^{T}x)^{2}\lambda_{j}\leq\lambda_{n}\sum_{j}(v_{j}^{T}x)^{2}          =    λ  n    x  T   x       absent     subscript  λ  n    superscript  x  T   x     =\lambda_{n}x^{T}x   , where we used Parseval's identity in the last line. Finally we obtain that         x  T   M  x     x  T   x    ≤   λ  n            superscript  x  T   M  x      superscript  x  T   x     subscript  λ  n     \frac{x^{T}Mx}{x^{T}x}\leq\lambda_{n}     so the Rayleigh quotient is always less than    λ  n     subscript  λ  n    \lambda_{n}   .  25  See also   Spectrum (functional analysis) , Resolvent formalism , Decomposition of spectrum (functional analysis)  Spectral radius , Spectrum of an operator , Spectral theorem  Self-adjoint operator , Functions of operators , Operator theory  Sturm–Liouville theory , Integral equations , Fredholm theory  Compact operators , Isospectral operators, Completeness  Lax pairs  Spectral geometry  Spectral graph theory  List of functional analysis topics   Notes  References                             External links   Evans M. Harrell II : A Short History of Operator Theory    de:Spektrum (Operatortheorie) "  Category:Linear algebra  *     ↩  ↩  ↩  E. Brian Davies , quoted on the King's College London analysis group website ↩  ↩  ↩  Cf. Spectra in mathematics and in physics by Jean Mawhin, p.4 and pp. 10-11. ↩  ↩  ↩  ↩  ↩  ↩  ↩  ↩  ↩  ↩  ↩   ↩  See, for example, the fundamental text of  and , , ↩    ↩  ↩  Spielman,Daniel A. "Lecture Note of Spectral Graph Theory" Yale University(2012) http://cs.yale.edu/homes/spielman/561/ . ↩     