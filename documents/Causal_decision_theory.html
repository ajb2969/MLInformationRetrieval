<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="562">Causal decision theory</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>Causal decision theory</h1>
<hr/>

<p><strong>Causal decision theory</strong> is a mathematical theory intended to determine the set of rational choices in a given situation. In informal terms, it maintains that the rational choice is that with the best expected causal consequences. This theory is often contrasted with <a href="evidential_decision_theory" title="wikilink">evidential decision theory</a>, which recommends those actions that provide the best evidence about the world.</p>
<h2 id="informal-description">Informal Description</h2>

<p>Very informally, causal decision theory advises decision makers to make the decision with the best expected causal consequences. The basic idea is simple enough: if eating an apple will cause you to be happy and eating an orange will cause you to be sad then you would be rational to eat the apple. One complication is the notion of <em>expected</em> causal consequences. Imagine that eating a good apple will cause you to be happy and eating a bad apple will cause you to be sad but you aren't sure if the apple is good or bad. In this case you don't know the causal effects of eating the apple. Instead, then, you work from the <em>expected</em> causal effects, where these will depend on three things: (1) how likely you think the apple is to be good and how likely you think it is to be bad; (2) how happy eating a good apple makes you; and (3) how sad eating a bad apple makes you. In informal terms, causal decision theory advises the agent to make the decision with the best expected causal effects.</p>
<h2 id="formal-description">Formal Description</h2>

<p>In a 1981 article, Allan Gibbard and William Harper explained causal decision theory as maximization of the expected utility 

<math display="inline" id="Causal_decision_theory:0">
 <semantics>
  <mi>U</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>U</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   U
  </annotation>
 </semantics>
</math>

 of an action 

<math display="inline" id="Causal_decision_theory:1">
 <semantics>
  <mi>A</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>A</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   A
  </annotation>
 </semantics>
</math>

 of an action "calculated from probabilities of <a href="Counterfactual_conditional" title="wikilink">counterfactuals</a>":<a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a></p>

<p>

<math display="block" id="Causal_decision_theory:2">
 <semantics>
  <mrow>
   <mi>U</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <mi>A</mi>
    <mo stretchy="false">)</mo>
   </mrow>
   <mo>=</mo>
   <munder>
    <mo largeop="true" movablelimits="false" symmetric="true">∑</mo>
    <mi>j</mi>
   </munder>
   <mi>P</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <mi>A</mi>
    <mo>></mo>
    <msub>
     <mi>O</mi>
     <mi>j</mi>
    </msub>
    <mo stretchy="false">)</mo>
   </mrow>
   <mi>D</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <msub>
     <mi>O</mi>
     <mi>j</mi>
    </msub>
    <mo stretchy="false">)</mo>
   </mrow>
   <mo>,</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <cerror>
    <csymbol cd="ambiguous">fragments</csymbol>
    <csymbol cd="unknown">U</csymbol>
    <cerror>
     <csymbol cd="ambiguous">fragments</csymbol>
     <ci>normal-(</ci>
     <csymbol cd="unknown">A</csymbol>
     <ci>normal-)</ci>
    </cerror>
    <eq></eq>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <sum></sum>
     <ci>j</ci>
    </apply>
    <csymbol cd="unknown">P</csymbol>
    <cerror>
     <csymbol cd="ambiguous">fragments</csymbol>
     <ci>normal-(</ci>
     <csymbol cd="unknown">A</csymbol>
     <gt></gt>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>O</ci>
      <ci>j</ci>
     </apply>
     <ci>normal-)</ci>
    </cerror>
    <csymbol cd="unknown">D</csymbol>
    <cerror>
     <csymbol cd="ambiguous">fragments</csymbol>
     <ci>normal-(</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>O</ci>
      <ci>j</ci>
     </apply>
     <ci>normal-)</ci>
    </cerror>
    <ci>normal-,</ci>
   </cerror>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   U(A)=\sum\limits_{j}P(A>O_{j})D(O_{j}),
  </annotation>
 </semantics>
</math>

 where 

<math display="inline" id="Causal_decision_theory:3">
 <semantics>
  <mrow>
   <mi>D</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <msub>
     <mi>O</mi>
     <mi>j</mi>
    </msub>
    <mo stretchy="false">)</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <ci>D</ci>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>O</ci>
     <ci>j</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   D(O_{j})
  </annotation>
 </semantics>
</math>

 is the desirability of outcome 

<math display="inline" id="Causal_decision_theory:4">
 <semantics>
  <msub>
   <mi>O</mi>
   <mi>j</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>O</ci>
    <ci>j</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   O_{j}
  </annotation>
 </semantics>
</math>

 and 

<math display="inline" id="Causal_decision_theory:5">
 <semantics>
  <mrow>
   <mi>P</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <mi>A</mi>
    <mo>></mo>
    <msub>
     <mi>O</mi>
     <mi>j</mi>
    </msub>
    <mo stretchy="false">)</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <cerror>
    <csymbol cd="ambiguous">fragments</csymbol>
    <csymbol cd="unknown">P</csymbol>
    <cerror>
     <csymbol cd="ambiguous">fragments</csymbol>
     <ci>normal-(</ci>
     <csymbol cd="unknown">A</csymbol>
     <gt></gt>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>O</ci>
      <ci>j</ci>
     </apply>
     <ci>normal-)</ci>
    </cerror>
   </cerror>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   P(A>O_{j})
  </annotation>
 </semantics>
</math>

 is the counterfactual probability that, if 

<math display="inline" id="Causal_decision_theory:6">
 <semantics>
  <mi>A</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>A</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   A
  </annotation>
 </semantics>
</math>

 were done, then 

<math display="inline" id="Causal_decision_theory:7">
 <semantics>
  <msub>
   <mi>O</mi>
   <mi>j</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>O</ci>
    <ci>j</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   O_{j}
  </annotation>
 </semantics>
</math>

 would hold.</p>
<h2 id="difference-from-evidential-decision-theory">Difference from evidential decision theory</h2>

<p><a href="David_Kellogg_Lewis" title="wikilink">David Lewis</a> proved<a class="footnoteRef" href="#fn2" id="fnref2"><sup>2</sup></a> that the probability of a conditional 

<math display="inline" id="Causal_decision_theory:8">
 <semantics>
  <mrow>
   <mi>P</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <mi>A</mi>
    <mo>></mo>
    <msub>
     <mi>O</mi>
     <mi>j</mi>
    </msub>
    <mo stretchy="false">)</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <cerror>
    <csymbol cd="ambiguous">fragments</csymbol>
    <csymbol cd="unknown">P</csymbol>
    <cerror>
     <csymbol cd="ambiguous">fragments</csymbol>
     <ci>normal-(</ci>
     <csymbol cd="unknown">A</csymbol>
     <gt></gt>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>O</ci>
      <ci>j</ci>
     </apply>
     <ci>normal-)</ci>
    </cerror>
   </cerror>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   P(A>O_{j})
  </annotation>
 </semantics>
</math>

 does not always equal the conditional probability 

<math display="inline" id="Causal_decision_theory:9">
 <semantics>
  <mrow>
   <mi>P</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <msub>
     <mi>O</mi>
     <mi>j</mi>
    </msub>
    <mo stretchy="false">|</mo>
    <mi>A</mi>
    <mo stretchy="false">)</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <cerror>
    <csymbol cd="ambiguous">fragments</csymbol>
    <csymbol cd="unknown">P</csymbol>
    <cerror>
     <csymbol cd="ambiguous">fragments</csymbol>
     <ci>normal-(</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>O</ci>
      <ci>j</ci>
     </apply>
     <ci>normal-|</ci>
     <csymbol cd="unknown">A</csymbol>
     <ci>normal-)</ci>
    </cerror>
   </cerror>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   P(O_{j}|A)
  </annotation>
 </semantics>
</math>

.<a class="footnoteRef" href="#fn3" id="fnref3"><sup>3</sup></a> If that were the case, causal decision theory would be equivalent to evidential decision theory, which uses conditional probabilities.</p>

<p>Gibbard and Harper showed that if we accept two axioms (one related to the controversial <a href="principle_of_the_conditional_excluded_middle" title="wikilink">principle of the conditional excluded middle</a><a class="footnoteRef" href="#fn4" id="fnref4"><sup>4</sup></a>), then the <a href="statistical_independence" title="wikilink">statistical independence</a> of 

<math display="inline" id="Causal_decision_theory:10">
 <semantics>
  <mi>A</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>A</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   A
  </annotation>
 </semantics>
</math>

 and 

<math display="inline" id="Causal_decision_theory:11">
 <semantics>
  <mrow>
   <mi>A</mi>
   <mo>></mo>
   <msub>
    <mi>O</mi>
    <mi>j</mi>
   </msub>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <gt></gt>
    <ci>A</ci>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>O</ci>
     <ci>j</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   A>O_{j}
  </annotation>
 </semantics>
</math>

 suffices to guarantee that 

<math display="inline" id="Causal_decision_theory:12">
 <semantics>
  <mrow>
   <mi>P</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <mi>A</mi>
    <mo>></mo>
    <msub>
     <mi>O</mi>
     <mi>j</mi>
    </msub>
    <mo stretchy="false">)</mo>
   </mrow>
   <mo>=</mo>
   <mi>P</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <msub>
     <mi>O</mi>
     <mi>j</mi>
    </msub>
    <mo stretchy="false">|</mo>
    <mi>A</mi>
    <mo stretchy="false">)</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <cerror>
    <csymbol cd="ambiguous">fragments</csymbol>
    <csymbol cd="unknown">P</csymbol>
    <cerror>
     <csymbol cd="ambiguous">fragments</csymbol>
     <ci>normal-(</ci>
     <csymbol cd="unknown">A</csymbol>
     <gt></gt>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>O</ci>
      <ci>j</ci>
     </apply>
     <ci>normal-)</ci>
    </cerror>
    <eq></eq>
    <csymbol cd="unknown">P</csymbol>
    <cerror>
     <csymbol cd="ambiguous">fragments</csymbol>
     <ci>normal-(</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>O</ci>
      <ci>j</ci>
     </apply>
     <ci>normal-|</ci>
     <csymbol cd="unknown">A</csymbol>
     <ci>normal-)</ci>
    </cerror>
   </cerror>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   P(A>O_{j})=P(O_{j}|A)
  </annotation>
 </semantics>
</math>

. However, there are cases in which actions and conditionals are not independent. Gibbard and Harper give an example in which King David wants Bathsheba but fears that summoning her would provoke a revolt.</p>
<blockquote>

<p>Further, David has studied works on psychology and political science which teach him the following: Kings have two personality types, charismatic and uncharismatic. A king's degree of charisma depends on his genetic make-up and early childhood experiences, and cannot be changed in adulthood. Now, charismatic kings tend to act justly and uncharismatic kings unjustly. Successful revolts against charismatic kings are rare, whereas successful revolts against uncharismatic kings are frequent. Unjust acts themselves, though, do not cause successful revolts; the reason uncharismatic kings are prone to successful revolts is that they have a sneaky, ignoble bearing. David does not know whether or not he is charismatic; he does know that it is unjust to send for another man's wife. (p. 164)</p>
</blockquote>

<p>In this case, evidential decision theory recommends that David abstain from Bathsheba, while causal decision theory—noting that whether David is charismatic or uncharismatic cannot be changed—recommends sending for her.</p>
<h2 id="criticism">Criticism</h2>
<h3 id="counterexamples">Counterexamples</h3>

<p><a href="Newcomb's_paradox" title="wikilink">Newcomb's paradox</a> is a classic example illustrating the potential conflict between causal and evidential decision theory: Because your choice of one or two boxes can't causally affect the Predictor's guess, causal decision theory recommends the two-boxing strategy.<a class="footnoteRef" href="#fn5" id="fnref5"><sup>5</sup></a> However, this results in getting only $1,000, not $1,000,000. Similar concerns arise in problems like the <a href="prisoner's_dilemma" title="wikilink">prisoner's dilemma</a><a class="footnoteRef" href="#fn6" id="fnref6"><sup>6</sup></a> and various other thought experiments.<a class="footnoteRef" href="#fn7" id="fnref7"><sup>7</sup></a></p>
<h3 id="probabilities-of-conditionals">Probabilities of conditionals</h3>

<p>As Michael John Shaffer points out,<a class="footnoteRef" href="#fn8" id="fnref8"><sup>8</sup></a> there are difficulties with assigning probabilities to counterfactuals. One proposal is the "imaging" technique suggested by Lewis:<a class="footnoteRef" href="#fn9" id="fnref9"><sup>9</sup></a> To evaluate 

<math display="inline" id="Causal_decision_theory:13">
 <semantics>
  <mrow>
   <mi>P</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <mi>A</mi>
    <mo>></mo>
    <msub>
     <mi>O</mi>
     <mi>j</mi>
    </msub>
    <mo stretchy="false">)</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <cerror>
    <csymbol cd="ambiguous">fragments</csymbol>
    <csymbol cd="unknown">P</csymbol>
    <cerror>
     <csymbol cd="ambiguous">fragments</csymbol>
     <ci>normal-(</ci>
     <csymbol cd="unknown">A</csymbol>
     <gt></gt>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>O</ci>
      <ci>j</ci>
     </apply>
     <ci>normal-)</ci>
    </cerror>
   </cerror>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   P(A>O_{j})
  </annotation>
 </semantics>
</math>

, move probability mass from each possible world 

<math display="inline" id="Causal_decision_theory:14">
 <semantics>
  <mi>w</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>w</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   w
  </annotation>
 </semantics>
</math>

 to the closest possible world 

<math display="inline" id="Causal_decision_theory:15">
 <semantics>
  <msub>
   <mi>w</mi>
   <mi>A</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>w</ci>
    <ci>A</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   w_{A}
  </annotation>
 </semantics>
</math>

 in which 

<math display="inline" id="Causal_decision_theory:16">
 <semantics>
  <mi>A</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>A</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   A
  </annotation>
 </semantics>
</math>

 holds, assuming 

<math display="inline" id="Causal_decision_theory:17">
 <semantics>
  <mi>A</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>A</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   A
  </annotation>
 </semantics>
</math>

 is possible. However, this procedure requires that we know what we would believe if we were certain of 

<math display="inline" id="Causal_decision_theory:18">
 <semantics>
  <mi>A</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>A</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   A
  </annotation>
 </semantics>
</math>

; this is itself a conditional to which we might assign probability less than 1, leading to regress.<a class="footnoteRef" href="#fn10" id="fnref10"><sup>10</sup></a></p>
<h2 id="see-also">See also</h2>
<ul>
<li><a href="Decision_making" title="wikilink">Decision making</a></li>
<li><a href="Evidential_decision_theory" title="wikilink">Evidential decision theory</a></li>
<li><a href="Expected_utility_hypothesis" title="wikilink">Expected utility hypothesis</a></li>
<li><a href="Game_theory" title="wikilink">Game theory</a></li>
<li><a href="Newcomb's_paradox" title="wikilink">Newcomb's paradox</a></li>
</ul>
<h2 id="notes">Notes</h2>
<h2 id="external-links">External links</h2>
<ul>
<li><a href="http://plato.stanford.edu/entries/decision-causal/">Causal Decision Theory</a> at the <a href="Stanford_Encyclopedia_of_Philosophy" title="wikilink">Stanford Encyclopedia of Philosophy</a></li>
<li><a href="http://plato.stanford.edu/entries/logic-conditionals/">The Logic of Conditionals</a> at the <a href="Stanford_Encyclopedia_of_Philosophy" title="wikilink">Stanford Encyclopedia of Philosophy</a></li>
</ul>

<p>"</p>

<p><a href="Category:Decision_theory" title="wikilink"> </a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1"><a href="#fnref1">↩</a></li>
<li id="fn2"><a href="#fnref2">↩</a></li>
<li id="fn3">In fact, Lewis proved a stronger result: "if a class of probability functions is closed under conditionalizing, then there can be no probability conditional for that class unless the class consists entirely of trivial probability functions," where a <em>trivial probability function</em> is one that "never assigns positive probability to more than two incompatible alternatives, and hence is at most four-valued [...]."<a href="#fnref3">↩</a></li>
<li id="fn4"><a href="#fnref4">↩</a></li>
<li id="fn5"></li>
<li id="fn6"><a href="#fnref6">↩</a></li>
<li id="fn7"><a href="#fnref7">↩</a></li>
<li id="fn8"></li>
<li id="fn9"><a href="#fnref9">↩</a></li>
<li id="fn10"></li>
</ol>
</section>
</body>
</html>
