<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="617">Simultaneous localization and mapping</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>Simultaneous localization and mapping</h1>
<hr/>

<p> </p>

<p>In <a href="robotic_mapping" title="wikilink">robotic mapping</a>, <strong>simultaneous localization and mapping</strong> (<strong>SLAM</strong>) is the computational problem of constructing or updating a map of an unknown environment while simultaneously keeping track of an agent's location within it. While this initially appears to be a <a href="chicken-and-egg_problem" title="wikilink">chicken-and-egg problem</a> there are several algorithms known for solving it, at least approximately, in tractable time for certain environments. Popular approximate solution methods include the <a href="particle_filter" title="wikilink">particle filter</a> and extended <a href="Kalman_filter" title="wikilink">Kalman filter</a>.</p>

<p>SLAM algorithms are tailored to the available resources, hence not aimed at perfection, but at operational compliance. Published approaches are employed in <a href="self-driving_cars" title="wikilink">self-driving cars</a>, <a href="unmanned_aerial_vehicles" title="wikilink">unmanned aerial vehicles</a>, <a href="Autonomous_Underwater_Vehicle" title="wikilink">autonomous underwater vehicles</a>, <a href="Rover_(space_exploration)" title="wikilink">planetary rovers</a>, newly emerging <a href="domestic_robot" title="wikilink">domestic robots</a> and even inside the human body.<a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a></p>
<h2 id="problem-definition">Problem definition</h2>

<p>Given a series of sensor observations 

<math display="inline" id="Simultaneous_localization_and_mapping:0">
 <semantics>
  <msub>
   <mi>o</mi>
   <mi>t</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>o</ci>
    <ci>t</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   o_{t}
  </annotation>
 </semantics>
</math>

 over discrete time steps 

<math display="inline" id="Simultaneous_localization_and_mapping:1">
 <semantics>
  <mi>t</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>t</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   t
  </annotation>
 </semantics>
</math>

, the SLAM problem is to compute an estimate of the agent's location 

<math display="inline" id="Simultaneous_localization_and_mapping:2">
 <semantics>
  <msub>
   <mi>x</mi>
   <mi>t</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>x</ci>
    <ci>t</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   x_{t}
  </annotation>
 </semantics>
</math>

 and a map of the environment 

<math display="inline" id="Simultaneous_localization_and_mapping:3">
 <semantics>
  <msub>
   <mi>m</mi>
   <mi>t</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>m</ci>
    <ci>t</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   m_{t}
  </annotation>
 </semantics>
</math>

. All quantities are usually probabilistic, so the objective is to compute:</p>

<p>

<math display="block" id="Simultaneous_localization_and_mapping:4">
 <semantics>
  <mrow>
   <mi>P</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <msub>
     <mi>m</mi>
     <mi>t</mi>
    </msub>
    <mo>,</mo>
    <msub>
     <mi>x</mi>
     <mi>t</mi>
    </msub>
    <mo stretchy="false">|</mo>
    <msub>
     <mi>o</mi>
     <mrow>
      <mn>1</mn>
      <mo>:</mo>
      <mi>t</mi>
     </mrow>
    </msub>
    <mo stretchy="false">)</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <cerror>
    <csymbol cd="ambiguous">fragments</csymbol>
    <csymbol cd="unknown">P</csymbol>
    <cerror>
     <csymbol cd="ambiguous">fragments</csymbol>
     <ci>normal-(</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>m</ci>
      <ci>t</ci>
     </apply>
     <ci>normal-,</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>x</ci>
      <ci>t</ci>
     </apply>
     <ci>normal-|</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>o</ci>
      <apply>
       <ci>normal-:</ci>
       <cn type="integer">1</cn>
       <ci>t</ci>
      </apply>
     </apply>
     <ci>normal-)</ci>
    </cerror>
   </cerror>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   P(m_{t},x_{t}|o_{1:t})
  </annotation>
 </semantics>
</math>

</p>

<p>Applying <a href="Bayes'_rule" title="wikilink">Bayes' rule</a> gives a framework for sequentially updating the location posteriors, given a map and a transition function 

<math display="inline" id="Simultaneous_localization_and_mapping:5">
 <semantics>
  <mrow>
   <mi>P</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <msub>
     <mi>x</mi>
     <mi>t</mi>
    </msub>
    <mo stretchy="false">|</mo>
    <msub>
     <mi>x</mi>
     <mrow>
      <mi>t</mi>
      <mo>-</mo>
      <mn>1</mn>
     </mrow>
    </msub>
    <mo stretchy="false">)</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <cerror>
    <csymbol cd="ambiguous">fragments</csymbol>
    <csymbol cd="unknown">P</csymbol>
    <cerror>
     <csymbol cd="ambiguous">fragments</csymbol>
     <ci>normal-(</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>x</ci>
      <ci>t</ci>
     </apply>
     <ci>normal-|</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>x</ci>
      <apply>
       <minus></minus>
       <ci>t</ci>
       <cn type="integer">1</cn>
      </apply>
     </apply>
     <ci>normal-)</ci>
    </cerror>
   </cerror>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   P(x_{t}|x_{t-1})
  </annotation>
 </semantics>
</math>

,</p>

<p>

<math display="block" id="Simultaneous_localization_and_mapping:6">
 <semantics>
  <mrow>
   <mi>P</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <msub>
     <mi>x</mi>
     <mi>t</mi>
    </msub>
    <mo stretchy="false">|</mo>
    <msub>
     <mi>o</mi>
     <mrow>
      <mn>1</mn>
      <mo>:</mo>
      <mi>t</mi>
     </mrow>
    </msub>
    <mo>,</mo>
    <msub>
     <mi>m</mi>
     <mi>t</mi>
    </msub>
    <mo stretchy="false">)</mo>
   </mrow>
   <mo>=</mo>
   <munder>
    <mo largeop="true" movablelimits="false" symmetric="true">∑</mo>
    <msub>
     <mi>m</mi>
     <mrow>
      <mi>t</mi>
      <mo>-</mo>
      <mn>1</mn>
     </mrow>
    </msub>
   </munder>
   <mi>P</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <msub>
     <mi>o</mi>
     <mi>t</mi>
    </msub>
    <mo stretchy="false">|</mo>
    <msub>
     <mi>x</mi>
     <mi>t</mi>
    </msub>
    <mo>,</mo>
    <msub>
     <mi>m</mi>
     <mi>t</mi>
    </msub>
    <mo stretchy="false">)</mo>
   </mrow>
   <munder>
    <mo largeop="true" movablelimits="false" symmetric="true">∑</mo>
    <msub>
     <mi>x</mi>
     <mrow>
      <mi>t</mi>
      <mo>-</mo>
      <mn>1</mn>
     </mrow>
    </msub>
   </munder>
   <mi>P</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <msub>
     <mi>x</mi>
     <mi>t</mi>
    </msub>
    <mo stretchy="false">|</mo>
    <msub>
     <mi>x</mi>
     <mrow>
      <mi>t</mi>
      <mo>-</mo>
      <mn>1</mn>
     </mrow>
    </msub>
    <mo stretchy="false">)</mo>
   </mrow>
   <mi>P</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <msub>
     <mi>x</mi>
     <mrow>
      <mi>t</mi>
      <mo>-</mo>
      <mn>1</mn>
     </mrow>
    </msub>
    <mo stretchy="false">|</mo>
    <msub>
     <mi>m</mi>
     <mi>t</mi>
    </msub>
    <mo>,</mo>
    <msub>
     <mi>o</mi>
     <mrow>
      <mn>1</mn>
      <mo>:</mo>
      <mrow>
       <mi>t</mi>
       <mo>-</mo>
       <mn>1</mn>
      </mrow>
     </mrow>
    </msub>
    <mo stretchy="false">)</mo>
   </mrow>
   <mo>/</mo>
   <mi>Z</mi>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <cerror>
    <csymbol cd="ambiguous">fragments</csymbol>
    <csymbol cd="unknown">P</csymbol>
    <cerror>
     <csymbol cd="ambiguous">fragments</csymbol>
     <ci>normal-(</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>x</ci>
      <ci>t</ci>
     </apply>
     <ci>normal-|</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>o</ci>
      <apply>
       <ci>normal-:</ci>
       <cn type="integer">1</cn>
       <ci>t</ci>
      </apply>
     </apply>
     <ci>normal-,</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>m</ci>
      <ci>t</ci>
     </apply>
     <ci>normal-)</ci>
    </cerror>
    <eq></eq>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <sum></sum>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>m</ci>
      <apply>
       <minus></minus>
       <ci>t</ci>
       <cn type="integer">1</cn>
      </apply>
     </apply>
    </apply>
    <csymbol cd="unknown">P</csymbol>
    <cerror>
     <csymbol cd="ambiguous">fragments</csymbol>
     <ci>normal-(</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>o</ci>
      <ci>t</ci>
     </apply>
     <ci>normal-|</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>x</ci>
      <ci>t</ci>
     </apply>
     <ci>normal-,</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>m</ci>
      <ci>t</ci>
     </apply>
     <ci>normal-)</ci>
    </cerror>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <sum></sum>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>x</ci>
      <apply>
       <minus></minus>
       <ci>t</ci>
       <cn type="integer">1</cn>
      </apply>
     </apply>
    </apply>
    <csymbol cd="unknown">P</csymbol>
    <cerror>
     <csymbol cd="ambiguous">fragments</csymbol>
     <ci>normal-(</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>x</ci>
      <ci>t</ci>
     </apply>
     <ci>normal-|</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>x</ci>
      <apply>
       <minus></minus>
       <ci>t</ci>
       <cn type="integer">1</cn>
      </apply>
     </apply>
     <ci>normal-)</ci>
    </cerror>
    <csymbol cd="unknown">P</csymbol>
    <cerror>
     <csymbol cd="ambiguous">fragments</csymbol>
     <ci>normal-(</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>x</ci>
      <apply>
       <minus></minus>
       <ci>t</ci>
       <cn type="integer">1</cn>
      </apply>
     </apply>
     <ci>normal-|</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>m</ci>
      <ci>t</ci>
     </apply>
     <ci>normal-,</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>o</ci>
      <apply>
       <ci>normal-:</ci>
       <cn type="integer">1</cn>
       <apply>
        <minus></minus>
        <ci>t</ci>
        <cn type="integer">1</cn>
       </apply>
      </apply>
     </apply>
     <ci>normal-)</ci>
    </cerror>
    <divide></divide>
    <csymbol cd="unknown">Z</csymbol>
   </cerror>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   P(x_{t}|o_{1:t},m_{t})=\sum_{m_{t-1}}P(o_{t}|x_{t},m_{t})\sum_{x_{t-1}}P(x_{t}%
|x_{t-1})P(x_{t-1}|m_{t},o_{1:t-1})/Z
  </annotation>
 </semantics>
</math>

</p>

<p>Similarly the map can be updated sequentially by</p>

<p>

<math display="block" id="Simultaneous_localization_and_mapping:7">
 <semantics>
  <mrow>
   <mi>P</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <msub>
     <mi>m</mi>
     <mi>t</mi>
    </msub>
    <mo stretchy="false">|</mo>
    <msub>
     <mi>x</mi>
     <mi>t</mi>
    </msub>
    <mo>,</mo>
    <msub>
     <mi>o</mi>
     <mrow>
      <mn>1</mn>
      <mo>:</mo>
      <mi>t</mi>
     </mrow>
    </msub>
    <mo stretchy="false">)</mo>
   </mrow>
   <mo>=</mo>
   <munder>
    <mo largeop="true" movablelimits="false" symmetric="true">∑</mo>
    <msub>
     <mi>x</mi>
     <mi>t</mi>
    </msub>
   </munder>
   <munder>
    <mo largeop="true" movablelimits="false" symmetric="true">∑</mo>
    <msub>
     <mi>m</mi>
     <mi>t</mi>
    </msub>
   </munder>
   <mi>P</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <msub>
     <mi>m</mi>
     <mi>t</mi>
    </msub>
    <mo stretchy="false">|</mo>
    <msub>
     <mi>x</mi>
     <mi>t</mi>
    </msub>
    <mo>,</mo>
    <msub>
     <mi>m</mi>
     <mrow>
      <mi>t</mi>
      <mo>-</mo>
      <mn>1</mn>
     </mrow>
    </msub>
    <mo>,</mo>
    <msub>
     <mi>o</mi>
     <mi>t</mi>
    </msub>
    <mo stretchy="false">)</mo>
   </mrow>
   <mi>P</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <msub>
     <mi>m</mi>
     <mrow>
      <mi>t</mi>
      <mo>-</mo>
      <mn>1</mn>
     </mrow>
    </msub>
    <mo>,</mo>
    <msub>
     <mi>x</mi>
     <mi>t</mi>
    </msub>
    <mo stretchy="false">|</mo>
    <msub>
     <mi>o</mi>
     <mrow>
      <mn>1</mn>
      <mo>:</mo>
      <mrow>
       <mi>t</mi>
       <mo>-</mo>
       <mn>1</mn>
      </mrow>
     </mrow>
    </msub>
    <mo>,</mo>
    <msub>
     <mi>m</mi>
     <mrow>
      <mi>t</mi>
      <mo>-</mo>
      <mn>1</mn>
     </mrow>
    </msub>
    <mo stretchy="false">)</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <cerror>
    <csymbol cd="ambiguous">fragments</csymbol>
    <csymbol cd="unknown">P</csymbol>
    <cerror>
     <csymbol cd="ambiguous">fragments</csymbol>
     <ci>normal-(</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>m</ci>
      <ci>t</ci>
     </apply>
     <ci>normal-|</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>x</ci>
      <ci>t</ci>
     </apply>
     <ci>normal-,</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>o</ci>
      <apply>
       <ci>normal-:</ci>
       <cn type="integer">1</cn>
       <ci>t</ci>
      </apply>
     </apply>
     <ci>normal-)</ci>
    </cerror>
    <eq></eq>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <sum></sum>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>x</ci>
      <ci>t</ci>
     </apply>
    </apply>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <sum></sum>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>m</ci>
      <ci>t</ci>
     </apply>
    </apply>
    <csymbol cd="unknown">P</csymbol>
    <cerror>
     <csymbol cd="ambiguous">fragments</csymbol>
     <ci>normal-(</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>m</ci>
      <ci>t</ci>
     </apply>
     <ci>normal-|</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>x</ci>
      <ci>t</ci>
     </apply>
     <ci>normal-,</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>m</ci>
      <apply>
       <minus></minus>
       <ci>t</ci>
       <cn type="integer">1</cn>
      </apply>
     </apply>
     <ci>normal-,</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>o</ci>
      <ci>t</ci>
     </apply>
     <ci>normal-)</ci>
    </cerror>
    <csymbol cd="unknown">P</csymbol>
    <cerror>
     <csymbol cd="ambiguous">fragments</csymbol>
     <ci>normal-(</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>m</ci>
      <apply>
       <minus></minus>
       <ci>t</ci>
       <cn type="integer">1</cn>
      </apply>
     </apply>
     <ci>normal-,</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>x</ci>
      <ci>t</ci>
     </apply>
     <ci>normal-|</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>o</ci>
      <apply>
       <ci>normal-:</ci>
       <cn type="integer">1</cn>
       <apply>
        <minus></minus>
        <ci>t</ci>
        <cn type="integer">1</cn>
       </apply>
      </apply>
     </apply>
     <ci>normal-,</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>m</ci>
      <apply>
       <minus></minus>
       <ci>t</ci>
       <cn type="integer">1</cn>
      </apply>
     </apply>
     <ci>normal-)</ci>
    </cerror>
   </cerror>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   P(m_{t}|x_{t},o_{1:t})=\sum_{x_{t}}\sum_{m_{t}}P(m_{t}|x_{t},m_{t-1},o_{t})P(m%
_{t-1},x_{t}|o_{1:t-1},m_{t-1})
  </annotation>
 </semantics>
</math>

</p>

<p>Like many inference problems, the solutions to inferring the two variables together can be found, to a local optimum solution, by alternating updates of the two beliefs in a form of <a href="EM_algorithm" title="wikilink">EM algorithm</a>.</p>
<h2 id="algorithms">Algorithms</h2>

<p>Statistical techniques used to approximate the above equations include <a href="Kalman_filter" title="wikilink">Kalman filters</a>, <a href="particle_filter" title="wikilink">particle filters</a> (aka. <a href="Monte_Carlo_method" title="wikilink">Monte Carlo methods</a>) and scan matching of range data. They provide an estimation of the posterior probability function for the pose of the robot and for the parameters of the map. <a href="Set_estimation" title="wikilink">Set-membership techniques</a> are mainly based on <a href="interval_propagation" title="wikilink">interval constraint propagation</a>.<a class="footnoteRef" href="#fn2" id="fnref2"><sup>2</sup></a><a class="footnoteRef" href="#fn3" id="fnref3"><sup>3</sup></a> They provide a set which encloses the pose of the robot and a set approximation of the map.</p>

<p><a href="Bundle_adjustment" title="wikilink">Bundle adjustment</a> is another popular technique for SLAM using image data. Bundle adjustment jointly estimates poses and landmark positions, increasing map fidelity, and is used in many recently commercialized SLAM systems such as Google's <a href="https://www.google.com/atap/projecttango/">Project Tango</a>.</p>

<p>New SLAM algorithms remain an active research area, and are often driven by differing requirements and assumptions about the types of maps, sensors and models as detailed below. Many SLAM systems can be viewed as combinations of choices from each of these aspects.</p>
<h3 id="mapping">Mapping</h3>

<p><a href="Topological_map" title="wikilink">Topological maps</a> are a method of environment representation which capture the connectivity (i.e., <a class="uri" href="topology" title="wikilink">topology</a>) of the environment rather than creating a geometrically accurate map. Topological SLAM approaches have been used to enforce global consistency in metric SLAM algorithms.<a class="footnoteRef" href="#fn4" id="fnref4"><sup>4</sup></a></p>

<p>In contrast, <a href="grid_maps" title="wikilink">grid maps</a> use arrays (typically square or hexagonal) of discretized cells to represent a topological world, and make inferences about which cells are occupied. Typically the cells are assumed to be statistically independent in order to simplify computation. Under such assumption, 

<math display="inline" id="Simultaneous_localization_and_mapping:8">
 <semantics>
  <mrow>
   <mi>P</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <msub>
     <mi>m</mi>
     <mi>t</mi>
    </msub>
    <mo stretchy="false">|</mo>
    <msub>
     <mi>x</mi>
     <mi>t</mi>
    </msub>
    <mo>,</mo>
    <msub>
     <mi>m</mi>
     <mrow>
      <mi>t</mi>
      <mo>-</mo>
      <mn>1</mn>
     </mrow>
    </msub>
    <mo>,</mo>
    <msub>
     <mi>o</mi>
     <mi>t</mi>
    </msub>
    <mo stretchy="false">)</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <cerror>
    <csymbol cd="ambiguous">fragments</csymbol>
    <csymbol cd="unknown">P</csymbol>
    <cerror>
     <csymbol cd="ambiguous">fragments</csymbol>
     <ci>normal-(</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>m</ci>
      <ci>t</ci>
     </apply>
     <ci>normal-|</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>x</ci>
      <ci>t</ci>
     </apply>
     <ci>normal-,</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>m</ci>
      <apply>
       <minus></minus>
       <ci>t</ci>
       <cn type="integer">1</cn>
      </apply>
     </apply>
     <ci>normal-,</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>o</ci>
      <ci>t</ci>
     </apply>
     <ci>normal-)</ci>
    </cerror>
   </cerror>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   P(m_{t}|x_{t},m_{t-1},o_{t})
  </annotation>
 </semantics>
</math>

 are set to 1 if the new map's cells are consistent with the observation 

<math display="inline" id="Simultaneous_localization_and_mapping:9">
 <semantics>
  <msub>
   <mi>o</mi>
   <mi>t</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>o</ci>
    <ci>t</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   o_{t}
  </annotation>
 </semantics>
</math>

 at location 

<math display="inline" id="Simultaneous_localization_and_mapping:10">
 <semantics>
  <msub>
   <mi>x</mi>
   <mi>t</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>x</ci>
    <ci>t</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   x_{t}
  </annotation>
 </semantics>
</math>

 and 0 if inconsistent.</p>
<h3 id="sensing">Sensing</h3>

<p>SLAM will always use several different types of sensors, and the powers and limits of various sensor types have been a major driver of new algorithms.<a class="footnoteRef" href="#fn5" id="fnref5"><sup>5</sup></a> Statistical independence is the mandatory requirement to cope with metric bias and with noise in measures. Different types of sensors give rise to different SLAM algorithms whose assumptions are which are most appropriate to the sensors. At one extreme, laser scans or visual features provide details of a great many points within an area, sometimes rendering SLAM inference unnecessary because shapes in these point clouds can be easily and unambiguously aligned at each step via <a href="image_registration" title="wikilink">image registration</a>. At the opposite extreme, <a href="tactile_sensor" title="wikilink">tactile sensors</a> are extremely sparse as they contain only information about points very close to the agent, so they require strong prior models to compensate in purely tactile SLAM. Most practical SLAM tasks fall somewhere between these visual and tactile extremes.</p>

<p>Sensor models divide broadly into landmark-based and raw-data approaches. Landmarks are uniquely identifiable objects in the world whose location can be estimated by a sensor -- such as wifi access points or radio beacons. Raw-data approaches make no assumption that landmarks can be identified, and instead model 

<math display="inline" id="Simultaneous_localization_and_mapping:11">
 <semantics>
  <mrow>
   <mi>P</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <msub>
     <mi>o</mi>
     <mi>t</mi>
    </msub>
    <mo stretchy="false">|</mo>
    <msub>
     <mi>x</mi>
     <mi>t</mi>
    </msub>
    <mo stretchy="false">)</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <cerror>
    <csymbol cd="ambiguous">fragments</csymbol>
    <csymbol cd="unknown">P</csymbol>
    <cerror>
     <csymbol cd="ambiguous">fragments</csymbol>
     <ci>normal-(</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>o</ci>
      <ci>t</ci>
     </apply>
     <ci>normal-|</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>x</ci>
      <ci>t</ci>
     </apply>
     <ci>normal-)</ci>
    </cerror>
   </cerror>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   P(o_{t}|x_{t})
  </annotation>
 </semantics>
</math>

 directly as a function of the location.</p>

<p>Optical sensors may be one-dimensional (single beam) or 2D- (sweeping) <a href="laser_rangefinder" title="wikilink">laser rangefinders</a>, 3D High Definition LiDAR, <a href="3D_Flash_LIDAR" title="wikilink">3D Flash LIDAR</a>, 2D or 3D <a class="uri" href="sonar" title="wikilink">sonar</a> sensors and one or more 2D <a href="camera" title="wikilink">cameras</a>.<a class="footnoteRef" href="#fn6" id="fnref6"><sup>6</sup></a> Since 2005, there has been intense research into VSLAM (visual SLAM) using primarily visual (camera) sensors, because of the increasing ubiquity of cameras such as those in mobile devices.<a class="footnoteRef" href="#fn7" id="fnref7"><sup>7</sup></a> Visual and LIDAR sensors are informative enough to allow for landmark extraction in many cases. Other recent forms of SLAM include tactile SLAM (sensing by local touch only),<a class="footnoteRef" href="#fn8" id="fnref8"><sup>8</sup></a> radar SLAM,<a class="footnoteRef" href="#fn9" id="fnref9"><sup>9</sup></a> and wifi-SLAM (sensing by strengths of nearby wifi access points). Recent approaches apply quasi-optical <a class="uri" href="wireless" title="wikilink">wireless</a> ranging for <a href="Trilateration" title="wikilink">multi-lateration</a> (<a href="Real-time_locating_system" title="wikilink">RTLS</a>) or <a href="Triangulation" title="wikilink">multi-angulation</a> in conjunction with SLAM as a tribute to erratic wireless measures. A kind of SLAM for human pedestrians uses a shoe mounted <a href="inertial_measurement_unit" title="wikilink">inertial measurement unit</a> as the main sensor and relies on the fact that pedestrians are able to avoid walls to automatically build floor plans of buildings. by an <a href="indoor_positioning_system" title="wikilink">indoor positioning system</a>.<a class="footnoteRef" href="#fn10" id="fnref10"><sup>10</sup></a></p>

<p>For some outdoor applications, the need for SLAM has been almost entirely removed due to high precision differential <a class="uri" href="GPS" title="wikilink">GPS</a> sensors. From a SLAM perspective, these may be viewed as location sensors whose likelihoods are so sharp that they completely dominate the inference. However GPS sensors may go down entirely or in performance on occasions, especially during times of military conflict which are of particular interest to some robotics applications.</p>
<h3 id="kinematics-modeling">Kinematics modeling</h3>

<p>The 

<math display="inline" id="Simultaneous_localization_and_mapping:12">
 <semantics>
  <mrow>
   <mi>P</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <msub>
     <mi>x</mi>
     <mi>t</mi>
    </msub>
    <mo stretchy="false">|</mo>
    <msub>
     <mi>x</mi>
     <mrow>
      <mi>t</mi>
      <mo>-</mo>
      <mn>1</mn>
     </mrow>
    </msub>
    <mo stretchy="false">)</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <cerror>
    <csymbol cd="ambiguous">fragments</csymbol>
    <csymbol cd="unknown">P</csymbol>
    <cerror>
     <csymbol cd="ambiguous">fragments</csymbol>
     <ci>normal-(</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>x</ci>
      <ci>t</ci>
     </apply>
     <ci>normal-|</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>x</ci>
      <apply>
       <minus></minus>
       <ci>t</ci>
       <cn type="integer">1</cn>
      </apply>
     </apply>
     <ci>normal-)</ci>
    </cerror>
   </cerror>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   P(x_{t}|x_{t-1})
  </annotation>
 </semantics>
</math>

 term represents the kinematics of the model, which usually include information about action commands given to a robot. As a part of the model, the kinematics of the robot is included, to improve estimates of sensing under conditions of inherent and ambient noise. The dynamic model balances the contributions from various sensors, various partial error models and finally comprises in a sharp virtual depiction as a map with the location and heading of the robot as some cloud of probability. Mapping is the final depicting of such model, the map is either such depiction or the abstract term for the model.</p>

<p>For 2D robots, the kinematics are usually given by a mixture of rotation and "move forward" commands, which are implemented with additional motor noise. Unfortunately the distribution formed by independent noise in angular and linear directions is non-Gaussian, but is often approximated by a Gaussian. An alternative approach is to ignore the kinematic term and read odometry data from robot wheels after each command -- such data may then be treated as one of the sensors rather than as kinematics.</p>
<h3 id="multiple-objects">Multiple objects</h3>

<p>The related problems of <a href="data_association" title="wikilink">data association</a> and computational complexity are among the problems yet to be fully resolved, for example the identification of multiple confusable landmarks. A significant recent advance in the feature-based SLAM literature involved the re-examination of the probabilistic foundation for Simultaneous Localisation and Mapping (SLAM) where it was posed in terms of multi-object Bayesian filtering with random finite sets that provide superior performance to leading feature-based SLAM algorithms in challenging measurement scenarios with high false alarm rates and high missed detection rates without the need for data association.<a class="footnoteRef" href="#fn11" id="fnref11"><sup>11</sup></a></p>

<p>Popular techniques for handling multiple objects include <a href="Joint_Probabilistic_Data_Association_Filter" title="wikilink">Joint Probabilistic Data Association Filter</a> (JPDAF) and <a href="probability_hypothesis_density_filter" title="wikilink">probability hypothesis density filter</a> (PHD).</p>
<h3 id="moving-objects">Moving objects</h3>

<p>Non-static environments, such as those containing other vehicles or pedestrians, continue to present research challenges. SLAM with DATMO is a model which tracks moving objects in a similar way to the agent itself.</p>
<h3 id="loop-closure">Loop closure</h3>

<p>Loop closure is the problem of recognizing a previously-visited location and updates the beliefs accordingly. This can be a problem because model or algorithm errors can assign low priors to the location. Typical loop closure methods apply a second algorithm to measure some type of sensor similarity, and re-set the location priors when a match is detected. For example this can be done by storing and comparing <a href="bag_of_words" title="wikilink">bag of words</a> vectors of <a href="Scale-invariant_feature_transform" title="wikilink">SIFT</a> features from each previously visited location.</p>
<h3 id="exploration">Exploration</h3>

<p>"Active SLAM" studies the combined problem of SLAM with deciding where to move next in order to build the map as efficiently as possible. The need for active exploration is especially pronounced in sparse sensing regimes such as tactile SLAM. Active SLAM is generally performed by approximating the <a class="uri" href="entropy" title="wikilink">entropy</a> of the map under hypothetical actions. "Multi agent SLAM" extends this problem to the case of multiple robots coordinating themselves to explore optimally.</p>
<h3 id="biological-inspiration">Biological inspiration</h3>

<p>In neuroscience, the <a class="uri" href="hippocampus" title="wikilink">hippocampus</a> appears to be involved in SLAM-like computations giving rise to <a href="place_cells" title="wikilink">place cells</a> and has formed the basis for bio-inspired SLAM systems such as RatSLAM. Bio-inspired methods are not currently competitive with engineering approaches however.</p>
<h3 id="complexity">Complexity</h3>

<p>Researchers and experts in artificial intelligence have struggled to solve the SLAM problem in practical settings: that is, it required a great deal of computational power to sense a sizable area and process the resulting data to both map and localize.<a class="footnoteRef" href="#fn12" id="fnref12"><sup>12</sup></a> A 2008 review of the topic summarized: "[SLAM] is one of the fundamental challenges of robotics . . . [but it] seems that almost all the current approaches can not perform consistent maps for large areas, mainly due to the increase of the computational cost and due to the uncertainties that become prohibitive when the scenario becomes larger."<a class="footnoteRef" href="#fn13" id="fnref13"><sup>13</sup></a> Generally, complete 3D SLAM solutions are highly computationally intensive as they use complex real-time particle filters, sub-mapping strategies or hierarchical combination of metric topological representations, etc.<a class="footnoteRef" href="#fn14" id="fnref14"><sup>14</sup></a> Robots that use embedded systems cannot fully implement SLAM because of their limitation in computing power. Nguyen V., Harati A., &amp; Siegwart R. (2007) presented a fast, lightweight solution called OrthoSLAM, which breaks down the complexity of the environment into orthogonal planes. By mapping only the planes that are orthogonal to each other, the structure of most indoor environments can be estimated fairly accurately. OrthoSLAM algorithm reduces SLAM to a linear estimation problem since only a single line is processed at a time.<a class="footnoteRef" href="#fn15" id="fnref15"><sup>15</sup></a></p>
<h2 id="history">History</h2>

<p>A seminal work in SLAM is the research of R.C. Smith and P. Cheeseman on the representation and estimation of spatial uncertainty in 1986.<a class="footnoteRef" href="#fn16" id="fnref16"><sup>16</sup></a><a class="footnoteRef" href="#fn17" id="fnref17"><sup>17</sup></a> Other pioneering work in this field was conducted by the research group of <a href="Hugh_F._Durrant-Whyte" title="wikilink">Hugh F. Durrant-Whyte</a> in the early 1990s.<a class="footnoteRef" href="#fn18" id="fnref18"><sup>18</sup></a> which showed that solutions to SLAM exist in the infinite data limit. This finding motivates the search for algorithms which are computationally tractable and approximate the solution. The self-driving STANLEY car won the DARPA Grand Challenge and included a SLAM system, bringing SLAM to worldwide attention. Mass-market SLAM implementations can now be found in consumer robot vacuum cleaners such as the Neato XV11. <a href="Self-driving_cars" title="wikilink">Self-driving cars</a> by Google and others have now received licenses to drive on public roads in some US states.</p>
<h2 id="see-also">See also</h2>
<ul>
<li><a href="Structure_from_motion" title="wikilink">Structure from motion</a></li>
<li><a href="Kalman_filter" title="wikilink">Kalman filter</a></li>
<li><a href="Monte_Carlo_localization" title="wikilink">Monte Carlo localization</a></li>
<li><a href="Particle_filter" title="wikilink">Particle filter</a></li>
<li><a href="List_of_SLAM_Methods" title="wikilink">List of SLAM Methods</a></li>
<li><a href="Stanley_(vehicle)" title="wikilink">DARPA Grand Challenge winner <em>Stanley</em>, a vehicle using SLAM techniques</a></li>
<li><a href="image_registration" title="wikilink">Registration</a> of range images</li>
<li><a href="Mobile_Robot_Programming_Toolkit" title="wikilink">The Mobile Robot Programming Toolkit (MRPT) project</a>: A set of open-source, cross-platform libraries covering SLAM through <a href="particle_filter" title="wikilink">particle filtering</a> and <a href="Kalman_filter" title="wikilink">Kalman Filtering</a>.</li>
<li><a href="Multi_Autonomous_Ground-robotic_International_Challenge" title="wikilink">Multi Autonomous Ground-robotic International Challenge</a>: A $1.6 million international challenge requiring multiple vehicles to collaboratively map a large area</li>
<li><a class="uri" href="Stereophotogrammetry" title="wikilink">Stereophotogrammetry</a></li>
</ul>
<h2 id="references">References</h2>
<h2 id="external-links">External links</h2>
<ul>
<li><a href="http://www.probabilistic-robotics.org/">Probabilistic Robotics by </a><a href="Sebastian_Thrun" title="wikilink">Sebastian Thrun</a>, <a href="Wolfram_Burgard" title="wikilink">Wolfram Burgard</a> and <a href="Dieter_Fox" title="wikilink">Dieter Fox</a> with a clear overview of SLAM.</li>
<li><a href="http://ocw.mit.edu/courses/aeronautics-and-astronautics/16-412j-cognitive-robotics-spring-2005/projects/1aslam_blas_repo.pdf">SLAM For Dummies (A Tutorial Approach to Simultaneous Localization and Mapping)</a>.</li>
<li><a href="http://www.doc.ic.ac.uk/%7Eajd/index.html">Andrew Davison</a> research page at <a href="Imperial_College_London" title="wikilink">Imperial College London</a> about SLAM using vision.</li>
<li><a href="http://www.ai.rug.nl/~gert/as/">Autonomous and Perceptive Systems</a> research page at <a href="University_of_Groningen" title="wikilink">University of Groningen</a> about visual SLAM.</li>
<li><a href="http://openslam.org/">openslam.org</a> A good collection of open source code and explanations of SLAM.</li>
<li><a href="http://eia.udg.es/~qsalvi/Slam.zip">Matlab Toolbox of Kalman Filtering applied to Simultaneous Localization and Mapping</a> Vehicle moving in 1D, 2D and 3D.</li>
<li><a href="http://rogerstuckey.com/2011/02/21/slam-html5/">SLAM Example</a> using <a href="http://processingjs.org/">Processing.js</a> of Feature-Based Navigation.</li>
<li><a href="http://www.kn-s.dlr.de/indoornav/footslam_video.html">FootSLAM research page</a> at <a href="German_Aerospace_Center" title="wikilink">DLR</a> including the related Wifi SLAM and PlaceSLAM approaches.</li>
<li>[<a class="uri" href="http://www.youtube.com/watch?v=B2qzYCeT9oQ&amp;list">http://www.youtube.com/watch?v=B2qzYCeT9oQ&amp;list;</a>;=PLpUPoM7Rgzi_7YWn14Va2FODh7LzADBSm SLAM lecture] Online SLAM lecture based on Python.</li>
</ul>

<p>"</p>

<p><a href="Category:Robot_navigation" title="wikilink">Category:Robot navigation</a> <a href="Category:Applied_machine_learning" title="wikilink">Category:Applied machine learning</a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1"><a href="#fnref1">↩</a></li>
<li id="fn2"><a href="#fnref2">↩</a></li>
<li id="fn3"><a href="#fnref3">↩</a></li>
<li id="fn4"><a href="#fnref4">↩</a></li>
<li id="fn5"><a href="#fnref5">↩</a></li>
<li id="fn6"></li>
<li id="fn7"><a href="#fnref7">↩</a></li>
<li id="fn8"><a href="#fnref8">↩</a></li>
<li id="fn9"><a href="#fnref9">↩</a></li>
<li id="fn10"><a href="#fnref10">↩</a></li>
<li id="fn11"><a href="#fnref11">↩</a></li>
<li id="fn12"><a href="#fnref12">↩</a></li>
<li id="fn13"><a href="#fnref13">↩</a></li>
<li id="fn14">Nguyen, V.; Harati, A; Siegwart, R., "A lightweight SLAM algorithm using Orthogonal planes for indoor mobile robotics," Intelligent Robots and Systems, 2007. IROS 2007. IEEE/RSJ International Conference on , vol., no., pp.658,663, Oct. 29 2007-Nov. 2 2007<a href="#fnref14">↩</a></li>
<li id="fn15"></li>
<li id="fn16"><a href="#fnref16">↩</a></li>
<li id="fn17"><a href="#fnref17">↩</a></li>
<li id="fn18"><a href="#fnref18">↩</a></li>
</ol>
</section>
</body>
</html>
