


Knuth–Bendix completion algorithm




Knuth–Bendix completion algorithm

The Knuth–Bendix completion algorithm (named after Donald Knuth and Peter Bendix1) is a semi-decision23 algorithm for transforming a set of equations (over terms) into a confluent term rewriting system. When the algorithm succeeds, it effectively solves the word problem for the specified algebra.
Buchberger's algorithm for computing Gröbner bases is a very similar algorithm. Although developed independently, it may also be seen as the instantiation of Knuth–Bendix algorithm in the theory of polynomial rings.
Introduction
For a set E of equations, its deductive closure (↔) is the set of all equations that can be derived by applying equations from E in any order. Formally, E is considered a binary relation, (→E) is its rewrite closure, and (↔) is the equivalence closure of (→E). For a set R of rewrite rules, its deductive closure (→ ∘ ←) is the set of all equations than can be confirmed by applying rules from R left-to-right to both sides until they are literally equal. Formally, R is again viewed as binary relation, (→R) is its rewrite closure, (←R) is its converse, and (→ ∘ ←) is the relation composition of their reflexive transitive closures (→ and ←).
For example, if E = { 1⋅x = x, x−1⋅x = 1, (x⋅y)⋅z = x⋅(y⋅z) } are the group axioms, the derivation chain

a−1⋅(a⋅b)   ↔   (a−1⋅a)⋅b   ↔    1⋅b   ↔   b


demonstrates that a−1⋅(a⋅b) ↔ b is a member of E's deductive closure. If R = { 1⋅x → x, x−1⋅x → 1, (x⋅y)⋅z → x⋅(y⋅z) } is a "rewrite rule" version of E, the derivation chains

(a−1⋅a)⋅b   →   1⋅b   →   b       and       b   ←   b⋅1
 

demonstrate that (a−1⋅a)⋅b →∘← b⋅1 is a member of R's deductive closure. However, there is no way to derive a−1⋅(a⋅b) →∘← b similar to above, since a right-to-left application of the rule (x⋅y)⋅z → x⋅(y⋅z) is not allowed.
The Knuth–Bendix algorithm takes a set E of equations between terms, and a reduction ordering (>) on the set of all terms, and attempts to construct a confluent and terminating term rewriting system R that has the same deductive closure as E. While proving consequences from E often requires human intuition, proving consequences from R does not. For more details, see Confluence (abstract rewriting)#Motivating examples, which gives an example proof from group theory, performed both using E and using R.
Rules
Given a set E of equations between terms, the following inference rules can be used to transform it into an equivalent convergent term rewrite system (if possible):45 They are based on a user-given reduction ordering (>) on the set of all terms; it is lifted to a well-founded ordering (▻) on the set of rewrite rules by defining (s → t) ▻ (l → r) if

s >e l, or
s and l are literally similar and t > r.





Delete

‹ E∪{s = s}

, R ›

⊢

‹ E

, R ›



Compose        

‹ E

, R∪{s → t} ›        

⊢        

‹ E

, R∪{s → u} ›        



Simplify

‹ E∪{s = t}

, R ›

⊢

‹ E∪{s = u}

, R ›



Orient

‹ E∪{s = t}

, R ›

⊢

‹ E

, R∪{s → t} ›



Collapse

‹ E

, R∪{s → t} ›

⊢

‹ E∪{u = t}

, R ›



Deduce

‹ E

, R ›

⊢

‹ E∪{s = t}

, R ›



Example
The following example run, obtained from the E theorem prover, computes a completion of the (additive) group axioms as in Knuth, Bendix (1970). It starts with the three initial equations for the group (neutral element 0, inverse elements, associativity), using f(X,Y) for X+Y, and i(X) for −X. The 10 equations marked with "final" represent the resulting convergent rewrite system. "pm" is short for "paramodulation", implementing deduce. Critical pair computation is an instance of paramodulation for equational unit clauses. "rw" is rewriting, implementing compose, collapse, and simplify. Orienting of equations is done implicitly and not recorded.
      1 :  : [++equal(f(X1,0), X1)] : initial("GROUP.lop", at_line_9_column_1)
       2 :  : [++equal(f(X1,i(X1)), 0)] : initial("GROUP.lop", at_line_12_column_1)
       3 :  : [++equal(f(f(X1,X2),X3), f(X1,f(X2,X3)))] : initial("GROUP.lop", at_line_15_column_1)
       5 :  : [++equal(f(X1,X2), f(X1,f(0,X2)))] : pm(3,1)
       6 :  : [++equal(f(X1,f(X2,i(f(X1,X2)))), 0)] : pm(2,3)
       7 :  : [++equal(f(0,X2), f(X1,f(i(X1),X2)))] : pm(3,2)
      27 :  : [++equal(f(X1,0), f(0,i(i(X1))))] : pm(7,2)
      36 :  : [++equal(X1, f(0,i(i(X1))))] : rw(27,1)
      46 :  : [++equal(f(X1,X2), f(X1,i(i(X2))))] : pm(5,36)
      52 :  : [++equal(f(0,X1), X1)] : rw(36,46)
      60 :  : [++equal(i(0), 0)] : pm(2,52)
      63 :  : [++equal(i(i(X1)), f(0,X1))] : pm(46,52)
      64 :  : [++equal(f(X1,f(i(X1),X2)), X2)] : rw(7,52)
      67 :  : [++equal(i(i(X1)), X1)] : rw(63,52)
      74 :  : [++equal(f(i(X1),X1), 0)] : pm(2,67)
      79 :  : [++equal(f(0,X2), f(i(X1),f(X1,X2)))] : pm(3,74)
      83 :  : [++equal(X2, f(i(X1),f(X1,X2)))] : rw(79,52)
     134 :  : [++equal(f(i(X1),0), f(X2,i(f(X1,X2))))] : pm(83,6)
     151 :  : [++equal(i(X1), f(X2,i(f(X1,X2))))] : rw(134,1)
     165 :  : [++equal(f(i(X1),i(X2)), i(f(X2,X1)))] : pm(83,151)
     239 :  : [++equal(f(X1,0), X1)] : 1 : 'final'
     240 :  : [++equal(f(X1,i(X1)), 0)] : 2 : 'final'
     241 :  : [++equal(f(f(X1,X2),X3), f(X1,f(X2,X3)))] : 3 : 'final'
     242 :  : [++equal(f(0,X1), X1)] : 52 : 'final'
     243 :  : [++equal(i(0), 0)] : 60 : 'final'
     244 :  : [++equal(i(i(X1)), X1)] : 67 : 'final'
     245 :  : [++equal(f(i(X1),X1), 0)] : 74 : 'final'
     246 :  : [++equal(f(X1,f(i(X1),X2)), X2)] : 64 : 'final'
     247 :  : [++equal(f(i(X1),f(X1,X2)), X2)] : 83 : 'final'
     248 :  : [++equal(i(f(X1,X2)), f(i(X2),i(X1)))] : 165 : 'final'
See also Word problem (mathematics) for another presentation of this example.
String rewriting systems in group theory
An important case in computational group theory are string rewriting systems which can be used to give canonical labels to elements or cosets of a finitely presented group as products of the generators. This special case is the focus of this section.
Motivation in group theory
The critical pair lemma states that a term rewriting system is locally confluent (or weakly confluent) if and only if all its critical pairs are convergent. Furthermore, we have Newman's lemma which states that if an (abstract) rewriting system is strongly normalizing and weakly confluent, then the rewriting system is confluent. So, if we can add rules to the term rewriting system in order to force all critical pairs to be convergent while maintaining the strong normalizing property, then this will force the resultant rewriting system to be confluent.
Consider a finitely presented monoid

 
  where X is a finite set of generators and R is a set of defining relations on X. Let X* be the set of all words in X (i.e. the free monoid generated by X). Since the relations R generate an equivalence relation on X*, one can consider elements of M to be the equivalence classes of X* under R. For each class {w1, w2, ... } it is desirable to choose a standard representative wk. This representative is called the canonical or normal form for each word wk in the class. If there is a computable method to determine for each wk its normal form wi then the word problem is easily solved. A confluent rewriting system allows one to do precisely this.
Although the choice of a canonical form can theoretically be made in an arbitrary fashion this approach is generally not computable. (Consider that an equivalence relation on a language can produce an infinite number of infinite classes.) If the language is well-ordered then the order  B and A → B. Since  W_1 > ... > W_n where W_n is irreducible under the rewriting system. However, depending on the rules that are applied at each Wi → Wi+1 it is possible to end up with two different irreducible reductions Wn ≠ W'm of W. However, if the rewriting system given by the relations is converted to a confluent rewriting system via the Knuth–Bendix algorithm, then all reductions are guaranteed to produce the same irreducible word, namely the normal form for that word.
Description of the algorithm for finitely presented monoids
Suppose we are given a presentation

 
 , where 
 
 
 
  is a set of generators and 
 
 
 
  is a set of relations giving the rewriting system. Suppose further that we have a reduction ordering 
 
 
 
  among the words generated by 
 
 
 
 (e.g., shortlex order). For each relation 
 
 
 
  in 
 
 
 
 , suppose 
 
 
 
 . Thus we begin with the set of reductions 
 
 
 
 .
First, if any relation 
 
 
 
  can be reduced, replace 
 
 
 
  and 
 
 
 
  with the reductions.
Next, we add more reductions (that is, rewriting rules) to eliminate possible exceptions of confluence. Suppose that 
 
 
 
  and 
 
 
 
 , where 
 
 
 
 , overlap.

Case 1: either the prefix of 
 
 
 
  equals the suffix of 
 
 
 
 , or vice versa. In the former case, we can write 
 
 
 
  and 
 
 
 
 ; in the latter case, 
 
 
 
  and 
 
 
 
 .
Case 2: either 
 
 
 
  is completely contained (surrounded) in 
 
 
 
 , or vice versa. In the former case, we can write 
 
 
 
  and 
 
 
 
 ; in the latter case, 
 
 
 
  and 
 
 
 
 .

Reduce the word 
 
 
 
  using 
 
 
 
  first, then using 
 
 
 
  first. Call the results 
 
 
 
 , respectively. If 
 
 
 
 , then we have an instance where confluence could fail. Hence, add the reduction 
 
 
 
  to 
 
 
 
 .
After adding a rule to 
 
 
 
 , remove any rules in 
 
 
 
  that might have reducible left sides.
Repeat the procedure until all overlapping left sides have been checked.
Examples
A terminating example
Consider the monoid
 
 
 
 . We use the shortlex order. This is an infinite monoid but nevertheless, the Knuth–Bendix algorithm is able to solve the word problem.
Our beginning three reductions are therefore (1) 
 
 
 
 , (2) 
 
 
 
 , and (3) 
 
 
 
 .
Consider the word 
 
 
 
 . Reducing using (1), we get 
 
 
 
 . Reducing using (3), we get 
 
 
 
 . Hence, we get 
 
 
 
 , giving the reduction rule (4) 
 
 
 
 .
Similarly, using 
 
 
 
  and reducing using (2) and (3), we get 
 
 
 
 . Hence the reduction (5) 
 
 
 
 .
Both of these rules obsolete (3), so we remove it.
Next, consider 
 
 
 
  by overlapping (1) and (5). Reducing we get 
 
 
 
 , so we add the rule (6) 
 
 
 
 . Considering 
 
 
 
  by overlapping (1) and (5), we get 
 
 
 
 , so we add the rule (7) 
 
 
 
 . These obsolete rules (4) and (5), so we remove them.
Now, we are left with the rewriting system

(1) 
 
 

(2) 
 
 

(6) 
 
 

(7) 
 
 


Checking the overlaps of these rules, we find no potential failures of confluence. Therefore, we have a confluent rewriting system, and the algorithm terminates successfully.
A non-terminating example
The order of the generators may crucially affect whether the Knuth–Bendix completion terminates. As an example, consider the free Abelian group by the monoid presentation:



The Knuth–Bendix completion with respect to lexicographic order 
 
 
 
  finishes with a convergent system, however considering the length-lexicographic order 
 
 
 
  it does not finish for there are no finite convergent systems compatible with this latter order.6
Generalizations
If Knuth–Bendix does not succeed, it will either run forever, or fail when it encounters an unorientable equation (i.e. an equation that it cannot turn into a rewrite rule). The enhanced completion without failure will not fail on unorientable equations and provides a semi-decision procedure for the word problem.
The notion of logged rewriting discussed in the paper by Heyworth and Wensley listed below allows some recording or logging of the rewriting process as it proceeds. This is useful for computing identities among relations for presentations of groups.
References



C. Sims. 'Computations with finitely presented groups.' Cambridge, 1994.
Anne Heyworth and C.D. Wensley. "Logged rewriting and identities among relators." Groups St. Andrews 2001 in Oxford. Vol. I, 256–276, London Math. Soc. Lecture Note Ser., 304, Cambridge Univ. Press, Cambridge, 2003.

External links



"
Category:Computational group theory Category:Donald Knuth Category:Combinatorics on words Category:Rewriting systems



D. Knuth, "The Genesis of Attribute Grammars"

, p. 55

 Here: sect.8.1, p.293





