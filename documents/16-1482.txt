   Distribution learning theory      Distribution learning theory   The distributional learning theory or learning of probability distribution is a framework in computational learning theory . It has been proposed from Michael Kearns , Yishay Mansour , Dana Ron , Ronitt Rubinfeld , Robert Schapire and Linda Sellie in 1994 1 and it was inspired from the PAC-framework introduced by Leslie Valiant . 2  In this framework the input is a number of samples drawn from a distribution that belongs to a specific class of distributions. The goal is to find an efficient algorithm that, based on these samples, determines with high probability the distribution from which the samples have been drawn. Because of its generality this framework it has been used in a large variety of different fields like machine learning , approximation algorithms , applied probability and statistics .  This article explains the basic definitions, tools and results in this framework from the theory of computation point of view.  Basic Definitions  Let   X   X   \textstyle X   be the support of the distributions that we are interested in. As in the original work of Kearns et. al. 3 if   X   X   \textstyle X   is finite it can be assumed without loss of generality that    X  =    {  0  ,  1  }   n       X   superscript   0  1   n     \textstyle X=\{0,1\}^{n}   where   n   n   \textstyle n   is the number of bits that have to be used in order to represent any    y  ∈  X      y  X    \textstyle y\in X   . We focus in probability distributions over   X   X   \textstyle X   .  There are two possible representations of a probability distribution   D   D   \textstyle D   over   X   X   \textstyle X   .   probability distribution function (or evaluator) an evaluator    E  D     subscript  E  D    \textstyle E_{D}   for   D   D   \textstyle D   takes as input any    y  ∈  X      y  X    \textstyle y\in X   and outputs a real number     E  D    [  y  ]        subscript  E  D    delimited-[]  y     \textstyle E_{D}[y]   which denotes the probability that of   y   y   \textstyle y   according to   D   D   \textstyle D   , i.e.      E  D    [  y  ]    =   Pr   [   Y  =  y   ]           subscript  E  D    delimited-[]  y     Pr    Y  y      \textstyle E_{D}[y]=\Pr[Y=y]   if    Y  ∼  D     similar-to  Y  D    \textstyle Y\sim D   .    generator a generator    G  D     subscript  G  D    \textstyle G_{D}   for   D   D   \textstyle D   takes as input a string of truly random bits   y   y   \textstyle y   and outputs      G  D    [  y  ]    ∈  X         subscript  G  D    delimited-[]  y    X    \textstyle G_{D}[y]\in X   according to the distribution   D   D   \textstyle D   . Generator can be interpreted as a routine that simulates sampling from the distribution   D   D   \textstyle D   given a sequence of fair coin tosses.   A distribution   D   D   \textstyle D   is called to have a polynomial generator (respectively evaluator) if its generator (respectively evaluator) exists and can be computed in polynomial time.  Let    C  X     subscript  C  X    \textstyle C_{X}   a class of distribution over X, that is    C  X     subscript  C  X    \textstyle C_{X}   is a set such that every    D  ∈   C  X       D   subscript  C  X     \textstyle D\in C_{X}   is a probability distribution with support   X   X   \textstyle X   . The    C  X     subscript  C  X    \textstyle C_{X}   can also be written as   C   C   \textstyle C   for simplicity.  Before defining learnability its necessary to define good approximations of a distribution   D   D   \textstyle D   . There are three ways to measure the distance between two distribution. The three more common possibilities are   Kullback-Leibler divergence    Total variation distance    Kolmogorov distance   The strongest of these distances is the Kullback-Leibler divergence and the weakest is the Kolmogorov distance . This means that for any pair of distributions   D   D   \textstyle D   ,    D  ′     superscript  D  normal-′    \textstyle D^{\prime}   :        K  L   -   d  i  s  t  a  n  c  e   (  D  ,   D  ′   )     ≥    T  V   -   d  i  s  t  a  n  c  e   (  D  ,   D  ′   )     ≥    K  o  l  m  o  g  o  r  o  v   -   d  i  s  t  a  n  c  e   (  D  ,   D  ′   )               K  L     d  i  s  t  a  n  c  e   D   superscript  D  normal-′          T  V     d  i  s  t  a  n  c  e   D   superscript  D  normal-′               K  o  l  m  o  g  o  r  o  v     d  i  s  t  a  n  c  e   D   superscript  D  normal-′         KL-distance(D,D^{\prime})\geq TV-distance(D,D^{\prime})\geq Kolmogorov-%
 distance(D,D^{\prime})     Therefore for example if   D   D   \textstyle D   and    D  ′     superscript  D  normal-′    \textstyle D^{\prime}   are close with respect to Kullback-Leibler divergence then they are also close with respect to all the other distances.  Next definitions hold for all the distances and therefore the symbol    d   (  D  ,   D  ′   )       d   D   superscript  D  normal-′      \textstyle d(D,D^{\prime})   denotes the distance between the distribution   D   D   \textstyle D   and the distribution    D  ′     superscript  D  normal-′    \textstyle D^{\prime}   using one of the distances that we describe above. Although learnability of a class of distributions can be defined using any of these distances, applications refer to a specific distance.  The basic input that we use in order to learn a distribution is an number of samples drawn by this distribution. For the computational point of view the assumption is that such a sample is given in a constant amount of time. So it's like having access to an oracle    G  E  N   (  D  )       G  E  N  D    \textstyle GEN(D)   that returns a sample from the distribution   D   D   \textstyle D   . Sometimes the interest is, apart from measuring the time complexity, to measure the number of samples that have to be used in order to learn a specific distribution   D   D   \textstyle D   in class of distributions   C   C   \textstyle C   . This quantity is called sample complexity of the learning algorithm.  In order for the problem of distribution learning to be more clear consider the problem of supervised learning as defined in. 4 In this framework of statistical learning theory a training set    S  =   {   (   x  1   ,   y  1   )   ,  …  ,   (   x  n   ,   y  n   )   }       S     subscript  x  1    subscript  y  1    normal-…    subscript  x  n    subscript  y  n       \textstyle S=\{(x_{1},y_{1}),\dots,(x_{n},y_{n})\}   and the goal is to find a target function    f  :   X  →  Y      normal-:  f   normal-→  X  Y     \textstyle f:X\rightarrow Y   that minimizes some loss function, e.g. the square loss function. More formally    f  =    arg   min  g     ∫   V   (  y  ,   g   (  x  )    )   d  ρ   (  x  ,  y  )          f       subscript   g        V   y    g  x    d  ρ   x  y        f=\arg\min_{g}\int V(y,g(x))d\rho(x,y)   , where    V   (  ⋅  ,  ⋅  )       V   normal-⋅  normal-⋅     V(\cdot,\cdot)   is the loss function, e.g.     V   (  y  ,  z  )    =    (   y  -  z   )   2         V   y  z     superscript    y  z   2     V(y,z)=(y-z)^{2}   and    ρ   (  x  ,  y  )       ρ   x  y     \rho(x,y)   the probability distribution according to which the elements of the training set are sampled. If the conditional probability distribution      ρ  x    (  y  )        subscript  ρ  x   y    \rho_{x}(y)   is known then the target function has the closed form     f   (  x  )    =    ∫  y    y  d   ρ  x    (  y  )           f  x     subscript   y     y  d   subscript  ρ  x   y      f(x)=\int_{y}yd\rho_{x}(y)   . So the set   S   S   S   is a set of samples from the probability distribution     ρ   (  x  ,  y  )       ρ   x  y     \rho(x,y)   . Now the goal of distributional learning theory if to find   ρ   ρ   \rho   given   S   S   S   which can be used to find the target function   f   f   f   .  Definition of learnability  A class of distributions   C   C   \textstyle C   is called efficiently learnable if for every    ϵ  >  0      ϵ  0    \textstyle\epsilon>0   and    0  <  δ  ≤  1        0  δ       1     \textstyle 0<\delta\leq 1   given access to    G  E  N   (  D  )       G  E  N  D    \textstyle GEN(D)   for an unknown distribution    D  ∈  C      D  C    \textstyle D\in C   , there exists a polynomial time algorithm   A   A   \textstyle A   , called learning algorithm of   C   C   \textstyle C   , that outputs an generator or an evaluator of a distribution    D  ′     superscript  D  normal-′    \textstyle D^{\prime}   such that       Pr   [    d   (  D  ,   D  ′   )    ≤  ϵ   ]    ≥   1  -  δ        Pr      d   D   superscript  D  normal-′     ϵ      1  δ     \Pr[d(D,D^{\prime})\leq\epsilon]\geq 1-\delta     If we know that     D  ′   ∈  C       superscript  D  normal-′   C    \textstyle D^{\prime}\in C   then   A   A   \textstyle A   is called proper learning algorithm , otherwise is called improper learning algorithm .  In some settings the class of distributions   C   C   \textstyle C   is a class with well known distributions which can be described by set a set of parameters. For instance   C   C   \textstyle C   could be the class of all the Gaussian distributions    N   (  μ  ,   σ  2   )       N   μ   superscript  σ  2      \textstyle N(\mu,\sigma^{2})   . In this case the algorithm   A   A   \textstyle A   should be able to estimate the parameters    μ  ,  σ     μ  σ    \textstyle\mu,\sigma   . In this case   A   A   \textstyle A   is called parameter learning algorithm .  Obviously the parameter learning for simple distributions is a very well studied field that is called statistical estimation and there is a very long bibliography on different estimators for different kinds of simple known distributions. But distributions learning theory deals with learning class of distributions that have more complicated description.  First results 5  In their seminal work, Kearns et. al. 6 deal with the case where   A   A   \textstyle A   is described in term of a finite polynomial sized circuit and they proved the following for some specific classes of distribution       O  R      O  R    \textstyle OR   gate distributions for this kind of distributions there is no polynomial-sized evaluator, unless     #  P   ⊆   P  /  poly         normal-#  P     P  poly     \textstyle\#P\subseteq P/\text{poly}   . On the other hand this class is efficiently learnable with generator.    Parity gate distributions this class is efficiently learnable with both generator and evaluator.    Mixtures of Hamming Balls this class is efficiently learnable with both generator and evaluator.    Probabilistic Finite Automata this class is not efficiently learnable with evaluator under the Noisy Parity Assumption which is an impossibility assumption in the PAC learning framework.       ϵ  -     limit-from  ϵ     \textstyle\epsilon-   Covers  One very common technique in order to find a learning algorithm for a class of distributions   C   C   \textstyle C   is to first find a small    ϵ  -     limit-from  ϵ     \textstyle\epsilon-   cover of   C   C   \textstyle C   .  Definition  A set    C  ϵ     subscript  C  ϵ    \textstyle C_{\epsilon}   is called   ϵ   ϵ   \textstyle\epsilon   -cover of   C   C   \textstyle C   if for every    D  ∈  C      D  C    \textstyle D\in C   there is a     D  ′   ∈   C  ϵ        superscript  D  normal-′    subscript  C  ϵ     \textstyle D^{\prime}\in C_{\epsilon}   such that     d   (  D  ,   D  ′   )    ≤  ϵ        d   D   superscript  D  normal-′     ϵ    \textstyle d(D,D^{\prime})\leq\epsilon   . An    ϵ  -     limit-from  ϵ     \textstyle\epsilon-   cover is small if it has polynomial size with respect to the parameters that describe   D   D   \textstyle D   .  Once there is an efficient procedure that for every    ϵ  >  0      ϵ  0    \textstyle\epsilon>0   finds a small    ϵ  -     limit-from  ϵ     \textstyle\epsilon-   cover    C  ϵ     subscript  C  ϵ    \textstyle C_{\epsilon}   of C then the only left task is to select from    C  ϵ     subscript  C  ϵ    \textstyle C_{\epsilon}   the distribution     D  ′   ∈   C  ϵ        superscript  D  normal-′    subscript  C  ϵ     \textstyle D^{\prime}\in C_{\epsilon}   that is closer to the distribution    D  ∈  C      D  C    \textstyle D\in C   that has to be learned.  The problem is that given      D  ′   ,   D  ′′    ∈   C  ϵ         superscript  D  normal-′    superscript  D  ′′     subscript  C  ϵ     \textstyle D^{\prime},D^{\prime\prime}\in C_{\epsilon}   it is not trivial how we can compare    d   (  D  ,   D  ′   )       d   D   superscript  D  normal-′      \textstyle d(D,D^{\prime})   and    d   (  D  ,   D  ′′   )       d   D   superscript  D  ′′      \textstyle d(D,D^{\prime\prime})   in order to decide which one is the closest to   D   D   \textstyle D   , because   D   D   \textstyle D   is unknown. Therefore the samples from   D   D   \textstyle D   have to be used to do these comparisons. Obviously the result of the comparison always has a probability of error. So the task is similar with finding the minimum in a set of element using noisy comparisons. There are a lot of classical algorithms in order to achieve this goal. The most recent one which achieves the best guarantees was proposed by Daskalakis and Kamath  7 This algorithm sets up a fast tournament between the elements of    C  ϵ     subscript  C  ϵ    \textstyle C_{\epsilon}   where the winner    D  *     superscript  D     \textstyle D^{*}   of this tournament is the element which is    ϵ  -     limit-from  ϵ     \textstyle\epsilon-   close to   D   D   \textstyle D   (i.e.     d   (   D  *   ,  D  )    ≤  ϵ        d    superscript  D    D    ϵ    \textstyle d(D^{*},D)\leq\epsilon   ) with probability at least    1  -  δ      1  δ    \textstyle 1-\delta   . In order to do so their algorithm uses    O   (   log   N  /   ϵ  2     )       O      N   superscript  ϵ  2       \textstyle O(\log N/\epsilon^{2})   samples from   D   D   \textstyle D   and runs in    O   (   N   log   N  /   ϵ  2      )       O    N      N   superscript  ϵ  2        \textstyle O(N\log N/\epsilon^{2})   time, where    N  =   |   C  ϵ   |       N     subscript  C  ϵ      \textstyle N=|C_{\epsilon}|   .  Learning Sums of Random Variables  Learning of simple well known distribution is an well studied field and there are a lot of estimators that can be used. One more complicated class of distributions is the distributions of sum of variables that follow simple distributions. These learning procedure have a close relation with limit theorems like the central limit theorem because they tent to examine the same object when the sum tends to an infinite sum. Recently there are two interesting results that we will describe here the : learning Poisson binomial distributions and learning sums of independent integer random variables. All the results below hold using the total variation distance as a distance measure.  Learning Poisson Binomial Distributions 8  Consider   n   n   \textstyle n   independent Bernoulli random variables     X  1   ,  …  ,   X  n       subscript  X  1   normal-…   subscript  X  n     \textstyle X_{1},\dots,X_{n}   with probabilities of success     p  1   ,  …  ,   p  n       subscript  p  1   normal-…   subscript  p  n     \textstyle p_{1},\dots,p_{n}   . A Poisson Binomial Distribution of order   n   n   \textstyle n   is the distribution of the sum    X  =    ∑  i    X  i        X    subscript   i    subscript  X  i      \textstyle X=\sum_{i}X_{i}   . For learning the class     P  B  D   =   {  D  :    D   is a Poisson binomial distribution   }         P  B  D    conditional-set  D    D  is a Poisson binomial distribution      \textstyle PBD=\{D:D~{}\text{ is a Poisson binomial distribution}\}   . The first of the following results deals with the case of improper learning of    P  B  D      P  B  D    \textstyle PBD   and the second with the proper learning of    P  B  D      P  B  D    \textstyle PBD   .  Theorem  Let    D  ∈   P  B  D       D    P  B  D     \textstyle D\in PBD   then there is an algorithm which given   n   n   \textstyle n   ,    ϵ  >  0      ϵ  0    \textstyle\epsilon>0   ,    0  <  δ  ≤  1        0  δ       1     \textstyle 0<\delta\leq 1   and access to    G  E  N   (  D  )       G  E  N  D    \textstyle GEN(D)   finds a    D  ′     superscript  D  normal-′    \textstyle D^{\prime}   such that     Pr   [    d   (  D  ,   D  ′   )    ≤  ϵ   ]    ≥   1  -  δ        Pr      d   D   superscript  D  normal-′     ϵ      1  δ     \textstyle\Pr[d(D,D^{\prime})\leq\epsilon]\geq 1-\delta   . The sample complexity of this algorithm is     O  ~    (    (   1  /   ϵ  3    )    log   (   1  /  δ   )     )        normal-~  O       1   superscript  ϵ  3        1  δ       \textstyle\tilde{O}((1/\epsilon^{3})\log(1/\delta))   and the running time is     O  ~    (    (   1  /   ϵ  3    )    log   n    log  2    (   1  /  δ   )       )        normal-~  O       1   superscript  ϵ  3        n    superscript   2     1  δ         \textstyle\tilde{O}((1/\epsilon^{3})\log n\log^{2}(1/\delta))   .  Theorem  Let    D  ∈   P  B  D       D    P  B  D     \textstyle D\in PBD   then there is an algorithm which given   n   n   \textstyle n   ,    ϵ  >  0      ϵ  0    \textstyle\epsilon>0   ,    0  <  δ  ≤  1        0  δ       1     \textstyle 0<\delta\leq 1   and access to    G  E  N   (  D  )       G  E  N  D    \textstyle GEN(D)   finds a     D  ′   ∈   P  B  D        superscript  D  normal-′     P  B  D     \textstyle D^{\prime}\in PBD   such that     Pr   [    d   (  D  ,   D  ′   )    ≤  ϵ   ]    ≥   1  -  δ        Pr      d   D   superscript  D  normal-′     ϵ      1  δ     \textstyle\Pr[d(D,D^{\prime})\leq\epsilon]\geq 1-\delta   . The sample complexity of this algorithm is     O  ~    (   (   1  /   ϵ  2    )   )    log   (   1  /  δ   )         normal-~  O     1   superscript  ϵ  2        1  δ      \textstyle\tilde{O}((1/\epsilon^{2}))\log(1/\delta)   and the running time is      (   1  /  ϵ   )    O   (    log  2    (   1  /  ϵ   )    )      O  ~    (   log   n   log   (   1  /  δ   )      )        superscript    1  ϵ     O    superscript   2     1  ϵ       normal-~  O       n      1  δ        \textstyle(1/\epsilon)^{O(\log^{2}(1/\epsilon))}\tilde{O}(\log n\log(1/\delta))   .  One very interesting part of the above results is that the sample complexity of the learning algorithm doesn't depend on   n   n   \textstyle n   , although the description of   D   D   \textstyle D   is linear in   n   n   \textstyle n   . Also the second result is almost optimal with respect to the sample complexity because there is also a lower bound of    O   (   1  /   ϵ  2    )       O    1   superscript  ϵ  2      \textstyle O(1/\epsilon^{2})   .  The proof uses a small    ϵ  -     limit-from  ϵ     \textstyle\epsilon-   cover of    P  B  D      P  B  D    \textstyle PBD   that has been produced by Daskalakis and Papadimitriou, 9 in order to get this algorithm.  Learning Sums of Independent Integer Random Variables 10  Consider   n   n   \textstyle n   independent random variables     X  1   ,  …  ,   X  n       subscript  X  1   normal-…   subscript  X  n     \textstyle X_{1},\dots,X_{n}   each of which follows an arbitrary distribution with support    {  0  ,  1  ,  …  ,   k  -  1   }     0  1  normal-…    k  1     \textstyle\{0,1,\dots,k-1\}   . A    k  -     limit-from  k     \textstyle k-   sum of independent integer random variable of order   n   n   \textstyle n   is the distribution of the sum    X  =    ∑  i    X  i        X    subscript   i    subscript  X  i      \textstyle X=\sum_{i}X_{i}   . For learning the class       k  -   S  I  I  R  V    =   {  D  :   D  is a k-sum of independent integer random variable   }         k    S  I  I  R  V     conditional-set  D    D  is a k-sum of independent integer random variable      \textstyle k-SIIRV=\{D:D\text{is a k-sum of independent integer random %
 variable }\}     there is the following result  Theorem  Let    D  ∈   k  -   S  I  I  R  V        D    k    S  I  I  R  V      \textstyle D\in k-SIIRV   then there is an algorithm which given   n   n   \textstyle n   ,    ϵ  >  0      ϵ  0    \textstyle\epsilon>0   and access to    G  E  N   (  D  )       G  E  N  D    \textstyle GEN(D)   finds a    D  ′     superscript  D  normal-′    \textstyle D^{\prime}   such that     Pr   [    d   (  D  ,   D  ′   )    ≤  ϵ   ]    ≥   1  -  δ        Pr      d   D   superscript  D  normal-′     ϵ      1  δ     \textstyle\Pr[d(D,D^{\prime})\leq\epsilon]\geq 1-\delta   . The sample complexity of this algorithm is    poly   (   k  /  ϵ   )       poly    k  ϵ     \textstyle\text{poly}(k/\epsilon)   and the running time is also    poly   (   k  /  ϵ   )       poly    k  ϵ     \textstyle\text{poly}(k/\epsilon)   .  Again one interesting part is that the sample and the time complexity does not depend on   n   n   \textstyle n   . Its possible to conclude this independence for the previous section if we set    k  =  2      k  2    \textstyle k=2   .  Learning Mixtures of Gaussians 11 12  Let the random variables    X  ∼   N   (   μ  1   ,   Σ  1   )       similar-to  X    N    subscript  μ  1    subscript  normal-Σ  1       \textstyle X\sim N(\mu_{1},\Sigma_{1})   and    Y  ∼   N   (   μ  2   ,   Σ  2   )       similar-to  Y    N    subscript  μ  2    subscript  normal-Σ  2       \textstyle Y\sim N(\mu_{2},\Sigma_{2})   . Define the random variable   Z   Z   \textstyle Z   which takes the same value as   X   X   \textstyle X   with probability    w  1     subscript  w  1    \textstyle w_{1}   and the same value as   Y   Y   \textstyle Y   with probability     w  2   =   1  -   w  1         subscript  w  2     1   subscript  w  1      \textstyle w_{2}=1-w_{1}   . Then if    F  1     subscript  F  1    \textstyle F_{1}   is the density of   X   X   \textstyle X   and    F  2     subscript  F  2    \textstyle F_{2}   is the density of   Y   Y   \textstyle Y   the density of   Z   Z   \textstyle Z   is    F  =     w  1    F  1    +    w  2    F  2         F       subscript  w  1    subscript  F  1       subscript  w  2    subscript  F  2       \textstyle F=w_{1}F_{1}+w_{2}F_{2}   . In this case   Z   Z   \textstyle Z   is said to follow a mixture of Gaussians. Pearson 13 was the first who introduced the notion of the mixtures of Gaussians in his attempt to explain the probability distribution from which he got same data that he wanted to analyze. So after doing a lot of calculations by hand, he finally fitted his data to a mixture of Gaussians. The learning task in this case is to determine the parameters of the mixture     w  1   ,   w  2   ,   μ  1   ,   μ  2   ,   Σ  1   ,   Σ  2       subscript  w  1    subscript  w  2    subscript  μ  1    subscript  μ  2    subscript  normal-Σ  1    subscript  normal-Σ  2     \textstyle w_{1},w_{2},\mu_{1},\mu_{2},\Sigma_{1},\Sigma_{2}   .  The first attempt to solve this problem was from Dasgupta . 14 In this work Dasgupta assumes that the two means of the Gaussians are far enough from each other. This means that there is a lower bound on the distance    ||    μ  1   -   μ  2    ||     norm     subscript  μ  1    subscript  μ  2      \textstyle||\mu_{1}-\mu_{2}||   . Using this assumption Dasgupta and a lot of scientists after him where able to learn the parameters of the mixture. The learning procedure starts with clustering the samples into two different clusters minimizing some metric. Using the assumption that the means of the Gaussians are far away from each other with high probability the samples in the first cluster correspond to samples from the first Gaussian and the samples in the second cluster to samples from the second one. Now that the samples are partitioned the     μ  i   ,   Σ  i       subscript  μ  i    subscript  normal-Σ  i     \textstyle\mu_{i},\Sigma_{i}   can be computed from simple statistical estimators and    w  i     subscript  w  i    \textstyle w_{i}   by comparing the magnitude of the clusters.  If    G  M      G  M    \textstyle GM   is the set of all the mixtures of two Gaussians, using the above procedure theorems like the following can be proved.  Theorem 15  Let    D  ∈   G  M       D    G  M     \textstyle D\in GM   with     ||    μ  1   -   μ  2    ||   ≥   c    n  max   (   λ   m  a  x     (   Σ  1   )   ,   λ   m  a  x     (   Σ  2   )            norm     subscript  μ  1    subscript  μ  2       c     fragments  n    fragments  normal-(   subscript  λ    m  a  x     fragments  normal-(   subscript  normal-Σ  1   normal-)   normal-,   subscript  λ    m  a  x     fragments  normal-(   subscript  normal-Σ  2   normal-)         \textstyle||\mu_{1}-\mu_{2}||\geq c\sqrt{n\max(\lambda_{max}(\Sigma_{1}),%
 \lambda_{max}(\Sigma_{2})}   , where    c  >   1  /  2       c    1  2     \textstyle c>1/2   and     λ   m  a  x     (  A  )        subscript  λ    m  a  x    A    \textstyle\lambda_{max}(A)   the largest eigenvalue of   A   A   \textstyle A   , then there is an algorithm which given    ϵ  >  0      ϵ  0    \textstyle\epsilon>0   ,    0  <  δ  ≤  1        0  δ       1     \textstyle 0<\delta\leq 1   and access to    G  E  N   (  D  )       G  E  N  D    \textstyle GEN(D)   finds an approximation     w  i  ′   ,   μ  i  ′   ,   Σ  i  ′       subscript   superscript  w  normal-′   i    subscript   superscript  μ  normal-′   i    subscript   superscript  normal-Σ  normal-′   i     \textstyle w^{\prime}_{i},\mu^{\prime}_{i},\Sigma^{\prime}_{i}   of the parameters such that     Pr   [    ||    w  i   -   w  i  ′    ||   ≤  ϵ   ]    ≥   1  -  δ        Pr     norm     subscript  w  i    subscript   superscript  w  normal-′   i     ϵ      1  δ     \textstyle\Pr[||w_{i}-w^{\prime}_{i}||\leq\epsilon]\geq 1-\delta   (respectively for    μ  i     subscript  μ  i    \textstyle\mu_{i}   and    Σ  i     subscript  normal-Σ  i    \textstyle\Sigma_{i}   . The sample complexity of this algorithm is    M  =   2   O   (    log  2    (   1  /   (   ϵ  δ   )    )    )         M   superscript  2    O    superscript   2     1    ϵ  δ         \textstyle M=2^{O(\log^{2}(1/(\epsilon\delta)))}   and the running time is    O   (     M  2   d   +   M  d  n    )       O       superscript  M  2   d     M  d  n      \textstyle O(M^{2}d+Mdn)   .  The above result could also be generalized in    k  -     limit-from  k     \textstyle k-   mixture of Gaussians. 16  Interestingly for the case of mixture of two Gaussians there are learning results without the assumption of the distance between their means, like the following one which uses the total variation distance as a distance measure.  Theorem 17  Let    F  ∈   G  M       F    G  M     \textstyle F\in GM   then there is an algorithm which given    ϵ  >  0      ϵ  0    \textstyle\epsilon>0   ,    0  <  δ  ≤  1        0  δ       1     \textstyle 0<\delta\leq 1   and access to    G  E  N   (  D  )       G  E  N  D    \textstyle GEN(D)   finds     w  i  ′   ,   μ  i  ′   ,   Σ  i  ′       subscript   superscript  w  normal-′   i    subscript   superscript  μ  normal-′   i    subscript   superscript  normal-Σ  normal-′   i     \textstyle w^{\prime}_{i},\mu^{\prime}_{i},\Sigma^{\prime}_{i}   such that if     F  ′   =     w  1  ′    F  1  ′    +    w  2  ′    F  2  ′          superscript  F  normal-′        subscript   superscript  w  normal-′   1    subscript   superscript  F  normal-′   1       subscript   superscript  w  normal-′   2    subscript   superscript  F  normal-′   2       \textstyle F^{\prime}=w^{\prime}_{1}F^{\prime}_{1}+w^{\prime}_{2}F^{\prime}_{2}   , where     F  i  ′   =   N   (   μ  i  ′   ,   Σ  i  ′   )         subscript   superscript  F  normal-′   i     N    subscript   superscript  μ  normal-′   i    subscript   superscript  normal-Σ  normal-′   i       \textstyle F^{\prime}_{i}=N(\mu^{\prime}_{i},\Sigma^{\prime}_{i})   then     Pr   [    d   (  F  ,   F  ′   )    ≤  ϵ   ]    ≥   1  -  δ        Pr      d   F   superscript  F  normal-′     ϵ      1  δ     \textstyle\Pr[d(F,F^{\prime})\leq\epsilon]\geq 1-\delta   . The sample complexity and the running time of this algorithm is    poly   (  n  ,   1  /  ϵ   ,   1  /  δ   ,   1  /   w  1    ,   1  /   w  2    ,    1  /  d    (   F  1   ,   F  2   )    )       poly   n    1  ϵ     1  δ     1   subscript  w  1      1   subscript  w  2        1  d     subscript  F  1    subscript  F  2        \textstyle\text{poly}(n,1/\epsilon,1/\delta,1/w_{1},1/w_{2},1/d(F_{1},F_{2}))   .  It is very interesting in the above result that the distance between    F  1     subscript  F  1    \textstyle F_{1}   and    F  2     subscript  F  2    \textstyle F_{2}   doesn't affect the quality of the result of the algorithm but just the sample complexity and the running time.  References    "  Category:Computational learning theory     M. Kearns, Y. Mansour, D. Ron, R. Rubinfeld, R. Schapire, L. Sellie On the Learnability of Discrete Distributions . ACM Symposium on Theory of Computing, 1994 1 ↩  L. Valiant A theory of the learnable . Communications of ACM, 1984 ↩   Lorenzo Rosasco, Tomaso Poggio, "A Regularization Tour of Machine Learning — MIT-9.520 Lectures Notes" Manuscript, Dec. 2014 2 ↩    C. Daskalakis, G. Kamath Faster and Sample Near-Optimal Algorithms for Proper Learning Mixtures of Gaussians . Annual Conference on Learning Theory, 2014 3 ↩  C. Daskalakis, I. Diakonikolas, R. Servedio Learning Poisson Binomial Distributions . ACM Symposium on Theory of Computing, 2012 4 ↩  C. Daskalakis, C. Papadimitriou Sparse Covers for Sums of Indicators . Probability Theory and Related Fields, 2014 5 ↩  C. Daskalakis, I. Diakonikolas, R. O’Donnell, R. Servedio, L. Tan Learning Sums of Independent Integer Random Variables . IEEE Symposium on Foundations of Computer Science, 2013 6 ↩   A. Kalai, A. Moitra, G. Valiant Efficiently Learning Mixtures of Two Gaussians ACM Symposium on Theory of Computing, 2010 7 ↩  K. Pearson Contribution to the Mathematical Theory of Evolution . Philosophical Transaction of the Royal Society in London, 1894 [ http://www.jstor.org/discover/10.2307/90649?sid=21104909080371&uid; ;=4&uid;=2] ↩  S. Dasgupta Learning Mixtures of Gaussians . IEEE Symposium on Foundations of Computer Science, 1999 8 ↩        