   Remez algorithm      Remez algorithm   The Remez algorithm or Remez exchange algorithm , published by Evgeny Yakovlevich Remez in 1934, 1 is an iterative algorithm used to find simple approximations to functions, specifically, approximations by functions in a Chebyshev space that are the best in the uniform norm  L ∞ sense.  A typical example of a Chebyshev space is the subspace of Chebyshev polynomials of order n in the space of real continuous functions on an interval , C [ a , b ]. The polynomial of best approximation within a given subspace is defined to be the one that minimizes the maximum absolute difference between the polynomial and the function. In this case, the form of the solution is precised by the equioscillation theorem .  Procedure  The Remez algorithm starts with the function f to be approximated and a set X of    n  +  2      n  2    n+2   sample points     x  1   ,   x  2   ,  …  ,   x   n  +  2        subscript  x  1    subscript  x  2   normal-…   subscript  x    n  2      x_{1},x_{2},...,x_{n+2}   in the approximation interval, usually the Chebyshev nodes linearly mapped to the interval. The steps are:   Solve the linear system of equations         b  0   +    b  1    x  i    +  …  +    b  n    x  i  n    +     (   -  1   )   i   E    =   f   (   x  i   )           subscript  b  0      subscript  b  1    subscript  x  i    normal-…     subscript  b  n    superscript   subscript  x  i   n       superscript    1   i   E      f   subscript  x  i      b_{0}+b_{1}x_{i}+...+b_{n}x_{i}^{n}+(-1)^{i}E=f(x_{i})   (where    i  =   1  ,  2  ,    …  n   +  2        i   1  2      normal-…  n   2      i=1,2,...n+2   ),   for the unknowns     b  0   ,    b  1   …   b  n        subscript  b  0      subscript  b  1   normal-…   subscript  b  n      b_{0},b_{1}...b_{n}   and E .    Use the    b  i     subscript  b  i    b_{i}   as coefficients to form a polynomial    P  n     subscript  P  n    P_{n}   .  Find the set M of points of local maximum error    |     P  n    (  x  )    -   f   (  x  )     |           subscript  P  n   x     f  x      |P_{n}(x)-f(x)|   .  If the errors at every    m  ∈  M      m  M    m\in M   are of equal magnitude and alternate in sign, then    P  n     subscript  P  n    P_{n}   is the minimax approximation polynomial. If not, replace X with M and repeat the steps above.   The result is called the polynomial of best approximation, the Chebyshev approximation, or the minimax approximation .  A review of technicalities in implementing the Remez algorithm is given by W. Fraser. 2  On the choice of initialization  The Chebyshev nodes are a common choice for the initial approximation because of their role in the theory of polynomial interpolation. For the initialization of the optimization problem for function f by the Lagrange interpolant L n ( f ), it can be shown that this initial approximation is bounded by        ∥   f  -    L  n    (  f  )     ∥   ∞   ≤    (   1  +    ∥   L  n   ∥   ∞    )     inf   p  ∈   P  n      ∥   f  -  p   ∥          subscript   norm    f     subscript  L  n   f           1   subscript   norm   subscript  L  n         subscript  infimum    p   subscript  P  n      norm    f  p        \lVert f-L_{n}(f)\rVert_{\infty}\leq(1+\lVert L_{n}\rVert_{\infty})\inf_{p\in P%
 _{n}}\lVert f-p\rVert     with the norm or Lebesgue constant of the Lagrange interpolation operator L n of the nodes ( t 1 , ..., t n + 1 ) being         ∥   L  n   ∥   ∞   =     Λ  ¯   n    (  T  )    =     max    -  1   ≤  x  ≤  1     λ  n     (  T  ;  x  )     ,         subscript   norm   subscript  L  n         subscript   normal-¯  normal-Λ   n   T            subscript         1   x       1      subscript  λ  n     T  x       \lVert L_{n}\rVert_{\infty}=\overline{\Lambda}_{n}(T)=\max_{-1\leq x\leq 1}%
 \lambda_{n}(T;x),     T being the zeros of the Chebyshev polynomials, and the Lebesgue functions being          λ  n    (  T  ;  x  )    =    ∑   j  =  1    n  +  1     |    l  j    (  x  )    |     ,     l  j    (  x  )    =    ∏    i  ≠  j    i  =  1     n  +  1      (   x  -   t  i    )    (    t  j   -   t  i    )       .     formulae-sequence       subscript  λ  n    T  x      superscript   subscript     j  1      n  1         subscript  l  j   x           subscript  l  j   x     superscript   subscript  product   superscript    i  j     i  1       n  1        x   subscript  t  i       subscript  t  j    subscript  t  i         \lambda_{n}(T;x)=\sum_{j=1}^{n+1}\left|l_{j}(x)\right|,\quad l_{j}(x)=\prod_{%
 \stackrel{i=1}{i\neq j}}^{n+1}\frac{(x-t_{i})}{(t_{j}-t_{i})}.     Theodore A. Kilgore, 3 Carl de Boor, and Allan Pinkus 4 proved that there exists a unique t i for each L n , although not known explicitly for (ordinary) polynomials. Similarly,       Λ  ¯   n    (  T  )    =     min    -  1   ≤  x  ≤  1     λ  n     (  T  ;  x  )           subscript   normal-¯  normal-Λ   n   T       subscript         1   x       1      subscript  λ  n     T  x      \underline{\Lambda}_{n}(T)=\min_{-1\leq x\leq 1}\lambda_{n}(T;x)   , and the optimality of a choice of nodes can be expressed as       Λ  ¯   n   -    Λ  ¯   n    ≥  0.         subscript   normal-¯  normal-Λ   n    subscript   normal-¯  normal-Λ   n    0.    \overline{\Lambda}_{n}-\underline{\Lambda}_{n}\geq 0.     For Chebyshev nodes, which provides a suboptimal, but analytically explicit choice, the asymptotic behavior is known as 5         Λ  ¯   n    (  T  )    =     2  π    log   (   n  +  1   )     +    2  π    (   γ  +   log   8  π     )    +   α   n  +  1            subscript   normal-¯  normal-Λ   n   T         2  π       n  1         2  π     γ      8  π       subscript  α    n  1       \overline{\Lambda}_{n}(T)=\frac{2}{\pi}\log(n+1)+\frac{2}{\pi}\left(\gamma+%
 \log\frac{8}{\pi}\right)+\alpha_{n+1}     ( γ being the Euler-Mascheroni constant ) with      0  <   α  n   <   π   72   n  2           0   subscript  α  n          π    72   superscript  n  2        0<\alpha_{n}<\frac{\pi}{72n^{2}}   for     n  ≥  1   ,      n  1    n\geq 1,     and upper bound 6         Λ  ¯   n    (  T  )    ≤     2  π    log   (   n  +  1   )     +  1          subscript   normal-¯  normal-Λ   n   T         2  π       n  1     1     \overline{\Lambda}_{n}(T)\leq\frac{2}{\pi}\log(n+1)+1     Lev Brutman 7 obtained the bound for    n  ≥  3      n  3    n\geq 3   , and    T  ^     normal-^  T    \hat{T}   being the zeros of the expanded Chebyshev polynomials:          Λ  ¯   n    (   T  ^   )    -     Λ  ¯   n    (   T  ^   )     <       Λ  ¯   3   -    1  6    cot   π  8      +    π  64    1    sin  2    (    3  π   /  16   )       -    2  π    (   γ  -   log  π    )     ≈  0.201.             subscript   normal-¯  normal-Λ   n    normal-^  T       subscript   normal-¯  normal-Λ   n    normal-^  T            subscript   normal-¯  normal-Λ   3       1  6       π  8          π  64     1    superscript   2       3  π   16           2  π     γ    π           0.201.     \overline{\Lambda}_{n}(\hat{T})-\underline{\Lambda}_{n}(\hat{T})<\overline{%
 \Lambda}_{3}-\frac{1}{6}\cot\frac{\pi}{8}+\frac{\pi}{64}\frac{1}{\sin^{2}(3\pi%
 /16)}-\frac{2}{\pi}(\gamma-\log\pi)\approx 0.201.     Rüdiger Günttner 8 obtained from a sharper estimate for    n  ≥  40      n  40    n\geq 40             Λ  ¯   n    (   T  ^   )    -     Λ  ¯   n    (   T  ^   )     <  0.0196.           subscript   normal-¯  normal-Λ   n    normal-^  T       subscript   normal-¯  normal-Λ   n    normal-^  T     0.0196.    \overline{\Lambda}_{n}(\hat{T})-\underline{\Lambda}_{n}(\hat{T})<0.0196.     Detailed discussion  This section provides more information on the steps outlined above. In this section, the index i runs from 0 to n +1.  Step 1: Given     x  0   ,   x  1   ,   …   x   n  +  1         subscript  x  0    subscript  x  1     normal-…   subscript  x    n  1       x_{0},x_{1},...x_{n+1}   , solve the linear system of n +2 equations        b  0   +    b  1    x  i    +  …  +    b  n    x  i  n    +     (   -  1   )   i   E    =   f   (   x  i   )           subscript  b  0      subscript  b  1    subscript  x  i    normal-…     subscript  b  n    superscript   subscript  x  i   n       superscript    1   i   E      f   subscript  x  i      b_{0}+b_{1}x_{i}+...+b_{n}x_{i}^{n}+(-1)^{i}E=f(x_{i})   (where    i  =   0  ,  1  ,    …  n   +  1        i   0  1      normal-…  n   1      i=0,1,...n+1   ),   for the unknowns     b  0   ,   b  1   ,   …   b  n        subscript  b  0    subscript  b  1     normal-…   subscript  b  n      b_{0},b_{1},...b_{n}   and E .   It should be clear that      (   -  1   )   i   E       superscript    1   i   E    (-1)^{i}E   in this equation makes sense only if the nodes     x  0   ,  …  ,   x   n  +  1        subscript  x  0   normal-…   subscript  x    n  1      x_{0},...,x_{n+1}   are ordered , either strictly increasing or strictly decreasing. Then this linear system has a unique solution. (As is well known, not every linear system has a solution.) Also, the solution can be obtained with only    O   (   n  2   )       O   superscript  n  2     O(n^{2})   arithmetic operations while a standard solver from the library would take    O   (   n  3   )       O   superscript  n  3     O(n^{3})   operations. Here is the simple proof:  Compute the standard n -th degree interpolant     p  1    (  x  )        subscript  p  1   x    p_{1}(x)   to    f   (  x  )       f  x    f(x)   at the first n +1 nodes and also the standard n -th degree interpolant     p  2    (  x  )        subscript  p  2   x    p_{2}(x)   to the ordinates     (   -  1   )   i     superscript    1   i    (-1)^{i}             p  1    (   x  i   )    =   f   (   x  i   )     ,      p  2    (   x  i   )    =    (   -  1   )   i    ,   i  =   0  ,  …  ,  n      .     formulae-sequence       subscript  p  1    subscript  x  i      f   subscript  x  i      formulae-sequence       subscript  p  2    subscript  x  i     superscript    1   i      i   0  normal-…  n       p_{1}(x_{i})=f(x_{i}),p_{2}(x_{i})=(-1)^{i},i=0,...,n.   To this end, use each time Newton's interpolation formula with the divided differences of order    0  ,  …  ,  n     0  normal-…  n    0,...,n   and    O   (   n  2   )       O   superscript  n  2     O(n^{2})   arithmetic operations.  The polynomial     p  2    (  x  )        subscript  p  2   x    p_{2}(x)   has its i -th zero between    x   i  -  1      subscript  x    i  1     x_{i-1}   and       x  i   ,  i   =  1   ,   …  ,  n      formulae-sequence      subscript  x  i   i   1    normal-…  n     x_{i},\ i=1,...,n   , and thus no further zeroes between    x  n     subscript  x  n    x_{n}   and    x   n  +  1      subscript  x    n  1     x_{n+1}        p  2    (   x  n   )        subscript  p  2    subscript  x  n     p_{2}(x_{n})   and     p  2    (   x   n  +  1    )        subscript  p  2    subscript  x    n  1      p_{2}(x_{n+1})   have the same sign     (   -  1   )   n     superscript    1   n    (-1)^{n}   .  The linear combination     p   (  x  )    :=     p  1    (  x  )    -     p  2    (  x  )    ⋅  E       assign    p  x        subscript  p  1   x    normal-⋅     subscript  p  2   x   E      p(x):=p_{1}(x)-p_{2}(x)\!\cdot\!E   is also a polynomial of degree n and         p   (   x  i   )    =     p  1    (   x  i   )    -     p  2    (   x  i   )    ⋅   E     =    f   (   x  i   )    -     (   -  1   )   i   E     ,   i  =   0  ,  …  ,  n     .     formulae-sequence        p   subscript  x  i         subscript  p  1    subscript  x  i     normal-⋅     subscript  p  2    subscript  x  i    E             f   subscript  x  i       superscript    1   i   E        i   0  normal-…  n      p(x_{i})=p_{1}(x_{i})-p_{2}(x_{i})\!\cdot\!E\ =\ f(x_{i})-(-1)^{i}E,\ \ \ \ i=%
 0,\ldots,n.   This is the same as the equation above for    i  =   0  ,  …  ,  n       i   0  normal-…  n     i=0,...,n   and for any choice of E . The same equation for i = n +1 is       p   (   x   n  +  1    )    =     p  1    (   x   n  +  1    )    -     p  2    (   x   n  +  1    )    ⋅   E     =    f   (   x   n  +  1    )    -     (   -  1   )    n  +  1    E            p   subscript  x    n  1          subscript  p  1    subscript  x    n  1      normal-⋅     subscript  p  2    subscript  x    n  1     E             f   subscript  x    n  1        superscript    1     n  1    E       p(x_{n+1})\ =\ p_{1}(x_{n+1})-p_{2}(x_{n+1})\!\cdot\!E\ =\ f(x_{n+1})-(-1)^{n+%
 1}E   and needs special reasoning: solved for the variable E , it is the definition of E :        E   :=      p  1    (   x   n  +  1    )    -   f   (   x   n  +  1    )        p  2    (   x   n  +  1    )    +    (   -  1   )   n      .     assign  E         subscript  p  1    subscript  x    n  1       f   subscript  x    n  1           subscript  p  2    subscript  x    n  1      superscript    1   n       E\ :=\ \frac{p_{1}(x_{n+1})-f(x_{n+1})}{p_{2}(x_{n+1})+(-1)^{n}}.   As mentioned above, the two terms in the denominator have same sign: E and thus     p   (  x  )    ≡    b  0   +    b  1   x   +  …  +    b  n    x  n           p  x      subscript  b  0      subscript  b  1   x   normal-…     subscript  b  n    superscript  x  n       p(x)\equiv b_{0}+b_{1}x+\ldots+b_{n}x^{n}   are always well-defined.  The error at the given n +2 ordered nodes is positive and negative in turn because         p   (   x  i   )    -   f   (   x  i   )     =   -     (   -  1   )   i   E     ,   i  =   0  ,  …  ,    n   +  1.        formulae-sequence        p   subscript  x  i      f   subscript  x  i          superscript    1   i   E       i   0  normal-…    n  1.       p(x_{i})-f(x_{i})\ =\ -(-1)^{i}E,\ \ i=0,...,n\!+\!1.     The theorem of de La Vallée Poussin states that under this condition no polynomial of degree n exists with error less than E . Indeed, if such a polynomial existed, call it     p  ~    (  x  )        normal-~  p   x    \tilde{p}(x)   , then the difference      p   (  x  )    -    p  ~    (  x  )     =    (    p   (  x  )    -   f   (  x  )     )   -   (     p  ~    (  x  )    -   f   (  x  )     )            p  x      normal-~  p   x          p  x     f  x         normal-~  p   x     f  x       p(x)-\tilde{p}(x)=(p(x)-f(x))-(\tilde{p}(x)-f(x))   would still be positive/negative at the n +2 nodes    x  i     subscript  x  i    x_{i}   and therefore have at least n +1 zeros which is impossible for a polynomial of degree n . Thus, this E is a lower bound for the minimum error which can be achieved with polynomials of degree n .  Step 2 changes the notation from     b  0   +    b  1   x   +  …  +    b  n    x  n         subscript  b  0      subscript  b  1   x   normal-…     subscript  b  n    superscript  x  n      b_{0}+b_{1}x+...+b_{n}x^{n}   to    p   (  x  )       p  x    p(x)   .  Step 3 improves upon the input nodes     x  0   ,  …  ,   x   n  +  1        subscript  x  0   normal-…   subscript  x    n  1      x_{0},...,x_{n+1}   and their errors    ±  E     plus-or-minus  E    \pm E   as follows.  In each P-region, the current node    x  i     subscript  x  i    x_{i}   is replaced with the local maximizer     x  ¯   i     subscript   normal-¯  x   i    \bar{x}_{i}   and in each N-region    x  i     subscript  x  i    x_{i}   is replaced with the local minimizer. (Expect     x  ¯   0     subscript   normal-¯  x   0    \bar{x}_{0}   at A , the     x  ¯   i     subscript   normal-¯  x   i    \bar{x}_{i}   near    x  i     subscript  x  i    x_{i}   , and     x  ¯    n  +  1      subscript   normal-¯  x     n  1     \bar{x}_{n+1}   at B .) No high precision is required here, the standard line search with a couple of quadratic fits should suffice. (See 9 )  Let     z  i   :=    p   (    x  ¯   i   )    -   f   (    x  ¯   i   )        assign   subscript  z  i       p   subscript   normal-¯  x   i      f   subscript   normal-¯  x   i       z_{i}:=p(\bar{x}_{i})-f(\bar{x}_{i})   . Each amplitude    |   z  i   |       subscript  z  i     |z_{i}|   is greater than or equal to E . The Theorem of de La Vallée Poussin and its proof also apply to     z  0   ,  …  ,   z   n  +  1        subscript  z  0   normal-…   subscript  z    n  1      z_{0},...,z_{n+1}   with     min   {   |   z  i   |   }    ≥  E           subscript  z  i     E    \min\{|z_{i}|\}\geq E   as the new lower bound for the best error possible with polynomials of degree n .  Moreover,    max   {   |   z  i   |   }          subscript  z  i      \max\{|z_{i}|\}   comes in handy as an obvious upper bound for that best possible error.  Step 4: With     min    {   |   z  i   |   }          subscript  z  i      \min\,\{|z_{i}|\}   and     max    {   |   z  i   |   }          subscript  z  i      \max\,\{|z_{i}|\}   as lower and upper bound for the best possible approximation error, one has a reliable stopping criterion: repeat the steps until     max   {   |   z  i   |   }    -   min   {   |   z  i   |   }             subscript  z  i          subscript  z  i       \max\{|z_{i}|\}-\min\{|z_{i}|\}   is sufficiently small or no longer decreases. These bounds indicate the progress.  Variants  Sometimes more than one sample point is replaced at the same time with the locations of nearby maximum absolute differences.  Sometimes relative error is used to measure the difference between the approximation and the function, especially if the approximation will be used to compute the function on a computer which uses floating point arithmetic.  See also   Approximation theory   Notes  External links   Intro to DSP    "  Category:Polynomials  Category:Approximation theory  Category:Numerical analysis     E. Ya. Remez, "Sur la détermination des polynômes d'approximation de degré donnée", Comm. Soc. Math. Kharkov 10 , 41 (1934); "Sur un procédé convergent d'approximations successives pour déterminer les polynômes d'approximation, Compt. Rend. Acad. Sc. 198 , 2063 (1934); "Sur le calcul effectiv des polynômes d'approximation des Tschebyscheff", Compt. Rend. Acade. Sc. 199 , 337 (1934). ↩  ↩  ↩  ↩  ↩  T. Rivlin, "The Lebesgue constants for polynomial interpolation", in Proceedings of the Int. Conf. on Functional Analysis and Its Application , edited by H. G. Garnier et al. (Springer-Verlag, Berlin, 1974), p. 422; The Chebyshev polynomials (Wiley-Interscience, New York, 1974). ↩  ↩  ↩  David G. Luenberger: Introduction to Linear and Nonlinear Programming , Addison-Wesley Publishing Company 1973. ↩     