


Jaccard index




Jaccard index

The Jaccard index, also known as the Jaccard similarity coefficient (originally coined coefficient de communauté by Paul Jaccard), is a statistic used for comparing the similarity and diversity of sample sets. The Jaccard coefficient measures similarity between finite sample sets, and is defined as the size of the intersection divided by the size of the union of the sample sets:



(If A and B are both empty, we define J(A,B) = 1.)



The MinHash min-wise independent permutations locality sensitive hashing scheme may be used to efficiently compute an accurate estimate of the Jaccard similarity coefficient of pairs of sets, where each set is represented by a constant-sized signature derived from the minimum values of a hash function.
The Jaccard distance, which measures dissimilarity between sample sets, is complementary to the Jaccard coefficient and is obtained by subtracting the Jaccard coefficient from 1, or, equivalently, by dividing the difference of the sizes of the union and the intersection of two sets by the size of the union:



An alternate interpretation of the Jaccard distance is as the ratio of the size of the symmetric difference

 
  to the union.
This distance is a metric on the collection of all finite sets.12
There is also a version of the Jaccard distance for measures, including probability measures. If 
 
 
 
  is a measure on a measurable space

 
 , then we define the Jaccard coefficient by 
 
 
 
 , and the Jaccard distance by 
 
 
 
 . Care must be taken if 
 
 
 
  or 
 
 
 
 , since these formulas are not well defined in that case.
Similarity of asymmetric binary attributes
Given two objects, A and B, each with n binary attributes, the Jaccard coefficient is a useful measure of the overlap that A and B share with their attributes. Each attribute of A and B can either be 0 or 1. The total number of each combination of attributes for both A and B are specified as follows:


 
  represents the total number of attributes where A and B both have a value of 1.


 
  represents the total number of attributes where the attribute of A is 0 and the attribute of B is 1.


 
  represents the total number of attributes where the attribute of A is 1 and the attribute of B is 0.


 
  represents the total number of attributes where A and B both have a value of 0. Each attribute must fall into one of these four categories, meaning that



The Jaccard similarity coefficient, J, is given as



The Jaccard distance, dJ, is given as



Generalized Jaccard similarity and distance
If 
 
 
 
  and 
 
 
 
  are two vectors with all real 
 
 
 
 , then their Jaccard similarity coefficient is defined as


 
  and Jaccard distance



With even more generality, if 
 
 
 
  and 
 
 
 
  are two non-negative measurable functions on a measurable space 
 
 
 
  with measure 
 
 
 
 , then we can define


 
  where 
 
 
 
  and 
 
 
 
  are pointwise operators. Then Jaccard distance is



Then, for example, for two measurable sets 
 
 
 
 , we have 
 
 
 
  where 
 
 
 
  and 
 
 
 
  are the characteristic functions of the corresponding set.
Tanimoto similarity and distance
Various forms of functions described as Tanimoto similarity and Tanimoto distance occur in the literature and on the Internet. Most of these are synonyms for Jaccard similarity and Jaccard distance, but some are mathematically different. Many sources3 cite an unavailable IBM Technical Report4 as the seminal reference.
In "A Computer Program for Classifying Plants", published in October 1960,5 a method of classification based on a similarity ratio, and a derived distance function, is given. It seems that this is the most authoritative source for the meaning of the terms "Tanimoto similarity" and "Tanimoto Distance". The similarity ratio is equivalent to Jaccard similarity, but the distance function is not the same as Jaccard distance.
Tanimoto's definitions of similarity and distance
In that paper, a "similarity ratio" is given over bitmaps, where each bit of a fixed-size array represents the presence or absence of a characteristic in the plant being modelled. The definition of the ratio is the number of common bits, divided by the number of bits set (i.e. nonzero) in either sample.
Presented in mathematical terms, if samples X and Y are bitmaps, 
 
 
 
  is the ith bit of X, and 
 
 
 
  are bitwise and, or operators respectively, then the similarity ratio 
 
 
 
  is



If each sample is modelled instead as a set of attributes, this value is equal to the Jaccard coefficient of the two sets. Jaccard is not cited in the paper, and it seems likely that the authors were not aware of it.
Tanimoto goes on to define a "distance coefficient" based on this ratio, defined for bitmaps with non-zero similarity:



This coefficient is, deliberately, not a distance metric. It is chosen to allow the possibility of two specimens, which are quite different from each other, to both be similar to a third. It is easy to construct an example which disproves the property of triangle inequality.
Other definitions of Tanimoto distance
Tanimoto distance is often referred to, erroneously, as a synonym for Jaccard distance 
 
 
 
 . This function is a proper distance metric. "Tanimoto Distance" is often stated as being a proper distance metric, probably because of its confusion with Jaccard distance.
If Jaccard or Tanimoto similarity is expressed over a bit vector, then it can be written as



where the same calculation is expressed in terms of vector scalar product and magnitude. This representation relies on the fact that, for a bit vector (where the value of each dimension is either 0 or 1) then 
 
 
 
  and 
 
 
 
 .
This is a potentially confusing representation, because the function as expressed over vectors is more general, unless its domain is explicitly restricted. Properties of 
 
 
 
  do not necessarily extend to 
 
 
 
 . In particular, the difference function 
 
 
 
  does not preserve triangle inequality, and is not therefore a proper distance metric, whereas 
 
 
 
  is.
There is a real danger that the combination of "Tanimoto Distance" being defined using this formula, along with the statement "Tanimoto Distance is a proper distance metric" will lead to the false conclusion that the function 
 
 
 
  is in fact a distance metric over vectors or multisets in general, whereas its use in similarity search or clustering algorithms may fail to produce correct results.
Lipkus6 uses a definition of Tanimoto similarity which is equivalent to 
 
 
 
 , and refers to Tanimoto distance as the function 
 
 
 
 . It is however made clear within the paper that the context is restricted by the use of a (positive) weighting vector 
 
 
 
  such that, for any vector A being considered, 
 
 
 
 . Under these circumstances, the function is a proper distance metric, and so a set of vectors governed by such a weighting vector forms a metric space under this function.
See also

Sørensen similarity index
simple matching coefficient
Mountford's index of similarity
Most frequent k characters
Hamming distance
Dice's coefficient, which is equivalent
 
 
 
  and 
 
 

Tversky index
Correlation
Mutual information, a normalized metricated variant of which is an entropic Jaccard distance.

Notes
References


.

.

.

External links

Introduction to Data Mining lecture notes from Tan, Steinbach, Kumar
SimMetrics a sourceforge implementation of Jaccard index and many other similarity metrics
Web based tool for comparing texts using Jaccard coefficient
A web based calculator for finding the Jaccard Coefficient
Tutorial on how to calculate different similarities
Open Source Jaccard Scala implementation as part of the larger stringmetric project

"
Category:Index numbers Category:Measure theory Category:Clustering criteria Category:String similarity measures



↩
↩
For example ↩
↩
↩





