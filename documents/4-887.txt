   Euler's rotation theorem      Euler's rotation theorem   (Figure)  A rotation represented by an Euler axis and angle.   In geometry , Euler's rotation theorem states that, in three-dimensional space , any displacement of a rigid body such that a point on the rigid body remains fixed, is equivalent to a single rotation about some axis that runs through the fixed point . It also means that the composition of two rotations is also a rotation. Therefore the set of rotations has a structure known as a rotation group .  The theorem is named after Leonhard Euler , who proved it in 1775 by an elementary geometric argument. The axis of rotation is known as an Euler axis , typically represented by a unit vector     𝐞  ^     normal-^  𝐞    \mathbf{\hat{e}}   . The extension of the theorem to kinematics yields the concept of instant axis of rotation , a line of fixed points.  In linear algebra terms, the theorem states that, in 3D space, any two Cartesian coordinate systems with a common origin are related by a rotation about some fixed axis. This also means that the product of two rotation matrices is again a rotation matrix and that for a non-identity rotation matrix it must happen that: one of its eigenvalues is 1 and the other two are -1, or it has only one real eigenvalue which is equal to unity. The eigenvector corresponding to this eigenvalue is the axis of rotation connecting the two systems.  Euler's theorem (1776)  Euler states the theorem as follows: 1   Theorema. Quomodocunque sphaera circa centrum suum conuertatur, semper assignari potest diameter, cuius directio in situ translato conueniat cum situ initiali.   or (in English):   When a sphere is moved around its centre it is always possible to find a diameter whose direction in the displaced position is the same as in the initial position.    To prove this, Euler considers a great circle on the sphere and the great circle to which it is transported by the movement. These two circles intersect in two (opposite) points of which one, say A , is chosen. This point lies on the initial circle and thus is transported to a point a on the second circle. On the other hand, A lies also on the transported circle, and thus corresponds to a point α on the initial circle. Notice that the arc aA must be equal to the arc Aα .  Now Euler needs to construct point O in the surface of the sphere that is in the same position in reference to the arcs aA and αA . If such a point exists then:   it is necessary, that the distances OA and Oa are equal to each other; the arcs Oa and OA must be equal,  it is necessary that the angles OaA and OAα are equal.   Now Euler points out that the angles OAa and OaA must also be equal, since Oa and OA have the same length. Thus OAa and OAα are equal, proving O lies on the angle bisecting αAa . To provide a complete construction for O , we need only note that the arc aO may also be constructed such that AaO is the same as αAO . This completes the proof.  (Figure)  Euler original drawing   Euler provides a further construction that might be easier in practice. He proposes two planes:   the symmetry plane of the angle αAa (which passes through the centre C of the sphere), and  the symmetry plane of the arc Aa (which also passes through C ).   Proposition . These two planes intersect in a diameter. This diameter is the one we are looking for.  Proof . Let's call O to any of the endpoints (there are two) of this diameter over the sphere surface. Since αA is mapped on Aa and the triangles have the same angles, it follows that the triangle OαA is transported onto the triangle OAa . Therefore the point O has to remain fixed under the movement.  Corollaries This also shows that the rotation of the sphere can be seen as two consecutive reflections about the two planes described above. Points in a mirror plane are invariant under reflection, and hence the points on their intersection (a line: the axis of rotation) are invariant under both the reflections, and hence under the rotation.  Another simple way to find the rotation axis is by considering the plane on which the points α , A , a lie. The rotation axis is obviously orthogonal to this plane, and passes through the center C of the sphere.  Given that for a rigid body any movement that leaves an axis invariant is a rotation, this also proves that any arbitrary composition of rotations is equivalent to a single rotation around a new axis.  Matrix proof  A spatial rotation is a linear map in one-to-one correspondence with a 3×3 rotation matrix  R that transforms a coordinate vector x into X , that is Rx = X . Therefore, another version of Euler's theorem is that for every rotation R , there is a vector n for which Rn = n . The line μ n is the rotation axis of R .  A rotation matrix has the fundamental property that its inverse is its transpose, that is         𝐑  T   𝐑   =   𝐑𝐑  T   =  𝐈   ,           superscript  𝐑  normal-T   𝐑    superscript  𝐑𝐑  normal-T        𝐈     \mathbf{R}^{\mathrm{T}}\mathbf{R}=\mathbf{R}\mathbf{R}^{\mathrm{T}}=\mathbf{I},   where I is the 3×3 identity matrix and superscript T indicates the transposed matrix.  Compute the determinant of this relation to find that a rotation matrix has determinant ±1. In particular,       1  =   det   (  𝐈  )    =   det   (    𝐑  T   𝐑   )    =   det    (   𝐑  T   )    det   (  𝐑  )      =   det    (  𝐑  )   2       ⟹   det   (  𝐑  )     =   ±  1.       formulae-sequence      1    𝐈             superscript  𝐑  normal-T   𝐑              superscript  𝐑  normal-T     𝐑             superscript  𝐑  2         normal-⟹    𝐑     plus-or-minus  1.      1=\det(\mathbf{I})=\det(\mathbf{R}^{\mathrm{T}}\mathbf{R})=\det(\mathbf{R}^{%
 \mathrm{T}})\det(\mathbf{R})=\det(\mathbf{R})^{2}\quad\Longrightarrow\quad\det%
 (\mathbf{R})=\pm 1.   A rotation matrix with determinant +1 is a proper rotation, and one with a negative determinant −1 is an improper rotation , that is a reflection combined with a proper rotation.  It will now be shown that a rotation matrix R has at least one invariant vector n , i.e., R  n = n . Because this requires that ( R − I ) n = 0, we see that the vector n must be an eigenvector of the matrix R with eigenvalue λ = 1. Thus, this is equivalent to showing that det( R − I ) = 0.  Use the two relations:         det   (   -  𝐑   )    =     (   -  1   )   3    det   (  𝐑  )     =   -   det   (  𝐑  )        and   det   (   𝐑   -  1    )     =  1    ,     formulae-sequence          𝐑       superscript    1   3     𝐑             𝐑         and     superscript  𝐑    1      1     \det(-\mathbf{R})=(-1)^{3}\det(\mathbf{R})=-\det(\mathbf{R})\quad\hbox{and}%
 \quad\det(\mathbf{R}^{-1})=1,   to compute       det   (   𝐑  -  𝐈   )    =           𝐑  𝐈    absent    \displaystyle\det(\mathbf{R}-\mathbf{I})=   This shows that λ = 1 is a root (solution) of the secular equation , that is,        det   (   𝐑  -   λ  𝐈    )    =   0  for     λ  =  1.      formulae-sequence        𝐑    λ  𝐈      0  for      λ  1.     \det(\mathbf{R}-\lambda\mathbf{I})=0\quad\hbox{for}\quad\lambda=1.   In other words, the matrix R − I is singular and has a non-zero kernel , that is, there is at least one non-zero vector, say n , for which          (   𝐑  -  𝐈   )   𝐧   =   𝟎  ⟺     𝐑𝐧  =  𝐧    .     formulae-sequence        𝐑  𝐈   𝐧    0  normal-⟺      𝐑𝐧  𝐧     (\mathbf{R}-\mathbf{I})\mathbf{n}=\mathbf{0}\quad\Longleftrightarrow\quad%
 \mathbf{R}\mathbf{n}=\mathbf{n}.   The line μ n for real μ is invariant under R , i.e., μ n is a rotation axis. This proves Euler's theorem.  Equivalence of an orthogonal matrix to a rotation matrix  Two matrices (representing linear maps) are said to be equivalent if there is a change of basis that makes one equal to the other. A proper orthogonal matrix is always equivalent (in this sense) to either the following matrix or to its vertical reflection:        𝐑  ∼   (      cos  ϕ      -   sin  ϕ      0       sin  ϕ      cos  ϕ     0      0    0    1     )    ,   0  ≤  ϕ  ≤   2  π     .     formulae-sequence   similar-to  𝐑      ϕ       ϕ    0      ϕ     ϕ   0    0  0  1         0  ϕ         2  π       \mathbf{R}\sim\begin{pmatrix}\cos\phi&-\sin\phi&0\\
 \sin\phi&\cos\phi&0\\
 0&0&1\\
 \end{pmatrix},\qquad 0\leq\phi\leq 2\pi.     Then, any orthogonal matrix is either a rotation or an improper rotation . A general orthogonal matrix has only one real eigenvalue, either +1 or −1. When it is +1 the matrix is a rotation. When −1, the matrix is an improper rotation.  If R has more than one invariant vector then    ϕ  =  0      ϕ  0    \phi=0   and R = I . Any vector is an invariant vector of I .  Excursion into matrix theory  In order to prove the previous equation some facts from matrix theory must be recalled.  An m × m matrix A has m orthogonal eigenvectors if and only if A is normal , that is, if A † A = AA † . 2 This result is equivalent to stating that normal matrices can be brought to diagonal form by a unitary similarity transformation:        𝐀𝐔  =     𝐔   diag   (   α  1   ,  …  ,   α  m   )    ⟺       𝐔  †   𝐀𝐔   =   diag   (   α  1   ,  …  ,   α  m   )      ,     formulae-sequence    𝐀𝐔     𝐔  diag    subscript  α  1   normal-…   subscript  α  m     normal-⟺         superscript  𝐔  normal-†   𝐀𝐔    diag   subscript  α  1   normal-…   subscript  α  m       \mathbf{A}\mathbf{U}=\mathbf{U}\;\mathrm{diag}(\alpha_{1},\ldots,\alpha_{m})%
 \quad\Longleftrightarrow\quad\mathbf{U}^{\dagger}\mathbf{A}\mathbf{U}=%
 \operatorname{diag}(\alpha_{1},\ldots,\alpha_{m}),   and U is unitary, that is,        𝐔  †   =   𝐔   -  1     .       superscript  𝐔  normal-†    superscript  𝐔    1      \mathbf{U}^{\dagger}=\mathbf{U}^{-1}.   The eigenvalues α 1 , ..., α m are roots of the secular equation. If the matrix A happens to be unitary (and note that unitary matrices are normal), then        (    𝐔  †   𝐀𝐔   )   †   =   diag   (   α  1  *   ,  …  ,   α  m  *   )    =    𝐔  †    𝐀   -  1    𝐔   =   diag   (   1  /   α  1    ,  …  ,   1  /   α  m    )           superscript     superscript  𝐔  normal-†   𝐀𝐔   normal-†     diag    subscript   superscript  α    1   normal-…   subscript   superscript  α    m             superscript  𝐔  normal-†    superscript  𝐀    1    𝐔          diag     1   subscript  α  1    normal-…    1   subscript  α  m         \left(\mathbf{U}^{\dagger}\mathbf{A}\mathbf{U}\right)^{\dagger}=\mathrm{diag}(%
 \alpha^{*}_{1},\ldots,\alpha^{*}_{m})=\mathbf{U}^{\dagger}\mathbf{A}^{-1}%
 \mathbf{U}=\mathrm{diag}(1/\alpha_{1},\ldots,1/\alpha_{m})   and it follows that the eigenvalues of a unitary matrix are on the unit circle in the complex plane:       α  k  *   =  1  /   α  k   ⟺   α  k  *    α  k   =  |   α  k    |  2   =  1  ,  k  =  1  ,  …  ,  m  .     fragments   subscript   superscript  α    k    1    subscript  α  k    normal-⟺   subscript   superscript  α    k    subscript  α  k    normal-|   subscript  α  k    superscript  normal-|  2    1  normal-,  k   1  normal-,  normal-…  normal-,  m  normal-.    \alpha^{*}_{k}=1/\alpha_{k}\quad\Longleftrightarrow\alpha^{*}_{k}\alpha_{k}=|%
 \alpha_{k}|^{2}=1,\qquad k=1,\ldots,m.   Also an orthogonal (real unitary) matrix has eigenvalues on the unit circle in the complex plane. Moreover, since its secular equation (an m th order polynomial in λ) has real coefficients, it follows that its roots appear in complex conjugate pairs, that is, if α is a root then so is α ∗ . There are 3 roots, thus at least one of them must be purely real (+1 or -1).  After recollection of these general facts from matrix theory, we return to the rotation matrix R . It follows from its realness and orthogonality that we can find a U such that:      𝐑𝐔  =   𝐔   (      e   i  ϕ      0    0      0     e   -   i  ϕ       0      0    0     ±  1      )        𝐑𝐔    𝐔     superscript  e    i  ϕ    0  0    0   superscript  e      i  ϕ     0    0  0   plus-or-minus  1        \mathbf{R}\mathbf{U}=\mathbf{U}\begin{pmatrix}e^{i\phi}&0&0\\
 0&e^{-i\phi}&0\\
 0&0&\pm 1\\
 \end{pmatrix}   If a matrix U can be found that gives the above form, and there is only one purely real component and it is -1, then we define R to be an improper rotation. Let us only consider the case, then, of matrices R that are proper rotations (the third eigenvalue is just 1). The third column of the 3×3 matrix U will then be equal to the invariant vector n . Writing u 1 and u 2 for the first two columns of U , this equation gives         𝐑𝐮  1   =      e   i  ϕ      𝐮  1    and      𝐑𝐮  2   =     e   -   i  ϕ       𝐮  2      .     formulae-sequence     subscript  𝐑𝐮  1       superscript  e    i  ϕ     subscript  𝐮  1    and       subscript  𝐑𝐮  2      superscript  e      i  ϕ      subscript  𝐮  2       \mathbf{R}\mathbf{u}_{1}=e^{i\phi}\,\mathbf{u}_{1}\quad\hbox{and}\quad\mathbf{%
 R}\mathbf{u}_{2}=e^{-i\phi}\,\mathbf{u}_{2}.   If u 1 has eigenvalue 1, then φ= 0 and u 2 has also eigenvalue 1, which implies that in that case R = E .  Finally, the matrix equation is transformed by means of a unitary matrix,       𝐑𝐔   (       1   2         i   2       0        1   2          -  i    2       0      0    0    1     )    =   𝐔      (       1   2         i   2       0        1   2          -  i    2       0      0    0    1     )    (       1   2         1   2       0         -  i    2         i   2       0      0    0    1     )    ⏟     =  𝐈     (      e   i  ϕ      0    0      0     e   -   i  ϕ       0      0    0    1     )    (       1   2         i   2       0        1   2          -  i    2       0      0    0    1     )          𝐑𝐔      1    2      i    2    0      1    2        i     2    0    0  0  1       𝐔   subscript   normal-⏟        1    2      i    2    0      1    2        i     2    0    0  0  1        1    2      1    2    0        i     2      i    2    0    0  0  1        absent  𝐈       superscript  e    i  ϕ    0  0    0   superscript  e      i  ϕ     0    0  0  1        1    2      i    2    0      1    2        i     2    0    0  0  1       \mathbf{R}\mathbf{U}\begin{pmatrix}\frac{1}{\sqrt{2}}&\frac{i}{\sqrt{2}}&0\\
 \frac{1}{\sqrt{2}}&\frac{-i}{\sqrt{2}}&0\\
 0&0&1\\
 \end{pmatrix}=\mathbf{U}\underbrace{\begin{pmatrix}\frac{1}{\sqrt{2}}&\frac{i}%
 {\sqrt{2}}&0\\
 \frac{1}{\sqrt{2}}&\frac{-i}{\sqrt{2}}&0\\
 0&0&1\\
 \end{pmatrix}\begin{pmatrix}\frac{1}{\sqrt{2}}&\frac{1}{\sqrt{2}}&0\\
 \frac{-i}{\sqrt{2}}&\frac{i}{\sqrt{2}}&0\\
 0&0&1\\
 \end{pmatrix}}_{=\;\mathbf{I}}\begin{pmatrix}e^{i\phi}&0&0\\
 0&e^{-i\phi}&0\\
 0&0&1\\
 \end{pmatrix}\begin{pmatrix}\frac{1}{\sqrt{2}}&\frac{i}{\sqrt{2}}&0\\
 \frac{1}{\sqrt{2}}&\frac{-i}{\sqrt{2}}&0\\
 0&0&1\\
 \end{pmatrix}   which gives          𝐔   ′   †    𝐑𝐔  ′    =    (      cos  ϕ      -   sin  ϕ      0       sin  ϕ      cos  ϕ     0      0    0    1     )   with      𝐔  ′   =   𝐔   (       1   2         i   2       0        1   2          -  i    2       0      0    0    1     )      .     formulae-sequence       superscript   superscript  𝐔  normal-′   normal-†    superscript  𝐑𝐔  normal-′         ϕ       ϕ    0      ϕ     ϕ   0    0  0  1    with       superscript  𝐔  normal-′     𝐔      1    2      i    2    0      1    2        i     2    0    0  0  1        \mathbf{U^{\prime}}^{\dagger}\mathbf{R}\mathbf{U^{\prime}}=\begin{pmatrix}\cos%
 \phi&-\sin\phi&0\\
 \sin\phi&\cos\phi&0\\
 0&0&1\\
 \end{pmatrix}\quad\text{ with }\quad\mathbf{U^{\prime}}=\mathbf{U}\begin{%
 pmatrix}\frac{1}{\sqrt{2}}&\frac{i}{\sqrt{2}}&0\\
 \frac{1}{\sqrt{2}}&\frac{-i}{\sqrt{2}}&0\\
 0&0&1\\
 \end{pmatrix}.   The columns of U ′ are orthonormal. The third column is still n , the other two columns are perpendicular to n . We can now see how our definition of improper rotation corresponds with the geometric interpretation: an improper rotation is a rotation around an axis (here, the axis corresponding to the 3rd coordinate) and a reflection on a plane perpendicular to that axis. If we only restrict ourselves to matrices with determinant 1, we can thus see that they must be proper rotations. This result implies that any orthogonal matrix R corresponding to a proper rotation is equivalent to a rotation over an angle φ around an axis n .  Equivalence classes  The trace (sum of diagonal elements) of the real rotation matrix given above is    1  +   2  c  o  s  φ       1    2  c  o  s  φ     1+2cosφ   . Since a trace is invariant under an orthogonal matrix similarity transformation,         Tr   [   𝐀𝐑𝐀  T   ]    =   Tr   [    𝐑𝐀  T   𝐀   ]    =   Tr   [  𝐑  ]       with   𝐀  T    =   𝐀   -  1      ,     formulae-sequence        Tr   delimited-[]   superscript  𝐀𝐑𝐀  normal-T       Tr   delimited-[]     superscript  𝐑𝐀  normal-T   𝐀            Tr   delimited-[]  𝐑         with   superscript  𝐀  normal-T     superscript  𝐀    1       \mathrm{Tr}[\mathbf{A}\mathbf{R}\mathbf{A}^{\mathrm{T}}]=\mathrm{Tr}[\mathbf{R%
 }\mathbf{A}^{\mathrm{T}}\mathbf{A}]=\mathrm{Tr}[\mathbf{R}]\quad\text{ with }%
 \quad\mathbf{A}^{\mathrm{T}}=\mathbf{A}^{-1},   it follows that all matrices that are equivalent to R by such orthogonal matrix transformations have the same trace: the trace is a class function . This matrix transformation is clearly an equivalence relation , that is, all such equivalent matrices form an equivalence class.  In fact, all proper rotation 3×3 rotation matrices form a group , usually denoted by SO(3) (the special orthogonal group in 3 dimensions) and all matrices with the same trace form an equivalence class in this group. All elements of such an equivalence class share their rotation angle , but all rotations are around different axes. If n is an eigenvector of R with eigenvalue 1, then An is also an eigenvector of ARA T , also with eigenvalue 1. Unless A = E , n and An are different.  Applications  Generators of rotations  Suppose we specify an axis of rotation by a unit vector [ x , y , z ] , and suppose we have an infinitely small rotation of angle Δθ  about that vector. Expanding the rotation matrix as an infinite addition, and taking the first order approach, the rotation matrix Δ R is represented as:        Δ  R   =    [     1    0    0      0    1    0      0    0    1     ]   +     [     0    z     -  y        -  z     0    x      y     -  x     0     ]    Δ  θ    =   𝐈  +    𝐀   Δ  θ     .          normal-Δ  R       1  0  0    0  1  0    0  0  1        0  z    y       z   0  x    y    x   0    normal-Δ  θ           𝐈    𝐀  normal-Δ  θ       \Delta R=\begin{bmatrix}1&0&0\\
 0&1&0\\
 0&0&1\end{bmatrix}+\begin{bmatrix}0&z&-y\\
 -z&0&x\\
 y&-x&0\end{bmatrix}\,\Delta\theta=\mathbf{I}+\mathbf{A}\,\Delta\theta.     A finite rotation through angle θ about this axis may be seen as a succession of small rotations about the same axis. Approximating Δθ  as θ/ N where N is a large number, a rotation of θ about the axis may be represented as:       R  =    (   𝟏  +    𝐀  θ   N    )   N   ≈   e   𝐀  θ     .        R   superscript    1      𝐀  θ   N    N         superscript  e    𝐀  θ       R=\left(\mathbf{1}+\frac{\mathbf{A}\theta}{N}\right)^{N}\approx e^{\mathbf{A}%
 \theta}.     It can be seen that Euler's theorem essentially states that all rotations may be represented in this form. The product    𝐀  θ      𝐀  θ    \mathbf{A}\theta   is the "generator" of the particular rotation, being the vector ( x , y , z ) associated with the matrix A. This shows that the rotation matrix and the axis-angle format are related by the exponential function.  One can derive a simple expression for the generator G. One starts with an arbitrary plane 3 defined by a pair of perpendicular unit vectors a and b. In this plane one can choose an arbitrary vector x with perpendicular y. One then solves for y in terms of x and substituting into an expression for a rotation in a plane yields the rotation matrix R which includes the generator G = ba T - ab T .      x  =    a   cos   (  α  )     +   b   sin   (  α  )          x      a    α      b    α       \displaystyle x=a\cos\left(\alpha\right)+b\sin\left(\alpha\right)     To include vectors outside the plane in the rotation one needs to modify the above expression for R by including two projection operators that partition the space. This modified rotation matrix can be rewritten as an exponential function .       P   a  b    =   -   G  2         subscript  P    a  b       superscript  G  2      \displaystyle{{P}_{ab}}=-{{G}^{2}}     Analysis is often easier in terms of these generators, rather than the full rotation matrix. Analysis in terms of the generators is known as the Lie algebra of the rotation group.  Quaternions  It follows from Euler's theorem that the relative orientation of any pair of coordinate systems may be specified by a set of three independent numbers. Sometimes a redundant fourth number is added to simplify operations with quaternion algebra. Three of these numbers are the direction cosines that orient the eigenvector. The fourth is the angle about the eigenvector that separates the two sets of coordinates. Such a set of four numbers is called a quaternion .  While the quaternion as described above, does not involve complex numbers , if quaternions are used to describe two successive rotations, they must be combined using the non-commutative quaternion algebra derived by William Rowan Hamilton through the use of imaginary numbers.  Rotation calculation via quaternions has come to replace the use of direction cosines in aerospace applications through their reduction of the required calculations, and their ability to minimize round-off errors . Also, in computer graphics the ability to perform spherical interpolation between quaternions with relative ease is of value.  Generalizations   See also rotations in 4-dimensional Euclidean space .    In higher dimensions, any rigid motion that preserve a point in dimension 2 n or 2 n +1 is a composition of at most n rotations in orthogonal planes of rotation , though these planes need not be uniquely determined, and a rigid motion may fix multiple axes.  A rigid motion in 3 dimensions that does not necessarily fix a point is a "screw motion". This is because a composition of a rotation with a translation perpendicular to the axis is a rotation about a parallel axis, while composition with a translation parallel to the axis yields a screw motion; see screw axis . This gives rise to screw theory .  See also   Euler angles  Euler–Rodrigues parameters  Rotation formalisms in three dimensions  Rotation operator (vector space)  Angular velocity  Rotation around a fixed axis  Matrix exponential  Axis–angle representation   Notes    References        Euler's theorem and its proof are contained in paragraphs 24–26 of the appendix ( Additamentum . pp. 201–203) of L. Eulero (Leonhard Euler) , Formulae generales pro translatione quacunque corporum rigidorum (General formulas for the translation of arbitrary rigid bodies), presented to the St. Petersburg Academy on October 9, 1775, and first published in Novi Commentarii academiae scientiarum Petropolitanae 20, 1776, pp. 189–207 (E478) and was reprinted in Theoria motus corporum rigidorum , ed. nova, 1790, pp. 449–460 (E478a) and later in his collected works Opera Omnia , Series 2, Volume 9, pp. 84–98.   External links   Euler's original treatise in The Euler Archive : entry on E478 , first publication 1776 ( pdf )  Euler's original text (in Latin) and English translation (by Johan Sten)   "  Category:Euclidean symmetries  Category:Theorems in geometry  Category:Rotation in three dimensions     Novi Commentarii academiae scientiarum Petropolitanae 20, 1776, pp. 189–207 (E478) ↩  The dagger symbol † stands for complex conjugation followed by transposition. For real matrices complex conjugation does nothing and daggering a real matrix is the same as transposing it. ↩  in Euclidean space ↩     