   Itō diffusion      Itō diffusion   In mathematics — specifically, in stochastic analysis — an Itō diffusion is a solution to a specific type of stochastic differential equation . That equation is similar to the Langevin equation used in physics to describe the Brownian motion of a particle subjected to a potential in a viscous fluid. Itō diffusions are named after the Japanese  mathematician  Kiyoshi Itō .  Overview  (Figure)  This Wiener process (Brownian motion) in three-dimensional space (one sample path shown) is an example of an Itō diffusion.   A ( time-homogeneous ) Itō diffusion in n -dimensional Euclidean space  R n is a process  X : [0, +∞) × Ω → R n defined on a probability space (Ω, Σ, P ) and satisfying a stochastic differential equation of the form        d   X  t    =    b   (   X  t   )   d  t   +   σ   (   X  t   )   d   B  t      ,        normal-d   subscript  X  t        b   subscript  X  t   normal-d  t     σ   subscript  X  t   normal-d   subscript  B  t       \mathrm{d}X_{t}=b(X_{t})\,\mathrm{d}t+\sigma(X_{t})\,\mathrm{d}B_{t},     where B is an m -dimensional Brownian motion and b : R n → R n and σ : R n → R n × m satisfy the usual Lipschitz continuity condition        |    b   (  x  )    -   b   (  y  )     |   +   |    σ   (  x  )    -   σ   (  y  )     |    ≤   C   |   x  -  y   |                b  x     b  y           σ  x     σ  y        C      x  y       |b(x)-b(y)|+|\sigma(x)-\sigma(y)|\leq C|x-y|     for some constant C and all x , y ∈ R n ; this condition ensures the existence of a unique strong solution  X to the stochastic differential equation given above. The vector field  b is known as the drift coefficient of X ; the matrix field σ is known as the diffusion coefficient of X . It is important to note that b and σ do not depend upon time; if they were to depend upon time, X would be referred to only as an Itō process , not a diffusion. Itō diffusions have a number of nice properties, which include   sample and Feller continuity ;  the Markov property ;  the strong Markov property ;  the existence of an infinitesimal generator ;  the existence of a characteristic operator ;  Dynkin's formula .   In particular, an Itō diffusion is a continuous, strongly Markovian process such that the domain of its characteristic operator includes all twice-continuously differentiable functions, so it is a diffusion in the sense defined by Dynkin (1965).  Continuity  Sample continuity  An Itō diffusion X is a sample continuous process , i.e., for almost all realisations B t (ω) of the noise, X t (ω) is a continuous function of the time parameter, t . More accurately, there is a "continuous version" of X , a continuous process Y so that      𝐏   [   X  t   =   Y  t   ]   =  1  for all  t  .     fragments  P   fragments  normal-[   subscript  X  t     subscript  Y  t   normal-]    1  for all  t  normal-.    \mathbf{P}[X_{t}=Y_{t}]=1\mbox{ for all }t.     This follows from the standard existence and uniqueness theory for strong solutions of stochastic differential equations.  Feller continuity  In addition to being (sample) continuous, an Itō diffusion X satisfies the stronger requirement to be a Feller-continuous process .  For a point x ∈ R n , let P x denote the law of X given initial datum X 0 = x , and let E x denote expectation with respect to P x .  Let f : R n → R be a Borel - measurable function that is bounded below and define, for fixed t ≥ 0, u : R n → R by        u   (  x  )    =    𝐄  x    [   f   (   X  t   )    ]     .        u  x      superscript  𝐄  x    delimited-[]    f   subscript  X  t        u(x)=\mathbf{E}^{x}[f(X_{t})].      Lower semi-continuity : if f is lower semi-continuous, then u is lower semi-continuous.  Feller continuity: if f is bounded and continuous, then u is continuous.   The behaviour of the function u above when the time t is varied is addressed by the Kolmogorov backward equation, the Fokker–Planck equation, etc. (See below.)  The Markov property  The Markov property  An Itō diffusion X has the important property of being Markovian : the future behaviour of X , given what has happened up to some time t , is the same as if the process had been started at the position X t at time 0. The precise mathematical formulation of this statement requires some additional notation:  Let Σ ∗ denote the natural  filtration of (Ω, Σ) generated by the Brownian motion B : for t ≥ 0,        Σ  t   =   Σ  t  B   =   σ   {     B  s   -  1     (  A  )    ⊆   Ω    :    0  ≤  s  ≤  t   ,   A  ⊆    𝐑  n   Borel     }     .         subscript  normal-Σ  t    superscript   subscript  normal-Σ  t   B          σ   conditional-set       superscript   subscript  B  s     1    A   normal-Ω    formulae-sequence      0  s       t      A     superscript  𝐑  n   Borel          \Sigma_{t}=\Sigma_{t}^{B}=\sigma\left\{B_{s}^{-1}(A)\subseteq\Omega\ :\ 0\leq s%
 \leq t,A\subseteq\mathbf{R}^{n}\mbox{ Borel}\right\}.     It is easy to show that X is adapted to Σ ∗ (i.e. each X t is Σ t -measurable), so the natural filtration F ∗ = F ∗ X of (Ω, Σ) generated by X has F t ⊆ Σ t for each t ≥ 0.  Let f : R n → R be a bounded, Borel-measurable function. Then, for all t and h ≥ 0, the conditional expectation conditioned on the σ-algebra Σ t and the expectation of the process "restarted" from X t satisfy the Markov property :       𝐄  x    [  f   (   X   t  +  h    )   |   Σ  t   ]    (  ω  )   =   𝐄    X  t    (  ω  )      [  f   (   X  h   )   ]   .     fragments   superscript  𝐄  x    fragments  normal-[  f   fragments  normal-(   subscript  X    t  h    normal-)   normal-|   subscript  normal-Σ  t   normal-]    fragments  normal-(  ω  normal-)     superscript  𝐄     subscript  X  t   ω     fragments  normal-[  f   fragments  normal-(   subscript  X  h   normal-)   normal-]   normal-.    \mathbf{E}^{x}\big[f(X_{t+h})\big|\Sigma_{t}\big](\omega)=\mathbf{E}^{X_{t}(%
 \omega)}[f(X_{h})].     In fact, X is also a Markov process with respect to the filtration F ∗ , as the following shows:       𝐄  x    [  f   (   X   t  +  h    )   |   F  t   ]      fragments   superscript  𝐄  x    fragments  normal-[  f   fragments  normal-(   subscript  X    t  h    normal-)   normal-|   subscript  F  t   normal-]     \displaystyle\mathbf{E}^{x}\left[f(X_{t+h})\big|F_{t}\right]     The strong Markov property  The strong Markov property is a generalization of the Markov property above in which t is replaced by a suitable random time τ : Ω → [0, +∞] known as a stopping time . So, for example, rather than "restarting" the process X at time t = 1, one could "restart" whenever X first reaches some specified point p of R n .  As before, let f : R n → R be a bounded, Borel-measurable function. Let τ be a stopping time with respect to the filtration Σ ∗ with τ \mathbf{E}^{x} \big[ f(X_{\tau+h}) \big| \Sigma_{\tau} \big] = \mathbf{E}^{X_{\tau}} \big[ f(X_{h}) \big].  The generator  Definition  Associated to each Itō diffusion, there is a second-order partial differential operator known as the generator of the diffusion. The generator is very useful in many applications and encodes a great deal of information about the process X . Formally, the infinitesimal generator of an Itō diffusion X is the operator A , which is defined to act on suitable functions f : R n → R by        A  f   (  x  )    =    lim   t  ↓  0        𝐄  x    [   f   (   X  t   )    ]    -   f   (  x  )     t     .        A  f  x     subscript    normal-↓  t  0           superscript  𝐄  x    delimited-[]    f   subscript  X  t        f  x    t      Af(x)=\lim_{t\downarrow 0}\frac{\mathbf{E}^{x}[f(X_{t})]-f(x)}{t}.     The set of all functions f for which this limit exists at a point x is denoted D A ( x ), while D A denotes the set of all f for which the limit exists for all x ∈ R n . One can show that any compactly-supported  C 2 (twice differentiable with continuous second derivative) function f lies in D A and that        A  f   (  x  )    =     ∑  i     b  i    (  x  )     ∂  f    ∂   x  i      (  x  )     +     1  2      ∑   i  ,  j       (   σ   (  x  )   σ    (  x  )   ⊤    )    i  ,  j       ∂  2   f     ∂    x  i      ∂   x  j       (  x  )        ,        A  f  x       subscript   i      subscript  b  i   x      f      subscript  x  i     x        1  2     subscript    i  j       subscript    σ  x  σ   superscript  x  top     i  j        superscript   2   f        subscript  x  i       subscript  x  j      x        Af(x)=\sum_{i}b_{i}(x)\frac{\partial f}{\partial x_{i}}(x)+\tfrac{1}{2}\sum_{i%
 ,j}\left(\sigma(x)\sigma(x)^{\top}\right)_{i,j}\frac{\partial^{2}f}{\partial x%
 _{i}\,\partial x_{j}}(x),     or, in terms of the gradient and scalar and Frobenius  inner products ,         A  f   (  x  )    =      b   (  x  )    ⋅    ∇  x   f     (  x  )    +     1  2     (   σ   (  x  )   σ    (  x  )   ⊤    )      :      ∇  x    ∇  x    f    (  x  )     .     normal-:      A  f  x        normal-⋅    b  x     subscript  normal-∇  x   f    x       1  2     σ  x  σ   superscript  x  top            subscript  normal-∇  x    subscript  normal-∇  x    f   x     Af(x)=b(x)\cdot\nabla_{x}f(x)+\tfrac{1}{2}\left(\sigma(x)\sigma(x)^{\top}%
 \right):\nabla_{x}\nabla_{x}f(x).     An example  The generator A for standard n -dimensional Brownian motion B , which satisfies the stochastic differential equation d X t = d B t , is given by       A  f   (  x  )    =     1  2      ∑   i  ,  j      δ   i  j       ∂  2   f     ∂    x  i      ∂   x  j       (  x  )      =     1  2      ∑  i       ∂  2   f    ∂   x  i  2      (  x  )              A  f  x       1  2     subscript    i  j       subscript  δ    i  j        superscript   2   f        subscript  x  i       subscript  x  j      x              1  2     subscript   i         superscript   2   f      superscript   subscript  x  i   2     x        Af(x)=\tfrac{1}{2}\sum_{i,j}\delta_{ij}\frac{\partial^{2}f}{\partial x_{i}\,%
 \partial x_{j}}(x)=\tfrac{1}{2}\sum_{i}\frac{\partial^{2}f}{\partial x_{i}^{2}%
 }(x)   ,  i.e., A = Δ/2, where Δ denotes the Laplace operator .  The Kolmogorov and Fokker–Planck equations  The generator is used in the formulation of Kolmogorov's backward equation. Intuitively, this equation tells us how the expected value of any suitably smooth statistic of X evolves in time: it must solve a certain partial differential equation in which time t and the initial position x are the independent variables. More precisely, if f ∈ C 2 ( R n ; R ) has compact support and u : [0, +∞) × R n → R is defined by        u   (  t  ,  x  )    =    𝐄  x    [   f   (   X  t   )    ]     ,        u   t  x       superscript  𝐄  x    delimited-[]    f   subscript  X  t        u(t,x)=\mathbf{E}^{x}[f(X_{t})],     then u ( t , x ) is differentiable with respect to t , u ( t , ·) ∈ D A for all t , and u satisfies the following partial differential equation , known as Kolmogorov's backward equation :      {          ∂  u    ∂  t     (  t  ,  x  )    =   A  u   (  t  ,  x  )     ,        t  >  0   ,   x  ∈   𝐑  n     ;          u   (  0  ,  x  )    =   f   (  x  )     ,       x  ∈   𝐑  n    .         cases          u     t     t  x      A  u   t  x      formulae-sequence    t  0     x   superscript  𝐑  n         u   0  x      f  x      x   superscript  𝐑  n      \begin{cases}\dfrac{\partial u}{\partial t}(t,x)=Au(t,x),&t>0,x\in\mathbf{R}^{%
 n};\\
 u(0,x)=f(x),&x\in\mathbf{R}^{n}.\end{cases}     The Fokker–Planck equation (also known as Kolmogorov's forward equation ) is in some sense the " adjoint " to the backward equation, and tells us how the probability density functions of X t evolve with time t . Let ρ( t , ·) be the density of X t with respect to Lebesgue measure on R n , i.e., for any Borel-measurable set S ⊆ R n ,      𝐏   [   X  t   ∈  S  ]   =   ∫  S   ρ   (  t  ,  x  )   d  x  .     fragments  P   fragments  normal-[   subscript  X  t    S  normal-]     subscript   S   ρ   fragments  normal-(  t  normal-,  x  normal-)   d  x  normal-.    \mathbf{P}\left[X_{t}\in S\right]=\int_{S}\rho(t,x)\,\mathrm{d}x.     Let A ∗ denote the Hermitian adjoint of A (with respect to the L 2  inner product ). Then, given that the initial position X 0 has a prescribed density ρ 0 , ρ( t , x ) is differentiable with respect to t , ρ( t , ·) ∈ D A * for all t , and ρ satisfies the following partial differential equation, known as the Fokker–Planck equation :      {          ∂  ρ    ∂  t     (  t  ,  x  )    =    A  *   ρ   (  t  ,  x  )     ,        t  >  0   ,   x  ∈   𝐑  n     ;          ρ   (  0  ,  x  )    =    ρ  0    (  x  )     ,       x  ∈   𝐑  n    .         cases          ρ     t     t  x       superscript  A    ρ   t  x      formulae-sequence    t  0     x   superscript  𝐑  n         ρ   0  x       subscript  ρ  0   x      x   superscript  𝐑  n      \begin{cases}\dfrac{\partial\rho}{\partial t}(t,x)=A^{*}\rho(t,x),&t>0,x\in%
 \mathbf{R}^{n};\\
 \rho(0,x)=\rho_{0}(x),&x\in\mathbf{R}^{n}.\end{cases}     The Feynman–Kac formula  The Feynman–Kac formula is a useful generalization of Kolmogorov's backward equation. Again, f is in C 2 ( R n ; R ) and has compact support, and q : R n → R is taken to be a continuous function that is bounded below. Define a function v : [0, +∞) × R n → R by        v   (  t  ,  x  )    =    𝐄  x    [    exp   (   -    ∫  0  t    q   (   X  s   )   d  s     )    f   (   X  t   )    ]     .        v   t  x       superscript  𝐄  x    delimited-[]          superscript   subscript   0   t     q   subscript  X  s   normal-d  s      f   subscript  X  t        v(t,x)=\mathbf{E}^{x}\left[\exp\left(-\int_{0}^{t}q(X_{s})\,\mathrm{d}s\right)%
 f(X_{t})\right].     The Feynman–Kac formula states that v satisfies the partial differential equation      {          ∂  v    ∂  t     (  t  ,  x  )    =    A  v   (  t  ,  x  )    -   q   (  x  )   v   (  t  ,  x  )      ,        t  >  0   ,   x  ∈   𝐑  n     ;          v   (  0  ,  x  )    =   f   (  x  )     ,       x  ∈   𝐑  n    .         cases          v     t     t  x        A  v   t  x      q  x  v   t  x       formulae-sequence    t  0     x   superscript  𝐑  n         v   0  x      f  x      x   superscript  𝐑  n      \begin{cases}\dfrac{\partial v}{\partial t}(t,x)=Av(t,x)-q(x)v(t,x),&t>0,x\in%
 \mathbf{R}^{n};\\
 v(0,x)=f(x),&x\in\mathbf{R}^{n}.\end{cases}     Moreover, if w : [0, +∞) × R n → R is C 1 in time, C 2 in space, bounded on K × R n for all compact K , and satisfies the above partial differential equation, then w must be v as defined above.  Kolmogorov's backward equation is the special case of the Feynman–Kac formula in which q ( x ) = 0 for all x ∈ R n .  The characteristic operator  Definition  The characteristic operator of an Itō diffusion X is a partial differential operator closely related to the generator, but somewhat more general. It is more suited to certain problems, for example in the solution of the Dirichlet problem .  The characteristic operator    𝒜   𝒜   \mathcal{A}   of an Itō diffusion X is defined by        𝒜  f   (  x  )    =    lim   U  ↓  x        𝐄  x    [   f   (   X   τ  U    )    ]    -   f   (  x  )       𝐄  x    [   τ  U   ]       ,        𝒜  f  x     subscript    normal-↓  U  x           superscript  𝐄  x    delimited-[]    f   subscript  X   subscript  τ  U         f  x       superscript  𝐄  x    delimited-[]   subscript  τ  U         \mathcal{A}f(x)=\lim_{U\downarrow x}\frac{\mathbf{E}^{x}\left[f(X_{\tau_{U}})%
 \right]-f(x)}{\mathbf{E}^{x}[\tau_{U}]},     where the sets U form a sequence of open sets  U k that decrease to the point x in the sense that        U   k  +  1    ⊆    U  k   and    ⋂   k  =  1   ∞    U  k     =   {  x  }    ,         subscript  U    k  1       subscript  U  k   and    superscript   subscript     k  1       subscript  U  k           x      U_{k+1}\subseteq U_{k}\mbox{ and }\bigcap_{k=1}^{\infty}U_{k}=\{x\},     and       τ  U   =   inf   {   t  ≥   0    :    X  t   ∉  U   }         subscript  τ  U    infimum   conditional-set    t  0      subscript  X  t   U       \tau_{U}=\inf\{t\geq 0\ :\ X_{t}\not\in U\}     is the first exit time from U for X .    D  𝒜     subscript  D  𝒜    D_{\mathcal{A}}   denotes the set of all f for which this limit exists for all x ∈ R n and all sequences { U k }. If E x [τ U ] = +∞ for all open sets U containing x , define       𝒜  f   (  x  )    =  0.        𝒜  f  x   0.    \mathcal{A}f(x)=0.     Relationship with the generator  The characteristic operator and infinitesimal generator are very closely related, and even agree for a large class of functions. One can show that       D  A   ⊆   D  𝒜        subscript  D  A    subscript  D  𝒜     D_{A}\subseteq D_{\mathcal{A}}     and that        A  f   =   𝒜  f  for all  f   ∈   D  A    .          A  f     𝒜  f  for all  f         subscript  D  A      Af=\mathcal{A}f\mbox{ for all }f\in D_{A}.     In particular, the generator and characteristic operator agree for all C 2 functions f , in which case        𝒜  f   (  x  )    =     ∑  i     b  i    (  x  )     ∂  f    ∂   x  i      (  x  )     +     1  2      ∑   i  ,  j       (   σ   (  x  )   σ    (  x  )   ⊤    )    i  ,  j       ∂  2   f     ∂    x  i      ∂   x  j       (  x  )        .        𝒜  f  x       subscript   i      subscript  b  i   x      f      subscript  x  i     x        1  2     subscript    i  j       subscript    σ  x  σ   superscript  x  top     i  j        superscript   2   f        subscript  x  i       subscript  x  j      x        \mathcal{A}f(x)=\sum_{i}b_{i}(x)\frac{\partial f}{\partial x_{i}}(x)+\tfrac{1}%
 {2}\sum_{i,j}\left(\sigma(x)\sigma(x)^{\top}\right)_{i,j}\frac{\partial^{2}f}{%
 \partial x_{i}\,\partial x_{j}}(x).     Application: Brownian motion on a Riemannian manifold  (Figure)  The characteristic operator of a Brownian motion is ½ times the Laplace-Beltrami operator. Here it is the Laplace-Beltrami operator on a 2-sphere.   Above, the generator (and hence characteristic operator) of Brownian motion on R n was calculated to be ½Δ, where Δ denotes the Laplace operator. The characteristic operator is useful in defining Brownian motion on an m -dimensional Riemannian manifold ( M , g ): a Brownian motion on  M is defined to be a diffusion on M whose characteristic operator   𝒜   𝒜   \mathcal{A}   in local coordinates x i , 1 ≤ i ≤ m , is given by ½Δ LB , where Δ LB is the Laplace-Beltrami operator given in local coordinates by        Δ  LB   =    1    det   (  g  )        ∑   i  =  1   m     ∂   ∂   x  i      (     det   (  g  )       ∑   j  =  1   m     g   i  j     ∂   ∂   x  j        )       ,       subscript  normal-Δ  LB       1      g       superscript   subscript     i  1    m           subscript  x  i           g      superscript   subscript     j  1    m      superscript  g    i  j          subscript  x  j             \Delta_{\mathrm{LB}}=\frac{1}{\sqrt{\det(g)}}\sum_{i=1}^{m}\frac{\partial}{%
 \partial x_{i}}\left(\sqrt{\det(g)}\sum_{j=1}^{m}g^{ij}\frac{\partial}{%
 \partial x_{j}}\right),     where [ g ij ] = [ g ij ] −1 in the sense of the inverse of a square matrix .  The resolvent operator  In general, the generator A of an Itō diffusion X is not a bounded operator . However, if a positive multiple of the identity operator I is subtracted from A then the resulting operator is invertible. The inverse of this operator can be expressed in terms of X itself using the resolvent operator.  For α > 0, the resolvent operator  R α , acting on bounded, continuous functions g : R n → R , is defined by         R  α   g   (  x  )    =    𝐄  x    [    ∫  0  ∞     e   -   α  t     g   (   X  t   )   d  t    ]     .         subscript  R  α   g  x      superscript  𝐄  x    delimited-[]    superscript   subscript   0        superscript  e      α  t     g   subscript  X  t   normal-d  t        R_{\alpha}g(x)=\mathbf{E}^{x}\left[\int_{0}^{\infty}e^{-\alpha t}g(X_{t})\,%
 \mathrm{d}t\right].     It can be shown, using the Feller continuity of the diffusion X , that R α g is itself a bounded, continuous function. Also, R α and α I − A are mutually inverse operators:   if f : R n → R is C 2 with compact support, then, for all α > 0,            R  α    (    α  𝐈   -  A   )   f   =  f   ;         subscript  R  α       α  𝐈   A   f   f    R_{\alpha}(\alpha\mathbf{I}-A)f=f;         if g : R n → R is bounded and continuous, then R α g lies in D A and, for all α > 0,            (    α  𝐈   -  A   )    R  α   g   =  g   .            α  𝐈   A    subscript  R  α   g   g    (\alpha\mathbf{I}-A)R_{\alpha}g=g.        Invariant measures  Sometimes it is necessary to find an invariant measure for an Itō diffusion X , i.e. a measure on R n that does not change under the "flow" of X : i.e., if X 0 is distributed according to such an invariant measure μ ∞ , then X t is also distributed according to μ ∞ for any t ≥ 0. The Fokker–Planck equation offers a way to find such a measure, at least if it has a probability density function ρ ∞ : if X 0 is indeed distributed according to an invariant measure μ ∞ with density ρ ∞ , then the density ρ( t , ·) of X t does not change with t , so ρ( t , ·) = ρ ∞ , and so ρ ∞ must solve the (time-independent) partial differential equation          A  *    ρ  ∞    (  x  )    =  0   ,   x  ∈   𝐑  n     .     formulae-sequence       superscript  A     subscript  ρ    x   0     x   superscript  𝐑  n      A^{*}\rho_{\infty}(x)=0,\quad x\in\mathbf{R}^{n}.     This illustrates one of the connections between stochastic analysis and the study of partial differential equations. Conversely, a given second-order linear partial differential equation of the form Λ f = 0 may be hard to solve directly, but if Λ = A ∗ for some Itō diffusion X , and an invariant measure for X is easy to compute, then that measure's density provides a solution to the partial differential equation.  Invariant measures for gradient flows  An invariant measure is comparatively easy to compute when the process X is a stochastic gradient flow of the form        d   X  t    =    -    ∇  Ψ    (   X  t   )   d  t    +      2   β   -  1       d   B  t      ,        normal-d   subscript  X  t           normal-∇  normal-Ψ    subscript  X  t   normal-d  t          2   superscript  β    1      normal-d   subscript  B  t       \mathrm{d}X_{t}=-\nabla\Psi(X_{t})\,\mathrm{d}t+\sqrt{2\beta^{-1}}\,\mathrm{d}%
 B_{t},     where β > 0 plays the role of an inverse temperature and Ψ : R n → R is a scalar potential satisfying suitable smoothness and growth conditions. In this case, the Fokker–Planck equation has a unique stationary solution ρ ∞ (i.e. X has a unique invariant measure μ ∞ with density ρ ∞ ) and it is given by the Gibbs distribution :         ρ  ∞    (  x  )    =    Z   -  1     exp   (   -   β  Ψ   (  x  )     )      ,         subscript  ρ    x      superscript  Z    1          β  normal-Ψ  x        \rho_{\infty}(x)=Z^{-1}\exp(-\beta\Psi(x)),     where the partition function  Z is given by       Z  =    ∫   𝐑  n      exp   (   -   β  Ψ   (  x  )     )    d  x     .      Z    subscript    superscript  𝐑  n            β  normal-Ψ  x     normal-d  x      Z=\int_{\mathbf{R}^{n}}\exp(-\beta\Psi(x))\,\mathrm{d}x.     Moreover, the density ρ ∞ satisfies a variational principle : it minimizes over all probability densities ρ on R n the free energy functional F given by        F   [  ρ  ]    =    E   [  ρ  ]    +    1  β   S   [  ρ  ]      ,        F   delimited-[]  ρ        E   delimited-[]  ρ        1  β   S   delimited-[]  ρ       F[\rho]=E[\rho]+\frac{1}{\beta}S[\rho],     where       E   [  ρ  ]    =    ∫   𝐑  n     Ψ   (  x  )   ρ   (  x  )   d  x          E   delimited-[]  ρ      subscript    superscript  𝐑  n      normal-Ψ  x  ρ  x  normal-d  x      E[\rho]=\int_{\mathbf{R}^{n}}\Psi(x)\rho(x)\,\mathrm{d}x     plays the role of an energy functional, and       S   [  ρ  ]    =    ∫   𝐑  n     ρ   (  x  )    log  ρ    (  x  )   d  x          S   delimited-[]  ρ      subscript    superscript  𝐑  n      ρ  x    ρ   x  normal-d  x      S[\rho]=\int_{\mathbf{R}^{n}}\rho(x)\log\rho(x)\,\mathrm{d}x     is the negative of the Gibbs-Boltzmann entropy functional. Even when the potential Ψ is not well-behaved enough for the partition function Z and the Gibbs measure μ ∞ to be defined, the free energy F [ρ( t , ·)] still makes sense for each time t ≥ 0, provided that the initial condition has F [ρ(0, ·)] n satisfying the stochastic differential equation        d   X  t    =    -   κ   (    X  t   -  m   )   d  t    +      2   β   -  1       d   B  t      ,        normal-d   subscript  X  t          κ     subscript  X  t   m   normal-d  t          2   superscript  β    1      normal-d   subscript  B  t       \mathrm{d}X_{t}=-\kappa(X_{t}-m)\,\mathrm{d}t+\sqrt{2\beta^{-1}}\,\mathrm{d}B_%
 {t},     where m ∈ R n and β, κ > 0 are given constants. In this case, the potential Ψ is given by        Ψ   (  x  )    =     1  2    κ    |   x  -  m   |   2     ,        normal-Ψ  x       1  2   κ   superscript      x  m    2      \Psi(x)=\tfrac{1}{2}\kappa|x-m|^{2},     and so the invariant measure for X is a Gaussian measure with density ρ ∞ given by        ρ  ∞    (  x  )    =     (    β  κ    2  π    )    n  2     exp   (   -    β  κ    |   x  -  m   |   2    2    )            subscript  ρ    x      superscript      β  κ     2  π      n  2            β  κ   superscript      x  m    2    2        \rho_{\infty}(x)=\left(\frac{\beta\kappa}{2\pi}\right)^{\frac{n}{2}}\exp\left(%
 -\frac{\beta\kappa|x-m|^{2}}{2}\right)   .  Heuristically, for large t , X t is approximately normally distributed with mean m and variance (βκ) −1 . The expression for the variance may be interpreted as follows: large values of κ mean that the potential well Ψ has "very steep sides", so X t is unlikely to move far from the minimum of Ψ at m ; similarly, large values of β mean that the system is quite "cold" with little noise, so, again, X t is unlikely to move far away from m .  The martingale property  In general, an Itō diffusion X is not a martingale . However, for any f ∈ C 2 ( R n ; R ) with compact support, the process M : [0, +∞) × Ω → R defined by        M  t   =    f   (   X  t   )    -    ∫  0  t    A  f   (   X  s   )   d  s      ,       subscript  M  t       f   subscript  X  t      superscript   subscript   0   t     A  f   subscript  X  s   normal-d  s       M_{t}=f(X_{t})-\int_{0}^{t}Af(X_{s})\,\mathrm{d}s,     where A is the generator of X , is a martingale with respect to the natural filtration F ∗ of (Ω, Σ) by X . The proof is quite simple: it follows from the usual expression of the action of the generator on smooth enough functions f and Itō's lemma (the stochastic chain rule ) that        f   (   X  t   )    =    f   (  x  )    +    ∫  0  t    A  f   (   X  s   )   d  s    +    ∫  0  t     ∇  f     (   X  s   )   ⊤   σ   (   X  s   )   d   B  s       .        f   subscript  X  t        f  x     superscript   subscript   0   t     A  f   subscript  X  s   normal-d  s      superscript   subscript   0   t      normal-∇  f    superscript   subscript  X  s   top   σ   subscript  X  s   normal-d   subscript  B  s        f(X_{t})=f(x)+\int_{0}^{t}Af(X_{s})\,\mathrm{d}s+\int_{0}^{t}\nabla f(X_{s})^{%
 \top}\sigma(X_{s})\,\mathrm{d}B_{s}.     Since Itō integrals are martingales with respect to the natural filtration Σ ∗ of (Ω, Σ) by B , for t > s ,       𝐄  x    [   M  t   |   Σ  s   ]   =   M  s   .     fragments   superscript  𝐄  x    fragments  normal-[   subscript  M  t   normal-|   subscript  normal-Σ  s   normal-]     subscript  M  s   normal-.    \mathbf{E}^{x}\big[M_{t}\big|\Sigma_{s}\big]=M_{s}.     Hence, as required,       𝐄  x    [   M  t   |   F  s   ]   =   𝐄  x    [   𝐄  x    [   M  t   |   Σ  s   ]   |   F  s   ]   =   𝐄  x    [   M  s   |   F  s   ]   =   M  s   ,     fragments   superscript  𝐄  x    fragments  normal-[   subscript  M  t   normal-|   subscript  F  s   normal-]     superscript  𝐄  x    fragments  normal-[   superscript  𝐄  x    fragments  normal-[   subscript  M  t   normal-|   subscript  normal-Σ  s   normal-]   normal-|   subscript  F  s   normal-]     superscript  𝐄  x    fragments  normal-[   subscript  M  s   normal-|   subscript  F  s   normal-]     subscript  M  s   normal-,    \mathbf{E}^{x}[M_{t}|F_{s}]=\mathbf{E}^{x}\left[\mathbf{E}^{x}\big[M_{t}\big|%
 \Sigma_{s}\big]\big|F_{s}\right]=\mathbf{E}^{x}\big[M_{s}\big|F_{s}\big]=M_{s},     since M s is F s -measurable.  Dynkin's formula  Dynkin's formula, named after Eugene Dynkin , gives the expected value of any suitably smooth statistic of an Itō diffusion X (with generator A ) at a stopping time. Precisely, if τ is a stopping time with E x [τ] n → R is C 2 with compact support, then         𝐄  x    [   f   (   X  τ   )    ]    =    f   (  x  )    +    𝐄  x    [    ∫  0  τ    A  f   (   X  s   )   d  s    ]      .         superscript  𝐄  x    delimited-[]    f   subscript  X  τ          f  x      superscript  𝐄  x    delimited-[]    superscript   subscript   0   τ     A  f   subscript  X  s   normal-d  s         \mathbf{E}^{x}[f(X_{\tau})]=f(x)+\mathbf{E}^{x}\left[\int_{0}^{\tau}Af(X_{s})%
 \,\mathrm{d}s\right].     Dynkin's formula can be used to calculate many useful statistics of stopping times. For example, canonical Brownian motion on the real line starting at 0 exits the interval (− R , + R ) at a random time τ R with expected value         𝐄  0    [   τ  R   ]    =   R  2    .         superscript  𝐄  0    delimited-[]   subscript  τ  R      superscript  R  2     \mathbf{E}^{0}[\tau_{R}]=R^{2}.     Dynkin's formula provides information about the behaviour of X at a fairly general stopping time. For more information on the distribution of X at a hitting time , one can study the harmonic measure of the process.  Associated measures  The harmonic measure  In many situations, it is sufficient to know when an Itō diffusion X will first leave a measurable set  H ⊆ R n . That is, one wishes to study the first exit time         τ  H    (  ω  )    =   inf   {   t  ≥  0   |    X  t   ∉  H   }     .         subscript  τ  H   ω    infimum   conditional-set    t  0      subscript  X  t   H       \tau_{H}(\omega)=\inf\{t\geq 0|X_{t}\not\in H\}.     Sometimes, however, one also wishes to know the distribution of the points at which X exits the set. For example, canonical Brownian motion B on the real line starting at 0 exits the interval (−1, 1) at −1 with probability ½ and at 1 with probability ½, so B τ (−1, 1) is uniformly distributed on the set {−1, 1}.  In general, if G is compactly embedded within R n , then the harmonic measure (or hitting distribution ) of X on the boundary ∂ G of G is the measure μ G x defined by       μ  G  x    (  F  )   =   𝐏  x    [   X   τ  G    ∈  F  ]      fragments   superscript   subscript  μ  G   x    fragments  normal-(  F  normal-)     superscript  𝐏  x    fragments  normal-[   subscript  X   subscript  τ  G     F  normal-]     \mu_{G}^{x}(F)=\mathbf{P}^{x}\left[X_{\tau_{G}}\in F\right]     for x ∈ G and F ⊆ ∂ G .  Returning to the earlier example of Brownian motion, one can show that if B is a Brownian motion in R n starting at x ∈ R n and D ⊂ R n is an open ball centred on x , then the harmonic measure of B on ∂ D is invariant under all rotations of D about x and coincides with the normalized surface measure on ∂ D .  The harmonic measure satisfies an interesting mean value property : if f : R n → R is any bounded, Borel-measurable function and φ is given by        φ   (  x  )    =    𝐄  x    [   f   (   X   τ  H    )    ]     ,        φ  x      superscript  𝐄  x    delimited-[]    f   subscript  X   subscript  τ  H         \varphi(x)=\mathbf{E}^{x}\left[f(X_{\tau_{H}})\right],     then, for all Borel sets G ⊂⊂ H and all x ∈ G ,        φ   (  x  )    =    ∫   ∂  G     φ   (  y  )   d   μ  G  x    (  y  )      .        φ  x     subscript     G      φ  y  normal-d   superscript   subscript  μ  G   x   y      \varphi(x)=\int_{\partial G}\varphi(y)\,\mathrm{d}\mu_{G}^{x}(y).     The mean value property is very useful in the solution of partial differential equations using stochastic processes .  The Green measure and Green formula  Let A be a partial differential operator on a domain D ⊆ R n and let X be an Itō diffusion with A as its generator. Intuitively, the Green measure of a Borel set H is the expected length of time that X stays in H before it leaves the domain D . That is, the Green measure of X with respect to D at x , denoted G ( x , ·), is defined for Borel sets H ⊆ R n by        G   (  x  ,  H  )    =    𝐄  x    [    ∫  0   τ  D      χ  H    (   X  s   )   d  s    ]     ,        G   x  H       superscript  𝐄  x    delimited-[]    superscript   subscript   0    subscript  τ  D       subscript  χ  H    subscript  X  s   normal-d  s        G(x,H)=\mathbf{E}^{x}\left[\int_{0}^{\tau_{D}}\chi_{H}(X_{s})\,\mathrm{d}s%
 \right],     or for bounded, continuous functions f : D → R by         ∫  D    f   (  y  )   G   (  x  ,   d  y   )     =    𝐄  x    [    ∫  0   τ  D     f   (   X  s   )   d  s    ]     .        subscript   D     f  y  G   x    normal-d  y         superscript  𝐄  x    delimited-[]    superscript   subscript   0    subscript  τ  D      f   subscript  X  s   normal-d  s        \int_{D}f(y)\,G(x,\mathrm{d}y)=\mathbf{E}^{x}\left[\int_{0}^{\tau_{D}}f(X_{s})%
 \,\mathrm{d}s\right].     The name "Green measure" comes from the fact that if X is Brownian motion, then        G   (  x  ,  H  )    =    ∫  H    G   (  x  ,  y  )   d  y     ,        G   x  H      subscript   H     G   x  y   normal-d  y      G(x,H)=\int_{H}G(x,y)\,\mathrm{d}y,     where G ( x , y ) is Green's function for the operator ½Δ on the domain D .  Suppose that E x [τ D ] 2( R n ; R ) with compact support:        f   (  x  )    =     𝐄  x    [   f   (   X   τ  D    )    ]    -    ∫  D    A  f   (  y  )   G   (  x  ,   d  y   )       .        f  x        superscript  𝐄  x    delimited-[]    f   subscript  X   subscript  τ  D         subscript   D     A  f  y  G   x    normal-d  y         f(x)=\mathbf{E}^{x}\left[f\left(X_{\tau_{D}}\right)\right]-\int_{D}Af(y)\,G(x,%
 \mathrm{d}y).     In particular, if the support of f is compactly embedded in D ,        f   (  x  )    =   -    ∫  D    A  f   (  y  )   G   (  x  ,   d  y   )       .        f  x       subscript   D     A  f  y  G   x    normal-d  y         f(x)=-\int_{D}Af(y)\,G(x,\mathrm{d}y).     See also   Diffusion process   References        (See Sections 7, 8 and 9)   "  Category:Stochastic differential equations   