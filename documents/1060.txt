   Eigenvalue perturbation      Eigenvalue perturbation   In mathematics, an eigenvalue perturbation problem is that of finding the eigenvectors and eigenvalues of a system that is perturbed from one with known eigenvectors and eigenvalues. This is useful for studying how sensitive the original system's eigenvectors and eigenvalues are to changes in the system. This type of analysis popularized by Lord Rayleigh , in his investigation of harmonic vibrations of a string perturbed by small inhomogeneities. 1  The derivations in this article are essentially self-contained and can be found in many texts on numerical linear algebra 2 or numerical functional analysis.  Example  Suppose we have solutions to the generalized eigenvalue problem ,       ğŠ  0    ğ±   0  i    =   Î»   0  i     ğŒ  0    ğ±   0  i    .   (  0  )      fragments   subscript  ğŠ  0    subscript  ğ±    0  i      subscript  Î»    0  i     subscript  ğŒ  0    subscript  ğ±    0  i    normal-.  italic-   fragments  normal-(  0  normal-)     \mathbf{K}_{0}\mathbf{x}_{0i}=\lambda_{0i}\mathbf{M}_{0}\mathbf{x}_{0i}.\qquad%
 (0)     where    ğŠ  0     subscript  ğŠ  0    \mathbf{K}_{0}   and    ğŒ  0     subscript  ğŒ  0    \mathbf{M}_{0}   are matrices. That is, we know the eigenvalues and eigenvectors for    i  =   1  ,  â€¦  ,  N       i   1  normal-â€¦  N     i=1,...,N   . Now suppose we want to change the matrices by a small amount. That is, we want to find the eigenvalues and eigenvectors of       ğŠğ±  i   =     Î»  i    ğŒğ±  i     (  1  )         subscript  ğŠğ±  i       subscript  Î»  i    subscript  ğŒğ±  i    1     \mathbf{K}\mathbf{x}_{i}=\lambda_{i}\mathbf{M}\mathbf{x}_{i}\qquad(1)   where     ğŠ   ğŠ   \displaystyle\mathbf{K}     with the perturbations    Î´  ğŠ      Î´  ğŠ    \delta\mathbf{K}   and    Î´  ğŒ      Î´  ğŒ    \delta\mathbf{M}   much smaller than   ğŠ   ğŠ   \mathbf{K}   and   ğŒ   ğŒ   \mathbf{M}   respectively. Then we expect the new eigenvalues and eigenvectors to be similar to the original, plus small perturbations:      Î»  i     subscript  Î»  i    \displaystyle\lambda_{i}     Steps  We assume that the matrices are symmetric and positive definite , and assume we have scaled the eigenvectors such that        ğ±   0  j   âŠ¤    ğŒ  0    ğ±   0  i     =    Î´   i  j     (  2  )           superscript   subscript  ğ±    0  j    top    subscript  ğŒ  0    subscript  ğ±    0  i       subscript  Î´    i  j    2     \mathbf{x}_{0j}^{\top}\mathbf{M}_{0}\mathbf{x}_{0i}=\delta_{ij}\qquad(2)     where is the Kronecker delta . Now we want to solve the equation        ğŠğ±  i   =    Î»  i    ğŒğ±  i     .       subscript  ğŠğ±  i      subscript  Î»  i    subscript  ğŒğ±  i      \mathbf{K}\mathbf{x}_{i}=\lambda_{i}\mathbf{M}\mathbf{x}_{i}.     Substituting, we get         (    ğŠ  0   +   Î´  ğŠ    )    (    ğ±   0  i    +   Î´   ğ±  i     )    =    (    Î»   0  i    +   Î´   Î»  i     )    (    ğŒ  0   +   Î´  ğŒ    )    (    ğ±   0  i    +   Î´   ğ±  i     )     ,           subscript  ğŠ  0     Î´  ğŠ       subscript  ğ±    0  i      Î´   subscript  ğ±  i           subscript  Î»    0  i      Î´   subscript  Î»  i        subscript  ğŒ  0     Î´  ğŒ       subscript  ğ±    0  i      Î´   subscript  ğ±  i        (\mathbf{K}_{0}+\delta\mathbf{K})(\mathbf{x}_{0i}+\delta\mathbf{x}_{i})=\left(%
 \lambda_{0i}+\delta\lambda_{i}\right)\left(\mathbf{M}_{0}+\delta\mathbf{M}%
 \right)\left(\mathbf{x}_{0i}+\delta\mathbf{x}_{i}\right),     which expands to       ğŠ  0    ğ±   0  i         subscript  ğŠ  0    subscript  ğ±    0  i      \displaystyle\mathbf{K}_{0}\mathbf{x}_{0i}     Canceling from (1) leaves         Î´   ğŠğ±   0  i     +    ğŠ  0   Î´   ğ±  i    +   Î´  ğŠ  Î´   ğ±  i     =     Î»   0  i     ğŒ  0   Î´   ğ±  i    +    Î»   0  i    Î´   ğŒğ±   0  i     +   Î´   Î»  i    ğŒ  0    ğ±   0  i     +    Î»   0  i    Î´  ğŒ  Î´   ğ±  i    +   Î´   Î»  i   Î´   ğŒğ±   0  i     +   Î´   Î»  i    ğŒ  0   Î´   ğ±  i    +   Î´   Î»  i   Î´  ğŒ  Î´   ğ±  i      .          Î´   subscript  ğŠğ±    0  i        subscript  ğŠ  0   Î´   subscript  ğ±  i      Î´  ğŠ  Î´   subscript  ğ±  i          subscript  Î»    0  i     subscript  ğŒ  0   Î´   subscript  ğ±  i       subscript  Î»    0  i    Î´   subscript  ğŒğ±    0  i       Î´   subscript  Î»  i    subscript  ğŒ  0    subscript  ğ±    0  i        subscript  Î»    0  i    Î´  ğŒ  Î´   subscript  ğ±  i      Î´   subscript  Î»  i   Î´   subscript  ğŒğ±    0  i       Î´   subscript  Î»  i    subscript  ğŒ  0   Î´   subscript  ğ±  i      Î´   subscript  Î»  i   Î´  ğŒ  Î´   subscript  ğ±  i       \displaystyle\delta\mathbf{K}\mathbf{x}_{0i}+\mathbf{K}_{0}\delta\mathbf{x}_{i%
 }+\delta\mathbf{K}\delta\mathbf{x}_{i}=\lambda_{0i}\mathbf{M}_{0}\delta\mathbf%
 {x}_{i}+\lambda_{0i}\delta\mathbf{M}\mathbf{x}_{0i}+\delta\lambda_{i}\mathbf{M%
 }_{0}\mathbf{x}_{0i}+\lambda_{0i}\delta\mathbf{M}\delta\mathbf{x}_{i}+\delta%
 \lambda_{i}\delta\mathbf{M}\mathbf{x}_{0i}+\delta\lambda_{i}\mathbf{M}_{0}%
 \delta\mathbf{x}_{i}+\delta\lambda_{i}\delta\mathbf{M}\delta\mathbf{x}_{i}.     Removing the higher-order terms, this simplifies to       ğŠ  0   Î´   ğ±  i   +  Î´   ğŠğ±   0  i    =   Î»   0  i     ğŒ  0   Î´   ğ±  i   +   Î»   0  i    Î´  ğŒ   x   0  i    +  Î´   Î»  i    ğŒ  0    ğ±   0  i    .   (  3  )      fragments   subscript  ğŠ  0   Î´   subscript  ğ±  i    Î´   subscript  ğŠğ±    0  i      subscript  Î»    0  i     subscript  ğŒ  0   Î´   subscript  ğ±  i     subscript  Î»    0  i    Î´  M   subscript  normal-x    0  i     Î´   subscript  Î»  i    subscript  ğŒ  0    subscript  ğ±    0  i    normal-.  italic-   fragments  normal-(  3  normal-)     \mathbf{K}_{0}\delta\mathbf{x}_{i}+\delta\mathbf{K}\mathbf{x}_{0i}=\lambda_{0i%
 }\mathbf{M}_{0}\delta\mathbf{x}_{i}+\lambda_{0i}\delta\mathbf{M}\mathrm{x}_{0i%
 }+\delta\lambda_{i}\mathbf{M}_{0}\mathbf{x}_{0i}.\qquad(3)     When the matrix is symmetric, the unperturbed eigenvectors are orthogonal and so we use them as a basis for the perturbed eigenvectors. That is, we want to construct       Î´   ğ±  i    =     âˆ‘   j  =  1   N     Îµ   i  j     ğ±   0  j       (  4  )          Î´   subscript  ğ±  i       superscript   subscript     j  1    N      subscript  Îµ    i  j     subscript  ğ±    0  j      4     \delta\mathbf{x}_{i}=\sum_{j=1}^{N}\varepsilon_{ij}\mathbf{x}_{0j}\qquad(4)     where the are small constants that are to be determined. Substituting (4) into (3) and rearranging gives        ğŠ  0      âˆ‘   j  =  1   N      Îµ   i  j     ğ±   0  j       +   Î´   ğŠğ±   0  i            subscript  ğŠ  0     superscript   subscript     j  1    N      subscript  Îµ    i  j     subscript  ğ±    0  j         Î´   subscript  ğŠğ±    0  i       \displaystyle\mathbf{K}_{0}\sum_{j=1}^{N}\varepsilon_{ij}\mathbf{x}_{0j}+%
 \delta\mathbf{K}\mathbf{x}_{0i}     Because the eigenvectors are -orthogonal when is positive definite, we can remove the summations by left multiplying by    ğ±   0  i   âŠ¤     superscript   subscript  ğ±    0  i    top    \mathbf{x}_{0i}^{\top}   :          ğ±   0  i   âŠ¤    Îµ   i  i     Î»   0  i     ğŒ  0    ğ±   0  i     +    ğ±   0  i   âŠ¤   Î´   ğŠğ±   0  i      =     Î»   0  i     ğ±   0  i   âŠ¤    ğŒ  0    Îµ   i  i     ğ±   0  i     +    Î»   0  i     ğ±   0  i   âŠ¤   Î´   ğŒğ±   0  i     +   Î´   Î»  i    ğ±   0  i   âŠ¤    ğŒ  0    ğ±   0  i       .           superscript   subscript  ğ±    0  i    top    subscript  Îµ    i  i     subscript  Î»    0  i     subscript  ğŒ  0    subscript  ğ±    0  i        superscript   subscript  ğ±    0  i    top   Î´   subscript  ğŠğ±    0  i           subscript  Î»    0  i     superscript   subscript  ğ±    0  i    top    subscript  ğŒ  0    subscript  Îµ    i  i     subscript  ğ±    0  i        subscript  Î»    0  i     superscript   subscript  ğ±    0  i    top   Î´   subscript  ğŒğ±    0  i       Î´   subscript  Î»  i    superscript   subscript  ğ±    0  i    top    subscript  ğŒ  0    subscript  ğ±    0  i        \mathbf{x}_{0i}^{\top}\varepsilon_{ii}\lambda_{0i}\mathbf{M}_{0}\mathbf{x}_{0i%
 }+\mathbf{x}_{0i}^{\top}\delta\mathbf{K}\mathbf{x}_{0i}=\lambda_{0i}\mathbf{x}%
 _{0i}^{\top}\mathbf{M}_{0}\varepsilon_{ii}\mathbf{x}_{0i}+\lambda_{0i}\mathbf{%
 x}_{0i}^{\top}\delta\mathbf{M}\mathbf{x}_{0i}+\delta\lambda_{i}\mathbf{x}_{0i}%
 ^{\top}\mathbf{M}_{0}\mathbf{x}_{0i}.     By use of equation (1) again:       ğ±   0  i   âŠ¤    ğŠ  0    Îµ   i  i     ğ±   0  i    +   ğ±   0  i   âŠ¤   Î´   ğŠğ±   0  i    =   Î»   0  i     ğ±   0  i   âŠ¤    ğŒ  0    Îµ   i  i     ğ±   0  i    +   Î»   0  i     ğ±   0  i   âŠ¤   Î´   ğŒğ±   0  i    +  Î´   Î»  i    ğ±   0  i   âŠ¤    ğŒ  0    ğ±   0  i    .   (  6  )      fragments   superscript   subscript  ğ±    0  i    top    subscript  ğŠ  0    subscript  Îµ    i  i     subscript  ğ±    0  i      superscript   subscript  ğ±    0  i    top   Î´   subscript  ğŠğ±    0  i      subscript  Î»    0  i     superscript   subscript  ğ±    0  i    top    subscript  ğŒ  0    subscript  Îµ    i  i     subscript  ğ±    0  i      subscript  Î»    0  i     superscript   subscript  ğ±    0  i    top   Î´   subscript  ğŒğ±    0  i     Î´   subscript  Î»  i    superscript   subscript  ğ±    0  i    top    subscript  ğŒ  0    subscript  ğ±    0  i    normal-.  italic-   fragments  normal-(  6  normal-)     \mathbf{x}_{0i}^{\top}\mathbf{K}_{0}\varepsilon_{ii}\mathbf{x}_{0i}+\mathbf{x}%
 _{0i}^{\top}\delta\mathbf{K}\mathbf{x}_{0i}=\lambda_{0i}\mathbf{x}_{0i}^{\top}%
 \mathbf{M}_{0}\varepsilon_{ii}\mathbf{x}_{0i}+\lambda_{0i}\mathbf{x}_{0i}^{%
 \top}\delta\mathbf{M}\mathbf{x}_{0i}+\delta\lambda_{i}\mathbf{x}_{0i}^{\top}%
 \mathbf{M}_{0}\mathbf{x}_{0i}.\qquad(6)     The two terms containing are equal because left-multiplying (1) by    ğ±   0  i   âŠ¤     superscript   subscript  ğ±    0  i    top    \mathbf{x}_{0i}^{\top}   gives         ğ±   0  i   âŠ¤    ğŠ  0    ğ±   0  i     =    Î»   0  i     ğ±   0  i   âŠ¤    ğŒ  0    ğ±   0  i      .         superscript   subscript  ğ±    0  i    top    subscript  ğŠ  0    subscript  ğ±    0  i        subscript  Î»    0  i     superscript   subscript  ğ±    0  i    top    subscript  ğŒ  0    subscript  ğ±    0  i       \mathbf{x}_{0i}^{\top}\mathbf{K}_{0}\mathbf{x}_{0i}=\lambda_{0i}\mathbf{x}_{0i%
 }^{\top}\mathbf{M}_{0}\mathbf{x}_{0i}.     Canceling those terms in (6) leaves         ğ±   0  i   âŠ¤   Î´   ğŠğ±   0  i     =     Î»   0  i     ğ±   0  i   âŠ¤   Î´   ğŒğ±   0  i     +   Î´   Î»  i    ğ±   0  i   âŠ¤    ğŒ  0    ğ±   0  i       .         superscript   subscript  ğ±    0  i    top   Î´   subscript  ğŠğ±    0  i          subscript  Î»    0  i     superscript   subscript  ğ±    0  i    top   Î´   subscript  ğŒğ±    0  i       Î´   subscript  Î»  i    superscript   subscript  ğ±    0  i    top    subscript  ğŒ  0    subscript  ğ±    0  i        \mathbf{x}_{0i}^{\top}\delta\mathbf{K}\mathbf{x}_{0i}=\lambda_{0i}\mathbf{x}_{%
 0i}^{\top}\delta\mathbf{M}\mathbf{x}_{0i}+\delta\lambda_{i}\mathbf{x}_{0i}^{%
 \top}\mathbf{M}_{0}\mathbf{x}_{0i}.     Rearranging gives       Î´   Î»  i    =     ğ±   0  i   âŠ¤    (    Î´  ğŠ   -    Î»   0  i    Î´  ğŒ    )    ğ±   0  i       ğ±   0  i   âŠ¤    ğŒ  0    ğ±   0  i            Î´   subscript  Î»  i         subscript   superscript  ğ±  top     0  i        Î´  ğŠ      subscript  Î»    0  i    Î´  ğŒ     subscript  ğ±    0  i        superscript   subscript  ğ±    0  i    top    subscript  ğŒ  0    subscript  ğ±    0  i        \delta\lambda_{i}=\frac{\mathbf{x}^{\top}_{0i}\left(\delta\mathbf{K}-\lambda_{%
 0i}\delta\mathbf{M}\right)\mathbf{x}_{0i}}{\mathbf{x}_{0i}^{\top}\mathbf{M}_{0%
 }\mathbf{x}_{0i}}     But by (2), this denominator is equal to 1. Thus        Î´   Î»  i    =    ğ±   0  i   âŠ¤    (    Î´  ğŠ   -    Î»   0  i    Î´  ğŒ    )    ğ±   0  i      .        Î´   subscript  Î»  i       subscript   superscript  ğ±  top     0  i        Î´  ğŠ      subscript  Î»    0  i    Î´  ğŒ     subscript  ğ±    0  i       \delta\lambda_{i}=\mathbf{x}^{\top}_{0i}\left(\delta\mathbf{K}-\lambda_{0i}%
 \delta\mathbf{M}\right)\mathbf{x}_{0i}.     Then, by left-multiplying equation (5) by :         Îµ   i  k    =     ğ±   0  k   âŠ¤    (    Î´  ğŠ   -    Î»   0  i    Î´  ğŒ    )    ğ±   0  i       Î»   0  i    -   Î»   0  k       ,   i  â‰   k    .     formulae-sequence     subscript  Îµ    i  k         subscript   superscript  ğ±  top     0  k        Î´  ğŠ      subscript  Î»    0  i    Î´  ğŒ     subscript  ğ±    0  i        subscript  Î»    0  i     subscript  Î»    0  k         i  k     \varepsilon_{ik}=\frac{\mathbf{x}^{\top}_{0k}\left(\delta\mathbf{K}-\lambda_{0%
 i}\delta\mathbf{M}\right)\mathbf{x}_{0i}}{\lambda_{0i}-\lambda_{0k}},\qquad i%
 \neq k.     Or by changing the name of the indices:         Îµ   i  j    =     ğ±   0  j   âŠ¤    (    Î´  ğŠ   -    Î»   0  i    Î´  ğŒ    )    ğ±   0  i       Î»   0  i    -   Î»   0  j       ,   i  â‰   j    .     formulae-sequence     subscript  Îµ    i  j         subscript   superscript  ğ±  top     0  j        Î´  ğŠ      subscript  Î»    0  i    Î´  ğŒ     subscript  ğ±    0  i        subscript  Î»    0  i     subscript  Î»    0  j         i  j     \varepsilon_{ij}=\frac{\mathbf{x}^{\top}_{0j}\left(\delta\mathbf{K}-\lambda_{0%
 i}\delta\mathbf{M}\right)\mathbf{x}_{0i}}{\lambda_{0i}-\lambda_{0j}},\qquad i%
 \neq j.     To find , use the fact that:        ğ±  i  âŠ¤    ğŒğ±  i    =  1         subscript   superscript  ğ±  top   i    subscript  ğŒğ±  i    1    \mathbf{x}^{\top}_{i}\mathbf{M}\mathbf{x}_{i}=1     implies:        Îµ   i  i    =   -     1  2     ğ±   0  i   âŠ¤   Î´   ğŒğ±   0  i       .       subscript  Îµ    i  i          1  2    subscript   superscript  ğ±  top     0  i    Î´   subscript  ğŒğ±    0  i        \varepsilon_{ii}=-\tfrac{1}{2}\mathbf{x}^{\top}_{0i}\delta\mathbf{M}\mathbf{x}%
 _{0i}.     Summary      Î»  i     subscript  Î»  i    \displaystyle\lambda_{i}     for infinitesimal    Î´  K      Î´  K    Î´K   and    Î´  M      Î´  M    Î´M   (the high order terms in (3) being negligible)  Results  This means it is possible to efficiently do a sensitivity analysis on as a function of changes in the entries of the matrices. (Recall that the matrices are symmetric and so changing will also change , hence the term.)        âˆ‚   Î»  i     âˆ‚   ğŠ   (   k  â„“   )             subscript  Î»  i       subscript  ğŠ    k  normal-â„“       \displaystyle\frac{\partial\lambda_{i}}{\partial\mathbf{K}_{(k\ell)}}     Similarly        âˆ‚   ğ±  i     âˆ‚   ğŠ   (   k  â„“   )             subscript  ğ±  i       subscript  ğŠ    k  normal-â„“       \displaystyle\frac{\partial\mathbf{x}_{i}}{\partial\mathbf{K}_{(k\ell)}}     Existence of eigenvectors  Note that in the above example we assumed that both the unperturbed and the perturbed systems involved symmetric matrices , which guaranteed the existence of   N   N   N   linearly independent eigenvectors. An eigenvalue problem involving non-symmetric matrices is not guaranteed to have   N   N   N   linearly independent eigenvectors, though a sufficient condition is that   ğŠ   ğŠ   \mathbf{K}   and   ğŒ   ğŒ   \mathbf{M}   be simultaneously diagonalisable .  See also   Perturbation theory (quantum mechanics)  Bauerâ€“Fike theorem   References       Further reading     "  Category:Perturbation theory  Category:Linear algebra  Category:Numerical linear algebra     â†©  â†©     