   Adaptive estimator      Adaptive estimator   In statistics , an adaptive estimator is an estimator in a parametric or semiparametric model with nuisance parameters such that the presence of these nuisance parameters does not affect efficiency of estimation.  Definition  Formally, let parameter θ in a parametric model consists of two parts: the parameter of interest , and the nuisance parameter . Thus . Then we will say that     ν  ^   n     subscript   normal-^  ν   n    \scriptstyle\hat{\nu}_{n}   is an adaptive estimator of ν in the presence of η if this estimator is regular , and efficient for each of the submodels 1         𝒫  ν    (   η  0   )    =   {   P  θ   :    ν  ∈  N   ,   η  =   η  0     }    .         subscript  𝒫  ν    subscript  η  0     conditional-set   subscript  P  θ    formulae-sequence    ν  N     η   subscript  η  0        \mathcal{P}_{\nu}(\eta_{0})=\big\{P_{\theta}:\nu\in N,\,\eta=\eta_{0}\big\}.   Adaptive estimator estimates the parameter of interest equally well regardless whether the value of the nuisance parameter is known or not.  The necessary condition for a regular parametric model to have an adaptive estimator is that          I   ν  η     (  θ  )    =   E   [    z  ν     z  η  ′     ]    =  0    for all  θ    ,     formulae-sequence         subscript  I    ν  η    θ    normal-E     subscript  z  ν    superscript   subscript  z  η   normal-′          0      for all  θ     I_{\nu\eta}(\theta)=\operatorname{E}[\,z_{\nu}z_{\eta}^{\prime}\,]=0\quad\text%
 {for all }\theta,   where z ν and z η are components of the score function corresponding to parameters ν and η respectively, and thus I νη is the top-right k×m block of the Fisher information matrix  I ( θ ).  Example  Suppose   𝒫   𝒫   \scriptstyle\mathcal{P}   is the normal  location-scale family :       𝒫  =   {     f  θ    (  x  )    =     1     2  π    σ       e   -    1   2   σ  2       (   x  -  μ   )   2         |    μ  ∈  ℝ   ,   σ  >   0     }    .      𝒫   conditional-set       subscript  f  θ   x       1        2  π    σ     superscript  e        1    2   superscript  σ  2      superscript    x  μ   2         formulae-sequence    μ  ℝ     σ  0       \mathcal{P}=\Big\{\ f_{\theta}(x)=\tfrac{1}{\sqrt{2\pi}\sigma}e^{-\frac{1}{2%
 \sigma^{2}}(x-\mu)^{2}}\ \Big|\ \mu\in\mathbb{R},\sigma>0\ \Big\}.   Then the usual estimator      μ  ^    =   x  ¯        normal-^  μ    normal-¯  x     \hat{\mu}\,=\,\bar{x}   is adaptive: we can estimate the mean equally well whether we know the variance or not.  Notes  Basic references     Other useful references   [ http://ieeexplore.ieee.org/xpl/freeabs_all.jsp?isnumber=5200771&arnumber; ;=4838921&count;=38&index;=2 I. V. Blagouchine and E. Moreau: "Unbiased Adaptive Estimations of the Fourth-Order Cumulant for Real Random Zero-Mean Signal", IEEE Transactions on Signal Processing , vol. 57, no. 9, pp. 3330–3346, September 2009.]   "  Category:Estimation theory     ↩     