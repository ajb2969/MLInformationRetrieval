   Row space      Row space   In linear algebra , the row space of a matrix is the set of all possible linear combinations of its row vectors . Let K be a field (such as real or complex numbers). The row space of an m × n matrix with components from K is a linear subspace of the n -space  K n . The dimension of the row space is called the row rank of the matrix. 1  A definition for matrices over a ring  K (such as integers ) is also possible. 2  Definition  Let K be a field of scalars . Let A be an m × n matrix, with row vectors r 1 , r 2 , ... , r m . A linear combination of these vectors is any vector of the form         c  1    𝐫  1    +    c  2    𝐫  2    +  ⋯  +    c  m    𝐫  m     ,         subscript  c  1    subscript  𝐫  1       subscript  c  2    subscript  𝐫  2    normal-⋯     subscript  c  m    subscript  𝐫  m      c_{1}\mathbf{r}_{1}+c_{2}\mathbf{r}_{2}+\cdots+c_{m}\mathbf{r}_{m},   where c 1 , c 2 , ... , c m are scalars. The set of all possible linear combinations of r 1 , ... , r m is called the row space of A . That is, the row space of A is the span of the vectors r 1 , ... , r m .  For example, if       A  =   [     1    0    2      0    1    0     ]    ,      A    1  0  2    0  1  0      A=\begin{bmatrix}1&0&2\\
 0&1&0\end{bmatrix},   then the row vectors are r 1 = (1, 0, 2) and r 2 = (0, 1, 0). A linear combination of r 1 and r 2 is any vector of the form          c  1    (  1  ,  0  ,  2  )    +    c  2    (  0  ,  1  ,  0  )     =   (   c  1   ,   c  2   ,   2   c  1    )    .           subscript  c  1    1  0  2       subscript  c  2    0  1  0       subscript  c  1    subscript  c  2     2   subscript  c  1       c_{1}(1,0,2)+c_{2}(0,1,0)=(c_{1},c_{2},2c_{1}).\,   The set of all such vectors is the row space of A . In this case, the row space is precisely the set of vectors ( x , y , z ) ∈ K 3 satisfying the equation z = 2 x (using Cartesian coordinates , this set is a plane through the origin in three-dimensional space ).  For a matrix that represents a homogeneous system of linear equations , the row space consists of all linear equations that follow from those in the system.  The column space of A is equal to the row space of A T .  Basis  The row space is not affected by elementary row operations . This makes it possible to use row reduction to find a basis for the row space.  For example, consider the matrix       A  =   [     1    3    2      2    7    4      1    5    2     ]    .      A    1  3  2    2  7  4    1  5  2      A=\begin{bmatrix}1&3&2\\
 2&7&4\\
 1&5&2\end{bmatrix}.   The rows of this matrix span the row space, but they may not be linearly independent , in which case the rows will not be a basis. To find a basis, we reduce A to row echelon form :  r 1 , r 2 , r 3 represents the rows.        [     1    3    2      2    7    4      1    5    2     ]     ∼  ⏟     r  2   -   2   r  1       [     1    3    2      0    1    0      1    5    2     ]     ∼  ⏟     r  3   -   r  1      [     1    3    2      0    1    0      0    2    0     ]     ∼  ⏟     r  3   -   2   r  2       [     1    3    2      0    1    0      0    0    0     ]     ∼  ⏟     r  1   -   3   r  2       [     1    0    2      0    1    0      0    0    0     ]    .        1  3  2    2  7  4    1  5  2     subscript   normal-⏟  similar-to      subscript  r  2     2   subscript  r  1        1  3  2    0  1  0    1  5  2     subscript   normal-⏟  similar-to      subscript  r  3    subscript  r  1       1  3  2    0  1  0    0  2  0     subscript   normal-⏟  similar-to      subscript  r  3     2   subscript  r  2        1  3  2    0  1  0    0  0  0     subscript   normal-⏟  similar-to      subscript  r  1     3   subscript  r  2        1  0  2    0  1  0    0  0  0      \begin{bmatrix}1&3&2\\
 2&7&4\\
 1&5&2\end{bmatrix}\underbrace{\sim}_{r_{2}-2r_{1}}\begin{bmatrix}1&3&2\\
 0&1&0\\
 1&5&2\end{bmatrix}\underbrace{\sim}_{r_{3}-r_{1}}\begin{bmatrix}1&3&2\\
 0&1&0\\
 0&2&0\end{bmatrix}\underbrace{\sim}_{r_{3}-2r_{2}}\begin{bmatrix}1&3&2\\
 0&1&0\\
 0&0&0\end{bmatrix}\underbrace{\sim}_{r_{1}-3r_{2}}\begin{bmatrix}1&0&2\\
 0&1&0\\
 0&0&0\end{bmatrix}.   Once the matrix is in echelon form, the nonzero rows are a basis for the row space. In this case, the basis is { (1, 3, 2), (0, 1, 0) }. Another possible basis { (1, 0, 2), (0, 1, 0) } comes from a further reduction. 3  This algorithm can be used in general to find a basis for the span of a set of vectors. If the matrix is further simplified to reduced row echelon form , then the resulting basis is uniquely determined by the row space.  Dimension  The dimension of the row space is called the rank of the matrix. This is the same as the maximum number of linearly independent rows that can be chosen from the matrix, or equivalently the number of pivots. For example, the 3 × 3 matrix in the example above has rank two. 4  The rank of a matrix is also equal to the dimension of the column space . The dimension of the null space is called the nullity of the matrix, and is related to the rank by the following equation:         rank   (  A  )    +   nullity   (  A  )     =  n   ,         rank  A    nullity  A    n    \operatorname{rank}(A)+\operatorname{nullity}(A)=n,   where n is the number of columns of the matrix A . The equation above is known as the rank-nullity theorem .  Relation to the null space  The null space of matrix A is the set of all vectors x for which A x = 0 . The product of the matrix A and the vector x can be written in terms of the dot product of vectors:        A  𝐱   =   [       𝐫  1   ⋅  𝐱         𝐫  2   ⋅  𝐱       ⋮        𝐫  m   ⋅  𝐱      ]    ,        A  𝐱      normal-⋅   subscript  𝐫  1   𝐱      normal-⋅   subscript  𝐫  2   𝐱     normal-⋮     normal-⋅   subscript  𝐫  m   𝐱       A\mathbf{x}=\begin{bmatrix}\mathbf{r}_{1}\cdot\mathbf{x}\\
 \mathbf{r}_{2}\cdot\mathbf{x}\\
 \vdots\\
 \mathbf{r}_{m}\cdot\mathbf{x}\end{bmatrix},   where r 1 , ... , r m are the row vectors of A . Thus A x = 0 if and only if x is orthogonal (perpendicular) to each of the row vectors of A .  It follows that the null space of A is the orthogonal complement to the row space. For example, if the row space is a plane through the origin in three dimensions, then the null space will be the perpendicular line through the origin. This provides a proof of the rank-nullity theorem (see dimension above).  The row space and null space are two of the four fundamental subspaces associated with a matrix A (the other two being the column space and left null space ).  Relation to coimage  If V and W are vector spaces , then the kernel of a linear transformation  T : V → W is the set of vectors v ∈ V for which T ( v ) = 0 . The kernel of a linear transformation is analogous to the null space of a matrix.  If V is an inner product space , then the orthogonal complement to the kernel can be thought of as a generalization of the row space. This is sometimes called the coimage of T . The transformation T is one-to-one on its coimage, and the coimage maps isomorphically onto the image of T .  When V is not an inner product space, the coimage of T can be defined as the quotient space  V / ker( T ).  Notes  References  Textbooks          External links     , MIT Linear Algebra Lecture on the Four Fundamental Subspaces at Google Video, from MIT OpenCourseWare   it:Spazi delle righe e delle colonne  nl:Kolom- en rijruimte  ur:قطار اور ستون فضا  zh:行空间与列空间 "  Category:Linear algebra  Category:Matrices     Linear algebra, as discussed in this article, is a very well established mathematical discipline for which there are many sources. Almost all of the material in this article can be found in Lay 2005, Meyer 2001, and Strang 2005. ↩  A definition and certain properties for rings are the same with replacement of the " vector n -space " K n with "left free module " and "linear subspace" with " submodule ". For non-commutative rings this row space is sometimes disambiguated as left row space. ↩  The example is valid over real, rational numbers , and other number fields . It is not necessarily correct over fields and rings with non-zero characteristic . ↩      