   Welch bounds      Welch bounds   In mathematics , Welch bounds are a family of inequalities pertinent to the problem of evenly spreading a set of unit vectors in a vector space . The bounds are important tools in the design and analysis of certain methods in telecommunication engineering, particularly in coding theory . The bounds were originally published in a 1974 paper by L. R. Welch.  Mathematical statement  If    {   x  1   ,  …  ,   x  m   }      subscript  x  1   normal-…   subscript  x  m     \{x_{1},\ldots,x_{m}\}   are unit vectors in    ℂ  n     superscript  ℂ  n    \mathbb{C}^{n}   , define     c  max   =    max   i  ≠  j     |   ⟨   x  i   ,   x  j   ⟩   |         subscript  c      subscript     i  j        subscript  x  i    subscript  x  j        c_{\max}=\max_{i\neq j}|\langle x_{i},x_{j}\rangle|   , where    ⟨  ⋅  ,  ⋅  ⟩     normal-⋅  normal-⋅    \langle\cdot,\cdot\rangle   is the usual inner product on    ℂ  n     superscript  ℂ  n    \mathbb{C}^{n}   . Then the following inequalities hold for    k  =   1  ,  2  ,  …       k   1  2  normal-…     k=1,2,\dots   :        (   c  max   )    2  k    ≥    1   m  -  1     [    m   (        n  +  k   -  1       k      )    -  1   ]         superscript   subscript  c      2  k        1    m  1     delimited-[]      m   binomial      n  k   1   k    1       (c_{\max})^{2k}\geq\frac{1}{m-1}\left[\frac{m}{{\left({{n+k-1}\atop{k}}\right)%
 }}-1\right]     Applicability  If    m  ≤  n      m  n    m\leq n   , then the vectors    {   x  i   }      subscript  x  i     \{x_{i}\}   can form an orthonormal set in    ℂ  n     superscript  ℂ  n    \mathbb{C}^{n}   . In this case,     c  max   =  0       subscript  c    0    c_{\max}=0   and the bounds are vacuous. Consequently, interpretation of the bounds is only meaningful if    m  >  n      m  n    m>n   . This will be assumed throughout the remainder of this article.  ==Proof for k = 1==  The "first Welch bound," corresponding to    k  =  1      k  1    k=1   , is by far the most commonly used in applications. Its proof proceeds in two steps, each of which depends on a more basic mathematical inequality. The first step invokes the Cauchy-Schwarz inequality and begins by considering the    m  ×  m      m  m    m\times m    Gram matrix    G   G   G   of the vectors    {   x  i   }      subscript  x  i     \{x_{i}\}   ; i.e.,      G  =   [      ⟨   x  1   ,   x  1   ⟩     ⋯     ⟨   x  1   ,   x  m   ⟩       ⋮    ⋱    ⋮       ⟨   x  m   ,   x  1   ⟩     ⋯     ⟨   x  m   ,   x  m   ⟩      ]       G   delimited-[]      subscript  x  1    subscript  x  1    normal-⋯    subscript  x  1    subscript  x  m      normal-⋮  normal-⋱  normal-⋮      subscript  x  m    subscript  x  1    normal-⋯    subscript  x  m    subscript  x  m         G=\left[\begin{array}[]{ccc}\langle x_{1},x_{1}\rangle&\cdots&\langle x_{1},x_%
 {m}\rangle\\
 \vdots&\ddots&\vdots\\
 \langle x_{m},x_{1}\rangle&\cdots&\langle x_{m},x_{m}\rangle\end{array}\right]     The trace of   G   G   G   is equal to the sum of its eigenvalues. Because the rank of   G   G   G   is at most   n   n   n   , and it is a positive semidefinite matrix,   G   G   G   has at most   n   n   n   positive eigenvalues with its remaining eigenvalues all equal to zero. Writing the non-zero eigenvalues of   G   G   G   as     λ  1   ,  …  ,   λ  r       subscript  λ  1   normal-…   subscript  λ  r     \lambda_{1},\ldots,\lambda_{r}   with    r  ≤  n      r  n    r\leq n   and applying the Cauchy-Schwarz inequality to the inner product of an   r   r   r   -vector of ones with a vector whose components are these eigenvalues yields        (    Tr   G   )   2   =    (    ∑   i  =  1   r    λ  i    )   2   ≤   r    ∑   i  =  1   r    λ  i  2     ≤   n    ∑   i  =  1   m    λ  i  2            superscript    Tr  G   2    superscript    superscript   subscript     i  1    r    subscript  λ  i    2          r    superscript   subscript     i  1    r    superscript   subscript  λ  i   2            n    superscript   subscript     i  1    m    superscript   subscript  λ  i   2        (\mathrm{Tr}\;G)^{2}=\left(\sum_{i=1}^{r}\lambda_{i}\right)^{2}\leq r\sum_{i=1%
 }^{r}\lambda_{i}^{2}\leq n\sum_{i=1}^{m}\lambda_{i}^{2}     The square of the Frobenius norm (Hilbert–Schmidt norm) of   G   G   G   satisfies        ||  G  ||   2   =    ∑   i  =  1   m     ∑   j  =  1   m     |   ⟨   x  i   ,   x  j   ⟩   |   2     =    ∑   i  =  1   m    λ  i  2           superscript   norm  G   2     superscript   subscript     i  1    m     superscript   subscript     j  1    m    superscript      subscript  x  i    subscript  x  j     2            superscript   subscript     i  1    m    superscript   subscript  λ  i   2       ||G||^{2}=\sum_{i=1}^{m}\sum_{j=1}^{m}|\langle x_{i},x_{j}\rangle|^{2}=\sum_{i%
 =1}^{m}\lambda_{i}^{2}     Taking this together with the preceding inequality gives        ∑   i  =  1   m     ∑   j  =  1   m     |   ⟨   x  i   ,   x  j   ⟩   |   2     ≥     (    Tr   G   )   2   n         superscript   subscript     i  1    m     superscript   subscript     j  1    m    superscript      subscript  x  i    subscript  x  j     2        superscript    Tr  G   2   n     \sum_{i=1}^{m}\sum_{j=1}^{m}|\langle x_{i},x_{j}\rangle|^{2}\geq\frac{(\mathrm%
 {Tr}\;G)^{2}}{n}     Because each    x  i     subscript  x  i    x_{i}   has unit length, the elements on the main diagonal of   G   G   G   are ones, and hence its trace is      Tr   G   =  m        Tr  G   m    \mathrm{Tr}\;G=m   . So,        ∑   i  =  1   m     ∑   j  =  1   m     |   ⟨   x  i   ,   x  j   ⟩   |   2     =   m  +    ∑   i  ≠  j      |   ⟨   x  i   ,   x  j   ⟩   |   2     ≥    m  2   n           superscript   subscript     i  1    m     superscript   subscript     j  1    m    superscript      subscript  x  i    subscript  x  j     2       m    subscript     i  j     superscript      subscript  x  i    subscript  x  j     2             superscript  m  2   n      \sum_{i=1}^{m}\sum_{j=1}^{m}|\langle x_{i},x_{j}\rangle|^{2}=m+\sum_{i\neq j}|%
 \langle x_{i},x_{j}\rangle|^{2}\geq\frac{m^{2}}{n}     or        ∑   i  ≠  j      |   ⟨   x  i   ,   x  j   ⟩   |   2    ≥    m   (   m  -  n   )    n         subscript     i  j     superscript      subscript  x  i    subscript  x  j     2        m    m  n    n     \sum_{i\neq j}|\langle x_{i},x_{j}\rangle|^{2}\geq\frac{m(m-n)}{n}     The second part of the proof uses an inequality encompassing the simple observation that the average of a set of non-negative numbers can be no greater than the largest number in the set. In mathematical notation, if     a  ℓ   ≥  0       subscript  a  normal-ℓ   0    a_{\ell}\geq 0   for    ℓ  =   1  ,  …  ,  L       normal-ℓ   1  normal-…  L     \ell=1,\ldots,L   , then        1  L     ∑   ℓ  =  1   L    a  ℓ     ≤   max   a  ℓ            1  L     superscript   subscript     normal-ℓ  1    L    subscript  a  normal-ℓ        subscript  a  normal-ℓ      \frac{1}{L}\sum_{\ell=1}^{L}a_{\ell}\leq\max a_{\ell}     The previous expression has    m   (   m  -  1   )       m    m  1     m(m-1)   non-negative terms in the sum,the largest of which is    c  max  2     superscript   subscript  c    2    c_{\max}^{2}   . So,        (   c  max   )   2   ≥    1   m   (   m  -  1   )       ∑   i  ≠  j      |   ⟨   x  i   ,   x  j   ⟩   |   2     ≥    m  -  n    n   (   m  -  1   )            superscript   subscript  c    2       1    m    m  1       subscript     i  j     superscript      subscript  x  i    subscript  x  j     2              m  n     n    m  1        (c_{\max})^{2}\geq\frac{1}{m(m-1)}\sum_{i\neq j}|\langle x_{i},x_{j}\rangle|^{%
 2}\geq\frac{m-n}{n(m-1)}     or        (   c  max   )   2   ≥    m  -  n    n   (   m  -  1   )          superscript   subscript  c    2       m  n     n    m  1       (c_{\max})^{2}\geq\frac{m-n}{n(m-1)}     which is precisely the inequality given by Welch in the case that    k  =  1      k  1    k=1     Achieving Welch bound equality  In certain telecommunications applications, it is desirable to construct sets of vectors that meet the Welch bounds with equality. Several techniques have been introduced to obtain so-called Welch Bound Equality (WBE) sets of vectors for the k = 1 bound.  The proof given above shows that two separate mathematical inequalities are incorporated into the Welch bound when    k  =  1      k  1    k=1   . The Cauchy–Schwarz inequality is met with equality when the two vectors involved are collinear. In the way it is used in the above proof, this occurs when all the non-zero eigenvalues of the Gram matrix   G   G   G   are equal, which happens precisely when the vectors    {   x  1   ,  …  ,   x  m   }      subscript  x  1   normal-…   subscript  x  m     \{x_{1},\ldots,x_{m}\}   constitute a tight frame for    ℂ  n     superscript  ℂ  n    \mathbb{C}^{n}   .  The other inequality in the proof is satisfied with equality if and only if    |   ⟨   x  i   ,   x  j   ⟩   |        subscript  x  i    subscript  x  j      |\langle x_{i},x_{j}\rangle|   is the same for every choice of    i  ≠  j      i  j    i\neq j   . In this case, the vectors are equiangular . So this Welch bound is met with equality if and only if the set of vectors    {   x  i   }      subscript  x  i     \{x_{i}\}   is an equiangular tight frame in    ℂ  n     superscript  ℂ  n    \mathbb{C}^{n}   .  References      "  Category:Inequalities   