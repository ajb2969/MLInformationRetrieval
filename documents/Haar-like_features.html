<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="1694">Haar-like features</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>Haar-like features</h1>
<hr/>

<p><strong>Haar-like features</strong> are <a href="digital_image" title="wikilink">digital image</a> <a href="feature_(computer_vision)" title="wikilink">features</a> used in <a href="object_recognition" title="wikilink">object recognition</a>. They owe their name to their intuitive similarity with <a href="Haar_wavelet" title="wikilink">Haar wavelets</a> and were used in the first real-time face detector.<a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a></p>

<p>Historically, working with only image intensities (i.e., the <a class="uri" href="RGB" title="wikilink">RGB</a> <a class="uri" href="pixel" title="wikilink">pixel</a> values at each and every pixel of image) made the task of feature calculation <a href="computationally_expensive" title="wikilink">computationally expensive</a>. A publication by Papageorgiou et al.<a class="footnoteRef" href="#fn2" id="fnref2"><sup>2</sup></a> discussed working with an alternate feature set based on Haar wavelets instead of the usual image intensities. Viola and Jones<a class="footnoteRef" href="#fn3" id="fnref3"><sup>3</sup></a> adapted the idea of using Haar wavelets and developed the so-called Haar-like features. A Haar-like feature considers adjacent rectangular regions at a specific location in a detection window, sums up the pixel intensities in each region and calculates the difference between these sums. This difference is then used to <a href="categorization" title="wikilink">categorize</a> subsections of an image. For example, let us say we have an image database with human <a href="face" title="wikilink">faces</a>. It is a common observation that among all faces the region of the eyes is darker than the region of the cheeks. Therefore a common haar feature for face detection is a set of two adjacent rectangles that lie above the eye and the cheek region. The position of these rectangles is defined relative to a detection window that acts like a bounding box to the target object (the face in this case).</p>

<p>In the detection phase of the <a href="Viola–Jones_object_detection_framework" title="wikilink">Viola–Jones object detection framework</a>, a window of the target size is moved over the input image, and for each subsection of the image the Haar-like feature is calculated. This difference is then compared to a learned threshold that separates non-objects from objects. Because such a Haar-like feature is only a weak learner or classifier (its detection quality is slightly better than random guessing) a large number of Haar-like features are necessary to describe an object with sufficient accuracy. In the Viola–Jones object detection framework, the Haar-like features are therefore organized in something called a <em>classifier cascade</em> to form a strong learner or classifier.</p>

<p>The key advantage of a Haar-like feature over most other features is its calculation speed. Due to the use of <em><a href="integral_image" title="wikilink">integral images</a></em>, a Haar-like feature of any size can be calculated in constant time (approximately 60 microprocessor instructions for a 2-rectangle feature).</p>
<h2 id="rectangular-haar-like-features">Rectangular Haar-like features</h2>

<p>A simple rectangular Haar-like feature can be defined as the difference of the sum of pixels of areas inside the rectangle, which can be at any position and scale within the original image. This modified feature set is called <em>2-rectangle feature</em>. Viola and Jones also defined 3-rectangle features and 4-rectangle features. The values indicate certain characteristics of a particular area of the image. Each feature type can indicate the existence (or absence) of certain characteristics in the image, such as edges or changes in texture. For example, a 2-rectangle feature can indicate where the border lies between a dark region and a light region.</p>
<h2 id="fast-computation-of-haar-like-features">Fast computation of Haar-like features</h2>

<p>One of the contributions of Viola and Jones was to use <a href="summed_area_table" title="wikilink">summed area tables</a>,<a class="footnoteRef" href="#fn4" id="fnref4"><sup>4</sup></a> which they called <em><a href="integral_image" title="wikilink">integral images</a></em>. Integral images can be defined as two-dimensional <a href="lookup_table" title="wikilink">lookup tables</a> in the form of a matrix with the same size of the original image. Each element of the integral image contains the sum of all pixels located on the up-left region of the original image (in relation to the element's position). This allows to compute sum of rectangular areas in the image, at any position or scale, using only four lookups: </p>

<p>

<math display="block" id="Haar-like_features:0">
 <semantics>
  <mrow>
   <mrow>
    <mtext>sum</mtext>
    <mo>=</mo>
    <mrow>
     <mrow>
      <mrow>
       <mi>I</mi>
       <mrow>
        <mo stretchy="false">(</mo>
        <mi>C</mi>
        <mo stretchy="false">)</mo>
       </mrow>
      </mrow>
      <mo>+</mo>
      <mrow>
       <mi>I</mi>
       <mrow>
        <mo stretchy="false">(</mo>
        <mi>A</mi>
        <mo stretchy="false">)</mo>
       </mrow>
      </mrow>
     </mrow>
     <mo>-</mo>
     <mrow>
      <mi>I</mi>
      <mrow>
       <mo stretchy="false">(</mo>
       <mi>B</mi>
       <mo stretchy="false">)</mo>
      </mrow>
     </mrow>
     <mo>-</mo>
     <mrow>
      <mi>I</mi>
      <mrow>
       <mo stretchy="false">(</mo>
       <mi>D</mi>
       <mo stretchy="false">)</mo>
      </mrow>
     </mrow>
    </mrow>
   </mrow>
   <mo>.</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <mtext>sum</mtext>
    <apply>
     <minus></minus>
     <apply>
      <plus></plus>
      <apply>
       <times></times>
       <ci>I</ci>
       <ci>C</ci>
      </apply>
      <apply>
       <times></times>
       <ci>I</ci>
       <ci>A</ci>
      </apply>
     </apply>
     <apply>
      <times></times>
      <ci>I</ci>
      <ci>B</ci>
     </apply>
     <apply>
      <times></times>
      <ci>I</ci>
      <ci>D</ci>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \text{sum}=I(C)+I(A)-I(B)-I(D).\,
  </annotation>
 </semantics>
</math>

</p>

<p>where points 

<math display="inline" id="Haar-like_features:1">
 <semantics>
  <mrow>
   <mi>A</mi>
   <mo>,</mo>
   <mi>B</mi>
   <mo>,</mo>
   <mi>C</mi>
   <mo>,</mo>
   <mi>D</mi>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <list>
    <ci>A</ci>
    <ci>B</ci>
    <ci>C</ci>
    <ci>D</ci>
   </list>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   A,B,C,D
  </annotation>
 </semantics>
</math>

 belong to the integral image 

<math display="inline" id="Haar-like_features:2">
 <semantics>
  <mi>I</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>I</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   I
  </annotation>
 </semantics>
</math>

, as shown in the figure.</p>

<p>Each Haar-like feature may need more than four lookups, depending on how it was defined. Viola and Jones's 2-rectangle features need six lookups, 3-rectangle features need eight lookups, and 4-rectangle features need nine lookups.</p>
<h2 id="tilted-haar-like-features">Tilted Haar-like features</h2>

<p>Lienhart and Maydt<a class="footnoteRef" href="#fn5" id="fnref5"><sup>5</sup></a> introduced the concept of a tilted (45°) Haar-like feature. This was used to increase the <a class="uri" href="dimensionality" title="wikilink">dimensionality</a> of the set of features in an attempt to improve the detection of objects in images. This was successful, as some of these features are able to describe the object in a better way. For example, a 2-rectangle tilted Haar-like feature can indicate the existence of an edge at 45°.</p>

<p>Messom and Barczak<a class="footnoteRef" href="#fn6" id="fnref6"><sup>6</sup></a> extended the idea to a generic rotated Haar-like feature. Although the idea sounds mathematically sound, practical problems prevented the use of Haar-like features at any angle. In order to be fast, detection algorithms use low resolution images, causing <a href="rounding_error" title="wikilink">rounding errors</a>. For this reason, rotated Haar-like features are not commonly used.</p>
<h2 id="references">References</h2>
<references>
</references>
<ul>
<li>Haar A. <em>Zur Theorie der orthogonalen Funktionensysteme</em>, Mathematische Annalen, <strong>69</strong>, pp. 331–371, 1910.</li>
</ul>

<p>"</p>

<p><a class="uri" href="Category:Bioinformatics" title="wikilink">Category:Bioinformatics</a> <a href="Category:Feature_detection_(computer_vision)" title="wikilink">Category:Feature detection (computer vision)</a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1">Viola and Jones, "Rapid object detection using a boosted cascade of simple features", Computer Vision and <a href="Pattern_Recognition" title="wikilink">Pattern Recognition</a>, 2001<a href="#fnref1">↩</a></li>
<li id="fn2">Papageorgiou, Oren and Poggio, "A general framework for object detection", International Conference on Computer Vision, 1998.<a href="#fnref2">↩</a></li>
<li id="fn3">Viola and Jones, "Rapid object detection using a boosted cascade of simple features", Computer Vision and <a href="Pattern_Recognition" title="wikilink">Pattern Recognition</a>, 2001<a href="#fnref3">↩</a></li>
<li id="fn4">Crow, F, "Summed-area tables for texture mapping", in Proceedings of <a class="uri" href="SIGGRAPH" title="wikilink">SIGGRAPH</a>, 18(3):207–212, 1984<a href="#fnref4">↩</a></li>
<li id="fn5">Lienhart, R. and Maydt, J., "An extended set of Haar-like features for rapid object detection", ICIP02, pp. I: 900–903, 2002<a href="#fnref5">↩</a></li>
<li id="fn6">Messom, C.H. and Barczak, A.L.C., "Fast and Efficient Rotated Haar-like Features Using Rotated Integral Images", Australian Conference on Robotics and Automation (ACRA2006), pp. 1–6, 2006<a href="#fnref6">↩</a></li>
</ol>
</section>
</body>
</html>
