   Adomian decomposition method      Adomian decomposition method   The Adomian decomposition method (ADM) is a semi-analytical method for solving ordinary and partial  nonlinear  differential equations . The method was developed from the 1970s to the 1990s by George Adomian , chair of the Center for Applied Mathematics at the University of Georgia . 1 It is further extensible to stochastic systems by using the Ito integral . 2 The aim of this method is towards a unified theory for the solution of partial differential equations (PDE); an aim which has been superseded by the more general theory of the homotopy analysis method . 3 The crucial aspect of the method is employment of the "Adomian polynomials" which allow for solution convergence of the nonlinear portion of the equation, without simply linearizing the system. These polynomials mathematically generalize to a Maclaurin series about an arbitrary external parameter; which gives the solution method more flexibility than direct Taylor series expansion. 4  Ordinary Differential Equations  Adomian method is well suited to solve Cauchy problems , an important class of problems which include initial conditions problems.  Application to a first order nonlinear system  An example of initial condition problem for an Ordinary Differential Equation is the following:          y  ′    (  t  )    +    y  2    (  t  )     =   -  1    ,           superscript  y  normal-′   t      superscript  y  2   t      1     y^{\prime}(t)+y^{2}(t)=-1,          y   (  0  )    =  0.        y  0   0.    y(0)=0.     To solve the problem, the highest degree differential operator (written here as L ) is put on the left side, in the following way:        L  y   =    -  1   -   y  2     ,        L  y       1    superscript  y  2      Ly=-1-y^{2},     with L = d/d t and     L   -  1    =    ∫  0  t    (  )         superscript  L    1      superscript   subscript   0   t       L^{-1}=\int_{0}^{t}()   . Now the solution is assumed to be an infinite series of contributions:       y  =    y  0   +   y  1   +   y  2   +   y  3   +  ⋯    .      y     subscript  y  0    subscript  y  1    subscript  y  2    subscript  y  3   normal-⋯     y=y_{0}+y_{1}+y_{2}+y_{3}+\cdots.     Replacing in the previous expression, we obtain:        (    y  0   +   y  1   +   y  2   +   y  3   +  ⋯   )   =    y   (  0  )    +    L   -  1     [    -  1   -    (    y  0   +   y  1   +   y  2   +   y  3   +  ⋯   )   2    ]      .         subscript  y  0    subscript  y  1    subscript  y  2    subscript  y  3   normal-⋯       y  0      superscript  L    1     delimited-[]      1    superscript     subscript  y  0    subscript  y  1    subscript  y  2    subscript  y  3   normal-⋯   2         (y_{0}+y_{1}+y_{2}+y_{3}+\cdots)=y(0)+L^{-1}[-1-(y_{0}+y_{1}+y_{2}+y_{3}+%
 \cdots)^{2}].     Now we identify y 0 with some explicit expression on the right, and y i , i = 1, 2, 3, ..., with some expression on the right containing terms of lower order than i . For instance:      y   ;  0      fragments  y   subscript  normal-;  0     \displaystyle y;_{0}     In this way, any contribution can be explicitly calculated at any order. If we settle for the four first terms, the approximant is the following:     y   y   \displaystyle y     Application to Blasius equation  A second example, with more complex boundary conditions is the Blasius Equation for a flow in a boundary layer :          d  3   u    d   x  3     +    1  2   u     d  2   u    d   x  2       =  0             superscript  normal-d  3   u     normal-d   superscript  x  3         1  2   u       superscript  normal-d  2   u     normal-d   superscript  x  2       0    \frac{\mathrm{d}^{3}u}{\mathrm{d}x^{3}}+\frac{1}{2}u\frac{\mathrm{d}^{2}u}{%
 \mathrm{d}x^{2}}=0     With the following conditions at the boundaries:      u   (  0  )       u  0    \displaystyle u(0)     Linear and non-linear operators are now called    L  =    d  3    d   x  3         L     superscript  normal-d  3     normal-d   superscript  x  3       L=\frac{\mathrm{d}^{3}}{\mathrm{d}x^{3}}   and     N  u   =    1  2   u    d  2    d   x  2            N  u       1  2   u     superscript  normal-d  2     normal-d   superscript  x  2        Nu=\frac{1}{2}u\frac{\mathrm{d}^{2}}{\mathrm{d}x^{2}}   , respectively. Then, the expression becomes:        L  u   +   N  u    =  0          L  u     N  u    0    Lu+Nu=0     and the solution may be expressed, in this case, in the following simple way:      u  =    α  +   β  x   +    γ   x  2    /  2    -    L   -  1    N  u        u      α    β  x       γ   superscript  x  2    2       superscript  L    1    N  u      u=\alpha+\beta x+\gamma x^{2}/2-L^{-1}Nu     where      L   -  1    ξ   (  x  )    =   ∫   d  x   ∫   d  x   ∫   d   x   ξ   (  x  )                superscript  L    1    ξ  x       d  x      normal-d  x      normal-d  x  ξ  x          L^{-1}\xi(x)=\int dx\int\mathrm{d}x\int\mathrm{d}x\;\;\xi(x)   If:     u   u   \displaystyle u     and:      u   ;  0      fragments  u   superscript  normal-;  0     \displaystyle u;^{0}     Adomian’s polynomials to linearize the non-linear term can be obtained systematically by using the following rule:        A  n   =      1   n  !      d  n    d   λ  n     f   (   u   (  λ  )    )    |    λ  =  0     ,       subscript  A  n    evaluated-at      1    n       superscript  normal-d  n     normal-d   superscript  λ  n     f    u  λ      λ  0      A_{n}=\frac{1}{n!}\frac{\mathrm{d}^{n}}{\mathrm{d}\lambda^{n}}f(u(\lambda))%
 \mid_{\lambda=0},     where         d  n    d   λ  n     u   (  λ  )    |    λ  =  0    =    n  !    u  n         evaluated-at       superscript  normal-d  n     normal-d   superscript  λ  n     u  λ     λ  0        n    subscript  u  n      \frac{\mathrm{d}^{n}}{\mathrm{d}\lambda^{n}}u(\lambda)\mid_{\lambda=0}=n!u_{n}     Boundary conditions must be applied, in general, at the end of each approximation. In this case, the integration constants must be grouped into three final independent constants. However, in our example, the three constants appear grouped from the beginning in the form shown in the formal solution above. After applying the two first boundary conditions we obtain the so-called Blasius series:      u  =        γ  2    x  2    -     γ  2   2    (    x  5    5  !    )     +     11   γ  3    4    (    x  8    8  !    )     -     375   γ  4    8    (    x  11    11  !    )     +  ⋯       u              γ  2    superscript  x  2         superscript  γ  2   2      superscript  x  5     5            11   superscript  γ  3    4      superscript  x  8     8            375   superscript  γ  4    8      superscript  x  11     11      normal-⋯     u=\frac{\gamma}{2}x^{2}-\frac{\gamma^{2}}{2}\left(\frac{x^{5}}{5!}\right)+%
 \frac{11\gamma^{3}}{4}\left(\frac{x^{8}}{8!}\right)-\frac{375\gamma^{4}}{8}%
 \left(\frac{x^{11}}{11!}\right)+\cdots     To obtain γ we have to apply boundary conditions at ∞, which may be done by writing the series as a Padé approximant:       f   (  z  )    =    ∑   n  =  0    L  +  M      c  n    z  n     =     a  0   +    a  1   z   +  ⋯  +    a  L    z  L       b  0   +    b  1   z   +  ⋯  +    b  M    z  M              f  z     superscript   subscript     n  0      L  M       subscript  c  n    superscript  z  n               subscript  a  0      subscript  a  1   z   normal-⋯     subscript  a  L    superscript  z  L        subscript  b  0      subscript  b  1   z   normal-⋯     subscript  b  M    superscript  z  M         f(z)=\sum_{n=0}^{L+M}c_{n}z^{n}=\frac{a_{0}+a_{1}z+\cdots+a_{L}z^{L}}{b_{0}+b_%
 {1}z+\cdots+b_{M}z^{M}}     where L = M . The limit at   ∞     \infty   of this expression is a L / b M .  If we choose b 0 = 1, M linear equations for the b coefficients are obtained:        [      c    L  -  M   +  1       c    L  -  M   +  2      ⋯     c  L        c    L  -  M   +  2       c    L  -  M   +  3      ⋯     c   L  +  1        ⋮    ⋮     ⋮       c  L      c   L  +  1      ⋯     c    L  +  M   -  1       ]    [      b  M        b   M  -  1        ⋮       b  1      ]    =   -   [      c   L  +  1         c   L  +  2        ⋮       c   L  +  M       ]           delimited-[]     subscript  c      L  M   1     subscript  c      L  M   2    normal-⋯   subscript  c  L      subscript  c      L  M   2     subscript  c      L  M   3    normal-⋯   subscript  c    L  1      normal-⋮  normal-⋮   missing-subexpression   normal-⋮     subscript  c  L    subscript  c    L  1    normal-⋯   subscript  c      L  M   1        delimited-[]     subscript  b  M      subscript  b    M  1      normal-⋮     subscript  b  1          delimited-[]     subscript  c    L  1       subscript  c    L  2      normal-⋮     subscript  c    L  M          \left[\begin{array}[]{cccc}c_{L-M+1}&c_{L-M+2}&\cdots&c_{L}\\
 c_{L-M+2}&c_{L-M+3}&\cdots&c_{L+1}\\
 \vdots&\vdots&&\vdots\\
 c_{L}&c_{L+1}&\cdots&c_{L+M-1}\end{array}\right]\left[\begin{array}[]{c}b_{M}%
 \\
 b_{M-1}\\
 \vdots\\
 b_{1}\end{array}\right]=-\left[\begin{array}[]{c}c_{L+1}\\
 c_{L+2}\\
 \vdots\\
 c_{L+M}\end{array}\right]     Then, we obtain the a coefficients by means of the following sequence:      a  0     subscript  a  0    \displaystyle a_{0}     In our example:        u  ′    (  x  )    =      γ  x   -     γ  2   2    (    x  4    4  !    )     +     11   γ  3    4    (    x  7    7  !    )     -     375   γ  4    8    (    x  10    10  !    )            superscript  u  normal-′   x           γ  x        superscript  γ  2   2      superscript  x  4     4            11   superscript  γ  3    4      superscript  x  7     7            375   superscript  γ  4    8      superscript  x  10     10        u^{\prime}(x)=\gamma x-\frac{\gamma^{2}}{2}\left(\frac{x^{4}}{4!}\right)+\frac%
 {11\gamma^{3}}{4}\left(\frac{x^{7}}{7!}\right)-\frac{375\gamma^{4}}{8}\left(%
 \frac{x^{10}}{10!}\right)     Which when γ = 0.0408 becomes:         u  ′    (  x  )    =       0.0204  +    0.0379   z    -    0.0059    z  2    -    0.00004575    z  3     +    6.357  ⋅   10   -  6      z  4     -    1.291  ⋅   10   -  6      z  5        1  -    0.1429   z   -    0.0000232    z  2     +    0.0008375    z  3     -    0.0001558    z  4    -    1.2849  ⋅   10   -  6      z  5       ,         superscript  u  normal-′   x             0.0204    0.0379  z      0.0059   superscript  z  2      0.00004575   superscript  z  3        normal-⋅  6.357   superscript  10    6      superscript  z  4        normal-⋅  1.291   superscript  10    6      superscript  z  5           1    0.1429  z     0.0000232   superscript  z  2       0.0008375   superscript  z  3       0.0001558   superscript  z  4       normal-⋅  1.2849   superscript  10    6      superscript  z  5        u^{\prime}(x)=\frac{0.0204+0.0379\,z-0.0059\,z^{2}-0.00004575\,z^{3}+6.357%
 \cdot 10^{-6}z^{4}-1.291\cdot 10^{-6}z^{5}}{1-0.1429\,z-0.0000232\,z^{2}+0.000%
 8375\,z^{3}-0.0001558\,z^{4}-1.2849\cdot 10^{-6}z^{5}},     with the limit:        lim   x  →  ∞      u  ′    (  x  )     =  1.004.        subscript    normal-→  x        superscript  u  normal-′   x    1.004.    \lim_{x\to\infty}u^{\prime}(x)=1.004.     Which is approximately equal to 1 (from boundary condition (3)) with an accuracy of 4/1000.  Partial Differential Equations  Application to a rectangular system with nonlinearity  One of the most frequent problems in physical sciences is to obtain the solution of a (linear or nonlinear) partial differential equation which satisfies a set of functional values on a rectangular boundary. For instance, let us consider the following problem:           ∂  2   u    ∂   x  2     +     ∂  2   u    ∂   y  2      -   b    ∂   u  2     ∂  x      =    ρ   (  x  ,  y  )     (  1  )                superscript   2   u      superscript  x  2         superscript   2   u      superscript  y  2        b       superscript  u  2      x         ρ   x  y    1     \frac{\partial^{2}u}{\partial x^{2}}+\frac{\partial^{2}u}{\partial y^{2}}-b%
 \frac{\partial u^{2}}{\partial x}=\rho(x,y)\qquad(1)     with the following boundary conditions defined on a rectangle:      u   (  x  =  0  )   =   f  1    (  y  )   and  u   (  x  =   x  l   )   =   f  2    (  y  )   (1-a)     fragments  u   fragments  normal-(  x   0  normal-)     subscript  f  1    fragments  normal-(  y  normal-)    and   u   fragments  normal-(  x    subscript  x  l   normal-)     subscript  f  2    fragments  normal-(  y  normal-)   italic-  (1-a)    u(x=0)=f_{1}(y)\quad\text{and}\quad u(x=x_{l})=f_{2}(y)\qquad\text{(1-a)}         u   (  y  =  -   y  l   )   =   g  1    (  x  )   and  u   (  y  =   y  l   )   =   g  2    (  x  )   (1-b)     fragments  u   fragments  normal-(  y     subscript  y  l   normal-)     subscript  g  1    fragments  normal-(  x  normal-)    and   u   fragments  normal-(  y    subscript  y  l   normal-)     subscript  g  2    fragments  normal-(  x  normal-)   italic-  (1-b)    u(y=-y_{l})=g_{1}(x)\quad\text{and}\quad u(y=y_{l})=g_{2}(x)\qquad\text{(1-b)}     This kind of partial differential equation appears frequently coupled with others in science and engineering . For instance, in the incompressible fluid flow problem, the Navier–Stokes equations must be solved in parallel with a Poisson equation for the pressure.  Decomposition of the system  Let us use the following notation for the problem (1):         L  x   u   +    L  y   u   +   N  u    =    ρ   (  x  ,  y  )     (  2  )             subscript  L  x   u      subscript  L  y   u     N  u       ρ   x  y    2     L_{x}u+L_{y}u+Nu=\rho(x,y)\qquad(2)     where L x , L y are double derivate operators and N is a non-linear operator.  The formal solution of (2) is:      u  =      a   (  y  )    +   b   (  y  )   x   +    L  x   -  1    ρ   (  x  ,  y  )     -    L  x   -  1     L  y   u   -    L  x   -  1    N  u     (  3  )        u         a  y     b  y  x      superscript   subscript  L  x     1    ρ   x  y        superscript   subscript  L  x     1     subscript  L  y   u      superscript   subscript  L  x     1    N  u    3     u=a(y)+b(y)x+L_{x}^{-1}\rho(x,y)-L_{x}^{-1}L_{y}u-L_{x}^{-1}Nu\qquad(3)     Expanding now u as a set of contributions to the solution we have:      u  =    u  0   +   u  1   +   u  2   +   u  3   +  ⋯       u     subscript  u  0    subscript  u  1    subscript  u  2    subscript  u  3   normal-⋯     u=u_{0}+u_{1}+u_{2}+u_{3}+\cdots     By substitution in (3) and making a one-to-one correspondence between the contributions on the left side and the terms on the right side we obtain the following iterative scheme:      u  0     subscript  u  0    \displaystyle u_{0}     where the couple { a n ( y ), b n ( y )} is the solution of the following system of equations:       φ  n    (  x  =  0  )      fragments   superscript  φ  n    fragments  normal-(  x   0  normal-)     \displaystyle\varphi^{n}(x=0)     here     φ  n   ≡    ∑   i  =  0   n    u  i         superscript  φ  n     superscript   subscript     i  0    n    subscript  u  i      \varphi^{n}\equiv\sum_{i=0}^{n}u_{i}   is the n th-order approximant to the solution and N u has been consistently expanded in Adomian polynomials:      N  u      N  u    \displaystyle Nu     where     A  n   =    ∑   ν  =  1   n    C   (  ν  ,  n  )    f   (  ν  )     (   u  0   )          subscript  A  n     superscript   subscript     ν  1    n     C   ν  n    superscript  f  ν    subscript  u  0       A_{n}=\sum_{\nu=1}^{n}C(\nu,n)f^{(\nu)}(u_{0})   and f ( u ) = u 2 in the example (1).  Here C (ν, n ) are products (or sum of products) of ν components of u whose subscripts sum up to n , divided by the factorial of the number of repeated subscripts. It is only a thumb-rule to order systematically the decomposition to be sure that all the combinations appearing are utilized sooner or later.  The     ∑   n  =  0   ∞    A  n       superscript   subscript     n  0       subscript  A  n     \sum_{n=0}^{\infty}A_{n}   is equal to the sum of a generalized Taylor series about u 0 . 5  For the example (1) the Adomian polynomials are:      A  0     subscript  A  0    \displaystyle A_{0}     Other possible choices are also possible for the expression of A n .  Series solutions  Cherruault established that the series terms obtained by Adomian's method approach zero as 1/( mn )! if m is the order of the highest linear differential operator and that      lim   n  →  ∞     φ  n    =  u        subscript    normal-→  n      superscript  φ  n    u    \lim_{n\to\infty}\varphi^{n}=u   . 6 With this method the solution can be found by systematically integrating along any of the two directions: in the x -direction we would use expression (3); in the alternative y -direction we would use the following expression:      u  =     c   (  x  )    +   d   (  x  )   y   +    L  y   -  1    ρ   (  x  ,  y  )     -    L  y   -  1     L  x   u   -    L  y   -  1    N  u        u        c  x     d  x  y      superscript   subscript  L  y     1    ρ   x  y        superscript   subscript  L  y     1     subscript  L  x   u      superscript   subscript  L  y     1    N  u      u=c(x)+d(x)y+L_{y}^{-1}\rho(x,y)-L_{y}^{-1}L_{x}u-L_{y}^{-1}Nu     where: c ( x ), d ( x ) is obtained from the boundary conditions at y = - y l and y = y l :      u   (  y  =  -   y  l   )      fragments  u   fragments  normal-(  y     subscript  y  l   normal-)     \displaystyle u(y=-y_{l})     If we call the two respective solutions x-partial solution and y-partial solution , one of the most interesting consequences of the method is that the x-partial solution uses only the two boundary conditions (1-a) and the y-partial solution uses only the conditions (1-b).  Thus, one of the two sets of boundary functions { f 1 , f 2 } or { g 1 , g 2 } is redundant, and this implies that a partial differential equation with boundary conditions on a rectangle cannot have arbitrary boundary conditions on the borders, since the conditions at x = x 1 , x = x 2 must be consistent with those imposed at y = y 1 and y = y 2 .  An example to clarify this point is the solution of the Poisson problem with the following boundary conditions:      u   (  x  =  0  )      fragments  u   fragments  normal-(  x   0  normal-)     \displaystyle u(x=0)     By using Adomian's method and a symbolic processor (such as Mathematica or Maple ) it is easy to obtain the third order approximant to the solution. This approximant has an error lower than 5×10 −16 in any point, as it can be proved by substitution in the initial problem and by displaying the absolute value of the residual obtained as a function of ( x , y ). 7  The solution at y = -0.25 and y = 0.25 is given by specific functions that in this case are:        g  1    (  x  )    =       0.0520833   x   -    0.347222    x  3     +    9.25186  ×   10   -  17      x  4    +    0.833333    x  5     -    0.555556    x  6            subscript  g  1   x           0.0520833  x     0.347222   superscript  x  3         9.25186   superscript  10    17      superscript  x  4      0.833333   superscript  x  5       0.555556   superscript  x  6       g_{1}(x)=0.0520833\,x-0.347222\,x^{3}+9.25186\times 10^{-17}x^{4}+0.833333\,x^%
 {5}-0.555556\,x^{6}     and g 2 ( x ) = g 1 ( x ) respectively.  If a (double) integration is now performed in the y -direction using these two boundary functions the same solution will be obtained, which satisfy u ( x =0, y ) = 0 and u ( x =0.5, y ) = 0 and cannot satisfy any other condition on these borders.  Some people are surprised by these results; it seems strange that not all initial-boundary conditions must be explicitly used to solve a differential system. However, it is a well established fact that any elliptic equation has one and only one solution for any functional conditions in the four sides of a rectangle provided there is no discontinuity on the edges. The cause of the misconception is that scientists and engineers normally think in a boundary condition in terms of weak convergence in a Hilbert space (the distance to the boundary function is small enough to practical purposes). In contrast, Cauchy problems impose a point-to-point convergence to a given boundary function and to all its derivatives (and this is a quite strong condition!). For the first ones, a function satisfies a boundary condition when the area (or another functional distance) between it and the true function imposed in the boundary is so small as desired; for the second ones, however, the function must tend to the true function imposed in any and every point of the interval.  The commented Poisson problem does not have a solution for any functional boundary conditions f 1 , f 2 , g 1 , g 2 ; however, given f 1 , f 2 it is always possible to find boundary functions g 1 * , g 2 * so close to g 1 , g 2 as desired (in the weak convergence meaning) for which the problem has solution. This property makes it possible to solve Poisson's and many other problems with arbitrary boundary conditions but never for analytic functions exactly specified on the boundaries. The reader can convince himself (herself) of the high sensitivity of PDE solutions to small changes in the boundary conditions by solving this problem integrating along the x -direction, with boundary functions slightly different even though visually not distinguishable. For instance, the solution with the boundary conditions:        f   1  ,  2     (  y  )    =     0.00413682  -    0.0813801    y  2     +    0.260416    y  4     -    0.277778    y  6            subscript  f   1  2    y         0.00413682    0.0813801   superscript  y  2       0.260416   superscript  y  4       0.277778   superscript  y  6       f_{1,2}(y)=0.00413682-0.0813801\,y^{2}+0.260416\,y^{4}-0.277778\,y^{6}     at x = 0 and x = 0.5, and the solution with the boundary conditions:        f   1  ,  2     (  y  )    =  0.00413683         subscript  f   1  2    y   0.00413683    \displaystyle f_{1,2}(y)=0.00413683     at x = 0 and x = 0.5, produce lateral functions with different sign convexity even though both functions are visually not distinguishable.  Solutions of elliptic problems and other partial differential equations are highly sensitive to small changes in the boundary function imposed when only two sides are used. And this sensitivity is not easily compatible with models that are supposed to represent real systems, which are described by means of measurements containing experimental errors and are normally expressed as initial-boundary value problems in a Hilbert space.  Improvements to the decomposition method  At least three methods have been reported 8  9  10 to obtain the boundary functions g 1 * , g 2 * that are compatible with any lateral set of conditions { f 1 , f 2 } imposed. This makes it possible to find the analytical solution of any PDE boundary problem on a closed rectangle with the required accuracy, so allowing to solve a wide range of problems that the standard Adomian's method was not able to address.  The first one perturbs the two boundary functions imposed at x = 0 and x = x 1 (condition 1-a) with a N th-order polynomial in y : p 1 , p 2 in such a way that: f 1 ' = f 1 + p 1 , f 2 ' = f 2 + p 2 , where the norm of the two perturbation functions are smaller than the accuracy needed at the boundaries. These p 1 , p 2 depend on a set of polynomial coefficients c i , i = 1, ..., N . Then, the Adomian method is applied and functions are obtained at the four boundaries which depend on the set of c i , i = 1, ..., N . Finally, a boundary function F ( c 1 , c 2 , ..., c N ) is defined as the sum of these four functions, and the distance between F ( c 1 , c 2 , ..., c N ) and the real boundary functions ((1-a) and (1-b)) is minimized. The problem has been reduced, in this way, to the global minimization of the function F ( c 1 , c 2 , ..., c N ) which has a global minimum for some combination of the parameters c i , i = 1, ..., N . This minimum may be found by means of a genetic algorithm or by using some other optimization method, as the one proposed by Cherruault (1999). 11  A second method to obtain analytic approximants of initial-boundary problems is to combine Adomian decomposition with spectral methods. 12  Finally, the third method proposed by García-Olivares is based on imposing analytic solutions at the four boundaries, but modifying the original differential operator in such a way that it is different from the original one only in a narrow region close to the boundaries, and it forces the solution to satisfy exactly analytic conditions at the four boundaries. 13  Gallery    References    "  Category:Differential equations     ↩   1 ↩   2 ↩  ↩   ↩   [ http://www.emeraldinsight.com/journals.htm?articleid=1454508&show; ;=abstract] ↩   3 ↩  [DOI: 10.1108/03684920310463939] [ http://www.emeraldinsight.com/journals.htm?articleid=876024&show; ;=abstract] ↩  ↩       