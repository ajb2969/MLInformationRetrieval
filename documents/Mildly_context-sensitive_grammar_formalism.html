<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="1207">Mildly context-sensitive grammar formalism</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>Mildly context-sensitive grammar formalism</h1>
<hr/>

<p>In <a href="computational_linguistics" title="wikilink">computational linguistics</a>, the term <strong>mildly context-sensitive grammar formalisms</strong> refers to several <a href="grammar_formalism" title="wikilink">grammar formalisms</a> that have been developed with the ambition to provide <a href="linguistic_description" title="wikilink">adequate descriptions</a> of the <a href="syntactic_structure" title="wikilink">syntactic structure</a> of <a href="language" title="wikilink">natural language</a>.</p>

<p>Every mildly context-sensitive grammar formalism defines a class of <strong>mildly context-sensitive grammars</strong> (the grammars that can be specified in the formalism), and therefore also a class of <strong>mildly context-sensitive languages</strong> (the <a href="formal_language" title="wikilink">formal languages</a> generated by the grammars).</p>
<h2 id="background">Background</h2>

<p>By 1985, several researchers in descriptive and mathematical linguistics had provided evidence against the hypothesis that the syntactic structure of natural language can be adequately described by <a href="context-free_grammar" title="wikilink">context-free grammars</a>.<a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a><a class="footnoteRef" href="#fn2" id="fnref2"><sup>2</sup></a> At the same time, the step to the next level of the <a href="Chomsky_hierarchy" title="wikilink">Chomsky hierarchy</a>, to <a href="context-sensitive_grammar" title="wikilink">context-sensitive grammars</a>, appeared both unnecessary and undesirable. In an attempt to pinpoint the exact formal power required for the adequate description of natural language syntax, <a href="Aravind_Joshi" title="wikilink">Aravind Joshi</a> characterized ‚Äògrammars (and associated <a href="formal_language" title="wikilink">languages</a>) that are only slightly more powerful than context-free grammars (context-free languages)‚Äô.<a class="footnoteRef" href="#fn3" id="fnref3"><sup>3</sup></a> He called these grammars <em>mildly context-sensitive grammars</em> and the associated languages <em>mildly context-sensitive languages</em>.</p>

<p>Joshi‚Äôs characterization of mildly context-sensitive grammars was biased toward his work on <a href="tree-adjoining_grammar" title="wikilink">tree-adjoining grammar</a> (TAG). However, together with his students Vijay Shanker and David Weir, Joshi soon discovered that TAGs are equivalent, in terms of the generated string languages, to the independently introduced <a href="head_grammar" title="wikilink">head grammar</a> (HG).<a class="footnoteRef" href="#fn4" id="fnref4"><sup>4</sup></a> This was followed by two similar equivalence results, for <a href="linear_indexed_grammar" title="wikilink">linear indexed grammar</a> (LIG)<a class="footnoteRef" href="#fn5" id="fnref5"><sup>5</sup></a> and <a href="combinatory_categorial_grammar" title="wikilink">combinatory categorial grammar</a> (CCG),<a class="footnoteRef" href="#fn6" id="fnref6"><sup>6</sup></a> which showed that the notion of mildly context-sensitivity is a very general one and not tied to a specific formalism.</p>

<p>The TAG-equivalent formalisms were generalized by the introduction of <a href="linear_context-free_rewriting_system" title="wikilink">linear context-free rewriting systems</a> (LCFRS).<a class="footnoteRef" href="#fn7" id="fnref7"><sup>7</sup></a><a class="footnoteRef" href="#fn8" id="fnref8"><sup>8</sup></a> These grammars define an infinite hierarchy of string languages in between the context-free and the context-sensitive languages, with the languages generated by the TAG-equivalent formalisms at the lower end of the hierarchy. Independently of and almost simultaneously to LCFRS, Hiroyuki Seki et al. proposed the essentially identical formalism of multiple context-free grammar (MCFG).<a class="footnoteRef" href="#fn9" id="fnref9"><sup>9</sup></a> LCFRS/MCFG is sometimes regarded as the most general formalism for specifying mildly context-sensitive grammars. However, several authors have noted that some of the characteristic properties of the TAG-equivalent formalisms are not preserved by LCFRS/MCFG,<a class="footnoteRef" href="#fn10" id="fnref10"><sup>10</sup></a> and that there are languages that have the characteristic properties of mildly context-sensitivity but are not generated by LCFRS/MCFG.<a class="footnoteRef" href="#fn11" id="fnref11"><sup>11</sup></a></p>

<p>Recent years have seen increased interest in the restricted class of <em>well-nested</em> linear context-free rewriting systems/multiple context-free grammars,<a class="footnoteRef" href="#fn12" id="fnref12"><sup>12</sup></a><a class="footnoteRef" href="#fn13" id="fnref13"><sup>13</sup></a> which define a class of grammars that properly includes the TAG-equivalent formalisms but is properly included in the unrestricted LCFRS/MCFG hierarchy.</p>
<h2 id="characterization">Characterization</h2>

<p>Despite a considerable amount of work on the subject, there is no generally accepted formal definition of mildly context-sensitivity.</p>

<p>According to the original characterization by Joshi,<a class="footnoteRef" href="#fn14" id="fnref14"><sup>14</sup></a> a class of mildly context-sensitive grammars should have the following properties:</p>
<ol>
<li>limited <a href="cross-serial_dependencies" title="wikilink">cross-serial dependencies</a></li>
<li>constant growth</li>
<li>polynomial parsing</li>
</ol>

<p>In addition to these, it is understood that every class of mildly context-sensitive grammars should be able to generate all context-free languages.</p>

<p>Joshi‚Äôs characterization is not a formal definition. He notes:<a class="footnoteRef" href="#fn15" id="fnref15"><sup>15</sup></a> </p>

<p>Other authors have proposed alternative characterizations of mild context-sensitivity, some of which take the form of formal definitions. For example, Laura Kallmeyer<a class="footnoteRef" href="#fn16" id="fnref16"><sup>16</sup></a> takes the perspective that mild context-sensitivity should be defined as a property of classes of languages rather than, as in Joshi‚Äôs characterization, classes of grammars. Such a language-based definition leads to a different notion of the concept than Joshi‚Äôs.</p>
<h3 id="cross-serial-dependencies">Cross-serial dependencies</h3>

<p>The term <em><a href="cross-serial_dependencies" title="wikilink">cross-serial dependencies</a></em> refers to certain characteristic word ordering patterns, in particular to the verb‚Äìargument patterns observed in subordinate clauses in Dutch<a class="footnoteRef" href="#fn17" id="fnref17"><sup>17</sup></a> and Swiss German.<a class="footnoteRef" href="#fn18" id="fnref18"><sup>18</sup></a> These are the very patterns that can be used to argue against the context-freeness of natural language; thus requiring mildly context-sensitive grammars to model cross-serial dependencies means that these grammars must be more powerful than context-free grammars.</p>

<p>Kallmeyer<a class="footnoteRef" href="#fn19" id="fnref19"><sup>19</sup></a> identifies the ability to model cross-serial dependencies with the ability to generate the <em>copy language</em></p>

<p>

<math display="inline" id="Mildly_context-sensitive_grammar_formalism:0">
 <semantics>
  <mrow>
   <mi>ùê∂ùëÇùëÉùëå</mi>
   <mo>=</mo>
   <mrow>
    <mo rspace="4.2pt" stretchy="false">{</mo>
    <mrow>
     <mi>w</mi>
     <mi>w</mi>
    </mrow>
    <mo>‚à£</mo>
    <mrow>
     <mi>w</mi>
     <mo>‚àà</mo>
     <mpadded width="+1.7pt">
      <msup>
       <mrow>
        <mo stretchy="false">{</mo>
        <mi>a</mi>
        <mo>,</mo>
        <mi>b</mi>
        <mo stretchy="false">}</mo>
       </mrow>
       <mo>*</mo>
      </msup>
     </mpadded>
    </mrow>
    <mo stretchy="false">}</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <ci>ùê∂ùëÇùëÉùëå</ci>
    <apply>
     <csymbol cd="latexml">conditional-set</csymbol>
     <apply>
      <times></times>
      <ci>w</ci>
      <ci>w</ci>
     </apply>
     <apply>
      <in></in>
      <ci>w</ci>
      <apply>
       <csymbol cd="ambiguous">superscript</csymbol>
       <set>
        <ci>a</ci>
        <ci>b</ci>
       </set>
       <times></times>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \mathit{COPY}=\{\,ww\mid w\in\{a,b\}^{*}\,\}
  </annotation>
 </semantics>
</math>

</p>

<p>and its generalizations to two or more copies of¬†<em>w</em>, up to some bound. These languages are not context-free, which can be shown using the <a href="pumping_lemma_for_context-free_languages" title="wikilink">pumping lemma</a>.</p>
<h3 id="constant-growth">Constant growth</h3>

<p>A formal language is of <em>constant growth</em> if every string in the language is longer than the next shorter strings by at most a (language-specific) constant. Languages that violate this property are often considered to be beyond human capacity, although some authors have argued that certain phenomena in natural language do show a growth that cannot be bounded by a constant .<a class="footnoteRef" href="#fn20" id="fnref20"><sup>20</sup></a></p>

<p>Most mildly context-sensitive grammar formalisms (in particular, LCFRS/MCFG) actually satisfy a stronger property than constant growth called <em>semilinearity</em>.<a class="footnoteRef" href="#fn21" id="fnref21"><sup>21</sup></a> A language is semilinear if its image under the Parikh-mapping (the mapping that ‚Äòforgets‚Äô the relative position of the symbols in a string, effectively treating it as a bag of words) is a <a href="regular_language" title="wikilink">regular language</a>. All semilinear languages are of constant growth, but not every language with constant growth is semilinear.<a class="footnoteRef" href="#fn22" id="fnref22"><sup>22</sup></a></p>
<h3 id="polynomial-parsing">Polynomial parsing</h3>

<p>A grammar formalism is said to have <em>polynomial parsing</em> if its membership problem can be solved in <a href="PTIME" title="wikilink">deterministic polynomial time</a>. This is the problem to decide, given a grammar <em>G</em> written in the formalism and a string¬†<em>w</em>, whether <em>w</em> is generated by¬†<em>G</em> ‚Äì that is, whether <em>w</em> is ‚Äògrammatical‚Äô according to¬†<em>G</em>. The time complexity of this problem is measured in terms of the combined size of¬†<em>G</em> and¬†<em>w</em>.</p>

<p>Under the view on mild context-sensitivity as a property of classes of languages, <em>polynomial parsing</em> refers to the language membership problem. This is the problem to decide, for a fixed language¬†<em>L</em>, whether a given string¬†<em>w</em> belongs to¬†<em>L</em>. The time complexity of this problem is measured in terms of the length of¬†<em>w</em>; it ignores the question how <em>L</em> is specified.</p>

<p>Note that both understandings of <em>polynomial parsing</em> are idealizations in the sense that for practical applications one is interested not only in the yes/no question whether a sentence is grammatical, but also in the syntactic structure that the grammar assigns to the sentence.</p>
<h2 id="formalisms">Formalisms</h2>

<p>Over the years, a large number of grammar formalisms have been introduced that satisfy some or all of the characteristic properties put forth by Joshi. Several of them have alternative, automaton-based characterizations that are not discussed in this article; for example, the languages generated by tree-adjoining grammar can be characterized by <a href="embedded_pushdown_automaton" title="wikilink">embedded pushdown automata</a>.</p>
<h3 id="formalisms-equivalent-to-tag">Formalisms equivalent to TAG</h3>
<ul>
<li><a href="Tree-adjoining_grammar" title="wikilink">Tree-adjoining grammar</a> (TAG)<a class="footnoteRef" href="#fn23" id="fnref23"><sup>23</sup></a></li>
<li><a href="Head_grammar" title="wikilink">Head grammar</a> (HG)<a class="footnoteRef" href="#fn24" id="fnref24"><sup>24</sup></a><a class="footnoteRef" href="#fn25" id="fnref25"><sup>25</sup></a></li>
<li><a href="Linear_indexed_grammar" title="wikilink">Linear indexed grammar</a> (LIG)<a class="footnoteRef" href="#fn26" id="fnref26"><sup>26</sup></a></li>
<li><a href="Combinatory_categorial_grammar" title="wikilink">Combinatory categorial grammar</a> (CCG)<a class="footnoteRef" href="#fn27" id="fnref27"><sup>27</sup></a></li>
<li>Well-nested LCFRS/MCFG of fan-out¬†2</li>
</ul>
<h3 id="formalisms-equivalent-to-general-lcfrsmcfg">Formalisms equivalent to general LCFRS/MCFG</h3>
<ul>
<li><a href="Linear_context-free_rewriting_system" title="wikilink">Linear context-free rewriting systems</a> (LCFRS)<a class="footnoteRef" href="#fn28" id="fnref28"><sup>28</sup></a><a class="footnoteRef" href="#fn29" id="fnref29"><sup>29</sup></a></li>
<li>Multiple context-free grammars (MCFG)<a class="footnoteRef" href="#fn30" id="fnref30"><sup>30</sup></a></li>
<li>Multicomponent tree-adjoining grammars (MCTAG)<a class="footnoteRef" href="#fn31" id="fnref31"><sup>31</sup></a></li>
<li><a href="Minimalist_grammar" title="wikilink">Minimalist grammars</a> (MG)<a class="footnoteRef" href="#fn32" id="fnref32"><sup>32</sup></a></li>
<li>Simple (linear, non-erasing, non-combinatorial), positive <a href="range_concatenation_grammars" title="wikilink">range concatenation grammars</a> (sRCG)<a class="footnoteRef" href="#fn33" id="fnref33"><sup>33</sup></a></li>
</ul>
<h3 id="formalisms-equivalent-to-well-nested-lcfrsmcfg">Formalisms equivalent to well-nested LCFRS/MCFG</h3>
<ul>
<li>Non-duplicating macro grammars<a class="footnoteRef" href="#fn34" id="fnref34"><sup>34</sup></a></li>
<li>Coupled context-free grammars (CCFG)<a class="footnoteRef" href="#fn35" id="fnref35"><sup>35</sup></a></li>
<li>Well-nested linear context-free rewriting systems<a class="footnoteRef" href="#fn36" id="fnref36"><sup>36</sup></a></li>
<li>Well-nested multiple context-free grammars<a class="footnoteRef" href="#fn37" id="fnref37"><sup>37</sup></a></li>
</ul>
<h3 id="relations-among-the-formalisms">Relations among the formalisms</h3>

<p>Linear context-free rewriting systems/multiple context-free grammars form a two-dimensional hierarchy of generative power with respect to two grammar-specific parameters called <em>fan-out</em> and <em>rank</em>.<a class="footnoteRef" href="#fn38" id="fnref38"><sup>38</sup></a> More precisely, the languages generated by LCFRS/MCFG with fan-out¬†<em>f¬†‚â•¬†1</em> and rank¬†<em>r¬†‚â•¬†3</em> are properly included in the class of languages generated by LCFRS/MCFG with rank¬†<em>r¬†+¬†1</em> and fan-out¬†<em>f</em>, as well as the class of languages generated by LCFRS/MCFG with rank¬†<em>r</em> and fan-out¬†<em>f¬†+¬†1</em>. In the presence of well-nestedness, this hierarchy collapses to a one-dimensional hierarchy with respect to fan-out; this is because every well-nested LCFRS/MCFG can be transformed into an equivalent well-nested LCFRS/MCFG with the same fan-out and rank¬†2.<a class="footnoteRef" href="#fn39" id="fnref39"><sup>39</sup></a><a class="footnoteRef" href="#fn40" id="fnref40"><sup>40</sup></a> Within the LCFRS/MCFG hierarchy, the context-free languages can be characterized by the grammars with fan-out¬†1; for this fan-out there is no difference between general and well-nested grammars. The TAG-equivalent formalisms can be characterized as well-nested LCFRS/MCFG of fan-out¬†2.</p>
<h2 id="see-also">See also</h2>
<ul>
<li><a href="Tree-adjoining_grammar" title="wikilink">Tree-adjoining grammar</a></li>
<li><a href="Linear_context-free_rewriting_system" title="wikilink">Linear context-free rewriting system</a></li>
<li><a href="Range_concatenation_grammar" title="wikilink">Range concatenation grammar</a></li>
<li><a href="Weir_hierarchy" title="wikilink">Weir hierarchy</a></li>
</ul>
<h2 id="references">References</h2>
<references>
</references>

<p>"</p>

<p><a href="Category:Formal_languages" title="wikilink">Category:Formal languages</a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1">Riny Huybregts. The Weak Inadequacy of Context-Free Phrase Structure Grammars. In Ger de Haan, Mieke Trommelen, and Wim Zonneveld, editors, <em>Van periferie naar kern</em>, pages 81‚Äì99. Foris, Dordrecht, The Netherlands, 1984.<a href="#fnref1">‚Ü©</a></li>
<li id="fn2">Stuart M. Shieber. Evidence Against the Context-Freeness of Natural Language. <em>Linguistics and Philosophy</em>, 8(3):333‚Äì343, 1985.<a href="#fnref2">‚Ü©</a></li>
<li id="fn3">Aravind K. Joshi. Tree Adjoining Grammars: How Much Context-Sensitivity Is Required to Provide Reasonable Structural Descriptions?. In David R. Dowty, Lauri Karttunen, and Arnold M. Zwicky, editors, <em>Natural Language Parsing</em>, pages 206‚Äì250. Cambridge University Press, 1985.<a href="#fnref3">‚Ü©</a></li>
<li id="fn4">David J. Weir, K. Vijay-Shanker, and Aravind K. Joshi. The Relationship Between Tree Adjoining Grammars and Head Grammars. In <em>Proceedings of the 24th Annual Meeting of the Association for Computational Linguistics (ACL)</em>, pages 67‚Äì74, New York, USA, 1986.<a href="#fnref4">‚Ü©</a></li>
<li id="fn5">K. Vijay-Shanker. A Study of Tree Adjoining Grammars. Ph.D. thesis, University of Pennsylvania, Philadelphia, USA, 1987.<a href="#fnref5">‚Ü©</a></li>
<li id="fn6">David J. Weir and Aravind K. Joshi. Combinatory Categorial Grammars: Generative Power and Relationship to Linear Context-Free Rewriting Systems. In <em>Proceedings of the 26th Annual Meeting of the Association for Computational Linguistics (ACL)</em>, pages 278‚Äì285, Buffalo, USA, 1988.<a href="#fnref6">‚Ü©</a></li>
<li id="fn7">K. Vijay-Shanker, David J. Weir, and Aravind K. Joshi. Characterizing Structural Descriptions Produced by Various Grammatical Formalisms. In <em>Proceedings of the 25th Annual Meeting of the Association for Computational Linguistics (ACL)</em>, pages 104‚Äì111, Stanford, CA, USA, 1987.<a href="#fnref7">‚Ü©</a></li>
<li id="fn8">David J. Weir. Characterizing Mildly Context-Sensitive Grammar Formalisms. Ph.D. thesis, University of Pennsylvania, Philadelphia, USA, 1988.<a href="#fnref8">‚Ü©</a></li>
<li id="fn9">Hiroyuki Seki, Takashi Matsumura, Mamoru Fujii, and Tadao Kasami. On Multiple Context-Free Grammars. <em>Theoretical Computer Science</em>, 88(2):191‚Äì229, 1991.<a href="#fnref9">‚Ü©</a></li>
<li id="fn10">Makoto Kanazawa. The Pumping Lemma for Well-Nested Multiple Context-Free Languages. In <em>Developments in Language Theory. 13th International Conference, DLT 2009, Stuttgart, Germany, June 30‚ÄìJuly 3, 2009. Proceedings</em>, volume 5583 of <em>Lecture Notes in Computer Science</em>, pages 312‚Äì325, 2009.<a href="#fnref10">‚Ü©</a></li>
<li id="fn11">Laura Kallmeyer. On Mildly Context-Sensitive Non-Linear Rewriting. <em>Research on Language and Computation</em>, 8(4):341‚Äì363, 2010.<a href="#fnref11">‚Ü©</a></li>
<li id="fn12"></li>
<li id="fn13">Carlos G√≥mez-Rodr√≠guez, Marco Kuhlmann, and Giorgio Satta. Efficient Parsing of Well-Nested Linear Context-Free Rewriting Systems. In <em>Proceedings of Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL)</em>, pages 276‚Äì284, Los Angeles, USA, 2010.<a href="#fnref13">‚Ü©</a></li>
<li id="fn14"></li>
<li id="fn15"></li>
<li id="fn16">Laura Kallmeyer. <em>Parsing Beyond Context-Free Grammars</em>. Springer, 2010.<a href="#fnref16">‚Ü©</a></li>
<li id="fn17"></li>
<li id="fn18"></li>
<li id="fn19"></li>
<li id="fn20">Jens Michaelis and Marcus Kracht. Semilinearity as a Syntactic Invariant. In <em>Logical Aspects of Computational Linguistics. First International Conference, LACL 1996, Nancy, France, September 23‚Äì25, 1996. Selected Papers</em>, volume 1328 of <em>Lecture Notes in Computer Science</em>, pages 329‚Äì345. Springer, 1997.<a href="#fnref20">‚Ü©</a></li>
<li id="fn21"></li>
<li id="fn22"></li>
<li id="fn23"></li>
<li id="fn24">Carl J. Pollard. Generalized Phrase Structure Grammars, Head Grammars, and Natural Language. Ph.D. thesis, Stanford University, 1984.<a href="#fnref24">‚Ü©</a></li>
<li id="fn25">Kelly Roach. Formal Properties of Head Grammars. In Alexis Manaster-Ramer, editor, <em>Mathematics of Language</em>, pages 293‚Äì347. John Benjamins, 1987.<a href="#fnref25">‚Ü©</a></li>
<li id="fn26">Gerald Gazdar. Applicability of Indexed Grammars to Natural Language. In Uwe Reyle and Christian Rohrer, editors, <em>Natural Language Parsing and Linguistic Theories</em>, pages 69‚Äì94. D. Reidel, 1987.<a href="#fnref26">‚Ü©</a></li>
<li id="fn27"></li>
<li id="fn28"></li>
<li id="fn29"></li>
<li id="fn30"></li>
<li id="fn31"></li>
<li id="fn32">Jens Michaelis. Derivational Minimalism Is Mildly Context-Sensitive. In <em>Logical Aspects of Computational Linguistics, Third International Conference, LACL 1998, Grenoble, France, December 14‚Äì16, 1998, Selected Papers</em>, volume 2014 of <em>Lecture Notes in Computer Science</em>, pages 179‚Äì198. Springer, 1998.<a href="#fnref32">‚Ü©</a></li>
<li id="fn33">Pierre Boullier. Range Concatenation Grammars. In Harry C. Bunt, John Carroll, and Giorgio Satta, editors, <em>New Developments in Parsing Technology</em>, volume 23 of <em>Text, Speech and Language Technology</em>, pages 269‚Äì289. Kluwer Academic Publishers, 2004.<a href="#fnref33">‚Ü©</a></li>
<li id="fn34">Michael J. Fischer. Grammars with Macro-Like Productions. In <em>Ninth Annual Symposium on Switching and Automata Theory</em>, pages 131‚Äì142, Schenectady, NY, USA, 1968.<a href="#fnref34">‚Ü©</a></li>
<li id="fn35">G√ºnter Hotz and Gisela Pitsch. On Parsing Coupled-Context-Free Languages. <em>Theoretical Computer Science</em>, 161(1‚Äì2):205‚Äì233, 1996.<a href="#fnref35">‚Ü©</a></li>
<li id="fn36"></li>
<li id="fn37"></li>
<li id="fn38">Owen Rambow and Giorgio Satta. A Two-Dimensional Hierarchy for Parallel Rewriting Systems. Technical Report IRCS-94-02, University of Pennsylvania, Philadelphia, USA, 1994.<a href="#fnref38">‚Ü©</a></li>
<li id="fn39"></li>
<li id="fn40"></li>
</ol>
</section>
</body>
</html>
