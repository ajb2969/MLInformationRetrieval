   Particle filter      Particle filter   Particle filters or Sequential Monte Carlo (SMC) methods are a set of genetic -type particle Monte Carlo methodologies to solve the filtering problem . The term "particle filters" was first coined in 1996 by Del Moral 1 in reference to mean field interacting particle methods used in fluid mechanics since the beginning of the 1960s. The terminology "sequential Monte Carlo" was proposed by Liu and Chen in 1998.  From the statistical and probabilistic point of view, particle filters can be interpreted as mean field particle interpretations of Feynman-Kac probability measures. 2 3 4 5 6 These particle integration techniques were developed in molecular chemistry and computational physics by Theodore E. Harris and Herman Kahn in 1951, Marshall. N. Rosenbluth and Arianna. W. Rosenbluth in 1955 7 and more recently by Jack H. Hetherington in 1984. 8 In computational physics, these Feynman-Kac type path particle integration methods are also used in Quantum Monte Carlo , and more specifically Diffusion Monte Carlo methods . 9 10 11 Feynman-Kac interacting particle methods are also strongly related to mutation-selection genetic algorithms currently used in evolutionary computing to solve complex optimization problems.  The particle filter methodology is used to solve Hidden Markov Chain (HMM) and nonlinear filtering problems arising in signal processing and Bayesian statistical inference . The filtering problem consists in estimating the internal states in dynamical systems when partial observations are made, and random perturbations are present in the sensors as well as in the dynamical system. The objective is to compute the conditional probability (a.k.a. posterior distributions) of the states of some Markov process , given some noisy and partial observations. With the notable exception of linear-Gaussian signal-observation models ( Kalman filter) or wider classes of models (Benes filter 12 ) Mireille Chaleyat-Maurel and Dominique Michel proved in 1984 that the sequence of posterior distributions of the random states of the signal given the observations (a.k.a. optimal filter) have no finitely recursive recursion. 13 Various numerical methods based on fixed grid approximations, Markov Chain Monte Carlo techniques (MCMC), conventional linearization, extended Kalman filters , or determining the best linear system (in expect cost-error sense) have never really coped with large scale systems, unstable processes or when the nonlinearities are not sufficiently smooth.  Particle filtering methodology uses a genetic type mutation-selection sampling approach, with a set of particles (also called individuals, or samples) to represent the posterior distribution of some stochastic process given some noisy and/or partial observations. The state-space model can be nonlinear and the initial state and noise distributions can take any form required. Particle filter techniques provide a well-established methodology 14 15 16 for generating samples from the required distribution without requiring assumptions about the state-space model or the state distributions. However, these methods do not perform well when applied to very high-dimensional systems.  Particle filters implement the prediction-updating transitions of the filtering equation directly by using a genetic type mutation-selection particle algorithm. The samples from the distribution are represented by a set of particles; each particle has a likelihood weight assigned to it that represents the probability of that particle being sampled from the probability density function. Weight disparity leading to weight collapse is a common issue encountered in these filtering algorithms; however it can be mitigated by including a resampling step before the weights become too uneven. Several adaptive resampling criteria can be used, including the variance of the weights and the relative entropy w.r.t. the uniform distribution. 17 In the resampling step, the particles with negligible weights are replaced by new particles in the proximity of the particles with higher weights.  Particle filters and Feynman-Kac particle methodologies find application in signal and image processing,  Bayesian inference , machine learning , risk analysis and rare event sampling,  engineering  and robotics , artificial intelligence , bioinformatics , phylogenetics , computational science , Economics  and  mathematical finance , molecular chemistry , computational physics , pharmacokinetic and other fields.  History  Heuristic like algorithms  From the statistical and probabilistic viewpoint, particle filters belong to the class of branching / genetic type algorithms , and mean field type interacting particle methodologies. The interpretations of these particle methods depends on the scientific discipline. In Evolutionary Computing , m ean field genetic type particle methodologies are often used as a heuristic and natural search algorithms (a.k.a. Metaheuristic ). In computational physics and molecular chemistry they are used to solve Feynman-Kac path integration problems, or the compute Boltzmann-Gibbs measures, top eigenvalues and ground states of Schrödinger operators. In Biology and Genetics they also represent the evolution of a population of individuals or genes in some environment.  The origins of mean field type evolutionary computational techniques can be traced to 1950 and 1954 with the seminal work of Alan Turing on genetic type mutation-selection learning machines 18 and the articles by Nils Aall Barricelli at the Institute for Advanced Study in Princeton, New Jersey . 19 20 The first trace of particle filters in statistical methodology dates back to the mid-50's; the 'Poor Man's Monte Carlo', 21 that was proposed by Hammersley et al., in 1954, contained hints of the genetic type particle filtering methods used today. In 1963, Nils Aall Barricelli simulated a genetic type algorithm to mimic the ability of individuals to play a simple game. 22 In evolutionary computing literature, genetic type mutation-selection algorithms became popular through the seminal work of John Holland in the early 1970s, and particularly his book 23 published in 1975.  In Biology and Genetics, the Australian geneticist Alex Fraser also published in 1957 a series of papers on the genetic type simulation of artificial selection of organisms. 24 The computer simulation of evolution by biologists became more common in the early 1960s, and the methods were described in books by Fraser and Burnell (1970) 25 and Crosby (1973). 26 Fraser's simulations included all of the essential elements of modern mutation-selection genetic particle algorithms.  From the mathematical viewpoint, the conditional distribution of the random states of a signal given some partial and noisy observations is described by a Feynman-Kac probability on the random trajectories of the signal weighted by a sequence of likelihood potential functions. 27 28  Quantum Monte Carlo , and more specifically Diffusion Monte Carlo methods can also be interpreted as a mean field genetic type particle approximation of Feynman-Kac path integrals. 29 30 31 32 33 34 35 The origins of Quantum Monte Carlo methods are often attributed to Enrico Fermi and Robert Richtmyer who developed in 1948 a mean field particle interpretation of neutron-chain reactions, 36 but the first heuristic-like and genetic type particle algorithm (a.k.a. Resampled or Reconfiguration Monte Carlo methods) for estimating ground state energies of quantum systems (in reduced matrix models) is due to Jack H. Hetherington in 1984. 37 We also quote an earlier seminal works of Theodore E. Harris and Herman Kahn in particle physics, published in 1951, using mean field but heuristic-like genetic methods for estimating particle transmission energies. 38 In molecular chemistry, the use of genetic heuristic-like particle methodologies (a.k.a. pruning and enrichment strategies) can be traced back to 1955 with the seminal work of Marshall. N. Rosenbluth and Arianna. W. Rosenbluth. 39 The use of genetic particle algorithms in advanced signal processing and Bayesian inference is more recent. It was in 1993, that Gordon et al., published in their seminal work 40 the first application of genetic type algorithm in Bayesian statistical inference. The authors named their algorithm 'the bootstrap filter', and demonstrated that compared to other filtering methods, their bootstrap algorithm does not require any assumption about that state-space or the noise of the system. We also quote another pioneering article in this field of Genshiro Kitagawa on a related "Monte Carlo filter", 41 and the ones by Pierre Del Moral 42 and Himilcon Carvalho, Pierre Del Moral, André Monin and Gérard Salut 43 on particle filters published in the mid-1990s. Particle filters were also developed in signal processing in the early 1989-1992 by P. Del Moral, J.C. Noyer, G. Rigal, and G. Salut in the LAAS-CNRS in a series of restricted and classified research reports with STCAN (Service Technique des Constructions et Armes Navales), the IT company DIGILOG, and the LAAS-CNRS (the Laboratory for Analysis and Architecture of Systems) on RADAR/SONAR and GPS signal processing problems. 44 45 46 47 48 49  Mathematical foundations  From 1950 to 1996, all the publications on particle filters, genetic algorithms, including the pruning and resample Monte Carlo methods introduced in computational physics and molecular chemistry, present natural and heuristic-like algorithms applied to different situations without a single proof of their consistency, nor a discussion on the bias of the estimates and on genealogical and ancestral tree based algorithms.  The mathematical foundations and the first rigorous analysis of these particle algorithms are due to Pierre Del Moral 50 51 in 1996. The article 52 also contains a proof of the unbiased properties of a particle approximations of likelihood functions and unnormalized conditional probability measures. The unbiased particle estimator of the likelihood functions presented in this article is currently used today in Bayesian statistical inference.  Branching type particle methodologies with varying population sizes were also developed in the end of the 1990s by Dan Crisan, Jessica Gaines and Terry Lyons, 53 54 55 and by Dan Crisan, Pierre Del Moral and Terry Lyons. 56 Further developments in this field were developed in 2000 by P. Del Moral, A. Guionnet and L. Miclo. 57 58 59 The first central limit theorems are due to Pierre Del Moral and Alice Guionnet 60 in 1999 and Pierre Del Moral and Laurent Miclo 61 in 2000. The first uniform convergence results with respect to the time parameter for particle filters were developed in the end of the 1990s by Pierre Del Moral and Alice Guionnet. 62 63 The first rigorous analysis of genealogical tree based particle filter smoothers is due to P. Del Moral and L. Miclo in 2001 64  The theory on Feynman-Kac particle methodologies and related particle filters algorithms has been developed in 2000 and 2004 in the books. 65 66 These abstract probabilistic models encapsulate genetic type algorithms, particle and bootstrap filters, interacting Kalman filters (a.k.a. Rao–Blackwellized particle filter 67 ), importance sampling and resampling style particle filter techniques, including genealogical tree based and particle backward methodologies for solving filtering and smoothing problems. Other classes of particle filtering methodologies includes genealogical tree based models, 68 69 70 backward Markov particle models, 71 72 adaptive mean field particle models, 73 island type particle models, 74 75 and particle Markov chain Monte Carlo methodologies. 76 77  The filtering problem  Objective  The objective of a particle filter is to estimate the posterior density of the state variables given the observation variables. The particle filter is designed for a hidden Markov Model , where the system consists of hidden and observable variables. The observable variables (observation process) are related to the hidden variables (state-process) by some functional form that is known. Similarly the dynamical system describing the evolution of the state variables is also known probabilistically.  A generic particle filter estimates the posterior distribution of the hidden states using the observation measurement process. Consider a state-space shown in the diagram below.         X  0     →     X   ;  1      →     X   ;  2      →     X   ;  3      →    …    signal      ↓     ↓     ↓     ↓     …        Y  0       Y   ;  1        Y   ;  2        Y   ;  3       …    observation         subscript  X  0   normal-→   fragments  X   subscript  normal-;  1    normal-→   fragments  X   subscript  normal-;  2    normal-→   fragments  X   subscript  normal-;  3    normal-→  normal-…  signal    normal-↓   missing-subexpression   normal-↓   missing-subexpression   normal-↓   missing-subexpression   normal-↓   missing-subexpression   normal-…   missing-subexpression      subscript  Y  0    missing-subexpression    fragments  Y   subscript  normal-;  1     missing-subexpression    fragments  Y   subscript  normal-;  2     missing-subexpression    fragments  Y   subscript  normal-;  3     missing-subexpression   normal-…  observation     \begin{array}[]{cccccccccc}X_{0}&\rightarrow&X_{1}&\rightarrow&X_{2}&%
 \rightarrow&X_{3}&\rightarrow&\ldots&\mbox{signal}\\
 \downarrow&&\downarrow&&\downarrow&&\downarrow&&\ldots&\\
 Y_{0}&&Y_{1}&&Y_{2}&&Y_{3}&&\ldots&\mbox{observation}\end{array}     The filtering problem is to estimate sequentially the values of the hidden states    X  k     subscript  X  k    X_{k}   , given the values of the observation process       Y  0   ,  …  ,    Y  k     ,      subscript  Y  0   normal-…   subscript  Y  k     Y_{0},\ldots,Y_{k}~{},   at any time step k.  All Bayesian estimates of    X  k     subscript  X  k    X_{k}   follow from the posterior density  p ( x k | y 0 , y 1 ,…, y k ). The particle filter methodology provides an approximation of these conditional probabilities using the empirical measure associated with a genetic type particle algorithm . In contrast, the MCMC or importance sampling approach would model the full posterior p ( x 0 , x 1 ,…, x k | y 0 , y 1 ,…, y k ).  An illustration in Tracking and RADAR processing  In a 3d-simplified Singer's tracking model 78 the target is represented by a Markov chain with 3 coordinates     X  n   =   (      X  n   (  1  )         X  n   (  2  )         X  n   (  3  )       )        subscript  X  n      subscript   superscript  X  1   n      subscript   superscript  X  2   n      subscript   superscript  X  3   n       X_{n}=\left(\begin{array}[]{c}X^{(1)}_{n}\\
 X^{(2)}_{n}\\
 X^{(3)}_{n}\end{array}\right)     The first coordinate    X  n   (  1  )      subscript   superscript  X  1   n    X^{(1)}_{n}   represents the acceleration of the target at time   n   n   n   , the second and the third     X  n   (  2  )    ,   X  n   (  3  )        subscript   superscript  X  2   n    subscript   superscript  X  3   n     X^{(2)}_{n},~{}X^{(3)}_{n}   stands for the speed and the position of the target at time .  The maneuver equation are often derived from a time discretization of a continuous time model given by the equations      {      X  n   (  1  )      =     X   ;   n  -  1    (  1  )    +    ϵ  n     W  n         X  n   (  2  )      =       (   1  -    α   Δ    )    X   n  -  1    (  2  )     +    β    Δ    X  n   (  1  )           X  n   (  3  )      =     X   ;   n  -  1    (  3  )    +   Δ    X  n   (  2  )            cases     superscript   subscript  X  n   1     fragments  X   superscript   subscript  normal-;    n  1    1     subscript  ϵ  n    subscript  W  n       superscript   subscript  X  n   2          1    α  normal-Δ     superscript   subscript  X    n  1    2      β  normal-Δ   superscript   subscript  X  n   1        superscript   subscript  X  n   3     fragments  X   superscript   subscript  normal-;    n  1    3    Δ   superscript   subscript  X  n   2        \left\{\begin{array}[]{rcl}X_{n}^{(1)}&=&X_{n-1}^{(1)}+\epsilon_{n}~{}W_{n}\\
 X_{n}^{(2)}&=&(1-\alpha~{}\Delta)~{}X_{n-1}^{(2)}+\beta~{}\Delta~{}X_{n}^{(1)}%
 \\
 X_{n}^{(3)}&=&X_{n-1}^{(3)}+\Delta~{}X_{n}^{(2)}\end{array}\right.   for some viscosity coefficients     α  ,   β    >  0       α  β   0    \alpha,~{}\beta~{}>0   , some time step    Δ  >  0      normal-Δ  0    \Delta>0   . In the above display, the unknown acceleration jump times are modeled by a sequence of independent and identically distributed    {  0  ,  1  }     0  1    \{0,1\}   -valued Bernoulli variables    ϵ  n     subscript  ϵ  n    \epsilon_{n}   . The unknown speed-up changes are modeled by a sequence of independent and identically distributed variables    W  n     subscript  W  n    W_{n}   . The RADAR sensor delivers at each time step some noisy information on the position of the target. This observation model is given the equation        ∀  n   ≥  0     Y  n   =    X  n   (  3  )    +    Δ    V  n         formulae-sequence     for-all  n   0      subscript  Y  n      superscript   subscript  X  n   3     normal-Δ   subscript  V  n        \forall n\geq 0\,\qquad Y_{n}=X_{n}^{(3)}+\Delta~{}V_{n}   The random perturbations of the sensors coming from the thermic noise of the uncertainty of the model are represented by a sequence of independent random variable    V  n     subscript  V  n    V_{n}   with a prescribed probability density. The objective of the filtering problem consists of computing sequentially the conditional distribution of the signal     X  n      subscript  X  n    X_{n}~{}   given an observation sequence      Y  0   =    y  0   ,  …    ,    Y  n   =    y  n        formulae-sequence     subscript  Y  0     subscript  y  0   normal-…       subscript  Y  n    subscript  y  n      Y_{0}=y_{0},\ldots,Y_{n}=y_{n}~{}   , at any time step    n  .    n   n.   A more complex problem is to compute the conditional distribution of the random paths of the signal    (   X  0   ,  …  ,   X  n   )      subscript  X  0   normal-…   subscript  X  n     (X_{0},\ldots,X_{n})~{}   given an observation sequence      Y  0   =    y  0   ,  …    ,    Y  n   =    y  n        formulae-sequence     subscript  Y  0     subscript  y  0   normal-…       subscript  Y  n    subscript  y  n      Y_{0}=y_{0},\ldots,Y_{n}=y_{n}~{}   , at any time step    n  .    n   n.   In filtering literature, these state estimation problems can be given different names:   The optimal filter is the conditional probability distribution of the signal     X  n      subscript  X  n    X_{n}~{}   given the observation sequence      Y  0   =    y  0   ,  …    ,     Y   n  -  1    =   y   n  -  1     ,    Y  n   =    y  n         formulae-sequence     subscript  Y  0     subscript  y  0   normal-…     formulae-sequence     subscript  Y    n  1     subscript  y    n  1        subscript  Y  n    subscript  y  n       Y_{0}=y_{0},\ldots,Y_{n-1}=y_{n-1},Y_{n}=y_{n}~{}   .  The one step optimal predictor is the conditional probability distribution of the signal     X  n      subscript  X  n    X_{n}~{}   given the observation sequence      Y  0   =    y  0   ,  …    ,    Y   n  -  1    =   y   n  -  1        formulae-sequence     subscript  Y  0     subscript  y  0   normal-…       subscript  Y    n  1     subscript  y    n  1       Y_{0}=y_{0},\ldots,Y_{n-1}=y_{n-1}   .  The smoothing problem consists of estimating the conditional probability distribution of the signal     X  n      subscript  X  n    X_{n}~{}   given the observation sequence      Y  0   =    y  0   ,  …  ,   Y  n     :     y  n   ,  …  ,   Y  m    =   y  m       normal-:     subscript  Y  0     subscript  y  0   normal-…   subscript  Y  n         subscript  y  n   normal-…   subscript  Y  m     subscript  y  m      Y_{0}=y_{0},\ldots,Y_{n}:y_{n},\ldots,Y_{m}=y_{m}   , for some    m  >  n      m  n    m>n   .   The Signal-Observation Model  Particle methods often assume    X  k     subscript  X  k    X_{k}   and the observations    Y  k     subscript  Y  k    Y_{k}   can be modeled in this form:        X  0   ,   X  1   ,  …      subscript  X  0    subscript  X  1   normal-…    X_{0},X_{1},\ldots   is a Markov process on    ℝ   d  x      superscript  ℝ   subscript  d  x     \mathbb{R}^{d_{x}}   (for some     d  x   ≥  1       subscript  d  x   1    d_{x}\geq 1   ) that evolves according to the transition probability density    p   (   x  k   |   x   k  -  1    )      fragments  p   fragments  normal-(   subscript  x  k   normal-|   subscript  x    k  1    normal-)     p(x_{k}|x_{k-1})   . This model is also often written in a synthetic way as       X  k   |   X   k  -  1    =   x   k  -  1    ∼  p   (   x  k   |   x   k  -  1    )      fragments   subscript  X  k   normal-|   subscript  X    k  1      subscript  x    k  1    similar-to  p   fragments  normal-(   subscript  x  k   normal-|   subscript  x    k  1    normal-)     X_{k}|X_{k-1}=x_{k-1}\sim p(x_{k}|x_{k-1})   with an initial probability density    p   (   x  0   )       p   subscript  x  0     p(x_{0})   .     The observations     Y  0   ,   Y  1   ,  …      subscript  Y  0    subscript  Y  1   normal-…    Y_{0},Y_{1},\ldots   take values in some state space on    ℝ   d  y      superscript  ℝ   subscript  d  y     \mathbb{R}^{d_{y}}   (for some     d  y   ≥  1       subscript  d  y   1    d_{y}\geq 1   ) are conditionally independent provided that     X  0   ,   X  1   ,  …      subscript  X  0    subscript  X  1   normal-…    X_{0},X_{1},\ldots   are known. In other words, each    Y  k     subscript  Y  k    Y_{k}   only depends on    X  k     subscript  X  k    X_{k}   . In addition, we assume conditional distribution for    Y  k     subscript  Y  k    Y_{k}   given     X  k   =   x  k        subscript  X  k    subscript  x  k     X_{k}=x_{k}   are absolutely continuous, and in a synthetic way we have       Y  k   |   X  k   =   x  k   ∼  p   (   y  k   |   x  k   )      fragments   subscript  Y  k   normal-|   subscript  X  k     subscript  x  k   similar-to  p   fragments  normal-(   subscript  y  k   normal-|   subscript  x  k   normal-)     Y_{k}|X_{k}=x_{k}\sim p(y_{k}|x_{k})      An example of system with these properties is:       X  k   =    g   (   X   k  -  1    )    +    W  k          subscript  X  k       g   subscript  X    k  1      subscript  W  k      X_{k}=g(X_{k-1})+W_{k}\,          Y  k   =    h   (   X  k   )    +    V  k          subscript  Y  k       h   subscript  X  k     subscript  V  k      Y_{k}=h(X_{k})+V_{k}\,     where both    W  k     subscript  W  k    W_{k}   and    V  k     subscript  V  k    V_{k}   are mutually independent sequences with known probability density functions and    g   (  ⋅  )       g  normal-⋅    g(\cdot)   and    h   (  ⋅  )       h  normal-⋅    h(\cdot)   are known functions. These two equations can be viewed as state space equations and look similar to the state space equations for the Kalman filter. If the functions    g   (  ⋅  )       g  normal-⋅    g(\cdot)   and    h   (  ⋅  )       h  normal-⋅    h(\cdot)   in the above example are linear, and if both    W  k     subscript  W  k    W_{k}   and    V  k     subscript  V  k    V_{k}   are Gaussian , the Kalman filter finds the exact Bayesian filtering distribution. If not, Kalman filter based methods are a first-order approximation ( EKF ) or a second-order approximation (UKF in general, but if probability distribution is Gaussian a third-order approximation is possible).  The assumption that the initial distribution and the transitions of the Markov chain are absolutely continuous with respect to the Lebesgue measure can be relaxed.  To design a particle filter we simply need to assume that we can sample the transitions      X   k  -  1     →   X  k      normal-→   subscript  X    k  1     subscript  X  k     X_{k-1}~{}\rightarrow~{}X_{k}   of the Markov chain     X  k   ,     subscript  X  k    X_{k},   and to compute the likelihood function     x  k   ↦  p   (   y  k   |   x  k   )      fragments   subscript  x  k   maps-to  p   fragments  normal-(   subscript  y  k   normal-|   subscript  x  k   normal-)     x_{k}\mapsto p(y_{k}|x_{k})   (see for instance the genetic selection mutation description of the particle filter given below). The absolutely continuous assumption on the Markov transitions of    X  k     subscript  X  k    X_{k}   are only used to derive in an informal (and rather abusive) way different formulae between posterior distributions using the Bayes' rule for conditional densities.  Approximate Bayesian Computation models  In some important problems, the conditional distribution of the observations given the random states of the signal may fail to have a density or may be impossible or too complex to compute. In this situation, we need to resort to an additional level of approximation. One strategy is to replace the signal    X  k     subscript  X  k    X_{k}   by the Markov chain     𝒳  k   =   (   X  k   ,   Y  k   )        subscript  𝒳  k     subscript  X  k    subscript  Y  k      \mathcal{X}_{k}=\left(X_{k},Y_{k}\right)   and to introduce a virtual observation of the form        𝒴  k   =     Y  k   +    ϵ    𝒱  k     for some parameter     ϵ  ∈   [  0  ,  1  ]       formulae-sequence     subscript  𝒴  k       subscript  Y  k     ϵ   subscript  𝒱  k     for some parameter      ϵ   0  1      \mathcal{Y}_{k}=Y_{k}+\epsilon~{}\mathcal{V}_{k}\quad\mbox{for some parameter}%
 \quad\epsilon\in[0,1]     for some sequence of independent sequences with known probability density functions . The central idea is to observe that      Law   (    X  k    |   𝒴  0   =   y  0   ,  …  ,   𝒴  k   =   y  k   )     ≈   ϵ  ↓  0     Law   (    X  k    |   Y  0   =   y  0   ,  …  ,   Y  k   =   y  k   )      fragments  Law   fragments  normal-(   subscript  X  k   normal-|   subscript  𝒴  0     subscript  y  0   normal-,  normal-…  normal-,   subscript  𝒴  k     subscript  y  k   normal-)    subscript    normal-↓  ϵ  0    Law   fragments  normal-(   subscript  X  k   normal-|   subscript  Y  0     subscript  y  0   normal-,  normal-…  normal-,   subscript  Y  k     subscript  y  k   normal-)     \mbox{Law}\left(X_{k}~{}|~{}\mathcal{Y}_{0}=y_{0},\ldots,\mathcal{Y}_{k}=y_{k}%
 \right)\approx_{\epsilon\downarrow 0}~{}\mbox{Law}\left(X_{k}~{}|~{}Y_{0}=y_{0%
 },\ldots,Y_{k}=y_{k}\right)   The particle filter associated with the Markov process     𝒳  k   =   (   X  k   ,   Y  k   )        subscript  𝒳  k     subscript  X  k    subscript  Y  k      \mathcal{X}_{k}=\left(X_{k},Y_{k}\right)   given the partial observations      𝒴  0   =    y  0   ,  …    ,    𝒴  k   =   y  k       formulae-sequence     subscript  𝒴  0     subscript  y  0   normal-…       subscript  𝒴  k    subscript  y  k      \mathcal{Y}_{0}=y_{0},\ldots,\mathcal{Y}_{k}=y_{k}   , is defined in terms of particles evolving in    ℝ    d  x   +   d  y       superscript  ℝ     subscript  d  x    subscript  d  y      \mathbb{R}^{d_{x}+d_{y}}   with a likelihood function given with some obvious abusive notation by    p   (    𝒴  k    |   𝒳  k   )      fragments  p   fragments  normal-(   subscript  𝒴  k   normal-|   subscript  𝒳  k   normal-)     p(\mathcal{Y}_{k}~{}|~{}\mathcal{X}_{k})   . These probabilistic techniques are closely related to Approximate Bayesian Computation (ABC). In the context of particle filters, these ABC particle filtering techniques were introduced in 1998 by P. Del Moral, J. Jacod and P. Protter in the article. 79 They were further developed by P. Del Moral, A. Doucet and A. Jasra. 80 81  The nonlinear filtering equation  The conditional probability densities p ( x 0 , x 1 ,…, x k | y 0 , y 1 ,…, y k ) are given by the Bayes' rule      p   (   x  0   ,  …  ,   x  k   |   y  0   ,  …  ,   y  k   )   =    p   (   y  0   ,  …  ,   y  k   |   x  0   ,  …  ,   x  k   )   ×  p   (   x  0   ,  …  ,   x  k   )     p   (   y  0   ,  …  ,   y  k   )     with  p   (   y  0   ,  …  ,   y  k   )   =  ∫  p   (   y  0   ,  …  ,   y  k   |   x  0   ,  …  ,   x  k   )   p   (   x  0   ,  …  ,   x  k   )   d   x  0   …  d   x  k      fragments  p   fragments  normal-(   subscript  x  0   normal-,  normal-…  normal-,   subscript  x  k   normal-|   subscript  y  0   normal-,  normal-…  normal-,   subscript  y  k   normal-)       fragments  p   fragments  normal-(   subscript  y  0   normal-,  normal-…  normal-,   subscript  y  k   normal-|   subscript  x  0   normal-,  normal-…  normal-,   subscript  x  k   normal-)    p   fragments  normal-(   subscript  x  0   normal-,  normal-…  normal-,   subscript  x  k   normal-)      p    subscript  y  0   normal-…   subscript  y  k       with   p   fragments  normal-(   subscript  y  0   normal-,  normal-…  normal-,   subscript  y  k   normal-)     p   fragments  normal-(   subscript  y  0   normal-,  normal-…  normal-,   subscript  y  k   normal-|   subscript  x  0   normal-,  normal-…  normal-,   subscript  x  k   normal-)   p   fragments  normal-(   subscript  x  0   normal-,  normal-…  normal-,   subscript  x  k   normal-)   d   subscript  x  0   normal-…  d   subscript  x  k     p(x_{0},...,x_{k}|y_{0},\dots,y_{k})=\frac{p(y_{0},\dots,y_{k}|x_{0},...,x_{k}%
 )\times p(x_{0},...,x_{k})}{p(y_{0},\dots,y_{k})}\quad\mbox{with}\quad p(y_{0}%
 ,\dots,y_{k})=\int p(y_{0},\dots,y_{k}|x_{0},...,x_{k})~{}p(x_{0},...,x_{k})~{%
 }dx_{0}\ldots dx_{k}     and the likelihood functions are defined by the product formulae      p   (   y  0   ,  …  ,   y  k   |   x  0   ,  …  ,   x  k   )   =   ∏   0  ≤  l  ≤  k    p   (   y  l   |   x  l   )   with  p   (   x  0   ,  …  ,   x  k   )   =   p  0    (   x  0   )    ∏   1  ≤  l  ≤  k    p   (   x  l   |   x   l  -  1    )      fragments  p   fragments  normal-(   subscript  y  0   normal-,  normal-…  normal-,   subscript  y  k   normal-|   subscript  x  0   normal-,  normal-…  normal-,   subscript  x  k   normal-)     subscript  product      0  l       k     p   fragments  normal-(   subscript  y  l   normal-|   subscript  x  l   normal-)   italic-  with  italic-  p   fragments  normal-(   subscript  x  0   normal-,  normal-…  normal-,   subscript  x  k   normal-)     subscript  p  0    fragments  normal-(   subscript  x  0   normal-)    subscript  product      1  l       k     p   fragments  normal-(   subscript  x  l   normal-|   subscript  x    l  1    normal-)     p(y_{0},\dots,y_{k}|x_{0},...,x_{k})=\prod_{0\leq l\leq k}p(y_{l}|x_{l})\qquad%
 \mbox{with}\qquad p(x_{0},...,x_{k})=p_{0}(x_{0})\prod_{1\leq l\leq k}p(x_{l}|%
 x_{l-1})     Particle filters are also an approximation, but with enough particles they can be much more accurate 82 83 84 85 86 . . The nonlinear filtering equation is given by the recursion  {-\!\!\!\!-\!\!\!\!-\!\!\!\!-\!\!\!\!-\!\!\!\!-\!\!\!\!-\!\!\!\!-\!\!\!\!-\!\!\!\!-\!\!\!\!\longrightarrow}~~~ p(x_k|y_0,\ldots,y_{k})=\displaystyle\frac{p(y_k|x_k)p(x_k|y_0,\ldots,y_{k-1})}{\int p(y_k|x'_k)p(x'_k|y_0,\ldots,y_{k-1})dx'_k}~~\stackrel{\mbox{prediction}}{-\!\!\!\!-\!\!\!\!-\!\!\!\!-\!\!\!\!-\!\!\!\!-\!\!\!\!-\!\!\!\!-\!\!\!\!-\!\!\!\!-\!\!\!\!\longrightarrow}~~~p(x_{k+1}|y_0,\ldots,y_{k})=\int~p(x_{k+1}|x_k)~p(x_k|y_0,\ldots,y_{k})~dx_k |Eq. 1}} with the convention    p   (   x  0   |   y  0   ,  …  ,   y   -  1    )   =  p   (   x  0   )      fragments  p   fragments  normal-(   subscript  x  0   normal-|   subscript  y  0   normal-,  normal-…  normal-,   subscript  y    1    normal-)    p   fragments  normal-(   subscript  x  0   normal-)     p(x_{0}|y_{0},\ldots,y_{-1})=p(x_{0})   for k=0. The nonlinear filtering problem consists in computing sequentially these sequence of conditional distributions.  Feynman-Kac formulation  We fix a time horizon n and a sequence of observations      Y  0   =    y  0   ,  …    ,    Y  n   =   y  n       formulae-sequence     subscript  Y  0     subscript  y  0   normal-…       subscript  Y  n    subscript  y  n      Y_{0}=y_{0},\ldots,Y_{n}=y_{n}   , and we set     G  k    (   x  k   )   =  p   (   y  k   |   x  k   )   ,   for each   k  =  0  ,  …  ,  n     fragments   subscript  G  k    fragments  normal-(   subscript  x  k   normal-)    p   fragments  normal-(   subscript  y  k   normal-|   subscript  x  k   normal-)   normal-,  for each  k   0  normal-,  normal-…  normal-,  n    G_{k}(x_{k})=p(y_{k}|x_{k}),~{}\mbox{for each}~{}k=0,\ldots,n   . In this notation, for any bounded function F(.) on the set of trajectories of    X  k     subscript  X  k    X_{k}   from the origin k=0 up to time k=n, we have the Feynman-Kac formula          ∫   F   (   x  0   ,  …  ,   x  n   )   p   (   x  0   ,  …  ,   x  n   |   y  0   ,  …  ,   y  n   )   d   x  0   …  d   x  n      =       ∫  F   (   x  0   ,  …  ,   x  n   )    {   ∏   0  ≤  k  ≤  n    p   (   y  k   |   x  k   )   }   p   (   x  0   ,  …  ,   x  n   )   d   x  0   …  d   x  n     ∫   {   ∏   0  ≤  k  ≤  n    p   (   y  k   |   x  k   )   }   p   (   x  0   ,  …  ,   x  n   )   d   x  0   …  d   x  n                =       E   (   F   (   X  0   ,  …  ,   X  n   )     ∏   0  ≤  k  ≤  n      G  k    (   X  k   )      )     E   (    ∏   0  ≤  k  ≤  n      G  k    (   X  k   )     )             fragments   F   fragments  normal-(   subscript  x  0   normal-,  normal-…  normal-,   subscript  x  n   normal-)   p   fragments  normal-(   subscript  x  0   normal-,  normal-…  normal-,   subscript  x  n   normal-|   subscript  y  0   normal-,  normal-…  normal-,   subscript  y  n   normal-)   d   subscript  x  0   normal-…  d   subscript  x  n        fragments   F   fragments  normal-(   subscript  x  0   normal-,  normal-…  normal-,   subscript  x  n   normal-)    fragments  normal-{   subscript  product      0  k       n     p   fragments  normal-(   subscript  y  k   normal-|   subscript  x  k   normal-)   normal-}   p   fragments  normal-(   subscript  x  0   normal-,  normal-…  normal-,   subscript  x  n   normal-)   d   subscript  x  0   normal-…  d   subscript  x  n     fragments    fragments  normal-{   subscript  product      0  k       n     p   fragments  normal-(   subscript  y  k   normal-|   subscript  x  k   normal-)   normal-}   p   fragments  normal-(   subscript  x  0   normal-,  normal-…  normal-,   subscript  x  n   normal-)   d   subscript  x  0   normal-…  d   subscript  x  n        missing-subexpression    missing-subexpression    missing-subexpression      missing-subexpression        E    F    subscript  X  0   normal-…   subscript  X  n      subscript  product      0  k       n        subscript  G  k    subscript  X  k         E    subscript  product      0  k       n        subscript  G  k    subscript  X  k          \begin{array}[]{rcl}\displaystyle\int F(x_{0},\ldots,x_{n})~{}p(x_{0},\ldots,x%
 _{n}|y_{0},\ldots,y_{n})~{}dx_{0}\ldots dx_{n}&=&\displaystyle\frac{\int F(x_{%
 0},\ldots,x_{n})~{}\left\{\prod_{0\leq k\leq n}p(y_{k}|x_{k})\right\}p(x_{0},%
 \ldots,x_{n})~{}dx_{0}\ldots dx_{n}}{\int~{}\left\{\prod_{0\leq k\leq n}p(y_{k%
 }|x_{k})\right\}p(x_{0},\ldots,x_{n})~{}dx_{0}\ldots dx_{n}}\\
 &&\\
 &=&\displaystyle\frac{E\left(F(X_{0},\ldots,X_{n})\prod_{0\leq k\leq n}G_{k}(X%
 _{k})\right)}{E\left(\prod_{0\leq k\leq n}G_{k}(X_{k})\right)}\end{array}   These Feynman-Kac path integration models arise a variety of scientific disciplines, including in computational physics, biology, information theory and computer sciences. 87 88 89 Their interpretations depend on the application domain. For instance, if we choose the indicator function      G  n    (   x  n   )    =    1  A    (   x  n   )           subscript  G  n    subscript  x  n       subscript  1  A    subscript  x  n      G_{n}(x_{n})=1_{A}(x_{n})   of some subset of the state space, they represent the conditional distribution of a Markov chain given it stays in a given tube; that is, we have that      E   (  F   (   X  0   ,  …  ,   X  n   )   |   X  0   ∈  A  ,  …  ,   X  n   ∈  A  )   =     E   (   F   (   X  0   ,  …  ,   X  n   )     ∏   0  ≤  k  ≤  n      G  k    (   X  k   )      )     E   (    ∏   0  ≤  k  ≤  n      G  k    (   X  k   )     )      and  P   (   X  0   ∈  A  ,  …  ,   X  n   ∈  A  )   =  E   (    ∏   0  ≤  k  ≤  n      G  k    (   X  k   )   )      fragments  E   fragments  normal-(  F   fragments  normal-(   subscript  X  0   normal-,  normal-…  normal-,   subscript  X  n   normal-)   normal-|   subscript  X  0    A  normal-,  normal-…  normal-,   subscript  X  n    A  normal-)        E    F    subscript  X  0   normal-…   subscript  X  n      subscript  product      0  k       n        subscript  G  k    subscript  X  k         E    subscript  product      0  k       n        subscript  G  k    subscript  X  k        and   P   fragments  normal-(   subscript  X  0    A  normal-,  normal-…  normal-,   subscript  X  n    A  normal-)    E   fragments  normal-(   subscript  product      0  k       n      subscript  G  k    fragments  normal-(   subscript  X  k   normal-)   normal-)     E\left(F(X_{0},\ldots,X_{n})~{}|~{}X_{0}\in A,~{}\ldots,X_{n}\in A\right)=%
 \displaystyle\frac{E\left(F(X_{0},\ldots,X_{n})\prod_{0\leq k\leq n}G_{k}(X_{k%
 })\right)}{E\left(\prod_{0\leq k\leq n}G_{k}(X_{k})\right)}\quad\mbox{and}%
 \quad P\left(X_{0}\in A,~{}\ldots,X_{n}\in A\right)=E\left(\prod_{0\leq k\leq n%
 }G_{k}(X_{k})\right)   as soon as the normalizing constant is strictly positive.  Particle filters  A Genetic type particle algorithm  Initially we start with   N   N   N   independent random variable     (   ξ  0  i   )    1  ≤  i  ≤  N      subscript   subscript   superscript  ξ  i   0       1  i       N      \left(\xi^{i}_{0}\right)_{1\leq i\leq N}   with common probability density    p   (   x  0   )       p   subscript  x  0     p(x_{0})   . The genetic algorithm selection-mutation transitions       ξ  k   :=    (   ξ  k  i   )    1  ≤  i  ≤  N       -  -  -  -  -  -  -  -  -  -  ⟶   selection      ξ  ^   k   :=    (    ξ  ^   k  i   )    1  ≤  i  ≤  N       -  -  -  -  -  -  -  -  -  -  ⟶   mutation     ξ   k  +  1    :=    (   ξ   k  +  1   i   )    1  ≤  i  ≤  N         assign   subscript  ξ  k    subscript   subscript   superscript  ξ  i   k       1  i       N        superscript             normal-⟶   selection      subscript   normal-^  ξ   k     assign     subscript   subscript   superscript   normal-^  ξ   i   k       1  i       N        superscript             normal-⟶   mutation      subscript  ξ    k  1      assign     subscript   subscript   superscript  ξ  i     k  1        1  i       N        \xi_{k}:=\left(\xi^{i}_{k}\right)_{1\leq i\leq N}\stackrel{\mbox{selection}}{-%
 \!\!\!\!-\!\!\!\!-\!\!\!\!-\!\!\!\!-\!\!\!\!-\!\!\!\!-\!\!\!\!-\!\!\!\!-\!\!\!%
 \!-\!\!\!\!\longrightarrow}~{}\widehat{\xi}_{k}:=\left(\widehat{\xi}^{i}_{k}%
 \right)_{1\leq i\leq N}\stackrel{\mbox{mutation}}{-\!\!\!\!-\!\!\!\!-\!\!\!\!-%
 \!\!\!\!-\!\!\!\!-\!\!\!\!-\!\!\!\!-\!\!\!\!-\!\!\!\!-\!\!\!\!\longrightarrow}%
 ~{}\xi_{k+1}:=\left(\xi^{i}_{k+1}\right)_{1\leq i\leq N}     mimic/approximate the updating-prediction transitions of the optimal filter evolution ():   During the selection-updating transition we sample N (conditionally) independent random variables      ξ  ^   k   :=    (    ξ  ^   k  i   )    1  ≤  i  ≤  N       assign   subscript   normal-^  ξ   k    subscript   subscript   superscript   normal-^  ξ   i   k       1  i       N       \widehat{\xi}_{k}:=\left(\widehat{\xi}^{i}_{k}\right)_{1\leq i\leq N}   with common (conditional) distribution      ∑   1  ≤  i  ≤  N         p   (    y  k    |   ξ  k  i   )       ∑   1  ≤  j  ≤  N     p   (    y  k    |   ξ  k  j   )       δ   ξ  k  i     (   d   x  k    )        subscript       1  i       N          fragments  p   fragments  normal-(   subscript  y  k   normal-|   subscript   superscript  ξ  i   k   normal-)     fragments   subscript       1  j       N     p   fragments  normal-(   subscript  y  k   normal-|   subscript   superscript  ξ  j   k   normal-)      subscript  δ   subscript   superscript  ξ  i   k      d   subscript  x  k       \sum_{1\leq i\leq N}~{}\frac{p(y_{k}~{}|~{}\xi^{i}_{k})}{\sum_{1\leq j\leq N}p%
 (y_{k}~{}|~{}\xi^{j}_{k})}~{}\delta_{\xi^{i}_{k}}(dx_{k})     During the mutation-prediction transition, from each selected particle     ξ  ^   k  i     subscript   superscript   normal-^  ξ   i   k    \widehat{\xi}^{i}_{k}   we sample independently a transition       ξ  ^   k  i    ⟶    ξ   k  +  1   i    ∼  p   (   x   k  +  1    |    ξ  ^   k  i   )      fragments   subscript   superscript   normal-^  ξ   i   k   normal-⟶   subscript   superscript  ξ  i     k  1    similar-to  p   fragments  normal-(   subscript  x    k  1    normal-|   subscript   superscript   normal-^  ξ   i   k   normal-)     \widehat{\xi}^{i}_{k}~{}\longrightarrow\xi^{i}_{k+1}~{}~{}\sim~{}~{}p(x_{k+1}|%
 \widehat{\xi}^{i}_{k})   , for     i  =   1  ,  …  ,  N    .      i   1  normal-…  N     i=1,\ldots,N.      In the above displayed formulae    p   (    y  k    |   ξ  k  i   )      fragments  p   fragments  normal-(   subscript  y  k   normal-|   subscript   superscript  ξ  i   k   normal-)     p(y_{k}~{}|~{}\xi^{i}_{k})   stands for the likelihood function     x  k   ↦  p   (    y  k    |   x  k   )      fragments   subscript  x  k   maps-to  p   fragments  normal-(   subscript  y  k   normal-|   subscript  x  k   normal-)     x_{k}\mapsto p(y_{k}~{}|~{}x_{k})   evaluated at     x  k   =   ξ  k  i        subscript  x  k    subscript   superscript  ξ  i   k     x_{k}=\xi^{i}_{k}   , and    p   (    x   k  +  1     |    ξ  ^   k  i   )      fragments  p   fragments  normal-(   subscript  x    k  1    normal-|   subscript   superscript   normal-^  ξ   i   k   normal-)     p(x_{k+1}~{}|~{}\widehat{\xi}^{i}_{k})   stands for the conditional density    p   (    x   k  +  1     |   x  k   )      fragments  p   fragments  normal-(   subscript  x    k  1    normal-|   subscript  x  k   normal-)     p(x_{k+1}~{}|~{}x_{k})   evaluated at     x  k   =    ξ  ^   k  i        subscript  x  k    subscript   superscript   normal-^  ξ   i   k     x_{k}=\widehat{\xi}^{i}_{k}   .  At each time k, we have the particle approximations       p  ^    (  d    x  k    |   y  0   ,  …  ,   y  k   )   :=   1  N    ∑   1  ≤  i  ≤  N     δ    ξ  ^   k  i     (  d   x  k   )     ≈   N  ↑  ∞     p   (  d    x  k    |   y  0   ,  …  ,   y  k   )     ≈   N  ↑  ∞       ∑   1  ≤  i  ≤  N        p   (    y  k    |   ξ  k  i   )       ∑   1  ≤  j  ≤  N     p   (    y  k    |   ξ  k  j   )       δ   ξ  k  i     (  d   x  k   )      fragments   normal-^  p    fragments  normal-(  d   subscript  x  k   normal-|   subscript  y  0   normal-,  normal-…  normal-,   subscript  y  k   normal-)   assign    1  N    subscript       1  i       N      subscript  δ   subscript   superscript   normal-^  ξ   i   k     fragments  normal-(  d   subscript  x  k   normal-)    subscript    normal-↑  N     p   fragments  normal-(  d   subscript  x  k   normal-|   subscript  y  0   normal-,  normal-…  normal-,   subscript  y  k   normal-)    subscript    normal-↑  N      subscript       1  i       N        fragments  p   fragments  normal-(   subscript  y  k   normal-|   subscript   superscript  ξ  i   k   normal-)     fragments   subscript       1  j       N     p   fragments  normal-(   subscript  y  k   normal-|   subscript   superscript  ξ  j   k   normal-)      subscript  δ   subscript   superscript  ξ  i   k     fragments  normal-(  d   subscript  x  k   normal-)     \widehat{p}(dx_{k}~{}|~{}y_{0},\ldots,y_{k}):=\frac{1}{N}\sum_{1\leq i\leq N}%
 \delta_{\widehat{\xi}^{i}_{k}}(dx_{k})~{}~{}\approx_{N\uparrow\infty}~{}~{}p(%
 dx_{k}~{}|~{}y_{0},\ldots,y_{k})~{}~{}\approx_{N\uparrow\infty}~{}~{}\sum_{1%
 \leq i\leq N}~{}\frac{p(y_{k}~{}|~{}\xi^{i}_{k})}{\sum_{1\leq j\leq N}p(y_{k}~%
 {}|~{}\xi^{j}_{k})}~{}\delta_{\xi^{i}_{k}}(dx_{k})   and       p  ^    (  d    x  k    |   y  0   ,  …  ,   y   k  -  1    )   :=   1  N    ∑   1  ≤  i  ≤  N     δ   ξ  k  i     (  d   x  k   )     ≈   N  ↑  ∞     p   (  d    x  k    |   y  0   ,  …  ,   y   k  -  1    )      fragments   normal-^  p    fragments  normal-(  d   subscript  x  k   normal-|   subscript  y  0   normal-,  normal-…  normal-,   subscript  y    k  1    normal-)   assign    1  N    subscript       1  i       N      subscript  δ   subscript   superscript  ξ  i   k     fragments  normal-(  d   subscript  x  k   normal-)    subscript    normal-↑  N     p   fragments  normal-(  d   subscript  x  k   normal-|   subscript  y  0   normal-,  normal-…  normal-,   subscript  y    k  1    normal-)     \widehat{p}(dx_{k}~{}|~{}y_{0},\ldots,y_{k-1}):=\frac{1}{N}\sum_{1\leq i\leq N%
 }\delta_{\xi^{i}_{k}}(dx_{k})~{}~{}\approx_{N\uparrow\infty}~{}~{}p(dx_{k}~{}|%
 ~{}y_{0},\ldots,y_{k-1})     A detailed proof of these convergence results can be found in, 90 91 see also the more recent developments provided in the books. 92 93 In Genetic algorithms and Evolutionary computing community, the mutation-selection  Markov chain described above is often called the genetic algorithm with proportional selection. Several branching variants, including with random population sizes have also been proposed in the articles. 94 95 96  Monte Carlo principles  Particle methods, like all sampling-based approaches (e.g., MCMC ), generate a set of samples that approximate the filtering density    p   (   x  k   |   y  0   ,  …  ,   y  k   )      fragments  p   fragments  normal-(   subscript  x  k   normal-|   subscript  y  0   normal-,  normal-…  normal-,   subscript  y  k   normal-)     p(x_{k}|y_{0},\dots,y_{k})   . For example, we may have   N   N   N   samples from the approximate posterior distribution of    X  k     subscript  X  k    X_{k}   , where the samples are labeled with superscripts as      ξ  ^   k  1   ,    ξ  ^   k  2   ,  …  ,    ξ  ^   k  N       superscript   subscript   normal-^  ξ   k   1    superscript   subscript   normal-^  ξ   k   2   normal-…   superscript   subscript   normal-^  ξ   k   N     \widehat{\xi}_{k}^{1},\widehat{\xi}_{k}^{2},\ldots,\widehat{\xi}_{k}^{N}   . Then, expectations with respect to the filtering distribution are approximated by  In the above display    δ  a     subscript  δ  a    \delta_{a}   stands for the Dirac measure at a given state a. The function    f   (  ⋅  )       f  normal-⋅    f(\cdot)   , in the usual way for Monte Carlo, can give all the moments etc. of the distribution up to some degree of approximation. When the approximation equation () is satisfied for any bounded function    f   (  ⋅  )       f  normal-⋅    f(\cdot)   we write      p   (  d   x  k   |   y  0   ,  …  ,   y  k   )   :=  p   (   x  k   |   y  0   ,  …  ,   y  k   )   d    x  k     ≈   N  ↑  ∞     p  ^    (  d   x  k   |   y  0   ,  …  ,   y  k   )   =   1  N    ∑   1  ≤  i  ≤  N     δ    ξ  ^   k  i     (  d   x  k   )      fragments  p   fragments  normal-(  d   subscript  x  k   normal-|   subscript  y  0   normal-,  normal-…  normal-,   subscript  y  k   normal-)   assign  p   fragments  normal-(   subscript  x  k   normal-|   subscript  y  0   normal-,  normal-…  normal-,   subscript  y  k   normal-)   d   subscript  x  k    subscript    normal-↑  N      normal-^  p    fragments  normal-(  d   subscript  x  k   normal-|   subscript  y  0   normal-,  normal-…  normal-,   subscript  y  k   normal-)      1  N    subscript       1  i       N      subscript  δ   subscript   superscript   normal-^  ξ   i   k     fragments  normal-(  d   subscript  x  k   normal-)     p(dx_{k}|y_{0},\dots,y_{k}):=p(x_{k}|y_{0},\dots,y_{k})~{}dx_{k}~{}\approx_{N%
 \uparrow\infty}\widehat{p}(dx_{k}|y_{0},\dots,y_{k})=\frac{1}{N}\sum_{1\leq i%
 \leq N}\delta_{\widehat{\xi}^{i}_{k}}(dx_{k})     Particle filters can be interpreted as a genetic type particle algorithm evolving with mutation and selection transitions. We can keep track of the ancestral lines    (    ξ  ^    0  ,  k   i   ,    ξ  ^    1  ,  k   i   ,  …  ,    ξ  ^     k  -  1   ,  k   i   ,    ξ  ^    k  ,  k   i   )      subscript   superscript   normal-^  ξ   i    0  k     subscript   superscript   normal-^  ξ   i    1  k    normal-…   subscript   superscript   normal-^  ξ   i      k  1   k     subscript   superscript   normal-^  ξ   i    k  k      \left(\widehat{\xi}^{i}_{0,k},\widehat{\xi}^{i}_{1,k},...,\widehat{\xi}^{i}_{k%
 -1,k},\widehat{\xi}^{i}_{k,k}\right)   of the particles    i  =   1  ,  …  ,  N       i   1  normal-…  N     i=1,...,N   . The random states     ξ  ^    l  ,  k   i     subscript   superscript   normal-^  ξ   i    l  k     \widehat{\xi}^{i}_{l,k}   , with the lower indices l=0,...,k, stands for the ancestor of the individual      ξ  ^    k  ,  k   i   =    ξ  ^   k  i        subscript   superscript   normal-^  ξ   i    k  k     subscript   superscript   normal-^  ξ   i   k     \widehat{\xi}^{i}_{k,k}=\widehat{\xi}^{i}_{k}   at level l=0,...,k. In his situation, we have the approximation formula  Here F stands for any founded function on the path space of the signal. In a more synthetic form () is equivalent to      p   (  d   (   x  0   ,  …  ,   x  k   )   |   y  0   ,  …  ,   y  k   )   :=  p   (   x  0   ,  …  ,   x  k   |   y  0   ,  …  ,   y  k   )   d   x  0   …  d   x  k    ≈   N  ↑  ∞     p  ^    (  d   (   x  0   ,  …  ,   x  k   )   |   y  0   ,  …  ,   y  k   )   :=   1  N    ∑   1  ≤  i  ≤  N     δ   (    ξ  ^    0  ,  k   i   ,    ξ  ^    1  ,  k   i   ,  …  ,    ξ  ^    k  ,  k   i   )     (  d   (   x  0   ,  …  ,   x  k   )   )      fragments  p   fragments  normal-(  d   fragments  normal-(   subscript  x  0   normal-,  normal-…  normal-,   subscript  x  k   normal-)   normal-|   subscript  y  0   normal-,  normal-…  normal-,   subscript  y  k   normal-)   assign  p   fragments  normal-(   subscript  x  0   normal-,  normal-…  normal-,   subscript  x  k   normal-|   subscript  y  0   normal-,  normal-…  normal-,   subscript  y  k   normal-)   d   subscript  x  0   normal-…  d   subscript  x  k    subscript    normal-↑  N      normal-^  p    fragments  normal-(  d   fragments  normal-(   subscript  x  0   normal-,  normal-…  normal-,   subscript  x  k   normal-)   normal-|   subscript  y  0   normal-,  normal-…  normal-,   subscript  y  k   normal-)   assign    1  N    subscript       1  i       N      subscript  δ    subscript   superscript   normal-^  ξ   i    0  k     subscript   superscript   normal-^  ξ   i    1  k    normal-…   subscript   superscript   normal-^  ξ   i    k  k       fragments  normal-(  d   fragments  normal-(   subscript  x  0   normal-,  normal-…  normal-,   subscript  x  k   normal-)   normal-)     p(d(x_{0},...,x_{k})|y_{0},\dots,y_{k}):=p(x_{0},...,x_{k}|y_{0},\dots,y_{k})%
 \,dx_{0}...dx_{k}\approx_{N\uparrow\infty}\widehat{p}(d(x_{0},\ldots,x_{k})|y_%
 {0},\dots,y_{k}):=\frac{1}{N}\sum_{1\leq i\leq N}\delta_{\left(\widehat{\xi}^{%
 i}_{0,k},\widehat{\xi}^{i}_{1,k},\ldots,\widehat{\xi}^{i}_{k,k}\right)}(d(x_{0%
 },\ldots,x_{k}))   Particle filters can be interpreted in many different ways. From the probabilistic point of view they coincide with a mean field particle interpretation of the nonlinear filtering equation. The updating-prediction transitions of the optimal filter evolution can also be interpreted as the classical genetic type selection-mutation transitions of individuals. The sequential importance resampling technique provides another interpretation of the filtering transitions coupling importance sampling with the bootstrap resampling step. Last, but not least, particle filters can be seen as an acceptance-rejection methodology equipped with a recycling mechanism. 97 98  Mean field particle simulation  The general probabilistic principle  The nonlinear filtering evolution can be interpreted as a dynamical system in the set of probability measures of the following form     η   n  +  1    =    Φ   n  +  1     (   η  n   )         subscript  η    n  1       subscript  normal-Φ    n  1     subscript  η  n      \eta_{n+1}=\Phi_{n+1}\left(\eta_{n}\right)   where    Φ   n  +  1      subscript  normal-Φ    n  1     \Phi_{n+1}   stands for some mapping from the set of probability distribution into itself. For instance, the evolution of the one-step optimal predictor     η  n    (  d   x  n   )   =  p   (   x  n   |   y  0   ,  …  ,   y   n  -  1    )   d   x  n      fragments   subscript  η  n    fragments  normal-(  d   subscript  x  n   normal-)    p   fragments  normal-(   subscript  x  n   normal-|   subscript  y  0   normal-,  normal-…  normal-,   subscript  y    n  1    normal-)   d   subscript  x  n     \eta_{n}(dx_{n})=p(x_{n}|y_{0},\ldots,y_{n-1})dx_{n}   satisfies a nonlinear evolution starting with the probability distribution      η  0    (   d   x  0    )    =   p   (   x  0   )   d   x  0           subscript  η  0     d   subscript  x  0       p   subscript  x  0   d   subscript  x  0      \eta_{0}(dx_{0})=p(x_{0})dx_{0}   . One of the simplest way to approximate these probability measures is to start with   N   N   N   independent random variables     (   ξ  0  i   )    1  ≤  i  ≤  N      subscript   subscript   superscript  ξ  i   0       1  i       N      \left(\xi^{i}_{0}\right)_{1\leq i\leq N}   with common probability distribution      η  0    (   d   x  0    )    =   p   (   x  0   )   d   x  0           subscript  η  0     d   subscript  x  0       p   subscript  x  0   d   subscript  x  0      \eta_{0}(dx_{0})=p(x_{0})dx_{0}   . Suppose we have defined a sequence of   N   N   N   random variables     (   ξ  n  i   )    1  ≤  i  ≤  N      subscript   subscript   superscript  ξ  i   n       1  i       N      \left(\xi^{i}_{n}\right)_{1\leq i\leq N}   such that      1  N     ∑   1  ≤  i  ≤  N      δ   ξ  n  i     (   d   x  n    )        ≈   N  ↑  ∞       η  n    (   d   x  n    )        subscript    normal-↑  N         1  N     subscript       1  i       N        subscript  δ   subscript   superscript  ξ  i   n      d   subscript  x  n          subscript  η  n     d   subscript  x  n       \frac{1}{N}\sum_{1\leq i\leq N}\delta_{\xi^{i}_{n}}(dx_{n})~{}\approx_{N%
 \uparrow\infty}~{}\eta_{n}(dx_{n})   At the next step we sample   N   N   N   (conditionally) independent random variables     ξ   n  +  1    :=    (   ξ   n  +  1   i   )    1  ≤  i  ≤  N       assign   subscript  ξ    n  1     subscript   subscript   superscript  ξ  i     n  1        1  i       N       \xi_{n+1}:=\left(\xi^{i}_{n+1}\right)_{1\leq i\leq N}   with common law .        Φ   n  +  1     (    1  N     ∑   1  ≤  i  ≤  N     δ   ξ  n  i      )      ≈   N  ↑  ∞       Φ   n  +  1     (   η  n   )    =   η   n  +  1          subscript    normal-↑  N        subscript  normal-Φ    n  1        1  N     subscript       1  i       N      subscript  δ   subscript   superscript  ξ  i   n          subscript  normal-Φ    n  1     subscript  η  n          subscript  η    n  1       \Phi_{n+1}\left(\frac{1}{N}\sum_{1\leq i\leq N}\delta_{\xi^{i}_{n}}\right)~{}%
 \approx_{N\uparrow\infty}~{}\Phi_{n+1}\left(\eta_{n}\right)=\eta_{n+1}     A particle interpretation of the filtering equation  We illustrate this mean field particle principle in the context of the evolution of the one step optimal predictors  |Eq. 4}}  For k=0 we use the convention    p   (   x  0   |   y  0   ,  …  ,   y   -  1    )   :=  p   (   x  0   )      fragments  p   fragments  normal-(   subscript  x  0   normal-|   subscript  y  0   normal-,  normal-…  normal-,   subscript  y    1    normal-)   assign  p   fragments  normal-(   subscript  x  0   normal-)     p(x_{0}|y_{0},\dots,y_{-1}):=p(x_{0})   .  By the law of large numbers, we have         p  ^    (   d   x  0    )    =    1  N     ∑   1  ≤  i  ≤  N      δ   ξ  0  i     (   d   x  0    )        ≈   N  ↑  ∞      p   (   x  0   )   d   x  0       in the sense that   ∫   f   (   x  0   )    p  ^    (   d   x  0    )      =    1  N     ∑   1  ≤  i  ≤  N     f   (   ξ  0  i   )       ≈   N  ↑  ∞     ∫   f   (   x  0   )   p   (   d   x  0    )   d   x  0         formulae-sequence         normal-^  p     d   subscript  x  0         1  N     subscript       1  i       N        subscript  δ   subscript   superscript  ξ  i   0      d   subscript  x  0          subscript    normal-↑  N         p   subscript  x  0   d   subscript  x  0           in the sense that      f   subscript  x  0    normal-^  p     d   subscript  x  0           1  N     subscript       1  i       N       f   subscript   superscript  ξ  i   0         subscript    normal-↑  N           f   subscript  x  0   p    d   subscript  x  0    d   subscript  x  0         \widehat{p}(dx_{0})=\frac{1}{N}\sum_{1\leq i\leq N}\delta_{\xi^{i}_{0}}(dx_{0}%
 )\approx_{N\uparrow\infty}~{}p(x_{0})dx_{0}\quad\mbox{in the sense that}\quad%
 \int f(x_{0})\widehat{p}(dx_{0})=\frac{1}{N}\sum_{1\leq i\leq N}f(\xi^{i}_{0})%
 \approx_{N\uparrow\infty}\int f(x_{0})p(dx_{0})dx_{0}   for any bounded function   f   f   f   . We further assume that we have constructed a sequence of particles     (   ξ  k  i   )    1  ≤  i  ≤  N      subscript   subscript   superscript  ξ  i   k       1  i       N      \left(\xi^{i}_{k}\right)_{1\leq i\leq N}   at some rank k such that       p  ^    (  d   x  k   |   y  0   ,  …  ,   y   k  -  1    )   :=   1  N    ∑   1  ≤  i  ≤  N     δ   ξ  k  i     (  d   x  k   )     ≈   N  ↑  ∞     p   (    x  k    |   y  0   ,  …  ,   y   k  -  1    )   d   x  k      fragments   normal-^  p    fragments  normal-(  d   subscript  x  k   normal-|   subscript  y  0   normal-,  normal-…  normal-,   subscript  y    k  1    normal-)   assign    1  N    subscript       1  i       N      subscript  δ   subscript   superscript  ξ  i   k     fragments  normal-(  d   subscript  x  k   normal-)    subscript    normal-↑  N     p   fragments  normal-(   subscript  x  k   normal-|   subscript  y  0   normal-,  normal-…  normal-,   subscript  y    k  1    normal-)   d   subscript  x  k     \widehat{p}(dx_{k}|y_{0},\ldots,y_{k-1}):=\frac{1}{N}\sum_{1\leq i\leq N}%
 \delta_{\xi^{i}_{k}}(dx_{k})\approx_{N\uparrow\infty}~{}p(x_{k}~{}|~{}y_{0},%
 \ldots,y_{k-1})dx_{k}   in the sense that for any bounded function   f   f   f   we have    ∫  f   (   x  k   )    p  ^    (  d    x  k    |   y  0   ,  …  ,   y   k  -  1    )   =   1  N    ∑   1  ≤  i  ≤  N    f   (   ξ  k  i   )    ≈   N  ↑  ∞    ∫  f   (   x  k   )   p   (  d   x  k   |   y  0   ,  …  ,   y   k  -  1    )      fragments   f   fragments  normal-(   subscript  x  k   normal-)    normal-^  p    fragments  normal-(  d   subscript  x  k   normal-|   subscript  y  0   normal-,  normal-…  normal-,   subscript  y    k  1    normal-)      1  N    subscript       1  i       N     f   fragments  normal-(   subscript   superscript  ξ  i   k   normal-)    subscript    normal-↑  N      f   fragments  normal-(   subscript  x  k   normal-)   p   fragments  normal-(  d   subscript  x  k   normal-|   subscript  y  0   normal-,  normal-…  normal-,   subscript  y    k  1    normal-)     \int f(x_{k})\widehat{p}(dx_{k}~{}|~{}y_{0},\ldots,y_{k-1})=\frac{1}{N}\sum_{1%
 \leq i\leq N}f(\xi^{i}_{k})\approx_{N\uparrow\infty}\int f(x_{k})p(dx_{k}|y_{0%
 },\ldots,y_{k-1})   In this situation, '''replacing    p   (   x   k  +  1    |   y  0   ,  …  ,   y  k   )    ≈   N  ↑  ∞    ∫  p   (   x   k  +  1    |   x  k  ′   )      p   (   y  k   |   x  k  ′   )    p  ^    (  d   x  k  ′   |   y  0   ,  …  ,   y   k  -  1    )       ∫    p   (   y  k   |   x  k  ′′   )    p  ^    (  d   x  k  ′′   |   y  0   ,  …  ,   y   k  -  1    )         fragments  p   fragments  normal-(   subscript  x    k  1    normal-|   subscript  y  0   normal-,  normal-…  normal-,   subscript  y  k   normal-)    subscript    normal-↑  N      p   fragments  normal-(   subscript  x    k  1    normal-|   subscript   superscript  x  normal-′   k   normal-)      fragments  p   fragments  normal-(   subscript  y  k   normal-|   superscript   subscript  x  k   normal-′   normal-)    normal-^  p    fragments  normal-(  d   subscript   superscript  x  normal-′   k   normal-|   subscript  y  0   normal-,  normal-…  normal-,   subscript  y    k  1    normal-)     fragments   p   fragments  normal-(   subscript  y  k   normal-|   subscript   superscript  x  ′′   k   normal-)    normal-^  p    fragments  normal-(  d   subscript   superscript  x  ′′   k   normal-|   subscript  y  0   normal-,  normal-…  normal-,   subscript  y    k  1    normal-)       p(x_{k+1}|y_{0},\ldots,y_{k})\approx_{N\uparrow\infty}\int~{}p(x_{k+1}|x^{%
 \prime}_{k})~{}\displaystyle\frac{p(y_{k}|x_{k}^{\prime})~{}\widehat{p}(dx^{%
 \prime}_{k}|y_{0},\dots,y_{k-1})}{\displaystyle\int~{}p(y_{k}|x^{\prime\prime}%
 _{k})~{}\widehat{p}(dx^{\prime\prime}_{k}|y_{0},\ldots,y_{k-1})}    ">p(x_k~|~y_0,\ldots,y_{k-1})~dx_k$ by the empirical measure     ∫  p   (   x   k  +  1    |   x  k  ′   )      p   (   y  k   |   x  k  ′   )    p  ^    (  d   x  k  ′   |   y  0   ,  …  ,   y   k  -  1    )       ∫    p   (   y  k   |   x  k  ′′   )    p  ^    (  d   x  k  ′′   |   y  0   ,  …  ,   y   k  -  1    )      =     ∑   1  ≤  i  ≤  N          p   (    y  k    |   ξ  k  i   )      ∑   1  ≤  j  ≤  N    p   (    y  k    |   ξ  k  j   )       p   (    x   k  +  1     |   ξ  k  i   )   =  :   q  ^    (   x   k  +  1    |   y  0   ,  …  ,   y  k   )      fragments   p   fragments  normal-(   subscript  x    k  1    normal-|   subscript   superscript  x  normal-′   k   normal-)      fragments  p   fragments  normal-(   subscript  y  k   normal-|   superscript   subscript  x  k   normal-′   normal-)    normal-^  p    fragments  normal-(  d   subscript   superscript  x  normal-′   k   normal-|   subscript  y  0   normal-,  normal-…  normal-,   subscript  y    k  1    normal-)     fragments   p   fragments  normal-(   subscript  y  k   normal-|   subscript   superscript  x  ′′   k   normal-)    normal-^  p    fragments  normal-(  d   subscript   superscript  x  ′′   k   normal-|   subscript  y  0   normal-,  normal-…  normal-,   subscript  y    k  1    normal-)       subscript       1  i       N        fragments  p   fragments  normal-(   subscript  y  k   normal-|   subscript   superscript  ξ  i   k   normal-)     fragments   subscript       1  j       N     p   fragments  normal-(   subscript  y  k   normal-|   subscript   superscript  ξ  j   k   normal-)     p   fragments  normal-(   subscript  x    k  1    normal-|   subscript   superscript  ξ  i   k   normal-)    normal-:   normal-^  q    fragments  normal-(   subscript  x    k  1    normal-|   subscript  y  0   normal-,  normal-…  normal-,   subscript  y  k   normal-)     \int~{}p(x_{k+1}|x^{\prime}_{k})~{}\displaystyle\frac{p(y_{k}|x_{k}^{\prime})~%
 {}\widehat{p}(dx^{\prime}_{k}|y_{0},\dots,y_{k-1})}{\displaystyle\int~{}p(y_{k%
 }|x^{\prime\prime}_{k})~{}\widehat{p}(dx^{\prime\prime}_{k}|y_{0},\ldots,y_{k-%
 1})}=\sum_{1\leq i\leq N}~{}\frac{p(y_{k}~{}|~{}\xi^{i}_{k})}{\sum_{1\leq j%
 \leq N}p(y_{k}~{}|~{}\xi^{j}_{k})}~{}~{}p(x_{k+1}~{}|~{}\xi^{i}_{k})=:\widehat%
 {q}(x_{k+1}|y_{0},\ldots,y_{k})   ">\widehat{p}(dx_k~|~y_0,\ldots,y_{k-1})$ in the evolution equation of the one-step optimal filter stated in () we find that     p   (    y  k    |   ξ  k  i   )      fragments  p   fragments  normal-(   subscript  y  k   normal-|   subscript   superscript  ξ  i   k   normal-)     p(y_{k}~{}|~{}\xi^{i}_{k})   Notice that the right hand side in the above formula is a weighted probability mixture      p   (    y  k    |   x  k   )      fragments  p   fragments  normal-(   subscript  y  k   normal-|   subscript  x  k   normal-)     p(y_{k}~{}|~{}x_{k})     where     x  k   =   ξ  k  i        subscript  x  k    subscript   superscript  ξ  i   k     x_{k}=\xi^{i}_{k}   stands for the density    p   (    x   k  +  1     |   ξ  k  i   )      fragments  p   fragments  normal-(   subscript  x    k  1    normal-|   subscript   superscript  ξ  i   k   normal-)     p(x_{k+1}~{}|~{}\xi^{i}_{k})   evaluated at    p   (    x   k  +  1     |   x  k   )      fragments  p   fragments  normal-(   subscript  x    k  1    normal-|   subscript  x  k   normal-)     p(x_{k+1}~{}|~{}x_{k})   , and     x  k   =   ξ  k  i        subscript  x  k    subscript   superscript  ξ  i   k     x_{k}=\xi^{i}_{k}   stands for the density     i  =   1  ,  …  ,  N    .      i   1  normal-…  N     i=1,\ldots,N.   evaluated at   N   N   N   , for     (   ξ   k  +  1   i   )    1  ≤  i  ≤  N      subscript   subscript   superscript  ξ  i     k  1        1  i       N      \left(\xi^{i}_{k+1}\right)_{1\leq i\leq N}     Then, we sample     q  ^    (   x   k  +  1    |   y  0   ,  …  ,   y  k   )      fragments   normal-^  q    fragments  normal-(   subscript  x    k  1    normal-|   subscript  y  0   normal-,  normal-…  normal-,   subscript  y  k   normal-)     \widehat{q}(x_{k+1}|y_{0},\ldots,y_{k})   independent random variable     p  ^    (  d   x   k  +  1    |   y  0   ,  …  ,   y  k   )   :=   1  N    ∑   1  ≤  i  ≤  N     δ   ξ   k  +  1   i     (  d   x   k  +  1    )     ≈   N  ↑  ∞      q  ^    (    x   k  +  1     |   y  0   ,  …  ,   y  k   )   d   x   k  +  1      ≈   N  ↑  ∞     p   (    x   k  +  1     |   y  0   ,  …  ,   y  k   )   d   x   k  +  1       fragments   normal-^  p    fragments  normal-(  d   subscript  x    k  1    normal-|   subscript  y  0   normal-,  normal-…  normal-,   subscript  y  k   normal-)   assign    1  N    subscript       1  i       N      subscript  δ   subscript   superscript  ξ  i     k  1      fragments  normal-(  d   subscript  x    k  1    normal-)    subscript    normal-↑  N      normal-^  q    fragments  normal-(   subscript  x    k  1    normal-|   subscript  y  0   normal-,  normal-…  normal-,   subscript  y  k   normal-)   d   subscript  x    k  1     subscript    normal-↑  N     p   fragments  normal-(   subscript  x    k  1    normal-|   subscript  y  0   normal-,  normal-…  normal-,   subscript  y  k   normal-)   d   subscript  x    k  1      \widehat{p}(dx_{k+1}|y_{0},\ldots,y_{k}):=\frac{1}{N}\sum_{1\leq i\leq N}%
 \delta_{\xi^{i}_{k+1}}(dx_{k+1})\approx_{N\uparrow\infty}~{}\widehat{q}(x_{k+1%
 }~{}|~{}y_{0},\ldots,y_{k})dx_{k+1}\approx_{N\uparrow\infty}~{}p(x_{k+1}~{}|~{%
 }y_{0},\ldots,y_{k})dx_{k+1}   with common probability density     p  ^    (  d   x  k   |   y  0   ,  …  ,   y   k  -  1    )   :=   1  N    ∑   1  ≤  i  ≤  N     δ   ξ  k  i     (  d   x  k   )     ≈   N  ↑  ∞     p   (  d    x  k    |   y  0   ,  …  ,   y   k  -  1    )   :=  p   (    x  k    |   y  0   ,  …  ,   y   k  -  1    )   d   x  k      fragments   normal-^  p    fragments  normal-(  d   subscript  x  k   normal-|   subscript  y  0   normal-,  normal-…  normal-,   subscript  y    k  1    normal-)   assign    1  N    subscript       1  i       N      subscript  δ   subscript   superscript  ξ  i   k     fragments  normal-(  d   subscript  x  k   normal-)    subscript    normal-↑  N     p   fragments  normal-(  d   subscript  x  k   normal-|   subscript  y  0   normal-,  normal-…  normal-,   subscript  y    k  1    normal-)   assign  p   fragments  normal-(   subscript  x  k   normal-|   subscript  y  0   normal-,  normal-…  normal-,   subscript  y    k  1    normal-)   d   subscript  x  k     \widehat{p}(dx_{k}|y_{0},\ldots,y_{k-1}):=\frac{1}{N}\sum_{1\leq i\leq N}%
 \delta_{\xi^{i}_{k}}(dx_{k})\approx_{N\uparrow\infty}~{}p(dx_{k}~{}|~{}y_{0},%
 \ldots,y_{k-1}):=p(x_{k}~{}|~{}y_{0},\ldots,y_{k-1})dx_{k}   so that      p   (  d   x  k   |   y  0   ,  …  ,   y  k   )     ≈   N  ↑  ∞        p   (   y  k   |   x  k   )    p  ^    (  d   x  k   |   y  0   ,  …  ,   y   k  -  1    )      ∫   p   (   y  k   |   x  k  ′   )    p  ^    (  d   x  k  ′   |   y  0   ,  …  ,   y   k  -  1    )      =     ∑   1  ≤  i  ≤  N          p   (    y  k    |   ξ  k  i   )      ∑   1  ≤  j  ≤  N    p   (    y  k    |   ξ  k  j   )        δ   ξ  k  i     (  d   x  k   )      fragments  p   fragments  normal-(  d   subscript  x  k   normal-|   subscript  y  0   normal-,  normal-…  normal-,   subscript  y  k   normal-)    subscript    normal-↑  N        fragments  p   fragments  normal-(   subscript  y  k   normal-|   subscript  x  k   normal-)    normal-^  p    fragments  normal-(  d   subscript  x  k   normal-|   subscript  y  0   normal-,  normal-…  normal-,   subscript  y    k  1    normal-)     fragments   p   fragments  normal-(   subscript  y  k   normal-|   subscript   superscript  x  normal-′   k   normal-)    normal-^  p    fragments  normal-(  d   subscript   superscript  x  normal-′   k   normal-|   subscript  y  0   normal-,  normal-…  normal-,   subscript  y    k  1    normal-)       subscript       1  i       N        fragments  p   fragments  normal-(   subscript  y  k   normal-|   subscript   superscript  ξ  i   k   normal-)     fragments   subscript       1  j       N     p   fragments  normal-(   subscript  y  k   normal-|   subscript   superscript  ξ  j   k   normal-)      subscript  δ   subscript   superscript  ξ  i   k     fragments  normal-(  d   subscript  x  k   normal-)     p(dx_{k}|y_{0},\ldots,y_{k})~{}\approx_{N\uparrow\infty}~{}\displaystyle\frac{%
 p(y_{k}|x_{k})~{}\widehat{p}(dx_{k}|y_{0},\ldots,y_{k-1})}{\displaystyle\int p%
 (y_{k}|x^{\prime}_{k})\widehat{p}(dx^{\prime}_{k}|y_{0},\ldots,y_{k-1})}=\sum_%
 {1\leq i\leq N}~{}\frac{p(y_{k}~{}|~{}\xi^{i}_{k})}{\sum_{1\leq j\leq N}p(y_{k%
 }~{}|~{}\xi^{j}_{k})}~{}\delta_{\xi^{i}_{k}}(dx_{k})   Iterating this procedure, we design a Markov chain such that      p   (  d    x  k    |   y  0   ,  …  ,   y   k  -  1    )      fragments  p   fragments  normal-(  d   subscript  x  k   normal-|   subscript  y  0   normal-,  normal-…  normal-,   subscript  y    k  1    normal-)     p(dx_{k}~{}|~{}y_{0},\ldots,y_{k-1})     Notice that the optimal filter is approximated at each time step k using the Bayes' formulae       p  ^    (  d    x  k    |   y  0   ,  …  ,   y   k  -  1    )      fragments   normal-^  p    fragments  normal-(  d   subscript  x  k   normal-|   subscript  y  0   normal-,  normal-…  normal-,   subscript  y    k  1    normal-)     \widehat{p}(dx_{k}~{}|~{}y_{0},\ldots,y_{k-1})    The terminology "mean field approximation" comes from the fact that we replace at each time step the probability measure       I  k    (  f  )   :=  ∫  f   (   x  k   )   p   (  d   x  k   |   y  0   ,  …  ,   y   k  -  1    )     ≈   N  ↑  ∞       I  ^   k    (  f  )   :=  ∫  f   (   x  k   )    p  ^    (  d   x  k   |   y  0   ,  …  ,   y   k  -  1    )      fragments   subscript  I  k    fragments  normal-(  f  normal-)   assign   f   fragments  normal-(   subscript  x  k   normal-)   p   fragments  normal-(  d   subscript  x  k   normal-|   subscript  y  0   normal-,  normal-…  normal-,   subscript  y    k  1    normal-)    subscript    normal-↑  N      subscript   normal-^  I   k    fragments  normal-(  f  normal-)   assign   f   fragments  normal-(   subscript  x  k   normal-)    normal-^  p    fragments  normal-(  d   subscript  x  k   normal-|   subscript  y  0   normal-,  normal-…  normal-,   subscript  y    k  1    normal-)     I_{k}(f):=\int f(x_{k})~{}p(dx_{k}|y_{0},\ldots,y_{k-1})~{}\approx_{N\uparrow%
 \infty}~{}\widehat{I}_{k}(f):=\int f(x_{k})~{}\widehat{p}(dx_{k}|y_{0},\ldots,%
 y_{k-1})~{}     by the empirical approximation         sup   k  ≥  0     |    E   (     I  ^   k    (  f  )    )    -    I  k    (  f  )     |    ≤     c  1   /  N   and       sup   k  ≥  0     E   (    [      I  ^   k    (  f  )    -    I  k    (  f  )     ]   2   )     ≤    c  2   /  N       formulae-sequence      subscript  supremum    k  0          E     subscript   normal-^  I   k   f       subscript  I  k   f          subscript  c  1   N   and        subscript  supremum    k  0      E   superscript   delimited-[]       subscript   normal-^  I   k   f      subscript  I  k   f     2        subscript  c  2   N      \sup_{k\geq 0}\left|E\left(\widehat{I}_{k}(f)\right)-I_{k}(f)\right|\leq{c_{1}%
 }/{N}\quad\mbox{and}\quad\sup_{k\geq 0}E\left(\left[\widehat{I}_{k}(f)-I_{k}(f%
 )\right]^{2}\right)\leq{c_{2}}/{N}    . The mean field particle approximation of the filtering problem is far from being unique. Several strategies are developed in the books. 99 100  Some convergence results  The analysis of the convergence of particle filters has been started in 1996 101 102 and in 2000 in the book 103 and the series of articles. 104 105 106 107 108 109 110 More recent developments can be found in the books, 111 112 When the filtering equation is stable (in the sense that it corrects any erroneous initial condition), the bias and the variance of the particle particle estimates         c  1   ,   c  2    <   ∞    .        subscript  c  1    subscript  c  2       c_{1},c_{2}<\infty~{}.   are controlled by the non asymptotic uniform estimates    x  ≥  0      x  0    x\geq 0   for any function f(.) bounded by 1, and for some finite constants      |      I  ^   k    (  f  )    -    I  k    (  f  )     |   ≤       c  1     x  N    +     c  2      x  N      and       sup   0  ≤  k  ≤  n     |      I  ^   k    (  f  )    -    I  k    (  f  )     |    ≤    c      x   log   (  n  )     N         formulae-sequence           subscript   normal-^  I   k   f      subscript  I  k   f           subscript  c  1     x  N       subscript  c  2       x  N      and        subscript  supremum      0  k       n            subscript   normal-^  I   k   f      subscript  I  k   f        c        x    n    N        \left|\widehat{I}_{k}(f)-I_{k}(f)\right|\leq c_{1}~{}\frac{x}{N}+c_{2}~{}\sqrt%
 {\frac{x}{N}}\quad\mbox{and}\quad\sup_{0\leq k\leq n}\left|\widehat{I}_{k}(f)-%
 I_{k}(f)\right|\leq c~{}\sqrt{\frac{x\log(n)}{N}}   In addition, for any    1  -   e   -  x        1   superscript  e    x      1-e^{-x}   , the probability that       c  1     and    c  2    <   ∞          subscript  c  1   and   subscript  c  2       c_{1}~{}\mbox{and}~{}c_{2}<\infty~{}   is larger than    (    ξ  ^    0  ,  k   i   ,    ξ  ^    1  ,  k   i   ,  …  ,    ξ  ^     k  -  1   ,  k   i   ,    ξ  ^    k  ,  k   i   )      subscript   superscript   normal-^  ξ   i    0  k     subscript   superscript   normal-^  ξ   i    1  k    normal-…   subscript   superscript   normal-^  ξ   i      k  1   k     subscript   superscript   normal-^  ξ   i    k  k      \left(\widehat{\xi}^{i}_{0,k},\widehat{\xi}^{i}_{1,k},\ldots,\widehat{\xi}^{i}%
 _{k-1,k},\widehat{\xi}^{i}_{k,k}\right)   , for some finite constants    (   ξ   0  ,  k   i   ,   ξ   1  ,  k   i   ,  …  ,   ξ    k  -  1   ,  k   i   ,   ξ   k  ,  k    )      subscript   superscript  ξ  i    0  k     subscript   superscript  ξ  i    1  k    normal-…   subscript   superscript  ξ  i      k  1   k     subscript  ξ   k  k      \left(\xi^{i}_{0,k},\xi^{i}_{1,k},\ldots,\xi^{i}_{k-1,k},\xi_{k,k}\right)   related to the asymptotic bias and variance of the particle estimate, and some finite constant c. The same results are satisfied if we replace the one step optimal predictor by the optimal filter approximation.  Genealogical trees and Unbiasedness properties  Genealogical tree based particle smoothing  Tracing back in time the ancestral lines      ξ  ^   k  i      (    =    ξ  ^    k  ,  k   i    )      annotated   subscript   superscript   normal-^  ξ   i   k     absent   subscript   superscript   normal-^  ξ   i    k  k       \widehat{\xi}^{i}_{k}\left(=\widehat{\xi}^{i}_{k,k}\right)   and     ξ  k  i      (    =   ξ   k  ,  k   i    )      annotated   subscript   superscript  ξ  i   k     absent   subscript   superscript  ξ  i    k  k       {\xi}^{i}_{k}\left(={\xi}^{i}_{k,k}\right)   of the individuals     p  ^    (  d   (   x  0   ,  …  ,   x  k   )   |   y  0   ,  …  ,   y  k   )   :=   1  N    ∑   1  ≤  i  ≤  N     δ   (    ξ  ^    0  ,  k   i   ,  …  ,    ξ  ^    0  ,  k   i   )     (  d   (   x  0   ,  …  ,   x  k   )   )     ≈   N  ↑  ∞     p   (  d   (   x  0   ,  …  ,   x  k   )   |   y  0   ,  …  ,   y  k   )      fragments   normal-^  p    fragments  normal-(  d   fragments  normal-(   subscript  x  0   normal-,  normal-…  normal-,   subscript  x  k   normal-)   normal-|   subscript  y  0   normal-,  normal-…  normal-,   subscript  y  k   normal-)   assign    1  N    subscript       1  i       N      subscript  δ    subscript   superscript   normal-^  ξ   i    0  k    normal-…   subscript   superscript   normal-^  ξ   i    0  k       fragments  normal-(  d   fragments  normal-(   subscript  x  0   normal-,  normal-…  normal-,   subscript  x  k   normal-)   normal-)    subscript    normal-↑  N     p   fragments  normal-(  d   fragments  normal-(   subscript  x  0   normal-,  normal-…  normal-,   subscript  x  k   normal-)   normal-|   subscript  y  0   normal-,  normal-…  normal-,   subscript  y  k   normal-)     \widehat{p}(d(x_{0},\ldots,x_{k})~{}|~{}y_{0},\ldots,y_{k}):=\frac{1}{N}\sum_{%
 1\leq i\leq N}\delta_{\left(\widehat{\xi}^{i}_{0,k},\ldots,\widehat{\xi}^{i}_{%
 0,k}\right)}(d(x_{0},\ldots,x_{k}))~{}~{}\approx_{N\uparrow\infty}~{}~{}p(d(x_%
 {0},\ldots,x_{k})~{}|~{}y_{0},\ldots,y_{k})   and    p   (  d   (   x  0   ,  …  ,   x  k   )   |   y  0   ,  …  ,   y  k   )     ≈   N  ↑  ∞       ∑   1  ≤  i  ≤  N        p   (    y  k    |   ξ   k  ,  k   i   )       ∑   1  ≤  j  ≤  N     p   (    y  k    |   ξ   k  ,  k   j   )       δ   (   ξ   0  ,  k   i   ,  …  ,   ξ   0  ,  k   i   )     (  d   (   x  0   ,  …  ,   x  k   )   )      fragments  p   fragments  normal-(  d   fragments  normal-(   subscript  x  0   normal-,  normal-…  normal-,   subscript  x  k   normal-)   normal-|   subscript  y  0   normal-,  normal-…  normal-,   subscript  y  k   normal-)    subscript    normal-↑  N      subscript       1  i       N        fragments  p   fragments  normal-(   subscript  y  k   normal-|   subscript   superscript  ξ  i    k  k    normal-)     fragments   subscript       1  j       N     p   fragments  normal-(   subscript  y  k   normal-|   subscript   superscript  ξ  j    k  k    normal-)      subscript  δ    subscript   superscript  ξ  i    0  k    normal-…   subscript   superscript  ξ  i    0  k       fragments  normal-(  d   fragments  normal-(   subscript  x  0   normal-,  normal-…  normal-,   subscript  x  k   normal-)   normal-)     p(d(x_{0},\ldots,x_{k})~{}|~{}y_{0},\ldots,y_{k})~{}\approx_{N\uparrow\infty}~%
 {}~{}\sum_{1\leq i\leq N}~{}\frac{p(y_{k}~{}|~{}\xi^{i}_{k,k})}{\sum_{1\leq j%
 \leq N}p(y_{k}~{}|~{}\xi^{j}_{k,k})}~{}\delta_{\left(\xi^{i}_{0,k},\ldots,\xi^%
 {i}_{0,k}\right)}(d(x_{0},\ldots,x_{k}))   at every time step k, we also have the particle approximations       p  ^    (  d   (   x  0   ,  …  ,   x  k   )   |   y  0   ,  …  ,   y   k  -  1    )   :=   1  N    ∑   1  ≤  i  ≤  N     δ   (   ξ   0  ,  k   i   ,  …  ,   ξ   k  ,  k   i   )     (  d   (   x  0   ,  …  ,   x  k   )   )     ≈   N  ↑  ∞     p   (  d   (   x  0   ,  …  ,   x  k   )   |   y  0   ,  …  ,   y   k  -  1    )   :=  p   (   x  0   ,  …  ,    x  k    |   y  0   ,  …  ,   y   k  -  1    )   d   x  0   ,  …  ,  d   x  k      fragments   normal-^  p    fragments  normal-(  d   fragments  normal-(   subscript  x  0   normal-,  normal-…  normal-,   subscript  x  k   normal-)   normal-|   subscript  y  0   normal-,  normal-…  normal-,   subscript  y    k  1    normal-)   assign    1  N    subscript       1  i       N      subscript  δ    subscript   superscript  ξ  i    0  k    normal-…   subscript   superscript  ξ  i    k  k       fragments  normal-(  d   fragments  normal-(   subscript  x  0   normal-,  normal-…  normal-,   subscript  x  k   normal-)   normal-)    subscript    normal-↑  N     p   fragments  normal-(  d   fragments  normal-(   subscript  x  0   normal-,  normal-…  normal-,   subscript  x  k   normal-)   normal-|   subscript  y  0   normal-,  normal-…  normal-,   subscript  y    k  1    normal-)   assign  p   fragments  normal-(   subscript  x  0   normal-,  normal-…  normal-,   subscript  x  k   normal-|   subscript  y  0   normal-,  normal-…  normal-,   subscript  y    k  1    normal-)   d   subscript  x  0   normal-,  normal-…  normal-,  d   subscript  x  k     \widehat{p}(d(x_{0},\ldots,x_{k})~{}|~{}y_{0},\ldots,y_{k-1}):=\frac{1}{N}\sum%
 _{1\leq i\leq N}\delta_{\left(\xi^{i}_{0,k},\ldots,\xi^{i}_{k,k}\right)}(d(x_{%
 0},\ldots,x_{k}))~{}~{}\approx_{N\uparrow\infty}~{}~{}p(d(x_{0},\ldots,x_{k})~%
 {}|~{}y_{0},\ldots,y_{k-1}):=p(x_{0},\ldots,x_{k}~{}|~{}y_{0},\ldots,y_{k-1})~%
 {}dx_{0},\ldots,dx_{k}   and      ∫  F   (   x  0   ,  …  ,   x  n   )    p  ^    (  d   (   x  0   ,  …  ,   x  k   )   |   y  0   ,  …  ,   y  k   )   :=   1  N    ∑   1  ≤  i  ≤  N    F   (    ξ  ^    0  ,  k   i   ,  …  ,    ξ  ^    0  ,  k   i   )     ≈   N  ↑  ∞     ∫  F   (   x  0   ,  …  ,   x  n   )   p   (  d   (   x  0   ,  …  ,   x  k   )   |   y  0   ,  …  ,   y  k   )      fragments   F   fragments  normal-(   subscript  x  0   normal-,  normal-…  normal-,   subscript  x  n   normal-)    normal-^  p    fragments  normal-(  d   fragments  normal-(   subscript  x  0   normal-,  normal-…  normal-,   subscript  x  k   normal-)   normal-|   subscript  y  0   normal-,  normal-…  normal-,   subscript  y  k   normal-)   assign    1  N    subscript       1  i       N     F   fragments  normal-(   subscript   superscript   normal-^  ξ   i    0  k    normal-,  normal-…  normal-,   subscript   superscript   normal-^  ξ   i    0  k    normal-)    subscript    normal-↑  N      F   fragments  normal-(   subscript  x  0   normal-,  normal-…  normal-,   subscript  x  n   normal-)   p   fragments  normal-(  d   fragments  normal-(   subscript  x  0   normal-,  normal-…  normal-,   subscript  x  k   normal-)   normal-|   subscript  y  0   normal-,  normal-…  normal-,   subscript  y  k   normal-)     \int F(x_{0},\ldots,x_{n})~{}\widehat{p}(d(x_{0},\ldots,x_{k})~{}|~{}y_{0},%
 \ldots,y_{k}):=\frac{1}{N}\sum_{1\leq i\leq N}F\left(\widehat{\xi}^{i}_{0,k},%
 \ldots,\widehat{\xi}^{i}_{0,k}\right)~{}~{}\approx_{N\uparrow\infty}~{}~{}\int%
 ~{}F(x_{0},\ldots,x_{n})~{}p(d(x_{0},\ldots,x_{k})~{}|~{}y_{0},\ldots,y_{k})   and finally      ∫  F   (   x  0   ,  …  ,   x  n   )   p   (  d   (   x  0   ,  …  ,   x  k   )   |   y  0   ,  …  ,   y  k   )     ≈   N  ↑  ∞       ∑   1  ≤  i  ≤  N        p   (    y  k    |   ξ   k  ,  k   i   )       ∑   1  ≤  j  ≤  N     p   (    y  k    |   ξ   k  ,  k   j   )      F   (   ξ   0  ,  k   i   ,   ξ   1  ,  k   i   ,  …  ,   ξ   k  ,  k   i   )      fragments   F   fragments  normal-(   subscript  x  0   normal-,  normal-…  normal-,   subscript  x  n   normal-)   p   fragments  normal-(  d   fragments  normal-(   subscript  x  0   normal-,  normal-…  normal-,   subscript  x  k   normal-)   normal-|   subscript  y  0   normal-,  normal-…  normal-,   subscript  y  k   normal-)    subscript    normal-↑  N      subscript       1  i       N        fragments  p   fragments  normal-(   subscript  y  k   normal-|   subscript   superscript  ξ  i    k  k    normal-)     fragments   subscript       1  j       N     p   fragments  normal-(   subscript  y  k   normal-|   subscript   superscript  ξ  j    k  k    normal-)     F   fragments  normal-(   subscript   superscript  ξ  i    0  k    normal-,   subscript   superscript  ξ  i    1  k    normal-,  normal-…  normal-,   subscript   superscript  ξ  i    k  k    normal-)     \int F(x_{0},\ldots,x_{n})~{}p(d(x_{0},\ldots,x_{k})~{}|~{}y_{0},\ldots,y_{k})%
 ~{}\approx_{N\uparrow\infty}~{}~{}\sum_{1\leq i\leq N}~{}\frac{p(y_{k}~{}|~{}%
 \xi^{i}_{k,k})}{\sum_{1\leq j\leq N}p(y_{k}~{}|~{}\xi^{j}_{k,k})}~{}F\left(\xi%
 ^{i}_{0,k},\xi^{i}_{1,k},\ldots,\xi^{i}_{k,k}\right)   These empirical approximations are equivalent to the particle integral approximations      ∫  F   (   x  0   ,  …  ,   x  n   )    p  ^    (  d   (   x  0   ,  …  ,   x  k   )   |   y  0   ,  …  ,   y   k  -  1    )   :=   1  N    ∑   1  ≤  i  ≤  N    F   (   ξ   0  ,  k   i   ,  …  ,   ξ   k  ,  k   i   )     ≈   N  ↑  ∞     ∫  F   (   x  0   ,  …  ,   x  n   )   p   (  d   (   x  0   ,  …  ,   x  k   )   |   y  0   ,  …  ,   y   k  -  1    )      fragments   F   fragments  normal-(   subscript  x  0   normal-,  normal-…  normal-,   subscript  x  n   normal-)    normal-^  p    fragments  normal-(  d   fragments  normal-(   subscript  x  0   normal-,  normal-…  normal-,   subscript  x  k   normal-)   normal-|   subscript  y  0   normal-,  normal-…  normal-,   subscript  y    k  1    normal-)   assign    1  N    subscript       1  i       N     F   fragments  normal-(   subscript   superscript  ξ  i    0  k    normal-,  normal-…  normal-,   subscript   superscript  ξ  i    k  k    normal-)    subscript    normal-↑  N      F   fragments  normal-(   subscript  x  0   normal-,  normal-…  normal-,   subscript  x  n   normal-)   p   fragments  normal-(  d   fragments  normal-(   subscript  x  0   normal-,  normal-…  normal-,   subscript  x  k   normal-)   normal-|   subscript  y  0   normal-,  normal-…  normal-,   subscript  y    k  1    normal-)     \int~{}F(x_{0},\ldots,x_{n})~{}\widehat{p}(d(x_{0},\ldots,x_{k})~{}|~{}y_{0},%
 \ldots,y_{k-1}):=\frac{1}{N}\sum_{1\leq i\leq N}F\left(\xi^{i}_{0,k},\ldots,%
 \xi^{i}_{k,k}\right)~{}~{}\approx_{N\uparrow\infty}~{}~{}\int~{}F(x_{0},\ldots%
 ,x_{n})~{}p(d(x_{0},\ldots,x_{k})~{}|~{}y_{0},\ldots,y_{k-1})   and      p   (   y  0   ,  …  ,   y  n   )   =   ∏   0  ≤  k  ≤  n    p   (   y  k   |   y  0   ,  …  ,   y   k  -  1    )   with  p   (   y  k   |   y  0   ,  …  ,   y   k  -  1    )   =  ∫  p   (   y  k   |   x  k   )   p   (  d   x  k   |   y  0   ,  …  ,   y   k  -  1    )      fragments  p   fragments  normal-(   subscript  y  0   normal-,  normal-…  normal-,   subscript  y  n   normal-)     subscript  product      0  k       n     p   fragments  normal-(   subscript  y  k   normal-|   subscript  y  0   normal-,  normal-…  normal-,   subscript  y    k  1    normal-)    with   p   fragments  normal-(   subscript  y  k   normal-|   subscript  y  0   normal-,  normal-…  normal-,   subscript  y    k  1    normal-)     p   fragments  normal-(   subscript  y  k   normal-|   subscript  x  k   normal-)   p   fragments  normal-(  d   subscript  x  k   normal-|   subscript  y  0   normal-,  normal-…  normal-,   subscript  y    k  1    normal-)     p(y_{0},\ldots,y_{n})=\prod_{0\leq k\leq n}p(y_{k}|y_{0},\ldots,y_{k-1})\quad%
 \mbox{with}\quad p(y_{k}|y_{0},\ldots,y_{k-1})=\int~{}p(y_{k}|x_{k})~{}p(dx_{k%
 }|y_{0},\ldots,y_{k-1})   and finally      p   (   y  0   |   y  0   ,  …  ,   y   -  1    )   =  p   (   y  0   )      fragments  p   fragments  normal-(   subscript  y  0   normal-|   subscript  y  0   normal-,  normal-…  normal-,   subscript  y    1    normal-)    p   fragments  normal-(   subscript  y  0   normal-)     p(y_{0}|y_{0},\ldots,y_{-1})=p(y_{0})     for any bounded function F on the random trajectories of the signal. As shown in 113 the evolution of the genealogical tree coincides with a mean field particle interpretation of the evolution equations associated with the posterior densities of the signal trajectories. For more details on these path space models, we refer to the books. 114 115  Unbiased particle estimates of likelihood functions  We use the product formula    p   (   x  0   |   y  0   ,  …  ,   y   -  1    )   =  p   (   x  0   )      fragments  p   fragments  normal-(   subscript  x  0   normal-|   subscript  y  0   normal-,  normal-…  normal-,   subscript  y    1    normal-)    p   fragments  normal-(   subscript  x  0   normal-)     p(x_{0}|y_{0},\ldots,y_{-1})=p(x_{0})   with the conventions    p   (   x  k   |   y  0   ,  …  ,   y   k  -  1    )   d   x  k      fragments  p   fragments  normal-(   subscript  x  k   normal-|   subscript  y  0   normal-,  normal-…  normal-,   subscript  y    k  1    normal-)   d   subscript  x  k     p(x_{k}|y_{0},\ldots,y_{k-1})dx_{k}   and     p  ^    (  d    x  k    |   y  0   ,  …  ,   y   k  -  1    )   :=   1  N    ∑   1  ≤  i  ≤  N     δ   ξ  k  i     (  d   x  k   )     ≈   N  ↑  ∞     p   (  d    x  k    |   y  0   ,  …  ,   y   k  -  1    )      fragments   normal-^  p    fragments  normal-(  d   subscript  x  k   normal-|   subscript  y  0   normal-,  normal-…  normal-,   subscript  y    k  1    normal-)   assign    1  N    subscript       1  i       N      subscript  δ   subscript   superscript  ξ  i   k     fragments  normal-(  d   subscript  x  k   normal-)    subscript    normal-↑  N     p   fragments  normal-(  d   subscript  x  k   normal-|   subscript  y  0   normal-,  normal-…  normal-,   subscript  y    k  1    normal-)     \widehat{p}(dx_{k}~{}|~{}y_{0},\ldots,y_{k-1}):=\frac{1}{N}\sum_{1\leq i\leq N%
 }\delta_{\xi^{i}_{k}}(dx_{k})~{}~{}\approx_{N\uparrow\infty}~{}~{}p(dx_{k}~{}|%
 ~{}y_{0},\ldots,y_{k-1})   , for k=0. Replacing    p   (   y  0   ,  …  ,   y  n   )     ≈   N  ↑  ∞      p  ^    (   y  0   ,  …  ,   y  n   )   =   ∏   0  ≤  k  ≤  n     p  ^    (   y  k   |   y  0   ,  …  ,   y   k  -  1    )   with   p  ^    (   y  k   |   y  0   ,  …  ,   y   k  -  1    )   =  ∫  p   (   y  k   |   x  k   )    p  ^    (  d   x  k   |   y  0   ,  …  ,   y   k  -  1    )   =   1  N     ∑   1  ≤  i  ≤  N     p   (   y  k   |   ξ  k  i   )      fragments  p   fragments  normal-(   subscript  y  0   normal-,  normal-…  normal-,   subscript  y  n   normal-)    subscript    normal-↑  N      normal-^  p    fragments  normal-(   subscript  y  0   normal-,  normal-…  normal-,   subscript  y  n   normal-)     subscript  product      0  k       n      normal-^  p    fragments  normal-(   subscript  y  k   normal-|   subscript  y  0   normal-,  normal-…  normal-,   subscript  y    k  1    normal-)    with    normal-^  p    fragments  normal-(   subscript  y  k   normal-|   subscript  y  0   normal-,  normal-…  normal-,   subscript  y    k  1    normal-)     p   fragments  normal-(   subscript  y  k   normal-|   subscript  x  k   normal-)    normal-^  p    fragments  normal-(  d   subscript  x  k   normal-|   subscript  y  0   normal-,  normal-…  normal-,   subscript  y    k  1    normal-)      1  N    subscript       1  i       N     p   fragments  normal-(   subscript  y  k   normal-|   subscript   superscript  ξ  i   k   normal-)     p(y_{0},\ldots,y_{n})~{}~{}\approx_{N\uparrow\infty}~{}~{}\widehat{p}(y_{0},%
 \ldots,y_{n})=\prod_{0\leq k\leq n}\widehat{p}(y_{k}|y_{0},\ldots,y_{k-1})%
 \quad\mbox{with}\quad\widehat{p}(y_{k}|y_{0},\ldots,y_{k-1})=\int~{}p(y_{k}|x_%
 {k})~{}\widehat{p}(dx_{k}|y_{0},\ldots,y_{k-1})=\frac{1}{N}\sum_{1\leq i\leq N%
 }~{}p(y_{k}|\xi^{i}_{k})   by the empirical approximation      p   (    y  k    |   ξ  k  i   )      fragments  p   fragments  normal-(   subscript  y  k   normal-|   subscript   superscript  ξ  i   k   normal-)     p(y_{k}~{}|~{}\xi^{i}_{k})   in the above displayed formula, we design the following unbiased particle approximation of the likelihood function      p   (    y  k    |   x  k   )      fragments  p   fragments  normal-(   subscript  y  k   normal-|   subscript  x  k   normal-)     p(y_{k}~{}|~{}x_{k})   where     x  k   =   ξ  k  i        subscript  x  k    subscript   superscript  ξ  i   k     x_{k}=\xi^{i}_{k}   stands for the density       p   (   (   x  0   ,  …  ,   x  n   )   |   (   y  0   ,  …  ,   y   n  -  1    )   )            =  p   (    x  n    |   (   y  0   ,  …  ,   y   n  -  1    )   )   p   (    x   n  -  1     |   x  n   ,   (   y  0   ,  …  ,   y   n  -  1    )   )   ×  p   (    x   n  -  2     |   x   n  -  1    ,   (   y  0   ,  …  ,   y   n  -  2    )   )    …   p   (    x  1    |   x  2   ,   (   y  0   ,   y  1   )   )   p   (    x  0    |   x  1   ,   y  0   )           fragments  p   fragments  normal-(   fragments  normal-(   subscript  x  0   normal-,  normal-…  normal-,   subscript  x  n   normal-)   normal-|   fragments  normal-(   subscript  y  0   normal-,  normal-…  normal-,   subscript  y    n  1    normal-)   normal-)       missing-subexpression      fragments   p   fragments  normal-(   subscript  x  n   normal-|   fragments  normal-(   subscript  y  0   normal-,  normal-…  normal-,   subscript  y    n  1    normal-)   normal-)   p   fragments  normal-(   subscript  x    n  1    normal-|   subscript  x  n   normal-,   fragments  normal-(   subscript  y  0   normal-,  normal-…  normal-,   subscript  y    n  1    normal-)   normal-)    p   fragments  normal-(   subscript  x    n  2    normal-|   subscript  x    n  1    normal-,   fragments  normal-(   subscript  y  0   normal-,  normal-…  normal-,   subscript  y    n  2    normal-)   normal-)   normal-…  p   fragments  normal-(   subscript  x  1   normal-|   subscript  x  2   normal-,   fragments  normal-(   subscript  y  0   normal-,   subscript  y  1   normal-)   normal-)   p   fragments  normal-(   subscript  x  0   normal-|   subscript  x  1   normal-,   subscript  y  0   normal-)       \begin{array}[]{l}p((x_{0},\ldots,x_{n})~{}|~{}(y_{0},\ldots,y_{n-1}))\\
 \\
 =p(x_{n}~{}|~{}(y_{0},\ldots,y_{n-1}))~{}p(x_{n-1}~{}|~{}x_{n},(y_{0},\ldots,y%
 _{n-1}))~{}\times p(x_{n-2}~{}|~{}x_{n-1},(y_{0},\ldots,y_{n-2}))~{}~{}\ldots~%
 {}~{}p(x_{1}~{}|~{}x_{2},(y_{0},y_{1}))~{}p(x_{0}~{}|~{}x_{1},y_{0})\end{array}   evaluated at    p   (    x   k  -  1     |   x  k   ,   (   y  0   ,  …  ,   y   k  -  1    )   )   ∝  p   (    x  k    |   x   k  -  1    )   p   (    x   k  -  1     |   (   y  0   ,  …  ,   y   k  -  1    )   )   and  p   (    x   k  -  1     |   (   y  0   ,  …  ,   y   k  -  1    )   ∝  p   (   y   k  -  1    |   x   k  -  1    )   p   (    x   k  -  1     |   (   y  0   ,  …  ,   y   k  -  2    )        fragments  p   fragments  normal-(   subscript  x    k  1    normal-|   subscript  x  k   normal-,   fragments  normal-(   subscript  y  0   normal-,  normal-…  normal-,   subscript  y    k  1    normal-)   normal-)   proportional-to  p   fragments  normal-(   subscript  x  k   normal-|   subscript  x    k  1    normal-)   p   fragments  normal-(   subscript  x    k  1    normal-|   fragments  normal-(   subscript  y  0   normal-,  normal-…  normal-,   subscript  y    k  1    normal-)   normal-)    and   p   fragments  normal-(   subscript  x    k  1    normal-|   fragments  normal-(   subscript  y  0   normal-,  normal-…  normal-,   subscript  y    k  1    normal-)   proportional-to  p   fragments  normal-(   subscript  y    k  1    normal-|   subscript  x    k  1    normal-)   p   fragments  normal-(   subscript  x    k  1    normal-|   fragments  normal-(   subscript  y  0   normal-,  normal-…  normal-,   subscript  y    k  2    normal-)       p(x_{k-1}~{}|~{}x_{k},(y_{0},\ldots,y_{k-1}))\propto p(x_{k}~{}|~{}x_{k-1})~{}%
 p(x_{k-1}~{}|~{}(y_{0},\ldots,y_{k-1}))\quad\mbox{and}\quad p(x_{k-1}~{}|~{}(y%
 _{0},\ldots,y_{k-1})\propto p(y_{k-1}|x_{k-1})~{}p(x_{k-1}~{}|~{}(y_{0},\ldots%
 ,y_{k-2})   . The design of this particle estimate and the unbiasedness property has been proved in 1996 in the article. 116 Refined variance estimates can be found in 117 and. 118  Backward particle smoothers  Using Bayes' rule, we have the formula      p   (    x   k  -  1     |   x  k   ,   (   y  0   ,  …  ,   y   k  -  1    )   )   =    p   (   y   k  -  1    |   x   k  -  1    )   p   (    x  k    |   x   k  -  1    )   p   (   x   k  -  1    |   y  0   ,  …  ,   y   k  -  2    )       ∫    p   (   y   k  -  1    |   x   k  -  1   ′   )   p   (    x  k    |   x   k  -  1   ′   )   p   (   x   k  -  1   ′   |   y  0   ,  …  ,   y   k  -  2    )   d   x   k  -  1   ′        fragments  p   fragments  normal-(   subscript  x    k  1    normal-|   subscript  x  k   normal-,   fragments  normal-(   subscript  y  0   normal-,  normal-…  normal-,   subscript  y    k  1    normal-)   normal-)       fragments  p   fragments  normal-(   subscript  y    k  1    normal-|   subscript  x    k  1    normal-)   p   fragments  normal-(   subscript  x  k   normal-|   subscript  x    k  1    normal-)   p   fragments  normal-(   subscript  x    k  1    normal-|   subscript  y  0   normal-,  normal-…  normal-,   subscript  y    k  2    normal-)     fragments   p   fragments  normal-(   subscript  y    k  1    normal-|   subscript   superscript  x  normal-′     k  1    normal-)   p   fragments  normal-(   subscript  x  k   normal-|   subscript   superscript  x  normal-′     k  1    normal-)   p   fragments  normal-(   subscript   superscript  x  normal-′     k  1    normal-|   subscript  y  0   normal-,  normal-…  normal-,   subscript  y    k  2    normal-)   d   subscript   superscript  x  normal-′     k  1        p(x_{k-1}~{}|~{}x_{k},(y_{0},\ldots,y_{k-1}))=\frac{p(y_{k-1}|x_{k-1})~{}p(x_{%
 k}~{}|~{}x_{k-1})~{}p(x_{k-1}|y_{0},\ldots,y_{k-2})}{\int~{}p(y_{k-1}|x^{%
 \prime}_{k-1})~{}p(x_{k}~{}|~{}x^{\prime}_{k-1})~{}p(x^{\prime}_{k-1}|y_{0},%
 \ldots,y_{k-2})~{}dx^{\prime}_{k-1}}   Notice that      p   (    x   k  -  1     |   (   y  0   ,  …  ,   y   k  -  2    )   )   d   x   k  -  1       fragments  p   fragments  normal-(   subscript  x    k  1    normal-|   fragments  normal-(   subscript  y  0   normal-,  normal-…  normal-,   subscript  y    k  2    normal-)   normal-)   d   subscript  x    k  1      p(x_{k-1}~{}|~{}(y_{0},\ldots,y_{k-2}))dx_{k-1}   This implies that       p  ^    (  d    x   k  -  1     |   (   y  0   ,  …  ,   y   k  -  2    )   )   =   1  N    ∑   1  ≤  i  ≤  N     δ   ξ   k  -  1   i     (  d   x   k  -  1    )    (    ≈   N  ↑  ∞     p   (  d    x   k  -  1     |   (   y  0   ,  …  ,   y   k  -  2    )   )   :=  p   (    x   k  -  1     |   (   y  0   ,  …  ,   y   k  -  2    )   )   d   x   k  -  1    )      fragments   normal-^  p    fragments  normal-(  d   subscript  x    k  1    normal-|   fragments  normal-(   subscript  y  0   normal-,  normal-…  normal-,   subscript  y    k  2    normal-)   normal-)      1  N    subscript       1  i       N      subscript  δ   subscript   superscript  ξ  i     k  1      fragments  normal-(  d   subscript  x    k  1    normal-)    fragments  normal-(   subscript    normal-↑  N     p   fragments  normal-(  d   subscript  x    k  1    normal-|   fragments  normal-(   subscript  y  0   normal-,  normal-…  normal-,   subscript  y    k  2    normal-)   normal-)   assign  p   fragments  normal-(   subscript  x    k  1    normal-|   fragments  normal-(   subscript  y  0   normal-,  normal-…  normal-,   subscript  y    k  2    normal-)   normal-)   d   subscript  x    k  1    normal-)     \widehat{p}(dx_{k-1}~{}|~{}(y_{0},\ldots,y_{k-2}))=\frac{1}{N}\sum_{1\leq i%
 \leq N}\delta_{\xi^{i}_{k-1}}(dx_{k-1})~{}\left(\approx_{N\uparrow\infty}~{}{p%
 }(dx_{k-1}~{}|~{}(y_{0},\ldots,y_{k-2})):={p}(x_{k-1}~{}|~{}(y_{0},\ldots,y_{k%
 -2}))~{}dx_{k-1}\right)     Replacing the one-step optimal predictors    p   (  d    x   k  -  1     |   x  k   ,   (   y  0   ,  …  ,   y   k  -  1    )   )     ≈   N  ↑  ∞          p  ^    (  d    x   k  -  1     |   x  k   ,   (   y  0   ,  …  ,   y   k  -  1    )   )        :  =        p   (   y   k  -  1    |   x   k  -  1    )   p   (    x  k    |   x   k  -  1    )    p  ^    (  d   x   k  -  1    |   y  0   ,  …  ,   y   k  -  2    )     ∫  p   (   y   k  -  1    |   x   k  -  1   ′   )   p   (    x  k    |   x   k  -  1   ′   )    p  ^    (  d   x   k  -  1   ′   |   y  0   ,  …  ,   y   k  -  2    )                =       ∑   1  ≤  i  ≤  N          p   (   y   k  -  1    |   ξ   k  -  1   i   )   p   (    x  k    |   ξ   k  -  1   i   )      ∑   1  ≤  j  ≤  N    p   (   y   k  -  1    |   ξ   k  -  1   j   )   p   (    x  k    |   ξ   k  -  1   j   )        δ   ξ   k  -  1   i     (   d   x   k  -  1     )           fragments  p   fragments  normal-(  d   subscript  x    k  1    normal-|   subscript  x  k   normal-,   fragments  normal-(   subscript  y  0   normal-,  normal-…  normal-,   subscript  y    k  1    normal-)   normal-)    subscript    normal-↑  N        fragments   normal-^  p    fragments  normal-(  d   subscript  x    k  1    normal-|   subscript  x  k   normal-,   fragments  normal-(   subscript  y  0   normal-,  normal-…  normal-,   subscript  y    k  1    normal-)   normal-)     normal-:  absent       fragments  p   fragments  normal-(   subscript  y    k  1    normal-|   subscript  x    k  1    normal-)   p   fragments  normal-(   subscript  x  k   normal-|   subscript  x    k  1    normal-)    normal-^  p    fragments  normal-(  d   subscript  x    k  1    normal-|   subscript  y  0   normal-,  normal-…  normal-,   subscript  y    k  2    normal-)     fragments   p   fragments  normal-(   subscript  y    k  1    normal-|   subscript   superscript  x  normal-′     k  1    normal-)   p   fragments  normal-(   subscript  x  k   normal-|   subscript   superscript  x  normal-′     k  1    normal-)    normal-^  p    fragments  normal-(  d   subscript   superscript  x  normal-′     k  1    normal-|   subscript  y  0   normal-,  normal-…  normal-,   subscript  y    k  2    normal-)        missing-subexpression    missing-subexpression    missing-subexpression      missing-subexpression      subscript       1  i       N          fragments  p   fragments  normal-(   subscript  y    k  1    normal-|   subscript   superscript  ξ  i     k  1    normal-)   p   fragments  normal-(   subscript  x  k   normal-|   subscript   superscript  ξ  i     k  1    normal-)     fragments   subscript       1  j       N     p   fragments  normal-(   subscript  y    k  1    normal-|   subscript   superscript  ξ  j     k  1    normal-)   p   fragments  normal-(   subscript  x  k   normal-|   subscript   superscript  ξ  j     k  1    normal-)      subscript  δ   subscript   superscript  ξ  i     k  1       d   subscript  x    k  1           p(dx_{k-1}~{}|~{}x_{k},(y_{0},\ldots,y_{k-1}))\approx_{N\uparrow\infty}~{}%
 \begin{array}[t]{rcl}\widehat{p}(dx_{k-1}~{}|~{}x_{k},(y_{0},\ldots,y_{k-1}))&%
 :=&\displaystyle\frac{p(y_{k-1}|x_{k-1})~{}p(x_{k}~{}|~{}x_{k-1})~{}\widehat{p%
 }(dx_{k-1}|y_{0},\ldots,y_{k-2})}{\int~{}p(y_{k-1}|x^{\prime}_{k-1})~{}p(x_{k}%
 ~{}|~{}x^{\prime}_{k-1})~{}\widehat{p}(dx^{\prime}_{k-1}|y_{0},\ldots,y_{k-2})%
 }\\
 &&\\
 &=&\displaystyle\sum_{1\leq i\leq N}\frac{p(y_{k-1}|\xi^{i}_{k-1})~{}p(x_{k}~{%
 }|~{}\xi^{i}_{k-1})}{\sum_{1\leq j\leq N}p(y_{k-1}|\xi^{j}_{k-1})~{}p(x_{k}~{}%
 |~{}\xi^{j}_{k-1})}~{}\delta_{\xi^{i}_{k-1}}(dx_{k-1})\end{array}   by the particle empirical measures     p   (  d   (   x  0   ,  …  ,   x  n   )   |   (   y  0   ,  …  ,   y   n  -  1    )   )    ≈   N  ↑  ∞      p  ^    b  a  c  k  w  a  r  d     (  d   (   x  0   ,  …  ,   x  n   )   |   (   y  0   ,  …  ,   y   n  -  1    )   )      fragments  p   fragments  normal-(  d   fragments  normal-(   subscript  x  0   normal-,  normal-…  normal-,   subscript  x  n   normal-)   normal-|   fragments  normal-(   subscript  y  0   normal-,  normal-…  normal-,   subscript  y    n  1    normal-)   normal-)    subscript    normal-↑  N      subscript   normal-^  p     b  a  c  k  w  a  r  d     fragments  normal-(  d   fragments  normal-(   subscript  x  0   normal-,  normal-…  normal-,   subscript  x  n   normal-)   normal-|   fragments  normal-(   subscript  y  0   normal-,  normal-…  normal-,   subscript  y    n  1    normal-)   normal-)     p(d(x_{0},\ldots,x_{n})~{}|~{}(y_{0},\ldots,y_{n-1}))\approx_{N\uparrow\infty}%
 \widehat{p}_{backward}(d(x_{0},\ldots,x_{n})~{}|~{}(y_{0},\ldots,y_{n-1}))   we find that           p  ^    b  a  c  k  w  a  r  d     (  d   (   x  0   ,  …  ,   x  n   )   |   (   y  0   ,  …  ,   y   n  -  1    )   )            =   p  ^    (  d    x  n    |   (   y  0   ,  …  ,   y   n  -  1    )   )    p  ^    (  d    x   n  -  1     |   x  n   ,   (   y  0   ,  …  ,   y   n  -  1    )   )   ×   p  ^    (  d    x   n  -  2     |   x   n  -  1    ,   (   y  0   ,  …  ,   y   n  -  2    )   )    …    p  ^    (  d    x  1    |   x  2   ,   (   y  0   ,   y  1   )   )    p  ^    (  d    x  0    |   x  1   ,   y  0   )           fragments   subscript   normal-^  p     b  a  c  k  w  a  r  d     fragments  normal-(  d   fragments  normal-(   subscript  x  0   normal-,  normal-…  normal-,   subscript  x  n   normal-)   normal-|   fragments  normal-(   subscript  y  0   normal-,  normal-…  normal-,   subscript  y    n  1    normal-)   normal-)       missing-subexpression      fragments    normal-^  p    fragments  normal-(  d   subscript  x  n   normal-|   fragments  normal-(   subscript  y  0   normal-,  normal-…  normal-,   subscript  y    n  1    normal-)   normal-)    normal-^  p    fragments  normal-(  d   subscript  x    n  1    normal-|   subscript  x  n   normal-,   fragments  normal-(   subscript  y  0   normal-,  normal-…  normal-,   subscript  y    n  1    normal-)   normal-)     normal-^  p    fragments  normal-(  d   subscript  x    n  2    normal-|   subscript  x    n  1    normal-,   fragments  normal-(   subscript  y  0   normal-,  normal-…  normal-,   subscript  y    n  2    normal-)   normal-)   normal-…   normal-^  p    fragments  normal-(  d   subscript  x  1   normal-|   subscript  x  2   normal-,   fragments  normal-(   subscript  y  0   normal-,   subscript  y  1   normal-)   normal-)    normal-^  p    fragments  normal-(  d   subscript  x  0   normal-|   subscript  x  1   normal-,   subscript  y  0   normal-)       \begin{array}[]{l}\widehat{p}_{backward}(d(x_{0},\ldots,x_{n})~{}|~{}(y_{0},%
 \ldots,y_{n-1}))\\
 \\
 =\widehat{p}(dx_{n}~{}|~{}(y_{0},\ldots,y_{n-1}))~{}\widehat{p}(dx_{n-1}~{}|~{%
 }x_{n},(y_{0},\ldots,y_{n-1}))~{}\times\widehat{p}(dx_{n-2}~{}|~{}x_{n-1},(y_{%
 0},\ldots,y_{n-2}))~{}~{}\ldots~{}~{}\widehat{p}(dx_{1}~{}|~{}x_{2},(y_{0},y_{%
 1}))~{}\widehat{p}(dx_{0}~{}|~{}x_{1},y_{0})\end{array}     We conclude that      p  ^    b  a  c  k  w  a  r  d     (  d   (   x  0   ,  …  ,   x  n   )   |   (   y  0   ,  …  ,   y   n  -  1    )   )      fragments   subscript   normal-^  p     b  a  c  k  w  a  r  d     fragments  normal-(  d   fragments  normal-(   subscript  x  0   normal-,  normal-…  normal-,   subscript  x  n   normal-)   normal-|   fragments  normal-(   subscript  y  0   normal-,  normal-…  normal-,   subscript  y    n  1    normal-)   normal-)     \widehat{p}_{backward}(d(x_{0},\ldots,x_{n})~{}|~{}(y_{0},\ldots,y_{n-1}))   with the backward particle approximation       (   𝕏   k  ,  n   ♭   )    0  ≤  k  ≤  n      subscript   subscript   superscript  𝕏  normal-♭    k  n        0  k       n      \left(\mathbb{X}^{\flat}_{k,n}\right)_{0\leq k\leq n}     The probability measure        ξ  k  i   ,    with   i    =  1   ,   …  ,  N    .     formulae-sequence      subscript   superscript  ξ  i   k     with  i    1    normal-…  N     \xi^{i}_{k},~{}\mbox{with}~{}i=1,\ldots,N.   is the probability of the random paths of a Markov chain    𝕏   n  ,  n   ♭     subscript   superscript  𝕏  normal-♭    n  n     \mathbb{X}^{\flat}_{n,n}   running backward in time from time k=n to time k=0, and evolving at each time step k in the state space associated with the population of particles     p  ^    (  d    x  n    |   (   y  0   ,  …  ,   y   n  -  1    )   )   =   1  N    ∑   1  ≤  i  ≤  N     δ   ξ  n  i     (  d   x  n   )      fragments   normal-^  p    fragments  normal-(  d   subscript  x  n   normal-|   fragments  normal-(   subscript  y  0   normal-,  normal-…  normal-,   subscript  y    n  1    normal-)   normal-)      1  N    subscript       1  i       N      subscript  δ   subscript   superscript  ξ  i   n     fragments  normal-(  d   subscript  x  n   normal-)     \widehat{p}(dx_{n}~{}|~{}(y_{0},\ldots,y_{n-1}))=\frac{1}{N}\sum_{1\leq i\leq N%
 }\delta_{\xi^{i}_{n}}(dx_{n})      Initially (at time k=n) the chain     𝕏   k  ,  n   ♭   =    ξ  k  i     (   for some   i  =  1  ,  …  ,  N  )      fragments   subscript   superscript  𝕏  normal-♭    k  n      subscript   superscript  ξ  i   k    fragments  normal-(  for some  i   1  normal-,  normal-…  normal-,  N  normal-)     \mathbb{X}^{\flat}_{k,n}=\xi^{i}_{k}~{}(\mbox{for some}~{}i=1,\ldots,N)   chooses randomly a state with the distribution    𝕏    k  -  1   ,  n   ♭     subscript   superscript  𝕏  normal-♭      k  1   n     \mathbb{X}^{\flat}_{k-1,n}     From time k to the time (k-1), the chain starting at some state     p  ^    (  d    x   k  -  1     |   ξ  k  i   ,   (   y  0   ,  …  ,   y   k  -  1    )   )   =    ∑   1  ≤  j  ≤  N         p   (   y   k  -  1    |   ξ   k  -  1   j   )   p   (    ξ  k  i    |   ξ   k  -  1   j   )       ∑   1  ≤  l  ≤  N     p   (   y   k  -  1    |   ξ   k  -  1   l   )   p   (    ξ  k  i    |   ξ   k  -  1   l   )        δ   ξ   k  -  1   j     (  d   x   k  -  1    )      fragments   normal-^  p    fragments  normal-(  d   subscript  x    k  1    normal-|   subscript   superscript  ξ  i   k   normal-,   fragments  normal-(   subscript  y  0   normal-,  normal-…  normal-,   subscript  y    k  1    normal-)   normal-)     subscript       1  j       N        fragments  p   fragments  normal-(   subscript  y    k  1    normal-|   subscript   superscript  ξ  j     k  1    normal-)   p   fragments  normal-(   subscript   superscript  ξ  i   k   normal-|   subscript   superscript  ξ  j     k  1    normal-)     fragments   subscript       1  l       N     p   fragments  normal-(   subscript  y    k  1    normal-|   subscript   superscript  ξ  l     k  1    normal-)   p   fragments  normal-(   subscript   superscript  ξ  i   k   normal-|   subscript   superscript  ξ  l     k  1    normal-)      subscript  δ   subscript   superscript  ξ  j     k  1      fragments  normal-(  d   subscript  x    k  1    normal-)     \widehat{p}(dx_{k-1}~{}|~{}\xi^{i}_{k},(y_{0},\ldots,y_{k-1}))=\displaystyle%
 \sum_{1\leq j\leq N}\frac{p(y_{k-1}|\xi^{j}_{k-1})~{}p(\xi^{i}_{k}~{}|~{}\xi^{%
 j}_{k-1})}{\displaystyle\sum_{1\leq l\leq N}p(y_{k-1}|\xi^{l}_{k-1})~{}p(\xi^{%
 i}_{k}~{}|~{}\xi^{l}_{k-1})}~{}\delta_{\xi^{j}_{k-1}}(dx_{k-1})   at time k moves at time (k-1) to a random state     p  ^    (  d    x   k  -  1     |   ξ  k  i   ,   (   y  0   ,  …  ,   y   k  -  1    )   )      fragments   normal-^  p    fragments  normal-(  d   subscript  x    k  1    normal-|   subscript   superscript  ξ  i   k   normal-,   fragments  normal-(   subscript  y  0   normal-,  normal-…  normal-,   subscript  y    k  1    normal-)   normal-)     \widehat{p}(dx_{k-1}~{}|~{}\xi^{i}_{k},(y_{0},\ldots,y_{k-1}))   chosen with the discrete weighted probability     p  ^    (  d    x   k  -  1     |   x  k   ,   (   y  0   ,  …  ,   y   k  -  1    )   )      fragments   normal-^  p    fragments  normal-(  d   subscript  x    k  1    normal-|   subscript  x  k   normal-,   fragments  normal-(   subscript  y  0   normal-,  normal-…  normal-,   subscript  y    k  1    normal-)   normal-)     \widehat{p}(dx_{k-1}~{}|~{}x_{k},(y_{0},\ldots,y_{k-1}))   In the above displayed formula,     x  k   =   ξ  k  i        subscript  x  k    subscript   superscript  ξ  i   k     x_{k}=\xi^{i}_{k}   stands for the conditional distribution    p   (   y   k  -  1    |   ξ   k  -  1   j   )      fragments  p   fragments  normal-(   subscript  y    k  1    normal-|   subscript   superscript  ξ  j     k  1    normal-)     p(y_{k-1}|\xi^{j}_{k-1})   evaluated at    p   (    ξ  k  i    |   ξ   k  -  1   j   )      fragments  p   fragments  normal-(   subscript   superscript  ξ  i   k   normal-|   subscript   superscript  ξ  j     k  1    normal-)     p(\xi^{i}_{k}~{}|~{}\xi^{j}_{k-1})   . In the same vein,    p   (   y   k  -  1    |   x   k  -  1    )      fragments  p   fragments  normal-(   subscript  y    k  1    normal-|   subscript  x    k  1    normal-)     p(y_{k-1}|x_{k-1})   and    p   (    x  k    |   x   k  -  1    )      fragments  p   fragments  normal-(   subscript  x  k   normal-|   subscript  x    k  1    normal-)     p(x_{k}~{}|~{}x_{k-1})   stand for the conditional densities     x  k   =   ξ  k  i        subscript  x  k    subscript   superscript  ξ  i   k     x_{k}=\xi^{i}_{k}   and      x   k  -  1    =   ξ   k  -  1   j    .       subscript  x    k  1     subscript   superscript  ξ  j     k  1      x_{k-1}=\xi^{j}_{k-1}.   evaluated at    p   (   (   x  0   ,  …  ,   x  n   )   |   (   y  0   ,  …  ,   y   n  -  1    )   )      fragments  p   fragments  normal-(   fragments  normal-(   subscript  x  0   normal-,  normal-…  normal-,   subscript  x  n   normal-)   normal-|   fragments  normal-(   subscript  y  0   normal-,  normal-…  normal-,   subscript  y    n  1    normal-)   normal-)     p((x_{0},\ldots,x_{n})~{}|~{}(y_{0},\ldots,y_{n-1}))   and     f  k    (  .  )      fragments   subscript  f  k    fragments  normal-(  normal-.  normal-)     f_{k}(.)      These models allows to reduce integration with respect to the densities         ∫    p   (  d   (   x  0   ,  …  ,   x  n   )   |   (   y  0   ,  …  ,   y   n  -  1    )   )    f  k    (   x  k   )              ≈   N  ↑  ∞      ∫     p  ^    b  a  c  k  w  a  r  d     (  d   (   x  0   ,  …  ,   x  n   )   |   (   y  0   ,  …  ,   y   n  -  1    )   )    f  k    (   x  k   )            =    ∫     p  ^    (  d    x  n    |   (   y  0   ,  …  ,   y   n  -  1    )   )    p  ^    (  d    x   n  -  1     |   x  n   ,   (   y  0   ,  …  ,   y   n  -  1    )   )   ×   p  ^    (  d    x   n  -  2     |   x   n  -  1    ,   (   y  0   ,  …  ,   y   n  -  2    )   )    …    p  ^    (  d    x  k    |   x   k  +  1    ,   (   y  0   ,  …  ,   y  k   )   )    f  k    (   x  k   )             =      [   1  N   ,  …  ,   1  N   ]   ⏟   N times    𝕄   n  -  1     𝕄   n  -  2    …   𝕄  k    [       f  k    (   ξ  k  1   )        ⋮        f  k    (   ξ  k  N   )       ]            fragments   p   fragments  normal-(  d   fragments  normal-(   subscript  x  0   normal-,  normal-…  normal-,   subscript  x  n   normal-)   normal-|   fragments  normal-(   subscript  y  0   normal-,  normal-…  normal-,   subscript  y    n  1    normal-)   normal-)    subscript  f  k    fragments  normal-(   subscript  x  k   normal-)       missing-subexpression      fragments   subscript    normal-↑  N       subscript   normal-^  p     b  a  c  k  w  a  r  d     fragments  normal-(  d   fragments  normal-(   subscript  x  0   normal-,  normal-…  normal-,   subscript  x  n   normal-)   normal-|   fragments  normal-(   subscript  y  0   normal-,  normal-…  normal-,   subscript  y    n  1    normal-)   normal-)    subscript  f  k    fragments  normal-(   subscript  x  k   normal-)       missing-subexpression      fragments     normal-^  p    fragments  normal-(  d   subscript  x  n   normal-|   fragments  normal-(   subscript  y  0   normal-,  normal-…  normal-,   subscript  y    n  1    normal-)   normal-)    normal-^  p    fragments  normal-(  d   subscript  x    n  1    normal-|   subscript  x  n   normal-,   fragments  normal-(   subscript  y  0   normal-,  normal-…  normal-,   subscript  y    n  1    normal-)   normal-)     normal-^  p    fragments  normal-(  d   subscript  x    n  2    normal-|   subscript  x    n  1    normal-,   fragments  normal-(   subscript  y  0   normal-,  normal-…  normal-,   subscript  y    n  2    normal-)   normal-)   normal-…   normal-^  p    fragments  normal-(  d   subscript  x  k   normal-|   subscript  x    k  1    normal-,   fragments  normal-(   subscript  y  0   normal-,  normal-…  normal-,   subscript  y  k   normal-)   normal-)    subscript  f  k    fragments  normal-(   subscript  x  k   normal-)       missing-subexpression       absent     subscript   normal-⏟     1  N   normal-…    1  N     N times    subscript  𝕄    n  1     subscript  𝕄    n  2    normal-…   subscript  𝕄  k    delimited-[]       subscript  f  k    subscript   superscript  ξ  1   k      normal-⋮       subscript  f  k    subscript   superscript  ξ  N   k            \begin{array}[]{l}\displaystyle\int~{}p(d(x_{0},\ldots,x_{n})~{}|~{}(y_{0},%
 \ldots,y_{n-1}))~{}f_{k}(x_{k})\\
 \\
 ~{}\approx_{N\uparrow\infty}~{}\displaystyle\int\widehat{p}_{backward}(d(x_{0}%
 ,\ldots,x_{n})~{}|~{}(y_{0},\ldots,y_{n-1}))~{}f_{k}(x_{k})\\
 \\
 =\displaystyle\int~{}\widehat{p}(dx_{n}~{}|~{}(y_{0},\ldots,y_{n-1}))~{}%
 \widehat{p}(dx_{n-1}~{}|~{}x_{n},(y_{0},\ldots,y_{n-1}))~{}\times\widehat{p}(%
 dx_{n-2}~{}|~{}x_{n-1},(y_{0},\ldots,y_{n-2}))~{}~{}\ldots~{}~{}\widehat{p}(dx%
 _{k}~{}|~{}x_{k+1},(y_{0},\ldots,y_{k}))~{}f_{k}(x_{k})\\
 \\
 =\underbrace{\left[\frac{1}{N},\ldots,\frac{1}{N}\right]}_{\mbox{N times}}%
 \mathbb{M}_{n-1}\mathbb{M}_{n-2}\ldots\mathbb{M}_{k}\left[\begin{array}[]{c}f_%
 {k}(\xi^{1}_{k})\\
 \vdots\\
 f_{k}(\xi^{N}_{k})\end{array}\right]\end{array}   in terms of matrix operations with respect to the Markov transitions of the chain described above. 119 For instance, for any function    (   N  ×  N   )      N  N    (N\times N)   we have the particle estimates       𝕄  k   =    (    𝕄  k    (  i  ,  j  )    )     1  ≤  i   ,   j  ≤  N          subscript  𝕄  k    subscript     subscript  𝕄  k    i  j     formulae-sequence    1  i     j  N       \mathbb{M}_{k}=\left(\mathbb{M}_{k}(i,j)\right)_{1\leq i,j\leq N}   with the      𝕄  k    (  i  ,  j  )    =    p   (    ξ  k  i    |   ξ   k  -  1   j   )   p   (   y   k  -  1    |   ξ   k  -  1   j   )        ∑   1  ≤  l  ≤  N      p   (    ξ  k  i    |   ξ   k  -  1   l   )   p   (   y   k  -  1    |   ξ   k  -  1   l   )            subscript  𝕄  k    i  j       fragments  p   fragments  normal-(   subscript   superscript  ξ  i   k   normal-|   subscript   superscript  ξ  j     k  1    normal-)   p   fragments  normal-(   subscript  y    k  1    normal-|   subscript   superscript  ξ  j     k  1    normal-)     fragments   subscript       1  l       N     p   fragments  normal-(   subscript   superscript  ξ  i   k   normal-|   subscript   superscript  ξ  l     k  1    normal-)   p   fragments  normal-(   subscript  y    k  1    normal-|   subscript   superscript  ξ  l     k  1    normal-)       \mathbb{M}_{k}(i,j)=\frac{p(\xi^{i}_{k}~{}|~{}\xi^{j}_{k-1})~{}p(y_{k-1}|\xi^{%
 j}_{k-1})~{}}{\displaystyle\sum_{1\leq l\leq N}~{}p(\xi^{i}_{k}~{}|~{}\xi^{l}_%
 {k-1})~{}p(y_{k-1}|\xi^{l}_{k-1})}   -matrices      F  ¯    (   x  0   ,  …  ,   x  n   )    :=     1   n  +  1      ∑   0  ≤  k  ≤  n      f  k    (   x  k   )      ⟹        ∫     F  ¯    (   x  0   ,  …  ,   x  n   )   p   (  d   (   x  0   ,  …  ,   x  n   )   |   (   y  0   ,  …  ,   y   n  -  1    )   )              ≈   N  ↑  ∞      ∫    F  ¯    (   x  0   ,  …  ,   x  n   )     p  ^    b  a  c  k  w  a  r  d     (  d   (   x  0   ,  …  ,   x  n   )   |   (   y  0   ,  …  ,   y   n  -  1    )   )             =     1   n  +  1        ∑   0  ≤  k  ≤  n         [    1  N    ,  …  ,    1  N    ]   ⏟   N times    𝕄   n  -  1     𝕄   n  -  2    …   𝕄  k    [       f  k    (   ξ  k  1   )        ⋮        f  k    (   ξ  k  N   )       ]              assign     normal-¯  F     subscript  x  0   normal-…   subscript  x  n          1    n  1      subscript       0  k       n        subscript  f  k    subscript  x  k      normal-⟹     fragments    normal-¯  F    fragments  normal-(   subscript  x  0   normal-,  normal-…  normal-,   subscript  x  n   normal-)   p   fragments  normal-(  d   fragments  normal-(   subscript  x  0   normal-,  normal-…  normal-,   subscript  x  n   normal-)   normal-|   fragments  normal-(   subscript  y  0   normal-,  normal-…  normal-,   subscript  y    n  1    normal-)   normal-)       missing-subexpression      fragments   subscript    normal-↑  N       normal-¯  F    fragments  normal-(   subscript  x  0   normal-,  normal-…  normal-,   subscript  x  n   normal-)    subscript   normal-^  p     b  a  c  k  w  a  r  d     fragments  normal-(  d   fragments  normal-(   subscript  x  0   normal-,  normal-…  normal-,   subscript  x  n   normal-)   normal-|   fragments  normal-(   subscript  y  0   normal-,  normal-…  normal-,   subscript  y    n  1    normal-)   normal-)       missing-subexpression       absent      1    n  1      subscript       0  k       n        subscript   normal-⏟     1  N   normal-…    1  N     N times    subscript  𝕄    n  1     subscript  𝕄    n  2    normal-…   subscript  𝕄  k    delimited-[]       subscript  f  k    subscript   superscript  ξ  1   k      normal-⋮       subscript  f  k    subscript   superscript  ξ  N   k                \overline{F}(x_{0},\ldots,x_{n}):=\frac{1}{n+1}\sum_{0\leq k\leq n}f_{k}(x_{k}%
 )\quad\Longrightarrow\quad\begin{array}[t]{l}\displaystyle\int~{}\overline{F}(%
 x_{0},\ldots,x_{n})~{}p(d(x_{0},\ldots,x_{n})~{}|~{}(y_{0},\ldots,y_{n-1}))\\
 \\
 ~{}\approx_{N\uparrow\infty}~{}\displaystyle\int\overline{F}(x_{0},\ldots,x_{n%
 })~{}\widehat{p}_{backward}(d(x_{0},\ldots,x_{n})~{}|~{}(y_{0},\ldots,y_{n-1})%
 )\\
 \\
 \displaystyle=\frac{1}{n+1}\sum_{0\leq k\leq n}\underbrace{\left[\frac{1}{N},%
 \ldots,\frac{1}{N}\right]}_{\mbox{N times}}\mathbb{M}_{n-1}\mathbb{M}_{n-2}%
 \ldots\mathbb{M}_{k}\left[\begin{array}[]{c}f_{k}(\xi^{1}_{k})\\
 \vdots\\
 f_{k}(\xi^{N}_{k})\end{array}\right]\end{array}   with entries      E   (    p  ^    (   y  0   ,  …  ,   y  n   )    )    =    p   (   y  0   ,  …  ,   y  n   )    and      E   (    [      p  ^    (   y  0   ,  …  ,   y  n   )     p   (   y  0   ,  …  ,   y  n   )     -  1   ]   2   )    ≤     c   n   /  N       formulae-sequence      E     normal-^  p     subscript  y  0   normal-…   subscript  y  n         p    subscript  y  0   normal-…   subscript  y  n     and        E   superscript   delimited-[]         normal-^  p     subscript  y  0   normal-…   subscript  y  n       p    subscript  y  0   normal-…   subscript  y  n      1    2        c  n   N      E\left(\widehat{p}(y_{0},\ldots,y_{n})\right)=p(y_{0},\ldots,y_{n})\quad\mbox{%
 and}\quad E\left(\left[\frac{\widehat{p}(y_{0},\ldots,y_{n})}{p(y_{0},\ldots,y%
 _{n})}-1\right]^{2}\right)\leq{c}~{}n/{N}   This also show that      x  ≥  0      x  0    x\geq 0     Some convergence results  We shall assume that filtering equation is stable, in the sense that it corrects any erroneous initial condition.  In this situation, the particle approximations of the likelihood functions are unbiased and the relative variance is controlled by       |     1  n    log   p  ^     (   y  0   ,  …  ,   y  n   )    -    1  n    log   p  ^     (   y  0   ,  …  ,   y  n   )     |   ≤      c  1     x  N    +     c  2      x  N                  1  n      normal-^  p      subscript  y  0   normal-…   subscript  y  n         1  n      normal-^  p      subscript  y  0   normal-…   subscript  y  n            subscript  c  1     x  N       subscript  c  2       x  N        \left|\frac{1}{n}\log{\widehat{p}(y_{0},\ldots,y_{n})}-\frac{1}{n}\log{%
 \widehat{p}(y_{0},\ldots,y_{n})}\right|\leq c_{1}~{}\frac{x}{N}+c_{2}~{}\sqrt{%
 \frac{x}{N}}   for some finite constant c. In addition, for any    1  -   e   -  x        1   superscript  e    x      1-e^{-x}   , the probability that       c  1     and    c  2    <   ∞          subscript  c  1   and   subscript  c  2       c_{1}~{}\mbox{and}~{}c_{2}<\infty~{}   is larger than     I  k   p  a  t  h     (  F  )   :=  ∫  F   (   x  0   ,  …  ,   x  k   )   p   (  d   (   x  0   ,  …  ,   x  k   )   |   y  0   ,  …  ,   y   k  -  1    )     ≈   N  ↑  ∞       I  ^   k   p  a  t  h     (  F  )   :=  ∫  F   (   x  0   ,  …  ,   x  k   )    p  ^    (  d   (   x  0   ,  …  ,   x  k   )   |   y  0   ,  …  ,   y   k  -  1    )   =   1  N    ∑   1  ≤  i  ≤  N    F   (   ξ   0  ,  k   i   ,  …  ,   ξ   k  ,  k   i   )      fragments   subscript   superscript  I    p  a  t  h    k    fragments  normal-(  F  normal-)   assign   F   fragments  normal-(   subscript  x  0   normal-,  normal-…  normal-,   subscript  x  k   normal-)   p   fragments  normal-(  d   fragments  normal-(   subscript  x  0   normal-,  normal-…  normal-,   subscript  x  k   normal-)   normal-|   subscript  y  0   normal-,  normal-…  normal-,   subscript  y    k  1    normal-)    subscript    normal-↑  N      subscript   superscript   normal-^  I     p  a  t  h    k    fragments  normal-(  F  normal-)   assign   F   fragments  normal-(   subscript  x  0   normal-,  normal-…  normal-,   subscript  x  k   normal-)    normal-^  p    fragments  normal-(  d   fragments  normal-(   subscript  x  0   normal-,  normal-…  normal-,   subscript  x  k   normal-)   normal-|   subscript  y  0   normal-,  normal-…  normal-,   subscript  y    k  1    normal-)      1  N    subscript       1  i       N     F   fragments  normal-(   subscript   superscript  ξ  i    0  k    normal-,  normal-…  normal-,   subscript   superscript  ξ  i    k  k    normal-)     I^{path}_{k}(F):=\int F(x_{0},\ldots,x_{k})~{}p(d(x_{0},\ldots,x_{k})|y_{0},%
 \ldots,y_{k-1})~{}\approx_{N\uparrow\infty}~{}\widehat{I}^{path}_{k}(F):=\int F%
 (x_{0},\ldots,x_{k})~{}\widehat{p}(d(x_{0},\ldots,x_{k})|y_{0},\ldots,y_{k-1})%
 ~{}=\frac{1}{N}\sum_{1\leq i\leq N}F\left(\xi^{i}_{0,k},\ldots,\xi^{i}_{k,k}\right)   , for some finite constants      |    E   (     I  ^   k   p  a  t  h     (  F  )    )    -    I  k   p  a  t  h     (  F  )     |   ≤       c  1    k   /  N   and      E   (    [      I  ^   k   p  a  t  h     (  F  )    -    I  k   p  a  t  h     (  F  )     ]   2   )    ≤      c  2    k   /  N       formulae-sequence          E     subscript   superscript   normal-^  I     p  a  t  h    k   F       superscript   subscript  I  k     p  a  t  h    F           subscript  c  1   k   N   and        E   superscript   delimited-[]       subscript   superscript   normal-^  I     p  a  t  h    k   F      superscript   subscript  I  k     p  a  t  h    F     2         subscript  c  2   k   N      \left|E\left(\widehat{I}^{path}_{k}(F)\right)-I_{k}^{path}(F)\right|\leq{c_{1}%
 }~{}k/{N}\quad\mbox{and}\quad E\left(\left[\widehat{I}^{path}_{k}(F)-I_{k}^{%
 path}(F)\right]^{2}\right)\leq{c_{2}}~{}k/{N}   related to the asymptotic bias and variance of the particle estimate, and for some finite constant c.  The bias and the variance of the particle particle estimates based on the ancestral lines of the genealogical trees         c  1   ,   c  2    <   ∞    .        subscript  c  1    subscript  c  2       c_{1},c_{2}<\infty~{}.   are controlled by the non asymptotic uniform estimates    x  ≥  0      x  0    x\geq 0   for any function F(.) bounded by 1, and for some finite constants      |      I  ^   k   p  a  t  h     (  F  )    -    I  k   p  a  t  h     (  F  )     |   ≤       c  1       k   x   N    +     c  2        k   x   N      and       sup   0  ≤  k  ≤  n     |      I  ^   k   p  a  t  h     (  F  )    -    I  k   p  a  t  h     (  F  )     |    ≤    c       x    n    log   (  n  )     N         formulae-sequence           subscript   superscript   normal-^  I     p  a  t  h    k   F      superscript   subscript  I  k     p  a  t  h    F           subscript  c  1       k  x   N       subscript  c  2         k  x   N      and        subscript  supremum      0  k       n            superscript   subscript   normal-^  I   k     p  a  t  h    F      subscript   superscript  I    p  a  t  h    k   F        c        x  n    n    N        \left|\widehat{I}^{path}_{k}(F)-I_{k}^{path}(F)\right|\leq c_{1}~{}\frac{k~{}x%
 }{N}+c_{2}~{}\sqrt{\frac{k~{}x}{N}}\quad\mbox{and}\quad\sup_{0\leq k\leq n}%
 \left|\widehat{I}_{k}^{path}(F)-I^{path}_{k}(F)\right|\leq c~{}\sqrt{\frac{x~{%
 }n~{}\log(n)}{N}}   In addition, for any    1  -   e   -  x        1   superscript  e    x      1-e^{-x}   , the probability that       c  1     and    c  2    <   ∞          subscript  c  1   and   subscript  c  2       c_{1}~{}\mbox{and}~{}c_{2}<\infty~{}   is larger than     F  ¯    (   x  0   ,  …  ,   x  n   )   :=   1   n  +  1     ∑   0  ≤  k  ≤  n     f  k    (   x  k   )   with   I  n   p  a  t  h     (   F  ¯   )     ≈   N  ↑  ∞      I  n   ♭  ,   p  a  t  h      (   F  ¯   )   :=   ∫    F  ¯    (   x  0   ,  …  ,   x  n   )     p  ^    b  a  c  k  w  a  r  d     (  d   (   x  0   ,  …  ,   x  n   )   |   (   y  0   ,  …  ,   y   n  -  1    )   )      fragments   normal-¯  F    fragments  normal-(   subscript  x  0   normal-,  normal-…  normal-,   subscript  x  n   normal-)   assign    1    n  1     subscript       0  k       n      subscript  f  k    fragments  normal-(   subscript  x  k   normal-)    with    subscript   superscript  I    p  a  t  h    n    fragments  normal-(   normal-¯  F   normal-)    subscript    normal-↑  N      subscript   superscript  I   normal-♭    p  a  t  h     n    fragments  normal-(   normal-¯  F   normal-)   assign    normal-¯  F    fragments  normal-(   subscript  x  0   normal-,  normal-…  normal-,   subscript  x  n   normal-)    subscript   normal-^  p     b  a  c  k  w  a  r  d     fragments  normal-(  d   fragments  normal-(   subscript  x  0   normal-,  normal-…  normal-,   subscript  x  n   normal-)   normal-|   fragments  normal-(   subscript  y  0   normal-,  normal-…  normal-,   subscript  y    n  1    normal-)   normal-)     \overline{F}(x_{0},\ldots,x_{n}):=\frac{1}{n+1}\sum_{0\leq k\leq n}f_{k}(x_{k}%
 )\quad\mbox{with}\quad I^{path}_{n}(\overline{F})~{}\approx_{N\uparrow\infty}~%
 {}I^{\flat,path}_{n}(\overline{F}):=\displaystyle\int\overline{F}(x_{0},\ldots%
 ,x_{n})~{}\widehat{p}_{backward}(d(x_{0},\ldots,x_{n})~{}|~{}(y_{0},\ldots,y_{%
 n-1}))   , for some finite constants     f  k    (  .  )      fragments   subscript  f  k    fragments  normal-(  normal-.  normal-)     f_{k}(.)   related to the asymptotic bias and variance of the particle estimate, and for some finite constant c. The same type of bias and variance estimates hold for the backward particle smoothers. For additive functionals of the form         sup   n  ≥  0     |    E   (     I  ^   n   ♭  ,   p  a  t  h      (   F  ¯   )    )    -    I  n   p  a  t  h     (   F  ¯   )     |    ≤     c  1   /  N   and      E   (    [      I  ^   n   ♭  ,   p  a  t  h      (  F  )    -    I  n   p  a  t  h     (  F  )     ]   2   )    ≤     c  2   /   (   n  N   )    +    c  3   /   N  2         formulae-sequence      subscript  supremum    n  0          E     subscript   superscript   normal-^  I    normal-♭    p  a  t  h     n    normal-¯  F        superscript   subscript  I  n     p  a  t  h     normal-¯  F           subscript  c  1   N   and        E   superscript   delimited-[]       subscript   superscript   normal-^  I    normal-♭    p  a  t  h     n   F      superscript   subscript  I  n     p  a  t  h    F     2         subscript  c  2     n  N       subscript  c  3    superscript  N  2        \sup_{n\geq 0}{\left|E\left(\widehat{I}^{\flat,path}_{n}(\overline{F})\right)-%
 I_{n}^{path}(\overline{F})\right|}~{}\leq{c_{1}}/{N}\quad\mbox{and}\quad E%
 \left(\left[\widehat{I}^{\flat,path}_{n}(F)-I_{n}^{path}(F)\right]^{2}\right)%
 \leq{c_{2}}/{(nN)}+{c_{3}}/{N^{2}}   with functions      c  1   ,   c  2   ,   c  3    <  ∞        subscript  c  1    subscript  c  2    subscript  c  3       c_{1},c_{2},c_{3}<\infty   bounded by 1, we have      p   (   x  k   |   y  0   ,  …  ,   y  k   )      fragments  p   fragments  normal-(   subscript  x  k   normal-|   subscript  y  0   normal-,  normal-…  normal-,   subscript  y  k   normal-)     p(x_{k}|y_{0},\ldots,y_{k})   for some finite constants     {   (   w  k   (  i  )    ,   x  k   (  i  )    )   :   i  ∈   {  1  ,  …  ,  N  }    }   .     conditional-set    subscript   superscript  w  i   k    subscript   superscript  x  i   k      i   1  normal-…  N      \{(w^{(i)}_{k},x^{(i)}_{k})~{}:~{}i\in\{1,\ldots,N\}\}.   . More refined estimates including exponentially small probability of errors are developed in. 120  Sequential importance resampling (SIR)  The bootstrap filter  Sequential importance resampling (SIR) , the original bootstrap filtering algorithm (Gordon et al. 1993), is also very commonly used filtering algorithm, which approximates the filtering probability density    w  k   (  i  )      subscript   superscript  w  i   k    w^{(i)}_{k}   by a weighted set of N samples        ∑   i  =  1   N    w  k   (  i  )     =  1        superscript   subscript     i  1    N    subscript   superscript  w  i   k    1    \sum_{i=1}^{N}w^{(i)}_{k}=1     The importance weights     f   (  ⋅  )       f  normal-⋅    f(\cdot)   are approximations to the relative posterior probabilities (or densities) of the samples such that    ∫  f   (   x  k   )   p   (   x  k   |   y  0   ,  …  ,   y  k   )   d   x  k   ≈   ∑   i  =  1   N    w  k   (  i  )    f   (   x  k   (  i  )    )   .     fragments   f   fragments  normal-(   subscript  x  k   normal-)   p   fragments  normal-(   subscript  x  k   normal-|   subscript  y  0   normal-,  normal-…  normal-,   subscript  y  k   normal-)   d   subscript  x  k     superscript   subscript     i  1    N    superscript   subscript  w  k   i   f   fragments  normal-(   superscript   subscript  x  k   i   normal-)   normal-.    \int f(x_{k})p(x_{k}|y_{0},\dots,y_{k})dx_{k}\approx\sum_{i=1}^{N}w_{k}^{(i)}f%
 (x_{k}^{(i)}).   .  SIR is a sequential (i.e., recursive) version of importance sampling . As in importance sampling, the expectation of a function    π   (   x  k   |   x   0  :   k  -  1     ,   y   0  :  k    )      fragments  π   fragments  normal-(   subscript  x  k   normal-|   subscript  x   normal-:  0    k  1     normal-,   subscript  y   normal-:  0  k    normal-)     \pi(x_{k}|x_{0:k-1},y_{0:k})\,   can be approximated as a weighted average      π   (   x  k   |   x   0  :   k  -  1     ,   y   0  :  k    )   =  p   (   x  k   |   x   k  -  1    ,   y  k   )   =     p   (   y  k   |   x  k   )     ∫  p   (   y  k   |   x  k   )   p   (   x  k   |   x   k  -  1    )   d   x  k      p   (   x  k   |   x   k  -  1    )   .     fragments  π   fragments  normal-(   subscript  x  k   normal-|   subscript  x   normal-:  0    k  1     normal-,   subscript  y   normal-:  0  k    normal-)    p   fragments  normal-(   subscript  x  k   normal-|   subscript  x    k  1    normal-,   subscript  y  k   normal-)       fragments  p   fragments  normal-(   subscript  y  k   normal-|   subscript  x  k   normal-)     fragments   p   fragments  normal-(   subscript  y  k   normal-|   subscript  x  k   normal-)   p   fragments  normal-(   subscript  x  k   normal-|   subscript  x    k  1    normal-)   d   subscript  x  k     p   fragments  normal-(   subscript  x  k   normal-|   subscript  x    k  1    normal-)   normal-.    \pi(x_{k}|x_{0:k-1},y_{0:k})=p(x_{k}|x_{k-1},y_{k})=\frac{p(y_{k}|x_{k})}{\int%
 ~{}p(y_{k}|x_{k})p(x_{k}|x_{k-1})dx_{k}}~{}p(x_{k}|x_{k-1}).\,     For a finite set of samples, the algorithm performance is dependent on the choice of the proposal distribution      p   (   x  k   |   x   k  -  1    ,   y  k   )      fragments  p   fragments  normal-(   subscript  x  k   normal-|   subscript  x    k  1    normal-,   subscript  y  k   normal-)     p(x_{k}|x_{k-1},y_{k})   .  The " optimal" proposal distribution is given as the target distribution         p   (   y  k   |   x  k   )       ∫    p   (   y  k   |   x  k   )   p   (   x  k   |   x   k  -  1    )   d   x  k      p   (   x  k   |   x   k  -  1    )   d   x  k    ≃   N  ↑  ∞       p   (   y  k   |   x  k   )       ∫    p   (   y  k   |   x  k   )    p  ^    (  d   x  k   |   x   k  -  1    )       p  ^    (  d   x  k   |   x   k  -  1    )   =   ∑   1  ≤  i  ≤  N       p   (   y  k   |   X  k  i    (   x   k  -  1    )   )       ∑   1  ≤  j  ≤  N     p   (   y  k   |   X  k  j    (   x   k  -  1    )   )       δ    X  k  i    (   x   k  -  1    )      (  d   x  k   )      fragments     fragments  p   fragments  normal-(   subscript  y  k   normal-|   subscript  x  k   normal-)     fragments   p   fragments  normal-(   subscript  y  k   normal-|   subscript  x  k   normal-)   p   fragments  normal-(   subscript  x  k   normal-|   subscript  x    k  1    normal-)   d   subscript  x  k     p   fragments  normal-(   subscript  x  k   normal-|   subscript  x    k  1    normal-)   d   subscript  x  k    subscript  similar-to-or-equals   normal-↑  N        fragments  p   fragments  normal-(   subscript  y  k   normal-|   subscript  x  k   normal-)     fragments   p   fragments  normal-(   subscript  y  k   normal-|   subscript  x  k   normal-)    normal-^  p    fragments  normal-(  d   subscript  x  k   normal-|   subscript  x    k  1    normal-)      normal-^  p    fragments  normal-(  d   subscript  x  k   normal-|   subscript  x    k  1    normal-)     subscript       1  i       N        fragments  p   fragments  normal-(   subscript  y  k   normal-|   subscript   superscript  X  i   k    fragments  normal-(   subscript  x    k  1    normal-)   normal-)     fragments   subscript       1  j       N     p   fragments  normal-(   subscript  y  k   normal-|   subscript   superscript  X  j   k    fragments  normal-(   subscript  x    k  1    normal-)   normal-)      subscript  δ     subscript   superscript  X  i   k    subscript  x    k  1       fragments  normal-(  d   subscript  x  k   normal-)     \frac{p(y_{k}|x_{k})}{\int~{}p(y_{k}|x_{k})p(x_{k}|x_{k-1})dx_{k}}~{}p(x_{k}|x%
 _{k-1})dx_{k}\simeq_{N\uparrow\infty}\frac{p(y_{k}|x_{k})}{\int~{}p(y_{k}|x_{k%
 })\widehat{p}(dx_{k}|x_{k-1})}~{}\widehat{p}(dx_{k}|x_{k-1})=\sum_{1\leq i\leq
 N%
 }\frac{p(y_{k}|X^{i}_{k}(x_{k-1}))}{\sum_{1\leq j\leq N}p(y_{k}|X^{j}_{k}(x_{k%
 -1}))}~{}\delta_{X^{i}_{k}(x_{k-1})}(dx_{k})     This particular choice of proposal transition has been proposed by P. Del Moral in 121 in 1996 and 1998. When it is difficult to sample transitions according to the distribution     p  ^    (  d   x  k   |   x   k  -  1    )   =   1  N    ∑   i  =  1   N    δ    X  k  i    (   x   k  -  1    )      (  d   x  k   )     ≃   N  ↑  ∞     p   (   x  k   |   x   k  -  1    )   d   x  k      fragments   normal-^  p    fragments  normal-(  d   subscript  x  k   normal-|   subscript  x    k  1    normal-)      1  N    superscript   subscript     i  1    N    subscript  δ     subscript   superscript  X  i   k    subscript  x    k  1       fragments  normal-(  d   subscript  x  k   normal-)    subscript  similar-to-or-equals   normal-↑  N     p   fragments  normal-(   subscript  x  k   normal-|   subscript  x    k  1    normal-)   d   subscript  x  k     \widehat{p}(dx_{k}|x_{k-1})=\frac{1}{N}\sum_{i=1}^{N}\delta_{X^{i}_{k}(x_{k-1}%
 )}(dx_{k})~{}\simeq_{N\uparrow\infty}~{}p(x_{k}|x_{k-1})dx_{k}   one natural strategy is to use the following particle approximation     N   N   N     with the empirical approximation          X  k  i    (   x   k  -  1    )    ,  i   =  1   ,   …  ,  N      formulae-sequence        subscript   superscript  X  i   k    subscript  x    k  1     i   1    normal-…  N     X^{i}_{k}(x_{k-1}),~{}i=1,...,N     associated with    X  k     subscript  X  k    X_{k}   (or any other large number of samples) independent random samples     X   k  -  1    =   x   k  -  1         subscript  X    k  1     subscript  x    k  1      X_{k-1}=x_{k-1}   with the conditional distribution of the random state    δ  a     subscript  δ  a    \delta_{a}   given    π   (   x  k   |   x   0  :   k  -  1     ,   y   0  :  k    )   =  p   (   x  k   |   x   k  -  1    )   .     fragments  π   fragments  normal-(   subscript  x  k   normal-|   subscript  x   normal-:  0    k  1     normal-,   subscript  y   normal-:  0  k    normal-)    p   fragments  normal-(   subscript  x  k   normal-|   subscript  x    k  1    normal-)   normal-.    \pi(x_{k}|x_{0:k-1},y_{0:k})=p(x_{k}|x_{k-1}).\,   . The consistency of the resulting particle filter of this approximation and other extensions are developed in. 122 In the above display    i  =   1  ,  …  ,  N       i   1  normal-…  N     i=1,\ldots,N   stands for the Dirac measure at a given state a.  However, the transition prior probability distribution is often used as importance function, since it is easier to draw particles (or samples) and perform subsequent importance weight calculations:      i  =   1  ,  …  ,  N       i   1  normal-…  N     i=1,\ldots,N    Sequential Importance Resampling (SIR) filters with transition prior probability distribution as importance function are commonly known as bootstrap filter and condensation algorithm .  Resampling is used to avoid the problem of degeneracy of the algorithm, that is, avoiding the situation that all but one of the importance weights are close to zero. The performance of the algorithm can be also affected by proper choice of resampling method. The stratified sampling proposed by Kitagawa (1996) is optimal in terms of variance.  A single step of sequential importance resampling is as follows:   1) For       w  ^   k   (  i  )    =    w   k  -  1    (  i  )      p   (   y  k   |   x  k   (  i  )    )   p   (   x  k   (  i  )    |   x   k  -  1    (  i  )    )     π   (   x  k   (  i  )    |   x   0  :   k  -  1     (  i  )    ,   y   0  :  k    )       .       subscript   superscript   normal-^  w   i   k      subscript   superscript  w  i     k  1       fragments  p   fragments  normal-(   subscript  y  k   normal-|   subscript   superscript  x  i   k   normal-)   p   fragments  normal-(   subscript   superscript  x  i   k   normal-|   subscript   superscript  x  i     k  1    normal-)     fragments  π   fragments  normal-(   superscript   subscript  x  k   i   normal-|   subscript   superscript  x  i    normal-:  0    k  1     normal-,   subscript  y   normal-:  0  k    normal-)        \hat{w}^{(i)}_{k}=w^{(i)}_{k-1}\frac{p(y_{k}|x^{(i)}_{k})p(x^{(i)}_{k}|x^{(i)}%
 _{k-1})}{\pi(x_{k}^{(i)}|x^{(i)}_{0:k-1},y_{0:k})}.   draw samples from the proposal distribution           x^{(i)}_k \sim \pi(x_k|x^{(i)}_{0:k-1},y_{0:k})   2) For    π   (   x  k   (  i  )    |   x   0  :   k  -  1     (  i  )    ,   y   0  :  k    )   =  p   (   x  k   (  i  )    |   x   k  -  1    (  i  )    )      fragments  π   fragments  normal-(   superscript   subscript  x  k   i   normal-|   subscript   superscript  x  i    normal-:  0    k  1     normal-,   subscript  y   normal-:  0  k    normal-)    p   fragments  normal-(   subscript   superscript  x  i   k   normal-|   subscript   superscript  x  i     k  1    normal-)     \pi(x_{k}^{(i)}|x^{(i)}_{0:k-1},y_{0:k})=p(x^{(i)}_{k}|x^{(i)}_{k-1})   update the importance weights up to a normalizing constant:         w  ^   k   (  i  )    =   w   k  -  1    (  i  )    p   (   y  k   |   x  k   (  i  )    )   ,     fragments   subscript   superscript   normal-^  w   i   k     subscript   superscript  w  i     k  1    p   fragments  normal-(   subscript  y  k   normal-|   subscript   superscript  x  i   k   normal-)   normal-,    \hat{w}^{(i)}_{k}=w^{(i)}_{k-1}p(y_{k}|x^{(i)}_{k}),       Note that when we use the transition prior probability distribution as the importance function,    i  =   1  ,  …  ,  N       i   1  normal-…  N     i=1,\ldots,N   , this simplifies to the following :       N  ^   𝑒𝑓𝑓   <   N   t  h  r         subscript   normal-^  N   𝑒𝑓𝑓    subscript  N    t  h  r      \hat{N}_{\mathit{eff}}          3) For   N   N   N   compute the normalized importance weights:          w^{(i)}_k = \frac{\hat{w}^{(i)}_k}{\sum_{j=1}^N \hat{w}^{(j)}_k}   4) Compute an estimate of the effective number of particles as          \hat{N}_\mathit{eff} = \frac{1}{\sum_{i=1}^N\left(w^{(i)}_k\right)^2}  This criteria reflects the variance of the weights, other criteria can be found in the article, 123 including their rigorous analysis and central limit theorems.   5) If the effective number of particles is less than a given threshold    i  =   1  ,  …  ,  N       i   1  normal-…  N     i=1,\ldots,N   , then perform resampling:     a) Draw      w  k   (  N  )    =   1  /  N    .       subscript   superscript  w  N   k     1  N     w^{(N)}_{k}=1/N.   particles from the current particle set with probabilities proportional to their weights. Replace the current particle set with this new one.       b) For   x   x   x   set   k   k   k        The term Sampling Importance Resampling is also sometimes used when referring to SIR filters.  Sequential importance sampling (SIS)   Is the same as sequential importance resampling, but without the resampling stage.   "direct version" algorithm  The "direct version" algorithm  is rather simple (compared to other particle filtering algorithms) and it uses composition and rejection. To generate a single sample     p    x  k   |   y   1  :  k       (  x  |   y   1  :  k    )      fragments   subscript  p   fragments   subscript  x  k   normal-|   subscript  y   normal-:  1  k       fragments  normal-(  x  normal-|   subscript  y   normal-:  1  k    normal-)     p_{x_{k}|y_{1:k}}(x|y_{1:k})   at    {  1  ,  …  ,  N  }     1  normal-…  N    \{1,...,N\}   from    x  ^     normal-^  x    \hat{x}   :   1) Set n=0 (This will count the number of particles generated so far)    2) Uniformly choose an index i from the range    p   (   x  k   |   x   k  -  1    )   ,   with    x   k  -  1    =   x   k  -  1  |  k  -  1    (  i  )       fragments  p   fragments  normal-(   subscript  x  k   normal-|   subscript  x    k  1    normal-)   normal-,  with   subscript  x    k  1      superscript   subscript  x   fragments  k   1  normal-|  k   1    i     p(x_{k}|x_{k-1}),~{}\mbox{with}~{}x_{k-1}=x_{k-1|k-1}^{(i)}       3) Generate a test    y  ^     normal-^  y    \hat{y}   from the distribution    x  ^     normal-^  x    \hat{x}       4) Generate the probability of    p   (   y  k   |   x  k   )   ,   with    x  k   =   x  ^      fragments  p   fragments  normal-(   subscript  y  k   normal-|   subscript  x  k   normal-)   normal-,  with   subscript  x  k     normal-^  x     p(y_{k}|x_{k}),~{}\mbox{with}~{}x_{k}=\hat{x}   using    y  k     subscript  y  k    y_{k}   from    [  0  ,   m  k   ]     0   subscript  m  k     [0,m_{k}]   where     m  k   =   sup   x  k    p   (   y  k   |   x  k   )      fragments   subscript  m  k     subscript  supremum   subscript  x  k    p   fragments  normal-(   subscript  y  k   normal-|   subscript  x  k   normal-)     m_{k}=\sup_{x_{k}}p(y_{k}|x_{k})   is the measured value    5) Generate another uniform u from    p   (   y  ^   )       p   normal-^  y     p\left(\hat{y}\right)   where    x  ^     normal-^  x    \hat{x}       6) Compare u and    x   k  |  k    (  i  )      superscript   subscript  x   fragments  k  normal-|  k    i    x_{k|k}^{(i)}        6a) If u is larger then repeat from step 2       6b) If u is smaller then save   k   k   k   as    k  -  1      k  1    k-1   and increment n      7) If n == N then quit   The goal is to generate P "particles" at    x  k     subscript  x  k    x_{k}   using only the particles from    x   k  -  1      subscript  x    k  1     x_{k-1}   . This requires that a Markov equation can be written (and computed) to generate a    k  -  1      k  1    k-1   based only upon   k   k   k   . This algorithm uses composition of the P particles from   k   k   k   to generate a particle at   x   x   x   and repeats (steps 2–6) until P particles are generated at   k   k   k   .  This can be more easily visualized if    x   (  k  ,  i  )       x   k  i     x(k,i)   is viewed as a two-dimensional array. One dimension is   k   k   k   and the other dimensions is the particle number. For example,    x  k   (  i  )      superscript   subscript  x  k   i    x_{k}^{(i)}   would be the i th particle at    x  k     subscript  x  k    x_{k}   and can also be written    x   k  -  1    (  i  )      superscript   subscript  x    k  1    i    x_{k-1}^{(i)}   (as done above in the algorithm). Step 3 generates a potential     k  -  1      k  1    k-1   based on a randomly chosen particle (    x  k     subscript  x  k    x_{k}   ) at time    x   k  -  1      subscript  x    k  1     x_{k-1}   and rejects or accepts it in step 6. In other words, the $x_k$ values are generated using the previously generated $x_{k-1}$ .  Other particle filters   Auxiliary particle filter  124  Regularized auxiliary particle filter  125  Gaussian particle filter  Unscented particle filter  Gauss–Hermite particle filter  Cost Reference particle filter  Hierarchical/Scalable particle filter 126  Rao–Blackwellized particle filter 127  Rejection-sampling based optimal particle filter   128   Feynman-Kac and mean field particle methodologies 129 130 131   See also   Mean field particle methods  Genetic algorithms  Ensemble Kalman filter  Generalized filtering  Moving horizon estimation  Recursive Bayesian estimation  Monte Carlo localization   References  Bibliography   Del Moral, Pierre (1996). "Non Linear Filtering: Interacting Particle Solution." 1 . Markov Processes and Related Fields  2 (4): 555–580.  Del Moral, Pierre (2004). Feynman-Kac formulae. Genealogical and interacting particle approximations . Springer. p. 575. Series: Probability and Applications  Del Moral, Pierre (2013). Mean field simulation for Monte Carlo integration . Chapman & Hall/CRC Press. p. 626. Monographs on Statistics & Applied Probability                                                  External links   Feynman–Kac models and interacting particle algorithms (a.k.a. Particle Filtering) Theoretical aspects and a list of application domains of particle filters  Sequential Monte Carlo Methods (Particle Filtering) homepage on University of Cambridge  Dieter Fox's MCL Animations  Rob Hess' free software  SMCTC: A Template Class for Implementing SMC algorithms in C++  Java applet on particle filtering  vSMC : Vectorized Sequential Monte Carlo   "  Category:Estimation theory  Category:Monte Carlo methods  Category:Computational statistics    Category:Nonlinear filters  Category:Robot control  Category:Numerical analysis  Category:Statistical mechanics  Category:Sampling techniques  Category:Stochastic simulation     ↩  ↩  ↩  ↩   ↩  ↩   ↩  ↩  ↩  ↩  ↩   ↩  ↩  ↩  ↩  ↩  ↩  ↩  ↩  ↩  ↩  ↩  ↩       ↩   ↩  ↩  ↩   ↩   ↩  ↩   ↩  P. Del Moral, G. Rigal, and G. Salut. Estimation and nonlinear optimal control : An unified framework for particle solutions LAAS-CNRS, Toulouse, Research Report no. 91137, DRET-DIGILOG- LAAS/CNRS contract, April (1991). ↩  P. Del Moral, G. Rigal, and G. Salut. Nonlinear and non Gaussian particle filters applied to inertial platform repositioning. LAAS-CNRS, Toulouse, Research Report no. 92207, STCAN/DIGILOG-LAAS/CNRS Convention STCAN no. A.91.77.013, (94p.) September (1991). ↩  P. Del Moral, G. Rigal, and G. Salut. Estimation and nonlinear optimal control : Particle resolution in filtering and estimation. Experimental results. Convention DRET no. 89.34.553.00.470.75.01, Research report no.2 (54p.), January (1992). ↩  P. Del Moral, G. Rigal, and G. Salut. Estimation and nonlinear optimal control : Particle resolution in filtering and estimation. Theoretical results Convention DRET no. 89.34.553.00.470.75.01, Research report no.3 (123p.), October (1992). ↩  P. Del Moral, J.-Ch. Noyer, G. Rigal, and G. Salut. Particle filters in radar signal processing : detection, estimation and air targets recognition. LAAS-CNRS, Toulouse, Research report no. 92495, December (1992). ↩  P. Del Moral, G. Rigal, and G. Salut. Estimation and nonlinear optimal control : Particle resolution in filtering and estimation. Studies on: Filtering, optimal control, and maximum likelihood estimation. Convention DRET no. 89.34.553.00.470.75.01. Research report no.4 (210p.), January (1993). ↩     ↩  ↩  ↩  ↩     ↩   ↩  ↩  ↩    ↩  ↩   ↩   ↩   ↩  ↩  ↩  ↩  ↩  ↩  ↩  ↩                             ↩  ↩               ↩  ↩  ↩   ↩      