<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="1508">Maximum entropy probability distribution</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>Maximum entropy probability distribution</h1>
<hr/>

<p>In <a class="uri" href="statistics" title="wikilink">statistics</a> and <a href="information_theory" title="wikilink">information theory</a>, a <strong>maximum entropy probability distribution</strong> has <a href="information_entropy" title="wikilink">entropy</a> that is at least as great as that of all other members of a specified class of <a href="probability_distribution" title="wikilink">probability distributions</a>. According to the <a href="principle_of_maximum_entropy" title="wikilink">principle of maximum entropy</a>, if nothing is known about a distribution except that it belongs to a certain class (usually defined in terms of specified properties or measures), then the distribution with the largest entropy should be chosen as the least-informative default. The motivation is twofold: first, maximizing entropy minimizes the amount of prior information built into the distribution; second, many physical systems tend to move towards maximal entropy configurations over time.</p>
<h2 id="definition-of-entropy-and-differential-entropy">Definition of entropy and differential entropy</h2>

<p>If <em>X</em> is a <a href="discrete_random_variable" title="wikilink">discrete random variable</a> with distribution given by</p>

<p>

<math display="block" id="Maximum_entropy_probability_distribution:0">
 <semantics>
  <mrow>
   <mrow>
    <mrow>
     <mo>Pr</mo>
     <mrow>
      <mo stretchy="false">(</mo>
      <mrow>
       <mi>X</mi>
       <mo>=</mo>
       <msub>
        <mi>x</mi>
        <mi>k</mi>
       </msub>
      </mrow>
      <mo stretchy="false">)</mo>
     </mrow>
    </mrow>
    <mo>=</mo>
    <msub>
     <mi>p</mi>
     <mi>k</mi>
    </msub>
   </mrow>
   <mrow>
    <mrow>
     <mtext>for</mtext>
     <mi>k</mi>
    </mrow>
    <mo>=</mo>
    <mrow>
     <mn>1</mn>
     <mo>,</mo>
     <mn>2</mn>
     <mo>,</mo>
     <mi mathvariant="normal">…</mi>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">formulae-sequence</csymbol>
    <apply>
     <eq></eq>
     <apply>
      <ci>Pr</ci>
      <apply>
       <eq></eq>
       <ci>X</ci>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <ci>x</ci>
        <ci>k</ci>
       </apply>
      </apply>
     </apply>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>p</ci>
      <ci>k</ci>
     </apply>
    </apply>
    <apply>
     <eq></eq>
     <apply>
      <times></times>
      <mtext>for</mtext>
      <ci>k</ci>
     </apply>
     <list>
      <cn type="integer">1</cn>
      <cn type="integer">2</cn>
      <ci>normal-…</ci>
     </list>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \operatorname{Pr}(X=x_{k})=p_{k}\quad\mbox{ for }k=1,2,\ldots
  </annotation>
 </semantics>
</math>

 then the entropy of <em>X</em> is defined as</p>

<p>

<math display="block" id="Maximum_entropy_probability_distribution:1">
 <semantics>
  <mrow>
   <mrow>
    <mrow>
     <mi>H</mi>
     <mrow>
      <mo stretchy="false">(</mo>
      <mi>X</mi>
      <mo stretchy="false">)</mo>
     </mrow>
    </mrow>
    <mo>=</mo>
    <mrow>
     <mo>-</mo>
     <mrow>
      <munder>
       <mo largeop="true" movablelimits="false" symmetric="true">∑</mo>
       <mrow>
        <mi>k</mi>
        <mo>≥</mo>
        <mn>1</mn>
       </mrow>
      </munder>
      <mrow>
       <msub>
        <mi>p</mi>
        <mi>k</mi>
       </msub>
       <mrow>
        <mi>log</mi>
        <mpadded width="+2.8pt">
         <msub>
          <mi>p</mi>
          <mi>k</mi>
         </msub>
        </mpadded>
       </mrow>
      </mrow>
     </mrow>
    </mrow>
   </mrow>
   <mo>.</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <times></times>
     <ci>H</ci>
     <ci>X</ci>
    </apply>
    <apply>
     <minus></minus>
     <apply>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <sum></sum>
       <apply>
        <geq></geq>
        <ci>k</ci>
        <cn type="integer">1</cn>
       </apply>
      </apply>
      <apply>
       <times></times>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <ci>p</ci>
        <ci>k</ci>
       </apply>
       <apply>
        <log></log>
        <apply>
         <csymbol cd="ambiguous">subscript</csymbol>
         <ci>p</ci>
         <ci>k</ci>
        </apply>
       </apply>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   H(X)=-\sum_{k\geq 1}p_{k}\log p_{k}\;.
  </annotation>
 </semantics>
</math>

</p>

<p>If <em>X</em> is a <a href="continuous_random_variable" title="wikilink">continuous random variable</a> with <a href="probability_density_function" title="wikilink">probability density</a> <em>p</em>(<em>x</em>), then the <a href="differential_entropy" title="wikilink">differential entropy</a> of <em>X</em> is defined as<a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a><a class="footnoteRef" href="#fn2" id="fnref2"><sup>2</sup></a><a class="footnoteRef" href="#fn3" id="fnref3"><sup>3</sup></a></p>

<p>

<math display="block" id="Maximum_entropy_probability_distribution:2">
 <semantics>
  <mrow>
   <mrow>
    <mrow>
     <mi>H</mi>
     <mrow>
      <mo stretchy="false">(</mo>
      <mi>X</mi>
      <mo stretchy="false">)</mo>
     </mrow>
    </mrow>
    <mo>=</mo>
    <mrow>
     <mo>-</mo>
     <mrow>
      <msubsup>
       <mo largeop="true" symmetric="true">∫</mo>
       <mrow>
        <mo>-</mo>
        <mi mathvariant="normal">∞</mi>
       </mrow>
       <mi mathvariant="normal">∞</mi>
      </msubsup>
      <mrow>
       <mi>p</mi>
       <mrow>
        <mo stretchy="false">(</mo>
        <mi>x</mi>
        <mo stretchy="false">)</mo>
       </mrow>
       <mrow>
        <mi>log</mi>
        <mi>p</mi>
       </mrow>
       <mrow>
        <mo stretchy="false">(</mo>
        <mi>x</mi>
        <mo stretchy="false">)</mo>
       </mrow>
       <mi>d</mi>
       <mpadded width="+2.8pt">
        <mi>x</mi>
       </mpadded>
      </mrow>
     </mrow>
    </mrow>
   </mrow>
   <mo>.</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <times></times>
     <ci>H</ci>
     <ci>X</ci>
    </apply>
    <apply>
     <minus></minus>
     <apply>
      <apply>
       <csymbol cd="ambiguous">superscript</csymbol>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <int></int>
        <apply>
         <minus></minus>
         <infinity></infinity>
        </apply>
       </apply>
       <infinity></infinity>
      </apply>
      <apply>
       <times></times>
       <ci>p</ci>
       <ci>x</ci>
       <apply>
        <log></log>
        <ci>p</ci>
       </apply>
       <ci>x</ci>
       <ci>d</ci>
       <ci>x</ci>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   H(X)=-\int_{-\infty}^{\infty}p(x)\log p(x)dx\;.
  </annotation>
 </semantics>
</math>

</p>

<p><em>p</em>(<em>x</em>) log <em>p</em>(<em>x</em>) is understood to be zero whenever <em>p</em>(<em>x</em>) = 0.</p>

<p>This is a special case of more general forms described in the articles <a href="Entropy_(information_theory)" title="wikilink">Entropy (information theory)</a>, <a href="Principle_of_maximum_entropy" title="wikilink">Principle of maximum entropy</a>, and <a href="Differential_entropy" title="wikilink">Differential entropy</a>. In connection with maximum entropy distributions, this is the only one needed, because maximizing 

<math display="inline" id="Maximum_entropy_probability_distribution:3">
 <semantics>
  <mrow>
   <mi>H</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <mi>X</mi>
    <mo stretchy="false">)</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <ci>H</ci>
    <ci>X</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   H(X)
  </annotation>
 </semantics>
</math>

 will also maximize the more general forms.</p>

<p>The base of the <a class="uri" href="logarithm" title="wikilink">logarithm</a> is not important as long as the same one is used consistently: change of base merely results in a rescaling of the entropy. Information theorists may prefer to use base 2 in order to express the entropy in <a href="bit" title="wikilink">bits</a>; mathematicians and physicists will often prefer the <a href="natural_logarithm" title="wikilink">natural logarithm</a>, resulting in a unit of <a href="Nat_(unit)" title="wikilink">nats</a> for the entropy.</p>
<h2 id="distributions-with-measured-constants">Distributions with measured constants</h2>

<p>Many statistical distributions of applicable interest are those for which the <a href="moment_(mathematics)" title="wikilink">moments</a> or other measurable quantities are constrained to be constants. The following theorem by <a href="Ludwig_Boltzmann" title="wikilink">Ludwig Boltzmann</a> gives the form of the probability density under these constraints.</p>
<h3 id="continuous-version">Continuous version</h3>

<p>Suppose <em>S</em> is a <a href="closed_set" title="wikilink">closed subset</a> of the <a href="real_number" title="wikilink">real numbers</a> <strong>R</strong> and we choose to specify <em>n</em> <a href="measurable_function" title="wikilink">measurable functions</a> <em>f</em><sub>1</sub>,...,<em>f</em><sub><em>n</em></sub> and <em>n</em> numbers <em>a</em><sub>1</sub>,...,<em>a</em><sub><em>n</em></sub>. We consider the class <em>C</em> of all real-valued random variables which are supported on <em>S</em> (i.e. whose density function is zero outside of <em>S</em>) and which satisfy the <em>n</em> <a href="expected_value" title="wikilink">expected value</a> conditions</p>

<p>

<math display="block" id="Maximum_entropy_probability_distribution:4">
 <semantics>
  <mrow>
   <mrow>
    <mrow>
     <mo>E</mo>
     <mrow>
      <mo stretchy="false">(</mo>
      <mrow>
       <msub>
        <mi>f</mi>
        <mi>j</mi>
       </msub>
       <mrow>
        <mo stretchy="false">(</mo>
        <mi>X</mi>
        <mo stretchy="false">)</mo>
       </mrow>
      </mrow>
      <mo stretchy="false">)</mo>
     </mrow>
    </mrow>
    <mo>=</mo>
    <msub>
     <mi>a</mi>
     <mi>j</mi>
    </msub>
   </mrow>
   <mrow>
    <mrow>
     <mtext>for</mtext>
     <mi>j</mi>
    </mrow>
    <mo>=</mo>
    <mrow>
     <mn>1</mn>
     <mo>,</mo>
     <mi mathvariant="normal">…</mi>
     <mo>,</mo>
     <mi>n</mi>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">formulae-sequence</csymbol>
    <apply>
     <eq></eq>
     <apply>
      <ci>normal-E</ci>
      <apply>
       <times></times>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <ci>f</ci>
        <ci>j</ci>
       </apply>
       <ci>X</ci>
      </apply>
     </apply>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>a</ci>
      <ci>j</ci>
     </apply>
    </apply>
    <apply>
     <eq></eq>
     <apply>
      <times></times>
      <mtext>for</mtext>
      <ci>j</ci>
     </apply>
     <list>
      <cn type="integer">1</cn>
      <ci>normal-…</ci>
      <ci>n</ci>
     </list>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \operatorname{E}(f_{j}(X))=a_{j}\quad\mbox{ for }j=1,\ldots,n
  </annotation>
 </semantics>
</math>

 If there is a member in <em>C</em> whose density function is positive everywhere in <em>S</em>, and if there exists a maximal entropy distribution for <em>C</em>, then its probability density <em>p</em>(<em>x</em>) has the following shape:</p>

<p>

<math display="block" id="Maximum_entropy_probability_distribution:5">
 <semantics>
  <mrow>
   <mrow>
    <mrow>
     <mi>p</mi>
     <mrow>
      <mo stretchy="false">(</mo>
      <mi>x</mi>
      <mo stretchy="false">)</mo>
     </mrow>
    </mrow>
    <mo>=</mo>
    <mrow>
     <mi>c</mi>
     <mrow>
      <mi>exp</mi>
      <mrow>
       <mo>(</mo>
       <mrow>
        <munderover>
         <mo largeop="true" movablelimits="false" symmetric="true">∑</mo>
         <mrow>
          <mi>j</mi>
          <mo>=</mo>
          <mn>1</mn>
         </mrow>
         <mi>n</mi>
        </munderover>
        <mrow>
         <msub>
          <mi>λ</mi>
          <mi>j</mi>
         </msub>
         <msub>
          <mi>f</mi>
          <mi>j</mi>
         </msub>
         <mrow>
          <mo stretchy="false">(</mo>
          <mi>x</mi>
          <mo stretchy="false">)</mo>
         </mrow>
        </mrow>
       </mrow>
       <mo>)</mo>
      </mrow>
     </mrow>
    </mrow>
   </mrow>
   <mrow>
    <mrow>
     <mtext>for all</mtext>
     <mi>x</mi>
    </mrow>
    <mo>∈</mo>
    <mi>S</mi>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">formulae-sequence</csymbol>
    <apply>
     <eq></eq>
     <apply>
      <times></times>
      <ci>p</ci>
      <ci>x</ci>
     </apply>
     <apply>
      <times></times>
      <ci>c</ci>
      <apply>
       <exp></exp>
       <apply>
        <apply>
         <csymbol cd="ambiguous">superscript</csymbol>
         <apply>
          <csymbol cd="ambiguous">subscript</csymbol>
          <sum></sum>
          <apply>
           <eq></eq>
           <ci>j</ci>
           <cn type="integer">1</cn>
          </apply>
         </apply>
         <ci>n</ci>
        </apply>
        <apply>
         <times></times>
         <apply>
          <csymbol cd="ambiguous">subscript</csymbol>
          <ci>λ</ci>
          <ci>j</ci>
         </apply>
         <apply>
          <csymbol cd="ambiguous">subscript</csymbol>
          <ci>f</ci>
          <ci>j</ci>
         </apply>
         <ci>x</ci>
        </apply>
       </apply>
      </apply>
     </apply>
    </apply>
    <apply>
     <in></in>
     <apply>
      <times></times>
      <mtext>for all</mtext>
      <ci>x</ci>
     </apply>
     <ci>S</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   p(x)=c\exp\left(\sum_{j=1}^{n}\lambda_{j}f_{j}(x)\right)\quad\mbox{ for all }x\in
S
  </annotation>
 </semantics>
</math>

 where the constants <em>c</em> and λ<sub><em>j</em></sub> have to be determined so that the integral of <em>p</em>(<em>x</em>) over <em>S</em> is 1 and the above conditions for the expected values are satisfied. Conversely, if constants <em>c</em> and λ<sub><em>j</em></sub> like this can be found, then <em>p</em>(<em>x</em>) is indeed the density of the (unique) maximum entropy distribution for our class <em>C</em>.</p>
<h3 id="discrete-version">Discrete version</h3>

<p>Suppose <em>S</em> = {<em>x</em><sub>1</sub>,<em>x</em><sub>2</sub>,...} is a (finite or infinite) discrete subset of the reals and we choose to specify <em>n</em> functions <em>f</em><sub>1</sub>,...,<em>f</em><sub><em>n</em></sub> and <em>n</em> numbers <em>a</em><sub>1</sub>,...,<em>a</em><sub><em>n</em></sub>. We consider the class <em>C</em> of all discrete random variables <em>X</em> which are supported on <em>S</em> and which satisfy the <em>n</em> conditions</p>

<p>

<math display="block" id="Maximum_entropy_probability_distribution:6">
 <semantics>
  <mrow>
   <mrow>
    <mrow>
     <mo>E</mo>
     <mrow>
      <mo stretchy="false">(</mo>
      <mrow>
       <msub>
        <mi>f</mi>
        <mi>j</mi>
       </msub>
       <mrow>
        <mo stretchy="false">(</mo>
        <mi>X</mi>
        <mo stretchy="false">)</mo>
       </mrow>
      </mrow>
      <mo stretchy="false">)</mo>
     </mrow>
    </mrow>
    <mo>=</mo>
    <msub>
     <mi>a</mi>
     <mi>j</mi>
    </msub>
   </mrow>
   <mrow>
    <mrow>
     <mtext>for</mtext>
     <mi>j</mi>
    </mrow>
    <mo>=</mo>
    <mrow>
     <mn>1</mn>
     <mo>,</mo>
     <mi mathvariant="normal">…</mi>
     <mo>,</mo>
     <mi>n</mi>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">formulae-sequence</csymbol>
    <apply>
     <eq></eq>
     <apply>
      <ci>normal-E</ci>
      <apply>
       <times></times>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <ci>f</ci>
        <ci>j</ci>
       </apply>
       <ci>X</ci>
      </apply>
     </apply>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>a</ci>
      <ci>j</ci>
     </apply>
    </apply>
    <apply>
     <eq></eq>
     <apply>
      <times></times>
      <mtext>for</mtext>
      <ci>j</ci>
     </apply>
     <list>
      <cn type="integer">1</cn>
      <ci>normal-…</ci>
      <ci>n</ci>
     </list>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \operatorname{E}(f_{j}(X))=a_{j}\quad\mbox{ for }j=1,\ldots,n
  </annotation>
 </semantics>
</math>

</p>

<p>If there exists a member of <em>C</em> which assigns positive probability to all members of <em>S</em> and if there exists a maximum entropy distribution for <em>C</em>, then this distribution has the following shape:</p>

<p>

<math display="block" id="Maximum_entropy_probability_distribution:7">
 <semantics>
  <mrow>
   <mrow>
    <mrow>
     <mo>Pr</mo>
     <mrow>
      <mo stretchy="false">(</mo>
      <mrow>
       <mi>X</mi>
       <mo>=</mo>
       <msub>
        <mi>x</mi>
        <mi>k</mi>
       </msub>
      </mrow>
      <mo stretchy="false">)</mo>
     </mrow>
    </mrow>
    <mo>=</mo>
    <mrow>
     <mi>c</mi>
     <mrow>
      <mi>exp</mi>
      <mrow>
       <mo>(</mo>
       <mrow>
        <munderover>
         <mo largeop="true" movablelimits="false" symmetric="true">∑</mo>
         <mrow>
          <mi>j</mi>
          <mo>=</mo>
          <mn>1</mn>
         </mrow>
         <mi>n</mi>
        </munderover>
        <mrow>
         <msub>
          <mi>λ</mi>
          <mi>j</mi>
         </msub>
         <msub>
          <mi>f</mi>
          <mi>j</mi>
         </msub>
         <mrow>
          <mo stretchy="false">(</mo>
          <msub>
           <mi>x</mi>
           <mi>k</mi>
          </msub>
          <mo stretchy="false">)</mo>
         </mrow>
        </mrow>
       </mrow>
       <mo>)</mo>
      </mrow>
     </mrow>
    </mrow>
   </mrow>
   <mrow>
    <mrow>
     <mtext>for</mtext>
     <mi>k</mi>
    </mrow>
    <mo>=</mo>
    <mrow>
     <mn>1</mn>
     <mo>,</mo>
     <mn>2</mn>
     <mo>,</mo>
     <mi mathvariant="normal">…</mi>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">formulae-sequence</csymbol>
    <apply>
     <eq></eq>
     <apply>
      <ci>Pr</ci>
      <apply>
       <eq></eq>
       <ci>X</ci>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <ci>x</ci>
        <ci>k</ci>
       </apply>
      </apply>
     </apply>
     <apply>
      <times></times>
      <ci>c</ci>
      <apply>
       <exp></exp>
       <apply>
        <apply>
         <csymbol cd="ambiguous">superscript</csymbol>
         <apply>
          <csymbol cd="ambiguous">subscript</csymbol>
          <sum></sum>
          <apply>
           <eq></eq>
           <ci>j</ci>
           <cn type="integer">1</cn>
          </apply>
         </apply>
         <ci>n</ci>
        </apply>
        <apply>
         <times></times>
         <apply>
          <csymbol cd="ambiguous">subscript</csymbol>
          <ci>λ</ci>
          <ci>j</ci>
         </apply>
         <apply>
          <csymbol cd="ambiguous">subscript</csymbol>
          <ci>f</ci>
          <ci>j</ci>
         </apply>
         <apply>
          <csymbol cd="ambiguous">subscript</csymbol>
          <ci>x</ci>
          <ci>k</ci>
         </apply>
        </apply>
       </apply>
      </apply>
     </apply>
    </apply>
    <apply>
     <eq></eq>
     <apply>
      <times></times>
      <mtext>for</mtext>
      <ci>k</ci>
     </apply>
     <list>
      <cn type="integer">1</cn>
      <cn type="integer">2</cn>
      <ci>normal-…</ci>
     </list>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \operatorname{Pr}(X=x_{k})=c\exp\left(\sum_{j=1}^{n}\lambda_{j}f_{j}(x_{k})%
\right)\quad\mbox{ for }k=1,2,\ldots
  </annotation>
 </semantics>
</math>

 where the constants <em>c</em> and λ<sub><em>j</em></sub> have to be determined so that the sum of the probabilities is 1 and the above conditions for the expected values are satisfied. Conversely, if constants <em>c</em> and λ<sub><em>j</em></sub> like this can be found, then the above distribution is indeed the maximum entropy distribution for our class <em>C</em>.</p>
<h3 id="proof">Proof</h3>

<p>This theorem is proved with the <a href="calculus_of_variations" title="wikilink">calculus of variations</a> and <a href="Lagrange_multipliers" title="wikilink">Lagrange multipliers</a>. The constraints can be written as</p>

<p>

<math display="inline" id="Maximum_entropy_probability_distribution:8">
 <semantics>
  <mrow>
   <mrow>
    <msubsup>
     <mo largeop="true" symmetric="true">∫</mo>
     <mrow>
      <mo>-</mo>
      <mi mathvariant="normal">∞</mi>
     </mrow>
     <mi mathvariant="normal">∞</mi>
    </msubsup>
    <mrow>
     <msub>
      <mi>f</mi>
      <mi>j</mi>
     </msub>
     <mrow>
      <mo stretchy="false">(</mo>
      <mi>x</mi>
      <mo stretchy="false">)</mo>
     </mrow>
     <mi>p</mi>
     <mrow>
      <mo stretchy="false">(</mo>
      <mi>x</mi>
      <mo stretchy="false">)</mo>
     </mrow>
     <mi>d</mi>
     <mi>x</mi>
    </mrow>
   </mrow>
   <mo>=</mo>
   <msub>
    <mi>a</mi>
    <mi>j</mi>
   </msub>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <int></int>
       <apply>
        <minus></minus>
        <infinity></infinity>
       </apply>
      </apply>
      <infinity></infinity>
     </apply>
     <apply>
      <times></times>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>f</ci>
       <ci>j</ci>
      </apply>
      <ci>x</ci>
      <ci>p</ci>
      <ci>x</ci>
      <ci>d</ci>
      <ci>x</ci>
     </apply>
    </apply>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>a</ci>
     <ci>j</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \int_{-\infty}^{\infty}f_{j}(x)p(x)dx=a_{j}
  </annotation>
 </semantics>
</math>

</p>

<p>We consider the <a href="functional_(mathematics)" title="wikilink">functional</a></p>

<p>

<math display="inline" id="Maximum_entropy_probability_distribution:9">
 <semantics>
  <mrow>
   <mrow>
    <mi>J</mi>
    <mrow>
     <mo stretchy="false">(</mo>
     <mrow>
      <mi>p</mi>
      <mrow>
       <mo stretchy="false">(</mo>
       <mi>x</mi>
       <mo stretchy="false">)</mo>
      </mrow>
     </mrow>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
   <mo>=</mo>
   <mrow>
    <mrow>
     <mo>-</mo>
     <mrow>
      <msubsup>
       <mo largeop="true" symmetric="true">∫</mo>
       <mrow>
        <mo>-</mo>
        <mi mathvariant="normal">∞</mi>
       </mrow>
       <mi mathvariant="normal">∞</mi>
      </msubsup>
      <mrow>
       <mi>p</mi>
       <mrow>
        <mo stretchy="false">(</mo>
        <mi>x</mi>
        <mo stretchy="false">)</mo>
       </mrow>
       <mrow>
        <mi>ln</mi>
        <mi>p</mi>
       </mrow>
       <mrow>
        <mo stretchy="false">(</mo>
        <mi>x</mi>
        <mo stretchy="false">)</mo>
       </mrow>
       <mi>d</mi>
       <mi>x</mi>
      </mrow>
     </mrow>
    </mrow>
    <mo>+</mo>
    <mrow>
     <msub>
      <mi>λ</mi>
      <mn>0</mn>
     </msub>
     <mrow>
      <mo>(</mo>
      <mrow>
       <mrow>
        <msubsup>
         <mo largeop="true" symmetric="true">∫</mo>
         <mrow>
          <mo>-</mo>
          <mi mathvariant="normal">∞</mi>
         </mrow>
         <mi mathvariant="normal">∞</mi>
        </msubsup>
        <mrow>
         <mi>p</mi>
         <mrow>
          <mo stretchy="false">(</mo>
          <mi>x</mi>
          <mo stretchy="false">)</mo>
         </mrow>
         <mi>d</mi>
         <mi>x</mi>
        </mrow>
       </mrow>
       <mo>-</mo>
       <mn>1</mn>
      </mrow>
      <mo>)</mo>
     </mrow>
    </mrow>
    <mo>+</mo>
    <mrow>
     <msubsup>
      <mo largeop="true" symmetric="true">∑</mo>
      <mrow>
       <mi>j</mi>
       <mo>=</mo>
       <mn>1</mn>
      </mrow>
      <mi>n</mi>
     </msubsup>
     <mrow>
      <msub>
       <mi>λ</mi>
       <mi>j</mi>
      </msub>
      <mrow>
       <mo>(</mo>
       <mrow>
        <mrow>
         <msubsup>
          <mo largeop="true" symmetric="true">∫</mo>
          <mrow>
           <mo>-</mo>
           <mi mathvariant="normal">∞</mi>
          </mrow>
          <mi mathvariant="normal">∞</mi>
         </msubsup>
         <mrow>
          <msub>
           <mi>f</mi>
           <mi>j</mi>
          </msub>
          <mrow>
           <mo stretchy="false">(</mo>
           <mi>x</mi>
           <mo stretchy="false">)</mo>
          </mrow>
          <mi>p</mi>
          <mrow>
           <mo stretchy="false">(</mo>
           <mi>x</mi>
           <mo stretchy="false">)</mo>
          </mrow>
          <mi>d</mi>
          <mi>x</mi>
         </mrow>
        </mrow>
        <mo>-</mo>
        <msub>
         <mi>a</mi>
         <mi>j</mi>
        </msub>
       </mrow>
       <mo>)</mo>
      </mrow>
     </mrow>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <times></times>
     <ci>J</ci>
     <apply>
      <times></times>
      <ci>p</ci>
      <ci>x</ci>
     </apply>
    </apply>
    <apply>
     <plus></plus>
     <apply>
      <minus></minus>
      <apply>
       <apply>
        <csymbol cd="ambiguous">superscript</csymbol>
        <apply>
         <csymbol cd="ambiguous">subscript</csymbol>
         <int></int>
         <apply>
          <minus></minus>
          <infinity></infinity>
         </apply>
        </apply>
        <infinity></infinity>
       </apply>
       <apply>
        <times></times>
        <ci>p</ci>
        <ci>x</ci>
        <apply>
         <ln></ln>
         <ci>p</ci>
        </apply>
        <ci>x</ci>
        <ci>d</ci>
        <ci>x</ci>
       </apply>
      </apply>
     </apply>
     <apply>
      <times></times>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>λ</ci>
       <cn type="integer">0</cn>
      </apply>
      <apply>
       <minus></minus>
       <apply>
        <apply>
         <csymbol cd="ambiguous">superscript</csymbol>
         <apply>
          <csymbol cd="ambiguous">subscript</csymbol>
          <int></int>
          <apply>
           <minus></minus>
           <infinity></infinity>
          </apply>
         </apply>
         <infinity></infinity>
        </apply>
        <apply>
         <times></times>
         <ci>p</ci>
         <ci>x</ci>
         <ci>d</ci>
         <ci>x</ci>
        </apply>
       </apply>
       <cn type="integer">1</cn>
      </apply>
     </apply>
     <apply>
      <apply>
       <csymbol cd="ambiguous">superscript</csymbol>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <sum></sum>
        <apply>
         <eq></eq>
         <ci>j</ci>
         <cn type="integer">1</cn>
        </apply>
       </apply>
       <ci>n</ci>
      </apply>
      <apply>
       <times></times>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <ci>λ</ci>
        <ci>j</ci>
       </apply>
       <apply>
        <minus></minus>
        <apply>
         <apply>
          <csymbol cd="ambiguous">superscript</csymbol>
          <apply>
           <csymbol cd="ambiguous">subscript</csymbol>
           <int></int>
           <apply>
            <minus></minus>
            <infinity></infinity>
           </apply>
          </apply>
          <infinity></infinity>
         </apply>
         <apply>
          <times></times>
          <apply>
           <csymbol cd="ambiguous">subscript</csymbol>
           <ci>f</ci>
           <ci>j</ci>
          </apply>
          <ci>x</ci>
          <ci>p</ci>
          <ci>x</ci>
          <ci>d</ci>
          <ci>x</ci>
         </apply>
        </apply>
        <apply>
         <csymbol cd="ambiguous">subscript</csymbol>
         <ci>a</ci>
         <ci>j</ci>
        </apply>
       </apply>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   J(p(x))=-\int_{-\infty}^{\infty}p(x)\ln{p(x)}dx+\lambda_{0}\left(\int_{-\infty%
}^{\infty}p(x)dx-1\right)+\sum_{j=1}^{n}\lambda_{j}\left(\int_{-\infty}^{%
\infty}f_{j}(x)p(x)dx-a_{j}\right)
  </annotation>
 </semantics>
</math>

</p>

<p>where the 

<math display="inline" id="Maximum_entropy_probability_distribution:10">
 <semantics>
  <msub>
   <mi>λ</mi>
   <mi>j</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>λ</ci>
    <ci>j</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \lambda_{j}
  </annotation>
 </semantics>
</math>

 are the Lagrange multipliers. The zeroth constraint ensures the <a href="Probability_axioms#Second_axiom" title="wikilink">second axiom of probability</a>. The other constraints are that the measurements of the function are given constants up to order 

<math display="inline" id="Maximum_entropy_probability_distribution:11">
 <semantics>
  <mi>n</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>n</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   n
  </annotation>
 </semantics>
</math>

. The entropy attains an extremum when the <a href="functional_derivative" title="wikilink">functional derivative</a> is equal to zero:</p>

<p>

<math display="inline" id="Maximum_entropy_probability_distribution:12">
 <semantics>
  <mrow>
   <mfrac>
    <mrow>
     <mi>δ</mi>
     <mi>J</mi>
     <mrow>
      <mo stretchy="false">(</mo>
      <mrow>
       <mi>p</mi>
       <mrow>
        <mo stretchy="false">(</mo>
        <mi>x</mi>
        <mo stretchy="false">)</mo>
       </mrow>
      </mrow>
      <mo stretchy="false">)</mo>
     </mrow>
    </mrow>
    <mrow>
     <mi>δ</mi>
     <mi>p</mi>
     <mrow>
      <mo stretchy="false">(</mo>
      <mi>x</mi>
      <mo stretchy="false">)</mo>
     </mrow>
    </mrow>
   </mfrac>
   <mo>=</mo>
   <mrow>
    <mrow>
     <mrow>
      <mo>-</mo>
      <mrow>
       <mrow>
        <mi>ln</mi>
        <mi>p</mi>
       </mrow>
       <mrow>
        <mo stretchy="false">(</mo>
        <mi>x</mi>
        <mo stretchy="false">)</mo>
       </mrow>
      </mrow>
     </mrow>
     <mo>-</mo>
     <mn>1</mn>
    </mrow>
    <mo>+</mo>
    <msub>
     <mi>λ</mi>
     <mn>0</mn>
    </msub>
    <mo>+</mo>
    <mrow>
     <msubsup>
      <mo largeop="true" symmetric="true">∑</mo>
      <mrow>
       <mi>j</mi>
       <mo>=</mo>
       <mn>1</mn>
      </mrow>
      <mi>n</mi>
     </msubsup>
     <mrow>
      <msub>
       <mi>λ</mi>
       <mi>j</mi>
      </msub>
      <msub>
       <mi>f</mi>
       <mi>j</mi>
      </msub>
      <mrow>
       <mo stretchy="false">(</mo>
       <mi>x</mi>
       <mo stretchy="false">)</mo>
      </mrow>
     </mrow>
    </mrow>
   </mrow>
   <mo>=</mo>
   <mn>0</mn>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <and></and>
    <apply>
     <eq></eq>
     <apply>
      <divide></divide>
      <apply>
       <times></times>
       <ci>δ</ci>
       <ci>J</ci>
       <apply>
        <times></times>
        <ci>p</ci>
        <ci>x</ci>
       </apply>
      </apply>
      <apply>
       <times></times>
       <ci>δ</ci>
       <ci>p</ci>
       <ci>x</ci>
      </apply>
     </apply>
     <apply>
      <plus></plus>
      <apply>
       <minus></minus>
       <apply>
        <minus></minus>
        <apply>
         <times></times>
         <apply>
          <ln></ln>
          <ci>p</ci>
         </apply>
         <ci>x</ci>
        </apply>
       </apply>
       <cn type="integer">1</cn>
      </apply>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>λ</ci>
       <cn type="integer">0</cn>
      </apply>
      <apply>
       <apply>
        <csymbol cd="ambiguous">superscript</csymbol>
        <apply>
         <csymbol cd="ambiguous">subscript</csymbol>
         <sum></sum>
         <apply>
          <eq></eq>
          <ci>j</ci>
          <cn type="integer">1</cn>
         </apply>
        </apply>
        <ci>n</ci>
       </apply>
       <apply>
        <times></times>
        <apply>
         <csymbol cd="ambiguous">subscript</csymbol>
         <ci>λ</ci>
         <ci>j</ci>
        </apply>
        <apply>
         <csymbol cd="ambiguous">subscript</csymbol>
         <ci>f</ci>
         <ci>j</ci>
        </apply>
        <ci>x</ci>
       </apply>
      </apply>
     </apply>
    </apply>
    <apply>
     <eq></eq>
     <share href="#.cmml">
     </share>
     <cn type="integer">0</cn>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \frac{\delta{J(p(x))}}{\delta{p(x)}}=-\ln{p(x)}-1+\lambda_{0}+\sum_{j=1}^{n}%
\lambda_{j}f_{j}(x)=0
  </annotation>
 </semantics>
</math>

</p>

<p>It is an exercise for the reader that this extremum is a maximum. Therefore the maximum entropy probability distribution in this case must be of the form</p>

<p>

<math display="inline" id="Maximum_entropy_probability_distribution:13">
 <semantics>
  <mrow>
   <mrow>
    <mrow>
     <mi>p</mi>
     <mrow>
      <mo stretchy="false">(</mo>
      <mi>x</mi>
      <mo stretchy="false">)</mo>
     </mrow>
    </mrow>
    <mo>=</mo>
    <mrow>
     <msup>
      <mi>e</mi>
      <mrow>
       <mrow>
        <mo>-</mo>
        <mn>1</mn>
       </mrow>
       <mo>+</mo>
       <msub>
        <mi>λ</mi>
        <mn>0</mn>
       </msub>
      </mrow>
     </msup>
     <mo>⋅</mo>
     <msup>
      <mi>e</mi>
      <mrow>
       <mstyle displaystyle="false">
        <msubsup>
         <mo largeop="true" symmetric="true">∑</mo>
         <mrow>
          <mi>j</mi>
          <mo>=</mo>
          <mn>1</mn>
         </mrow>
         <mi>n</mi>
        </msubsup>
       </mstyle>
       <mrow>
        <msub>
         <mi>λ</mi>
         <mi>j</mi>
        </msub>
        <msub>
         <mi>f</mi>
         <mi>j</mi>
        </msub>
        <mrow>
         <mo stretchy="false">(</mo>
         <mi>x</mi>
         <mo stretchy="false">)</mo>
        </mrow>
       </mrow>
      </mrow>
     </msup>
    </mrow>
    <mo>=</mo>
    <mrow>
     <mi>c</mi>
     <mo>⋅</mo>
     <mrow>
      <mi>exp</mi>
      <mrow>
       <mo>(</mo>
       <mrow>
        <msubsup>
         <mo largeop="true" symmetric="true">∑</mo>
         <mrow>
          <mi>j</mi>
          <mo>=</mo>
          <mn>1</mn>
         </mrow>
         <mi>n</mi>
        </msubsup>
        <mrow>
         <msub>
          <mi>λ</mi>
          <mi>j</mi>
         </msub>
         <msub>
          <mi>f</mi>
          <mi>j</mi>
         </msub>
         <mrow>
          <mo stretchy="false">(</mo>
          <mi>x</mi>
          <mo stretchy="false">)</mo>
         </mrow>
        </mrow>
       </mrow>
       <mo rspace="5.3pt">)</mo>
      </mrow>
     </mrow>
    </mrow>
   </mrow>
   <mo>.</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <and></and>
    <apply>
     <eq></eq>
     <apply>
      <times></times>
      <ci>p</ci>
      <ci>x</ci>
     </apply>
     <apply>
      <ci>normal-⋅</ci>
      <apply>
       <csymbol cd="ambiguous">superscript</csymbol>
       <ci>e</ci>
       <apply>
        <plus></plus>
        <apply>
         <minus></minus>
         <cn type="integer">1</cn>
        </apply>
        <apply>
         <csymbol cd="ambiguous">subscript</csymbol>
         <ci>λ</ci>
         <cn type="integer">0</cn>
        </apply>
       </apply>
      </apply>
      <apply>
       <csymbol cd="ambiguous">superscript</csymbol>
       <ci>e</ci>
       <apply>
        <apply>
         <csymbol cd="ambiguous">superscript</csymbol>
         <apply>
          <csymbol cd="ambiguous">subscript</csymbol>
          <sum></sum>
          <apply>
           <eq></eq>
           <ci>j</ci>
           <cn type="integer">1</cn>
          </apply>
         </apply>
         <ci>n</ci>
        </apply>
        <apply>
         <times></times>
         <apply>
          <csymbol cd="ambiguous">subscript</csymbol>
          <ci>λ</ci>
          <ci>j</ci>
         </apply>
         <apply>
          <csymbol cd="ambiguous">subscript</csymbol>
          <ci>f</ci>
          <ci>j</ci>
         </apply>
         <ci>x</ci>
        </apply>
       </apply>
      </apply>
     </apply>
    </apply>
    <apply>
     <eq></eq>
     <share href="#.cmml">
     </share>
     <apply>
      <ci>normal-⋅</ci>
      <ci>c</ci>
      <apply>
       <exp></exp>
       <apply>
        <apply>
         <csymbol cd="ambiguous">superscript</csymbol>
         <apply>
          <csymbol cd="ambiguous">subscript</csymbol>
          <sum></sum>
          <apply>
           <eq></eq>
           <ci>j</ci>
           <cn type="integer">1</cn>
          </apply>
         </apply>
         <ci>n</ci>
        </apply>
        <apply>
         <times></times>
         <apply>
          <csymbol cd="ambiguous">subscript</csymbol>
          <ci>λ</ci>
          <ci>j</ci>
         </apply>
         <apply>
          <csymbol cd="ambiguous">subscript</csymbol>
          <ci>f</ci>
          <ci>j</ci>
         </apply>
         <ci>x</ci>
        </apply>
       </apply>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   p(x)=e^{-1+\lambda_{0}}\cdot e^{\sum_{j=1}^{n}\lambda_{j}f_{j}(x)}=c\cdot\exp%
\left(\sum_{j=1}^{n}\lambda_{j}f_{j}(x)\right)\;.
  </annotation>
 </semantics>
</math>

</p>

<p>The proof of the discrete version is essentially the same.</p>
<h3 id="caveats">Caveats</h3>

<p>Note that not all classes of distributions contain a maximum entropy distribution. It is possible that a class contain distributions of arbitrarily large entropy (e.g. the class of all continuous distributions on <strong>R</strong> with mean 0 but arbitrary standard deviation), or that the entropies are bounded above but there is no distribution which attains the maximal entropy (e.g. the class of all continuous distributions <em>X</em> on <strong>R</strong> with E(<em>X</em>) = 0 and E(<em>X</em><sup>2</sup>) = E(<em>X</em><sup>3</sup>) = 1 (See Cover, Ch 11)). It is also possible that the expected value restrictions for the class <em>C</em> force the probability distribution to be zero in certain subsets of <em>S</em>. In that case our theorem doesn't apply, but one can work around this by shrinking the set <em>S</em>.</p>
<h2 id="examples-of-maximum-entropy-distributions">Examples of maximum entropy distributions</h2>

<p>Every probability distribution is trivially a maximum entropy probability distribution under the constraint that the distribution have its own entropy. To see this, rewrite the density as 

<math display="inline" id="Maximum_entropy_probability_distribution:14">
 <semantics>
  <mrow>
   <mrow>
    <mi>p</mi>
    <mrow>
     <mo stretchy="false">(</mo>
     <mi>x</mi>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
   <mo>=</mo>
   <mrow>
    <mi>exp</mi>
    <mrow>
     <mo stretchy="false">(</mo>
     <mrow>
      <mrow>
       <mi>ln</mi>
       <mi>p</mi>
      </mrow>
      <mrow>
       <mo stretchy="false">(</mo>
       <mi>x</mi>
       <mo stretchy="false">)</mo>
      </mrow>
     </mrow>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <times></times>
     <ci>p</ci>
     <ci>x</ci>
    </apply>
    <apply>
     <exp></exp>
     <apply>
      <times></times>
      <apply>
       <ln></ln>
       <ci>p</ci>
      </apply>
      <ci>x</ci>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   p(x)=\exp{(\ln{p(x)})}
  </annotation>
 </semantics>
</math>

 and compare to the expression of the theorem above. By choosing 

<math display="inline" id="Maximum_entropy_probability_distribution:15">
 <semantics>
  <mrow>
   <mrow>
    <mrow>
     <mi>ln</mi>
     <mi>p</mi>
    </mrow>
    <mrow>
     <mo stretchy="false">(</mo>
     <mi>x</mi>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
   <mo>→</mo>
   <mrow>
    <mi>f</mi>
    <mrow>
     <mo stretchy="false">(</mo>
     <mi>x</mi>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <ci>normal-→</ci>
    <apply>
     <times></times>
     <apply>
      <ln></ln>
      <ci>p</ci>
     </apply>
     <ci>x</ci>
    </apply>
    <apply>
     <times></times>
     <ci>f</ci>
     <ci>x</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \ln{p(x)}\rightarrow f(x)
  </annotation>
 </semantics>
</math>

 to be the measurable function and 

<math display="inline" id="Maximum_entropy_probability_distribution:16">
 <semantics>
  <mrow>
   <mrow>
    <mo largeop="true" symmetric="true">∫</mo>
    <mrow>
     <mrow>
      <mi>exp</mi>
      <mrow>
       <mo stretchy="false">(</mo>
       <mrow>
        <mi>f</mi>
        <mrow>
         <mo stretchy="false">(</mo>
         <mi>x</mi>
         <mo stretchy="false">)</mo>
        </mrow>
       </mrow>
       <mo stretchy="false">)</mo>
      </mrow>
     </mrow>
     <mi>f</mi>
     <mrow>
      <mo stretchy="false">(</mo>
      <mi>x</mi>
      <mo stretchy="false">)</mo>
     </mrow>
     <mi>d</mi>
     <mi>x</mi>
    </mrow>
   </mrow>
   <mo>=</mo>
   <mrow>
    <mo>-</mo>
    <mi>H</mi>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <int></int>
     <apply>
      <times></times>
      <apply>
       <exp></exp>
       <apply>
        <times></times>
        <ci>f</ci>
        <ci>x</ci>
       </apply>
      </apply>
      <ci>f</ci>
      <ci>x</ci>
      <ci>d</ci>
      <ci>x</ci>
     </apply>
    </apply>
    <apply>
     <minus></minus>
     <ci>H</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \int\exp{(f(x))}f(x)dx=-H
  </annotation>
 </semantics>
</math>

 to be the constant, 

<math display="inline" id="Maximum_entropy_probability_distribution:17">
 <semantics>
  <mrow>
   <mi>p</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <mi>x</mi>
    <mo stretchy="false">)</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <ci>p</ci>
    <ci>x</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   p(x)
  </annotation>
 </semantics>
</math>

 is the maximum entropy probability distribution under the constraint 

<math display="inline" id="Maximum_entropy_probability_distribution:18">
 <semantics>
  <mrow>
   <mrow>
    <mo largeop="true" symmetric="true">∫</mo>
    <mrow>
     <mi>p</mi>
     <mrow>
      <mo stretchy="false">(</mo>
      <mi>x</mi>
      <mo stretchy="false">)</mo>
     </mrow>
     <mi>f</mi>
     <mrow>
      <mo stretchy="false">(</mo>
      <mi>x</mi>
      <mo stretchy="false">)</mo>
     </mrow>
     <mi>d</mi>
     <mi>x</mi>
    </mrow>
   </mrow>
   <mo>=</mo>
   <mrow>
    <mo>-</mo>
    <mi>H</mi>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <int></int>
     <apply>
      <times></times>
      <ci>p</ci>
      <ci>x</ci>
      <ci>f</ci>
      <ci>x</ci>
      <ci>d</ci>
      <ci>x</ci>
     </apply>
    </apply>
    <apply>
     <minus></minus>
     <ci>H</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \int p(x)f(x)dx=-H
  </annotation>
 </semantics>
</math>

.</p>

<p>Nontrivial examples are distributions that are subject to multiple constraints that are different from the assignment of the entropy. These are often found by starting with the same procedure 

<math display="inline" id="Maximum_entropy_probability_distribution:19">
 <semantics>
  <mrow>
   <mrow>
    <mrow>
     <mi>ln</mi>
     <mi>p</mi>
    </mrow>
    <mrow>
     <mo stretchy="false">(</mo>
     <mi>x</mi>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
   <mo>→</mo>
   <mrow>
    <mi>f</mi>
    <mrow>
     <mo stretchy="false">(</mo>
     <mi>x</mi>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <ci>normal-→</ci>
    <apply>
     <times></times>
     <apply>
      <ln></ln>
      <ci>p</ci>
     </apply>
     <ci>x</ci>
    </apply>
    <apply>
     <times></times>
     <ci>f</ci>
     <ci>x</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \ln{p(x)}\rightarrow f(x)
  </annotation>
 </semantics>
</math>

 and finding that 

<math display="inline" id="Maximum_entropy_probability_distribution:20">
 <semantics>
  <mrow>
   <mi>f</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <mi>x</mi>
    <mo stretchy="false">)</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <ci>f</ci>
    <ci>x</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   f(x)
  </annotation>
 </semantics>
</math>

 can be separated into parts.</p>

<p>A table of examples of maximum entropy distributions is given in Lisman (1972) <a class="footnoteRef" href="#fn4" id="fnref4"><sup>4</sup></a> and Park &amp; Bera (2009)<a class="footnoteRef" href="#fn5" id="fnref5"><sup>5</sup></a></p>
<h3 id="uniform-and-piecewise-uniform-distributions">Uniform and piecewise uniform distributions</h3>

<p>The <a href="Uniform_distribution_(continuous)" title="wikilink">uniform distribution</a> on the interval [<em>a</em>,<em>b</em>] is the maximum entropy distribution among all continuous distributions which are supported in the interval [<em>a</em>, <em>b</em>], and thus the probability density is 0 outside of the interval. This uniform density can be related to Laplace's <a href="principle_of_indifference" title="wikilink">principle of indifference</a>, sometimes called the principle of insufficient reason. More generally, if we're given a subdivision <em>a</em>=<em>a</em><sub>0</sub> 1 <em>k</em> = <em>b</em> of the interval [<em>a</em>,<em>b</em>] and probabilities <em>p</em><sub>1</sub>,...,<em>p</em><sub><em>k</em></sub> which add up to one, then we can consider the class of all continuous distributions such that</p>

<p>

<math display="block" id="Maximum_entropy_probability_distribution:21">
 <semantics>
  <mrow>
   <mrow>
    <mrow>
     <mo>Pr</mo>
     <mrow>
      <mo stretchy="false">(</mo>
      <mrow>
       <msub>
        <mi>a</mi>
        <mrow>
         <mi>j</mi>
         <mo>-</mo>
         <mn>1</mn>
        </mrow>
       </msub>
       <mo>≤</mo>
       <mi>X</mi>
       <mo><</mo>
       <msub>
        <mi>a</mi>
        <mi>j</mi>
       </msub>
      </mrow>
      <mo stretchy="false">)</mo>
     </mrow>
    </mrow>
    <mo>=</mo>
    <msub>
     <mi>p</mi>
     <mi>j</mi>
    </msub>
   </mrow>
   <mrow>
    <mrow>
     <mtext>for</mtext>
     <mi>j</mi>
    </mrow>
    <mo>=</mo>
    <mrow>
     <mn>1</mn>
     <mo>,</mo>
     <mi mathvariant="normal">…</mi>
     <mo>,</mo>
     <mi>k</mi>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">formulae-sequence</csymbol>
    <apply>
     <eq></eq>
     <apply>
      <ci>Pr</ci>
      <apply>
       <and></and>
       <apply>
        <leq></leq>
        <apply>
         <csymbol cd="ambiguous">subscript</csymbol>
         <ci>a</ci>
         <apply>
          <minus></minus>
          <ci>j</ci>
          <cn type="integer">1</cn>
         </apply>
        </apply>
        <ci>X</ci>
       </apply>
       <apply>
        <lt></lt>
        <share href="#.cmml">
        </share>
        <apply>
         <csymbol cd="ambiguous">subscript</csymbol>
         <ci>a</ci>
         <ci>j</ci>
        </apply>
       </apply>
      </apply>
     </apply>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>p</ci>
      <ci>j</ci>
     </apply>
    </apply>
    <apply>
     <eq></eq>
     <apply>
      <times></times>
      <mtext>for</mtext>
      <ci>j</ci>
     </apply>
     <list>
      <cn type="integer">1</cn>
      <ci>normal-…</ci>
      <ci>k</ci>
     </list>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \operatorname{Pr}(a_{j-1}\leq X<a_{j})=p_{j}\quad\mbox{ for }j=1,\ldots,k
  </annotation>
 </semantics>
</math>

 The density of the maximum entropy distribution for this class is constant on each of the intervals [<em>a</em><sub><em>j</em>-1</sub>,<em>a</em><sub><em>j</em></sub>). The uniform distribution on the finite set {<em>x</em><sub>1</sub>,...,<em>x</em><sub><em>n</em></sub>} (which assigns a probability of 1/<em>n</em> to each of these values) is the maximum entropy distribution among all discrete distributions supported on this set.</p>
<h3 id="positive-and-specified-mean-the-exponential-distribution">Positive and specified mean: the exponential distribution</h3>

<p>The <a href="exponential_distribution" title="wikilink">exponential distribution</a>, for which the density function is</p>

<p>

<math display="block" id="Maximum_entropy_probability_distribution:22">
 <semantics>
  <mrow>
   <mi>p</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <mi>x</mi>
    <mo stretchy="false">|</mo>
    <mi>λ</mi>
    <mo stretchy="false">)</mo>
   </mrow>
   <mo>=</mo>
   <mrow>
    <mo>{</mo>
    <mtable displaystyle="true">
     <mtr>
      <mtd columnalign="left">
       <mrow>
        <mi>λ</mi>
        <msup>
         <mi>e</mi>
         <mrow>
          <mo>-</mo>
          <mrow>
           <mi>λ</mi>
           <mi>x</mi>
          </mrow>
         </mrow>
        </msup>
       </mrow>
      </mtd>
      <mtd columnalign="left">
       <mrow>
        <mrow>
         <mi>x</mi>
         <mo>≥</mo>
         <mn>0</mn>
        </mrow>
        <mo>,</mo>
       </mrow>
      </mtd>
     </mtr>
     <mtr>
      <mtd columnalign="left">
       <mn>0</mn>
      </mtd>
      <mtd columnalign="left">
       <mrow>
        <mrow>
         <mi>x</mi>
         <mo><</mo>
         <mn>0</mn>
        </mrow>
        <mo>,</mo>
       </mrow>
      </mtd>
     </mtr>
    </mtable>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <cerror>
    <csymbol cd="ambiguous">fragments</csymbol>
    <csymbol cd="unknown">p</csymbol>
    <cerror>
     <csymbol cd="ambiguous">fragments</csymbol>
     <ci>normal-(</ci>
     <csymbol cd="unknown">x</csymbol>
     <ci>normal-|</ci>
     <csymbol cd="unknown">λ</csymbol>
     <ci>normal-)</ci>
    </cerror>
    <eq></eq>
    <apply>
     <csymbol cd="latexml">cases</csymbol>
     <apply>
      <times></times>
      <ci>λ</ci>
      <apply>
       <csymbol cd="ambiguous">superscript</csymbol>
       <ci>e</ci>
       <apply>
        <minus></minus>
        <apply>
         <times></times>
         <ci>λ</ci>
         <ci>x</ci>
        </apply>
       </apply>
      </apply>
     </apply>
     <apply>
      <geq></geq>
      <ci>x</ci>
      <cn type="integer">0</cn>
     </apply>
     <cn type="integer">0</cn>
     <apply>
      <lt></lt>
      <ci>x</ci>
      <cn type="integer">0</cn>
     </apply>
    </apply>
   </cerror>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   p(x|\lambda)=\begin{cases}\lambda e^{-\lambda x}&x\geq 0,\\
0&x<0,\end{cases}
  </annotation>
 </semantics>
</math>

</p>

<p>is the maximum entropy distribution among all continuous distributions supported in [0,∞] that have a specified mean of 1/λ.</p>
<h3 id="specified-variance-the-normal-distribution">Specified variance: the normal distribution</h3>

<p>The <a href="normal_distribution" title="wikilink">normal distribution</a> N(μ,σ<sup>2</sup>), for which the density function is</p>

<p>

<math display="block" id="Maximum_entropy_probability_distribution:23">
 <semantics>
  <mrow>
   <mi>p</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <mi>x</mi>
    <mo stretchy="false">|</mo>
    <mi>μ</mi>
    <mo>,</mo>
    <mi>σ</mi>
    <mo stretchy="false">)</mo>
   </mrow>
   <mo>=</mo>
   <mfrac>
    <mn>1</mn>
    <mrow>
     <mi>σ</mi>
     <msqrt>
      <mrow>
       <mn>2</mn>
       <mi>π</mi>
      </mrow>
     </msqrt>
    </mrow>
   </mfrac>
   <msup>
    <mi>e</mi>
    <mrow>
     <mo>-</mo>
     <mfrac>
      <msup>
       <mrow>
        <mo stretchy="false">(</mo>
        <mrow>
         <mi>x</mi>
         <mo>-</mo>
         <mi>μ</mi>
        </mrow>
        <mo stretchy="false">)</mo>
       </mrow>
       <mn>2</mn>
      </msup>
      <mrow>
       <mn>2</mn>
       <msup>
        <mi>σ</mi>
        <mn>2</mn>
       </msup>
      </mrow>
     </mfrac>
    </mrow>
   </msup>
   <mo>,</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <cerror>
    <csymbol cd="ambiguous">fragments</csymbol>
    <csymbol cd="unknown">p</csymbol>
    <cerror>
     <csymbol cd="ambiguous">fragments</csymbol>
     <ci>normal-(</ci>
     <csymbol cd="unknown">x</csymbol>
     <ci>normal-|</ci>
     <csymbol cd="unknown">μ</csymbol>
     <ci>normal-,</ci>
     <csymbol cd="unknown">σ</csymbol>
     <ci>normal-)</ci>
    </cerror>
    <eq></eq>
    <apply>
     <divide></divide>
     <cn type="integer">1</cn>
     <apply>
      <times></times>
      <ci>σ</ci>
      <apply>
       <root></root>
       <apply>
        <times></times>
        <cn type="integer">2</cn>
        <ci>π</ci>
       </apply>
      </apply>
     </apply>
    </apply>
    <apply>
     <csymbol cd="ambiguous">superscript</csymbol>
     <ci>e</ci>
     <apply>
      <minus></minus>
      <apply>
       <divide></divide>
       <apply>
        <csymbol cd="ambiguous">superscript</csymbol>
        <apply>
         <minus></minus>
         <ci>x</ci>
         <ci>μ</ci>
        </apply>
        <cn type="integer">2</cn>
       </apply>
       <apply>
        <times></times>
        <cn type="integer">2</cn>
        <apply>
         <csymbol cd="ambiguous">superscript</csymbol>
         <ci>σ</ci>
         <cn type="integer">2</cn>
        </apply>
       </apply>
      </apply>
     </apply>
    </apply>
    <ci>normal-,</ci>
   </cerror>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   p(x|\mu,\sigma)=\frac{1}{\sigma\sqrt{2\pi}}e^{-\frac{(x-\mu)^{2}}{2\sigma^{2}}},
  </annotation>
 </semantics>
</math>

</p>

<p>has maximum entropy among all <a href="real_number" title="wikilink">real</a>-valued distributions with a specified <a class="uri" href="variance" title="wikilink">variance</a> <em>σ</em><sup>2</sup> (a particular <a href="Moment_(mathematics)" title="wikilink">moment</a>). Therefore, the assumption of normality imposes the minimal prior structural constraint beyond this moment. (See the <a href="Differential_entropy#Maximization_in_the_normal_distribution" title="wikilink">differential entropy</a> article for a derivation.)</p>
<h3 id="discrete-distributions-with-specified-mean">Discrete distributions with specified mean</h3>

<p>Among all the discrete distributions supported on the set {<em>x</em><sub>1</sub>,...,<em>x</em><sub><em>n</em></sub>} with a specified mean μ, the maximum entropy distribution has the following shape:</p>

<p>

<math display="block" id="Maximum_entropy_probability_distribution:24">
 <semantics>
  <mrow>
   <mrow>
    <mrow>
     <mo>Pr</mo>
     <mrow>
      <mo stretchy="false">(</mo>
      <mrow>
       <mi>X</mi>
       <mo>=</mo>
       <msub>
        <mi>x</mi>
        <mi>k</mi>
       </msub>
      </mrow>
      <mo stretchy="false">)</mo>
     </mrow>
    </mrow>
    <mo>=</mo>
    <mrow>
     <mi>C</mi>
     <msup>
      <mi>r</mi>
      <msub>
       <mi>x</mi>
       <mi>k</mi>
      </msub>
     </msup>
    </mrow>
   </mrow>
   <mrow>
    <mrow>
     <mtext>for</mtext>
     <mi>k</mi>
    </mrow>
    <mo>=</mo>
    <mrow>
     <mn>1</mn>
     <mo>,</mo>
     <mi mathvariant="normal">…</mi>
     <mo>,</mo>
     <mi>n</mi>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">formulae-sequence</csymbol>
    <apply>
     <eq></eq>
     <apply>
      <ci>Pr</ci>
      <apply>
       <eq></eq>
       <ci>X</ci>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <ci>x</ci>
        <ci>k</ci>
       </apply>
      </apply>
     </apply>
     <apply>
      <times></times>
      <ci>C</ci>
      <apply>
       <csymbol cd="ambiguous">superscript</csymbol>
       <ci>r</ci>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <ci>x</ci>
        <ci>k</ci>
       </apply>
      </apply>
     </apply>
    </apply>
    <apply>
     <eq></eq>
     <apply>
      <times></times>
      <mtext>for</mtext>
      <ci>k</ci>
     </apply>
     <list>
      <cn type="integer">1</cn>
      <ci>normal-…</ci>
      <ci>n</ci>
     </list>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \operatorname{Pr}(X=x_{k})=Cr^{x_{k}}\quad\mbox{ for }k=1,\ldots,n
  </annotation>
 </semantics>
</math>

 where the positive constants <em>C</em> and <em>r</em> can be determined by the requirements that the sum of all the probabilities must be 1 and the expected value must be μ.</p>

<p>For example, if a large number <em>N</em> of dice are thrown, and you are told that the sum of all the shown numbers is <em>S</em>. Based on this information alone, what would be a reasonable assumption for the number of dice showing 1, 2, ..., 6? This is an instance of the situation considered above, with {<em>x</em><sub>1</sub>,...,<em>x</em><sub>6</sub>} = {1,...,6} and μ = <em>S</em>/<em>N</em>.</p>

<p>Finally, among all the discrete distributions supported on the infinite set {<em>x</em><sub>1</sub>,<em>x</em><sub>2</sub>,...} with mean μ, the maximum entropy distribution has the shape:</p>

<p>

<math display="block" id="Maximum_entropy_probability_distribution:25">
 <semantics>
  <mrow>
   <mrow>
    <mrow>
     <mrow>
      <mo>Pr</mo>
      <mrow>
       <mo stretchy="false">(</mo>
       <mrow>
        <mi>X</mi>
        <mo>=</mo>
        <msub>
         <mi>x</mi>
         <mi>k</mi>
        </msub>
       </mrow>
       <mo stretchy="false">)</mo>
      </mrow>
     </mrow>
     <mo>=</mo>
     <mrow>
      <mi>C</mi>
      <msup>
       <mi>r</mi>
       <msub>
        <mi>x</mi>
        <mi>k</mi>
       </msub>
      </msup>
     </mrow>
    </mrow>
    <mrow>
     <mrow>
      <mtext>for</mtext>
      <mi>k</mi>
     </mrow>
     <mo>=</mo>
     <mrow>
      <mn>1</mn>
      <mo>,</mo>
      <mn>2</mn>
      <mo>,</mo>
      <mi mathvariant="normal">…</mi>
     </mrow>
    </mrow>
   </mrow>
   <mo>,</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">formulae-sequence</csymbol>
    <apply>
     <eq></eq>
     <apply>
      <ci>Pr</ci>
      <apply>
       <eq></eq>
       <ci>X</ci>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <ci>x</ci>
        <ci>k</ci>
       </apply>
      </apply>
     </apply>
     <apply>
      <times></times>
      <ci>C</ci>
      <apply>
       <csymbol cd="ambiguous">superscript</csymbol>
       <ci>r</ci>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <ci>x</ci>
        <ci>k</ci>
       </apply>
      </apply>
     </apply>
    </apply>
    <apply>
     <eq></eq>
     <apply>
      <times></times>
      <mtext>for</mtext>
      <ci>k</ci>
     </apply>
     <list>
      <cn type="integer">1</cn>
      <cn type="integer">2</cn>
      <ci>normal-…</ci>
     </list>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \operatorname{Pr}(X=x_{k})=Cr^{x_{k}}\quad\mbox{ for }k=1,2,\ldots,
  </annotation>
 </semantics>
</math>

 where again the constants <em>C</em> and <em>r</em> were determined by the requirements that the sum of all the probabilities must be 1 and the expected value must be μ. For example, in the case that <em>x<sub>k</sub> = k</em>, this gives</p>

<p>

<math display="block" id="Maximum_entropy_probability_distribution:26">
 <semantics>
  <mrow>
   <mrow>
    <mrow>
     <mi>C</mi>
     <mo>=</mo>
     <mfrac>
      <mn>1</mn>
      <mrow>
       <mi>μ</mi>
       <mo>-</mo>
       <mn>1</mn>
      </mrow>
     </mfrac>
    </mrow>
    <mo rspace="22.5pt">,</mo>
    <mrow>
     <mi>r</mi>
     <mo>=</mo>
     <mfrac>
      <mrow>
       <mi>μ</mi>
       <mo>-</mo>
       <mn>1</mn>
      </mrow>
      <mi>μ</mi>
     </mfrac>
    </mrow>
   </mrow>
   <mo>,</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">formulae-sequence</csymbol>
    <apply>
     <eq></eq>
     <ci>C</ci>
     <apply>
      <divide></divide>
      <cn type="integer">1</cn>
      <apply>
       <minus></minus>
       <ci>μ</ci>
       <cn type="integer">1</cn>
      </apply>
     </apply>
    </apply>
    <apply>
     <eq></eq>
     <ci>r</ci>
     <apply>
      <divide></divide>
      <apply>
       <minus></minus>
       <ci>μ</ci>
       <cn type="integer">1</cn>
      </apply>
      <ci>μ</ci>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   C=\frac{1}{\mu-1},\quad\quad r=\frac{\mu-1}{\mu},
  </annotation>
 </semantics>
</math>

</p>

<p>such that respective maximum entropy distribution is the <a href="geometric_distribution" title="wikilink">geometric distribution</a>.</p>
<h3 id="circular-random-variables">Circular random variables</h3>

<p>For a continuous random variable 

<math display="inline" id="Maximum_entropy_probability_distribution:27">
 <semantics>
  <msub>
   <mi>θ</mi>
   <mi>i</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>θ</ci>
    <ci>i</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \theta_{i}
  </annotation>
 </semantics>
</math>

 distributed about the unit circle, the <a href="Von_Mises_distribution" title="wikilink">Von Mises distribution</a> maximizes the entropy when the real and imaginary parts of the first <a href="Directional_statistics" title="wikilink">circular moment</a> are specified<a class="footnoteRef" href="#fn6" id="fnref6"><sup>6</sup></a> or, equivalently, the <a href="circular_mean" title="wikilink">circular mean</a> and <a href="circular_variance" title="wikilink">circular variance</a> are specified.</p>

<p>When the mean and variance of the angles 

<math display="inline" id="Maximum_entropy_probability_distribution:28">
 <semantics>
  <msub>
   <mi>θ</mi>
   <mi>i</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>θ</ci>
    <ci>i</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \theta_{i}
  </annotation>
 </semantics>
</math>

 modulo 

<math display="inline" id="Maximum_entropy_probability_distribution:29">
 <semantics>
  <mrow>
   <mn>2</mn>
   <mi>π</mi>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <cn type="integer">2</cn>
    <ci>π</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   2\pi
  </annotation>
 </semantics>
</math>

 are specified, the <a href="wrapped_normal_distribution" title="wikilink">wrapped normal distribution</a> maximizes the entropy.<a class="footnoteRef" href="#fn7" id="fnref7"><sup>7</sup></a></p>
<h3 id="maximizer-for-specified-mean-variance-and-skew">Maximizer for specified mean, variance and skew</h3>

<p>There exists an upper bound on the entropy of continuous random variables on 

<math display="inline" id="Maximum_entropy_probability_distribution:30">
 <semantics>
  <mi>ℝ</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>ℝ</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \mathbb{R}
  </annotation>
 </semantics>
</math>


 with a specified mean, variance, and skew. However, there is <em>no distribution which achieves this upper bound</em> because 

<math display="inline" id="Maximum_entropy_probability_distribution:31">
 <semantics>
  <mrow>
   <mrow>
    <mi>p</mi>
    <mrow>
     <mo stretchy="false">(</mo>
     <mi>x</mi>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
   <mo>=</mo>
   <mrow>
    <mi>c</mi>
    <mrow>
     <mi>exp</mi>
     <mrow>
      <mo stretchy="false">(</mo>
      <mrow>
       <mrow>
        <msub>
         <mi>λ</mi>
         <mn>1</mn>
        </msub>
        <mi>x</mi>
       </mrow>
       <mo>+</mo>
       <mrow>
        <msub>
         <mi>λ</mi>
         <mn>2</mn>
        </msub>
        <msup>
         <mi>x</mi>
         <mn>2</mn>
        </msup>
       </mrow>
       <mo>+</mo>
       <mrow>
        <msub>
         <mi>λ</mi>
         <mn>3</mn>
        </msub>
        <msup>
         <mi>x</mi>
         <mn>3</mn>
        </msup>
       </mrow>
      </mrow>
      <mo stretchy="false">)</mo>
     </mrow>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <times></times>
     <ci>p</ci>
     <ci>x</ci>
    </apply>
    <apply>
     <times></times>
     <ci>c</ci>
     <apply>
      <exp></exp>
      <apply>
       <plus></plus>
       <apply>
        <times></times>
        <apply>
         <csymbol cd="ambiguous">subscript</csymbol>
         <ci>λ</ci>
         <cn type="integer">1</cn>
        </apply>
        <ci>x</ci>
       </apply>
       <apply>
        <times></times>
        <apply>
         <csymbol cd="ambiguous">subscript</csymbol>
         <ci>λ</ci>
         <cn type="integer">2</cn>
        </apply>
        <apply>
         <csymbol cd="ambiguous">superscript</csymbol>
         <ci>x</ci>
         <cn type="integer">2</cn>
        </apply>
       </apply>
       <apply>
        <times></times>
        <apply>
         <csymbol cd="ambiguous">subscript</csymbol>
         <ci>λ</ci>
         <cn type="integer">3</cn>
        </apply>
        <apply>
         <csymbol cd="ambiguous">superscript</csymbol>
         <ci>x</ci>
         <cn type="integer">3</cn>
        </apply>
       </apply>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   p(x)=c\exp{(\lambda_{1}x+\lambda_{2}x^{2}+\lambda_{3}x^{3})}
  </annotation>
 </semantics>
</math>

 is unbounded except when 

<math display="inline" id="Maximum_entropy_probability_distribution:32">
 <semantics>
  <mrow>
   <msub>
    <mi>λ</mi>
    <mn>3</mn>
   </msub>
   <mo>=</mo>
   <mn>0</mn>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>λ</ci>
     <cn type="integer">3</cn>
    </apply>
    <cn type="integer">0</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \lambda_{3}=0
  </annotation>
 </semantics>
</math>

 (see Cover, chapter 11). Thus, we cannot construct a maximum entropy distribution given these constraints.</p>

<p>However, the maximum entropy is 

<math display="inline" id="Maximum_entropy_probability_distribution:33">
 <semantics>
  <mi>ϵ</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>ϵ</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \epsilon
  </annotation>
 </semantics>
</math>

-achievable. Start with a normal distribution of the specified mean and variance. To introduce a positive skew, perturb the normal distribution upward by a small amount at a value many 

<math display="inline" id="Maximum_entropy_probability_distribution:34">
 <semantics>
  <mi>σ</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>σ</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \sigma
  </annotation>
 </semantics>
</math>

 larger than the mean. The skewness, being proportional to the third moment, will be affected more than the lower order moments.</p>
<h3 id="other-examples">Other examples</h3>

<p>In the table below, each listed distribution maximizes the entropy for a particular set of functional constraints listed in the third column, and the constraint that x be included in the support of the probability density, which is listed in the fourth column.<a class="footnoteRef" href="#fn8" id="fnref8"><sup>8</sup></a> <a class="footnoteRef" href="#fn9" id="fnref9"><sup>9</sup></a> Several examples (Bernoulli, geometric, exponential, Laplace, Pareto) listed are trivially true because their associated constraints are equivalent to the assignment of their entropy. They are included anyway because their constraint is related to a common or easily measured quantity. For reference, 

<math display="inline" id="Maximum_entropy_probability_distribution:35">
 <semantics>
  <mrow>
   <mrow>
    <mi mathvariant="normal">Γ</mi>
    <mrow>
     <mo stretchy="false">(</mo>
     <mi>x</mi>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
   <mo>=</mo>
   <mrow>
    <msubsup>
     <mo largeop="true" symmetric="true">∫</mo>
     <mn>0</mn>
     <mi mathvariant="normal">∞</mi>
    </msubsup>
    <mrow>
     <msup>
      <mi>e</mi>
      <mrow>
       <mo>-</mo>
       <mi>t</mi>
      </mrow>
     </msup>
     <msup>
      <mi>t</mi>
      <mrow>
       <mi>x</mi>
       <mo>-</mo>
       <mn>1</mn>
      </mrow>
     </msup>
     <mi>d</mi>
     <mi>t</mi>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <times></times>
     <ci>normal-Γ</ci>
     <ci>x</ci>
    </apply>
    <apply>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <int></int>
       <cn type="integer">0</cn>
      </apply>
      <infinity></infinity>
     </apply>
     <apply>
      <times></times>
      <apply>
       <csymbol cd="ambiguous">superscript</csymbol>
       <ci>e</ci>
       <apply>
        <minus></minus>
        <ci>t</ci>
       </apply>
      </apply>
      <apply>
       <csymbol cd="ambiguous">superscript</csymbol>
       <ci>t</ci>
       <apply>
        <minus></minus>
        <ci>x</ci>
        <cn type="integer">1</cn>
       </apply>
      </apply>
      <ci>d</ci>
      <ci>t</ci>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \Gamma(x)=\int_{0}^{\infty}e^{-t}t^{x-1}dt
  </annotation>
 </semantics>
</math>


 is the <a href="gamma_function" title="wikilink">gamma function</a>, 

<math display="inline" id="Maximum_entropy_probability_distribution:36">
 <semantics>
  <mrow>
   <mrow>
    <mi>ψ</mi>
    <mrow>
     <mo stretchy="false">(</mo>
     <mi>x</mi>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
   <mo>=</mo>
   <mrow>
    <mfrac>
     <mi>d</mi>
     <mrow>
      <mi>d</mi>
      <mi>x</mi>
     </mrow>
    </mfrac>
    <mrow>
     <mi>ln</mi>
     <mi mathvariant="normal">Γ</mi>
    </mrow>
    <mrow>
     <mo stretchy="false">(</mo>
     <mi>x</mi>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
   <mo>=</mo>
   <mfrac>
    <mrow>
     <msup>
      <mi mathvariant="normal">Γ</mi>
      <mo>′</mo>
     </msup>
     <mrow>
      <mo stretchy="false">(</mo>
      <mi>x</mi>
      <mo stretchy="false">)</mo>
     </mrow>
    </mrow>
    <mrow>
     <mi mathvariant="normal">Γ</mi>
     <mrow>
      <mo stretchy="false">(</mo>
      <mi>x</mi>
      <mo stretchy="false">)</mo>
     </mrow>
    </mrow>
   </mfrac>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <and></and>
    <apply>
     <eq></eq>
     <apply>
      <times></times>
      <ci>ψ</ci>
      <ci>x</ci>
     </apply>
     <apply>
      <times></times>
      <apply>
       <divide></divide>
       <ci>d</ci>
       <apply>
        <times></times>
        <ci>d</ci>
        <ci>x</ci>
       </apply>
      </apply>
      <apply>
       <ln></ln>
       <ci>normal-Γ</ci>
      </apply>
      <ci>x</ci>
     </apply>
    </apply>
    <apply>
     <eq></eq>
     <share href="#.cmml">
     </share>
     <apply>
      <divide></divide>
      <apply>
       <times></times>
       <apply>
        <csymbol cd="ambiguous">superscript</csymbol>
        <ci>normal-Γ</ci>
        <ci>normal-′</ci>
       </apply>
       <ci>x</ci>
      </apply>
      <apply>
       <times></times>
       <ci>normal-Γ</ci>
       <ci>x</ci>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \psi(x)=\frac{d}{dx}\ln\Gamma(x)=\frac{\Gamma^{\prime}(x)}{\Gamma(x)}
  </annotation>
 </semantics>
</math>

 is the <a href="digamma_function" title="wikilink">digamma function</a>, 

<math display="inline" id="Maximum_entropy_probability_distribution:37">
 <semantics>
  <mrow>
   <mrow>
    <mi>B</mi>
    <mrow>
     <mo stretchy="false">(</mo>
     <mi>p</mi>
     <mo>,</mo>
     <mi>q</mi>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
   <mo>=</mo>
   <mfrac>
    <mrow>
     <mi mathvariant="normal">Γ</mi>
     <mrow>
      <mo stretchy="false">(</mo>
      <mi>p</mi>
      <mo stretchy="false">)</mo>
     </mrow>
     <mi mathvariant="normal">Γ</mi>
     <mrow>
      <mo stretchy="false">(</mo>
      <mi>q</mi>
      <mo stretchy="false">)</mo>
     </mrow>
    </mrow>
    <mrow>
     <mi mathvariant="normal">Γ</mi>
     <mrow>
      <mo stretchy="false">(</mo>
      <mrow>
       <mi>p</mi>
       <mo>+</mo>
       <mi>q</mi>
      </mrow>
      <mo stretchy="false">)</mo>
     </mrow>
    </mrow>
   </mfrac>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <times></times>
     <ci>B</ci>
     <interval closure="open">
      <ci>p</ci>
      <ci>q</ci>
     </interval>
    </apply>
    <apply>
     <divide></divide>
     <apply>
      <times></times>
      <ci>normal-Γ</ci>
      <ci>p</ci>
      <ci>normal-Γ</ci>
      <ci>q</ci>
     </apply>
     <apply>
      <times></times>
      <ci>normal-Γ</ci>
      <apply>
       <plus></plus>
       <ci>p</ci>
       <ci>q</ci>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   B(p,q)=\frac{\Gamma(p)\Gamma(q)}{\Gamma(p+q)}
  </annotation>
 </semantics>
</math>

 is the <a href="beta_function" title="wikilink">beta function</a>, and γ<sub><em>E</em></sub> is <a href="Euler-Mascheroni_constant" title="wikilink">Euler's constant</a>.</p>
<table>
<tbody>
<tr class="odd">
<td style="text-align: left;">
<p>Table of probability distributions and corresponding maximum entropy constraints</p></td>
</tr>
<tr class="even">
<td style="text-align: left;">
<p>Distribution Name</p></td>
</tr>
<tr class="odd">
<td style="text-align: left;">
<p><a href="Uniform_distribution_(discrete)" title="wikilink">Uniform (discrete)</a></p></td>
</tr>
<tr class="even">
<td style="text-align: left;">
<p><a href="Uniform_distribution_(continuous)" title="wikilink">Uniform (continuous)</a></p></td>
</tr>
<tr class="odd">
<td style="text-align: left;">
<p><a href="Bernoulli_distribution" title="wikilink">Bernoulli</a></p></td>
</tr>
<tr class="even">
<td style="text-align: left;">
<p><a href="Geometric_distribution" title="wikilink">Geometric</a></p></td>
</tr>
<tr class="odd">
<td style="text-align: left;">
<p><a href="Exponential_distribution" title="wikilink">Exponential</a></p></td>
</tr>
<tr class="even">
<td style="text-align: left;">
<p><a href="Laplace_distribution" title="wikilink">Laplace</a></p></td>
</tr>
<tr class="odd">
<td style="text-align: left;">
<p><a href="Pareto_distribution" title="wikilink">Pareto</a></p></td>
</tr>
<tr class="even">
<td style="text-align: left;">
<p><a href="Normal_distribution" title="wikilink">Normal</a></p></td>
</tr>
<tr class="odd">
<td style="text-align: left;">
<p><a href="von_Mises_distribution" title="wikilink">von Mises</a></p></td>
</tr>
<tr class="even">
<td style="text-align: left;">
<p><a href="Rayleigh_distribution" title="wikilink">Rayleigh</a></p></td>
</tr>
<tr class="odd">
<td style="text-align: left;">
<p><a href="Beta_distribution" title="wikilink">Beta</a></p></td>
</tr>
<tr class="even">
<td style="text-align: left;">
<p><a href="Cauchy_distribution" title="wikilink">Cauchy</a></p></td>
</tr>
<tr class="odd">
<td style="text-align: left;">
<p><a href="Chi_distribution" title="wikilink">Chi</a></p></td>
</tr>
<tr class="even">
<td style="text-align: left;">
<p><a href="Chi-squared_distribution" title="wikilink">Chi-squared</a></p></td>
</tr>
<tr class="odd">
<td style="text-align: left;">
<p><a href="Erlang_distribution" title="wikilink">Erlang</a></p></td>
</tr>
<tr class="even">
<td style="text-align: left;">
<p><a href="Gamma_distribution" title="wikilink">Gamma</a></p></td>
</tr>
<tr class="odd">
<td style="text-align: left;">
<p><a href="Log-normal_distribution" title="wikilink">Lognormal</a></p></td>
</tr>
<tr class="even">
<td style="text-align: left;">
<p><a href="Maxwell–Boltzmann_distribution" title="wikilink">Maxwell–Boltzmann</a></p></td>
</tr>
<tr class="odd">
<td style="text-align: left;">
<p><a href="Weibull_distribution" title="wikilink">Weibull</a></p></td>
</tr>
<tr class="even">
<td style="text-align: left;">
<p><a href="Multivariate_normal_distribution" title="wikilink">Multivariate normal</a></p></td>
</tr>
<tr class="odd">
<td style="text-align: left;">
<p><a href="Binomial_distribution" title="wikilink">Binomial</a></p></td>
</tr>
<tr class="even">
<td style="text-align: left;">
<p><a href="Poisson_distribution" title="wikilink">Poisson</a></p></td>
</tr>
<tr class="odd">
</tr>
</tbody>
</table>
<h2 id="see-also">See also</h2>
<ul>
<li><a href="Exponential_family" title="wikilink">Exponential family</a></li>
<li><a href="Gibbs_measure" title="wikilink">Gibbs measure</a></li>
<li><a href="Partition_function_(mathematics)" title="wikilink">Partition function (mathematics)</a></li>
</ul>
<h2 id="notes">Notes</h2>
<h2 id="references">References</h2>
<ul>
<li></li>
<li>I. J. Taneja, <em><a href="http://www.mtm.ufsc.br/~taneja/book/book.html">Generalized Information Measures and Their Applications</a></em> 2001. <a href="http://www.mtm.ufsc.br/~taneja/book/node14.html">Chapter 1</a></li>
</ul>

<p>"</p>

<p><a href="Category:Entropy_and_information" title="wikilink">Category:Entropy and information</a> <a href="Category:Continuous_distributions" title="wikilink">Category:Continuous distributions</a> <a href="Category:Discrete_distributions" title="wikilink">Category:Discrete distributions</a> <a href="Category:Particle_statistics" title="wikilink">Category:Particle statistics</a> <a href="Category:Types_of_probability_distributions" title="wikilink">Category:Types of probability distributions</a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1">Williams, D. (2001) <em>Weighing the Odds</em> Cambridge UP ISBN 0-521-00618-X (pages 197-199)<a href="#fnref1">↩</a></li>
<li id="fn2">Bernardo, J.M., Smith, A.F.M. (2000) ''Bayesian Theory'.' Wiley. ISBN 0-471-49464-X (pages 209, 366)<a href="#fnref2">↩</a></li>
<li id="fn3">O'Hagan, A. (1994) <em>Kendall's Advanced Theory of statistics, Vol 2B, Bayesian Inference</em>, Edward Arnold. ISBN 0-340-52922-9 (Section 5.40)<a href="#fnref3">↩</a></li>
<li id="fn4"><a href="#fnref4">↩</a></li>
<li id="fn5"><a href="#fnref5">↩</a></li>
<li id="fn6"><a href="#fnref6">↩</a></li>
<li id="fn7"></li>
<li id="fn8"></li>
<li id="fn9"></li>
</ol>
</section>
</body>
</html>
