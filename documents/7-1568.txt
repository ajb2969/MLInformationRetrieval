   False discovery rate      False discovery rate  The '''False discovery rate''' ('''FDR''') is one way of conceptualizing the rate of [[Type I and type II errors|type I errors]] in [[null hypothesis]] testing when conducting [[multiple comparisons]]. FDR-controlling procedures are designed to control the [[Expected value|expected]] proportion of rejected [[null hypothesis|null hypotheses]] that were incorrec t rejections ("false discoveries"). 1 FDR-controlling procedures provide less stringent control of Type I errors compared to familywise error rate (FWER) controlling procedures (such as the Bonferroni correction ), which control the probability of at least one Type I error. Thus, FDR-controlling procedures have greater power , at the cost of increased rates of Type I errors. 2  History  Technological motivations  The modern widespread use of the FDR is believed to stem from, and be motivated by, the development in technologies that allowed the collection and analysis of a large number of distinct variables in several individuals (e.g., the expression level of each of 10,000 different genes in 100 different persons). 3 By the late 1980s and 1990s, the development of "high-throughput" sciences, such as genomics , allowed for rapid data acquisition. This, coupled with the growth in computing power, made it possible to seamlessly perform hundreds and thousands of statistical tests on a given data set. The technology of microarrays was a prototypical example, as it enabled thousands of genes to be tested simultaneously for differential expression between two biological conditions. 4  As high-throughput technologies became common, technological and/or financial constraints led researchers to collect datasets with relatively small sample sizes (e.g. few individuals being tested) and large numbers of variables being measured per sample (e.g. thousands of gene expression levels). In these datasets, too few of the measured variables showed statistical significance after classic correction for multiple tests with standard multiple comparison procedures . This created a need within many scientific communities to abandon FWER and unadjusted multiple hypothesis testing for other ways to highlight and rank in publications those variables showing marked effects across individuals or treatments that would otherwise be dismissed as non-significant after standard correction for multiple tests. In response to this, a variety of error rates have been proposed—and become commonly used in publications—that are less conservative than FWER in flagging possibly noteworthy observations. As a side effect, standard correction for multiple tests has disappeared from all but those publications which present results with huge sample sizes.  The false discovery rate concept was formally described by Yoav Benjamini and Yosi Hochberg in 1995 5 as a less conservative and arguably more appropriate approach for identifying the important few from the trivial many effects tested. The FDR has been particularly influential, as it was the first alternative to the FWER to gain broad acceptance in many scientific fields (especially in the life sciences, from genetics to biochemistry, oncology and plant sciences). 6 In 2005, the Benjamini and Hochberg paper from 1995 was identified as one of the 25 most-cited statistical papers. 7  Related statistical concepts  Prior to the 1995 introduction of the FDR concept, various precursor ideas had been considered in the statistics literature. In 1979, Holm proposed the Holm procedure , 8 a stepwise algorithm for controlling the FWER that is at least as powerful as the well-known Bonferroni adjustment. This stepwise algorithm sorts the p-values and sequentially rejects the hypotheses starting from the smallest p-value.  Benjamini (2010) 9 said that the false discovery rate, and the paper Benjamini and Hochberg (1995), had its origins in two papers concerned with multiple testing:   The first paper is by Schweder and Spjotvoll (1982) 10 who suggested plotting the ranked p-values and assessing the number of true null hypotheses (    m  0     subscript  m  0    m_{0}   ) via an eye-fitted line starting from the largest p-values. The p-values that deviate from this straight line then should correspond to the false null hypotheses. This idea was later developed into an algorithm and incorporated the estimation of    m  0     subscript  m  0    m_{0}   into procedures such as Bonferroni, Holm or Hochberg. 11 This idea is closely related to the graphical interpretation of the BH procedure.  The second paper is by Branko Soric (1989) 12 which introduced the terminology of "discovery" in the multiple hypothesis testing context. Soric used the expected number of false discoveries divided by the number of discoveries    (    E   [  V  ]    R   )        E   delimited-[]  V    R    \left(\frac{E[V]}{R}\right)   as a warning that "a large part of statistical discoveries may be wrong". This led Benjamini and Hochberg to the idea that a similar error rate, rather than being merely a warning, can serve as a worthy goal to control.   The q-value quantity (defined below) was first proposed by John Storey . 13  Definitions  Classification of m hypothesis tests  The following table gives a number of errors committed when testing   m   m   m   null hypotheses. It defines some random variables that are related to the   m   m   m   hypothesis tests.      |   Null hypothesis is True (H 0 )   Alternative hypothesis is True (H 1 )   | Total       | Declared significant      V   V   V         S   S   S         R   R   R        | Declared non-significant      U   U   U         T   T   T          m  -  R      m  R    m-R        Total       m  0     subscript  m  0    m_{0}          m  -   m  0       m   subscript  m  0     m-m_{0}         m   m   m            m   m   m   is the total number hypotheses tested      m  0     subscript  m  0    m_{0}   is the number of true null hypotheses      m  -   m  0       m   subscript  m  0     m-m_{0}   is the number of true alternative hypotheses     V   V   V   is the number of false positives (Type I error) (also called "false discoveries")     S   S   S   is the number of true positives (also called "true discoveries")     T   T   T   is the number of false negatives (Type II error)     U   U   U   is the number of true negatives     R   R   R   is the number of rejected null hypotheses (also called "discoveries")  In   m   m   m   hypothesis tests of which    m  0     subscript  m  0    m_{0}   are true null hypotheses,   R   R   R   is an observable random variable, and   S   S   S   ,   T   T   T   ,   U   U   U   , and   V   V   V   are unobservable random variables .   The FDR  Based on previous definitions we can define   Q   Q   Q   as the proportion of false discoveries among the discoveries    (   Q  =   V  R    )      Q    V  R     \left(Q=\frac{V}{R}\right)   . And the false discovery rate is given by: 14        F  D  R   =   Q  e   =    E    [  Q  ]    =    E    [   V   V  +  S    ]    =    E    [   V  R   ]     ,          F  D  R    subscript  Q  e          normal-E   delimited-[]  Q           normal-E   delimited-[]    V    V  S             normal-E   delimited-[]    V  R        FDR=Q_{e}=\mathrm{E}\!\left[Q\right]=\mathrm{E}\!\left[\frac{V}{V+S}\right]=%
 \mathrm{E}\!\left[\frac{V}{R}\right],     where    V  R      V  R    \frac{V}{R}   is defined to be 0 when    R  =  0      R  0    R=0   .  And one wants to keep this value below a threshold q .  Properties  The FDR is the expected proportion of false positives among all discoveries (rejected null hypotheses); for example, if the null hypotheses of 1000 hypothesis tests were experimentally rejected, and a maximum FDR level (q-value) for these tests was 0.10, then less than 100 of these rejections would be expected to be false positives.  Adaptive and scalable  Using a multiplicity procedure that controls the FDR criterion is adaptive and scalable . Meaning that controlling the FDR can be very permissive (if the data justify it), or conservative (acting close to control of FWER for sparse problem) - all depending on the number of hypotheses tested and the level of significance. 15  The FDR criterion adapts so that the same number of false discoveries (V) will mean different things, depending on the total number of discoveries (R). This contrasts the family wise error rate criterion. For example, if inspecting 100 hypotheses (say, 100 genetic mutations or SNPs for association with some phenotype in some population):   If we make 4 discoveries (R), having 2 of them be false discoveries (V) is often unbearable. Whereas,  If we make 50 discoveries (R), having 2 of them be false discoveries (V) is often bearable.   The FDR criterion is scalable in that the same proportion of false discoveries out of the total number of discoveries (Q), remains sensible for different number of total discoveries (R). For example:   If we make 100 discoveries (R), having 5 of them be false discoveries (    q  =   5  %       q   percent  5     q=5\%   ) can be bearable.  Similarly, if we make 1000 discoveries (R), having 50 of them be false discoveries (as before,    q  =   5  %       q   percent  5     q=5\%   ) can still be bearable.   The FDR criterion is also scalable in the sense that when making a correction on a set of hypotheses, or two corrections if the set of hypotheses were to be split into two - the discoveries in the combined study are (about) the same as when analyzed separately. For this to hold, the sub-studies should be large with some discoveries in them.  Dependency in the test statistics  Controlling the FDR using the linear step-up BH Procedure, at level q, has several properties related to the dependency structure between the test statistics of the   m   m   m   null hypothesis that are being corrected for. If the test statistics are:   Independent: 16      F  D  R   ≤     m  0   m   q         F  D  R        subscript  m  0   m   q     FDR\leq\frac{m_{0}}{m}q     Independent and continuous: 17      F  D  R   =     m  0   m   q         F  D  R        subscript  m  0   m   q     FDR=\frac{m_{0}}{m}q     Positive dependent: 18      F  D  R   ≤     m  0   m   q         F  D  R        subscript  m  0   m   q     FDR\leq\frac{m_{0}}{m}q     In the general case: 19      F  D  R   ≤     m  0   m   q   (   1  +   1  2   +   1  3   +  ⋯  +   1  m    )    ≈     m  0   m   q   log   (  m  )             F  D  R        subscript  m  0   m   q    1    1  2     1  3   normal-⋯    1  m               subscript  m  0   m   q    m       FDR\leq\frac{m_{0}}{m}q\left(1+\frac{1}{2}+\frac{1}{3}+\cdots+\frac{1}{m}%
 \right)\approx\frac{m_{0}}{m}q\log(m)      Proportion of true hypotheses  If all of the null hypotheses are true (     m  0   =  m       subscript  m  0   m    m_{0}=m   ), then controlling the FDR at level q guarantees control over the FWER (this is also called "weak control of the FWER" )    F  W  E  R  =  P   (  V  ≥  1  )   =  E   (   V  R   )   =  F  D  R  ≤  q     fragments  F  W  E  R   P   fragments  normal-(  V   1  normal-)    E   fragments  normal-(    V  R   normal-)    F  D  R   q    FWER=P\left(V\geq 1\right)=E\left(\frac{V}{R}\right)=FDR\leq q   . 20 But if there are some true discoveries to be made (     H  1   …   H  m        subscript  H  1   normal-…   subscript  H  m     H_{1}\ldots H_{m}   . In that case there will be room for improving detection power. It also means that any procedure that controls the FWER will also control the FDR.  Bayesian approaches  Connections have been made between the FDR and Bayesian approaches (including empirical Bayes methods), 21 22 23 thresholding wavelets coefficients and model selection, 24 25 26 27 and generalizing the confidence interval into the False coverage statement rate (FCR). 28  Controlling procedures  The settings for many procedures is such that we have     P  1   …   P  m        subscript  P  1   normal-…   subscript  P  m     P_{1}\ldots P_{m}   null hypotheses tested and     P   (  1  )    …   P   (  m  )         subscript  P  1   normal-…   subscript  P  m     P_{(1)}\ldots P_{(m)}   their corresponding p-values . We order these p-values in increasing order and denote them by   α   α   \alpha   . A small p-value often corresponds to a high test statistic. A procedure that goes from a small p-value to a large one will be called a step-up procedure. In a similar way, in a "step-down" procedure we move to a small corresponding test statistic from a larger one.  Benjamini–Hochberg procedure  The Benjamini–Hochberg procedure (BH step-up procedure) controls the false discovery rate (at level   α   α   \alpha   ). 29 The procedure works as follows:   For a given   k   k   k   , find the largest      P   (  k  )    ≤    k  m   α    .       subscript  P  k       k  m   α     P_{(k)}\leq\frac{k}{m}\alpha.   such that    H   (  i  )      subscript  H  i    H_{(i)}     Then reject (i.e. declare positive discoveries) all    i  =   1  ,  …  ,  k       i   1  normal-…  k     i=1,\ldots,k   for   m   m   m   .   The BH procedure is valid when the     E   (  Q  )    ≤     m  0   m   α   ≤  α          E  Q        subscript  m  0   m   α        α     E(Q)\leq\frac{m_{0}}{m}\alpha\leq\alpha   tests are independent , and also in various scenarios of dependence. 30 It also satisfies the inequality:      m  0     subscript  m  0    m_{0}     If an estimator of   α   α   \alpha   is inserted into the BH procedure, it is no longer guaranteed to achieve FDR control at the desired level. 31 Adjustments may be needed in the estimator and several modifications have been proposed. 32 33 34 35  The BH procedure was proven to control the FDR in 1995 by Benjamini and Hochberg. 36 In 1986, R. J. Simes offered the same procedure as the " Simes procedure ", in order to control the FWER in the weak sense (under the intersection null hypothesis) when the statistics are independent. 37 In 1988, G. Hommel showed that it does not control the FWER in the strong sense in general. 38 Based on the Simes procedure, Yossi Hochberg proposed Hochberg's step-up procedure (1988) which does control the FWER in the strong sense under certain assumptions on the dependence of the test statistics. 39  Note that the mean   m   m   m   for these     α   (   m  +  1   )     2  m         α    m  1      2  m     \frac{\alpha(m+1)}{2m}   tests is   α   α   \alpha   , the Mean(FDR   α   α   \alpha   ) or MFDR,   m   m   m   adjusted for   k   k   k   independent (or positively correlated, see below) tests. The MFDR calculation shown here is for a single value and is not part of the Benjamini and Hochberg method; see AFDR below.  Benjamini–Hochberg–Yekutieli procedure  The Benjamini–Hochberg–Yekutieli procedure controls the false discovery rate under positive dependence assumptions. 40 This refinement modifies the threshold and finds the largest     P   (  k  )    ≤    k    m  ⋅  c    (  m  )     α        subscript  P  k       k     normal-⋅  m  c   m    α     P_{(k)}\leq\frac{k}{m\cdot c(m)}\alpha   such that:       c   (  m  )    =  1        c  m   1    c(m)=1      If the tests are independent or positively correlated     c   (  m  )    =    ∑   i  =  1   m    1  i          c  m     superscript   subscript     i  1    m     1  i      c(m)=\sum_{i=1}^{m}\frac{1}{i}     Under arbitrary dependence    c   (  m  )       c  m    c(m)      In the case of negative correlation,       ∑   i  =  1   m    1  i    ≈    ln   (  m  )    +  γ    .        superscript   subscript     i  1    m     1  i        m   γ     \sum_{i=1}^{m}\frac{1}{i}\approx\ln(m)+\gamma.   can be approximated by using the Euler–Mascheroni constant .     α   α   \alpha     Using MFDR and formulas above, an adjusted MFDR, or AFDR, is the min(mean   m   m   m   ) for     /   c   (  m  )        absent    c  m     /c(m)   dependent tests = MFDR    π  0     subscript  π  0    \pi_{0}   .  The other way to address dependence is by bootstrapping and rerandomization. 41 42 43  Estimating the FDR  Let     π  1   =   1  -   π  0         subscript  π  1     1   subscript  π  0      \pi_{1}=1-\pi_{0}   be the proportion of true null hypotheses, and    N   π  0       N   subscript  π  0     N\pi_{0}   be the proportion of true alternative hypotheses. 44 Then    1  -  α      1  α    1-\alpha   times the average p-value of rejected effects divided by the number of rejected effects gives an estimate of the FDR.  False coverage rate  The false coverage rate (FCR) is the FDR equivalent to the idea of confidence interval . FCR indicates the average rate of false coverage, namely, not covering the true parameters, among the selected intervals. The FCR gives a simultaneous coverage at a    P  C  E  R      P  C  E  R    PCER   level for all of the parameters considered in the problem. Intervals with simultaneous coverage probability 1−q can control the FCR to be bounded by q . There are many FCR procedures such as: Bonferroni-Selected–Bonferroni-Adjusted, Adjusted BH-Selected CIs (Benjamini and Yekutieli (2005)), 45 Bayes FCR (Yekutieli (2008)), and other Bayes methods. 46 The incentive of choosing one procedure over another is the length of the CI we will want it to be narrow as possible while controlling the FCR.  Related error rates  The discovery of the FDR was preceded and followed by many other types of error rates. These include:        P  C  E  R   =   E   [   V  m   ]          P  C  E  R     E   delimited-[]    V  m       PCER=E\left[\frac{V}{m}\right]   ( per-comparison error rate ) is defined as   α   α   \alpha   . Testing individually each hypothesis at level     P  C  E  R   ≤  α        P  C  E  R   α    PCER\leq\alpha   guarantees that    F  W  E  R      F  W  E  R    FWER   (this is testing without any correction for multiplicity)      F  W  E  R  =   P  all    (  V  ≥  1  )      fragments  F  W  E  R    subscript  P  all    fragments  normal-(  V   1  normal-)     FWER=P_{\text{all}}(V\geq 1)   (the family wise error rate , in the weak sense) is defined as    F  W  E  R      F  W  E  R    FWER   . There are numerous procedures that control the FWER .      F  W  E  R  =   P  any    (  V  ≥  1  )      fragments  F  W  E  R    subscript  P  any    fragments  normal-(  V   1  normal-)     FWER=P_{\text{any}}(V\geq 1)   (the family wise error rate , in the strong sense) is defined as    k  -FWER      k  -FWER    k\text{-FWER}   . There are numerous procedures that control the FWER .      k  -  F  W  E  R  =  P   (  V  ≥  k  )   ≤  q     fragments  k   F  W  E  R   P   fragments  normal-(  V   k  normal-)    q    k-FWER=P(V\geq k)\leq q   (The tail probability of the False Discovery Proportion), suggested by Lehmann and Romano, van der Laan at al , is defined as    k  -FDR      k  -FDR    k\text{-FDR}   .       k  -FDR   =   E   (    V  R    I   (  V  >  k  )     )    ≤  q          k  -FDR     E      V  R    subscript  I   fragments  normal-(  V   k  normal-)           q     k\text{-FDR}=E\left(\frac{V}{R}I_{(V>k)}\right)\leq q   (Suggested by Sarkar) is defined as    Q  ′     superscript  Q  normal-′    Q^{\prime}   .       Q  ′   =    E   [  V  ]    R        superscript  Q  normal-′       E   delimited-[]  V    R     Q^{\prime}=\frac{E[V]}{R}   is the proportion of false discoveries among the discoveries", suggested by Soric in 1989, 47 and is defined as     m  0   =  m       subscript  m  0   m    m_{0}=m   . This is a mixture of expectations and realizations, and has the problem of control for    F  D   R   -  1        F  D   subscript  R    1      FDR_{-1}   . 48       F  D   R   -  1     =   F  d  r   =    E   [  V  ]     E   [  R  ]             F  D   subscript  R    1       F  d  r            E   delimited-[]  V      E   delimited-[]  R        FDR_{-1}=Fdr=\frac{E[V]}{E[R]}   (or Fdr) was used by Benjamini and Hochberg, 49 and later called "Fdr" by Efron (2008) and earlier. 50 It is defined as    F  D   R   +  1        F  D   subscript  R    1      FDR_{+1}   . Controlling this error rate does not provide a weak control of the FWER.       F  D   R   +  1     =   p  F  D  R   =   E   [    V  R    |  R  >   0   ]            F  D   subscript  R    1       p  F  D  R          E   delimited-[]      V  R    ket  R   0        FDR_{+1}=pFDR=E\left[\left.{\frac{V}{R}}\right|R>0\right]   (or pFDR) was used by Benjamini and Hochberg, 51 and later called "pFDR" by Storey (2002). 52 It is defined as    P   (   V  R   >  q  )      fragments  P   fragments  normal-(    V  R    q  normal-)     P\left(\frac{V}{R}>q\right)   . Controlling this error rate does not provide a weak control of the FWER.  False exceedance rate (the tail probability of FDP), defined as: 53     W  -FDR      W  -FDR    W\text{-FDR}          w  i   ≥  0       subscript  w  i   0    w_{i}\geq 0   (Weighted FDR). Associated with each hypothesis i is a weight     W  -FDR   =   E   (    ∑    w  i    V  i      ∑    w  i    R  i      )          W  -FDR     E         subscript  w  i    subscript  V  i          subscript  w  i    subscript  R  i         W\text{-FDR}=E\left(\frac{\sum w_{i}V_{i}}{\sum w_{i}R_{i}}\right)   , the weights capture importance/price. The W-FDR is defined as    F  D  C  R      F  D  C  R    FDCR   .      c  i     subscript  c  i    c_{i}   (False Discovery Cost Rate). Stemming from statistical process control : associated with each hypothesis i is a cost    H  00     subscript  H  00    H_{00}   and with the intersection hypothesis    c  0     subscript  c  0    c_{0}   a cost     F  D  C  R   =   E   (     c  0    V  0    +    ∑    c  i    V  i        c  0    R  0    +   ∑    c  i    R  i        )          F  D  C  R     E       subscript  c  0    subscript  V  0           subscript  c  i    subscript  V  i          subscript  c  0    subscript  R  0         subscript  c  i    subscript  R  i           FDCR=E\left(c_{0}V_{0}+\frac{\sum c_{i}V_{i}}{c_{0}R_{0}+\sum c_{i}R_{i}}\right)   . The motivation is that stopping a production process may incur a fixed cost. It is defined as    P  F  E  R      P  F  E  R    PFER        α   α   \alpha   ( per-family error rate ), at     P  F  E  R   =   E   (  V  )    ≤  α          P  F  E  R     E  V        α     PFER=E(V)\leq\alpha   level, is defined as    F  N  R      F  N  R    FNR   .       F  N  R   =   E   (   T   m  -  R    )    =   E   (    m  -   m  0   -   (   R  -  V   )     m  -  R    )            F  N  R     E    T    m  R            E      m   subscript  m  0     R  V      m  R        FNR=E\left(\frac{T}{m-R}\right)=E\left(\frac{m-m_{0}-(R-V)}{m-R}\right)   (False non-discovery rates) by Sarkar; Genovese and Wasserman  is define as    F  d  r   (  z  )       F  d  r  z    Fdr(z)      Related statistics        F  d  r   (  z  )    =     p  0    F  0    (  z  )     F   (  z  )           F  d  r  z        subscript  p  0    subscript  F  0   z     F  z      Fdr(z)=\frac{p_{0}F_{0}(z)}{F(z)}   is defined as    f  d  r      f  d  r    fdr          f  d  r   =     p  0    f  0    (  z  )     f   (  z  )           f  d  r        subscript  p  0    subscript  f  0   z     f  z      fdr=\frac{p_{0}f_{0}(z)}{f(z)}   The local fdr is defined as $$fdr = \frac{p_0 f_0 (z)}{f(z)}$$   See also   Positive predictive value   References  External links   False Discovery Rate Analysis in R – Lists links with popular R packages  Large-scale Simultaneous Inference – Syllabus, notes, and homework from Efron's course at Stanford. Includes PDFs for each chapter of his book.   "  Category:Hypothesis testing  Category:Summary statistics for contingency tables  Category:Multiple comparisons     ↩  Shaffer J.P. (1995) Multiple hypothesis testing, Annual Review of Psychology 46:561-584, Annual Reviews ↩   ↩    ↩  ↩  ↩  ↩  ↩  ↩  ↩         ↩  ↩  ↩  ↩  ↩  ↩  ↩  ↩     ↩  ↩  ↩  ↩   ↩  ↩  ↩  ↩   ↩  ↩    ↩     ↩    ↩     