<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="946">Focused information criterion</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>Focused information criterion</h1>
<hr>In [[statistics]], the '''focused information criterion (FIC)''' is a method for selecting the most appropriate model among a set of competitors for a given data set. Unlike most other [[model selection]]
<p><code>strategies, like the </code><a href="Akaike_information_criterion" title="wikilink"><code>Akaike</code> <code>information</code> <code>criterion</code></a><code> (AIC), the </code><a href="Bayesian_information_criterion" title="wikilink"><code>Bayesian</code> <code>information</code> <code>criterion</code></a><code> (BIC) and the </code><a href="deviance_information_criterion" title="wikilink"><code>deviance</code> <code>information</code> <code>criterion</code></a><code> (DIC), the FIC does not attempt to assess the overall fit of candidate models but focuses attention directly on the parameter of primary interest with the statistical analysis, say </code>

<math display="inline" id="Focused_information_criterion:0">
 <semantics>
  <mi>μ</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>μ</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \mu
  </annotation>
 </semantics>
</math>

<code>, for which competing models lead to different estimates, say </code>

<math display="inline" id="Focused_information_criterion:1">
 <semantics>
  <msub>
   <mover accent="true">
    <mi>μ</mi>
    <mo stretchy="false">^</mo>
   </mover>
   <mi>j</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <apply>
     <ci>normal-^</ci>
     <ci>μ</ci>
    </apply>
    <ci>j</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \hat{\mu}_{j}
  </annotation>
 </semantics>
</math>

<code> for model </code>

<math display="inline" id="Focused_information_criterion:2">
 <semantics>
  <mi>j</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>j</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   j
  </annotation>
 </semantics>
</math>

<code>. The FIC method consists in first developing an exact or approximate expression for the precision or quality of each </code><a href="estimator" title="wikilink"><code>estimator</code></a><code>, say </code>

<math display="inline" id="Focused_information_criterion:3">
 <semantics>
  <msub>
   <mi>r</mi>
   <mi>j</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>r</ci>
    <ci>j</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   r_{j}
  </annotation>
 </semantics>
</math>


<code> for </code>

<math display="inline" id="Focused_information_criterion:4">
 <semantics>
  <msub>
   <mover accent="true">
    <mi>μ</mi>
    <mo stretchy="false">^</mo>
   </mover>
   <mi>j</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <apply>
     <ci>normal-^</ci>
     <ci>μ</ci>
    </apply>
    <ci>j</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \hat{\mu}_{j}
  </annotation>
 </semantics>
</math>

<code>, and then use data to estimate these precision measures, say </code>

<math display="inline" id="Focused_information_criterion:5">
 <semantics>
  <msub>
   <mover accent="true">
    <mi>r</mi>
    <mo stretchy="false">^</mo>
   </mover>
   <mi>j</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <apply>
     <ci>normal-^</ci>
     <ci>r</ci>
    </apply>
    <ci>j</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \hat{r}_{j}
  </annotation>
 </semantics>
</math>

<code>. In the end the model with best estimated precision is selected. The FIC methodology was developed by Gerda Claeskens and </code><a href="Nils_Lid_Hjort" title="wikilink"><code>Nils</code> <code>Lid</code> <code>Hjort</code></a><code>, first in two 2003 discussion articles in </code><em><a href="Journal_of_the_American_Statistical_Association" title="wikilink"><code>Journal</code> <code>of</code> <code>the</code> <code>American</code> <code>Statistical</code> <code>Association</code></a></em><code> and later on in other papers and in their 2008 book.</code></p>

<p>The concrete formulae and implementation for FIC depend firstly on the particular parameter of interest, the choice of which does not depend on mathematics but on the scientific and statistical context. Thus the FIC apparatus may be selecting one model as most appropriate for estimating a quantile of a distribution but preferring another model as best for estimating the mean value. Secondly, the FIC formulae depend on the specifics of the models used for the observed data and also on how precision is to be measured. The clearest case is where precision is taken to be <a href="mean_squared_error" title="wikilink">mean squared error</a>, say 

<math display="inline" id="Focused_information_criterion:6">
 <semantics>
  <mrow>
   <msub>
    <mi>r</mi>
    <mi>j</mi>
   </msub>
   <mo>=</mo>
   <mrow>
    <msubsup>
     <mi>b</mi>
     <mi>j</mi>
     <mn>2</mn>
    </msubsup>
    <mo>+</mo>
    <msubsup>
     <mi>τ</mi>
     <mi>j</mi>
     <mn>2</mn>
    </msubsup>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>r</ci>
     <ci>j</ci>
    </apply>
    <apply>
     <plus></plus>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>b</ci>
       <ci>j</ci>
      </apply>
      <cn type="integer">2</cn>
     </apply>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>τ</ci>
       <ci>j</ci>
      </apply>
      <cn type="integer">2</cn>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   r_{j}=b_{j}^{2}+\tau_{j}^{2}
  </annotation>
 </semantics>
</math>

 in terms of <a href="Bias_of_an_estimator" title="wikilink">squared bias</a> and <a class="uri" href="variance" title="wikilink">variance</a> for the estimator associated with model 

<math display="inline" id="Focused_information_criterion:7">
 <semantics>
  <mi>j</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>j</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   j
  </annotation>
 </semantics>
</math>

. FIC formulae are then available in a variety of situations, both for handling <a href="parametric_model" title="wikilink">parametric</a>, <a href="semiparametric_model" title="wikilink">semiparametric</a> and <a href="non-parametric_statistics" title="wikilink">nonparametric</a> situations, involving separate estimation of squared bias and variance, leading to estimated precision 

<math display="inline" id="Focused_information_criterion:8">
 <semantics>
  <msub>
   <mover accent="true">
    <mi>r</mi>
    <mo stretchy="false">^</mo>
   </mover>
   <mi>j</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <apply>
     <ci>normal-^</ci>
     <ci>r</ci>
    </apply>
    <ci>j</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \hat{r}_{j}
  </annotation>
 </semantics>
</math>


. In the end the FIC selects the model with smallest estimated mean squared error.</p>

<p>Associated with the use of the FIC for selecting a good model is the <em>FIC plot</em>, designed to give a clear and informative picture of all estimates, across all candidate models, and their merit. It displays estimates on the 

<math display="inline" id="Focused_information_criterion:9">
 <semantics>
  <mi>y</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>y</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   y
  </annotation>
 </semantics>
</math>

 axis along with FIC scores on the 

<math display="inline" id="Focused_information_criterion:10">
 <semantics>
  <mi>x</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>x</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   x
  </annotation>
 </semantics>
</math>

 axis; thus estimates found to the left in the plot are associated with the better models and those found in the middle and to the right stem from models less or not adequate for the purpose of estimating the focus parameter in question.</p>

<p>Generally speaking, complex models (with many parameters relative to <a href="sample_size" title="wikilink">sample size</a>) tend to lead to estimators with small bias but high variance; more parsimonious models (with fewer parameters) typically yield estimators with larger bias but smaller variance. The FIC method balances the two desired data of having small bias and small variance in an optimal fashion. The main difficulty lies with the bias 

<math display="inline" id="Focused_information_criterion:11">
 <semantics>
  <msub>
   <mi>b</mi>
   <mi>j</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>b</ci>
    <ci>j</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   b_{j}
  </annotation>
 </semantics>
</math>

, as it involves the distance from the expected value of the estimator to the true underlying quantity to be estimated, and the true data generating mechanism may lie outside each of the candidate models.</p>

<p>In situations where there is not a unique focus parameter, but rather a family of such, there are versions of <em>average FIC</em> (AFIC or wFIC) that find the best model in terms of suitably weighted performance measures, e.g. when searching for a <a href="regression_analysis" title="wikilink">regression</a> model to perform particularly well in a portion of the <a class="uri" href="covariate" title="wikilink">covariate</a> space.</p>

<p>It is also possible to keep several of the best models on board, ending the statistical analysis with a data-dicated weighted average of the estimators of the best FIC scores, typically giving highest weight to estimators associated with the best FIC scores. Such schemes of <em>model averaging</em> extend the direct FIC selection method.</p>

<p>The FIC methodology applies in particular to selection of variables in different forms of <a href="regression_analysis" title="wikilink">regression analysis</a>, including the framework of <a href="generalized_linear_model" title="wikilink">generalised linear models</a> and the semiparametric <a href="proportional_hazards_models" title="wikilink">proportional hazards models</a> (i.e. Cox regression).</p>
<h2 id="see-also">See also</h2>
<ul>
<li><a href="Hannan-Quinn_information_criterion" title="wikilink">Hannan-Quinn information criterion</a></li>
</ul>
<h2 id="references">References</h2>
<ul>
<li>Claeskens, G. and Hjort, N.L. (2003). "The focused information criterion" (with discussion). <em><a href="Journal_of_the_American_Statistical_Association" title="wikilink">Journal of the American Statistical Association</a></em>, volume 98, pp. 879–899. </li>
<li>Hjort, N.L. and Claeskens, G. (2003). "Frequentist model average estimators" (with discussion). <em><a href="Journal_of_the_American_Statistical_Association" title="wikilink">Journal of the American Statistical Association</a></em>, volume 98, pp. 900–916. </li>
<li>Hjort, N.L. and Claeskens, G. (2006). "Focused information criteria and model averaging for the Cox hazard regression model." <em><a href="Journal_of_the_American_Statistical_Association" title="wikilink">Journal of the American Statistical Association</a></em>, volume 101, pp. 1449–1464. </li>
<li>Claeskens, G. and Hjort, N.L. (2008). <em>Model Selection and Model Averaging.</em> <a href="Cambridge_University_Press" title="wikilink">Cambridge University Press</a>.</li>
</ul>
<h2 id="external-links">External links</h2>
<ul>
<li><a href="http://www.esi-topics.com/fbp/2005/august05-Hjort_Claeskens.html">Interview on frequentist model averaging</a> with Essential Science Indicators</li>
<li><a href="http://www.econ.kuleuven.ac.be/public/ndbaf45/modelselection/">Webpage for Model Selection and Model Averaging</a> the Claeskens and Hjort book</li>
</ul>

<p>"</p>

<p><a href="Category:Bayesian_statistics" title="wikilink">Category:Bayesian statistics</a> <a href="Category:Regression_variable_selection" title="wikilink">Category:Regression variable selection</a> <a href="Category:Model_selection" title="wikilink">Category:Model selection</a> <a href="Category:Statistical_inference" title="wikilink">Category:Statistical inference</a></p>
</hr></body>
</html>
