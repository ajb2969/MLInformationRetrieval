   Divergence (computer science)      Divergence (computer science)   In computer science , a computation is said to diverge if it does not terminate or terminates in an (unobservable) exceptional state . Otherwise it is said to converge . In domains where computations are expected to be infinite, such as process calculi , a computation is said to diverge if it fails to be productive (always produces an action within a finite amount of time.)  Definitions  Various subfields of computer science use varying, but mathematically precise, definitions of what it means for a computation to converge or diverge.  Rewriting  In abstract rewriting , an abstract rewriting system is called convergent if it is both confluent and terminating .  The notation t ↓ n means that t reduces to normal form n in zero or more reductions , t ↓ means t reduces to some normal form in zero or more reductions, and t ↑ means t does not reduce to a normal form; the latter is impossible in a terminating rewriting system.  In the lambda calculus an expression is divergent if it has no normal form .  Denotational semantics  In denotational semantics an object function  f : A → B can be modelled as a mathematical function  f : A ∪ {⊥} → B ∪ {⊥} where ⊥ ( bottom ) indicates that the object function or its argument diverges.  Concurrency theory  In the calculus of communicating sequential processes , divergence is a drastic situation where a process performs an endless series of hidden actions. For example, consider the following process, defined by CSP notation:       C  l  o  c  k   =   t  i  c  k   →   C  l  o  c  k           C  l  o  c  k     t  i  c  k     normal-→      C  l  o  c  k      Clock=tick\rightarrow Clock   The traces of this process are defined as:       traces   (   C  l  o  c  k   )    =   {   ⟨  ⟩   ,   ⟨   t  i  c  k   ⟩   ,   ⟨   t  i  c  k   ,   t  i  c  k   ⟩   ,  ⋯  }   =    {   t  i  c  k   }   *          traces    C  l  o  c  k       delimited-⟨⟩    t  i  c  k       t  i  c  k     t  i  c  k    normal-⋯         superscript     t  i  c  k         \operatorname{traces}(Clock)=\{\langle\rangle,\langle tick\rangle,\langle tick%
 ,tick\rangle,\cdots\}=\{tick\}^{*}   Now, consider the following process, which conceals the tick event of the Clock process:      P  =     C  l  o  c  k   \  t   i  c  k       P     normal-\    C  l  o  c  k   t   i  c  k     P=Clock\backslash tick   By definition, P is called a divergent process.  See also   Infinite loop   Notes  References     J. M. R. Martin and S. A. Jassim (1997). "How to Design Deadlock-Free Networks Using CSP and Verification Tools: A Tutorial Introduction" in Proceedings of the WoTUG-20 .   "  Category:Programming language theory  Category:Process (computing)  Category:Rewriting systems  Category:Lambda calculus  Category:Denotational semantics   