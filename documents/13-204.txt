   Magnus expansion      Magnus expansion   In mathematics and physics , the Magnus expansion , named after Wilhelm Magnus (1907–1990), provides an exponential representation of the solution of a first order homogeneous linear differential equation for a linear operator . In particular it furnishes the fundamental matrix of a system of linear ordinary differential equations of order   n   n   n   with varying coefficients. The exponent is built up as an infinite series whose terms involve multiple integrals and nested commutators.  Magnus approach and its interpretation  Given the    n  ×  n      n  normal-×  n    n×n   coefficient matrix    A   (  t  )       A  t    A(t)   , one wishes to solve the initial value problem associated with the linear ordinary differential equation         Y  ′    (  t  )    =   A   (  t  )   Y   (  t  )     ,    Y   (   t  0   )    =   Y  0       formulae-sequence       superscript  Y  normal-′   t     A  t  Y  t        Y   subscript  t  0     subscript  Y  0      Y^{\prime}(t)=A(t)Y(t),\qquad\qquad Y(t_{0})=Y_{0}     for the unknown   n   n   n   -dimensional vector function    Y   (  t  )       Y  t    Y(t)   .  When n = 1, the solution simply reads        Y   (  t  )    =    exp   (    ∫   t  0   t    A   (  s  )   d  s    )     Y  0     .        Y  t         superscript   subscript    subscript  t  0    t     A  s  d  s      subscript  Y  0      Y(t)=\exp\left(\int_{t_{0}}^{t}A(s)\,ds\right)Y_{0}.     This is still valid for n > 1 if the matrix    A   (  t  )       A  t    A(t)   satisfies  A ( t 2 ) A ( t 1 )}} for any pair of values of t , t 1 and t 2 . In particular, this is the case if the matrix   A   A   A   is independent of   t   t   t   . In the general case, however, the expression above is no longer the solution of the problem.  The approach introduced by Magnus to solve the matrix initial value problem is to express the solution by means of the exponential of a certain    n  ×  n      n  normal-×  n    n×n   matrix function ,        Y   (  t  )    =    exp   (   Ω   (  t  ,   t  0   )    )      Y  0      ,        Y  t         normal-Ω   t   subscript  t  0       subscript  Y  0      Y(t)=\exp\left(\Omega(t,t_{0})\right)\,Y_{0}~{},   which is subsequently constructed as a series expansion,          Ω   (  t  )    =    ∑   k  =  1   ∞     Ω  k    (  t  )      ,        normal-Ω  t     superscript   subscript     k  1         subscript  normal-Ω  k   t      \Omega(t)=\sum_{k=1}^{\infty}\Omega_{k}(t),        where, for simplicity, it is customary to write    Ω   (  t  )       normal-Ω  t    Ω(t)   for and to take t 0 = 0.  Magnus appreciated that, since  A ( t )}} , using a Poincaré−Hausdorff matrix identity, he could relate the time-derivative of   Ω   normal-Ω   Ω   to the generating function of Bernoulli numbers and the adjoint endomorphism of   Ω   normal-Ω   Ω   ,          Ω  ′   =      ad  Ω     exp   (   ad  Ω   )    -  1      A     ,       superscript  normal-Ω  normal-′        subscript  ad  normal-Ω        subscript  ad  normal-Ω    1    A     \Omega^{\prime}=\frac{\operatorname{ad}_{\Omega}}{\exp(\operatorname{ad}_{%
 \Omega})-1}~{}A~{},        to solve for   Ω   normal-Ω   Ω   recursively in terms of   A   A   A   , "in a continuous analog of the CBH expansion ", as outlined in a subsequent section.  The equation above constitutes the Magnus expansion or Magnus series for the solution of matrix linear initial value problem. The first four terms of this series read       Ω  1    (  t  )        subscript  normal-Ω  1   t    \displaystyle\Omega_{1}(t)   where     A  A   ,   B  ≡  A  B  −  B  A        A  A     B  normal-≡  A  B  normal-−  B  A     AA,B≡AB−BA   is the matrix commutator of A and B .  These equations may be interpreted as follows: coincides exactly with the exponent in the scalar (   n   n   n   = 1) case, but this equation cannot give the whole solution. If one insists in having an exponential representation ( Lie group ), the exponent needs to be corrected. The rest of the Magnus series provides that correction systematically:   Ω   normal-Ω   Ω   or parts of it are in the Lie algebra of the Lie group of the evolution.  In applications, one can rarely sum exactly the Magnus series and one has to truncate it to get approximate solutions. The main advantage of the Magnus proposal is that, very often, the truncated series still shares with the exact solution important qualitative properties, at variance with other conventional perturbation theories. For instance, in classical mechanics the symplectic character of the time evolution is preserved at every order of approximation. Similarly the unitary character of the time evolution operator in quantum mechanics is also preserved (in contrast, e.g., to the Dyson series solving the same problem).  Convergence of the expansion  From a mathematical point of view, the convergence problem is the following: given a certain matrix    A   (  t  )       A  t    A(t)   , when can the exponent    Ω   (  t  )       normal-Ω  t    Ω(t)   be obtained as the sum of the Magnus series?  A sufficient condition for this series to converge for    t  ∈  0  ,  ,  T  )     fragments  t  ∈  0  normal-,  normal-,  T  normal-)    t∈0,,T)   is        ∫  0  T      ∥   A   (  s  )    ∥   2   d  s    <  π        superscript   subscript   0   T      subscript   norm    A  s    2   d  s    π    \int_{0}^{T}\|A(s)\|_{2}ds<\pi   where    ∥  ⋅   ∥  2      fragments  parallel-to  normal-⋅   subscript  parallel-to  2     \|\cdot\|_{2}   denotes a matrix norm . This result is generic, in the sense that one may construct specific matrices    A   (  t  )       A  t    A(t)   for which the series diverges for any    t  >  T      t  T    t>T   .  Magnus generator  A recursive procedure to generate all the terms in the Magnus expansion utilizes the matrices , defined recursively through        S  n   (  j  )    =    ∑   m  =  1    n  -  j     [   Ω  m   ,   S   n  -  m    (   j  -  1   )    ]     ,   2  ≤  j  ≤   n  -  1       formulae-sequence     superscript   subscript  S  n   j     superscript   subscript     m  1      n  j      subscript  normal-Ω  m    superscript   subscript  S    n  m      j  1           2  j         n  1       S_{n}^{(j)}=\sum_{m=1}^{n-j}\left[\Omega_{m},S_{n-m}^{(j-1)}\right],\qquad%
 \qquad 2\leq j\leq n-1            S  n   (  1  )    =   [   Ω   n  -  1    ,  A  ]    ,    S  n   (   n  -  1   )    =    ad   Ω  1    n  -  1     (  A  )      ,     formulae-sequence     superscript   subscript  S  n   1     subscript  normal-Ω    n  1    A       superscript   subscript  S  n     n  1       superscript   subscript  ad   subscript  normal-Ω  1      n  1    A      S_{n}^{(1)}=\left[\Omega_{n-1},A\right],\qquad S_{n}^{(n-1)}=\mathrm{ad}_{%
 \Omega_{1}}^{n-1}(A)~{},   which then furnish       Ω  1   =    ∫  0  t    A   (  τ  )   d  τ         subscript  normal-Ω  1     superscript   subscript   0   t     A  τ  d  τ      \Omega_{1}=\int_{0}^{t}A(\tau)d\tau           Ω  n   =    ∑   j  =  1    n  -  1       B  j    j  !      ∫  0  t     S  n   (  j  )     (  τ  )   d  τ       ,   n  ≥  2.      formulae-sequence     subscript  normal-Ω  n     superscript   subscript     j  1      n  1         subscript  B  j     j      superscript   subscript   0   t      superscript   subscript  S  n   j   τ  d  τ         n  2.     \Omega_{n}=\sum_{j=1}^{n-1}\frac{B_{j}}{j!}\int_{0}^{t}S_{n}^{(j)}(\tau)d\tau,%
 \qquad\qquad n\geq 2.     Here, ad k Ω is a shorthand for an iterated commutator, (see adjoint endomorphism ),          ad  Ω  0   A   =  A   ,     ad  Ω   k  +  1    A   =   [  Ω  ,    ad  Ω  k   A   ]     ,     formulae-sequence       superscript   subscript  ad  normal-Ω   0   A   A        superscript   subscript  ad  normal-Ω     k  1    A    normal-Ω     superscript   subscript  ad  normal-Ω   k   A       \mathrm{ad}_{\Omega}^{0}A=A,\qquad\mathrm{ad}_{\Omega}^{k+1}A=[\Omega,\mathrm{%
 ad}_{\Omega}^{k}A],   while are the Bernoulli numbers .  Finally, when this recursion is worked out explicitly, it is possible to express as a linear combination of n -fold integrals of n −1 nested commutators involving   n   n   n   matrices   A   A   A   ,          Ω  n    (  t  )    =    ∑   j  =  1    n  -  1        B  j    j  !        ∑         k  1   +  ⋯  +   k  j    =   n  -  1           k  1   ≥   1  ,  …    ,    k  j   ≥  1             ∫  0  t       ad    Ω   k  1     (  τ  )       ad    Ω   k  2     (  τ  )      ⋯    ad    Ω   k  j     (  τ  )     A   (  τ  )   d  τ         n  ≥  2    ,     formulae-sequence       subscript  normal-Ω  n   t     superscript   subscript     j  1      n  1         subscript  B  j     j      subscript    STACKED       subscript  k  1   normal-⋯   subscript  k  j      n  1     formulae-sequence     subscript  k  1    1  normal-…       subscript  k  j   1        superscript   subscript   0   t      subscript  ad     subscript  normal-Ω   subscript  k  1    τ     subscript  ad     subscript  normal-Ω   subscript  k  2    τ    normal-⋯   subscript  ad     subscript  normal-Ω   subscript  k  j    τ    A  τ  d  τ          n  2     \Omega_{n}(t)=\sum_{j=1}^{n-1}\frac{B_{j}}{j!}\,\sum_{k_{1}+\cdots+k_{j}=n-1%
 \atop k_{1}\geq 1,\ldots,k_{j}\geq 1}\,\int_{0}^{t}\,\mathrm{ad}_{\Omega_{k_{1%
 }}(\tau)}\,\mathrm{ad}_{\Omega_{k_{2}}(\tau)}\cdots\,\mathrm{ad}_{\Omega_{k_{j%
 }}(\tau)}A(\tau)\,d\tau\qquad n\geq 2,   an expression which becomes increasingly intricate with   n   n   n   .  Applications  Since the 1960s, the Magnus expansion has been successfully applied as a perturbative tool in numerous areas of physics and chemistry, from atomic and molecular physics to nuclear magnetic resonance 1 and quantum electrodynamics . It has been also used since 1998 as a tool to construct practical algorithms for the numerical integration of matrix linear differential equations. As they inherit from the Magnus expansion the preservation of qualitative traits of the problem, the corresponding schemes are prototypical examples of geometric numerical integrators .  See also   Baker–Campbell–Hausdorff formula  Derivative of the exponential map   References        "  Category:Ordinary differential equations  Category:Lie algebras  Category:Recursion schemes  Category:Mathematical physics     1.Haeberlen, U. & Waugh, J. S. Coherent Averaging Effects in Magnetic Resonance. Phys. Rev. 175, 453–467 (1968). ↩     