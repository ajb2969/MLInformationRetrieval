


Distributed constraint optimization




Distributed constraint optimization

Distributed constraint optimization (DCOP or DisCOP) is the distributed analogue to constraint optimization. A DCOP is a problem in which a group of agents must distributedly choose values for a set of variables such that the cost of a set of constraints over the variables is either minimized or maximized.
Distributed Constraint Satisfaction is a framework for describing a problem in terms of constraints that are known and enforced by distinct participants (agents). The constraints are described on some variables with predefined domains, and have to be assigned to the same values by the different agents.
Problems defined with this framework can be solved by any of the algorithms that are proposed for it.
The framework was used under different names in the 1980s. The first known usage with the current name is in 1990.
Definitions
DCOP
A DCOP can be defined as a tuple

 
 , where:



 
  is a set of agents;


 
  is a set of variables, 
 
 
 
 ;


 
  is a set of domains, 
 
 
 
 , where each 
 
 
 
  is a finite set containing the values to which its associated variable may be assigned;


 
  is a function12





that maps every possible variable assignment to a cost. This function can also be thought of as defining constraints between variables however the variables must not be Hermitian;


 
  is a function 
 
 
 
  mapping variables to their associated agent. 
 
 
 
  implies that it is agent 
 
 
 
 's responsibility to assign the value of variable 
 
 
 
 . Note that it is not necessarily true that 
 
 
 
  is either an injection or surjection; and


 
  is an operator that aggregates all of the individual 
 
 
 
  costs for all possible variable assignments. This is usually accomplished through summation:
 


 
 .


The objective of a DCOP is to have each agent assign values to its associated variables in order to either minimize or maximize 
 
 
 
  for a given assignment of the variables.
Context
A Context is a variable assignment for a DCOP. This can be thought of as a function mapping variables in the DCOP to their current values:





Note that a context is essentially a partial solution and need not contain values for every variable in the problem; therefore, 
 
 
 
  implies that the agent 
 
 
 
  has not yet assigned a value to variable 
 
 
 
 . Given this representation, the "domain" (i.e., the set of input values) of the function f can be thought of as the set of all possible contexts for the DCOP. Therefore, in the remainder of this article we may use the notion of a context (i.e., the 
 
 
 
  function) as an input to the 
 
 
 
  function.
Example problems
Distributed graph coloring
The graph coloring problem is as follows: given a graph

 
  and a set of colors 
 
 
 
 , assign each vertex, 
 
 
 
 , a color, 
 
 
 
 , such that the number of adjacent vertices with the same color is minimized.
As a DCOP, there is one agent per vertex that is assigned to decide the associated color. Each agent has a single variable whose associated domain is of cardinality

 
  (there is one domain value for each possible color). For each vertex 
 
 
 
 , create a variable in the DCOP 
 
 
 
  with domain 
 
 
 
 . For each pair of adjacent vertices 
 
 
 
 , create a constraint of cost 1 if both of the associated variables are assigned the same color:





The objective, then, is to minimize 
 
 
 
 .
Distributed multiple knapsack problem
The distributed multiple- variant of the knapsack problem is as follows: given a set of items of varying volume and a set of knapsacks of varying capacity, assign each item to a knapsack such that the amount of overflow is minimized. Let 
 
 
 
  be the set of items, 
 
 
 
  be the set of knapsacks, 
 
 
 
  be a function mapping items to their volume, and 
 
 
 
  be a function mapping knapsacks to their capacities.
To encode this problem as a DCOP, for each 
 
 
 
  create one variable 
 
 
 
  with associated domain 
 
 
 
 . Then for all possible context 
 
 
 
 :





where 
 
 
 
  is a function such that





Algorithms
DCOP algorithms can be classified according to the search strategy (best-first search or depth-first branch-and-bound search), the synchronization among agents (synchronous or asynchronous), the communication among agents (point-to-point with neighbors in the constraint graph or broadcast) and the main communication topology (chain or tree).3 ADOPT, for example, uses best-first search, asynchronous synchronization, point-to-point communication between neighboring agents in the constraint graph and a constraint tree as main communication topology.




Algorithm Name

Year Introduced

Memory Complexity

Number of Messages

Correctness (computer science)/
Completeness (logic)

Implementations





NCBB
 No-Commitment Branch and Bound {{Citation

last1 = Chechetka | first1 = Anton

last2 = Sycara | first2 = Katia

contribution = No-Commitment Branch and Bound Search for Distributed Constraint Optimization

title = Proceedings of the Fifth International Joint Conference on Autonomous Agents and Multiagent Systems

date = May 2006



DPOP
 Distributed Pseudotree Optimization Procedure {{Citation

last1 = Petcu | first1 = Adrian

last2 = Faltings | first2 = Boi

contribution = DPOP: A Scalable Method for Multiagent Constraint Optimization

title = Proceedings of the 19th International Joint Conference on Artificial Intelligence, IJCAI 2005, Edinburgh, Scotland, pp. 266-271

date = August 2005



OptAPO
 Asynchronous Partial Overlay {{Citation

last1 = Mailler | first1 = Roger

last2 = Lesser | first2 = Victor

contribution = Solving Distributed Constraint Optimization Problems Using Cooperative Mediation

title = Proceedings of the Third International Joint Conference on Autonomous Agents and Multiagent Systems

pages = 438–445



Adopt
 Asynchronous BacktrackingThe originally published version of Adopt was uninformed, see {{Citation

last1 = Modi | first1 = Pragnesh Jay

last2 = Shen | first2 = Wei-Min

last3 = Tambe | first3 = Milind

last4 = Yokoo | first4 = Makoto

contribution = An asynchronous complete method for distributed constraint optimization



Secure Multiparty Computation For Solving DisCSPs
 (MPC-DisCSP1-MPC-DisCSP4)

2003



Note: secure if 1/2 of the participants are trustworthy




Secure Computation with Semi-Trusted Servers

2002



Note: security increases with the number of trustworthy servers




ABTR
 Asynchronous Backtracking with Reordering

2001



Note: eordering in ABT with bounded nogoods




DMAC
 Maintaining Asynchronously Consistencies

2001



Note: the fastest algorithm




AAS
 Asynchronous Aggregation Search

2000



aggregation of values in ABT




DFC
 Distributed Forward Chaining

2000



Note: low, comparable to ABT




DBA
 Distributed Breakout Algorithm

1995



Note: incomplete but fast

FRODO version 1



AWC
 Asynchronous Weak-Commitment

1994



Note: reordering, fast, complete (only with exponential space)




ABT
 Asynchronous Backtracking

1992



Note: static ordering, complete




CFL
 Co-ordination-Free Learning {{Citation

last1 = Duffy | first1 = K.R.

last2 = Leith | first2 = D.J.

contribution = Decentralized Constraint Satisfaction

title = IEEE/ACM Transactions on Networking, 21(4)

pages = 1298-1308





Hybrids of these DCOP algorithms also exist. BnB-Adopt,4 for example, changes the search strategy of Adopt from best-first search to depth-first branch-and-bound search.
See also

Constraint satisfaction problem

Notes and references


Books and surveys


A chapter in an edited book.






See Chapters 1 and 2; downloadable free online.





Yokoo, M., and Hirayama, K. (2000). Algorithms for distributed constraint satisfaction: A review. Proceedings of the International Joint Conference on Autonomous Agents and Multiagent Systems (pp. 185–207). A survey.

"
Category:Mathematical optimization Category:Constraint programming



"
 
 
 
 " denotes the power set of 
 
 

"
 
 
 
 " and "
 
 
 
 " denote the Cartesian product.






