   Distributed constraint optimization      Distributed constraint optimization   Distributed constraint optimization ( DCOP or DisCOP ) is the distributed analogue to constraint optimization . A DCOP is a problem in which a group of agents must distributedly choose values for a set of variables such that the cost of a set of constraints over the variables is either minimized or maximized.  Distributed Constraint Satisfaction is a framework for describing a problem in terms of constraints that are known and enforced by distinct participants (agents). The constraints are described on some variables with predefined domains, and have to be assigned to the same values by the different agents.  Problems defined with this framework can be solved by any of the algorithms that are proposed for it.  The framework was used under different names in the 1980s. The first known usage with the current name is in 1990.  Definitions  DCOP  A DCOP can be defined as a tuple     ‚ü®  A  ,  V  ,  ùîá  ,  f  ,  Œ±  ,  Œ∑  ‚ü©     A  V  ùîá  f  Œ±  Œ∑    \langle A,V,\mathfrak{D},f,\alpha,\eta\rangle   , where:      A   A   A   is a set of agents ;     V   V   V   is a set of variables,    {   v  1   ,   v  2   ,  ‚ãØ  ,   v   |  V  |    }      subscript  v  1    subscript  v  2   normal-‚ãØ   subscript  v    V      \{v_{1},v_{2},\cdots,v_{|V|}\}   ;     ùîá   ùîá   \mathfrak{D}   is a set of domains,    {   D  1   ,   D  2   ,  ‚Ä¶  ,   D   |  V  |    }      subscript  D  1    subscript  D  2   normal-‚Ä¶   subscript  D    V      \{D_{1},D_{2},\ldots,D_{|V|}\}   , where each    D  ‚àà  ùîá      D  ùîá    D\in\mathfrak{D}   is a finite set containing the values to which its associated variable may be assigned;     f   f   f   is a function 1 2       f  :     ‚ãÉ   S  ‚àà   ùîì   (  V  )       ‚àë   v  i     ‚àà   S   (    {   v  i   }   √ó   D  i    )    ‚Üí   ‚Ñï  ‚à™   {  ‚àû  }        normal-:  f        subscript     S    ùîì  V        subscript  v  i       S      subscript  v  i     subscript  D  i       normal-‚Üí      ‚Ñï          f:\bigcup_{S\in\mathfrak{P}(V)}\sum{v_{i}\in S}\left(\{v_{i}\}\times D_{i}%
 \right)\rightarrow\mathbb{N}\cup\{\infty\}      that maps every possible variable assignment to a cost. This function can also be thought of as defining constraints between variables however the variables must not be Hermitian;     Œ±   Œ±   \alpha   is a function    Œ±  :   V  ‚Üí  A      normal-:  Œ±   normal-‚Üí  V  A     \alpha:V\rightarrow A   mapping variables to their associated agent.     Œ±   (   v  i   )    ‚Ü¶   a  j      maps-to    Œ±   subscript  v  i     subscript  a  j     \alpha(v_{i})\mapsto a_{j}   implies that it is agent    a  j     subscript  a  j    a_{j}   's responsibility to assign the value of variable    v  i     subscript  v  i    v_{i}   . Note that it is not necessarily true that   Œ±   Œ±   \alpha   is either an injection or surjection ; and     Œ∑   Œ∑   \eta   is an operator that aggregates all of the individual   f   f   f   costs for all possible variable assignments. This is usually accomplished through summation:       Œ∑   (  f  )    ‚Ü¶    ‚àë   s  ‚àà     ‚ãÉ   S  ‚àà   ùîì   (  V  )         ‚àë   v  i      ‚àà   S   (    {   v  i   }   √ó   D  i    )       f   (  s  )        maps-to    Œ∑  f     subscript       s    subscript     S    ùîì  V        subscript  v  i            S      subscript  v  i     subscript  D  i          f  s      \eta(f)\mapsto\sum_{s\in\bigcup_{S\in\mathfrak{P}(V)}\sum{v_{i}\in S}\left(\{v%
 _{i}\}\times D_{i}\right)}f(s)   .    The objective of a DCOP is to have each agent assign values to its associated variables in order to either minimize or maximize    Œ∑   (  f  )       Œ∑  f    \eta(f)   for a given assignment of the variables.  Context  A Context is a variable assignment for a DCOP. This can be thought of as a function mapping variables in the DCOP to their current values:       t  :  V  ‚Üí   (  D  ‚àà  ùîá  )   ‚à™   {  ‚àÖ  }   .     fragments  t  normal-:  V  normal-‚Üí   fragments  normal-(  D   D  normal-)     fragments  normal-{   normal-}   normal-.    t:V\rightarrow(D\in\mathfrak{D})\cup\{\emptyset\}.      Note that a context is essentially a partial solution and need not contain values for every variable in the problem; therefore,     t   (   v  i   )    ‚Ü¶  ‚àÖ     maps-to    t   subscript  v  i       t(v_{i})\mapsto\emptyset   implies that the agent    Œ±   (   v  i   )       Œ±   subscript  v  i     \alpha(v_{i})   has not yet assigned a value to variable    v  i     subscript  v  i    v_{i}   . Given this representation, the " domain " ( i.e. , the set of input values) of the function f can be thought of as the set of all possible contexts for the DCOP. Therefore, in the remainder of this article we may use the notion of a context ( i.e. , the   t   t   t   function) as an input to the   f   f   f   function.  Example problems  Distributed graph coloring  The graph coloring problem is as follows: given a graph     G  =   ‚ü®  N  ,  E  ‚ü©       G   N  E     G=\langle N,E\rangle   and a set of colors   C   C   C   , assign each vertex ,    n  ‚àà  N      n  N    n\in N   , a color,    c  ‚àà  C      c  C    c\in C   , such that the number of adjacent vertices with the same color is minimized.  As a DCOP, there is one agent per vertex that is assigned to decide the associated color. Each agent has a single variable whose associated domain is of cardinality     |  C  |      C    |C|   (there is one domain value for each possible color). For each vertex     n  i   ‚àà  N       subscript  n  i   N    n_{i}\in N   , create a variable in the DCOP     v  i   ‚àà  V       subscript  v  i   V    v_{i}\in V   with domain     D  i   =  C       subscript  D  i   C    D_{i}=C   . For each pair of adjacent vertices     ‚ü®   n  i   ,   n  j   ‚ü©   ‚àà  E        subscript  n  i    subscript  n  j    E    \langle n_{i},n_{j}\rangle\in E   , create a constraint of cost 1 if both of the associated variables are assigned the same color:        (     ‚àÄ  c   ‚àà  C   :    f   (   ‚ü®   v  i   ,  c  ‚ü©   ,   ‚ü®   v  j   ,  c  ‚ü©   )    ‚Ü¶  1    )   .     normal-:     for-all  c   C    maps-to    f     subscript  v  i   c     subscript  v  j   c     1     (\forall c\in C:f(\langle v_{i},c\rangle,\langle v_{j},c\rangle)\mapsto 1).      The objective, then, is to minimize    Œ∑   (  f  )       Œ∑  f    \eta(f)   .  Distributed multiple knapsack problem  The distributed multiple- variant of the knapsack problem is as follows: given a set of items of varying volume and a set of knapsacks of varying capacity, assign each item to a knapsack such that the amount of overflow is minimized. Let   I   I   I   be the set of items,   K   K   K   be the set of knapsacks,    s  :   I  ‚Üê  ‚Ñï      normal-:  s   normal-‚Üê  I  ‚Ñï     s:I\leftarrow\mathbb{N}   be a function mapping items to their volume, and    c  :   K  ‚Üê  ‚Ñï      normal-:  c   normal-‚Üê  K  ‚Ñï     c:K\leftarrow\mathbb{N}   be a function mapping knapsacks to their capacities.  To encode this problem as a DCOP, for each    i  ‚àà  I      i  I    i\in I   create one variable     v  i   ‚àà  V       subscript  v  i   V    v_{i}\in V   with associated domain     D  i   =  K       subscript  D  i   K    D_{i}=K   . Then for all possible context   t   t   t   :        f   (  t  )    ‚Ü¶    ‚àë   k  ‚àà  K     {     0       r   (  t  ,  k  )    ‚â§   c   (  k  )     ,         r   (  t  ,  k  )    -   c   (  k  )        otherwise  ,           maps-to    f  t     subscript     k  K     cases  0      r   t  k      c  k        r   t  k      c  k    otherwise      f(t)\mapsto\sum_{k\in K}\begin{cases}0&r(t,k)\leq c(k),\\
 r(t,k)-c(k)&\text{otherwise},\end{cases}      where    r   (  t  ,  k  )       r   t  k     r(t,k)   is a function such that         r   (  t  ,  k  )    =    ‚àë    v  i   ‚àà    t   -  1     (  k  )       s   (  i  )      .        r   t  k      subscript      subscript  v  i      superscript  t    1    k       s  i      r(t,k)=\sum_{v_{i}\in t^{-1}(k)}s(i).      Algorithms  DCOP algorithms can be classified according to the search strategy (best-first search or depth-first branch-and-bound search), the synchronization among agents (synchronous or asynchronous), the communication among agents (point-to-point with neighbors in the constraint graph or broadcast) and the main communication topology (chain or tree). 3 ADOPT, for example, uses best-first search, asynchronous synchronization, point-to-point communication between neighboring agents in the constraint graph and a constraint tree as main communication topology.      Algorithm Name   Year Introduced   Memory Complexity   Number of Messages   Correctness (computer science) /  Completeness (logic)   Implementations       NCBB No-Commitment Branch and Bound {{Citation   last1 = Chechetka | first1 = Anton   last2 = Sycara | first2 = Katia   contribution = No-Commitment Branch and Bound Search for Distributed Constraint Optimization   title = Proceedings of the Fifth International Joint Conference on Autonomous Agents and Multiagent Systems   date = May 2006     DPOP Distributed Pseudotree Optimization Procedure {{Citation   last1 = Petcu | first1 = Adrian   last2 = Faltings | first2 = Boi   contribution = DPOP: A Scalable Method for Multiagent Constraint Optimization   title = Proceedings of the 19th International Joint Conference on Artificial Intelligence, IJCAI 2005, Edinburgh, Scotland, pp. 266-271   date = August 2005     OptAPO Asynchronous Partial Overlay {{Citation   last1 = Mailler | first1 = Roger   last2 = Lesser | first2 = Victor   contribution = Solving Distributed Constraint Optimization Problems Using Cooperative Mediation   title = Proceedings of the Third International Joint Conference on Autonomous Agents and Multiagent Systems   pages = 438‚Äì445     Adopt Asynchronous Backtracking The originally published version of Adopt was uninformed, see {{Citation   last1 = Modi | first1 = Pragnesh Jay   last2 = Shen | first2 = Wei-Min   last3 = Tambe | first3 = Milind   last4 = Yokoo | first4 = Makoto   contribution = An asynchronous complete method for distributed constraint optimization     Secure Multiparty Computation For Solving DisCSPs (MPC-DisCSP1-MPC-DisCSP4)   2003     Note: secure if 1/2 of the participants are trustworthy      Secure Computation with Semi-Trusted Servers   2002     Note: security increases with the number of trustworthy servers      ABTR Asynchronous Backtracking with Reordering   2001     Note: eordering in ABT with bounded nogoods      DMAC Maintaining Asynchronously Consistencies   2001     Note: the fastest algorithm      AAS Asynchronous Aggregation Search   2000     aggregation of values in ABT      DFC Distributed Forward Chaining   2000     Note: low, comparable to ABT      DBA Distributed Breakout Algorithm   1995     Note: incomplete but fast   FRODO version 1     AWC Asynchronous Weak-Commitment   1994     Note: reordering, fast, complete (only with exponential space)      ABT Asynchronous Backtracking   1992     Note: static ordering, complete      CFL Co-ordination-Free Learning {{Citation   last1 = Duffy | first1 = K.R.   last2 = Leith | first2 = D.J.   contribution = Decentralized Constraint Satisfaction   title = IEEE/ACM Transactions on Networking, 21(4)   pages = 1298-1308       Hybrids of these DCOP algorithms also exist. BnB-Adopt, 4 for example, changes the search strategy of Adopt from best-first search to depth-first branch-and-bound search.  See also   Constraint satisfaction problem   Notes and references    Books and surveys    A chapter in an edited book.        See Chapters 1 and 2; downloadable free online .       Yokoo, M., and Hirayama, K. (2000). Algorithms for distributed constraint satisfaction: A review. Proceedings of the International Joint Conference on Autonomous Agents and Multiagent Systems (pp.¬†185‚Äì207). A survey.   "  Category:Mathematical optimization  Category:Constraint programming     "    ùîì   (  ùîô  )       ùîì  ùîô    \mathfrak{P}(\mathfrak{V})   " denotes the power set of   V   V   V    ‚Ü©  "   √ó     \times   " and "   ‚àë     \sum   " denote the Cartesian product . ‚Ü©  ‚Ü©      