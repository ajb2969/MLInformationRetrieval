   Friedman test      Friedman test   The Friedman test is a non-parametric  statistical test developed by the U.S. economist Milton Friedman . Similar to the parametric  repeated measures  ANOVA , it is used to detect differences in treatments across multiple test attempts. The procedure involves ranking each row (or block ) together, then considering the values of ranks by columns. Applicable to complete block designs , it is thus a special case of the Durbin test .  Classic examples of use are:   n wine judges each rate k different wines. Are any wines ranked consistently higher or lower than the others?  n wines are each rated by k different judges. Are the judges' ratings consistent with each other?  n welders each use k welding torches, and the ensuing welds were rated on quality. Do any of the torches produce consistently better or worse welds?   The Friedman test is used for one-way repeated measures analysis of variance by ranks. In its use of ranks it is similar to the Kruskal‚ÄìWallis one-way analysis of variance by ranks.  Friedman test is widely supported by many statistical software packages .  Method   Given data     {   x   i  j    }    n  √ó  k      subscript    subscript  x    i  j       n  k     \{x_{ij}\}_{n\times k}   , that is, a matrix with   n   n   n   rows (the blocks ),   k   k   k   columns (the treatments ) and a single observation at the intersection of each block and treatment, calculate the ranks  within each block. If there are tied values, assign to each tied value the average of the ranks that would have been assigned without ties. Replace the data with a new matrix     {   r   i  j    }    n  √ó  k      subscript    subscript  r    i  j       n  k     \{r_{ij}\}_{n\times k}   where the entry    r   i  j      subscript  r    i  j     r_{ij}   is the rank of    x   i  j      subscript  x    i  j     x_{ij}   within block   i   i   i   .  Find the values:        r  ¬Ø     ‚ãÖ  j    =    1  n     ‚àë   i  =  1   n    r   i  j           subscript   normal-¬Ø  r    normal-‚ãÖ  absent  j        1  n     superscript   subscript     i  1    n    subscript  r    i  j        \bar{r}_{\cdot j}=\frac{1}{n}\sum_{i=1}^{n}{r_{ij}}          r  ¬Ø   =    1   n  k      ‚àë   i  =  1   n     ‚àë   j  =  1   k    r   i  j            normal-¬Ø  r       1    n  k      superscript   subscript     i  1    n     superscript   subscript     j  1    k    subscript  r    i  j         \bar{r}=\frac{1}{nk}\sum_{i=1}^{n}\sum_{j=1}^{k}r_{ij}          S   S  t    =   n    ‚àë   j  =  1   k     (     r  ¬Ø     ‚ãÖ  j    -   r  ¬Ø    )   2           S   subscript  S  t      n    superscript   subscript     j  1    k    superscript     subscript   normal-¬Ø  r    normal-‚ãÖ  absent  j     normal-¬Ø  r    2       SS_{t}=n\sum_{j=1}^{k}(\bar{r}_{\cdot j}-\bar{r})^{2}   ,       S   S  e    =    1   n   (   k  -  1   )       ‚àë   i  =  1   n     ‚àë   j  =  1   k     (    r   i  j    -   r  ¬Ø    )   2            S   subscript  S  e        1    n    k  1       superscript   subscript     i  1    n     superscript   subscript     j  1    k    superscript     subscript  r    i  j     normal-¬Ø  r    2        SS_{e}=\frac{1}{n(k-1)}\sum_{i=1}^{n}\sum_{j=1}^{k}(r_{ij}-\bar{r})^{2}      The test statistic is given by    Q  =    S   S  t     S   S  e         Q      S   subscript  S  t      S   subscript  S  e       Q=\frac{SS_{t}}{SS_{e}}   . Note that the value of Q as computed above does not need to be adjusted for tied values in the data.  Finally, when n or k is large (i.e. n > 15 or k > 4), the probability distribution of Q can be approximated by that of a chi-squared distribution . In this case the p-value is given by    ùêè   (   œá   k  -  1   2   ‚â•  Q  )      fragments  P   fragments  normal-(   subscript   superscript  œá  2     k  1     Q  normal-)     \mathbf{P}(\chi^{2}_{k-1}\geq Q)   . If n or k is small, the approximation to chi-square becomes poor and the p-value should be obtained from tables of Q specially prepared for the Friedman test. If the p-value is significant , appropriate post-hoc multiple comparisons tests would be performed.   Related tests   When using this kind of design for a binary response, one instead uses the Cochran's Q test .  Kendall's W is a normalization of the Friedman statistic between 0 and 1.  The Wilcoxon signed-rank test is a nonparametric test of nonindependent data from only two groups.  The Skillings‚ÄìMack test is a general Friedman-type statistic that can be used in almost any block design with an arbitrary missing-data structure   Post hoc analysis  Post-hoc tests were proposed by Schaich and Hamerle (1984) 1 as well as Conover (1971, 1980) 2 in order to decide which groups are significantly different from each other, based upon the mean rank differences of the groups. These procedures are detailed in Bortz, Lienert and Boehnke (2000, pp.¬†275). 3  Not all statistical packages support Post-hoc analysis for Friedman's test, but user-contributed code exists that provides these facilities (for example in SPSS 1 , and in R 2 )  References    Primary sources       Secondary sources   Kendall, M. G. Rank Correlation Methods. (1970, 4th ed.) London: Charles Griffin.  Hollander, M., and Wolfe, D. A. Nonparametric Statistics. (1973). New York: J. Wiley.  Siegel, Sidney, and Castellan, N. John Jr. Nonparametric Statistics for the Behavioral Sciences. (1988, 2nd ed.) New York: McGraw-Hill.   External links   Post-hoc comparisons for Friedman test in SPSS  Post hoc analysis for Friedman‚Äôs Test in R   "  Category:Statistical tests  Category:Milton Friedman  Category:Non-parametric statistics     Schaich, E. & Hamerle, A. (1984). Verteilungsfreie statistische Pr√ºfverfahren. Berlin: Springer. ISBN 3-540-13776-9. ‚Ü©  Conover, W. J. (1971, 1980). Practical nonparametric statistics. New York: Wiley. ISBN 0-471-16851-3. ‚Ü©  Bortz, J., Lienert, G. & Boehnke, K. (2000). Verteilungsfreie Methoden in der Biostatistik. Berlin: Springer. ISBN 3-540-67590-6. ‚Ü©     