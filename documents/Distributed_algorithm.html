<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="239">Distributed algorithm</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>Distributed algorithm</h1>
<hr/>

<p>A <strong>distributed algorithm</strong> is an <a class="uri" href="algorithm" title="wikilink">algorithm</a> designed to run on <a href="computer_hardware" title="wikilink">computer hardware</a> constructed from interconnected <a href="Central_processing_unit" title="wikilink">processors</a>. Distributed algorithms are used in many varied application areas of <a href="distributed_computing" title="wikilink">distributed computing</a>, such as <a class="uri" href="telecommunications" title="wikilink">telecommunications</a>, <a href="scientific_computing" title="wikilink">scientific computing</a>, distributed <a href="information_processing" title="wikilink">information processing</a>, and real-time <a href="process_control" title="wikilink">process control</a>. Standard problems solved by distributed algorithms include <a href="leader_election" title="wikilink">leader election</a>, <a href="Consensus_(computer_science)" title="wikilink">consensus</a>, distributed <a href="Search_algorithm" title="wikilink">search</a>, <a href="Spanning_tree_(mathematics)" title="wikilink">spanning tree</a> generation, <a href="mutual_exclusion" title="wikilink">mutual exclusion</a>, and <a href="resource_allocation" title="wikilink">resource allocation</a>.<a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a></p>

<p>Distributed algorithms are a sub-type of <a href="parallel_algorithm" title="wikilink">parallel algorithm</a>, typically executed <a href="concurrency_(computer_science)" title="wikilink">concurrently</a>, with separate parts of the algorithm being run simultaneously on independent processors, and having limited information about what the other parts of the algorithm are doing. One of the major challenges in developing and implementing distributed algorithms is successfully coordinating the behavior of the independent parts of the algorithm in the face of processor failures and unreliable communications links. The choice of an appropriate distributed algorithm to solve a given problem depends on both the characteristics of the problem, and characteristics of the system the algorithm will run on such as the type and probability of processor or link failures, the kind of inter-process communication that can be performed, and the level of timing synchronization between separate processes.<a class="footnoteRef" href="#fn2" id="fnref2"><sup>2</sup></a></p>
<h2 id="standard-problems">Standard problems</h2>
<dl>
<dt><a href="Atomic_commit" title="wikilink">Atomic commit</a></dt>
<dd>An atomic commit is an operation where a set of distinct changes is applied as a single operation. If the atomic commit succeeds, it means that all the changes have been applied. If there is a failure before the atomic commit can be completed, the "commit" is aborted and no changes will be applied.
</dd>
<dd>Algorithms for solving the atomic commit protocol include the <a href="two-phase_commit_protocol" title="wikilink">two-phase commit protocol</a> and the <a href="three-phase_commit_protocol" title="wikilink">three-phase commit protocol</a>.
</dd>
</dl>
<dl>
<dt><a href="Consensus_(computer_science)" title="wikilink">Consensus</a></dt>
<dd>Consensus algorithms try to solve the problem of a number of processes agreeing on a common decision.
</dd>
<dd>More precisely, a Consensus protocol must satisfy the four formal properties below.
</dd>
</dl>

<p>:* <strong>Termination</strong>: every correct process decides some value.</p>

<p>:* <strong>Validity</strong>: if all processes propose the same value 

<math display="inline" id="Distributed_algorithm:0">
 <semantics>
  <mi>v</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>v</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   v
  </annotation>
 </semantics>
</math>

, then every correct process decides 

<math display="inline" id="Distributed_algorithm:1">
 <semantics>
  <mi>v</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>v</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   v
  </annotation>
 </semantics>
</math>

.</p>

<p>:* <strong>Integrity</strong>: every correct process decides at most one value, and if it decides some value 

<math display="inline" id="Distributed_algorithm:2">
 <semantics>
  <mi>v</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>v</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   v
  </annotation>
 </semantics>
</math>

, then 

<math display="inline" id="Distributed_algorithm:3">
 <semantics>
  <mi>v</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>v</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   v
  </annotation>
 </semantics>
</math>

 must have been proposed by some process.</p>

<p>:* <strong>Agreement</strong>: if a correct process decides 

<math display="inline" id="Distributed_algorithm:4">
 <semantics>
  <mi>v</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>v</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   v
  </annotation>
 </semantics>
</math>

, then every correct process decides 

<math display="inline" id="Distributed_algorithm:5">
 <semantics>
  <mi>v</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>v</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   v
  </annotation>
 </semantics>
</math>

.</p>
<dl>
<dd>A typical algorithm for solving consensus is the <a href="paxos_algorithm" title="wikilink">paxos algorithm</a>.
</dd>
</dl>
<dl>
<dt>Distributed search</dt>
</dl>
<dl>
<dt><a href="Leader_election" title="wikilink">Leader election</a></dt>
</dl>
<dl>
<dd>Leader election is the process of designating a single process as the organizer of some task distributed among several computers (nodes). Before the task is begun, all network nodes are unaware which node will serve as the "leader," or coordinator, of the task. After a leader election algorithm has been run, however, each node throughout the network recognizes a particular, unique node as the task leader.
</dd>
</dl>
<dl>
<dt><a href="Mutual_exclusion" title="wikilink">Mutual exclusion</a></dt>
</dl>
<dl>
<dt><a href="Non-blocking_data_structures" title="wikilink">Non-blocking data structures</a></dt>
</dl>
<dl>
<dt>Reliable Broadcast</dt>
</dl>
<dl>
<dd>Reliable broadcast is a communication primitive in distributed systems. A reliable broadcast is defined by the following properties:
</dd>
</dl>

<p>:* <strong>Validity</strong> - if a correct process sends a message, then some correct process will eventually deliver that message</p>

<p>:* <strong>Agreement</strong> - if a correct process delivers a message, then all correct processes eventually deliver that message</p>

<p>:* <strong>Integrity</strong> - every correct process delivers the same message at most once and only if that message has been sent by a process</p>
<dl>
<dd>A reliable broadcast can have sequential, causal or total ordering.
</dd>
</dl>
<dl>
<dt><a href="Replication_(computer_science)" title="wikilink">Replication</a><br/>
<a href="Resource_allocation" title="wikilink">Resource allocation</a><br/>
<a href="Spanning_tree" title="wikilink">Spanning tree</a> generation<br/>
Symmetry breaking, e.g. <a href="vertex_coloring" title="wikilink">vertex coloring</a></dt>
</dl>
<h2 id="references">References</h2>
<h2 id="further-reading">Further reading</h2>
<ul>
<li>C. Rodríguez, M. Villagra and B. Barán, , Bionetics2007, pp. 66–69, 2007.</li>
</ul>
<h2 id="external-links">External links</h2>
<ul>
<li><a href="http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-852j-distributed-algorithms-fall-2009/">MIT Open Courseware - Distributed Algorithms</a></li>
</ul>

<p>"</p>

<p><a href="Category:Distributed_algorithms" title="wikilink"> </a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1"><a href="#fnref1">↩</a></li>
<li id="fn2"></li>
</ol>
</section>
</body>
</html>
