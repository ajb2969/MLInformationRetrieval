<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="1669">Noncentral hypergeometric distributions</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>Noncentral hypergeometric distributions</h1>
<hr/>

<p>In <a class="uri" href="statistics" title="wikilink">statistics</a>, the <a href="hypergeometric_distribution" title="wikilink">hypergeometric distribution</a> is the discrete <a href="probability_distribution" title="wikilink">probability distribution</a> generated by picking colored balls at random from an <a href="urn_problem" title="wikilink">urn</a> without replacement.</p>

<p>Various generalizations to this distribution exist for cases where the picking of colored balls is <a href="bias_(statistics)" title="wikilink">biased</a> so that balls of one color are more likely to be picked than balls of another color.</p>

<p>This can be illustrated by the following example. Assume that an <a href="opinion_poll" title="wikilink">opinion poll</a> is conducted by calling random telephone numbers. Unemployed people are more likely to be home and answer the phone than employed people are. Therefore, unemployed respondents are likely to be over-represented in the <a href="sample_(statistics)" title="wikilink">sample</a>. The <a href="probability_distribution" title="wikilink">probability distribution</a> of employed versus unemployed respondents in a sample of <em>n</em> respondents can be described as a noncentral hypergeometric distribution.</p>

<p>The description of <a href="bias_(statistics)" title="wikilink">biased</a> <a href="urn_problem" title="wikilink">urn models</a> is complicated by the fact that there is <em>more than one noncentral hypergeometric distribution</em>. Which distribution you get depends on whether items (e.g. colored balls) are sampled one by one in a manner where there is competition between the items, or they are sampled independently of each other.</p>

<p>There is widespread confusion about this fact. The name <em>noncentral hypergeometric distribution</em> has been used for two different distributions, and several scientists have used the wrong distribution or erroneously believed that the two distributions were identical.</p>

<p>The use of the same name for two different distributions has been possible because these two distributions were studied by two different groups of scientists with hardly any contact with each other.</p>

<p>Agner Fog (2007, 2008) has suggested that the best way to avoid confusion is to use the name <a href="Wallenius'_noncentral_hypergeometric_distribution" title="wikilink">Wallenius' noncentral hypergeometric distribution</a> for the distribution of a biased urn model where a predetermined number of items are drawn one by one in a competitive manner, while the name <a href="Fisher's_noncentral_hypergeometric_distribution" title="wikilink">Fisher's noncentral hypergeometric distribution</a> is used where items are drawn independently of each other, so that the total number of items drawn is known only after the experiment. The names refer to Kenneth Ted Wallenius and <a href="Ronald_Fisher" title="wikilink">R. A. Fisher</a> who were the first to describe the respective distributions.</p>

<p><a href="Fisher's_noncentral_hypergeometric_distribution" title="wikilink">Fisher's noncentral hypergeometric distribution</a> has previously been given the name <em>extended hypergeometric distribution</em>, but this name is rarely used in the scientific literature, except in handbooks that need to distinguish between the two distributions. Some scientists are strongly opposed to using this name.</p>

<p>A thorough explanation of the difference between the two noncentral hypergeometric distributions is obviously needed here.</p>
<h2 id="wallenius-noncentral-hypergeometric-distribution">Wallenius' noncentral hypergeometric distribution</h2>

<p>Wallenius' distribution can be explained as follows. Assume that an <a href="urn_problem" title="wikilink">urn</a> contains 

<math display="inline" id="Noncentral_hypergeometric_distributions:0">
 <semantics>
  <msub>
   <mi>m</mi>
   <mn>1</mn>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>m</ci>
    <cn type="integer">1</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   m_{1}
  </annotation>
 </semantics>
</math>

 red balls and 

<math display="inline" id="Noncentral_hypergeometric_distributions:1">
 <semantics>
  <msub>
   <mi>m</mi>
   <mn>2</mn>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>m</ci>
    <cn type="integer">2</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   m_{2}
  </annotation>
 </semantics>
</math>

 white balls, totalling 

<math display="inline" id="Noncentral_hypergeometric_distributions:2">
 <semantics>
  <mrow>
   <mi>N</mi>
   <mo>=</mo>
   <mrow>
    <msub>
     <mi>m</mi>
     <mn>1</mn>
    </msub>
    <mo>+</mo>
    <msub>
     <mi>m</mi>
     <mn>2</mn>
    </msub>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <ci>N</ci>
    <apply>
     <plus></plus>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>m</ci>
      <cn type="integer">1</cn>
     </apply>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>m</ci>
      <cn type="integer">2</cn>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   N=m_{1}+m_{2}
  </annotation>
 </semantics>
</math>

 balls. 

<math display="inline" id="Noncentral_hypergeometric_distributions:3">
 <semantics>
  <mi>n</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>n</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   n
  </annotation>
 </semantics>
</math>

 balls are drawn at random from the urn one by one without replacement. Each red ball has the weight 

<math display="inline" id="Noncentral_hypergeometric_distributions:4">
 <semantics>
  <msub>
   <mi>ω</mi>
   <mn>1</mn>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>ω</ci>
    <cn type="integer">1</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \omega_{1}
  </annotation>
 </semantics>
</math>

, and each white ball has the weight 

<math display="inline" id="Noncentral_hypergeometric_distributions:5">
 <semantics>
  <msub>
   <mi>ω</mi>
   <mn>2</mn>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>ω</ci>
    <cn type="integer">2</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \omega_{2}
  </annotation>
 </semantics>
</math>

. We assume that the probability of taking a particular ball is proportional to its weight. The physical property that determines the <a class="uri" href="odds" title="wikilink">odds</a> may be something else than weight, such as size or slipperiness or some other factor, but it is convenient to use the word <em>weight</em> for the odds parameter.</p>

<p>The probability that the first ball picked is red is equal to the weight fraction of red balls:</p>

<p>

<math display="block" id="Noncentral_hypergeometric_distributions:6">
 <semantics>
  <mrow>
   <mrow>
    <msub>
     <mi>p</mi>
     <mn>1</mn>
    </msub>
    <mo>=</mo>
    <mfrac>
     <mrow>
      <msub>
       <mi>m</mi>
       <mn>1</mn>
      </msub>
      <msub>
       <mi>ω</mi>
       <mn>1</mn>
      </msub>
     </mrow>
     <mrow>
      <mrow>
       <msub>
        <mi>m</mi>
        <mn>1</mn>
       </msub>
       <msub>
        <mi>ω</mi>
        <mn>1</mn>
       </msub>
      </mrow>
      <mo>+</mo>
      <mrow>
       <msub>
        <mi>m</mi>
        <mn>2</mn>
       </msub>
       <msub>
        <mi>ω</mi>
        <mn>2</mn>
       </msub>
      </mrow>
     </mrow>
    </mfrac>
   </mrow>
   <mo>.</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>p</ci>
     <cn type="integer">1</cn>
    </apply>
    <apply>
     <divide></divide>
     <apply>
      <times></times>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>m</ci>
       <cn type="integer">1</cn>
      </apply>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>ω</ci>
       <cn type="integer">1</cn>
      </apply>
     </apply>
     <apply>
      <plus></plus>
      <apply>
       <times></times>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <ci>m</ci>
        <cn type="integer">1</cn>
       </apply>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <ci>ω</ci>
        <cn type="integer">1</cn>
       </apply>
      </apply>
      <apply>
       <times></times>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <ci>m</ci>
        <cn type="integer">2</cn>
       </apply>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <ci>ω</ci>
        <cn type="integer">2</cn>
       </apply>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   p_{1}=\frac{m_{1}\omega_{1}}{m_{1}\omega_{1}+m_{2}\omega_{2}}.
  </annotation>
 </semantics>
</math>

 The probability that the second ball picked is red depends on whether the first ball was red or white. If the first ball was red then the above formula is used with 

<math display="inline" id="Noncentral_hypergeometric_distributions:7">
 <semantics>
  <msub>
   <mi>m</mi>
   <mn>1</mn>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>m</ci>
    <cn type="integer">1</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   m_{1}
  </annotation>
 </semantics>
</math>

 reduced by one. If the first ball was white then the above formula is used with 

<math display="inline" id="Noncentral_hypergeometric_distributions:8">
 <semantics>
  <msub>
   <mi>m</mi>
   <mn>2</mn>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>m</ci>
    <cn type="integer">2</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   m_{2}
  </annotation>
 </semantics>
</math>

 reduced by one.</p>

<p>The important fact that distinguishes Wallenius' distribution is that there is <a class="uri" href="competition" title="wikilink">competition</a> between the balls. The probability that a particular ball is taken in a particular draw depends not only on its own weight, but also on the total weight of the competing balls that remain in the urn at that moment. And the weight of the competing balls depends on the outcomes of all preceding draws.</p>

<p>A multivariate version of Wallenius' distribution is used if there are more than two different colors.</p>

<p>The distribution of the balls that are not drawn is a <a href="Wallenius'_noncentral_hypergeometric_distribution#Complementary_Wallenius.27_noncentral_hypergeometric_distribution" title="wikilink"> complementary Wallenius' noncentral hypergeometric distribution</a>.</p>
<h2 id="fishers-noncentral-hypergeometric-distribution">Fisher's noncentral hypergeometric distribution</h2>

<p>In the Fisher model, the fates of the balls are independent and there is no dependence between draws. We may as well take all <em>n</em> balls at the same time. Each ball has no "knowledge" of what happens to the other balls. For the same reason, it is impossible to know the value of <em>n</em> before the experiment. If we tried to fix the value of <em>n</em> then we would have no way of preventing ball number <em>n</em>+1 from being taken without violating the principle of independence between balls. <em>n</em> is therefore a random variable, and the Fisher distribution is a conditional distribution which can only be determined after the experiment when <em>n</em> is observed. The unconditional distribution is two independent <a href="binomial_distribution" title="wikilink">binomials</a>, one for each color.</p>

<p>Fisher's distribution can simply be defined as the <a href="Conditional_probability_distribution" title="wikilink">conditional distribution</a> of two or more independent binomial variates dependent upon their sum. A multivariate version of the Fisher's distribution is used if there are more than two colors of balls.</p>
<h2 id="the-difference-between-the-two-noncentral-hypergeometric-distributions">The difference between the two noncentral hypergeometric distributions</h2>

<p> <br/>
Wallenius’ and Fisher’s distributions are approximately equal when the odds ratio 

<math display="inline" id="Noncentral_hypergeometric_distributions:9">
 <semantics>
  <mrow>
   <mi>ω</mi>
   <mo>=</mo>
   <mrow>
    <msub>
     <mi>ω</mi>
     <mn>1</mn>
    </msub>
    <mo>/</mo>
    <msub>
     <mi>ω</mi>
     <mn>2</mn>
    </msub>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <ci>ω</ci>
    <apply>
     <divide></divide>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>ω</ci>
      <cn type="integer">1</cn>
     </apply>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>ω</ci>
      <cn type="integer">2</cn>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \omega=\omega_{1}/\omega_{2}
  </annotation>
 </semantics>
</math>

 is near 1, and <em>n</em> is low compared to the total number of balls, <em>N</em>. The difference between the two distributions becomes higher when the odds ratio is far from one and <em>n</em> is near <em>N</em>. The two distributions approximate each other better when they have the same mean than when they have the same odds (w = 1) (see figures above).</p>

<p>Both distributions degenerate into the <a href="hypergeometric_distribution" title="wikilink">hypergeometric distribution</a> when the odds ratio is 1, or to the <a href="binomial_distribution" title="wikilink">binomial distribution</a> when <em>n</em> = 1.</p>

<p>To understand why the two distributions are different, we may consider the following extreme example: An urn contains one red ball with the weight 1000, and a thousand white balls each with the weight 1. We want to calculate the probability that the red ball is <em>not</em> taken.</p>

<p>First we consider the Wallenius model. The probability that the red ball is not taken in the first draw is 1000/2000 = ½. The probability that the red ball is not taken in the second draw, under the condition that it was not taken in the first draw, is 999/1999 ≈ ½. The probability that the red ball is not taken in the third draw, under the condition that it was not taken in the first two draws, is 998/1998 ≈ ½. Continuing in this way, we can calculate that the probability of not taking the red ball in <em>n</em> draws is approximately 2<sup>−n</sup> as long as <em>n</em> is small compared to <em>N</em>. In other words, the probability of not taking a very heavy ball in <em>n</em> draws falls almost exponentially with <em>n</em> in Wallenius’ model. The exponential function arises because the probabilities for each draw are all multiplied together.</p>

<p>This is not the case in Fisher’s model where balls are taken independently, and possibly simultaneously. Here the draws are independent and the probabilities are therefore not multiplied together. The probability of not taking the heavy red ball in Fisher’s model is approximately 1/(<em>n</em>+1). The two distributions are therefore very different in this extreme case, even though they are quite similar in less extreme cases.</p>

<p>The following conditions must be fulfilled for Wallenius’ distribution to be applicable:</p>
<ul>
<li>Items are taken randomly from a finite source containing different kinds of items without replacement.</li>
<li>Items are drawn one by one.</li>
<li>The probability of taking a particular item at a particular draw is equal to its fraction of the total "weight" of all items that have not yet been taken at that moment. The weight of an item depends only on its kind (color).</li>
<li>The total number <em>n</em> of items to take is fixed and independent of which items happen to be taken first.</li>
</ul>

<p>The following conditions must be fulfilled for Fisher’s distribution to be applicable:</p>
<ul>
<li>Items are taken randomly from a finite source containing different kinds of items without replacement.</li>
<li>Items are taken independently of each other. Whether one item is taken is independent of whether another item is taken. Whether one item is taken before, after, or simultaneously with another item is irrelevant.</li>
<li>The probability of taking a particular item is proportional to its "weight". The weight of an item depends only on its kind (color).</li>
<li>The total number <em>n</em> of items that will be taken is not known before the experiment.</li>
<li><em>n</em> is determined after the experiment and the conditional distribution for <em>n</em> known is desired.</li>
</ul>
<h2 id="examples">Examples</h2>

<p>The following examples will further clarify which distribution to use in different situations.</p>
<h3 id="example-1">Example 1</h3>

<p>You are catching fish in a small lake that contains a limited number of fish. There are different kinds of fish with different weights. The probability of catching a particular fish at a particular moment is proportional to its weight.</p>

<p>You are catching the fish one by one with a fishing rod. You have decided to catch <em>n</em> fish. You are determined to catch exactly <em>n</em> fish regardless of how long time it may take. You are stopping after you have caught <em>n</em> fish even if you can see more fish that are tempting you.</p>

<p>This scenario will give a distribution of the types of fish caught that is equal to Wallenius’ noncentral hypergeometric distribution.</p>
<h3 id="example-2">Example 2</h3>

<p>You are catching fish as in example 1, but you are using a big net. You are setting up the net one day and coming back the next day to remove the net. You count how many fish you have caught and then you go home regardless of how many fish you have caught. Each fish has a probability of getting into the net that is proportional to its weight but independent of what happens to the other fish.</p>

<p>The total number of fish that will be caught in this scenario is not known in advance. The expected number of fish caught is therefore described by multiple binomial distributions, one for each kind of fish.</p>

<p>After the fish have been counted, the total number <em>n</em> of fish is known. The probability distribution when <em>n</em> is known (but the number of each type is not known yet) is Fisher’s noncentral hypergeometric distribution.</p>
<h3 id="example-3">Example 3</h3>

<p>You are catching fish with a small net. It is possible that more than one fish can go into the net at the same time. You are using the net multiple times until you have got at least <em>n</em> fish.</p>

<p>This scenario gives a distribution that lies between Wallenius’ and Fisher’s distributions. The total number of fish caught can vary if you are getting too many fish in the last catch. You may put the excess fish back into the lake, but this still doesn’t give Wallenius’ distribution. This is because you are catching multiple fish at the same time. The condition that each catch depends on all previous catches does not hold for fish that are caught simultaneously or in the same operation.</p>

<p>The resulting distribution will be close to Wallenius’ distribution if there are only few fish in the net in each catch and you are catching many times. The resulting distribution will be close to Fisher’s distribution if there are many fish in the net in each catch and you are catching few times.</p>
<h3 id="example-4">Example 4</h3>

<p>You are catching fish with a big net. Fish are swimming into the net randomly in a situation that resembles a <a href="Poisson_process" title="wikilink">Poisson process</a>. You are watching the net all the time and take up the net as soon as you have caught exactly <em>n</em> fish.</p>

<p>The resulting distribution will be close to Fisher’s distribution because the fish swim into the net independently of each other. But the fates of the fish are not totally independent because a particular fish can be saved from getting caught if <em>n</em> other fish happen to get into the net before the time that this particular fish would have been caught. This is more likely to happen if the other fish are heavy than if they are light.</p>
<h3 id="example-5">Example 5</h3>

<p>You are catching fish one by one with a fishing rod as in example 1. You need a particular amount of fish in order to feed your family. You are stopping when the total weight of the fish you have caught exceeds a predetermined limit. The resulting distribution will be close to Wallenius’ distribution, but not exactly because the decision to stop depends on the weight of the fish you have caught so far. <em>n</em> is therefore not known exactly before the fishing trip.</p>
<h3 id="conclusion-to-the-examples">Conclusion to the examples</h3>

<p>These examples show that the distribution of the types of fish you catch depends on the way they are caught. Many situations will give a distribution that lies somewhere between Wallenius’ and Fisher’s noncentral hypergeometric distributions.</p>

<p>An interesting consequence of the difference between these two distributions is that you will get more of the heavy fish, on average, if you catch <em>n</em> fish one by one than if you catch all <em>n</em> at the same time.</p>

<p>These conclusions can of course be applied to biased sampling of other items than fish. In general, we can say that the odds parameter has a stronger effect in Wallenius' distribution than in Fisher's distribution, especially when <em>n</em>/<em>N</em> is high.</p>
<figure><b>(Figure)</b>
<figcaption> Probability mass function for Wallenius' Noncentral Hypergeometric Distribution for different values of the odds ratio ω.<br/>
m1 = 80, m2 = 60, n = 100, ω = 0.1 ... 20</figcaption>
</figure>
<figure><b>(Figure)</b>
<figcaption> Probability mass function for Fisher's Noncentral Hypergeometric Distribution for different values of the odds ratio ω.<br/>
m1 = 80, m2 = 60, n = 100, ω = 0.01 ... 1000</figcaption>
</figure>

<p><br/>
</p>
<h2 id="see-also">See also</h2>
<ul>
<li><a href="Wallenius'_noncentral_hypergeometric_distribution" title="wikilink">Wallenius' noncentral hypergeometric distribution</a></li>
<li><a href="Fisher's_noncentral_hypergeometric_distribution" title="wikilink">Fisher's noncentral hypergeometric distribution</a></li>
<li><a href="hypergeometric_distribution" title="wikilink">hypergeometric distribution</a></li>
<li><a href="urn_problem" title="wikilink">urn problem</a></li>
<li><a href="bias_(statistics)" title="wikilink">Bias</a></li>
<li><a href="Biased_sample" title="wikilink">Biased sample</a></li>
</ul>
<h2 id="references">References</h2>

<p>.</p>

<p>{{ Citation</p>

<p><code>| last=McCullagh</code><br/>
<code>| first=P.</code><br/>
<code>| last2=Nelder</code><br/>
<code>| first2=J. A.</code><br/>
<code>| title=Generalized Linear Models</code><br/>
<code>| publisher=Chapman and Hall</code><br/>
<code>| place=London</code><br/>
<code>| year=1983</code><br/>
<code>}}.</code></p>

<p>.</p>

<p>.   "</p>

<p><a href="Category:Discrete_distributions" title="wikilink">Category:Discrete distributions</a> <a href="Category:Probability_distributions" title="wikilink">Category:Probability distributions</a></p>
</body>
</html>
