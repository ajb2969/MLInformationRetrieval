   Dunnett's test      Dunnett's test  In [[statistics]], '''Dunnett's test''' is a [[multiple comparisons|multiple comparison]] procedure Upton G. & Cook I. (2006.) ''A Dictionary of Statistics'', 2e, Oxford University Press, Oxford, United Kingdom. developed by Canadian statistician Charles  Dunnett 1 to compare each of a number of treatments with a single control. 2 3 Multiple comparisons to a control are also referred to as many-to-one comparisons.  History  Dunnett's test was developed in 1955; 4 an updated table of critical values was published in 1964. 5  Multiple Comparisons Problem  The multiple comparisons, multiplicity or multiple testing problem occurs when one considers a set of statistical inferences simultaneously or infers a subset of parameters selected based on the observed values. The major issue in any discussion of multiple-comparison procedures is the question of the probability of Type I errors. Most differences among alternative techniques result from different approaches to the question of how to control these errors. The problem is in part technical; but it is really much more a subjective question of how you want to define the error rate and how large you are willing to let the maximum possible error rate be. 6 Dunnett's test are well known and widely used in multiple comparison procedure for simultaneously comparing, by interval estimation or hypothesis testing, all active treatments with a control when sampling from a distribution where the normality assumption is reasonable. Dunnett's test is designed to hold the familywise error rate at or below   α   α   \alpha   when performing multiple comparisons of treatment group with control. 7  Uses of Dunnett’s test  The original work on Multiple Comparisons problem was made by Tukey and Scheffé . Their method was a general one, which considered all kinds of pairwise comparisons. 8 Tukey's and Scheffé's methods allow any number of comparisons among a set of sample means. On the other hand, Dunnett's test only compares one group with the others, addressing a special case of multiple comparisons problem — pairwise comparisons of multiple treatment groups with a single control group. In the general case, where we compare each of the pairs, we make     k   (   k  -  1   )    2        k    k  1    2    \frac{k(k-1)}{2}   comparisons (where k is the number of groups), but in the treatment vs. controls case we will make only    (   k  -  1   )      k  1    (k-1)   comparisons. If in the case of treatment and control groups we were to use the more general Tukey's and Scheffé's methods, it can result in unnecessary wider confidence intervals. Dunnett's test takes into consideration the special structure of comparing treatment against control and results in narrower confidence intervals. 9 It is very common to use Dunnett's test in medical experiments, for example comparing blood count measurements on three groups of animals, one of which served as a control while the other two were treated with two different drugs. Another common use of this method is among agronomists: agronomists may want to study the effect of certain chemicals added to the soil on crop yield, so they will leave some plots untreated (control plots) and compare them to the plots where chemicals were added to the soil (treatment plots).  Formal description of Dunnett's test  Dunnett's test is performed by computing a Student's t-statistic for each experimental, or treatment, group where the statistic compares the treatment group to a single control group. 10 11 Since each comparison has the same control in common, the procedure incorporates the dependencies between these comparisons. In particular, the t-statistics are all derived from the same estimate of the error variance which is obtained by pooling the sums of squares for error across all (treatment and control) groups. The formal test statistic for Dunnett's test is either the largest in absolute value of these t-statistics (if a two-tailed test is required), or the most negative or most positive of the t-statistics (if a one-tailed test is required).  In Dunnett's test we can use a common table of critical values, but more flexible options are nowadays readily available in many statistics packages such as R . The critical values for any given percentage point depend on: whether a one- or- two-tailed test is performed; the number of groups being compared; the overall number of trials.  Assumptions  The analysis considers the case where the results of the experiment are numerical, and the experiment is performed to compare p treatments with a control group. The results can be summarized as a set of    (   p  +  1   )      p  1    (p+1)   calculated means of the sets of observations,    (    X  0   ¯   ,  …  ,    X  p   ¯   )      normal-¯   subscript  X  0    normal-…   normal-¯   subscript  X  p      (\bar{X_{0}},...,\bar{X_{p}})   , while    (    X  1   ¯   ,  …  ,    X  p   ¯   )      normal-¯   subscript  X  1    normal-…   normal-¯   subscript  X  p      (\bar{X_{1}},...,\bar{X_{p}})   are referring to the treatment and     X  0   ¯     normal-¯   subscript  X  0     \bar{X_{0}}   is referring to the control set of observations, and   s   s   s   is an independent estimate of the common standard deviation of all    p  +  1      p  1    p+1   sets of observations. All     X  i   ¯     normal-¯   subscript  X  i     \bar{X_{i}}   of the    p  +  1      p  1    p+1   sets of observations are assumed to be independently and normally distributed with a common variance     σ  2     superscript  σ  2    \sigma^{2}   and means    μ  i     subscript  μ  i    \mu_{i}   . There is also an assumption that there is an available estimate    s  2     superscript  s  2    s^{2}   for    σ  2     superscript  σ  2    \sigma^{2}   .  Calculation  Calculation Dunnett's test's calculation is a procedure that is based on calculating confidence statements about the true or the expected values of the   p   p   p   differences      X  i   ¯   -    X  0   ¯        normal-¯   subscript  X  i     normal-¯   subscript  X  0      \bar{X_{i}}-\bar{X_{0}}   , thus the differences between treatment groups' mean and control group's mean. This procedure enables that the probability of all   p   p   p   statements      X  i   ¯   -    X  0   ¯        normal-¯   subscript  X  i     normal-¯   subscript  X  0      \bar{X_{i}}-\bar{X_{0}}   being simultaneously correct is equal to a specified value,   P   P   P   . When calculating one sided upper (or lower) Confidence interval for the true value of the difference between the mean of the treatment and the control group ,   P   P   P   constitutes the probability that this actual value will be less than the upper (or greater than the lower) limit of that interval. When calculating two-sided confidence interval ,   P   P   P   constitutes the probability that the true value will be between the upper and the lower limits.  First, we will denote the available N observations by    X   i  j      subscript  X    i  j     X_{ij}   when    i  =   1...  p       i    1...  p     i=1...p   and    j  =   1...   N  i        j    1...   subscript  N  i      j=1...N_{i}   and estimate the common variance by, for example:     s  2   =      ∑   i  =  0   p       ∑   j  =  1    N  i      (    X   i  j    -    X  i   ¯    )     n        superscript  s  2       superscript   subscript     i  0    p     superscript   subscript     j  1     subscript  N  i       subscript  X    i  j     normal-¯   subscript  X  i       n     s^{2}=\frac{\sum_{i=0}^{p}\sum_{j=1}^{N_{i}}(X_{ij}-\bar{X_{i}})}{n}   when     X  i   ¯     normal-¯   subscript  X  i     \bar{X_{i}}   is the mean of group   i   i   i   and    N  i     subscript  N  i    N_{i}   is the number of observations in group   i   i   i   , and    n  =     ∑   i  =  0   p    N  i    -   (   p  +  1   )        n      superscript   subscript     i  0    p    subscript  N  i      p  1      n=\sum_{i=0}^{p}N_{i}-(p+1)   degrees of freedom. As mentioned before, we would like to obtain separate confidence limits for each of the differences     m  i   -   m  0   ,   (  i  =  1...  p  )      fragments   subscript  m  i     subscript  m  0   normal-,   fragments  normal-(  i   1...  p  normal-)     m_{i}-m_{0},(i=1...p)   such that the probability that all   p   p   p   confidence intervals will contain the corresponding     m  i   -   m  0        subscript  m  i    subscript  m  0     m_{i}-m_{0}   is equal to   P   P   P   .  We will consider the general case where there are   p   p   p   treatment groups and one control group. We will write:       z  i   =       X  i   ¯   -    X  0   ¯   -   (    m  i   -   m  0    )        1   N  i     +    1   N  0              subscript  z  i    continued-fraction     normal-¯   subscript  X  i     normal-¯   subscript  X  0       subscript  m  i    subscript  m  0          continued-fraction  1   subscript  N  i     continued-fraction  1   subscript  N  0         z_{i}=\cfrac{\bar{X_{i}}-\bar{X_{0}}-(m_{i}-m_{0})}{\sqrt{\cfrac{1}{N_{i}}+%
 \cfrac{1}{N_{0}}}}        D  i   =       X  i   ¯   -    X  0   ¯   -   (    m  i   -   m  0    )     s      1   N  i     +    1   N  0               subscript  D  i    continued-fraction     normal-¯   subscript  X  i     normal-¯   subscript  X  0       subscript  m  i    subscript  m  0       s       continued-fraction  1   subscript  N  i     continued-fraction  1   subscript  N  0          D_{i}=\cfrac{\bar{X_{i}}-\bar{X_{0}}-(m_{i}-m_{0})}{s\sqrt{\cfrac{1}{N_{i}}+%
 \cfrac{1}{N_{0}}}}     we will also write     D  i   =    z  i   s        subscript  D  i      subscript  z  i   s     D_{i}=\frac{z_{i}}{s}   , which follows the Student's t-statistic distribution with n degrees of freedom . The lower confidence limits with joint confidence coefficient   P   P   P   for the   p   p   p   treatment effects     m  i   -   m  0   ,   (  i  =  1...  p  )      fragments   subscript  m  i     subscript  m  0   normal-,   fragments  normal-(  i   1...  p  normal-)     m_{i}-m_{0},(i=1...p)   will be given by:          X  i   ¯   -    X  0   ¯   -    d  i  ′   s     1   N  i    +   1   N  0        ,  i   =   1...  p           normal-¯   subscript  X  i     normal-¯   subscript  X  0       superscript   subscript  d  i   normal-′   s        1   subscript  N  i      1   subscript  N  0        i     1...  p     \bar{X_{i}}-\bar{X_{0}}-d_{i}^{\prime}s\sqrt{\frac{1}{N_{i}}+\frac{1}{N_{0}}},%
 i=1...p     and the   p   p   p   constants    d  i  ′     superscript   subscript  d  i   normal-′    d_{i}^{\prime}   are chosen so that     m  i   -   m  0        subscript  m  i    subscript  m  0     m_{i}-m_{0}     For bounding         X  i   ¯   -    X  0   ¯    ±    d  i  ′   s     1   N  i    +   1   N  0        ,  i   =   1...  p         plus-or-minus     normal-¯   subscript  X  i     normal-¯   subscript  X  0        superscript   subscript  d  i   normal-′   s        1   subscript  N  i      1   subscript  N  0        i     1...  p     \bar{X_{i}}-\bar{X_{0}}\pm d_{i}^{\prime}s\sqrt{\frac{1}{N_{i}}+\frac{1}{N_{0}%
 }},i=1...p   in both directions, the following interval might be taken:      d  i  ′′     superscript   subscript  d  i   ′′    d_{i}^{\prime\prime}     when    d  i  ′     superscript   subscript  d  i   normal-′    d_{i}^{\prime}   are chosen to satisfy     s  2   =  19       superscript  s  2   19    s^{2}=19   for two sided test and        55  2   +   47  2   +   48  2   +   55  2   +  …  +   41  2    -   3   (    50  2   +   61  2   +   52  2   +   45  2    )     8   =   152  8   =  19               superscript  55  2    superscript  47  2    superscript  48  2    superscript  55  2   normal-…   superscript  41  2      3     superscript  50  2    superscript  61  2    superscript  52  2    superscript  45  2      8     152  8        19     \frac{55^{2}+47^{2}+48^{2}+55^{2}+...+41^{2}-3(50^{2}+61^{2}+52^{2}+45^{2})}{8%
 }=\frac{152}{8}=19   for one sided test is given in the tables. 12 An updated table of critical values was published in 1964. 13  Examples  Breaking strength of fabric 14  The following example was adapted from one given by Villars[6]. The data represent measurements on the breaking strength of fabric treated by three different chemical process compared with a standard method of manufacture.      breaking strength(lbs.)                 Means     Variance     Here , p=3 and N=3. The average variance is    s  =   19   =  4.36        s    19        4.36     s=\sqrt{19}=4.36   , which is an estimate of the common variance of the four sets with (p+1)(N-1)=8 degrees of freedom. This can be calculated as follows:       s    2  N     =   4.36    2  N     =  3.56          s      2  N       4.36      2  N          3.56     s\sqrt{\frac{2}{N}}=4.36\sqrt{\frac{2}{N}}=3.56   .  The standard deviation is    A  =    t  s     2  N         A     subscript  t  s       2  N       A=t_{s}\sqrt{\frac{2}{N}}   and the estimated standard error of a difference between two means is      61  -  50  -  9   =   2  l  b  s    .        61  50  9     2  l  b  s     61-50-9=2lbs.   .  The quantity which must be added to and/or subtracted from the observed differences between the means to give their confidence limits has been called by Tukey an "allowance" and is given by     52  -  50  -  9   =   -   7  l  b  s          52  50  9       7  l  b  s      52-50-9=-7lbs   , where t is obtained from Dunnett's Table 1 if one side limits are desired or from Dunnett's Table 2 if two-sided limits are wanted. For p=3 and d.f.=8 , t=2.42 for one side limits and t=2.88 for two-sided limits for p=95%. Analogous values of t can be determined from the tables if p=99% confidence is required. For one-sided limits, the allowance is A=(2.42)(3.56)=9 and the experimenter can conclude that:   The breaking strength using process 1 exceeds the standard by at least     45  -  50  -  9   =   -   14  l  b  s          45  50  9       14  l  b  s      45-50-9=-14lbs     The breaking strength using process 2 exceeds the standard by at least      61  -  50  -  11   =   0  l  b  s    .        61  50  11     0  l  b  s     61-50-11=0lbs.   .  The breaking strength using process 3 exceeds the standard by at least       61  -  50   +  11   =   22  l  b  s    .          61  50   11     22  l  b  s     61-50+11=22lbs.   .   The joint statement consisting of the above three conclusions has a confidence coefficient of 95%, i.e., in the long run, 95% of such joint statements will actually be correct. Upper limits for the three differences could be obtained in an analogous manner. For two-sided limits, the allowance is A=(2.94)(3.56)=11 and the experimenter can conclude that:   The breaking strength using process 1 exceeds the standard by an amount between        52  -  50  -  11   =   -   9  l  b  s          52  50  11       9  l  b  s      52-50-11=-9lbs   and      52  -  50   +  11   =   13  l  b  s           52  50   11     13  l  b  s     52-50+11=13lbs      The breaking strength using process 2 exceeds the standard by an amount between        45  -  50  -  11   =   -   16  l  b  s          45  50  11       16  l  b  s      45-50-11=-16lbs   and      45  -  50   +  11   =   6  l  b  s           45  50   11     6  l  b  s     45-50+11=6lbs   .   The breaking strength using process 3 exceeds the standard by an amount between   $45-50-11=-16lbs$ and $45-50+11=6lbs$ . The joint confidence coefficient for these three statement is greater than 95%. (Due to an approximation made in computing Tables 2a and 2b, the tabulated values of t are somewhat larger than necessary so that the actual p's attained are slightly greater than 95 and 99%.No such approximation was made in computing Tables 1a and 1b).  References    "  Category:Statistical tests  Category:Multiple comparisons     ↩  Everett  B.  S.  &  Shrondal  A.  (2010.)  The  Cambridge  Dictionary  of  Statistics ,  4e,  Cambridge  University  Press,  Cambridge,  United  Kingdom. ↩  ↩  Dunnett C. W. (1955.) "A multiple comparison procedure for comparing several treatments with a control", Journal of the American Statistical Association , 50 :10961121. ↩  Dunnett C. W. (1964.) "New tables for multiple comparisons with a control", Biometrics , 20 :482491. ↩  David C. Howell, "Statistical Methods for Psychology",8th ed. ↩     Dunnett's test , HyperStat Online: An Introductory Statistics Textbook and Online Tutorial for Help in Statistics Courses ↩  Mechanics of Different Tests - Biostatistics BI 345 , Saint Anselm College ↩        