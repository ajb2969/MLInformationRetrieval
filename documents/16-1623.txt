


Domain adaptation




Domain adaptation

Domain Adaptation12 is a field of associated with machine learning and transfer learning. This scenario arises when we aim at learning from a source data distribution a well performing model on a different (but related) target data distribution. For instance, one of the tasks of the common spam filtering problem consists in adapting a model from one user (the source distribution) to a new one who receives significantly different emails (the target distribution). Note that, when more than one source distribution is available we talked about multi-source domain adaptation.3
Formalization
Let 
 
 
 
  be the input space (or description space) and let 
 
 
 
  be the output space (or label space). The objective of a machine learning algorithm is to learn a mathematical model (a hypothesis) 
 
 
 
  able to affect a label of 
 
 
 
  to an example from 
 
 
 
 . This model is learned from a learning sample 
 
 
 
 .
Usually in supervised learning (without domain adaptation), we suppose that the examples 
 
 
 
  are drawn i.i.d. from a distribution 
 
 
 
  of support 
 
 
 
  (unknown and fixed). The objective is then to learn 
 
 
 
  (from 
 
 
 
 ) such that it commits the less error as possible for labeling new examples coming from the distribution 
 
 
 
 .
The main difference between supervised learning and domain adaptation is that in the latter situation we study two different (but related) distributions 
 
 
 
  and 
 
 
 
  on 
 
 
 
 . The domain adaptation task consists then to transfer knowledge from the source domain 
 
 
 
 to the target one 
 
 
 
 . The goal is then to learn 
 
 
 
  (from labeled or unlabeled samples coming from the two domains) such that it commits the less error as possible on the target domain 
 
 
 
 .
The major issue is the following: if a model is learned from a source domain, what is its capacity to correctly label data coming from the target domain?
The different types of domain adaptation
There are several contexts of domain adaptation. They differ in the informations considered for the target task.

The unsupervised domain adaptation: the learning sample contains a set of labeled source examples, a set of unlabeled source examples and an unlabeled set of target examples.
The semi-supervised domain adaptation: in this situation, we also consider a "small" set of labeled target examples.
The supervised domain adaptation: all the examples considered are supposed to be labeled.

Three algorithmic principles
Reweighting algorithms
The objective is to reweight the source labeled sample such that it "looks like" the target sample (in term of the error measure considered)45
Iterative algorithms
A method for adapting consists in iteratively "auto-labeled" the target examples. The principle is simple:

a model 
 
 
 
  is learned from the labeled examples;


 
  automatically labels some target examples;
a new model is learned from the new labeled examples.

Note that there exists other iterative approaches, but they usually need target labeled examples.
Search of a common representation space
The goal is to find or construct a common representation space for the two domains. The objective is to obtain a space in which the domains are close to each other while keeping good performances on the source labeling task.
References
"
Category:Machine learning












