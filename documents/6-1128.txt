   Methods of computing square roots      Methods of computing square roots  table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
   margin: 0; padding: 0; vertical-align: baseline; border: none; }
 <style>
 table.sourceCode { width: 100%; line-height: 100%; }
 td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
 td.sourceCode { padding-left: 5px; }
 code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
 code > span.dt { color: #902000; } /* DataType */
 code > span.dv { color: #40a070; } /* DecVal */
 code > span.bn { color: #40a070; } /* BaseN */
 code > span.fl { color: #40a070; } /* Float */
 code > span.ch { color: #4070a0; } /* Char */
 code > span.st { color: #4070a0; } /* String */
 code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
 code > span.ot { color: #007020; } /* Other */
 code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
 code > span.fu { color: #06287e; } /* Function */
 code > span.er { color: #ff0000; font-weight: bold; } /* Error */
 code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
 code > span.cn { color: #880000; } /* Constant */
 code > span.sc { color: #4070a0; } /* SpecialChar */
 code > span.vs { color: #4070a0; } /* VerbatimString */
 code > span.ss { color: #bb6688; } /* SpecialString */
 code > span.im { } /* Import */
 code > span.va { color: #19177c; } /* Variable */
 code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
 code > span.op { color: #666666; } /* Operator */
 code > span.bu { } /* BuiltIn */
 code > span.ex { } /* Extension */
 code > span.pp { color: #bc7a00; } /* Preprocessor */
 code > span.at { color: #7d9029; } /* Attribute */
 code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
 code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
 code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
 code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */     In numerical analysis , a branch of mathematics, there are several square root algorithms or methods of computing the principal square root of a nonnegative  real number . For the square roots of a negative or complex number , see below .  Finding    S      S    \sqrt{S}   is the same as solving the equation     f   (  x  )    =    x  2   -  S   =  0          f  x      superscript  x  2   S        0     f(x)=x^{2}-S=0\,\!   . Therefore, any general numerical root-finding algorithm can be used. Newton's method , for example, reduces in this case to the so-called Babylonian method:       x   n  +  1    =    x  n   -    f   (   x  n   )      f  ′    (   x  n   )      =    x  n   -     x  n  2   -  S    2   x  n      =    1  2    (    x  n   +   S   x  n     )           subscript  x    n  1       subscript  x  n       f   subscript  x  n       superscript  f  normal-′    subscript  x  n              subscript  x  n        superscript   subscript  x  n   2   S     2   subscript  x  n               1  2      subscript  x  n     S   subscript  x  n         x_{n+1}=x_{n}-\frac{f(x_{n})}{f^{\prime}(x_{n})}=x_{n}-\frac{x_{n}^{2}-S}{2x_{%
 n}}=\frac{1}{2}\left(x_{n}+\frac{S}{x_{n}}\right)     Generally, these methods yield approximate results. To get a higher precision for the root, a higher precision for the square is required and a larger number of steps must be calculated.  Rough estimation  Many square root algorithms require an initial seed value . If the initial seed value is far away from the actual square root, the algorithm will be slowed down. It is therefore useful to have a rough estimate, which may be very inaccurate but easy to calculate. With   S   S   S   expressed in scientific notation as    a  ×   10   2  n        a   superscript  10    2  n      a\times 10^{2n}   where    1  ≤  a  <  100        1  a       100     1\leq a<100   and n is an integer, the square root     S   =    a   ×   10  n          S       a    superscript  10  n      \sqrt{S}=\sqrt{a}\times 10^{n}   can be estimated as       S   ≈   {      2  ⋅   10  n         if  a   <  10   ,        6  ⋅   10  n        if  a   ≥  10.             S    cases   normal-⋅  2   superscript  10  n        if  a   10    normal-⋅  6   superscript  10  n        if  a   10.      \sqrt{S}\approx\begin{cases}2\cdot 10^{n}&\text{if }a<10,\\
 6\cdot 10^{n}&\text{if }a\geq 10.\end{cases}     The factors two and six are used because they approximate the geometric means of the lowest and highest possible values with the given number of digits       1   ⋅   10     =   10  4   ≈   2            normal-⋅    1     10        4   10        2     \sqrt{\sqrt{1}\cdot\sqrt{10}}=\sqrt[4]{10}\approx 2\,   and       10   ⋅   100     =   1000  4   ≈   6            normal-⋅    10     100        4   1000        6     \sqrt{\sqrt{10}\cdot\sqrt{100}}=\sqrt[4]{1000}\approx 6\,   .  For    S  =  125348  =   12.5348  ×   10  4          S  125348         12.5348   superscript  10  4       S=125348=12.5348\times 10^{4}   , the estimate is     S   ≈   6  ⋅   10  2    =  600          S    normal-⋅  6   superscript  10  2         600     \sqrt{S}\approx 6\cdot 10^{2}=600   .  When working in the binary numeral system (as computers do internally), by expressing   S   S   S   as    a  ×   2   2  n        a   superscript  2    2  n      a\times 2^{2n}   where     0.1  2   ≤  a  <   10  2          subscript  0.1  2   a        subscript  10  2      0.1_{2}\leq a<10_{2}   , the square root     S   =    a   ×   2  n          S       a    superscript  2  n      \sqrt{S}=\sqrt{a}\times 2^{n}   can be estimated as     S   ≈   2  n         S    superscript  2  n     \sqrt{S}\approx 2^{n}   , since the geometric mean of the lowest and highest possible values is        0.1  2    ⋅    10  2      =   1  4   =  1           normal-⋅     subscript  0.1  2       subscript  10  2         4   1        1     \sqrt{\sqrt{0.1_{2}}\cdot\sqrt{10_{2}}}=\sqrt[4]{1}=1   .  For    S  =  125348  =   1 1110 1001 1010 0100  2   =    1.1110 1001 1010 0100  2   ×    2  16           S  125348        subscript  1 1110 1001 1010 0100  2           subscript  1.1110 1001 1010 0100  2    superscript  2  16       S=125348=1\;1110\;1001\;1010\;0100_{2}=1.1110\;1001\;1010\;0100_{2}\times 2^{1%
 6}\,   the binary approximation gives     S   ≈   2  8   =   1 0000 0000  2   =  256 .          S    superscript  2  8         subscript  1 0000 0000  2        256 .     \sqrt{S}\approx 2^{8}=1\;0000\;0000_{2}=256\,.     These approximations are useful to find better seeds for iterative algorithms, which results in faster convergence.  Babylonian method  (Figure)  Graph charting the use of the Babylonian method for approximating the square root of 100 (10) using starting values x 0 = 50 , x 0 = 1 , and x 0 = −5 . Note that using a negative starting value yields the negative root.   Perhaps the first algorithm used for approximating    S      S    \sqrt{S}   is known as the "Babylonian method", named after the Babylonians , 1 or "Hero's method", named after the first-century Greek mathematician Hero of Alexandria who gave the first explicit description of the method. 2 It can be derived from (but predates by 16 centuries) Newton's method . The basic idea is that if x is an overestimate to the square root of a non-negative real number S then    S  /   x       S  x    \scriptstyle S/x\,   will be an underestimate and so the average of these two numbers may reasonably be expected to provide a better approximation (though the formal proof of that assertion depends on the inequality of arithmetic and geometric means that shows this average is always an overestimate of the square root, as noted in the article on square roots , thus assuring convergence).  More precisely, if   x   x   x   is our initial guess of    S      S    \sqrt{S}   and   e   e   e   is the error in our estimate such that    S  =    (   x  +  e   )   2       S   superscript    x  e   2     S=(x+e)^{2}   , then we can expand the binomial and solve for      e  =    S  -   x  2      2  x   +  e    ≈    S  -   x  2     2  x          e      S   superscript  x  2        2  x   e             S   superscript  x  2      2  x       e=\frac{S-x^{2}}{2x+e}\approx\frac{S-x^{2}}{2x}   since    e  ≪  x     much-less-than  e  x    e\ll x   Therefore, we can compensate for the error and update our old estimate as      x  :=   x  +  e   =    S  +   x  2     2  x    =    x  +   S  x    2        assign  x    x  e            S   superscript  x  2      2  x             x    S  x    2      x:=x+e=\frac{S+x^{2}}{2x}=\frac{x+\frac{S}{x}}{2}   Since the computed error was not exact, this becomes our next best guess. The process of updating is iterated until desired accuracy is obtained. This is a quadratically convergent algorithm, which means that the number of correct digits of the approximation roughly doubles with each iteration. It proceeds as follows:   Begin with an arbitrary positive starting value x 0 (the closer to the actual square root of S, the better).  Let x n +1 be the average of x n and S / x n (using the arithmetic mean to approximate the geometric mean ).  Repeat step 2 until the desired accuracy is achieved.   It can also be represented as:        x  0   ≈   S    .       subscript  x  0     S     x_{0}\approx\sqrt{S}.           x   n  +  1    =    1  2    (    x  n   +   S   x  n     )     ,       subscript  x    n  1        1  2      subscript  x  n     S   subscript  x  n        x_{n+1}=\frac{1}{2}\left(x_{n}+\frac{S}{x_{n}}\right),           S   =    lim   n  →  ∞     x  n     .        S     subscript    normal-→  n      subscript  x  n      \sqrt{S}=\lim_{n\to\infty}x_{n}.     This algorithm works equally well in the p-adic numbers , but cannot be used to identify real square roots with p-adic square roots; one can, for example, construct a sequence of rational numbers by this method that converges to +3 in the reals, but to −3 in the 2-adics.  Example  To calculate    S      S    \sqrt{S}   , where S = 125348, to 6 significant figures, use the rough estimation method above to get       x  0   =   6  ⋅   10  2    =   600.000          subscript  x  0    normal-⋅  6   superscript  10  2         600.000     x_{0}=6\cdot 10^{2}=600.000\,          x  1   =    1  2    (    x  0   +   S   x  0     )    =    1  2    (   600.000  +   125348  600.000    )    =  404.457         subscript  x  1       1  2      subscript  x  0     S   subscript  x  0               1  2     600.000    125348  600.000          404.457     x_{1}=\frac{1}{2}\left(x_{0}+\frac{S}{x_{0}}\right)=\frac{1}{2}\left(600.000+%
 \frac{125348}{600.000}\right)=404.457          x  2   =    1  2    (    x  1   +   S   x  1     )    =    1  2    (   404.457  +   125348  404.457    )    =  357.187         subscript  x  2       1  2      subscript  x  1     S   subscript  x  1               1  2     404.457    125348  404.457          357.187     x_{2}=\frac{1}{2}\left(x_{1}+\frac{S}{x_{1}}\right)=\frac{1}{2}\left(404.457+%
 \frac{125348}{404.457}\right)=357.187          x  3   =    1  2    (    x  2   +   S   x  2     )    =    1  2    (   357.187  +   125348  357.187    )    =  354.059         subscript  x  3       1  2      subscript  x  2     S   subscript  x  2               1  2     357.187    125348  357.187          354.059     x_{3}=\frac{1}{2}\left(x_{2}+\frac{S}{x_{2}}\right)=\frac{1}{2}\left(357.187+%
 \frac{125348}{357.187}\right)=354.059          x  4   =    1  2    (    x  3   +   S   x  3     )    =    1  2    (   354.059  +   125348  354.059    )    =  354.045         subscript  x  4       1  2      subscript  x  3     S   subscript  x  3               1  2     354.059    125348  354.059          354.045     x_{4}=\frac{1}{2}\left(x_{3}+\frac{S}{x_{3}}\right)=\frac{1}{2}\left(354.059+%
 \frac{125348}{354.059}\right)=354.045          x  5   =    1  2    (    x  4   +   S   x  4     )    =    1  2    (   354.045  +   125348  354.045    )    =  354.045 .         subscript  x  5       1  2      subscript  x  4     S   subscript  x  4               1  2     354.045    125348  354.045          354.045 .     x_{5}=\frac{1}{2}\left(x_{4}+\frac{S}{x_{4}}\right)=\frac{1}{2}\left(354.045+%
 \frac{125348}{354.045}\right)=354.045\,.     Therefore,     125348   ≈  354.045 .        125348   354.045 .    \sqrt{125348}\approx 354.045\,.     Convergence  Let the relative error in x n be defined by       ε  n   =     x  n    S    -  1        subscript  ε  n        subscript  x  n     S    1     \varepsilon_{n}=\frac{x_{n}}{\sqrt{S}}-1     and thus        x  n   =    S   ⋅   (   1  +   ε  n    )     .       subscript  x  n    normal-⋅    S     1   subscript  ε  n       x_{n}=\sqrt{S}\cdot(1+\varepsilon_{n}).     Then it can be shown that       ε   n  +  1    =    ε  n  2    2   (   1  +   ε  n    )          subscript  ε    n  1       superscript   subscript  ε  n   2     2    1   subscript  ε  n        \varepsilon_{n+1}=\frac{\varepsilon_{n}^{2}}{2(1+\varepsilon_{n})}     and thus that      0  ≤   ε   n  +  2    ≤   min   {    ε   n  +  1   2   2   ,    ε   n  +  1    2   }          0   subscript  ε    n  2              superscript   subscript  ε    n  1    2   2      subscript  ε    n  1    2       0\leq\varepsilon_{n+2}\leq\min\left\{\frac{\varepsilon_{n+1}^{2}}{2},\frac{%
 \varepsilon_{n+1}}{2}\right\}     and consequently that convergence is assured provided that x 0 and S are both positive.  Worst case for convergence  If using the rough estimate above with the Babylonian method, then the least accurate cases in ascending order are as follows:     S   S   \displaystyle S     Thus in any case,        ε  1   ≤   2   -  2     .       subscript  ε  1    superscript  2    2      \varepsilon_{1}\leq 2^{-2}.\,           ε  2   <   2   -  5    <   10   -  1     .         subscript  ε  2    superscript  2    5          superscript  10    1       \varepsilon_{2}<2^{-5}<10^{-1}.\,           ε  3   <   2   -  11    <   10   -  3     .         subscript  ε  3    superscript  2    11          superscript  10    3       \varepsilon_{3}<2^{-11}<10^{-3}.\,           ε  4   <   2   -  23    <   10   -  6     .         subscript  ε  4    superscript  2    23          superscript  10    6       \varepsilon_{4}<2^{-23}<10^{-6}.\,           ε  5   <   2   -  47    <   10   -  14     .         subscript  ε  5    superscript  2    47          superscript  10    14       \varepsilon_{5}<2^{-47}<10^{-14}.\,           ε  6   <   2   -  95    <   10   -  28     .         subscript  ε  6    superscript  2    95          superscript  10    28       \varepsilon_{6}<2^{-95}<10^{-28}.\,           ε  7   <   2   -  191    <   10   -  57     .         subscript  ε  7    superscript  2    191          superscript  10    57       \varepsilon_{7}<2^{-191}<10^{-57}.\,           ε  8   <   2   -  383    <   10   -  115     .         subscript  ε  8    superscript  2    383          superscript  10    115       \varepsilon_{8}<2^{-383}<10^{-115}.\,     Remember that rounding errors will slow the convergence. It is recommended to keep at least one extra digit beyond the desired accuracy of the x n being calculated to minimize round off error.  Digit-by-digit calculation  This is a method to find each digit of the square root in a sequence. It is slower than the Babylonian method (if you have a calculator that can divide in one operation), but it has several advantages:   It can be easier for manual calculations.  Every digit of the root found is known to be correct, i.e., it does not have to be changed later.  If the square root has an expansion that terminates, the algorithm terminates after the last digit is found. Thus, it can be used to check whether a given integer is a square number .  The algorithm works for any base , and naturally, the way it proceeds depends on the base chosen.   Napier's bones include an aid for the execution of this algorithm. The shifting n th root algorithm is a generalization of this method.  Basic principle  Suppose we are able to find the square root of N by expressing it as a sum of n positive numbers such that       N  =    (    a  1   +   a  2   +   a  3   +  ⋯  +   a  n    )   2    .      N   superscript     subscript  a  1    subscript  a  2    subscript  a  3   normal-⋯   subscript  a  n    2     N=(a_{1}+a_{2}+a_{3}+\cdots+a_{n})^{2}.     By repeatedly applying the basic identity         (   x  +  y   )   2   =    x  2   +   2  x  y   +   y  2     ,       superscript    x  y   2      superscript  x  2     2  x  y    superscript  y  2      (x+y)^{2}=x^{2}+2xy+y^{2},   the right-hand-side term can be expanded as       (    a  1   +   a  2   +   a  3   +  ⋯  +   a  n    )   2     superscript     subscript  a  1    subscript  a  2    subscript  a  3   normal-⋯   subscript  a  n    2    \displaystyle(a_{1}+a_{2}+a_{3}+\cdots+a_{n})^{2}     This expression allows us to find the square root by sequentially guessing the values of    a  i     subscript  a  i    a_{i}   s. Suppose that the numbers     a  1   ,  …  ,   a   m  -  1        subscript  a  1   normal-…   subscript  a    m  1      a_{1},\ldots,a_{m-1}   have already been guessed, then the m-th term of the right-hand-side of above summation is given by      Y  m   =    [    2   P   m  -  1     +   a  m    ]    a  m     ,       subscript  Y  m      delimited-[]      2   subscript  P    m  1      subscript  a  m      subscript  a  m      Y_{m}=[2P_{m-1}+a_{m}]a_{m},   where     P   m  -  1    =    ∑   i  =  1    m  -  1     a  i         subscript  P    m  1      superscript   subscript     i  1      m  1     subscript  a  i      P_{m-1}=\sum_{i=1}^{m-1}a_{i}   is the approximate square root found so far. Now each new guess    a  m     subscript  a  m    a_{m}   should satisfy the recursion        X  m   =    X   m  -  1    -   Y  m     ,       subscript  X  m      subscript  X    m  1     subscript  Y  m      X_{m}=X_{m-1}-Y_{m},   such that     X  m   ≥  0       subscript  X  m   0    X_{m}\geq 0   for all     1  ≤  m  ≤  n   ,        1  m       n     1\leq m\leq n,   with initialization      X  0   =  N   .       subscript  X  0   N    X_{0}=N.   When      X  n   =  0   ,       subscript  X  n   0    X_{n}=0,   the exact square root has been found; if not, then the sum of    a  i     subscript  a  i    a_{i}   s gives a suitable approximation of the square root, with    X  n     subscript  X  n    X_{n}   being the approximation error.  For example, in the decimal number system we have       N  =    (     a  1   ⋅   10   n  -  1     +    a  2   ⋅   10   n  -  2     +  ⋯  +    a   n  -  1    ⋅  10   +   a  n    )   2    ,      N   superscript     normal-⋅   subscript  a  1    superscript  10    n  1      normal-⋅   subscript  a  2    superscript  10    n  2     normal-⋯   normal-⋅   subscript  a    n  1    10    subscript  a  n    2     N=(a_{1}\cdot 10^{n-1}+a_{2}\cdot 10^{n-2}+\cdots+a_{n-1}\cdot 10+a_{n})^{2},   where    10   n  -  i      superscript  10    n  i     10^{n-i}   are place holders and the coefficients     a  i   ∈   {  0  ,  1  ,  2  ,  …  ,  9  }        subscript  a  i    0  1  2  normal-…  9     a_{i}\in\{0,1,2,\ldots,9\}   . At any m-th stage of the square root calculation, the approximate root found so far,    P   m  -  1      subscript  P    m  1     P_{m-1}   and the summation term    Y  m     subscript  Y  m    Y_{m}   are given by        P   m  -  1    =    ∑   i  =  1    m  -  1      a  i   ⋅   10   n  -  i      =    10    n  -  m   +  1      ∑   i  =  1    m  -  1      a  i   ⋅   10   m  -  i  -  1        ,         subscript  P    m  1      superscript   subscript     i  1      m  1     normal-⋅   subscript  a  i    superscript  10    n  i              superscript  10      n  m   1      superscript   subscript     i  1      m  1     normal-⋅   subscript  a  i    superscript  10    m  i  1          P_{m-1}=\sum_{i=1}^{m-1}a_{i}\cdot 10^{n-i}=10^{n-m+1}\sum_{i=1}^{m-1}a_{i}%
 \cdot 10^{m-i-1},           Y  m   =     [    2   P   m  -  1     +    a  m   ⋅   10   n  -  m      ]    a  m    ⋅   10   n  -  m     =     [    20    ∑   i  =  1    m  -  1      a  i   ⋅   10   m  -  i  -  1       +   a  m    ]    a  m    ⋅   10   2   (   n  -  m   )       .         subscript  Y  m    normal-⋅     delimited-[]      2   subscript  P    m  1      normal-⋅   subscript  a  m    superscript  10    n  m        subscript  a  m     superscript  10    n  m           normal-⋅     delimited-[]      20    superscript   subscript     i  1      m  1     normal-⋅   subscript  a  i    superscript  10    m  i  1        subscript  a  m      subscript  a  m     superscript  10    2    n  m         Y_{m}=[2P_{m-1}+a_{m}\cdot 10^{n-m}]a_{m}\cdot 10^{n-m}=[20\sum_{i=1}^{m-1}a_{%
 i}\cdot 10^{m-i-1}+a_{m}]a_{m}\cdot 10^{2(n-m)}.     Here since the place value of    Y  m     subscript  Y  m    Y_{m}   is an even power of 10, we only need to work with the pair of most significant digits of the remaining term    X   m  -  1      subscript  X    m  1     X_{m-1}   at any m-th stage. The section below codifies this procedure.  It is obvious that a similar method can be used to compute the square root in number systems other than the decimal number system. For instance, finding the digit-by-digit square root in the binary number system is quite efficient since the value of    a  i     subscript  a  i    a_{i}   is searched from a smaller set of binary digits {0,1}. This makes the computation faster since at each stage the value of    Y  m     subscript  Y  m    Y_{m}   is either     Y  m   =  0       subscript  Y  m   0    Y_{m}=0   for     a  m   =  0       subscript  a  m   0    a_{m}=0   or     Y  m   =    2   P   m  -  1     +  1        subscript  Y  m       2   subscript  P    m  1     1     Y_{m}=2P_{m-1}+1   for     a  m   =  1       subscript  a  m   1    a_{m}=1   . The fact that we have only two possible options for    a  m     subscript  a  m    a_{m}   also makes the process of deciding the value of    a  m     subscript  a  m    a_{m}   at m-th stage of calculation easier. This is because we only need to check if     Y  m   ≤   X   m  -  1         subscript  Y  m    subscript  X    m  1      Y_{m}\leq X_{m-1}   for     a  m   =  1.       subscript  a  m   1.    a_{m}=1.   If this condition is satisfied, then we take     a  m   =  1       subscript  a  m   1    a_{m}=1   ; if not then     a  m   =  0.       subscript  a  m   0.    a_{m}=0.   Also, the fact that multiplication by 2 is done by left bit-shifts helps in the computation.  Decimal (base 10)  Write the original number in decimal form. The numbers are written similar to the long division algorithm, and, as in long division, the root will be written on the line above. Now separate the digits into pairs, starting from the decimal point and going both left and right. The decimal point of the root will be above the decimal point of the square. One digit of the root will appear above each pair of digits of the square.  Beginning with the left-most pair of digits, do the following procedure for each pair:   Starting on the left, bring down the most significant (leftmost) pair of digits not yet used (if all the digits have been used, write "00") and write them to the right of the remainder from the previous step (on the first step, there will be no remainder). In other words, multiply the remainder by 100 and add the two digits. This will be the current value c .  Find p , y and x , as follows:  Let p be the part of the root found so far , ignoring any decimal point. (For the first step, p = 0).  Determine the greatest digit x such that     x   (    20  p   +  x   )    ≤  c        x      20  p   x    c    x(20p+x)\leq c   . We will use a new variable y = x (20 p + x ).  Note: 20 p + x is simply twice p , with the digit x appended to the right).  Note: You can find x by guessing what c /(20· p ) is and doing a trial calculation of y , then adjusting x upward or downward as necessary.   Place the digit   x   x   x   as the next digit of the root, i.e., above the two digits of the square you just brought down. Thus the next p will be the old p times 10 plus x .   Subtract y from c to form a new remainder.  If the remainder is zero and there are no more digits to bring down, then the algorithm has terminated. Otherwise go back to step 1 for another iteration.   Examples  Find the square root of 152.2756.   1  2. 3  4  /  \/  01 52.27 56   01                   1*1 01 y = x*x = 1*1 = 1  00 52                22*2 00 44 y = (20+x)*x = 22*2 = 44  08 27             243*3 07 29 y = (240+x)*x = 243*3 = 729  98 56          2464*4 98 56 y = (2460+x)*x = 2464*4 = 9856  00 00          Algorithm terminates: Answer is 12.34  Find the square root of 2.   1. 4  1  4  2  /  \/  02.00 00 00 00   02                  1*1 01 y = x*x = 1*1 = 1  01 00               24*4 00 96 y = (20+x)*x = 24*4 = 96  04 00            281*1 02 81 y = (280+x)*x = 281*1 = 281  01 19 00         2824*4 01 12 96 y = (2820+x)*x = 2824*4 = 11296  06 04 00      28282*2 \, e , when added to the right of a current solution     r    r   \,r    , such that       (   r  +  e   )   ⋅   (   r  +  e   )    ≤  x       normal-⋅    r  e     r  e    x    \,(r+e)\cdot(r+e)\leq x    , where     x    x   \,x    is the value for which a root is desired. Expanding        r   ⋅  r   +   2  r  e   +   e  ⋅  e    ≤  x         normal-⋅  r  r     2  r  e    normal-⋅  e  e    x    \,r\cdot r+2re+e\cdot e\leq x    .  The current value of      r   ⋅  r     normal-⋅  r  r    \,r\cdot r    —or, usually, the remainder—can be incrementally updated efficiently when working in binary, as the value of     e    e   \,e    will have a single bit set (a power of 2), and the operations needed to compute     2  ⋅  r  ⋅  e     normal-⋅  2  r  e    \,2\cdot r\cdot e    and      e   ⋅  e     normal-⋅  e  e    \,e\cdot e    can be replaced with faster bit  shift operations.  Example  Here we obtain the square root of 81, which when converted into binary gives 1010001. The numbers in the left column gives the option between that number or zero to be used for subtraction at that stage of computation. The final answer is 1001, which in decimal is 9.  1 0 0 1  ---------  √ 1010001  1      1  1  ---------  101     01  0  --------  1001     100  0  --------  10001    10001  10001  -------  0  This gives rise to simple computer implementations: 3  short isqrt( short num) { short res = 0 ; short bit = 1 << 14 ; // The second-to-top bit is set: 1 << 30 for 32 bits  // "bit" starts at the highest power of four <= the argument.  while (bit > num)
         bit >>= 2 ; while (bit != 0 ) { if (num >= res + bit) {
             num -= res + bit;
             res = (res >> 1 ) + bit;
         } else res >>= 1 ;
         bit >>= 2 ;
     } return res;
 }  Using the notation above, the variable "bit" corresponds to    e  m  2     superscript   subscript  e  m   2    e_{m}^{2}   which is      (   2  m   )   2   =   4  m        superscript   superscript  2  m   2    superscript  4  m     (2^{m})^{2}=4^{m}   , the variable "res" is equal to    2  r   e  m       2  r   subscript  e  m     2re_{m}   , and the variable "num" is equal to the current    X  m     subscript  X  m    X_{m}   which is the difference of the number we want the square root of and the square of our current approximation with all bits set up to    2   m  +  1      superscript  2    m  1     2^{m+1}   . Thus in the first loop, we want to find the highest power of 4 in "bit" to find the highest power of 2 in   e   e   e   . In the second loop, if num is greater than res + bit, then    X  m     subscript  X  m    X_{m}   is greater than     2  r   e  m    +   e  m  2         2  r   subscript  e  m     superscript   subscript  e  m   2     2re_{m}+e_{m}^{2}   and we can subtract it. The next line, we want to add    e  m     subscript  e  m    e_{m}   to   r   r   r   which means we want to add    2   e  m  2       2   subscript   superscript  e  2   m     2e^{2}_{m}   to    2  r   e  m       2  r   subscript  e  m     2re_{m}   so we want res = res + bite_m to    e   m  -  1      subscript  e    m  1     e_{m-1}   inside res which involves dividing by 2 or another shift to the right. Combining these 2 into one line leads to res = res>>1 + bit. If    X  m     subscript  X  m    X_{m}   isn't greater than     2  r   e  m    +   e  m  2         2  r   subscript  e  m     superscript   subscript  e  m   2     2re_{m}+e_{m}^{2}   then we just update    e  m     subscript  e  m    e_{m}   to    e   m  -  1      subscript  e    m  1     e_{m-1}   inside res and divide it by 2. Then we update    e  m     subscript  e  m    e_{m}   to    e   m  -  1      subscript  e    m  1     e_{m-1}   in bit by dividing it by 4. The final iteration of the 2nd loop has bit equal to 1 and will cause update of   e   e   e   to run one extra time removing the factor of 2 from res making it our integer approximation of the root.  Faster algorithms, in binary and decimal or any other base, can be realized by using lookup tables—in effect trading more storage space for reduced run time . 4  Exponential identity  Pocket calculators typically implement good routines to compute the exponential function and the natural logarithm , and then compute the square root of S using the identity found using the properties of logarithms (     ln   x  n    =   n   ln  x           superscript  x  n      n    x      \ln x^{n}=n\ln x   ) and exponentials (     e   ln  x    =  x       superscript  e    x    x    e^{\ln x}=x   ):        S   =   e    1  2    ln  S      .        S    superscript  e      1  2     S       \sqrt{S}=e^{\frac{1}{2}\ln S}.   The denominator in the fraction corresponds to the n th root. In the case above the denominator is 2, hence the equation specifies that the square root is to be found. The same identity is used when computing square roots with logarithm tables or slide rules .  Bakhshali approximation  This method for finding an approximation to a square root was described in an ancient Indian mathematical manuscript called the Bakhshali manuscript . It is equivalent to two iterations of the Babylonian method beginning with N . The original presentation goes as follows: To calculate    S      S    \sqrt{S}   , let N 2 be the nearest perfect square to S . Then, calculate:      d  =   S  -   N  2        d    S   superscript  N  2      d=S-N^{2}\,\!         P  =   d   2  N        P    d    2  N      P=\frac{d}{2N}         A  =   N  +  P       A    N  P     A=N+P\,\!          S   ≈   A  -    P  2    2  A           S     A     superscript  P  2     2  A       \sqrt{S}\approx A-\frac{P^{2}}{2A}   This can be also written as:       S   ≈    N  +   d   2  N     -    d  2     8   N  3    +   4  N  d      =     8   N  4    +   8   N  2   d   +   d  2      8   N  3    +   4  N  d     =     N  4   +   6   N  2   S   +   S  2      4   N  3    +   4  N  S     =      N  2    (    N  2   +   6  S    )    +   S  2     4  N   (    N  2   +  S   )             S       N    d    2  N        superscript  d  2       8   superscript  N  3      4  N  d                 8   superscript  N  4      8   superscript  N  2   d    superscript  d  2        8   superscript  N  3      4  N  d               superscript  N  4     6   superscript  N  2   S    superscript  S  2        4   superscript  N  3      4  N  S                 superscript  N  2      superscript  N  2     6  S      superscript  S  2      4  N     superscript  N  2   S        \sqrt{S}\approx N+\frac{d}{2N}-\frac{d^{2}}{8N^{3}+4Nd}=\frac{8N^{4}+8N^{2}d+d%
 ^{2}}{8N^{3}+4Nd}=\frac{N^{4}+6N^{2}S+S^{2}}{4N^{3}+4NS}=\frac{N^{2}(N^{2}+6S)%
 +S^{2}}{4N(N^{2}+S)}     Example  Find    9.2345      9.2345    \sqrt{9.2345}         N  =  3      N  3    N=3\,\!         d  =   9.2345  -   3  2    =  0.2345        d    9.2345   superscript  3  2         0.2345     d=9.2345-3^{2}=0.2345\,\!         P  =   0.2345   2  ×  3    =  0.0391        P    0.2345    2  3         0.0391     P=\frac{0.2345}{2\times 3}=0.0391         A  =   3  +  0.0391   =  3.0391        A    3  0.0391        3.0391     A=3+0.0391=3.0391\,\!          9.2345   ≈   3.0391  -    0.0391  2    2  ×  3.0391     ≈  3.0388          9.2345     3.0391     superscript  0.0391  2     2  3.0391          3.0388     \sqrt{9.2345}\approx 3.0391-\frac{0.0391^{2}}{2\times 3.0391}\approx 3.0388     Vedic duplex method for extracting a square root  The Vedic duplex method from the book ' Vedic Mathematics ' is a variant of the digit by digit method for calculating the square root. 5 The duplex is the square of the central digit plus double the cross-product of digits equidistant from the center. The duplex is computed from the quotient digits (square root digits) computed thus far, but after the initial digits. The duplex is subtracted from the dividend digit prior to the second subtraction for the product of the quotient digit times the divisor digit. For perfect squares the duplex and the dividend will get smaller and reach zero after a few steps. For non-perfect squares the decimal value of the square root can be calculated to any precision desired. However, as the decimal places proliferate, the duplex adjustment gets larger and longer to calculate. The duplex method follows the Vedic ideal for an algorithm, one-line, mental calculation. It is flexible in choosing the first digit group and the divisor. Small divisors are to be avoided by starting with a larger initial group.  Basic Principle  We proceed as with the digit-by-digit calculation by assuming that we want to express a number N as a square of the sum of n positive numbers as      N  =    (    a  0   +   a  1   +  …  +   a   n  -  1     )   2       N   superscript     subscript  a  0    subscript  a  1   normal-…   subscript  a    n  1     2     N=(a_{0}+a_{1}+\ldots+a_{n-1})^{2}           =    a  0  2   +   2   a  0     ∑   i  =  1    n  -  1     a  i     +   a  1  2   +   2   a  1     ∑   i  =  2    n  -  1     a  i     +  ⋯  +   a   n  -  1   2     .      absent     superscript   subscript  a  0   2     2   subscript  a  0     superscript   subscript     i  1      n  1     subscript  a  i      superscript   subscript  a  1   2     2   subscript  a  1     superscript   subscript     i  2      n  1     subscript  a  i     normal-⋯   superscript   subscript  a    n  1    2      =a_{0}^{2}+2a_{0}\sum_{i=1}^{n-1}a_{i}+a_{1}^{2}+2a_{1}\sum_{i=2}^{n-1}a_{i}+%
 \cdots+a_{n-1}^{2}.     Define divisor as    q  =   2   a  0        q    2   subscript  a  0      q=2a_{0}   and the duplex for a sequence of m numbers as       d  m   =   {       a   ⌈   m  /  2   ⌉   2   +     ∑   i  =  1    ⌊   m  /  2   ⌋      2   a  i    a    m  -  i   +  1           for    m   odd          ∑   i  =  1    m  /  2      2   a  i    a    m  -  i   +  1           for    m   even   .            subscript  d  m    cases     superscript   subscript  a      m  2     2     superscript   subscript     i  1        m  2       2   subscript  a  i    subscript  a      m  i   1         for  m  odd     superscript   subscript     i  1      m  2      2   subscript  a  i    subscript  a      m  i   1        for  m  even      d_{m}=\begin{cases}a_{\lceil m/2\rceil}^{2}+\sum_{i=1}^{\lfloor m/2\rfloor}2a_%
 {i}a_{m-i+1}&\mbox{for}\;m\;\mbox{odd}\\
 \sum_{i=1}^{m/2}2a_{i}a_{m-i+1}&\mbox{for}\;m\;\mbox{even}.\\
 \end{cases}     Thus, we can re-express the above identity in terms of the divisor and the duplexes as        N  -   a  0  2    =    ∑   i  =  1    n  -  1     (    q   a  i    +   d  i    )     .        N   superscript   subscript  a  0   2      superscript   subscript     i  1      n  1        q   subscript  a  i     subscript  d  i       N-a_{0}^{2}=\sum_{i=1}^{n-1}(qa_{i}+d_{i}).     Now the computation can proceed by recursively guessing the values of    a  m     subscript  a  m    a_{m}   so that        X  m   =    X   m  -  1    -   q   a  m    -   d  m     ,       subscript  X  m      subscript  X    m  1      q   subscript  a  m     subscript  d  m      X_{m}=X_{m-1}-qa_{m}-d_{m},   such that     X  m   ≥  0       subscript  X  m   0    X_{m}\geq 0   for all    1  ≤  m  ≤   n  -  1         1  m         n  1      1\leq m\leq n-1   , with initialization      X  0   =   N  -   a  0  2     .       subscript  X  0     N   superscript   subscript  a  0   2      X_{0}=N-a_{0}^{2}.   When     X  m   =  0       subscript  X  m   0    X_{m}=0   the algorithm terminates and the sum of    a  i     subscript  a  i    a_{i}   s give the square root. The method is more similar to long division where    X   m  -  1      subscript  X    m  1     X_{m-1}   is the dividend and    X  m     subscript  X  m    X_{m}   is the remainder.  For the case of decimal numbers, if      N  =    (     a  0   ⋅   10   n  -  1     +    a  1   ⋅   10   n  -  2     +  ⋯  +    a   n  -  2    ⋅  10   +   a   n  -  1     )   2       N   superscript     normal-⋅   subscript  a  0    superscript  10    n  1      normal-⋅   subscript  a  1    superscript  10    n  2     normal-⋯   normal-⋅   subscript  a    n  2    10    subscript  a    n  1     2     N=(a_{0}\cdot 10^{n-1}+a_{1}\cdot 10^{n-2}+\cdots+a_{n-2}\cdot 10+a_{n-1})^{2}   where     a  i   ∈   {  0  ,  1  ,  2  ,  …  ,  9  }        subscript  a  i    0  1  2  normal-…  9     a_{i}\in\{0,1,2,\ldots,9\}   , then the initiation     X  0   =   N  -    a  0  2   ⋅   10   2   (   n  -  1   )            subscript  X  0     N   normal-⋅   superscript   subscript  a  0   2    superscript  10    2    n  1         X_{0}=N-a_{0}^{2}\cdot 10^{2(n-1)}   and the divisor will be    q  =    2   a  0    ⋅   10   n  -  1         q   normal-⋅    2   subscript  a  0     superscript  10    n  1       q=2a_{0}\cdot 10^{n-1}   . Also the product at any m-th stage will be      q   a  m    ⋅   10   n  -  m  -  1     =    2   a  0    a  m    ⋅   10    2  n   -  m  -  2          normal-⋅    q   subscript  a  m     superscript  10    n  m  1      normal-⋅    2   subscript  a  0    subscript  a  m     superscript  10      2  n   m  2       qa_{m}\cdot 10^{n-m-1}=2a_{0}a_{m}\cdot 10^{2n-m-2}   and the duplexes will be     d  m   =     d  ~   m   ⋅   10    2  n   -  m  -  3          subscript  d  m    normal-⋅   subscript   normal-~  d   m    superscript  10      2  n   m  3       d_{m}=\tilde{d}_{m}\cdot 10^{2n-m-3}   , where     d  ~   m     subscript   normal-~  d   m    \tilde{d}_{m}   are the duplexes of the sequence     a  1   ,   a  2   ,  …  ,   a  m       subscript  a  1    subscript  a  2   normal-…   subscript  a  m     a_{1},a_{2},\ldots,a_{m}   . At any m-th stage, we see that the place value of the duplex     d  ~   m     subscript   normal-~  d   m    \tilde{d}_{m}   is one less than the product    2   a  0    a  m       2   subscript  a  0    subscript  a  m     2a_{0}a_{m}   . Thus, in actual calculations it is customary to subtract the duplex value of the m-th stage at (m+1)-th stage. Also, unlike the previous digit-by-digit square root calculation, where at any given m-th stage, the calculation is done by taking the most significant pair of digits of the remaining term    X   m  -  1      subscript  X    m  1     X_{m-1}   , the duplex method uses only a single most significant digit of    X   m  -  1      subscript  X    m  1     X_{m-1}   .  In other words, to calculate the duplex of a number, double the product of each pair of equidistant digits plus the square of the center digit (of the digits to the right of the colon).  Number => Calculation = Duplex  3 ==> 3 2 = 9  14 ==>2(1·4) = 8  574 ==> 2(5·4) + 7 2 = 89  1,421 ==> 2(1·1) + 2(4·2) = 2 + 16 = 18  10,523 ==> 2(1·3) + 2(0·2) + 5 2 = 6+0+25 = 31  406,739 ==> 2(4·9)+ 2(0·3)+ 2(6·7) = 72+0+84  = 156   In a square root calculation the quotient digit set increases incrementally for each step.  Example  Consider the perfect square 2809 = 53 2 . Use the duplex method to find the square root of 2,809.   Set down the number in groups of two digits .  Define a divisor , a dividend and a quotient to find the root .  Given 2809. Consider the first group, 28.  Find the nearest perfect square below that group.  The root of that perfect square is the first digit of our root .  Since 28 > 25 and 25 = 5 2 , take 5 as the first digit in the square root.  For the divisor take double this first digit (2 · 5), which is 10.   Next, set up a division framework with a colon.  28: 0 9 is the dividend and 5: is the quotient . ( Note: the quotient should always be a single digit number, and it should be such that the dividend in the next stage is non-negative. )  Put a colon to the right of 28 and 5 and keep the colons lined up vertically. The duplex is calculated only on quotient digits to the right of the colon.   Calculate the remainder . 28: minus 25: is 3:.  Append the remainder on the left of the next digit to get the new dividend.  Here, append 3 to the next dividend digit 0, which makes the new dividend 30. The divisor 10 goes into 30 just 3 times. (No reserve needed here for subsequent deductions.)   Repeat the operation.  The zero remainder appended to 9. Nine is the next dividend.  This provides a digit to the right of the colon so deduct the duplex, 3 2 = 9.  Subtracting this duplex from the dividend 9, a zero remainder results.  Ten into zero is zero. The next root digit is zero. The next duplex is 2(3·0) = 0.  The dividend is zero. This is an exact square root, 53.    Find the square root of 2809.  Set down the number in groups of two digits.  The number of groups gives the number of whole digits in the root.  Put a colon after the first group, 28, to separate it.  From the first group, 28, obtain the divisor, 10, since  28>25=5 2 and by doubling this first root, 2x5=10.  Gross dividend:     28:  0  9. Using mental math:  Divisor: 10)     3  0   Square: 10)  28: 3 0  9  Duplex, Deduction:     25: xx 09  Square root:  5:   3. 0  Dividend:         30 00  Remainder:      3: 00 00  Square Root, Quotient:      5:  3. 0  A two-variable iterative method  This method is applicable for finding the square root of    0  <  S  <  3        0  S       3     0   and converges best for    S  ≈  1      S  1    S\approx 1   . This, however, is no real limitation for a computer based calculation, as in base 2 floating point and fixed point representations, it is trivial to multiply   S   S   S\,\!   by an integer power of 4, and therefore    S      S    \sqrt{S}   by the corresponding power of 2, by changing the exponent or by shifting, respectively. Therefore,   S   S   S\,\!   can be moved to the range     1  2   ≤  S  <  2          1  2   S       2     \frac{1}{2}\leq S<2   . Moreover, the following method does not employ general divisions, but only additions, subtractions, multiplications, and divisions by powers of two, which are again trivial to implement. A disadvantage of the method is that numerical errors accumulate, in contrast to single variable iterative methods such as the Babylonian one.  The initialization step of this method is       a  0   =  S       subscript  a  0   S    a_{0}=S\,\!          c  0   =   S  -  1        subscript  c  0     S  1     c_{0}=S-1\,\!   while the iterative steps read       a   n  +  1    =    a  n   -     a  n    c  n    /  2         subscript  a    n  1       subscript  a  n        subscript  a  n    subscript  c  n    2      a_{n+1}=a_{n}-a_{n}c_{n}/2\,\!          c   n  +  1    =     c  n  2    (    c  n   -  3   )    /  4        subscript  c    n  1         superscript   subscript  c  n   2      subscript  c  n   3    4     c_{n+1}=c_{n}^{2}(c_{n}-3)/4\,\!   Then,     a  n   →   S      normal-→   subscript  a  n     S     a_{n}\rightarrow\sqrt{S}   (while     c  n   →  0     normal-→   subscript  c  n   0    c_{n}\rightarrow 0   ).  Note that the convergence of    c  n     subscript  c  n    c_{n}\,\!   , and therefore also of    a  n     subscript  a  n    a_{n}\,\!   , is quadratic.  The proof of the method is rather easy. First, rewrite the iterative definition of    c  n     subscript  c  n    c_{n}\,\!   as       1  +   c   n  +  1     =    (   1  +   c  n    )     (   1  -    c  n   /  2    )   2          1   subscript  c    n  1         1   subscript  c  n     superscript    1     subscript  c  n   2    2      1+c_{n+1}=(1+c_{n})(1-c_{n}/2)^{2}\,\!   . Then it is straightforward to prove by induction that       S   (   1  +   c  n    )    =   a  n  2         S    1   subscript  c  n      superscript   subscript  a  n   2     S(1+c_{n})=a_{n}^{2}   and therefore the convergence of    a  n     subscript  a  n    a_{n}\,\!   to the desired result    S      S    \sqrt{S}   is ensured by the convergence of    c  n     subscript  c  n    c_{n}\,\!   to 0, which in turn follows from     -  1   <   c  0   <  2          1    subscript  c  0        2     -1   .  This method was developed around 1950 by M. V. Wilkes , D. J. Wheeler and S. Gill 6 for use on EDSAC , one of the first electronic computers. 7 The method was later generalized, allowing the computation of non-square roots. 8  Iterative methods for reciprocal square roots  The following are iterative methods for finding the reciprocal square root of S which is    1  /   S       1    S     1/\sqrt{S}   . Once it has been found, find    S      S    \sqrt{S}   by simple multiplication     S   =   S  ⋅   (   1  /   S    )          S    normal-⋅  S    1    S       \sqrt{S}=S\cdot(1/\sqrt{S})   . These iterations involve only multiplication, and not division. They are therefore faster than the Babylonian method . However, they are not stable. If the initial value is not close to the reciprocal square root, the iterations will diverge away from it rather than converge to it. It can therefore be advantageous to perform an iteration of the Babylonian method on a rough estimate before starting to apply these methods.   Applying Newton's method to the equation      (   1  /   x  2    )   -  S   =  0          1   superscript  x  2    S   0    (1/x^{2})-S=0   produces a method that converges quadratically using three multiplications per step:         x   n  +  1    =     x  n   2   ⋅   (   3  -   S  ⋅   x  n  2     )     .       subscript  x    n  1     normal-⋅     subscript  x  n   2     3   normal-⋅  S   superscript   subscript  x  n   2        x_{n+1}=\frac{x_{n}}{2}\cdot(3-S\cdot x_{n}^{2}).      Another iteration is obtained by Halley's method , which is the Householder's method of order two. This converges cubically , but involves four multiplications per iteration:         y  n   =   S  ⋅    x  n  2      ,       subscript  y  n    normal-⋅  S   superscript   subscript  x  n   2      y_{n}=S\cdot x_{n}^{2}\,,\!           x   n  +  1    =     x  n   8   ⋅   (   15  -    y  n   ⋅   (   10  -   3  ⋅   y  n     )     )     .       subscript  x    n  1     normal-⋅     subscript  x  n   8     15   normal-⋅   subscript  y  n     10   normal-⋅  3   subscript  y  n          x_{n+1}=\frac{x_{n}}{8}\cdot(15-y_{n}\cdot(10-3\cdot y_{n})).     Goldschmidt’s algorithm  Some computers use Goldschmidt's algorithm to simultaneously calculate    S      S    \sqrt{S}   and    1  /   S       1    S     1/\sqrt{S}   . Goldschmidt's algorithm finds    S      S    \sqrt{S}   faster than Newton-Raphson iteration on a computer with a fused multiply–add instruction and either a pipelined floating point unit or two independent floating-point units. Two ways of writing Goldschmidt's algorithm are: 9       b  0   =  S       subscript  b  0   S    b_{0}=S          Y  0   ≈   1  /   S         subscript  Y  0     1    S      Y_{0}\approx 1/\sqrt{S}   (typically using a table lookup)       y  0   =   Y  0        subscript  y  0    subscript  Y  0     y_{0}=Y_{0}          x  0   =   S   y  0         subscript  x  0     S   subscript  y  0      x_{0}=Sy_{0}     Each iteration:       b   n  +  1    =    b  n    Y  n  2         subscript  b    n  1       subscript  b  n    superscript   subscript  Y  n   2      b_{n+1}=b_{n}Y_{n}^{2}          Y   n  +  1    =    (   3  -   b   n  +  1     )   /  2        subscript  Y    n  1        3   subscript  b    n  1     2     Y_{n+1}=(3-b_{n+1})/2          x   n  +  1    =    x  n    Y   n  +  1          subscript  x    n  1       subscript  x  n    subscript  Y    n  1       x_{n+1}=x_{n}Y_{n+1}          y   n  +  1    =    y  n    Y   n  +  1          subscript  y    n  1       subscript  y  n    subscript  Y    n  1       y_{n+1}=y_{n}Y_{n+1}     until    b  i     subscript  b  i    b_{i}   is sufficiently close to 1, or a fixed number of iterations.  which causes        S   =    lim   n  →  ∞     x  n     .        S     subscript    normal-→  n      subscript  x  n      \sqrt{S}=\lim_{n\to\infty}x_{n}.           1  /   S    =    lim   n  →  ∞     y  n     .        1    S      subscript    normal-→  n      subscript  y  n      1/\sqrt{S}=\lim_{n\to\infty}y_{n}.     Goldschmidt's equation can be rewritten as:       y  0   ≈   1  /   S         subscript  y  0     1    S      y_{0}\approx 1/\sqrt{S}   (typically using a table lookup)       x  0   =   S   y  0         subscript  x  0     S   subscript  y  0      x_{0}=Sy_{0}          h  0   =    y  0   /  2        subscript  h  0      subscript  y  0   2     h_{0}=y_{0}/2     Each iteration: (All 3 operations in this loop are in the form of a fused multiply–add .)       r  n   =    (   1  /  2   )   -    x  n    h  n          subscript  r  n       1  2      subscript  x  n    subscript  h  n       r_{n}=(1/2)-x_{n}h_{n}          x   n  +  1    =    x  n   +    x  n    r  n          subscript  x    n  1       subscript  x  n      subscript  x  n    subscript  r  n       x_{n+1}=x_{n}+x_{n}r_{n}          h   n  +  1    =    h  n   +    h  n    r  n          subscript  h    n  1       subscript  h  n      subscript  h  n    subscript  r  n       h_{n+1}=h_{n}+h_{n}r_{n}     until    r  i     subscript  r  i    r_{i}   is sufficiently close to 0, or a fixed number of iterations.  which causes        S   =    lim   n  →  ∞     x  n     .        S     subscript    normal-→  n      subscript  x  n      \sqrt{S}=\lim_{n\to\infty}x_{n}.           1  /   S    =    lim   n  →  ∞     2   h  n      .        1    S      subscript    normal-→  n       2   subscript  h  n       1/\sqrt{S}=\lim_{n\to\infty}2h_{n}.     Taylor series  If N is an approximation to    S      S    \sqrt{S}   , a better approximation can be found by using the Taylor series of the square root function:         N  2   +  d    =    ∑   n  =  0   ∞       (   -  1   )   n     (   2  n   )   !    d  n      (   1  -   2  n    )     n  !   2    4  n    N    2  n   -  1       =       N  +   d   2  N     -    d  2    8   N  3      +    d  3    16   N  5      -    5   d  4     128   N  7      +  ⋯              superscript  N  2   d      superscript   subscript     n  0           superscript    1   n       2  n     superscript  d  n        1    2  n     superscript    n   2    superscript  4  n    superscript  N      2  n   1                      N    d    2  N        superscript  d  2     8   superscript  N  3         superscript  d  3     16   superscript  N  5          5   superscript  d  4      128   superscript  N  7      normal-⋯      \sqrt{N^{2}+d}=\sum_{n=0}^{\infty}\frac{(-1)^{n}(2n)!d^{n}}{(1-2n)n!^{2}4^{n}N%
 ^{2n-1}}=N+\frac{d}{2N}-\frac{d^{2}}{8N^{3}}+\frac{d^{3}}{16N^{5}}-\frac{5d^{4%
 }}{128N^{7}}+\cdots     As an iterative method, the order of convergence is equal to the number of terms used. With 2 terms, it is identical to the Babylonian method ; With 3 terms, each iteration takes almost as many operations as the Bakhshali approximation , but converges more slowly. Therefore, this is not a particularly efficient way of calculation. To maximize the rate of convergence, choose N so that      |  d  |    N  2          d    superscript  N  2     \frac{|d|}{N^{2}}\,   is as small as possible.  Other methods  Other methods are less efficient than the ones presented above.  A completely different method for computing the square root is based on the CORDIC algorithm, which uses only very simple operations (addition, subtraction, bitshift and table lookup, but no multiplication). The square root of S may be obtained as the output    x  n     subscript  x  n    x_{n}   using the hyperbolic coordinate system in vectoring mode, with the following initialization: 10       x  0   =   S  +  1        subscript  x  0     S  1     x_{0}=S+1          y  0   =   S  -  1        subscript  y  0     S  1     y_{0}=S-1          ω  0   =  0       subscript  ω  0   0    \omega_{0}=0     Continued fraction expansion  Quadratic irrationals (numbers of the form     a  +   b    c        a    b    c    \frac{a+\sqrt{b}}{c}   , where a , b and c are integers), and in particular, square roots of integers, have periodic continued fractions . Sometimes what is desired is finding not the numerical value of a square root, but rather its continued fraction expansion. The following iterative algorithm can be used for this purpose ( S is any natural number that is not a perfect square ):       m  0   =  0       subscript  m  0   0    m_{0}=0\,\!          d  0   =  1       subscript  d  0   1    d_{0}=1\,\!          a  0   =   ⌊   S   ⌋        subscript  a  0       S      a_{0}=\left\lfloor\sqrt{S}\right\rfloor\,\!          m   n  +  1    =     d  n    a  n    -   m  n         subscript  m    n  1         subscript  d  n    subscript  a  n     subscript  m  n      m_{n+1}=d_{n}a_{n}-m_{n}\,\!          d   n  +  1    =    S  -   m   n  +  1   2     d  n         subscript  d    n  1        S   superscript   subscript  m    n  1    2     subscript  d  n      d_{n+1}=\frac{S-m_{n+1}^{2}}{d_{n}}\,\!           a   n  +  1    =   ⌊     S   +   m   n  +  1      d   n  +  1     ⌋   =   ⌊     a  0   +   m   n  +  1      d   n  +  1     ⌋    .         subscript  a    n  1            S    subscript  m    n  1      subscript  d    n  1                  subscript  a  0    subscript  m    n  1      subscript  d    n  1         a_{n+1}=\left\lfloor\frac{\sqrt{S}+m_{n+1}}{d_{n+1}}\right\rfloor=\left\lfloor%
 \frac{a_{0}+m_{n+1}}{d_{n+1}}\right\rfloor\!.     Notice that m n , d n , and a n are always integers. The algorithm terminates when this triplet is the same as one encountered before. The algorithm can also terminate on a i when a i = 2 a 0 , 11 which is easier to implement.  The expansion will repeat from then on. The sequence [ a 0 ; a 1 , a 2 , a 3 , …] is the continued fraction expansion:       S   =    a  0   +   1    a  1   +    1    a  2   +    1    a  3   +  ⋱                 S      subscript  a  0    continued-fraction  1     subscript  a  1    continued-fraction  1     subscript  a  2    continued-fraction  1     subscript  a  3   normal-⋱           \sqrt{S}=a_{0}+\cfrac{1}{a_{1}+\cfrac{1}{a_{2}+\cfrac{1}{a_{3}+\,\ddots}}}     Example, square root of 114 as a continued fraction  Begin with m 0 = 0; d 0 = 1; and a 0 = 10 (10 2 = 100 and 11 2 = 121 > 114 so 10 chosen).      114      114    \displaystyle\sqrt{114}          m  1   =     d  0   ⋅   a  0    -   m  0    =    1  ⋅  10   -  0   =  10 .         subscript  m  1      normal-⋅   subscript  d  0    subscript  a  0     subscript  m  0            normal-⋅  1  10   0        10 .     m_{1}=d_{0}\cdot a_{0}-m_{0}=1\cdot 10-0=10\,.          d  1   =    S  -   m  1  2     d  0    =    114  -   10  2    1   =  14 .         subscript  d  1       S   superscript   subscript  m  1   2     subscript  d  0             114   superscript  10  2    1        14 .     d_{1}=\frac{S-m_{1}^{2}}{d_{0}}=\frac{114-10^{2}}{1}=14\,.          a  1   =   ⌊     a  0   +   m  1     d  1    ⌋   =   ⌊    10  +  10   14   ⌋   =   ⌊   20  14   ⌋   =  1 .         subscript  a  1          subscript  a  0    subscript  m  1     subscript  d  1                10  10   14             20  14         1 .     a_{1}=\left\lfloor\frac{a_{0}+m_{1}}{d_{1}}\right\rfloor=\left\lfloor\frac{10+%
 10}{14}\right\rfloor=\left\lfloor\frac{20}{14}\right\rfloor=1\,.     So, m 1 = 10; d 1 = 14; and a 1 = 1.          114   +  10   14   =   1  +     114   -  4   14    =   1  +    114  -  16    14   (    114   +  4   )      =   1  +   1     114   +  4   7      .              114   10   14     1        114   4   14           1      114  16     14      114   4             1    1        114   4   7        \frac{\sqrt{114}+10}{14}=1+\frac{\sqrt{114}-4}{14}=1+\frac{114-16}{14(\sqrt{11%
 4}+4)}=1+\frac{1}{\frac{\sqrt{114}+4}{7}}.     Next, m 2 = 4; d 2 = 7; and a 2 = 2.          114   +  4   7   =   2  +     114   -  10   7    =   2  +   14   7   (    114   +  10   )      =   2  +   1     114   +  10   2      .              114   4   7     2        114   10   7           2    14    7      114   10             2    1        114   10   2        \frac{\sqrt{114}+4}{7}=2+\frac{\sqrt{114}-10}{7}=2+\frac{14}{7(\sqrt{114}+10)}%
 =2+\frac{1}{\frac{\sqrt{114}+10}{2}}.             114   +  10   2   =   10  +     114   -  10   2    =   10  +   14   2   (    114   +  10   )      =   10  +   1     114   +  10   7      .              114   10   2     10        114   10   2           10    14    2      114   10             10    1        114   10   7        \frac{\sqrt{114}+10}{2}=10+\frac{\sqrt{114}-10}{2}=10+\frac{14}{2(\sqrt{114}+1%
 0)}=10+\frac{1}{\frac{\sqrt{114}+10}{7}}.             114   +  10   7   =   2  +     114   -  4   7    =   2  +   98   7   (    114   +  4   )      =   2  +   1     114   +  4   14      .              114   10   7     2        114   4   7           2    98    7      114   4             2    1        114   4   14        \frac{\sqrt{114}+10}{7}=2+\frac{\sqrt{114}-4}{7}=2+\frac{98}{7(\sqrt{114}+4)}=%
 2+\frac{1}{\frac{\sqrt{114}+4}{14}}.             114   +  4   14   =   1  +     114   -  10   14    =   1  +   14   14   (    114   +  10   )      =   1  +   1     114   +  10   1      .              114   4   14     1        114   10   14           1    14    14      114   10             1    1        114   10   1        \frac{\sqrt{114}+4}{14}=1+\frac{\sqrt{114}-10}{14}=1+\frac{14}{14(\sqrt{114}+1%
 0)}=1+\frac{1}{\frac{\sqrt{114}+10}{1}}.             114   +  10   1   =   20  +     114   -  10   1    =   20  +   14    114   +  10     =   20  +   1     114   +  10   14      .              114   10   1     20        114   10   1           20    14      114   10            20    1        114   10   14        \frac{\sqrt{114}+10}{1}=20+\frac{\sqrt{114}-10}{1}=20+\frac{14}{\sqrt{114}+10}%
 =20+\frac{1}{\frac{\sqrt{114}+10}{14}}.     Now, loop back to the second equation above.  Consequently, the simple continued fraction for the square root of 114 is        114   =   [  10  ;  1  ,  2  ,  10  ,  2  ,  1  ,  20  ,  1  ,  2  ,  10  ,  2  ,  1  ,  20  ,  1  ,  2  ,  10  ,  2  ,  1  ,  20  ,  …  ]    .        114    10  1  2  10  2  1  20  1  2  10  2  1  20  1  2  10  2  1  20  normal-…     \sqrt{114}=[10;1,2,10,2,1,20,1,2,10,2,1,20,1,2,10,2,1,20,\dots].\,     Its actual value is approximately 10.67707 82520 31311 21....  Generalized continued fraction  A more rapid method is to evaluate its generalized continued fraction . From the formula derived there :       z   =     x  2   +  y    =   x  +   y    2  x   +    y    2  x   +    y    2  x   +  ⋱           =   x  +     2  x   ⋅  y     2   (    2  z   -  y   )    -  y  -     y  2     2   (    2  z   -  y   )    -     y  2     2   (    2  z   -  y   )    -  ⋱                   z        superscript  x  2   y           x   continued-fraction  y      2  x    continued-fraction  y      2  x    continued-fraction  y      2  x   normal-⋱                x   continued-fraction   normal-⋅    2  x   y       2      2  z   y    y   continued-fraction   superscript  y  2       2      2  z   y     continued-fraction   superscript  y  2       2      2  z   y    normal-⋱            \sqrt{z}=\sqrt{x^{2}+y}=x+\cfrac{y}{2x+\cfrac{y}{2x+\cfrac{y}{2x+\ddots}}}=x+%
 \cfrac{2x\cdot y}{2(2z-y)-y-\cfrac{y^{2}}{2(2z-y)-\cfrac{y^{2}}{2(2z-y)-\ddots%
 }}}     and the fact that 114 is 2/3 of the way between 10 2 =100 and 11 2 =121 results in        114   =    1026   3   =      32  2   +  2    3   =    32  3   +    2  /  3    64  +    2   64  +    2   64  +    2   64  +  ⋱              =    32  3   +   2   192  +    18   192  +    18   192  +  ⋱            ,          114    continued-fraction    1026   3         continued-fraction       superscript  32  2   2    3           continued-fraction  32  3    continued-fraction    2  3     64   continued-fraction  2    64   continued-fraction  2    64   continued-fraction  2    64  normal-⋱                   continued-fraction  32  3    continued-fraction  2    192   continued-fraction  18    192   continued-fraction  18    192  normal-⋱            \sqrt{114}=\cfrac{\sqrt{1026}}{3}=\cfrac{\sqrt{32^{2}+2}}{3}=\cfrac{32}{3}+%
 \cfrac{2/3}{64+\cfrac{2}{64+\cfrac{2}{64+\cfrac{2}{64+\ddots}}}}=\cfrac{32}{3}%
 +\cfrac{2}{192+\cfrac{18}{192+\cfrac{18}{192+\ddots}}},     which is simply the aforementioned [10;1,2, 10,2,1, 20,1,2, 10,2,1, 20,1,2, ...] evaluated at every third term. Combining pairs of fractions produces        114   =      32  2   +  2    3   =    32  3   +    64  /  3    2050  -  1  -    1   2050  -    1   2050  -  ⋱           =    32  3   +   64   6150  -  3  -    9   6150  -    9   6150  -  ⋱            ,          114    continued-fraction       superscript  32  2   2    3           continued-fraction  32  3    continued-fraction    64  3     2050  1   continued-fraction  1    2050   continued-fraction  1    2050  normal-⋱                 continued-fraction  32  3    continued-fraction  64    6150  3   continued-fraction  9    6150   continued-fraction  9    6150  normal-⋱            \sqrt{114}=\cfrac{\sqrt{32^{2}+2}}{3}=\cfrac{32}{3}+\cfrac{64/3}{2050-1-\cfrac%
 {1}{2050-\cfrac{1}{2050-\ddots}}}=\cfrac{32}{3}+\cfrac{64}{6150-3-\cfrac{9}{61%
 50-\cfrac{9}{6150-\ddots}}},     which is now [10;1,2, 10,2,1,20,1,2, 10,2,1,20,1,2, ...] evaluated at the third term and every six terms thereafter.  Pell's equation  Pell's equation (also known as Brahmagupta equation since he was the first to give a solution to this particular equation) and its variants yield a method for efficiently finding continued fraction convergents of square roots of integers. However, it can be complicated to execute, and usually not every convergent is generated. The ideas behind the method are as follows:   If ( p , q ) is a solution (where p and q are integers) to the equation     p  2   =    S  ⋅   q  2    ±   1         superscript  p  2    plus-or-minus   normal-⋅  S   superscript  q  2    1     p^{2}=S\cdot q^{2}\pm 1\!   , then    p  q      p  q    \frac{p}{q}   is a continued fraction convergent of    S      S    \sqrt{S}   , and as such, is an excellent rational approximation to it.  If ( p a , q a ) and ( p b , q b ) are solutions, then so is:         p  =     p  a    p  b    +    S  ⋅   q  a     q  b         p       subscript  p  a    subscript  p  b       normal-⋅  S   subscript  q  a     subscript  q  b       p=p_{a}p_{b}+S\cdot q_{a}q_{b}\,\!         q  =     p  a    q  b    +    p  b    q  a         q       subscript  p  a    subscript  q  b       subscript  p  b    subscript  q  a       q=p_{a}q_{b}+p_{b}q_{a}\,\!       (compare to the multiplication of quadratic integers )    More generally, if ( p 1 , q 1 ) is a solution, then it is possible to generate a sequence of solutions ( p n , q n ) satisfying:          p   m  +  n    =     p  m    p  n    +    S  ⋅   q  m     q  n          subscript  p    m  n         subscript  p  m    subscript  p  n       normal-⋅  S   subscript  q  m     subscript  q  n       p_{m+n}=p_{m}p_{n}+S\cdot q_{m}q_{n}\,\!          q   m  +  n    =     p  m    q  n    +    p  n    q  m          subscript  q    m  n         subscript  p  m    subscript  q  n       subscript  p  n    subscript  q  m       q_{m+n}=p_{m}q_{n}+p_{n}q_{m}\,\!        The method is as follows:   Find positive integers p 1 and q 1 such that     p  1  2   =    S  ⋅   q  1  2    ±  1        superscript   subscript  p  1   2    plus-or-minus   normal-⋅  S   superscript   subscript  q  1   2    1     p_{1}^{2}=S\cdot q_{1}^{2}\pm 1   . This is the hard part; It can be done either by guessing, or by using fairly sophisticated techniques.   :*To generate a long list of convergents, iterate:         p   n  +  1    =     p  1    p  n    +    S  ⋅   q  1     q  n          subscript  p    n  1         subscript  p  1    subscript  p  n       normal-⋅  S   subscript  q  1     subscript  q  n       p_{n+1}=p_{1}p_{n}+S\cdot q_{1}q_{n}\,\!          q   n  +  1    =     p  1    q  n    +    p  n    q  1          subscript  q    n  1         subscript  p  1    subscript  q  n       subscript  p  n    subscript  q  1       q_{n+1}=p_{1}q_{n}+p_{n}q_{1}\,\!        :*To find the larger convergents quickly, iterate:         p   2  n    =    p  n  2   +   S  ⋅   q  n  2          subscript  p    2  n       superscript   subscript  p  n   2    normal-⋅  S   superscript   subscript  q  n   2       p_{2n}=p_{n}^{2}+S\cdot q_{n}^{2}\,\!          q   2  n    =   2   p  n    q  n         subscript  q    2  n      2   subscript  p  n    subscript  q  n      q_{2n}=2p_{n}q_{n}\,\!        Notice that the corresponding sequence of fractions coincides with the one given by the Hero's method starting with     p  1    q  1        subscript  p  1    subscript  q  1     \textstyle\frac{p_{1}}{q_{1}}   .      In either case,     p  n    q  n        subscript  p  n    subscript  q  n     \frac{p_{n}}{q_{n}}   is a rational approximation satisfying           |     p  n    q  n    -   S    |   <   1    q  n  2   ⋅   S      .             subscript  p  n    subscript  q  n      S       1   normal-⋅   superscript   subscript  q  n   2     S       \left|\frac{p_{n}}{q_{n}}-\sqrt{S}\right|<\frac{1}{q_{n}^{2}\cdot\sqrt{S}}.        Approximations that depend on the floating point representation  A number is represented in a floating point format as    m  ×   b  p       m   superscript  b  p     m\times b^{p}   which is also called scientific notation . Its square root is     m   ×   b   p  /  2          m    superscript  b    p  2      \sqrt{m}\times b^{p/2}   and similar formulae would apply for cube roots and logarithms. On the face of it, this is no improvement in simplicity, but suppose that only an approximation is required: then just    b   p  /  2      superscript  b    p  2     b^{p/2}   is good to an order of magnitude. Next, recognise that some powers, p , will be odd, thus for 3141.59 = 3.14159x10 3 rather than deal with fractional powers of the base, multiply the mantissa by the base and subtract one from the power to make it even. The adjusted representation will become the equivalent of 31.4159x10 2 so that the square root will be √31.4159 x 10.  If the integer part of the adjusted mantissa is taken, there can only be the values 1 to 99, and that could be used as an index into a table of 99 pre-computed square roots to complete the estimate. A computer using base sixteen would require a larger table, but one using base two would require only three entries: the possible bits of the integer part of the adjusted mantissa are 01 (the power being even so there was no shift, remembering that a normalised floating point number always has a non-zero high-order digit) or if the power was odd, 10 or 11, these being the first two bits of the original mantissa. Thus, 6.25 = 110.01 in binary, normalised to 1.1001 x 2 2 an even power so the paired bits of the mantissa are 01, while .625 = 0.101 in binary normalises to 1.01 x 2 −1 an odd power so the adjustment is to 10.1 x 2 −2 and the paired bits are 10. Notice that the low order bit of the power is echoed in the high order bit of the pairwise mantissa. An even power has its low-order bit zero and the adjusted mantissa will start with 0, whereas for an odd power that bit is one and the adjusted mantissa will start with 1. Thus, when the power is halved, it is as if its low order bit is shifted out to become the first bit of the pairwise mantissa.  A table with only three entries could be enlarged by incorporating additional bits of the mantissa. However, with computers, rather than calculate an interpolation into a table, it is often better to find some simpler calculation giving equivalent results. Everything now depends on the exact details of the format of the representation, plus what operations are available to access and manipulate the parts of the number. For example, Fortran offers an EXPONENT(x) function to obtain the power. Effort expended in devising a good initial approximation is to be recouped by thereby avoiding the additional iterations of the refinement process that would have been needed for a poor approximation. Since these are few (one iteration requires a divide, an add, and a halving) the constraint is severe.  Many computers follow the IEEE (or sufficiently similar) representation, and a very rapid approximation to the square root can be obtained for starting Newton's method. The technique that follows is based on the fact that the floating point format (in base two) approximates the base-2 logarithm. That is      log  2    (   m  ×   2  p    )    =   p  +    log  2    (  m  )           subscript   2     m   superscript  2  p       p    subscript   2   m      \log_{2}(m\times 2^{p})=p+\log_{2}(m)     So for a 32-bit single precision floating point number in IEEE format (where notably, the power has a bias of 127 added for the represented form) you can get the approximate logarithm by interpreting its binary representation as a 32-bit integer, scaling it by    2   -  23      superscript  2    23     2^{-23}   , and removing a bias of 127, i.e.          x  int   ⋅   2   -  23     -  127   ≈    log  2    (  x  )     .         normal-⋅   subscript  x  int    superscript  2    23     127     subscript   2   x     x_{\text{int}}\cdot 2^{-23}-127\approx\log_{2}(x).     For example, 1.0 is represented by a hexadecimal number 0x3F800000, which would represent    1065353216  =   127  ⋅   2  23        1065353216   normal-⋅  127   superscript  2  23      1065353216=127\cdot 2^{23}   if taken as an integer. Using the formula above you get      1065353216  ⋅   2   -  23     -  127   =  0         normal-⋅  1065353216   superscript  2    23     127   0    1065353216\cdot 2^{-23}-127=0   , as expected from     log  2    (  1.0  )       subscript   2   1.0    \log_{2}(1.0)   . In a similar fashion you get 0.5 from 1.5 (0x3FC00000).  (Figure)  Log2approx.png   To get the square root, divide the logarithm by 2 and convert the value back. The following program demonstrates the idea. Note that the exponent's lowest bit is intentionally allowed to propagate into the mantissa. One way to justify the steps in this program is to assume   b   b   b   is the exponent bias and   n   n   n   is the number of explicitly stored bits in the mantissa and then show that         (    (    (     x  int   /   2  n    -  b   )   /  2   )   +  b   )   ⋅   2  n    =     (    x  int   -   2  n    )   /  2   +    (    (   b  +  1   )   /  2   )   ⋅   2  n      .       normal-⋅           subscript  x  int    superscript  2  n    b   2   b    superscript  2  n           subscript  x  int    superscript  2  n    2    normal-⋅      b  1   2    superscript  2  n       (((x_{\text{int}}/2^{n}-b)/2)+b)\cdot 2^{n}=(x_{\text{int}}-2^{n})/2+((b+1)/2)%
 \cdot 2^{n}.      /* Assumes that float is in the IEEE 754 single precision floating point format  * and that int is 32 bits. */  float sqrt_approx( float z)
 { int val_int = *( int *)&z; /* Same bits, but as an int */  /*  * To justify the following code, prove that  *  * ((((val_int / 2^m) - b) / 2) + b) * 2^m = ((val_int - 2^m) / 2) + ((b + 1) / 2) * 2^m)  *  * where  *  * b = exponent bias  * m = number of mantissa bits  *  * .  */ val_int -= 1 << 23 ; /* Subtract 2^m. */ val_int >>= 1 ; /* Divide by 2. */ val_int += 1 << 29 ; /* Add ((b + 1) / 2) * 2^m. */  return *( float *)&val;_int; /* Interpret again as float */ }  The three mathematical operations forming the core of the above function can be expressed in a single line. An additional adjustment can be added to reduce the maximum relative error. So, the three operations, not including the cast, can be rewritten as  val_int = ( 1 << 29 ) + (val_int >> 1 ) - ( 1 << 22 ) + a;  where a is a bias for adjusting the approximation errors. For example, with a = 0 the results are accurate for even powers of 2 (e.g., 1.0), but for other numbers the results will be slightly too big (e.g.,1.5 for 2.0 instead of 1.414... with 6% error). With a = -0x4C000, the errors are between about -3.5% and 3.5%.  If the approximation is to be used for an initial guess for Newton's method to the equation      (   1  /   x  2    )   -  S   =  0          1   superscript  x  2    S   0    (1/x^{2})-S=0   , then the reciprocal form shown in the following section is preferred.  Reciprocal of the square root  A variant of the above routine is included below, which can be used to compute the reciprocal of the square root, i.e.,    x   -   1  2       superscript  x      1  2      x^{-{1\over 2}}   instead, was written by Greg Walsh, and implemented into SGI Indigo by Gary Tarolli. 12 13 The integer-shift approximation produced a relative error of less than 4%, and the error dropped further to 0.15% with one iteration of Newton's method on the following line. 14 In computer graphics it is a very efficient way to normalize a vector.  float invSqrt( float x)
 { float xhalf = 0. 5f*x; union { float x; int i;
         } u;
         u.x = x;
         u.i = 0x5f3759df - (u.i >> 1 ); /* The next line can be repeated any number of times to increase accuracy */ u.x = u.x * ( 1. 5f - xhalf * u.x * u.x); return u.x;
 }  Some VLSI hardware implements inverse square root using a second degree polynomial estimation followed by a Goldschmidt iteration . 15  Negative or complex square  If S \sqrt {S} = \sqrt {\vert S \vert} \, \, i \,.  If S = a + bi where a and b are real and b ≠ 0, then its principal square root is        S   =        |  S  |   +  a   2     +    sgn   (  b  )         |  S  |   -  a   2      i      .        S             S   a   2       sgn  b           S   a   2    i      \sqrt{S}=\sqrt{\frac{|S|+a}{2}}\,+\,\operatorname{sgn}(b)\sqrt{\frac{|S|-a}{2}%
 }\,\,i\,.     This can be verified by squaring the root. 16 17 Here       |  S  |   =     a  2   +   b  2           S        superscript  a  2    superscript  b  2       |S|=\sqrt{a^{2}+b^{2}}     is the modulus of S . The principal square root of a complex number is defined to be the root with the non-negative real part.  See also   Alpha max plus beta min algorithm  Integer square root  Mental calculation  n th root algorithm  Recurrence relation  Shifting nth-root algorithm  Square root of 2   Notes  External links    Square roots by subtraction  Integer Square Root Algorithm by Andrija Radović  Personal Calculator Algorithms I : Square Roots (William E. Egbert), Hewlett-Packard Journal (may 1977) : page 22  Calculator to learn the square root   "  Category:Root-finding algorithms  Category:Computer arithmetic algorithms     There is no direct evidence showing how the Babylonians computed square roots, although there are informed conjectures. ( Square root of 2#Notes gives a summary and references.) ↩  ↩  Fast integer square root by Mr. Woo's abacus algorithm ↩  Integer Square Root function ↩  ↩  M. V. Wilkes, D. J. Wheeler and S. Gill, "The Preparation of Programs for an Electronic Digital Computer", Addison-Wesley, 1951. ↩  M. Campbell-Kelly, "Origin of Computing", Scientific American, September 2009. ↩  J. C. Gower, "A Note on an Iterative Method for Root Extraction", The Computer Journal 1(3):142–143, 1958. ↩  ↩  ↩  ↩  ↩  ↩  Fast Inverse Square Root by Chris Lomont ↩  "High-Speed Double-Precision Computation of Reciprocal, Division, Square Root and Inverse Square Root" by José-Alejandro Piñeiro and Javier Díaz Bruguera 2002 (abstract) ↩  , Section 3.7.26, p. 17 ↩  , [ http://books.google.com/books?id=lUcTsYopfhkC&pg; ;=PA59 Extract: page 59] ↩    