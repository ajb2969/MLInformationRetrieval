   Cross product      Cross product   In mathematics , the cross product or vector product is a binary operation on two vectors in three-dimensional space and is denoted by the symbol ×. The cross product a × b of two linearly independent vectors a and b is a vector that is perpendicular to both and therefore normal to the plane containing them. It has many applications in mathematics, physics , engineering , and computer programming .  If two vectors have the same direction (or have the exact opposite direction from one another, i.e. are not linearly independent) or if either one has zero length, then their cross product is zero. More generally, the magnitude of the product equals the area of a parallelogram with the vectors for sides; in particular, the magnitude of the product of two perpendicular vectors is the product of their lengths. The cross product is anticommutative (i.e. ) and is distributive over addition (i.e. ). The space R 3 together with the cross product is an algebra over the real numbers , which is neither commutative nor associative , but is a Lie algebra with the cross product being the Lie bracket.  Like the dot product , it depends on the metric of Euclidean space, but unlike the dot product, it also depends on a choice of orientation or "handedness". The product can be generalized in various ways; it can be made independent of orientation by changing the result to pseudovector , or in arbitrary dimensions the exterior product of vectors can be used with a bivector or two-form result. Also, using the orientation and metric structure just as for the traditional 3-dimensional cross product, one can in n dimensions take the product of  vectors to produce a vector perpendicular to all of them. But if the product is limited to non-trivial binary products with vector results, it exists only in three and seven dimensions . 1 If one adds the further requirement that the product be uniquely defined, then only the 3-dimensional cross product qualifies. (See § Generalizations , below, for other dimensions.)  Definition  The cross product of two vectors a and b is defined only in three-dimensional space and is denoted by . In physics , sometimes the notation  is used, 2 though this is avoided in mathematics to avoid confusion with the exterior product .  The cross product  is defined as a vector c that is perpendicular to both a and b , with a direction given by the right-hand rule and a magnitude equal to the area of the parallelogram that the vectors span.  The cross product is defined by the formula 3 4       𝐚  ×  𝐛   =    ∥  𝐚  ∥    ∥  𝐛  ∥    sin    θ   𝐧           𝐚  𝐛      norm  𝐚    norm  𝐛       θ  𝐧       \mathbf{a}\times\mathbf{b}=\left\|\mathbf{a}\right\|\left\|\mathbf{b}\right\|%
 \sin\theta\ \mathbf{n}     where θ is the angle between a and b in the plane containing them (hence, it is between 0° and 180°), ‖ a ‖ and ‖ b ‖ are the magnitudes of vectors a and b , and n is a unit vector  perpendicular to the plane containing a and b in the direction given by the right-hand rule (illustrated). If the vectors a and b are parallel (i.e., the angle θ between them is either 0° or 180°), by the above formula, the cross product of a and b is the zero vector  0 .  (Figure)  The cross product  (vertical, in purple) changes as the angle between the vectors a (blue) and b (red) changes. The cross product is always perpendicular to both vectors, and has magnitude zero when the vectors are parallel and maximum magnitude ‖ a ‖‖ b ‖ when they are perpendicular.   By convention, the direction of the vector n is given by the right-hand rule, where one simply points the forefinger of the right hand in the direction of a and the middle finger in the direction of b . Then, the vector n is coming out of the thumb (see the picture on the right). Using this rule implies that the cross-product is anti-commutative , i.e., . By pointing the forefinger toward b first, and then pointing the middle finger toward a , the thumb will be forced in the opposite direction, reversing the sign of the product vector.  Using the cross product requires the handedness of the coordinate system to be taken into account (as explicit in the definition above). If a left-handed coordinate system is used, the direction of the vector n is given by the left-hand rule and points in the opposite direction.  This, however, creates a problem because transforming from one arbitrary reference system to another (e.g., a mirror image transformation from a right-handed to a left-handed coordinate system), should not change the direction of n . The problem is clarified by realizing that the cross product of two vectors is not a (true) vector, but rather a pseudovector . See cross product and handedness for more detail.  Names  upright=1.25|thumb|right|According to Sarrus' rule , the determinant of a 3×3 matrix involves multiplications between matrix elements identified by crossed diagonals  In 1881, Josiah Willard Gibbs , and independently Oliver Heaviside , introduced both the dot product and the cross product using a period () and an "x" (), respectively, to denote them. 5  In 1877, to emphasize the fact that the result of a dot product is a scalar while the result of a cross product is a vector , William Kingdon Clifford coined the alternative names scalar product and vector product for the two operations. 6 These alternative names are still widely used in the literature.  Both the cross notation () and the name cross product were possibly inspired by the fact that each scalar component of  is computed by multiplying non-corresponding components of a and b . Conversely, a dot product  involves multiplications between corresponding components of a and b . As explained below , the cross product can be expressed in the form of a determinant of a special 3×3 matrix. According to Sarrus' rule , this involves multiplications between matrix elements identified by crossed diagonals.  Computing the cross product  Coordinate notation  The standard basis vectors i , j , and k satisfy the following equalities:     𝐢   𝐢   \displaystyle\mathbf{i}     which imply, by the anticommutativity of the cross product, that      𝐤  ×  𝐣      𝐤  𝐣    \displaystyle\mathbf{k\times j}     The definition of the cross product also implies that       𝐢  ×  𝐢   =   𝐣  ×  𝐣   =   𝐤  ×  𝐤   =  𝟎          𝐢  𝐢     𝐣  𝐣          𝐤  𝐤        0     \mathbf{i}\times\mathbf{i}=\mathbf{j}\times\mathbf{j}=\mathbf{k}\times\mathbf{%
 k}=\mathbf{0}   (the zero vector ).  These equalities, together with the distributivity and linearity of the cross product (but both do not follow easily from the definition given above), are sufficient to determine the cross product of any two vectors u and v . Each vector can be defined as the sum of three orthogonal components parallel to the standard basis vectors:     𝐮   𝐮   \displaystyle\mathbf{u}     Their cross product  can be expanded using distributivity:       𝐮  ×  𝐯   =         𝐮  𝐯   absent    \displaystyle\mathbf{u}\times\mathbf{v}=     This can be interpreted as the decomposition of  into the sum of nine simpler cross products involving vectors aligned with i , j , or k . Each one of these nine cross products operates on two vectors that are easy to handle as they are either parallel or orthogonal to each other. From this decomposition, by using the above-mentioned equalities and collecting similar terms, we obtain:       𝐮  ×  𝐯   =         𝐮  𝐯   absent    \displaystyle\mathbf{u}\times\mathbf{v}=     meaning that the three scalar components of the resulting vector s = s 1 i + s 2 j + s 3 k =  are      s  1     subscript  s  1    \displaystyle s_{1}     Using column vectors , we can represent the same result as follows:       (      s  1        s  2        s  3      )   =   (        u  2    v  3    -    u  3    v  2            u  3    v  1    -    u  1    v  3            u  1    v  2    -    u  2    v  1        )          subscript  s  1      subscript  s  2      subscript  s  3            subscript  u  2    subscript  v  3       subscript  u  3    subscript  v  2            subscript  u  3    subscript  v  1       subscript  u  1    subscript  v  3            subscript  u  1    subscript  v  2       subscript  u  2    subscript  v  1         \begin{pmatrix}s_{1}\\
 s_{2}\\
 s_{3}\end{pmatrix}=\begin{pmatrix}u_{2}v_{3}-u_{3}v_{2}\\
 u_{3}v_{1}-u_{1}v_{3}\\
 u_{1}v_{2}-u_{2}v_{1}\end{pmatrix}     Matrix notation  The cross product can also be expressed as the formal 7  determinant :       𝐮  ×  𝐯   =   |     𝐢    𝐣    𝐤       u  1      u   ;  2       u   ;  3         v  1      v   ;  2       v   ;  3       |         𝐮  𝐯       𝐢  𝐣  𝐤     subscript  u  1    fragments  u   subscript  normal-;  2     fragments  u   subscript  normal-;  3       subscript  v  1    fragments  v   subscript  normal-;  2     fragments  v   subscript  normal-;  3         \mathbf{u\times v}=\begin{vmatrix}\mathbf{i}&\mathbf{j}&\mathbf{k}\\
 u_{1}&u_{2}&u_{3}\\
 v_{1}&v_{2}&v_{3}\\
 \end{vmatrix}   This determinant can be computed using Sarrus' rule or cofactor expansion . Using Sarrus' rule, it expands to        𝐮  ×  𝐯   =    (     u  2    v  3   𝐢   +    u  3    v  1   𝐣   +    u  1    v  2   𝐤    )   -   (     u  3    v  2   𝐢   +    u  1    v  3   𝐣   +    u  2    v  1   𝐤    )     .        𝐮  𝐯          subscript  u  2    subscript  v  3   𝐢      subscript  u  3    subscript  v  1   𝐣      subscript  u  1    subscript  v  2   𝐤         subscript  u  3    subscript  v  2   𝐢      subscript  u  1    subscript  v  3   𝐣      subscript  u  2    subscript  v  1   𝐤       \mathbf{u\times v}=(u_{2}v_{3}\mathbf{i}+u_{3}v_{1}\mathbf{j}+u_{1}v_{2}%
 \mathbf{k})-(u_{3}v_{2}\mathbf{i}+u_{1}v_{3}\mathbf{j}+u_{2}v_{1}\mathbf{k}).   Using cofactor expansion along the first row instead, it expands to 8       𝐮  ×  𝐯   =      |      u  2      u   ;  3         v  2      v   ;  3       |   𝐢   -    |      u  1      u   ;  3         v  1      v   ;  3       |   𝐣    +    |      u  1      u   ;  2         v  1      v   ;  2       |   𝐤          𝐮  𝐯              subscript  u  2    fragments  u   subscript  normal-;  3       subscript  v  2    fragments  v   subscript  normal-;  3       𝐢          subscript  u  1    fragments  u   subscript  normal-;  3       subscript  v  1    fragments  v   subscript  normal-;  3       𝐣           subscript  u  1    fragments  u   subscript  normal-;  2       subscript  v  1    fragments  v   subscript  normal-;  2       𝐤      \mathbf{u\times v}=\begin{vmatrix}u_{2}&u_{3}\\
 v_{2}&v_{3}\end{vmatrix}\mathbf{i}-\begin{vmatrix}u_{1}&u_{3}\\
 v_{1}&v_{3}\end{vmatrix}\mathbf{j}+\begin{vmatrix}u_{1}&u_{2}\\
 v_{1}&v_{2}\end{vmatrix}\mathbf{k}   which gives the components of the resulting vector directly.  Properties  Geometric meaning    The magnitude of the cross product can be interpreted as the positive area of the parallelogram having a and b as sides (see Figure 1):       A  =   ∥   𝐚  ×  𝐛   ∥   =    ∥  𝐚  ∥    ∥  𝐛  ∥    sin  θ     .        A   norm    𝐚  𝐛            norm  𝐚    norm  𝐛     θ       A=\left\|\mathbf{a}\times\mathbf{b}\right\|=\left\|\mathbf{a}\right\|\left\|%
 \mathbf{b}\right\|\sin\theta.\,\!     Indeed, one can also compute the volume V of a parallelepiped having a , b and c as sides by using a combination of a cross product and a dot product, called scalar triple product (see Figure 2):        𝐚  ⋅   (   𝐛  ×  𝐜   )    =   𝐛  ⋅   (   𝐜  ×  𝐚   )    =   𝐜  ⋅   (   𝐚  ×  𝐛   )     .         normal-⋅  𝐚    𝐛  𝐜     normal-⋅  𝐛    𝐜  𝐚          normal-⋅  𝐜    𝐚  𝐛       \mathbf{a}\cdot(\mathbf{b}\times\mathbf{c})=\mathbf{b}\cdot(\mathbf{c}\times%
 \mathbf{a})=\mathbf{c}\cdot(\mathbf{a}\times\mathbf{b}).     Since the result of the scalar triple product may be negative, the volume of the parallelepiped is given by its absolute value. For instance,       V  =   |   𝐚  ⋅   (   𝐛  ×  𝐜   )    |    .      V     normal-⋅  𝐚    𝐛  𝐜       V=|\mathbf{a}\cdot(\mathbf{b}\times\mathbf{c})|.     Because the magnitude of the cross product goes by the sine of the angle between its arguments, the cross product can be thought of as a measure of perpendicularity in the same way that the dot product is a measure of parallelism . Given two unit vectors , their cross product has a magnitude of 1 if the two are perpendicular and a magnitude of zero if the two are parallel. The converse is true for the dot product of two unit vectors.  Unit vectors enable two convenient identities: the dot product of two unit vectors yields the cosine (which may be positive or negative) of the angle between the two unit vectors. The magnitude of the cross product of the two unit vectors yields the sine (which will always be positive).  Algebraic properties  (Figure)  Cross product distributivity over vector addition. The vectors b and c are resolved into parallel and perpendicular components to a : parallel components vanish in the cross product, perpendicular ones remain. The planes indicate the axial vectors normal to those planes, and are not  bivectors . 9    If the cross product of two vectors is the zero vector (i.e. ), then either one or both of the inputs is the zero vector, ( and/or ) or else they are parallel or antiparallel () so that the sine of the angle between them is zero ( or  and ).    The self cross product of a vector is the zero vector, i.e., .    The cross product is anticommutative ,         𝐚  ×  𝐛   =   -   𝐛  ×  𝐚     ,        𝐚  𝐛       𝐛  𝐚      \mathbf{a}\times\mathbf{b}=-\mathbf{b}\times\mathbf{a},      distributive over addition,         𝐚  ×   (   𝐛  +  𝐜   )    =    (   𝐚  ×  𝐛   )   +   (   𝐚  ×  𝐜   )     ,        𝐚    𝐛  𝐜        𝐚  𝐛     𝐚  𝐜      \mathbf{a}\times(\mathbf{b}+\mathbf{c})=(\mathbf{a}\times\mathbf{b})+(\mathbf{%
 a}\times\mathbf{c}),      and compatible with scalar multiplication so that          (   r  𝐚   )   ×  𝐛   =   𝐚  ×   (   r  𝐛   )    =   r   (   𝐚  ×  𝐛   )     .            r  𝐚   𝐛     𝐚    r  𝐛           r    𝐚  𝐛       (r\mathbf{a})\times\mathbf{b}=\mathbf{a}\times(r\mathbf{b})=r(\mathbf{a}\times%
 \mathbf{b}).      It is not associative , but satisfies the Jacobi identity :         𝐚  ×   (   𝐛  ×  𝐜   )    +   𝐛  ×   (   𝐜  ×  𝐚   )    +   𝐜  ×   (   𝐚  ×  𝐛   )     =  0.          𝐚    𝐛  𝐜      𝐛    𝐜  𝐚      𝐜    𝐚  𝐛     0.    \mathbf{a}\times(\mathbf{b}\times\mathbf{c})+\mathbf{b}\times(\mathbf{c}\times%
 \mathbf{a})+\mathbf{c}\times(\mathbf{a}\times\mathbf{b})=\mathbf{0}.     Distributivity, linearity and Jacobi identity show that the R 3  vector space together with vector addition and the cross product forms a Lie algebra , the Lie algebra of the real orthogonal group in 3 dimensions, SO(3) .   The cross product does not obey the cancellation law : that is,  with  does not imply , but only that:      𝟎   0   \displaystyle\mathbf{0}     From the definition of the cross product, the angle between a and  must be zero, and these vectors must be parallel. That is, they are related by a scale factor t , leading to:       𝐜  =   𝐛  +   t  𝐚     ,      𝐜    𝐛    t  𝐚      \mathbf{c}=\mathbf{b}+t\mathbf{a},     for some scalar t .   If  and , for non-zero vector a , then , as        𝐚  ×   (   𝐛  -  𝐜   )    =  𝟎        𝐚    𝐛  𝐜    0    \mathbf{a}\times(\mathbf{b}-\mathbf{c})=\mathbf{0}   and        𝐚  ⋅   (   𝐛  -  𝐜   )    =  0   ,       normal-⋅  𝐚    𝐛  𝐜    0    \mathbf{a}\cdot(\mathbf{b}-\mathbf{c})=0,     so  is both parallel and perpendicular to the non-zero vector a , something that is only possible if  so they are identical.   From the geometrical definition, the cross product is invariant under proper rotations about the axis defined by . In formulae:         (   R  𝐚   )   ×   (   R  𝐛   )    =   R   (   𝐚  ×  𝐛   )            R  𝐚     R  𝐛      R    𝐚  𝐛      (R\mathbf{a})\times(R\mathbf{b})=R(\mathbf{a}\times\mathbf{b})   , where   R   R   R   is a rotation matrix with     det   (  R  )    =  1        R   1    \det(R)=1   .  More generally, the cross product obeys the following identity under matrix transformations:        (   M  𝐚   )   ×   (   M  𝐛   )    =    (   det  M   )    M   -  T     (   𝐚  ×  𝐛   )            M  𝐚     M  𝐛        M    superscript  M    T      𝐚  𝐛      (M\mathbf{a})\times(M\mathbf{b})=(\det M)M^{-T}(\mathbf{a}\times\mathbf{b})     where   M   M   \scriptstyle M   is a 3-by-3 matrix and    M   -  T      superscript  M    T     \scriptstyle M^{-T}   is the transpose of the inverse . It can be readily seen how this formula reduces to the former one if   M   M   \scriptstyle M   is a rotation matrix.   The cross product of two vectors lies in the null space of the 2×3 matrix with the vectors as rows:         𝐚  ×  𝐛   ∈   N  S   (   [     𝐚      𝐛     ]   )     .        𝐚  𝐛     N  S    𝐚    𝐛       \mathbf{a}\times\mathbf{b}\in NS\left(\begin{bmatrix}\mathbf{a}\\
 \mathbf{b}\end{bmatrix}\right).      For the sum of two cross products, the following identity holds:          𝐚  ×  𝐛   +   𝐜  ×  𝐝    =     (   𝐚  -  𝐜   )   ×   (   𝐛  -  𝐝   )    +   𝐚  ×  𝐝   +   𝐜  ×  𝐛     .          𝐚  𝐛     𝐜  𝐝          𝐚  𝐜     𝐛  𝐝      𝐚  𝐝     𝐜  𝐛      \mathbf{a}\times\mathbf{b}+\mathbf{c}\times\mathbf{d}=(\mathbf{a}-\mathbf{c})%
 \times(\mathbf{b}-\mathbf{d})+\mathbf{a}\times\mathbf{d}+\mathbf{c}\times%
 \mathbf{b}.     Differentiation  The product rule of differential calculus applies to any bilinear operation, and therefore also to the cross product:        d   d  t     (   𝐚  ×  𝐛   )    =      d  𝐚    d  t    ×  𝐛   +   𝐚  ×    d  𝐛    d  t              d    d  t      𝐚  𝐛            d  𝐚     d  t    𝐛     𝐚      d  𝐛     d  t        \frac{d}{dt}(\mathbf{a}\times\mathbf{b})=\frac{d\mathbf{a}}{dt}\times\mathbf{b%
 }+\mathbf{a}\times\frac{d\mathbf{b}}{dt}   where a and b are vectors that depend on the real variable t .  Triple product expansion  The cross product is used in both forms of the triple product. The scalar triple product of three vectors is defined as       𝐚  ⋅   (   𝐛  ×  𝐜   )    ,     normal-⋅  𝐚    𝐛  𝐜     \mathbf{a}\cdot(\mathbf{b}\times\mathbf{c}),     It is the signed volume of the parallelepiped with edges a , b and c and as such the vectors can be used in any order that's an even permutation of the above ordering. The following therefore are equal:        𝐚  ⋅   (   𝐛  ×  𝐜   )    =   𝐛  ⋅   (   𝐜  ×  𝐚   )    =   𝐜  ⋅   (   𝐚  ×  𝐛   )     ,         normal-⋅  𝐚    𝐛  𝐜     normal-⋅  𝐛    𝐜  𝐚          normal-⋅  𝐜    𝐚  𝐛       \mathbf{a}\cdot(\mathbf{b}\times\mathbf{c})=\mathbf{b}\cdot(\mathbf{c}\times%
 \mathbf{a})=\mathbf{c}\cdot(\mathbf{a}\times\mathbf{b}),     The vector triple product is the cross product of a vector with the result of another cross product, and is related to the dot product by the following formula        𝐚  ×   (   𝐛  ×  𝐜   )    =    𝐛   (   𝐚  ⋅  𝐜   )    -   𝐜   (   𝐚  ⋅  𝐛   )      .        𝐚    𝐛  𝐜        𝐛   normal-⋅  𝐚  𝐜      𝐜   normal-⋅  𝐚  𝐛       \mathbf{a}\times(\mathbf{b}\times\mathbf{c})=\mathbf{b}(\mathbf{a}\cdot\mathbf%
 {c})-\mathbf{c}(\mathbf{a}\cdot\mathbf{b}).     The mnemonic "BAC minus CAB" is used to remember the order of the vectors in the right hand member. This formula is used in physics to simplify vector calculations. A special case, regarding gradients and useful in vector calculus , is      ∇  ×   (   ∇  ×  𝐟   )       normal-∇    normal-∇  𝐟     \displaystyle\nabla\times(\nabla\times\mathbf{f})   where ∇ 2 is the vector Laplacian operator.  Other identities relate the cross product to the scalar triple product:        (   𝐚  ×  𝐛   )   ×   (   𝐚  ×  𝐜   )    =    (   𝐚  ⋅   (   𝐛  ×  𝐜   )    )   𝐚           𝐚  𝐛     𝐚  𝐜       normal-⋅  𝐚    𝐛  𝐜    𝐚     (\mathbf{a}\times\mathbf{b})\times(\mathbf{a}\times\mathbf{c})=(\mathbf{a}%
 \cdot(\mathbf{b}\times\mathbf{c}))\mathbf{a}           (   𝐚  ×  𝐛   )   ⋅   (   𝐜  ×  𝐝   )    =    𝐛  T    (     (    𝐜  T   𝐚   )   I   -   𝐜𝐚  T    )   𝐝        normal-⋅    𝐚  𝐛     𝐜  𝐝       superscript  𝐛  T          superscript  𝐜  T   𝐚   I    superscript  𝐜𝐚  T    𝐝     (\mathbf{a}\times\mathbf{b})\cdot(\mathbf{c}\times\mathbf{d})=\mathbf{b}^{T}((%
 \mathbf{c}^{T}\mathbf{a})I-\mathbf{c}\mathbf{a}^{T})\mathbf{d}   , where I is the identity matrix.  Alternative formulation  The cross product and the dot product are related by:         ∥   𝐚  ×  𝐛   ∥   2   =      ∥  𝐚  ∥   2     ∥  𝐛  ∥   2    -    (   𝐚  ⋅  𝐛   )   2     .       superscript   norm    𝐚  𝐛    2        superscript   norm  𝐚   2    superscript   norm  𝐛   2     superscript   normal-⋅  𝐚  𝐛   2      \left\|\mathbf{a}\times\mathbf{b}\right\|^{2}=\left\|\mathbf{a}\right\|^{2}%
 \left\|\mathbf{b}\right\|^{2}-(\mathbf{a}\cdot\mathbf{b})^{2}.   The right-hand side is the Gram determinant of a and b , the square of the area of the parallelogram defined by the vectors. This condition determines the magnitude of the cross product. Namely, since the dot product is defined, in terms of the angle θ between the two vectors, as:        𝐚  ⋅  𝐛   =    ∥  𝐚  ∥    ∥  𝐛  ∥    cos  θ     ,       normal-⋅  𝐚  𝐛      norm  𝐚    norm  𝐛     θ      \mathbf{a\cdot b}=\left\|\mathbf{a}\right\|\left\|\mathbf{b}\right\|\cos\theta,     the above given relationship can be rewritten as follows:         ∥   𝐚  ×  𝐛   ∥   2   =     ∥  𝐚  ∥   2     ∥  𝐛  ∥   2    (   1  -    cos  2   θ    )     .       superscript   norm    𝐚  𝐛    2      superscript   norm  𝐚   2    superscript   norm  𝐛   2     1    superscript   2   θ       \left\|\mathbf{a\times b}\right\|^{2}=\left\|\mathbf{a}\right\|^{2}\left\|%
 \mathbf{b}\right\|^{2}\left(1-\cos^{2}\theta\right).     Invoking the Pythagorean trigonometric identity one obtains:        ∥   𝐚  ×  𝐛   ∥   =    ∥  𝐚  ∥    ∥  𝐛  ∥    |   sin  θ   |     ,       norm    𝐚  𝐛       norm  𝐚    norm  𝐛       θ       \left\|\mathbf{a}\times\mathbf{b}\right\|=\left\|\mathbf{a}\right\|\left\|%
 \mathbf{b}\right\|\left|\sin\theta\right|,     which is the magnitude of the cross product expressed in terms of θ , equal to the area of the parallelogram defined by a and b (see definition above).  The combination of this requirement and the property that the cross product be orthogonal to its constituents a and b provides an alternative definition of the cross product. 10  Lagrange's identity  The relation:         ∥   𝐚  ×  𝐛   ∥   2   =   det   [      𝐚  ⋅  𝐚      𝐚  ⋅  𝐛        𝐚  ⋅  𝐛      𝐛  ⋅  𝐛      ]    =      ∥  𝐚  ∥   2     ∥  𝐛  ∥   2    -    (   𝐚  ⋅  𝐛   )   2     .         superscript   norm    𝐚  𝐛    2        normal-⋅  𝐚  𝐚    normal-⋅  𝐚  𝐛      normal-⋅  𝐚  𝐛    normal-⋅  𝐛  𝐛                superscript   norm  𝐚   2    superscript   norm  𝐛   2     superscript   normal-⋅  𝐚  𝐛   2       \left\|\mathbf{a}\times\mathbf{b}\right\|^{2}=\det\begin{bmatrix}\mathbf{a}%
 \cdot\mathbf{a}&\mathbf{a}\cdot\mathbf{b}\\
 \mathbf{a}\cdot\mathbf{b}&\mathbf{b}\cdot\mathbf{b}\\
 \end{bmatrix}=\left\|\mathbf{a}\right\|^{2}\left\|\mathbf{b}\right\|^{2}-(%
 \mathbf{a}\cdot\mathbf{b})^{2}.   can be compared with another relation involving the right-hand side, namely Lagrange's identity expressed as: 11         ∑   1  ≤  i  <  j  ≤  n      (     a  i    b  j    -    a  j    b  i     )   2    =      ∥  𝐚  ∥   2     ∥  𝐛  ∥   2    -     (   𝐚  ⋅  𝐛   )   2      ,        subscript       1  i       j       n      superscript       subscript  a  i    subscript  b  j       subscript  a  j    subscript  b  i     2         superscript   norm  𝐚   2    superscript   norm  𝐛   2     superscript   normal-⋅  𝐚  𝐛   2      \sum_{1\leq i     where a and b may be n -dimensional vectors. This also shows that the Riemannian volume form for surfaces is exactly the surface element from vector calculus. In the case where , combining these two equations results in the expression for the magnitude of the cross product in terms of its components: 12         |   𝐚  ×  𝐛   |   2   =    ∑   1  ≤  i  <  j  ≤  3      (     a  i    b  j    -    a  j    b  i     )   2    =     (     a  1    b  2    -    b  1    a  2     )   2   +    (     a  2    b  3    -    a  3    b  2     )   2   +     (     a  3    b  1    -    a  1    b  3     )   2      .         superscript      𝐚  𝐛    2     subscript       1  i       j       3      superscript       subscript  a  i    subscript  b  j       subscript  a  j    subscript  b  i     2            superscript       subscript  a  1    subscript  b  2       subscript  b  1    subscript  a  2     2    superscript       subscript  a  2    subscript  b  3       subscript  a  3    subscript  b  2     2    superscript       subscript  a  3    subscript  b  1       subscript  a  1    subscript  b  3     2       |\mathbf{a}\times\mathbf{b}|^{2}=\sum_{1\leq i     The same result is found directly using the components of the cross-product found from:        𝐚  ×  𝐛   =   det   [     𝐢    𝐣    𝐤       a  1      a  2      a  3        b  1      b  2      b  3      ]     .        𝐚  𝐛       𝐢  𝐣  𝐤     subscript  a  1    subscript  a  2    subscript  a  3      subscript  b  1    subscript  b  2    subscript  b  3        \mathbf{a}\times\mathbf{b}=\det\begin{bmatrix}\mathbf{i}&\mathbf{j}&\mathbf{k}%
 \\
 a_{1}&a_{2}&a_{3}\\
 b_{1}&b_{2}&b_{3}\\
 \end{bmatrix}.     In R 3 Lagrange's equation is a special case of the multiplicativity | vw | = | v || w | of the norm in the quaternion algebra .  It is a special case of another formula, also sometimes called Lagrange's identity, which is the three dimensional case of the Binet-Cauchy identity : 13 14         (   𝐚  ×  𝐛   )   ⋅   (   𝐜  ×  𝐝   )    =     (   𝐚  ⋅  𝐜   )    (   𝐛  ⋅  𝐝   )    -    (   𝐚  ⋅  𝐝   )    (   𝐛  ⋅  𝐜   )      .       normal-⋅    𝐚  𝐛     𝐜  𝐝         normal-⋅  𝐚  𝐜    normal-⋅  𝐛  𝐝       normal-⋅  𝐚  𝐝    normal-⋅  𝐛  𝐜       (\mathbf{a}\times\mathbf{b})\cdot(\mathbf{c}\times\mathbf{d})=(\mathbf{a}\cdot%
 \mathbf{c})(\mathbf{b}\cdot\mathbf{d})-(\mathbf{a}\cdot\mathbf{d})(\mathbf{b}%
 \cdot\mathbf{c}).     If  and  this simplifies to the formula above.  Infinitesimal generators of rotations  The cross product conveniently describes the infinitesimal generators of rotations in R 3 . Specifically, if n is a unit vector in R 3 and R (φ, n ) denotes a rotation about the axis through the origin specified by n , with angle φ (measured in radians, counterclockwise when viewed from the tip of n ), then          d   d  ϕ    |    ϕ  =  0    R   (  ϕ  ,  𝒏  )   𝒙   =   𝒏  ×  𝒙          evaluated-at    d    d  ϕ      ϕ  0    R   ϕ  𝒏   𝒙     𝒏  𝒙     \left.{d\over d\phi}\right|_{\phi=0}R(\phi,\boldsymbol{n})\boldsymbol{x}=%
 \boldsymbol{n}\times\boldsymbol{x}   for every vector x in R 3 . The cross product with n therefore describes the infinitesimal generator of the rotations about n . These infinitesimal generators form the Lie algebra  so(3) of the rotation group SO(3) , and we obtain the result that the Lie algebra R 3 with cross product is isomorphic to the Lie algebra so(3) .  Alternative ways to compute the cross product  Conversion to matrix multiplication  The vector cross product also can be expressed as the product of a skew-symmetric matrix and a vector: 15       𝐚  ×  𝐛   =     [  𝐚  ]   ×   𝐛   =    [     0     -   a  3        a   2         a   3     0     -   a  1         -   a  2        a   1     0     ]    [      b  1        b  2        b  3      ]            𝐚  𝐛      subscript   delimited-[]  𝐚     𝐛            0     subscript  a  3     subscript  a  2      subscript  a  3   0     subscript  a  1         subscript  a  2     subscript  a  1   0       subscript  b  1      subscript  b  2      subscript  b  3         \mathbf{a}\times\mathbf{b}=[\mathbf{a}]_{\times}\mathbf{b}=\begin{bmatrix}\,0&%
 \!-a_{3}&\,\,a_{2}\\
 \,\,a_{3}&0&\!-a_{1}\\
 -a_{2}&\,\,a_{1}&\,0\end{bmatrix}\begin{bmatrix}b_{1}\\
 b_{2}\\
 b_{3}\end{bmatrix}          𝐚  ×  𝐛   =     [  𝐛  ]   ×  T   𝐚   =    [     0      b   3      -   b  2         -   b  3      0      b   1         b   2      -   b  1      0     ]    [      a  1        a  2        a  3      ]            𝐚  𝐛      superscript   subscript   delimited-[]  𝐛     normal-T   𝐚            0   subscript  b  3      subscript  b  2         subscript  b  3    0   subscript  b  1      subscript  b  2      subscript  b  1    0       subscript  a  1      subscript  a  2      subscript  a  3         \mathbf{a}\times\mathbf{b}=[\mathbf{b}]_{\times}^{\mathrm{T}}\mathbf{a}=\begin%
 {bmatrix}\,0&\,\,b_{3}&\!-b_{2}\\
 -b_{3}&0&\,\,b_{1}\\
 \,\,b_{2}&\!-b_{1}&\,0\end{bmatrix}\begin{bmatrix}a_{1}\\
 a_{2}\\
 a_{3}\end{bmatrix}     where superscript T refers to the transpose operation, and [ a ] × is defined by:         [  𝐚  ]   ×    =  def    [     0     -   a  3        a   2         a   3     0     -   a  1         -   a  2        a   1     0     ]    .      superscript   def    subscript   delimited-[]  𝐚       0     subscript  normal-a  3     subscript  normal-a  2      subscript  normal-a  3   0     subscript  normal-a  1         subscript  normal-a  2     subscript  normal-a  1   0      [\mathbf{a}]_{\times}\stackrel{\rm def}{=}\begin{bmatrix}\,\,0&\!-a_{3}&\,\,\,%
 a_{2}\\
 \,\,\,a_{3}&0&\!-a_{1}\\
 \!-a_{2}&\,\,a_{1}&\,\,0\end{bmatrix}.     It should be noted that [ a ] × is a singular matrix where a is its (right and left) null-vector.  Also, if a is itself a cross product:      𝐚  =   𝐜  ×  𝐝       𝐚    𝐜  𝐝     \mathbf{a}=\mathbf{c}\times\mathbf{d}     then         [  𝐚  ]   ×   =    𝐝𝐜  T   -   𝐜𝐝  T     .       subscript   delimited-[]  𝐚        superscript  𝐝𝐜  normal-T    superscript  𝐜𝐝  normal-T      [\mathbf{a}]_{\times}=\mathbf{d}\mathbf{c}^{\mathrm{T}}-\mathbf{c}\mathbf{d}^{%
 \mathrm{T}}.           Proof by substitution       Evaluation of the cross product gives      𝐚  =   𝐜  ×  𝐝   =   (        c  2    d  3    -    c  3    d  2            c  3    d  1    -    c  1    d  3            c  1    d  2    -    c  2    d  1        )         𝐚    𝐜  𝐝               subscript  c  2    subscript  d  3       subscript  c  3    subscript  d  2            subscript  c  3    subscript  d  1       subscript  c  1    subscript  d  3            subscript  c  1    subscript  d  2       subscript  c  2    subscript  d  1          \mathbf{a}=\mathbf{c}\times\mathbf{d}=\begin{pmatrix}c_{2}d_{3}-c_{3}d_{2}\\
 c_{3}d_{1}-c_{1}d_{3}\\
 c_{1}d_{2}-c_{2}d_{1}\end{pmatrix}   Hence, the left hand side equals        [  𝐚  ]   ×   =   [     0       c  2    d  1    -    c  1    d  2          c  3    d  1    -    c  1    d  3            c  1    d  2    -    c  2    d  1       0       c  3    d  2    -    c  2    d  3            c  1    d  3    -    c  3    d  1          c  2    d  3    -    c  3    d  2       0     ]        subscript   delimited-[]  𝐚       0       subscript  c  2    subscript  d  1       subscript  c  1    subscript  d  2          subscript  c  3    subscript  d  1       subscript  c  1    subscript  d  3            subscript  c  1    subscript  d  2       subscript  c  2    subscript  d  1     0       subscript  c  3    subscript  d  2       subscript  c  2    subscript  d  3            subscript  c  1    subscript  d  3       subscript  c  3    subscript  d  1          subscript  c  2    subscript  d  3       subscript  c  3    subscript  d  2     0      [\mathbf{a}]_{\times}=\begin{bmatrix}0&c_{2}d_{1}-c_{1}d_{2}&c_{3}d_{1}-c_{1}d%
 _{3}\\
 c_{1}d_{2}-c_{2}d_{1}&0&c_{3}d_{2}-c_{2}d_{3}\\
 c_{1}d_{3}-c_{3}d_{1}&c_{2}d_{3}-c_{3}d_{2}&0\end{bmatrix}   Now, for the right hand side,       𝐜𝐝  T   =   [       c  1    d  1        c  1    d  2        c  1    d  3          c  2    d  1        c  2    d  2        c  2    d  3          c  3    d  1        c  3    d  2        c  3    d  3       ]        superscript  𝐜𝐝  normal-T        subscript  c  1    subscript  d  1       subscript  c  1    subscript  d  2       subscript  c  1    subscript  d  3         subscript  c  2    subscript  d  1       subscript  c  2    subscript  d  2       subscript  c  2    subscript  d  3         subscript  c  3    subscript  d  1       subscript  c  3    subscript  d  2       subscript  c  3    subscript  d  3        \mathbf{c}\mathbf{d}^{\mathrm{T}}=\begin{bmatrix}c_{1}d_{1}&c_{1}d_{2}&c_{1}d_%
 {3}\\
 c_{2}d_{1}&c_{2}d_{2}&c_{2}d_{3}\\
 c_{3}d_{1}&c_{3}d_{2}&c_{3}d_{3}\end{bmatrix}   And its transpose is       𝐝𝐜  T   =   [       c  1    d  1        c  2    d  1        c  3    d  1          c  1    d  2        c  2    d  2        c  3    d  2          c  1    d  3        c  2    d  3        c  3    d  3       ]        superscript  𝐝𝐜  normal-T        subscript  c  1    subscript  d  1       subscript  c  2    subscript  d  1       subscript  c  3    subscript  d  1         subscript  c  1    subscript  d  2       subscript  c  2    subscript  d  2       subscript  c  3    subscript  d  2         subscript  c  1    subscript  d  3       subscript  c  2    subscript  d  3       subscript  c  3    subscript  d  3        \mathbf{d}\mathbf{c}^{\mathrm{T}}=\begin{bmatrix}c_{1}d_{1}&c_{2}d_{1}&c_{3}d_%
 {1}\\
 c_{1}d_{2}&c_{2}d_{2}&c_{3}d_{2}\\
 c_{1}d_{3}&c_{2}d_{3}&c_{3}d_{3}\end{bmatrix}   Evaluation of the right hand side gives        𝐝𝐜  T   -   𝐜𝐝  T    =   [     0       c  2    d  1    -    c  1    d  2          c  3    d  1    -    c  1    d  3            c  1    d  2    -    c  2    d  1       0       c  3    d  2    -    c  2    d  3            c  1    d  3    -    c  3    d  1          c  2    d  3    -    c  3    d  2       0     ]          superscript  𝐝𝐜  normal-T    superscript  𝐜𝐝  normal-T      0       subscript  c  2    subscript  d  1       subscript  c  1    subscript  d  2          subscript  c  3    subscript  d  1       subscript  c  1    subscript  d  3            subscript  c  1    subscript  d  2       subscript  c  2    subscript  d  1     0       subscript  c  3    subscript  d  2       subscript  c  2    subscript  d  3            subscript  c  1    subscript  d  3       subscript  c  3    subscript  d  1          subscript  c  2    subscript  d  3       subscript  c  3    subscript  d  2     0      \mathbf{d}\mathbf{c}^{\mathrm{T}}-\mathbf{c}\mathbf{d}^{\mathrm{T}}=\begin{%
 bmatrix}0&c_{2}d_{1}-c_{1}d_{2}&c_{3}d_{1}-c_{1}d_{3}\\
 c_{1}d_{2}-c_{2}d_{1}&0&c_{3}d_{2}-c_{2}d_{3}\\
 c_{1}d_{3}-c_{3}d_{1}&c_{2}d_{3}-c_{3}d_{2}&0\end{bmatrix}   Comparison shows that the left hand side equals the right hand side.       This result can be generalized to higher dimensions using geometric algebra . In particular in any dimension bivectors can be identified with skew-symmetric matrices, so the product between a skew-symmetric matrix and vector is equivalent to the grade-1 part of the product of a bivector and vector. In three dimensions bivectors are dual to vectors so the product is equivalent to the cross product, with the bivector instead of its vector dual. In higher dimensions the product can still be calculated but bivectors have more degrees of freedom and are not equivalent to vectors.  This notation is also often much easier to work with, for example, in epipolar geometry .  From the general properties of the cross product follows immediately that          [  𝐚  ]   ×    𝐚   =  𝟎         subscript   delimited-[]  𝐚     𝐚   0    [\mathbf{a}]_{\times}\,\mathbf{a}=\mathbf{0}   and       𝐚  T      [  𝐚  ]   ×    =  𝟎         superscript  𝐚  normal-T    subscript   delimited-[]  𝐚      0    \mathbf{a}^{\mathrm{T}}\,[\mathbf{a}]_{\times}=\mathbf{0}     and from fact that [ a ] × is skew-symmetric it follows that         𝐛  T       [  𝐚  ]   ×    𝐛   =  0.         superscript  𝐛  normal-T    subscript   delimited-[]  𝐚     𝐛   0.    \mathbf{b}^{\mathrm{T}}\,[\mathbf{a}]_{\times}\,\mathbf{b}=0.     The above-mentioned triple product expansion (bac–cab rule) can be easily proven using this notation.  As mentioned above, the Lie algebra R 3 with cross product is isomorphic to the Lie algebra so(3) , whose elements can be identified with the 3×3 skew-symmetric matrices . The map a → [ a ] × provides an isomorphism between R 3 and so(3) . Under this map, the cross product of 3-vectors corresponds to the commutator of 3x3 skew-symmetric matrices.  Index notation for tensors  The cross product can alternatively be defined in terms of the Levi-Civita symbol ε ijk and a dot product η mi (= δ mi for an orthonormal basis), which are useful in converting vector notation for tensor applications:        𝐚  ×  𝐛   =  𝐜   ⇔    c  m   =    ∑   i  =  1   3     ∑   j  =  1   3     ∑   k  =  1   3     η   m  i     ε   i  j  k     a  j    b  k           normal-⇔      𝐚  𝐛   𝐜      superscript  c  m     superscript   subscript     i  1    3     superscript   subscript     j  1    3     superscript   subscript     k  1    3      superscript  η    m  i     subscript  ε    i  j  k     superscript  a  j    superscript  b  k          \mathbf{a\times b}=\mathbf{c}\Leftrightarrow\ c^{m}=\sum_{i=1}^{3}\sum_{j=1}^{%
 3}\sum_{k=1}^{3}\eta^{mi}\varepsilon_{ijk}a^{j}b^{k}   where the indices     i  ,  j  ,  k     i  j  k    \scriptstyle i,j,k   correspond to vector components. This characterization of the cross product is often expressed more compactly using the Einstein summation convention as        𝐚  ×  𝐛   =  𝐜   ⇔    c  m   =    η   m  i     ε   i  j  k     a  j    b  k        normal-⇔      𝐚  𝐛   𝐜      superscript  c  m      superscript  η    m  i     subscript  ε    i  j  k     superscript  a  j    superscript  b  k       \mathbf{a\times b}=\mathbf{c}\Leftrightarrow\ c^{m}=\eta^{mi}\varepsilon_{ijk}%
 a^{j}b^{k}   in which repeated indices are summed over the values 1 to 3. Note that this representation is another form of the skew-symmetric representation of the cross product:         η   m  i     ε   i  j  k     a  j    =    [  𝐚  ]   ×    .         superscript  η    m  i     subscript  ε    i  j  k     superscript  a  j     subscript   delimited-[]  𝐚       \eta^{mi}\varepsilon_{ijk}a^{j}=[\mathbf{a}]_{\times}.     In classical mechanics : representing the cross-product by using the Levi-Civita symbol can cause mechanical symmetries to be obvious when physical systems are isotropic . (An example: consider a particle in a Hooke's Law potential in three-space, free to oscillate in three dimensions; none of these dimensions are "special" in any sense, so symmetries lie in the cross-product-represented angular momentum, which are made clear by the abovementioned Levi-Civita representation).  Mnemonic  The word "xyzzy" can be used to remember the definition of the cross product.  If      𝐚  =   𝐛  ×  𝐜       𝐚    𝐛  𝐜     \mathbf{a}=\mathbf{b}\times\mathbf{c}     where:       𝐚  =   [      a  x        a  y        a  z      ]    ,    𝐛  =   [      b  x        b  y        b  z      ]    ,   𝐜  =   [      c  x        c  y        c  z      ]        formulae-sequence    𝐚     subscript  a  x      subscript  a  y      subscript  a  z       formulae-sequence    𝐛     subscript  b  x      subscript  b  y      subscript  b  z        𝐜     subscript  c  x      subscript  c  y      subscript  c  z         \mathbf{a}=\begin{bmatrix}a_{x}\\
 a_{y}\\
 a_{z}\end{bmatrix},\mathbf{b}=\begin{bmatrix}b_{x}\\
 b_{y}\\
 b_{z}\end{bmatrix},\mathbf{c}=\begin{bmatrix}c_{x}\\
 c_{y}\\
 c_{z}\end{bmatrix}     then:       a  x   =     b  y    c  z    -    b  z     c  y           subscript  a  x        subscript  b  y    subscript  c  z       subscript  b  z    subscript  c  y       a_{x}=b_{y}c_{z}-b_{z}c_{y}\,          a  y   =     b  z    c  x    -    b  x     c  z           subscript  a  y        subscript  b  z    subscript  c  x       subscript  b  x    subscript  c  z       a_{y}=b_{z}c_{x}-b_{x}c_{z}\,           a  z   =     b  x    c  y    -    b  y    c  x      .       subscript  a  z        subscript  b  x    subscript  c  y       subscript  b  y    subscript  c  x       a_{z}=b_{x}c_{y}-b_{y}c_{x}.\,     The second and third equations can be obtained from the first by simply vertically rotating the subscripts, . The problem, of course, is how to remember the first equation, and two options are available for this purpose: either to remember the relevant two diagonals of Sarrus's scheme (those containing i ), or to remember the xyzzy sequence.  Since the first diagonal in Sarrus's scheme is just the main diagonal of the above -mentioned 3×3 matrix, the first three letters of the word xyzzy can be very easily remembered.  Cross visualization  Similarly to the mnemonic device above, a "cross" or X can be visualized between the two vectors in the equation. This may be helpful for remembering the correct cross product formula.  If      𝐚  =   𝐛  ×  𝐜       𝐚    𝐛  𝐜     \mathbf{a}=\mathbf{b}\times\mathbf{c}     then:       𝐚  =    [      b  x        b  y        b  z      ]   ×   [      c  x        c  y        c  z      ]     .      𝐚       subscript  b  x      subscript  b  y      subscript  b  z        subscript  c  x      subscript  c  y      subscript  c  z        \mathbf{a}=\begin{bmatrix}b_{x}\\
 b_{y}\\
 b_{z}\end{bmatrix}\times\begin{bmatrix}c_{x}\\
 c_{y}\\
 c_{z}\end{bmatrix}.     If we want to obtain the formula for    a  x     subscript  a  x    a_{x}   we simply drop the    b  x     subscript  b  x    b_{x}   and    c  x     subscript  c  x    c_{x}   from the formula, and take the next two components down:        a  x   =    [      b  y        b  z      ]   ×   [      c  y        c  z      ]     .       subscript  a  x        subscript  b  y      subscript  b  z        subscript  c  y      subscript  c  z        a_{x}=\begin{bmatrix}b_{y}\\
 b_{z}\end{bmatrix}\times\begin{bmatrix}c_{y}\\
 c_{z}\end{bmatrix}.     It should be noted that when doing this for    a  y     subscript  a  y    a_{y}   the next two elements down should "wrap around" the matrix so that after the z component comes the x component. For clarity, when performing this operation for    a  y     subscript  a  y    a_{y}   , the next two components should be z and x (in that order). While for    a  z     subscript  a  z    a_{z}   the next two components should be taken as x and y.        a  y   =    [      b  z        b  x      ]   ×   [      c  z        c  x      ]     ,    a  z   =    [      b  x        b  y      ]   ×   [      c  x        c  y      ]        formulae-sequence     subscript  a  y        subscript  b  z      subscript  b  x        subscript  c  z      subscript  c  x          subscript  a  z        subscript  b  x      subscript  b  y        subscript  c  x      subscript  c  y         a_{y}=\begin{bmatrix}b_{z}\\
 b_{x}\end{bmatrix}\times\begin{bmatrix}c_{z}\\
 c_{x}\end{bmatrix},a_{z}=\begin{bmatrix}b_{x}\\
 b_{y}\end{bmatrix}\times\begin{bmatrix}c_{x}\\
 c_{y}\end{bmatrix}     For    a  x     subscript  a  x    a_{x}   then, if we visualize the cross operator as pointing from an element on the left to an element on the right, we can take the first element on the left and simply multiply by the element that the cross points to in the right hand matrix. We then subtract the next element down on the left, multiplied by the element that the cross points to here as well. This results in our    a  x     subscript  a  x    a_{x}   formula –        a  x   =     b  y    c  z    -    b  z    c  y      .       subscript  a  x        subscript  b  y    subscript  c  z       subscript  b  z    subscript  c  y       a_{x}=b_{y}c_{z}-b_{z}c_{y}.\,     We can do this in the same way for    a  y     subscript  a  y    a_{y}   and    a  z     subscript  a  z    a_{z}   to construct their associated formulas.  Applications  The cross product has applications in various contexts: e.g. it is used in computational geometry, physics and engineering. A non-exhaustive list of examples follows.  Computational geometry  The cross product appears in the calculation of the distance of two skew lines (lines not in the same plane) from each other in three-dimensional space.  The cross product can be used to calculate the normal for a triangle or polygon, an operation frequently performed in computer graphics . For example, the winding of a polygon (clockwise or anticlockwise) about a point within the polygon can be calculated by triangulating the polygon (like spoking a wheel) and summing the angles (between the spokes) using the cross product to keep track of the sign of each angle.  In computational geometry of the plane , the cross product is used to determine the sign of the acute angle defined by three points     p  1   =   (   x  1   ,   y  1   )        subscript  p  1     subscript  x  1    subscript  y  1      \scriptstyle p_{1}=(x_{1},y_{1})   ,     p  2   =   (   x  2   ,   y  2   )        subscript  p  2     subscript  x  2    subscript  y  2      \scriptstyle p_{2}=(x_{2},y_{2})   and     p  3   =   (   x  3   ,   y  3   )        subscript  p  3     subscript  x  3    subscript  y  3      \scriptstyle p_{3}=(x_{3},y_{3})   . It corresponds to the direction of the cross product of the two coplanar vectors defined by the pairs of points     p  1   ,   p  2       subscript  p  1    subscript  p  2     \scriptstyle p_{1},p_{2}   and     p  1   ,   p  3       subscript  p  1    subscript  p  3     \scriptstyle p_{1},p_{3}   , i.e., by the sign of the expression    P  =     (    x  2   -   x  1    )    (    y  3   -   y  1    )    -    (    y  2   -   y  1    )    (    x  3   -   x  1    )         P         subscript  x  2    subscript  x  1       subscript  y  3    subscript  y  1          subscript  y  2    subscript  y  1       subscript  x  3    subscript  x  1        \scriptstyle P=(x_{2}-x_{1})(y_{3}-y_{1})-(y_{2}-y_{1})(x_{3}-x_{1})   . In the "right-handed" coordinate system, if the result is 0, the points are collinear; if it is positive, the three points constitute a positive angle of rotation around    p  1     subscript  p  1    \scriptstyle p_{1}   from    p  2     subscript  p  2    \scriptstyle p_{2}   to    p  3     subscript  p  3    \scriptstyle p_{3}   , otherwise a negative angle. From another point of view, the sign of   P   P   \scriptstyle P   tells whether    p  3     subscript  p  3    \scriptstyle p_{3}   lies to the left or to the right of line     p  1   ,   p  2       subscript  p  1    subscript  p  2     \scriptstyle p_{1},p_{2}   .  The cross product is used in calculating the volume of a polyhedron such as a tetrahedron or parallelepiped .  Angular momentum and torque  The angular momentum    𝐋   𝐋   \scriptstyle\mathbf{L}   of a particle about a given origin is defined as:      𝐋  =   𝐫  ×   𝐩        𝐋    𝐫  𝐩     \mathbf{L}=\mathbf{r}\times\mathbf{p}\,   where   𝐫   𝐫   \scriptstyle\mathbf{r}   is the position vector of the particle relative to the origin,   𝐩   𝐩   \scriptstyle\mathbf{p}   is the linear momentum of the particle.  In the same way, the moment    𝐌   𝐌   \scriptstyle\mathbf{M}   of a force    𝐅  B     subscript  𝐅  normal-B    \scriptstyle\mathbf{F}_{\mathrm{B}}   applied at point B around point A is given as:       𝐌  A   =    𝐫  AB   ×    𝐅  B          subscript  𝐌  normal-A      subscript  𝐫  AB    subscript  𝐅  normal-B      \mathbf{M}_{\mathrm{A}}=\mathbf{r}_{\mathrm{AB}}\times\mathbf{F}_{\mathrm{B}}\,     In mechanics the moment of a force is also called torque and written as   τ   τ   \scriptstyle\mathbf{\tau}     Since position   𝐫   𝐫   \scriptstyle\mathbf{r}   , linear momentum   𝐩   𝐩   \scriptstyle\mathbf{p}   and force   𝐅   𝐅   \scriptstyle\mathbf{F}   are all true vectors, both the angular momentum   𝐋   𝐋   \scriptstyle\mathbf{L}   and the moment of a force   𝐌   𝐌   \scriptstyle\mathbf{M}   are pseudovectors or axial vectors .  Rigid body  The cross product frequently appears in the description of rigid motions. Two points P and Q on a rigid body can be related by:        𝐯  P   -   𝐯  Q    =   ω  ×   (    𝐫  P   -   𝐫  Q    )           subscript  𝐯  P    subscript  𝐯  Q      ω     subscript  𝐫  P    subscript  𝐫  Q       \mathbf{v}_{P}-\mathbf{v}_{Q}=\mathbf{\omega}\times\left(\mathbf{r}_{P}-%
 \mathbf{r}_{Q}\right)\,     where   𝐫   𝐫   \scriptstyle\mathbf{r}   is the point's position,   𝐯   𝐯   \scriptstyle\mathbf{v}   is its velocity and   ω   ω   \scriptstyle\mathbf{\omega}   is the body's angular velocity .  Since position   𝐫   𝐫   \scriptstyle\mathbf{r}   and velocity   𝐯   𝐯   \scriptstyle\mathbf{v}   are true vectors, the angular velocity   ω   ω   \scriptstyle\mathbf{\omega}   is a pseudovector or axial vector .  Lorentz force  The cross product is used to describe the Lorentz force experienced by a moving electric charge    q  e     subscript  q  e    q_{e}   :      𝐅  =     q  e     (   𝐄  +   𝐯  ×  𝐁    )        𝐅     subscript  q  e     𝐄    𝐯  𝐁       \mathbf{F}=q_{e}\,\left(\mathbf{E}+\mathbf{v}\times\mathbf{B}\right)     Since velocity   𝐯   𝐯   \scriptstyle\mathbf{v}   , force   𝐅   𝐅   \scriptstyle\mathbf{F}   and electric field   𝐄   𝐄   \scriptstyle\mathbf{E}   are all true vectors, the magnetic field   𝐁   𝐁   \scriptstyle\mathbf{B}   is a pseudovector .  Other  In vector calculus , the cross product is used to define the formula for the vector operator  curl .  The trick of rewriting a cross product in terms of a matrix multiplication appears frequently in epipolar and multi-view geometry, in particular when deriving matching constraints.  Cross product as an exterior product  The cross product can be viewed in terms of the exterior product . This view allows for a natural geometric interpretation of the cross product. In exterior algebra the exterior product (or wedge product) of two vectors is a bivector . A bivector is an oriented plane element, in much the same way that a vector is an oriented line element. Given two vectors a and b , one can view the bivector  as the oriented parallelogram spanned by a and b . The cross product is then obtained by taking the Hodge dual of the bivector , mapping 2-vectors to vectors:      a  ×  b  =  *   (  a  ∧  b  )   .     fragments  a   b     fragments  normal-(  a   b  normal-)   normal-.    a\times b=*(a\wedge b)\,.     This can be thought of as the oriented multi-dimensional element "perpendicular" to the bivector. Only in three dimensions is the result an oriented line element – a vector – whereas, for example, in 4 dimensions the Hodge dual of a bivector is two-dimensional – another oriented plane element. So, only in three dimensions is the cross product of a and b the vector dual to the bivector : it is perpendicular to the bivector, with orientation dependent on the coordinate system's handedness, and has the same magnitude relative to the unit normal vector as  has relative to the unit bivector; precisely the properties described above.  Cross product and handedness  When measurable quantities involve cross products, the handedness of the coordinate systems used cannot be arbitrary. However, when physics laws are written as equations, it should be possible to make an arbitrary choice of the coordinate system (including handedness). To avoid problems, one should be careful to never write down an equation where the two sides do not behave equally under all transformations that need to be considered. For example, if one side of the equation is a cross product of two vectors, one must take into account that when the handedness of the coordinate system is not fixed a priori, the result is not a (true) vector but a pseudovector . Therefore, for consistency, the other side must also be a pseudovector.  More generally, the result of a cross product may be either a vector or a pseudovector, depending on the type of its operands (vectors or pseudovectors). Namely, vectors and pseudovectors are interrelated in the following ways under application of the cross product:   vector × vector = pseudovector  pseudovector × pseudovector = pseudovector  vector × pseudovector = vector  pseudovector × vector = vector.   So by the above relationships, the unit basis vectors i , j and k of an orthonormal, right-handed (Cartesian) coordinate frame must all be pseudovectors (if a basis of mixed vector types is disallowed, as it normally is) since ,  and .  Because the cross product may also be a (true) vector, it may not change direction with a mirror image transformation. This happens, according to the above relationships, if one of the operands is a (true) vector and the other one is a pseudovector (e.g., the cross product of two vectors). For instance, a vector triple product involving three (true) vectors is a (true) vector.  A handedness-free approach is possible using exterior algebra .  Generalizations  There are several ways to generalize the cross product to the higher dimensions.  Lie algebra  The cross product can be seen as one of the simplest Lie products, and is thus generalized by Lie algebras , which are axiomatized as binary products satisfying the axioms of multilinearity, skew-symmetry, and the Jacobi identity. Many Lie algebras exist, and their study is a major field of mathematics, called Lie theory .  For example, the Heisenberg algebra gives another Lie algebra structure on     𝐑  3   .     superscript  𝐑  3    \scriptstyle\mathbf{R}^{3}.   In the basis     {  x  ,  y  ,  z  }   ,     x  y  z    \scriptstyle\{x,y,z\},   the product is      [  x  ,  y  ]   =  z   ,    [  x  ,  z  ]   =   [  y  ,  z  ]   =  0.      formulae-sequence     x  y   z        x  z    y  z        0.      \scriptstyle[x,y]=z,[x,z]=[y,z]=0.     Quaternions  The cross product can also be described in terms of quaternions , and this is why the letters i , j , k are a convention for the standard basis on R 3 . The unit vectors i , j , k correspond to "binary" (180 deg) rotations about their respective axes (Altmann, S. L., 1986, Ch. 12), said rotations being represented by "pure" quaternions (zero scalar part) with unit norms.  For instance, the above given cross product relations among i , j , and k agree with the multiplicative relations among the quaternions i , j , and k . In general, if a vector is represented as the quaternion , the cross product of two vectors can be obtained by taking their product as quaternions and deleting the real part of the result. The real part will be the negative of the dot product of the two vectors.  Alternatively, using the above identification of the 'purely imaginary' quaternions with R 3 , the cross product may be thought of as half of the commutator of two quaternions.  Octonions  A cross product for 7-dimensional vectors can be obtained in the same way by using the octonions instead of the quaternions. The nonexistence of nontrivial vector-valued cross products of two vectors in other dimensions is related to the result from Hurwitz's theorem that the only normed division algebras are the ones with dimension 1, 2, 4, and 8.  Wedge product  In general dimension, there is no direct analogue of the binary cross product that yields specifically a vector. There is however the wedge product , which has similar properties, except that the wedge product of two vectors is now a 2-vector instead of an ordinary vector. As mentioned above, the cross product can be interpreted as the wedge product in three dimensions by using the Hodge dual to map 2-vectors to vectors. The Hodge dual of the wedge product yields an -vector, which is a natural generalization of the cross product in any number of dimensions.  The wedge product and dot product can be combined (through summation) to form the geometric product .  Multilinear algebra  In the context of multilinear algebra , the cross product can be seen as the (1,2)-tensor (a mixed tensor , specifically a bilinear map ) obtained from the 3-dimensional volume form , 16 a (0,3)-tensor, by raising an index .  In detail, the 3-dimensional volume form defines a product      V  ×  V  ×  V   →  𝐑   ,     normal-→    V  V  V   𝐑    \scriptstyle V\times V\times V\to\mathbf{R},   by taking the determinant of the matrix given by these 3 vectors. By duality , this is equivalent to a function      V  ×  V   →   V  *    ,     normal-→    V  V    superscript  V      \scriptstyle V\times V\to V^{*},   (fixing any two inputs gives a function    V  →  𝐑     normal-→  V  𝐑    \scriptstyle V\to\mathbf{R}   by evaluating on the third input) and in the presence of an inner product (such as the dot product ; more generally, a non-degenerate bilinear form), we have an isomorphism     V  →   V  *    ,     normal-→  V   superscript  V      \scriptstyle V\to V^{*},   and thus this yields a map      V  ×  V   →  V   ,     normal-→    V  V   V    \scriptstyle V\times V\to V,   which is the cross product: a (0,3)-tensor (3 vector inputs, scalar output) has been transformed into a (1,2)-tensor (2 vector inputs, 1 vector output) by "raising an index".  Translating the above algebra into geometry, the function "volume of the parallelepiped defined by    (  a  ,  b  ,  -  )     a  b     \scriptstyle(a,b,-)   " (where the first two vectors are fixed and the last is an input), which defines a function    V  →  𝐑     normal-→  V  𝐑    \scriptstyle V\to\mathbf{R}   , can be represented uniquely as the dot product with a vector: this vector is the cross product     a  ×  b   .      a  b    \scriptstyle a\times b.   From this perspective, the cross product is defined by the scalar triple product ,      Vol   (  a  ,  b  ,  c  )    =    (   a  ×  b   )   ⋅  c    .        Vol   a  b  c     normal-⋅    a  b   c     \scriptstyle\mathrm{Vol}(a,b,c)=(a\times b)\cdot c.     In the same way, in higher dimensions one may define generalized cross products by raising indices of the n -dimensional volume form, which is a    (  0  ,  n  )     0  n    \scriptstyle(0,n)   -tensor. The most direct generalizations of the cross product are to define either:   a    (  1  ,   n  -  1   )     1    n  1     \scriptstyle(1,n-1)   -tensor, which takes as input    n  -  1      n  1    \scriptstyle n-1   vectors, and gives as output 1 vector – an    (   n  -  1   )      n  1    \scriptstyle(n-1)   -ary vector-valued product, or  a    (   n  -  2   ,  2  )       n  2   2    \scriptstyle(n-2,2)   -tensor, which takes as input 2 vectors and gives as output skew-symmetric tensor of rank  – a binary product with rank  tensor values. One can also define    (  k  ,   n  -  k   )     k    n  k     \scriptstyle(k,n-k)   -tensors for other k .   These products are all multilinear and skew-symmetric, and can be defined in terms of the determinant and parity .  The    (   n  -  1   )      n  1    \scriptstyle(n-1)   -ary product can be described as follows: given    n  -  1      n  1    \scriptstyle n-1   vectors     v  1   ,  …  ,   v   n  -  1        subscript  v  1   normal-…   subscript  v    n  1      \scriptstyle v_{1},\dots,v_{n-1}   in     𝐑  n   ,     superscript  𝐑  n    \scriptstyle\mathbf{R}^{n},   define their generalized cross product     v  n   =    v  1   ×  ⋯  ×   v   n  -  1          subscript  v  n      subscript  v  1   normal-⋯   subscript  v    n  1       \scriptstyle v_{n}=v_{1}\times\cdots\times v_{n-1}   as:   perpendicular to the hyperplane defined by the     v  i   ,     subscript  v  i    \scriptstyle v_{i},     magnitude is the volume of the parallelotope defined by the     v  i   ,     subscript  v  i    \scriptstyle v_{i},   which can be computed as the Gram determinant of the     v  i   ,     subscript  v  i    \scriptstyle v_{i},     oriented so that     v  1   ,  …  ,   v  n       subscript  v  1   normal-…   subscript  v  n     \scriptstyle v_{1},\dots,v_{n}   is positively oriented.   This is the unique multilinear, alternating product which evaluates to      e  1   ×  ⋯  ×   e   n  -  1     =   e  n          subscript  e  1   normal-⋯   subscript  e    n  1      subscript  e  n     \scriptstyle e_{1}\times\cdots\times e_{n-1}=e_{n}   ,       e  2   ×  ⋯  ×   e  n    =   e  1    ,         subscript  e  2   normal-⋯   subscript  e  n     subscript  e  1     \scriptstyle e_{2}\times\cdots\times e_{n}=e_{1},   and so forth for cyclic permutations of indices.  In coordinates, one can give a formula for this    (   n  -  1   )      n  1    \scriptstyle(n-1)   -ary analogue of the cross product in R n by:        ⋀   (   𝐯  1   ,  …  ,   𝐯   n  -  1    )    =   |       v  1     1      ⋯     v   ;  1     n        ⋮    ⋱    ⋮        v   n  -  1      1      ⋯     v   ;   n  -  1      n         𝐞  1     ⋯     𝐞  n      |    .          subscript  𝐯  1   normal-…   subscript  𝐯    n  1           fragments   subscript  v  1    1    normal-⋯   fragments  v   subscript  normal-;  1    n      normal-⋮  normal-⋱  normal-⋮     fragments   subscript  v    n  1     1    normal-⋯   fragments  v   subscript  normal-;    n  1     n       subscript  𝐞  1   normal-⋯   subscript  𝐞  n        \bigwedge(\mathbf{v}_{1},\dots,\mathbf{v}_{n-1})=\begin{vmatrix}v_{1}{}^{1}&%
 \cdots&v_{1}{}^{n}\\
 \vdots&\ddots&\vdots\\
 v_{n-1}{}^{1}&\cdots&v_{n-1}{}^{n}\\
 \mathbf{e}_{1}&\cdots&\mathbf{e}_{n}\end{vmatrix}.     This formula is identical in structure to the determinant formula for the normal cross product in R 3 except that the row of basis vectors is the last row in the determinant rather than the first. The reason for this is to ensure that the ordered vectors ( v 1 , ..., v n −1 , Λ( v 1 , ..., v n −1 )) have a positive orientation with respect to ( e 1 , ..., e n ). If n is odd, this modification leaves the value unchanged, so this convention agrees with the normal definition of the binary product. In the case that n is even, however, the distinction must be kept. This    (   n  -  1   )      n  1    \scriptstyle(n-1)   -ary form enjoys many of the same properties as the vector cross product: it is alternating and linear in its arguments, it is perpendicular to each argument, and its magnitude gives the hypervolume of the region bounded by the arguments. And just like the vector cross product, it can be defined in a coordinate independent way as the Hodge dual of the wedge product of the arguments.  Skew-symmetric matrix  If the cross product is defined as a binary operation, it takes as input exactly two vectors. If its output is not required to be a vector or a pseudovector but instead a matrix , then it can be generalized in an arbitrary number of dimensions. 17 18 19  In mechanics, for example, the angular velocity can be interpreted either as a pseudovector   ω   ω   \omega   or as a anti-symmetric matrix or skew-symmetric tensor    Ω   normal-Ω   \Omega   . In the latter case, the velocity law for a rigid body looks:        𝐯  P   -   𝐯  Q    =   Ω  ⋅   (    𝐫  P   -   𝐫  Q    )           subscript  𝐯  P    subscript  𝐯  Q     normal-⋅  normal-Ω     subscript  𝐫  P    subscript  𝐫  Q       \mathbf{v}_{P}-\mathbf{v}_{Q}={\Omega}\cdot\left(\mathbf{r}_{P}-\mathbf{r}_{Q}%
 \right)\,     where Ω is formally defined from the rotation matrix    R   N  ×  N      superscript  R    N  N     R^{N\times N}   associated to body's frame    Ω  ≜     d  R    d  t     R  T       normal-≜  normal-Ω        d  R     d  t     superscript  R  normal-T      \Omega\triangleq\frac{dR}{dt}R^{\mathrm{T}}   . In three-dimensions holds:      Ω  =    [  ω  ]   ×   =   [     0     -   ω  3        ω   2         ω   3     0     -   ω  1         -   ω  2        ω   1     0     ]         normal-Ω   subscript   delimited-[]  ω            0     subscript  ω  3     subscript  ω  2      subscript  ω  3   0     subscript  ω  1         subscript  ω  2     subscript  ω  1   0       \Omega=[\omega]_{\times}=\begin{bmatrix}\,\,0&\!-\omega_{3}&\,\,\,\omega_{2}\\
 \,\,\,\omega_{3}&0&\!-\omega_{1}\\
 \!-\omega_{2}&\,\,\omega_{1}&\,\,0\end{bmatrix}     In quantum Mechanics the angular momentum    L   L   L   is often represented as an anti-symmetric matrix or tensor. More precisely, it is the result of cross product involving position   𝐱   𝐱   \mathbf{x}   and linear momentum   𝐩   𝐩   \mathbf{p}   :       L   i  j    =     x  i    p  j    -    p  i    x  j          subscript  L    i  j         subscript  x  i    subscript  p  j       subscript  p  i    subscript  x  j       L_{ij}=x_{i}p_{j}-p_{i}x_{j}     Since both   𝐱   𝐱   \mathbf{x}   and   𝐩   𝐩   \mathbf{p}   can have an arbitrary number   N   N   N   of components, that kind of cross product can be extended to any dimension, holding the "physical" interpretation of the operation.  See  for numerical details.  History  In 1773, the Italian mathematician Joseph Louis Lagrange , (born Giuseppe Luigi Lagrancia), introduced the component form of both the dot and cross products in order to study the tetrahedron in three dimensions. 20 In 1843 the Irish mathematical physicist Sir William Rowan Hamilton introduced the quaternion product, and with it the terms "vector" and "scalar". Given two quaternions  and , where u and v are vectors in R 3 , their quaternion product can be summarized as . James Clerk Maxwell used Hamilton's quaternion tools to develop his famous electromagnetism equations , and for this and other reasons quaternions for a time were an essential part of physics education.  In 1878 William Kingdon Clifford published his Elements of Dynamic which was an advanced text for its time. He defined the product of two vectors 21 to have magnitude equal to the area of the parallelogram of which they are two sides, and direction perpendicular to their plane.  Oliver Heaviside in England and Josiah Willard Gibbs , a professor at Yale University in Connecticut , also felt that quaternion methods were too cumbersome, often requiring the scalar or vector part of a result to be extracted. Thus, about forty years after the quaternion product, the dot product and cross product were introduced—to heated opposition. Pivotal to (eventual) acceptance was the efficiency of the new approach, allowing Heaviside to reduce the equations of electromagnetism from Maxwell's original 20 to the four commonly seen today. 22  Largely independent of this development, and largely unappreciated at the time, Hermann Grassmann created a geometric algebra not tied to dimension two or three, with the exterior product playing a central role. In 1853 Augustin-Louis Cauchy , a contemporary of Grassmann, published a paper on algebraic keys which were used to solve equations and had the same multiplication properties as the cross product. 23 24  William Kingdon Clifford combined the algebras of Hamilton and Grassmann to produce Clifford algebra , where in the case of three-dimensional vectors the bivector produced from two vectors dualizes to a vector, thus reproducing the cross product.  The cross notation and the name "cross product" began with Gibbs. Originally they appeared in privately published notes for his students in 1881 as Elements of Vector Analysis . The utility for mechanics was noted by Aleksandr Kotelnikov . Gibbs's notation and the name "cross product" later reached a wide audience through Vector Analysis , a textbook by Edwin Bidwell Wilson , a former student. Wilson rearranged material from Gibbs's lectures, together with material from publications by Heaviside, Föpps, and Hamilton. He divided vector analysis into three parts:  Two main kinds of vector multiplications were defined, and they were called as follows:   The direct , scalar , or dot product of two vectors  The skew , vector , or cross product of two vectors   Several kinds of triple products and products of more than three vectors were also examined. The above-mentioned triple product expansion was also included.  See also   Bivector  Cartesian product – A product of two sets  Dot Product  Exterior algebra  Multiple cross products – Products involving more than three vectors  Pseudovector  × (the symbol)   Notes  References    E. A. Milne (1948) Vectorial Mechanics , Chapter 2: Vector Product, pp 11 –31, London: Methuen Publishing .     External links     A quick geometrical derivation and interpretation of cross products  C.A. Gonano and R.E. Zich (2014). Cross product in N Dimensions - the doublewedge product , Polytechnic University of Milan, Italy.  Z.K. Silagadze (2002). Multi-dimensional vector product. Journal of Physics. A35, 4949 (it is only possible in 7-D space)  Real and Complex Products of Complex Numbers  An interactive tutorial created at Syracuse University – (requires java )  W. Kahan (2007). Cross-Products and Rotations in Euclidean 2- and 3-Space. University of California, Berkeley (PDF).   "  Category:Bilinear operators  Category:Binary operations  Category:Vector calculus  Category:Analytic geometry     ↩  ↩  ↩  ↩  A History of Vector Analysis by Michael J. Crowe , Math. UC Davis ↩   Here, “formal" means that this notation has the form of a determinant, but does not strictly adhere to the definition; it is a mnemonic used to remember the expansion of the cross product. ↩  ↩  ↩  ↩  ↩  ↩   by ↩  ↩  By a volume form one means a function that takes in n vectors and gives out a scalar, the volume of the parallelotope defined by the vectors      V  ×  ⋯  ×  V   →  𝐑   .     normal-→    V  normal-⋯  V   𝐑    \scriptstyle V\times\cdots\times V\to\mathbf{R}.   This is an n -ary multilinear skew-symmetric form. In the presence of a basis, such as on     𝐑  n   ,     superscript  𝐑  n    \scriptstyle\mathbf{R}^{n},   this is given by the determinant , but in an abstract vector space, this is added structure. In terms of G -structures , a volume form is an     S  L      S  L    \scriptstyle SL    -structure. ↩  ↩  ↩  ↩  ↩  William Kingdon Clifford (1878) Elements of Dynamic , Part I, page 95, London: MacMillan & Co; online presentation by Cornell University  Historical Mathematical Monographs ↩  ↩  ↩  ↩     