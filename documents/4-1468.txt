   Confidence region      Confidence region   In statistics , a confidence region is a multi-dimensional generalization of a confidence interval . It is a set of points in an n -dimensional space, often represented as an ellipsoid around a point which is an estimated solution to a problem, although other shapes can occur.  Interpretation  The confidence region is calculated in such a way that if a set of measurements were repeated many times and a confidence region calculated in the same way on each set of measurements, then a certain percentage of the time, on average, (e.g. 95%) the confidence region would include the point representing the "true" values of the set of variables being estimated. However, unless certain assumptions about prior probabilities are made, it does not mean, when one confidence region has been calculated, that there is a 95% probability that the "true" values lie inside the region, since we do not assume any particular probability distribution of the "true" values and we may or may not have other information about where they are likely to lie.  The case of independent, identically normally-distributed errors  Suppose we have found a solution   ğœ·   ğœ·   \boldsymbol{\beta}   to the following overdetermined problem:      ğ˜  =    ğ—  ğœ·   +  ğœº       ğ˜      ğ—  ğœ·   ğœº     \mathbf{Y}=\mathbf{X}\boldsymbol{\beta}+\boldsymbol{\varepsilon}     where Y is an n -dimensional column vector containing observed values, X is an n -by- p matrix which can represent a physical model and which is assumed to be known exactly,   ğœ·   ğœ·   \boldsymbol{\beta}   is a column vector containing the p parameters which are to be estimated, and   ğœº   ğœº   \boldsymbol{\varepsilon}   is an n -dimensional column vector of errors which are assumed to be independently distributed with normal distributions with zero mean and each having the same unknown variance    Ïƒ  2     superscript  Ïƒ  2    \sigma^{2}   .  A joint 100(1Â âˆ’ Î± ) % confidence region for the elements of   ğœ·   ğœ·   \boldsymbol{\beta}   is represented by the set of values of the vector b which satisfy the following inequality: 1          (   ğœ·  -  ğ›   )   â€²    ğ—  â€²   ğ—   (   ğœ·  -  ğ›   )    â‰¤   p   s  2    F   1  -  Î±     (  p  ,  Î½  )     ,         superscript    ğœ·  ğ›   normal-â€²    superscript  ğ—  normal-â€²   ğ—    ğœ·  ğ›      p   superscript  s  2    subscript  F    1  Î±     p  Î½      (\boldsymbol{\beta}-\mathbf{b})^{\prime}\mathbf{X}^{\prime}\mathbf{X}(%
 \boldsymbol{\beta}-\mathbf{b})\leq ps^{2}F_{1-\alpha}(p,\nu),     where the variable b represents any point in the confidence region, p is the number of parameters, i.e. number of elements of the vector    ğœ·  ,    ğœ·   \boldsymbol{\beta},   and s 2 is an unbiased estimate of    Ïƒ  2     superscript  Ïƒ  2    \sigma^{2}   equal to        s  2   =     Îµ  â€²   Îµ    n  -  p     .       superscript  s  2        superscript  Îµ  normal-â€²   Îµ     n  p      s^{2}=\frac{\varepsilon^{\prime}\varepsilon}{n-p}.   Further, F is the quantile function of the F-distribution , with p and    Î½  =   n  -  p       Î½    n  p     \nu=n-p    degrees of freedom ,   Î±   Î±   \alpha   is the statistical significance level, and the symbol    X  â€²     superscript  X  normal-â€²    X^{\prime}   means the transpose of   X   X   X   .  The above inequality defines an ellipsoidal region in the p -dimensional Cartesian parameter space R p . The centre of the ellipsoid is at the solution   ğœ·   ğœ·   \boldsymbol{\beta}   . According to Press et al., it's easier to plot the ellipsoid after doing singular value decomposition . The lengths of the axes of the ellipsoid are proportional to the reciprocals of the values on the diagonals of the diagonal matrix, and the directions of these axes are given by the rows of the 3rd matrix of the decomposition.  Weighted and generalised least squares  Now let us consider the more general case where some distinct elements of   ğœº   ğœº   \boldsymbol{\varepsilon}   have known nonzero covariance (in other words, the errors in the observations are not independently distributed), and/or the standard deviations of the errors are not all equal. Suppose the covariance matrix of   ğœº   ğœº   \boldsymbol{\varepsilon}   is    ğ•   Ïƒ  2       ğ•   superscript  Ïƒ  2     \mathbf{V}\sigma^{2}   , where V is an n -by- n nonsingular matrix which was equal to    ğˆ   Ïƒ  2       ğˆ   superscript  Ïƒ  2     \mathbf{I}\sigma^{2}   in the more specific case handled in the previous section, (where I is the identity matrix ,) but here is allowed to have nonzero off-diagonal elements representing the covariance of pairs of individual observations, as well as not necessarily having all the diagonal elements equal.  It is possible to find 2 a nonsingular symmetric matrix P such that        ğ  â€²   ğ   =  ğğ  =  ğ•           superscript  ğ  normal-â€²   ğ   ğğ       ğ•     \mathbf{P}^{\prime}\mathbf{P}=\mathbf{P}\mathbf{P}=\mathbf{V}     In effect, P is a square root of the covariance matrix V .  The least-squares problem      ğ˜  =    ğ—  ğœ·   +  ğœº       ğ˜      ğ—  ğœ·   ğœº     \mathbf{Y}=\mathbf{X}\boldsymbol{\beta}+\boldsymbol{\varepsilon}     can then be transformed by left-multiplying each term by the inverse of P , forming the new problem formulation       ğ™  =    ğ  ğœ·   +  ğŸ    ,      ğ™      ğ  ğœ·   ğŸ     \mathbf{Z}=\mathbf{Q}\boldsymbol{\beta}+\mathbf{f},     where      ğ™  =    ğ   -  1    ğ˜       ğ™     superscript  ğ    1    ğ˜     \mathbf{Z}=\mathbf{P}^{-1}\mathbf{Y}         ğ  =    ğ   -  1    ğ—       ğ     superscript  ğ    1    ğ—     \mathbf{Q}=\mathbf{P}^{-1}\mathbf{X}   and      ğŸ  =    ğ   -  1    ğœº       ğŸ     superscript  ğ    1    ğœº     \mathbf{f}=\mathbf{P}^{-1}\boldsymbol{\varepsilon}     A joint confidence region for the parameters, i.e. for the elements of   ğœ·   ğœ·   \boldsymbol{\beta}   , is then bounded by the ellipsoid given by: 3          (   ğ›  -  ğœ·   )   â€²    ğ  â€²   ğ   (   ğ›  -  ğœ·   )    =    p   n  -  p     (     ğ™  â€²   ğ™   -    ğ›  â€²    ğ  â€²   ğ™    )    F   1  -  Î±     (  p  ,   n  -  p   )     .         superscript    ğ›  ğœ·   normal-â€²    superscript  ğ  normal-â€²   ğ    ğ›  ğœ·        p    n  p         superscript  ğ™  normal-â€²   ğ™      superscript  ğ›  normal-â€²    superscript  ğ  normal-â€²   ğ™     subscript  F    1  Î±     p    n  p       (\mathbf{b}-\boldsymbol{\beta})^{\prime}\mathbf{Q}^{\prime}\mathbf{Q}(\mathbf{%
 b}-\boldsymbol{\beta})={\frac{p}{n-p}}(\mathbf{Z}^{\prime}\mathbf{Z}-\mathbf{b%
 }^{\prime}\mathbf{Q}^{\prime}\mathbf{Z})F_{1-\alpha}(p,n-p).     Here F represents the percentage point of the F distribution and the quantities p and n-p are the degrees of freedom which are the parameters of this distribution.  Nonlinear problems  Confidence regions can be defined for any probability distribution. The experimenter can choose the significance level and the shape of the region, and then the size of the region is determined by the probability distribution. A natural choice is to use as a boundary a set of points with constant    Ï‡  2     superscript  Ï‡  2    \chi^{2}   ( chi-squared ) values.  One approach is to use a linear approximation to the nonlinear model, which may be a close approximation in the vicinity of the solution, and then apply the analysis for a linear problem to find an approximate confidence region. This may be a reasonable approach if the confidence region is not very large and the second derivatives of the model are also not very large.  Bootstrapping approaches can also be used. 4  See Uncertainty Quantification#Methodologies for forward uncertainty propagation for related concepts.  See also   Circular error probable  Linear regression  Confidence band   Notes  References      External links  "  Category:Estimation theory  Category:Statistical inference     Draper and Smith (1981, p. 94) â†©  Draper and Smith (1981, p. 108) â†©  Draper and Smith (1981, p. 109) â†©  Hutton TJ, Buxton BF, Hammond P, Potts HWW (2003). Estimating average growth trajectories in shape-space using kernel smoothing. IEEE Transactions on Medical Imaging , 22 (6):747-53 â†©     