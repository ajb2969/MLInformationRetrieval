   Finite element method      Finite element method   In mathematics , the finite element method ( FEM ) is a numerical technique for finding approximate solutions to boundary value problems for partial differential equations . It uses subdivision of a whole problem domain into simpler parts, called finite elements, and variational methods from the calculus of variations to solve the problem by minimizing an associated error function. Analogous to the idea that connecting many tiny straight lines can approximate a larger circle, FEM encompasses methods for connecting many simple element equations over many small subdomains, named finite elements, to approximate a more complex equation over a larger domain .  Basic concepts  The subdivision of a whole domain into simpler parts has several advantages: 1   Accurate representation of complex geometry  Inclusion of dissimilar material properties  Easy representation of the total solution  Capture of local effects.   A typical work out of the method involves (1) dividing the domain of the problem into a collection of subdomains, with each subdomain represented by a set of element equations to the original problem, followed by (2) systematically recombining all sets of element equations into a global system of equations for the final calculation. The global system of equations has known solution techniques, and can be calculated from the initial values of the original problem to obtain a numerical answer.  In the first step above, the element equations are simple equations that locally approximate the original complex equations to be studied, where the original equations are often partial differential equations (PDE). To explain the approximation in this process, FEM is commonly introduced as a special case of Galerkin method . The process, in mathematical language, is to construct an integral of the inner product of the residual and the weight functions and set the integral to zero. In simple terms, it is a procedure that minimizes the error of approximation by fitting trial functions into the PDE. The residual is the error caused by the trial functions, and the weight functions are polynomial approximation functions that project the residual. The process eliminates all the spatial derivatives from the PDE, thus approximating the PDE locally with   a set of algebraic equations for steady state problems,  a set of ordinary differential equations for transient problems.   These equation sets are the element equations. They are linear if the underlying PDE is linear, and vice versa. Algebraic equation sets that arise in the steady state problems are solved using numerical linear algebra methods, while ordinary differential equation sets that arise in the transient problems are solved by numerical integration using standard techniques such as Euler's method or the Runge-Kutta method.  In step (2) above, a global system of equations is generated from the element equations through a transformation of coordinates from the subdomains' local nodes to the domain's global nodes. This spatial transformation includes appropriate orientation adjustments as applied in relation to the reference coordinate system . The process is often carried out by FEM software using coordinate data generated from the subdomains.  FEM is best understood from its practical application, known as finite element analysis (FEA) . FEA as applied in engineering is a computational tool for performing engineering analysis . It includes the use of mesh generation techniques for dividing a complex problem into small elements, as well as the use of software program coded with FEM algorithm. In applying FEA, the complex problem is usually a physical system with the underlying physics such as the Euler-Bernoulli beam equation , the heat equation , or the Navier-Stokes equations expressed in either PDE or integral equations , while the divided small elements of the complex problem represent different areas in the physical system.  FEA is a good choice for analyzing problems over complicated domains (like cars and oil pipelines), when the domain changes (as during a solid state reaction with a moving boundary), when the desired precision varies over the entire domain, or when the solution lacks smoothness. For instance, in a frontal crash simulation it is possible to increase prediction accuracy in "important" areas like the front of the car and reduce it in its rear (thus reducing cost of the simulation). Another example would be in numerical weather prediction , where it is more important to have accurate predictions over developing highly nonlinear phenomena (such as tropical cyclones in the atmosphere, or eddies in the ocean) rather than relatively calm areas.  History  While it is difficult to quote a date of the invention of the finite element method, the method originated from the need to solve complex elasticity and structural analysis problems in civil and aeronautical engineering . Its development can be traced back to the work by A. Hrennikoff  2 and R. Courant . 3 In China, in the later 1950s and early 1960s, based on the computations of dam constructions, K. Feng proposed a systematic numerical method for solving partial differential equations . The method was called the finite difference method based on variation principle, which was another independent invention of finite element method. Although the approaches used by these pioneers are different, they share one essential characteristic: mesh  discretization of a continuous domain into a set of discrete sub-domains, usually called elements.  Hrennikoff's work discretizes the domain by using a lattice analogy, while Courant's approach divides the domain into finite triangular subregions to solve second order  elliptic partial differential equations (PDEs) that arise from the problem of torsion of a cylinder . Courant's contribution was evolutionary, drawing on a large body of earlier results for PDEs developed by Rayleigh , Ritz , and Galerkin .  The finite element method obtained its real impetus in the 1960s and 1970s by the developments of J. H. Argyris with co-workers at the University of Stuttgart , R. W. Clough with co-workers at UC Berkeley , O. C. Zienkiewicz with co-workers Ernest Hinton , Bruce Irons 4 and others at the University of Swansea , Philippe G. Ciarlet at the University of Paris 6 and Richard Gallagher 5 with co-workers at Cornell University . Further impetus was provided in these years by available open source finite element software programs. NASA sponsored the original version of NASTRAN , and UC Berkeley made the finite element program SAP IV 6 widely available. In Norway the ship classification society Det Norske Veritas (now DNV GL ) developed Sesam in 1969 for use in analysis of ships. 7 A rigorous mathematical basis to the finite element method was provided in 1973 with the publication by Strang and Fix . 8 The method has since been generalized for the numerical modeling of physical systems in a wide variety of engineering disciplines, e.g., electromagnetism , heat transfer , and fluid dynamics . 9 10  Technical discussion  The structure of finite element methods  Finite element methods are numerical methods for approximating the solutions of mathematical problems that are usually formulated so as to precisely state an idea of some aspect of physical reality.  A finite element method is characterized by a variational formulation , a discretization strategy, one or more solution algorithms and post-processing procedures.  Examples of variational formulation are the Galerkin method , the discontinuous Galerkin method, mixed methods, etc.  A discretization strategy is understood to mean a clearly defined set of procedures that cover (a) the creation of finite element meshes, (b) the definition of basis function on reference elements (also called shape functions) and (c) the mapping of reference elements onto the elements of the mesh. Examples of discretization strategies are the h-version, p-version , hp-version , x-FEM , isogeometric analysis , etc. Each discretization strategy has certain advantages and disadvantages. A reasonable criterion in selecting a discretization strategy is to realize nearly optimal performance for the broadest set of mathematical models in a particular model class.  There are various numerical solution algorithms that can be classified into two broad categories; direct and iterative solvers. These algorithms are designed to exploit the sparsity of matrices that depend on the choices of variational formulation and discretization strategy.  Postprocessing procedures are designed for the extraction of the data of interest from a finite element solution. In order to meet the requirements of solution verification, postprocessors need to provide for a posteriori error estimation in terms of the quantities of interest. When the errors of approximation are larger than what is considered acceptable then the discretization has to be changed either by an automated adaptive process or by action of the analyst. There are some very efficient postprocessors that provide for the realization of superconvergence .  Illustrative problems P1 and P2  We will illustrate the finite element method using two sample problems from which the general method can be extrapolated. It is assumed that the reader is familiar with calculus and linear algebra .  P1 is a ' one-dimensional ' problem      P1  :   {         u  ′′    (  x  )    =   f   (  x  )   in   (  0  ,  1  )     ,           u   (  0  )    =   u   (  1  )    =  0   ,           normal-:  P1   cases       superscript  u  ′′   x     f  x  in   0  1     otherwise        u  0     u  1        0    otherwise     \mbox{ P1 }:\begin{cases}u^{\prime\prime}(x)=f(x)\mbox{ in }(0,1),\\
 u(0)=u(1)=0,\end{cases}   where   f   f   f   is given,   u   u   u   is an unknown function of   x   x   x   , and    u  ′′     superscript  u  ′′    u^{\prime\prime}   is the second derivative of   u   u   u   with respect to   x   x   x   .  P2 is a ' two-dimensional ' problem ( Dirichlet problem )      P2  :   {         u   x  x     (  x  ,  y  )    +    u   y  y     (  x  ,  y  )     =   f   (  x  ,  y  )         in  Ω   ,        u  =  0       on   ∂  Ω    ,          normal-:  P2   cases         subscript  u    x  x     x  y       subscript  u    y  y     x  y       f   x  y       in  normal-Ω     u  0     on    normal-Ω       \mbox{P2 }:\begin{cases}u_{xx}(x,y)+u_{yy}(x,y)=f(x,y)&\mbox{ in }\Omega,\\
 u=0&\mbox{ on }\partial\Omega,\end{cases}     where   Ω   normal-Ω   \Omega   is a connected open region in the    (  x  ,  y  )     x  y    (x,y)   plane whose boundary    ∂  Ω      normal-Ω    \partial\Omega   is "nice" (e.g., a smooth manifold or a polygon ), and    u   x  x      subscript  u    x  x     u_{xx}   and    u   y  y      subscript  u    y  y     u_{yy}   denote the second derivatives with respect to   x   x   x   and   y   y   y   , respectively.  The problem P1 can be solved "directly" by computing antiderivatives . However, this method of solving the boundary value problem (BVP) works only when there is one spatial dimension and does not generalize to higher-dimensional problems or to problems like     u  +   u  ′′    =  f        u   superscript  u  ′′    f    u+u^{\prime\prime}=f   . For this reason, we will develop the finite element method for P1 and outline its generalization to P2.  Our explanation will proceed in two steps, which mirror two essential steps one must take to solve a boundary value problem (BVP) using the FEM.   In the first step, one rephrases the original BVP in its weak form. Little to no computation is usually required for this step. The transformation is done by hand on paper.  The second step is the discretization, where the weak form is discretized in a finite-dimensional space.   After this second step, we have concrete formulae for a large but finite-dimensional linear problem whose solution will approximately solve the original BVP. This finite-dimensional problem is then implemented on a computer .  Weak formulation  The first step is to convert P1 and P2 into their equivalent weak formulations .  The weak form of P1  If   u   u   u   solves P1, then for any smooth function   v   v   v   that satisfies the displacement boundary conditions, i.e.    v  =  0      v  0    v=0   at    x  =  0      x  0    x=0   and    x  =  1      x  1    x=1   , we have  (1)       ∫  0  1    f   (  x  )   v   (  x  )   d  x    =    ∫  0  1     u  ′′    (  x  )   v   (  x  )   d  x     .        superscript   subscript   0   1     f  x  v  x  d  x      superscript   subscript   0   1      superscript  u  ′′   x  v  x  d  x      \int_{0}^{1}f(x)v(x)\,dx=\int_{0}^{1}u^{\prime\prime}(x)v(x)\,dx.     Conversely, if   u   u   u   with     u   (  0  )    =   u   (  1  )    =  0          u  0     u  1        0     u(0)=u(1)=0   satisfies (1) for every smooth function    v   (  x  )       v  x    v(x)   then one may show that this   u   u   u   will solve P1. The proof is easier for twice continuously differentiable   u   u   u   ( mean value theorem ), but may be proved in a distributional sense as well.  By using integration by parts on the right-hand-side of (1), we obtain  (2)         ∫  0  1     f   (  x  )   v   (  x  )   d  x        =     ∫  0  1      u  ′′    (  x  )   v   (  x  )   d  x            =       u  ′    (  x  )   v   (  x  )    |   0  1   -     ∫  0  1      u  ′    (  x  )    v  ′    (  x  )   d  x              =   -     ∫  0  1      u  ′    (  x  )    v  ′    (  x  )   d  x     ≡   -   ϕ   (  u  ,  v  )      ,           superscript   subscript   0   1     f  x  v  x  d  x      absent    superscript   subscript   0   1      superscript  u  ′′   x  v  x  d  x        missing-subexpression     absent     evaluated-at     superscript  u  normal-′   x  v  x   0  1     superscript   subscript   0   1      superscript  u  normal-′   x   superscript  v  normal-′   x  d  x         missing-subexpression       absent      superscript   subscript   0   1      superscript  u  normal-′   x   superscript  v  normal-′   x  d  x              ϕ   u  v          \begin{aligned}\displaystyle\int_{0}^{1}f(x)v(x)\,dx&\displaystyle=\int_{0}^{1%
 }u^{\prime\prime}(x)v(x)\,dx\\
 &\displaystyle=u^{\prime}(x)v(x)|_{0}^{1}-\int_{0}^{1}u^{\prime}(x)v^{\prime}(%
 x)\,dx\\
 &\displaystyle=-\int_{0}^{1}u^{\prime}(x)v^{\prime}(x)\,dx\equiv-\phi(u,v),%
 \end{aligned}     where we have used the assumption that     v   (  0  )    =   v   (  1  )    =  0          v  0     v  1        0     v(0)=v(1)=0   .  The weak form of P2  If we integrate by parts using a form of Green's identities , we see that if   u   u   u   solves P2, then for any   v   v   v   ,         ∫  Ω    f   v   d  s    =   -    ∫  Ω     ∇  u   ⋅   ∇    v   d  s       ≡   -   ϕ   (  u  ,  v  )      ,          subscript   normal-Ω     f  v  d  s        subscript   normal-Ω    normal-⋅   normal-∇  u    normal-∇    v  d  s                ϕ   u  v        \int_{\Omega}fv\,ds=-\int_{\Omega}\nabla u\cdot\nabla v\,ds\equiv-\phi(u,v),     where   ∇   normal-∇   \nabla   denotes the gradient and   ⋅   normal-⋅   \cdot   denotes the dot product in the two-dimensional plane. Once more   ϕ   ϕ   \,\!\phi   can be turned into an inner product on a suitable space     H  0  1    (  Ω  )        superscript   subscript  H  0   1   normal-Ω    H_{0}^{1}(\Omega)   of "once differentiable" functions of   Ω   normal-Ω   \Omega   that are zero on    ∂  Ω      normal-Ω    \partial\Omega   . We have also assumed that    v  ∈    H  0  1    (  Ω  )        v     superscript   subscript  H  0   1   normal-Ω     v\in H_{0}^{1}(\Omega)   (see Sobolev spaces ). Existence and uniqueness of the solution can also be shown.  A proof outline of existence and uniqueness of the solution  We can loosely think of     H  0  1    (  0  ,  1  )        superscript   subscript  H  0   1    0  1     H_{0}^{1}(0,1)   to be the absolutely continuous functions of    (  0  ,  1  )     0  1    (0,1)   that are   0   0    at    x  =  0      x  0    x=0   and    x  =  1      x  1    x=1   (see Sobolev spaces ). Such functions are (weakly) "once differentiable" and it turns out that the symmetric bilinear map    ϕ   ϕ   \!\,\phi   then defines an inner product which turns     H  0  1    (  0  ,  1  )        superscript   subscript  H  0   1    0  1     H_{0}^{1}(0,1)   into a Hilbert space (a detailed proof is nontrivial). On the other hand, the left-hand-side     ∫  0  1    f   (  x  )   v   (  x  )   d  x       superscript   subscript   0   1     f  x  v  x  d  x     \int_{0}^{1}f(x)v(x)dx   is also an inner product, this time on the Lp space      L  2    (  0  ,  1  )        superscript  L  2    0  1     L^{2}(0,1)   . An application of the Riesz representation theorem for Hilbert spaces shows that there is a unique   u   u   u   solving (2) and therefore P1. This solution is a-priori only a member of     H  0  1    (  0  ,  1  )        superscript   subscript  H  0   1    0  1     H_{0}^{1}(0,1)   , but using elliptic regularity, will be smooth if   f   f   f   is.  Discretization  (Figure)  A function in     H  0  1   ,     superscript   subscript  H  0   1    H_{0}^{1},   with zero values at the endpoints (blue), and a piecewise linear approximation (red)   P1 and P2 are ready to be discretized which leads to a common sub-problem (3). The basic idea is to replace the infinite-dimensional linear problem:   Find    u  ∈   H  0  1       u   superscript   subscript  H  0   1     u\in H_{0}^{1}   such that        ∀  v   ∈   H  0  1    ,    -   ϕ   (  u  ,  v  )     =   ∫   f  v        formulae-sequence     for-all  v    superscript   subscript  H  0   1          ϕ   u  v         f  v       \forall v\in H_{0}^{1},\;-\phi(u,v)=\int fv      with a finite-dimensional version:   (3) Find    u  ∈  V      u  V    u\in V   such that        ∀  v   ∈  V   ,    -   ϕ   (  u  ,  v  )     =   ∫   f  v        formulae-sequence     for-all  v   V         ϕ   u  v         f  v       \forall v\in V,\;-\phi(u,v)=\int fv      where   V   V   V   is a finite-dimensional subspace of    H  0  1     superscript   subscript  H  0   1    H_{0}^{1}   . There are many possible choices for   V   V   V   (one possibility leads to the spectral method ). However, for the finite element method we take   V   V   V   to be a space of piecewise polynomial functions.  For problem P1  We take the interval    (  0  ,  1  )     0  1    (0,1)   , choose   n   n   n   values of   x   x   x   with    V  =   {  v  :     [  0  ,  1  ]   →   ℝ    :        v  is continuous,  v   |    [   x  k   ,   x   k  +  1    ]    is linear for  k   =   0  ,  …    ,    n  , and  v   (  0  )    =   v   (  1  )    =  0     }       V   conditional-set  v   normal-:   normal-→   0  1   ℝ    formulae-sequence       evaluated-at    v  is continuous,  v     subscript  x  k    subscript  x    k  1      is linear for  k    0  normal-…          n  , and  v  0     v  1        0         V=\{v:[0,1]\rightarrow\mathbb{R}\;:v\mbox{ is continuous, }v|_{[x_{k},x_{k+1}]%
 }\mbox{ is linear for }k=0,\dots,n\mbox{, and }v(0)=v(1)=0\}   by:       x  0   =  0       subscript  x  0   0    x_{0}=0     where we define     x   n  +  1    =  1       subscript  x    n  1    1    x_{n+1}=1   and   V   V   V   . Observe that functions in    v  ∈  V      v  V    v\in V   are not differentiable according to the elementary definition of calculus. Indeed, if    x  =   x  k       x   subscript  x  k     x=x_{k}   then the derivative is typically not defined at any    k  =   1  ,  …  ,  n       k   1  normal-…  n     k=1,\ldots,n   ,   x   x   x   . However, the derivative exists at every other value of   V   V   V   and one can use this derivative for the purpose of integration by parts .  (Figure)  A piecewise linear function in two dimensions   For problem P2  We need   Ω   normal-Ω   \Omega   to be a set of functions of   Ω   normal-Ω   \Omega   . In the figure on the right, we have illustrated a triangulation of a 15 sided polygonal region   V   V   V   in the plane (below), and a piecewise linear function (above, in color) of this polygon which is linear on each triangle of the triangulation; the space    V  h     subscript  V  h    V_{h}   would consist of functions that are linear on each triangle of the chosen triangulation.  One often reads   V   V   V   instead of    h  >  0      h  0    h>0   in the literature. The reason is that one hopes that as the underlying triangular grid becomes finer and finer, the solution of the discrete problem (3) will in some sense converge to the solution of the original boundary value problem P2. The triangulation is then indexed by a real valued parameter   V   V   V   which one takes to be very small. This parameter will be related to the size of the largest or average triangle in the triangulation. As we refine the triangulation, the space of piecewise linear functions   h   h   h   must also change with    V  h     subscript  V  h    V_{h}   , hence the notation   V   V   V   . Since we do not perform such an analysis, we will not use this notation.  Choosing a basis  To complete the discretization, we must select a basis of    x  k     subscript  x  k    x_{k}   . In the one-dimensional case, for each control point    v  k     subscript  v  k    v_{k}   we will choose the piecewise linear function   V   V   V   in   1   1   1   whose value is    x  k     subscript  x  k    x_{k}   at      x  j   ,  j   ≠  k        subscript  x  j   j   k    x_{j},\;j\neq k   and zero at every      v  k    (  x  )    =   {        x  -   x   k  -  1        x  k    -   x   k  -  1            if  x   ∈   [   x   k  -  1    ,   x  k   ]    ,            x   k  +  1     -  x      x   k  +  1     -   x  k           if  x   ∈   [   x  k   ,   x   k  +  1    ]    ,       0     otherwise  ,              subscript  v  k   x    cases      x   subscript  x    k  1        subscript  x  k    subscript  x    k  1          if  x     subscript  x    k  1     subscript  x  k          subscript  x    k  1    x      subscript  x    k  1     subscript  x  k         if  x     subscript  x  k    subscript  x    k  1      0  otherwise     v_{k}(x)=\begin{cases}{x-x_{k-1}\over x_{k}\,-x_{k-1}}&\mbox{ if }x\in[x_{k-1}%
 ,x_{k}],\\
 {x_{k+1}\,-x\over x_{k+1}\,-x_{k}}&\mbox{ if }x\in[x_{k},x_{k+1}],\\
 0&\mbox{ otherwise},\end{cases}   , i.e.,      k  =   1  ,  …  ,  n       k   1  normal-…  n     k=1,\dots,n     for    v  k     subscript  v  k    v_{k}   ; this basis is a shifted and scaled tent function . For the two-dimensional case, we choose again one basis function    x  k     subscript  x  k    x_{k}   per vertex   Ω   normal-Ω   \Omega   of the triangulation of the planar region    v  k     subscript  v  k    v_{k}   . The function   V   V   V   is the unique function of   1   1   1   whose value is    x  k     subscript  x  k    x_{k}   at      x  j   ,  j   ≠  k        subscript  x  j   j   k    x_{j},\;j\neq k   and zero at every     ⟨   v  j   ,   v  k   ⟩   =    ∫  0  1     v  j     v  k    d  x          subscript  v  j    subscript  v  k      superscript   subscript   0   1      subscript  v  j    subscript  v  k   d  x      \langle v_{j},v_{k}\rangle=\int_{0}^{1}v_{j}v_{k}\,dx   .  Depending on the author, the word "element" in "finite element method" refers either to the triangles in the domain, the piecewise linear basis function, or both. So for instance, an author interested in curved domains might replace the triangles with curved primitives, and so might describe the elements as being curvilinear. On the other hand, some authors replace "piecewise linear" by "piecewise quadratic" or even "piecewise polynomial". The author might then say "higher order element" instead of "higher degree polynomial". Finite element method is not restricted to triangles (or tetrahedra in 3-d, or higher order simplexes in multidimensional spaces), but can be defined on quadrilateral subdomains (hexahedra, prisms, or pyramids in 3-d, and so on). Higher order shapes (curvilinear elements) can be defined with polynomial and even non-polynomial shapes (e.g. ellipse or circle).  Examples of methods that use higher degree piecewise polynomial basis functions are the hp-FEM and spectral FEM .  More advanced implementations (adaptive finite element methods) utilize a method to assess the quality of the results (based on error estimation theory) and modify the mesh during the solution aiming to achieve approximate solution within some bounds from the 'exact' solution of the continuum problem. Mesh adaptivity may utilize various techniques, the most popular are:   moving nodes (r-adaptivity)  refining (and unrefining) elements (h-adaptivity)  changing order of base functions (p-adaptivity)  combinations of the above ( hp-adaptivity ).   Small support of the basis  The primary advantage of this choice of basis is that the inner products       ϕ   (   v  j   ,   v  k   )    =    ∫  0  1     v  j  ′     v  k  ′    d  x          ϕ    subscript  v  j    subscript  v  k       superscript   subscript   0   1      superscript   subscript  v  j   normal-′    superscript   subscript  v  k   normal-′   d  x      \phi(v_{j},v_{k})=\int_{0}^{1}v_{j}^{\prime}v_{k}^{\prime}\,dx   and      j  ,  k     j  k    j,k     will be zero for almost all    ⟨   v  j   ,   v  k   ⟩      subscript  v  j    subscript  v  k     \langle v_{j},v_{k}\rangle   . (The matrix containing    (  j  ,  k  )     j  k    (j,k)   in the    v  k     subscript  v  k    v_{k}   location is known as the Gramian matrix .) In the one dimensional case, the support of    [   x   k  -  1    ,   x   k  +  1    ]      subscript  x    k  1     subscript  x    k  1      [x_{k-1},x_{k+1}]   is the interval    ⟨   v  j   ,   v  k   ⟩      subscript  v  j    subscript  v  k     \langle v_{j},v_{k}\rangle   . Hence, the integrands of    ϕ   (   v  j   ,   v  k   )       ϕ    subscript  v  j    subscript  v  k      \phi(v_{j},v_{k})   and      |   j  -  k   |   >  1          j  k    1    |j-k|>1    are identically zero whenever    x  j     subscript  x  j    x_{j}   .  Similarly, in the planar case, if    x  k     subscript  x  k    x_{k}   and     ∫  Ω     v  j     v  k    d  s       subscript   normal-Ω      subscript  v  j    subscript  v  k   d  s     \int_{\Omega}v_{j}v_{k}\,ds   do not share an edge of the triangulation, then the integrals       ∫  Ω     ∇   v  j    ⋅   ∇     v  k    d  s         subscript   normal-Ω    normal-⋅   normal-∇   subscript  v  j     normal-∇     subscript  v  k   d  s       \int_{\Omega}\nabla v_{j}\cdot\nabla v_{k}\,ds   and       u   (  x  )    =    ∑   k  =  1   n     u  k    v  k    (  x  )           u  x     superscript   subscript     k  1    n      subscript  u  k    subscript  v  k   x      u(x)=\sum_{k=1}^{n}u_{k}v_{k}(x)   are both zero.  Matrix form of the problem  If we write     f   (  x  )    =    ∑   k  =  1   n     f  k    v  k    (  x  )           f  x     superscript   subscript     k  1    n      subscript  f  k    subscript  v  k   x      f(x)=\sum_{k=1}^{n}f_{k}v_{k}(x)   and     v   (  x  )    =    v  j    (  x  )          v  x      subscript  v  j   x     v(x)=v_{j}(x)   then problem (3), taking    j  =   1  ,  …  ,  n       j   1  normal-…  n     j=1,\dots,n   for     -    ∑   k  =  1   n     u  k   ϕ   (   v  k   ,   v  j   )      =    ∑   k  =  1   n     f  k    ∫    v  k    v  j   d  x              superscript   subscript     k  1    n      subscript  u  k   ϕ    subscript  v  k    subscript  v  j         superscript   subscript     k  1    n      subscript  f  k        subscript  v  k    subscript  v  j   d  x        -\sum_{k=1}^{n}u_{k}\phi(v_{k},v_{j})=\sum_{k=1}^{n}f_{k}\int v_{k}v_{j}dx   , becomes       j  =   1  ,  …  ,  n    .      j   1  normal-…  n     j=1,\dots,n.   for   𝐮   𝐮   \mathbf{u}   (4)  If we denote by   𝐟   𝐟   \mathbf{f}   and     (   u  1   ,  …  ,   u  n   )   t     superscript    subscript  u  1   normal-…   subscript  u  n    t    (u_{1},\dots,u_{n})^{t}   the column vectors     (   f  1   ,  …  ,   f  n   )   t     superscript    subscript  f  1   normal-…   subscript  f  n    t    (f_{1},\dots,f_{n})^{t}   and    L  =   (   L   i  j    )       L   subscript  L    i  j      L=(L_{ij})   , and if we let      M  =   (   M   i  j    )       M   subscript  M    i  j      M=(M_{ij})   and       L   i  j    =   ϕ   (   v  i   ,   v  j   )         subscript  L    i  j      ϕ    subscript  v  i    subscript  v  j       L_{ij}=\phi(v_{i},v_{j})   be matrices whose entries are       M   i  j    =   ∫    v  i    v  j   d  x         subscript  M    i  j         subscript  v  i    subscript  v  j   d  x      M_{ij}=\int v_{i}v_{j}dx   and        -   L  𝐮    =   M  𝐟    .          L  𝐮      M  𝐟     -L\mathbf{u}=M\mathbf{f}.   then we may rephrase (4) as       f   (  x  )    =    ∑   k  =  1   n     f  k    v  k    (  x  )           f  x     superscript   subscript     k  1    n      subscript  f  k    subscript  v  k   x      f(x)=\sum_{k=1}^{n}f_{k}v_{k}(x)   (5)  It is not necessary to assume    f   (  x  )       f  x    f(x)   . For a general function     v   (  x  )    =    v  j    (  x  )          v  x      subscript  v  j   x     v(x)=v_{j}(x)   , problem (3) with    j  =   1  ,  …  ,  n       j   1  normal-…  n     j=1,\dots,n   for   M   M   M   becomes actually simpler, since no matrix     -   L  𝐮    =  𝐛          L  𝐮    𝐛    -L\mathbf{u}=\mathbf{b}   is used,      𝐛  =    (   b  1   ,  …  ,   b  n   )   t       𝐛   superscript    subscript  b  1   normal-…   subscript  b  n    t     \mathbf{b}=(b_{1},\dots,b_{n})^{t}   , (6) where     b  j   =   ∫   f   v  j   d  x         subscript  b  j       f   subscript  v  j   d  x      b_{j}=\int fv_{j}dx   and    j  =   1  ,  …  ,  n       j   1  normal-…  n     j=1,\dots,n   for   L   L   L   .  As we have discussed before, most of the entries of   M   M   M   and    v  k     subscript  v  k    v_{k}   are zero because the basis functions   𝐮   𝐮   \mathbf{u}   have small support. So we now have to solve a linear system in the unknown   L   L   L   where most of the entries of the matrix   L   L   L   , which we need to invert, are zero.  Such matrices are known as sparse matrices , and there are efficient solvers for such problems (much more efficient than actually inverting the matrix.) In addition,   L   L   L   is symmetric and positive definite, so a technique such as the conjugate gradient method is favored. For problems that are not too large, sparse LU decompositions and Cholesky decompositions still work well. For instance, MATLAB 's backslash operator (which uses sparse LU, sparse Cholesky, and other factorization methods) can be sufficient for meshes with a hundred thousand vertices.  The matrix   M   M   M   is usually referred to as the stiffness matrix , while the matrix   Ω   normal-Ω   \Omega   is dubbed the mass matrix .  General form of the finite element method  In general, the finite element method is characterized by the following process.   One chooses a grid for      u   x  x  x  x    +   u   y  y  y  y     =  f         subscript  u    x  x  x  x     subscript  u    y  y  y  y     f    u_{xxxx}+u_{yyyy}=f   . In the preceding treatment, the grid consisted of triangles, but one can also use squares or curvilinear polygons.  Then, one chooses basis functions. In our discussion, we used piecewise linear basis functions, but it is also common to use piecewise polynomial basis functions.   A separate consideration is the smoothness of the basis functions. For second order elliptic boundary value problems , piecewise polynomial basis function that are merely continuous suffice (i.e., the derivatives are discontinuous.) For higher order partial differential equations, one must use smoother basis functions. For instance, for a fourth order problem such as    C  1     superscript  C  1    C^{1}   , one may use piecewise quadratic basis functions that are    V   V   V    .  Another consideration is the relation of the finite-dimensional space    H  0  1     superscript   subscript  H  0   1    H_{0}^{1}   to its infinite-dimensional counterpart, in the examples above   V   V   V   . A conforming element method is one in which the space    H  0  1     superscript   subscript  H  0   1    H_{0}^{1}   is a subspace of the element space for the continuous problem. The example above is such a method. If this condition is not satisfied, we obtain a nonconforming element method , an example of which is the space of piecewise linear functions over the mesh which are continuous at each edge midpoint. Since these functions are in general discontinuous along the edges, this finite-dimensional space is not a subspace of the original   h   h   h   .  Typically, one has an algorithm for taking a given mesh and subdividing it. If the main method for increasing precision is to subdivide the mesh, one has an h -method ( h is customarily the diameter of the largest element in the mesh.) In this manner, if one shows that the error with a grid    C   h  p       C   superscript  h  p     Ch^{p}   is bounded above by    C  <  ∞      C     C<\infty   , for some    p  >  0      p  0    p>0   and   d   d   d   , then one has an order p method. Under certain hypotheses (for instance, if the domain is convex), a piecewise polynomial of order    p  =   d  +  1       p    d  1     p=d+1   method will have an error of order    ℝ  n     superscript  ℝ  n    \mathbb{R}^{n}   .  If instead of making h smaller, one increases the degree of the polynomials used in the basis function, one has a p -method. If one combines these two refinement types, one obtains an hp -method ( hp-FEM ). In the hp-FEM, the polynomial degrees can vary from element to element. High order methods with large uniform p are called spectral finite element methods ( SFEM ). These are not to be confused with spectral methods .  For vector partial differential equations, the basis functions may take values in $\mathbb{R}^n$ .  Various types of finite element methods  AEM  The Applied Element Method, or AEM combines features of both FEM and Discrete element method , or (DEM).  Generalized finite element method  The generalized finite element method (GFEM) uses local spaces consisting of functions, not necessarily polynomials, that reflect the available information on the unknown solution and thus ensure good local approximation. Then a partition of unity is used to “bond” these spaces together to form the approximating subspace. The effectiveness of GFEM has been shown when applied to problems with domains having complicated boundaries, problems with micro-scales, and problems with boundary layers. 11  Mixed finite element method  hp-FEM  The hp-FEM combines adaptively, elements with variable size h and polynomial degree p in order to achieve exceptionally fast, exponential convergence rates. 12  hpk-FEM  The hpk-FEM combines adaptively, elements with variable size h , polynomial degree of the local approximations p and global differentiability of the local approximations (k-1) in order to achieve best convergence rates.  XFEM  S-FEM  Fiber beam method  Spectral element method  Meshfree methods  Discontinuous Galerkin methods  Finite element limit analysis  Stretched grid method  Comparison to the finite difference method  The finite difference method (FDM) is an alternative way of approximating solutions of PDEs. The differences between FEM and FDM are:   The most attractive feature of the FEM is its ability to handle complicated geometries (and boundaries) with relative ease. While FDM in its basic form is restricted to handle rectangular shapes and simple alterations thereof, the handling of geometries in FEM is theoretically straightforward.    The most attractive feature of finite differences is that it can be very easy to implement.    There are several ways one could consider the FDM a special case of the FEM approach. E.g., first order FEM is identical to FDM for Poisson's equation, if the problem is discretized by a regular rectangular mesh with each rectangle divided into two triangles.    There are reasons to consider the mathematical foundation of the finite element approximation more sound, for instance, because the quality of the approximation between grid points is poor in FDM.    The quality of a FEM approximation is often higher than in the corresponding FDM approach, but this is extremely problem-dependent and several examples to the contrary can be provided.   Generally, FEM is the method of choice in all types of analysis in structural mechanics (i.e. solving for deformation and stresses in solid bodies or dynamics of structures) while computational fluid dynamics (CFD) tends to use FDM or other methods like finite volume method (FVM). CFD problems usually require discretization of the problem into a large number of cells/gridpoints (millions and more), therefore cost of the solution favors simpler, lower order approximation within each cell. This is especially true for 'external flow' problems, like air flow around the car or airplane, or weather simulation.  Application  A variety of specializations under the umbrella of the mechanical engineering discipline (such as aeronautical, biomechanical, and automotive industries) commonly use integrated FEM in design and development of their products. Several modern FEM packages include specific components such as thermal, electromagnetic, fluid, and structural working environments. In a structural simulation, FEM helps tremendously in producing stiffness and strength visualizations and also in minimizing weight, materials, and costs.  FEM allows detailed visualization of where structures bend or twist, and indicates the distribution of stresses and displacements. FEM software provides a wide range of simulation options for controlling the complexity of both modeling and analysis of a system. Similarly, the desired level of accuracy required and associated computational time requirements can be managed simultaneously to address most engineering applications. FEM allows entire designs to be constructed, refined, and optimized before the design is manufactured.  This powerful design tool has significantly improved both the standard of engineering designs and the methodology of the design process in many industrial applications. 13 The introduction of FEM has substantially decreased the time to take products from concept to the production line. 14 It is primarily through improved initial prototype designs using FEM that testing and development have been accelerated. 15 In summary, benefits of FEM include increased accuracy, enhanced design and better insight into critical design parameters, virtual prototyping, fewer hardware prototypes, a faster and less expensive design cycle, increased productivity, and increased revenue. 16  FEA has also been proposed to use in stochastic modelling for numerically solving probability models. 17 18  See also   Applied element method  Boundary element method  Computer experiment  Direct stiffness method  Discontinuity layout optimization  Discrete element method  Finite element machine  Finite element method in structural mechanics  Finite volume method for unsteady flow  Interval finite element  Isogeometric analysis  Lattice Boltzmann methods  List of finite element software packages  Movable cellular automaton  Multidisciplinary design optimization  Multiphysics  Patch test  Rayleigh–Ritz method  Weakened weak form   References  Further reading   G. Allaire and A. Craig: Numerical Analysis and Optimization:An Introduction to Mathematical Modelling and Numerical Simulation  K. J. Bathe : Numerical methods in finite element analysis , Prentice-Hall (1976).  J. Chaskalovic, Finite Elements Methods for Engineering Sciences , Springer Verlag, (2008).  O. C. Zienkiewicz, R. L. Taylor, J. Z. Zhu : The Finite Element Method: Its Basis and Fundamentals , Butterworth-Heinemann, (2005).   External links   IFER Internet Finite Element Resources - Describes and provides access to finite element analysis software via the Internet.  MIT Open Course-ware on Linear finite element method (With video lectures)  NAFEMS —The International Association for the Engineering Analysis Community  Finite Element Analysis Resources - Finite Element news, articles and tips  Finite-element Methods for Electromagnetics - free 320-page text  Finite Element Books - books bibliography  Mathematics of the Finite Element Method  Finite Element Methods for Partial Differential Equations - Lecture notes by Endre Süli  Electromagnetic Modeling web site at Clemson University (includes list of currently available software)   "  Category:Continuum mechanics  Category:Finite element method  Category:Numerical differential equations  Category:Partial differential equations  Category:Structural analysis     ↩  ↩  ↩  ↩  ↩  ↩  ↩  ↩  ↩  ↩  ↩  P. Solin, K. Segeth, I. Dolezel: Higher-Order Finite Element Methods, Chapman & Hall/CRC Press, 2003 ↩  Hastings, J. K., Juds, M. A., Brauer, J. R., Accuracy and Economy of Finite Element Magnetic Analysis , 33rd Annual National Relay Conference, April 1985. ↩   ↩   ↩  ↩     