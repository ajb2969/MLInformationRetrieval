<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="222">BIRCH</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>BIRCH</h1>
<hr/>

<p><strong>BIRCH</strong> (balanced iterative reducing and clustering using hierarchies) is an unsupervised <a href="data_mining" title="wikilink">data mining</a> algorithm used to perform <a href="Data_clustering" title="wikilink">hierarchical clustering</a> over particularly large data-sets.<a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a> An advantage of BIRCH is its ability to incrementally and dynamically cluster incoming, multi-dimensional metric <a href="data_point" title="wikilink">data points</a> in an attempt to produce the best quality clustering for a given set of resources (memory and <a href="time_constraint" title="wikilink">time constraints</a>). In most cases, BIRCH only requires a single scan of the database.</p>

<p>Its inventors claim BIRCH to be the "first clustering algorithm proposed in the database area to handle 'noise' (data points that are not part of the underlying pattern) effectively",<a class="footnoteRef" href="#fn2" id="fnref2"><sup>2</sup></a> beating <a class="uri" href="DBSCAN" title="wikilink">DBSCAN</a> by two months. The algorithm received the SIGMOD 10 year test of time award in 2006.<a class="footnoteRef" href="#fn3" id="fnref3"><sup>3</sup></a></p>
<h2 id="problem-with-previous-methods">Problem with previous methods</h2>

<p>Previous clustering algorithms performed less effectively over very large databases and did not adequately consider the case wherein a data-set was too large to fit in <a href="Primary_storage" title="wikilink">main memory</a>. As a result, there was a lot of overhead maintaining high clustering quality while minimizing the cost of addition IO (input/output) operations. Furthermore, most of BIRCH's predecessors inspect all data points (or all currently existing clusters) equally for each 'clustering decision' and do not perform heuristic weighting based on the distance between these data points.</p>
<h2 id="advantages-with-birch">Advantages with BIRCH</h2>

<p>It is local in that each clustering decision is made without scanning all data points and currently existing clusters. It exploits the observation that data space is not usually uniformly occupied and not every data point is equally important. It makes full use of available memory to derive the finest possible sub-clusters while minimizing I/O costs. It is also an incremental method that does not require the whole <a href="data_set" title="wikilink">data set</a> in advance.</p>
<h2 id="algorithm">Algorithm</h2>

<p>The BIRCH algorithm takes as input a set of 

<math display="inline" id="BIRCH:0">
 <semantics>
  <mi>N</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>N</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   N
  </annotation>
 </semantics>
</math>

 data points, represented as <a href="feature_vector" title="wikilink">real-valued vectors</a>, and a desired number of clusters 

<math display="inline" id="BIRCH:1">
 <semantics>
  <mi>K</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>K</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   K
  </annotation>
 </semantics>
</math>

. It operates in four phases, the second of which is optional.</p>

<p>The first phase builds a <em>CF tree</em> out of the data points, a height-balanced <a href="tree_data_structure" title="wikilink">tree data structure</a>, defined as follows:</p>
<ul>
<li>Given a set of N d-dimensional data points, the <em>clustering feature</em> 

<math display="inline" id="BIRCH:2">
 <semantics>
  <mrow>
   <mi>C</mi>
   <mi>F</mi>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <ci>C</ci>
    <ci>F</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   CF
  </annotation>
 </semantics>
</math>

 of the set is defined as the triple 

<math display="inline" id="BIRCH:3">
 <semantics>
  <mrow>
   <mrow>
    <mi>C</mi>
    <mi>F</mi>
   </mrow>
   <mo>=</mo>
   <mrow>
    <mo stretchy="false">(</mo>
    <mi>N</mi>
    <mo>,</mo>
    <mrow>
     <mi>L</mi>
     <mi>S</mi>
    </mrow>
    <mo>,</mo>
    <mrow>
     <mi>S</mi>
     <mi>S</mi>
    </mrow>
    <mo stretchy="false">)</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <times></times>
     <ci>C</ci>
     <ci>F</ci>
    </apply>
    <vector>
     <ci>N</ci>
     <apply>
      <times></times>
      <ci>L</ci>
      <ci>S</ci>
     </apply>
     <apply>
      <times></times>
      <ci>S</ci>
      <ci>S</ci>
     </apply>
    </vector>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   CF=(N,LS,SS)
  </annotation>
 </semantics>
</math>


, where 

<math display="inline" id="BIRCH:4">
 <semantics>
  <mrow>
   <mi>L</mi>
   <mi>S</mi>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <ci>L</ci>
    <ci>S</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   LS
  </annotation>
 </semantics>
</math>

 is the linear sum and 

<math display="inline" id="BIRCH:5">
 <semantics>
  <mrow>
   <mi>S</mi>
   <mi>S</mi>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <ci>S</ci>
    <ci>S</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   SS
  </annotation>
 </semantics>
</math>

 is the square sum of data points.</li>
</ul>
<ul>
<li>Clustering features are organized in a <em>CF tree</em>, a height-balanced tree with two parameters: <a href="branching_factor" title="wikilink">branching factor</a> 

<math display="inline" id="BIRCH:6">
 <semantics>
  <mi>B</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>B</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   B
  </annotation>
 </semantics>
</math>

 and threshold 

<math display="inline" id="BIRCH:7">
 <semantics>
  <mi>T</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>T</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   T
  </annotation>
 </semantics>
</math>

. Each non-leaf node contains at most 

<math display="inline" id="BIRCH:8">
 <semantics>
  <mi>B</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>B</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   B
  </annotation>
 </semantics>
</math>


 entries of the form 

<math display="inline" id="BIRCH:9">
 <semantics>
  <mrow>
   <mo stretchy="false">[</mo>
   <mrow>
    <mi>C</mi>
    <msub>
     <mi>F</mi>
     <mi>i</mi>
    </msub>
   </mrow>
   <mo>,</mo>
   <mrow>
    <mi>c</mi>
    <mi>h</mi>
    <mi>i</mi>
    <mi>l</mi>
    <msub>
     <mi>d</mi>
     <mi>i</mi>
    </msub>
   </mrow>
   <mo stretchy="false">]</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <interval closure="closed">
    <apply>
     <times></times>
     <ci>C</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>F</ci>
      <ci>i</ci>
     </apply>
    </apply>
    <apply>
     <times></times>
     <ci>c</ci>
     <ci>h</ci>
     <ci>i</ci>
     <ci>l</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>d</ci>
      <ci>i</ci>
     </apply>
    </apply>
   </interval>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   [CF_{i},child_{i}]
  </annotation>
 </semantics>
</math>

, where 

<math display="inline" id="BIRCH:10">
 <semantics>
  <mrow>
   <mi>c</mi>
   <mi>h</mi>
   <mi>i</mi>
   <mi>l</mi>
   <msub>
    <mi>d</mi>
    <mi>i</mi>
   </msub>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <ci>c</ci>
    <ci>h</ci>
    <ci>i</ci>
    <ci>l</ci>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>d</ci>
     <ci>i</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   child_{i}
  </annotation>
 </semantics>
</math>

 is a pointer to its 

<math display="inline" id="BIRCH:11">
 <semantics>
  <mi>i</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>i</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   i
  </annotation>
 </semantics>
</math>

th <a href="Tree_(data_structure)" title="wikilink">child node</a> and 

<math display="inline" id="BIRCH:12">
 <semantics>
  <mrow>
   <mi>C</mi>
   <msub>
    <mi>F</mi>
    <mi>i</mi>
   </msub>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <ci>C</ci>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>F</ci>
     <ci>i</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   CF_{i}
  </annotation>
 </semantics>
</math>

 the clustering feature representing the associated subcluster. A <a href="leaf_node" title="wikilink">leaf node</a> contains at most 

<math display="inline" id="BIRCH:13">
 <semantics>
  <mi>L</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>L</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   L
  </annotation>
 </semantics>
</math>


 entries each of the form 

<math display="inline" id="BIRCH:14">
 <semantics>
  <mrow>
   <mo stretchy="false">[</mo>
   <mrow>
    <mi>C</mi>
    <msub>
     <mi>F</mi>
     <mi>i</mi>
    </msub>
   </mrow>
   <mo stretchy="false">]</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="latexml">delimited-[]</csymbol>
    <apply>
     <times></times>
     <ci>C</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>F</ci>
      <ci>i</ci>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   [CF_{i}]
  </annotation>
 </semantics>
</math>

 . It also has two pointers prev and next which are used to chain all leaf nodes together. The tree size depends on the parameter T. A node is required to fit in a page of size P. B and L are determined by P. So P can be varied for <a href="performance_tuning" title="wikilink">performance tuning</a>. It is a very compact representation of the dataset because each entry in a leaf node is not a single data point but a subcluster.</li>
</ul>

<p>In the second step, the algorithm scans all the leaf entries in the initial CF tree to rebuild a smaller CF tree, while removing outliers and grouping crowded subclusters into larger ones. This step is marked optional in the original presentation of BIRCH.</p>

<p>In step three an existing clustering algorithm is used to cluster all leaf entries. Here an agglomerative hierarchical clustering algorithm is applied directly to the subclusters represented by their CF vectors. It also provides the flexibility of allowing the user to specify either the desired number of clusters or the desired diameter threshold for clusters. After this step a set of clusters is obtained that captures major distribution pattern in the data. However there might exist minor and localized inaccuracies which can be handled by an optional step 4. In step 4 the centroids of the clusters produced in step 3 are used as seeds and redistribute the data points to its closest seeds to obtain a new set of clusters. Step 4 also provides us with an option of discarding outliers. That is a point which is too far from its closest seed can be treated as an outlier.</p>
<h2 id="notes">Notes</h2>

<p>"</p>

<p><a href="Category:Data_clustering_algorithms" title="wikilink">Category:Data clustering algorithms</a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1"><a href="#fnref1">↩</a></li>
<li id="fn2"></li>
<li id="fn3"><a href="#fnref3">↩</a></li>
</ol>
</section>
</body>
</html>
