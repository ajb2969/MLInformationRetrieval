


Algorithmic Lovász local lemma




Algorithmic Lovász local lemma

In theoretical computer science, the algorithmic Lovász local lemma gives an algorithmic way of constructing objects that obey a system of constraints with limited dependence.
Given a finite set of bad events {A1, ..., An} in a probability space with limited dependence amongst the Ais and with specific bounds on their respective probabilities, the Lovász local lemma proves that with non-zero probability all of these events can be avoided. However, the lemma is non-constructive in that it does not provide any insight on how to avoid the bad events.
If the events {A1, ..., An} are determined by a finite collection of mutually independent random variables, a simple Las Vegas algorithm with expected polynomial runtime proposed by Robin Moser and Gábor Tardos1 can compute an assignment to the random variables such that all events are avoided.
Review of Lovász local lemma
The Lovász Local Lemma is a powerful tool commonly used in the probabilistic method to prove the existence of certain complex mathematical objects with a set of prescribed features. A typical proof proceeds by operating on the complex object in a random manner and uses the Lovász Local Lemma to bound the probability that any of the features is missing. The absence of a feature is considered a bad event and if it can be shown that all such bad events can be avoided simultaneously with non-zero probability, the existence follows. The lemma itself reads as follows:

Let 
 
 
 
  be a finite set of events in the probability space Ω. For 
 
 
 
  let 
 
 
 
  denote a subset of 
 
 
 
  such that 
 
 
 
  is independent from the collection of events 
 
 
 
 . If there exists an assignment of reals 
 
 
 
  to the events such that



then the probability of avoiding all events in 
 
 
 
  is positive, in particular




Algorithmic version of the Lovász local lemma
The Lovász Local Lemma is non-constructive because it only allows us to conclude the existence of structural properties or complex objects but does not indicate how these can be found or constructed efficiently in practice. Note that random sampling from the probability space Ω is likely to be inefficient, since the probability of the event of interest



is only bounded by a product of small numbers



and therefore likely to be very small.
Under the assumption that all of the events in 
 
 
 
  are determined by a finite collection of mutually independent random variables

 
  in Ω, Robin Moser and Gábor Tardos proposed an efficient randomized algorithm that computes an assignment to the random variables in 
 
 
 
  such that all events in 
 
 
 
  are avoided.
Hence, this algorithm can be used to efficiently construct witnesses of complex objects with prescribed features for most problems to which the Lovász Local Lemma applies.
History
 Prior to the recent work of Moser and Tardos, earlier work had also made progress in developing algorithmic versions of the Lovász Local Lemma. József Beck in 1991 first gave proof that an algorithmic version was possible.2 In this breakthrough result, a stricter requirement was imposed upon the problem formulation than in the original non-constructive definition. Beck's approach required that for each 
 
 
 
 , the number of dependencies of A was bounded above with 
 
 
 
  (approximately). The existential version of the Local Lemma permits a larger upper bound on dependencies:



This bound is known to be tight. Since the initial algorithm, work has been done to push algorithmic versions of the Local Lemma closer to this tight value. Moser and Tardos's recent work are the most recent in this chain, and provide an algorithm that achieves this tight bound.
Algorithm
Let us first introduce some concepts that are used in the algorithm.
For any random variable 
 
 
 
  denotes the current assignment (evaluation) of P. An assignment (evaluation) to all random variables is denoted 
 
 
 
 .
The unique minimal subset of random variables in 
 
 
 
  that determine the event A is denoted by vbl(A).
If the event A is true under an evaluation 
 
 
 
 , we say that 
 
 
satisfies A, otherwise it avoids A.
Given a set of bad events 
 
 
 
  we wish to avoid that is determined by a collection of mutually independent random variables 
 
 
 
 , the algorithm proceeds as follows:




 
  a random evaluation of P
while

 
  such that A is satisfied by 
 
 

pick an arbitrary satisfied event 
 
 




 
  a new random evaluation of P

return



In the first step, the algorithm randomly initializes the current assignment vP for each random variable 
 
 
 
 . This means that an assignment vP is sampled randomly and independently according to the distribution of the random variable P.
The algorithm then enters the main loop which is executed until all events in 
 
 
 
  are avoided and which point the algorithm returns the current assignment. At each iteration of the main loop, the algorithm picks an arbitrary satisfied event A (either randomly or deterministically) and resamples all the random variables that determine A.
Main theorem
Let 
 
 
 
  be a finite set of mutually independent random variables in the probability space Ω. Let 
 
 
 
  be a finite set of events determined by these variables. If there exists an assignment of reals 
 
 
 
  to the events such that



then there exists an assignment of values to the variables 
 
 
 
  avoiding all of the events in 
 
 
 
 .
Moreover, the randomized algorithm described above resamples an event 
 
 
 
  at most an expected



times before it finds such an evaluation. Thus the expected total number of resampling steps and therefore the expected runtime of the algorithm is at most



The proof of this theorem using the method of entropy compression can be found in the paper by Moser and Tardos 3
Symmetric version
The requirement of an assignment function x satisfying a set of inequalities in the theorem above is complex and not intuitive. But this requirement can be replaced by three simple conditions:



 
 , i.e. each event A depends on at most D other events,


 
 , i.e. the probability of each event A is at most p,


 
 , where e is the base of the natural logarithm.

The version of the Lovász Local Lemma with these three conditions instead of the assignment function x is called the Symmetric Lovász Local Lemma. We can also state the Symmetric Algorithmic Lovász Local Lemma:
Let 
 
 
 
  be a finite set of mutually independent random variables and 
 
 
 
  be a finite set of events determined by these variables as before. If the above three conditions hold then there exists an assignment of values to the variables 
 
 
 
  avoiding all of the events in 
 
 
 
 .
Moreover, the randomized algorithm described above resamples an event 
 
 
 
  at most an expected 
 
 
 
  times before it finds such an evaluation. Thus the expected total number of resampling steps and therefore the expected runtime of the algorithm is at most 
 
 
 
 .
Example
The following example illustrates how the algorithmic version of the Lovász Local Lemma can be applied to a simple problem.
Let Φ be a CNF formula over variables X1, ..., Xn, containing n clauses, and with at least k literals in each clause, and with each variable Xi appearing in at most 
 
 
 
  clauses. Then, Φ is satisfiable.
This statement can be proven easily using the symmetric version of the Algorithmic Lovász Local Lemma. Let X1, ..., Xn be the set of mutually independent random variables 
 
 
 
  which are sampled uniformly at random.
Firstly, we truncate each clause in Φ to contain exactly k literals. Since each clause is a disjunction, this does not harm satisfiability, for if we can find a satisfying assignment for the truncated formula, it can easily be extended to a satisfying assignment for the original formula by reinserting the truncated literals.
Now, define a bad event Aj for each clause in Φ, where Aj is the event that clause j in Φ is unsatisfied by the current assignment. Since each clause contains k literals (and therefore k variables) and since all variables are sampled uniformly at random, we can bound the probability of each bad event by



Since each variable can appear in at most 
 
 
 
  clauses and there are k variables in each clause, each bad event Aj can depend on at most



other events. Therefore:



multiplying both sides by ep we get:



it follows by the symmetric Lovász Local Lemma that the probability of a random assignment to X1, ..., Xn satisfying all clauses in Φ is non-zero and hence such an assignment must exist.
Now, the Algorithmic Lovász Local Lemma actually allows us to efficiently compute such an assignment by applying the algorithm described above. The algorithm proceeds as follows:
It starts with a random truth value assignment to the variables X1, ..., Xn sampled uniformly at random. While there exists a clause in Φ that is unsatisfied, it randomly picks an unsatisfied clause C in Φ and assigns a new truth value to all variables that appear in C chosen uniformly at random. Once all clauses in Φ are satisfied, the algorithm returns the current assignment. Hence, the Algorithmic Lovász Local Lemma proves that this algorithm has an expected runtime of at most



steps on CNF formulas that satisfy the two conditions above. A stronger version of the above statement is proven by Moser,4 see also Berman, Karpinski and Scott.5
The algorithm is similar to WalkSAT which is used to solve general boolean satisfiability problems. The main difference is that in WalkSAT, after the unsatisfied clause C is selected, a single variable in C is selected at random and has its value flipped (which can be viewed as selecting uniformly among only 
 
 
 
  rather than all 
 
 
 
  value assignments to C).
Applications
As mentioned before, the Algorithmic Version of the Lovász Local Lemma applies to most problems for which the general Lovász Local Lemma is used as a proof technique. Some of these problems are discussed in the following articles:

Probabilistic proofs of non-probabilistic theorems
Random graph

Parallel version
The algorithm described above lends itself well to parallelization, since resampling two independent events 
 
 
 
 , i.e. 
 
 
 
 , in parallel is equivalent to resampling A, B sequentially. Hence, at each iteration of the main loop one can determine the maximal set of independent and satisfied events S and resample all events in S in parallel.
Under the assumption that the assignment function x satisfies the slightly stronger conditions:



for some ε > 0 Moser and Tardos proved that the parallel algorithm achieves a better runtime complexity. In this case, the parallel version of the algorithm takes an expected



steps before it terminates. The parallel version of the algorithm can be seen as a special case of the sequential algorithm shown above, and so this result also holds for the sequential case.
References
"
Category:Probability theorems Category:Combinatorics Category:Lemmas



.↩
.↩

.↩
Piotr Berman, Marek Karpinski and Alexander D. Scott, Approximation Hardness and Satisfiability of Bounded Occurrence Instances of SAT ], ECCC TR 03-022(2003).↩




