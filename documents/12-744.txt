   Continuous game      Continuous game   A continuous game is a mathematical generalization, used in game theory . It extends the notion of a discrete game, where the players choose from a finite set of pure strategies. The continuous game concepts allows games to include more general sets of pure strategies, which may be uncountably infinite .  In general, a game with uncountably infinite strategy sets will not necessarily have a Nash equilibrium solution. If, however, the strategy sets are required to be compact and the utility functions continuous , then a Nash equilibrium will be guaranteed; this is by Glicksberg's generalization of the Kakutani fixed point theorem . The class of continuous games is for this reason usually defined and studied as a subset of the larger class of infinite games (i.e. games with infinite strategy sets) in which the strategy sets are compact and the utility functions continuous.  Formal definition  Define the n -player continuous game    G  =   (  P  ,  𝐂  ,  𝐔  )       G   P  𝐂  𝐔     G=(P,\mathbf{C},\mathbf{U})   where        P  =   1  ,  2  ,  3  ,  …  ,  n       P   1  2  3  normal-…  n     P={1,2,3,\ldots,n}   is the set of    n    n   n\,   players,      𝐂  =   (   C  1   ,   C  2   ,  …  ,   C  n   )       𝐂    subscript  C  1    subscript  C  2   normal-…   subscript  C  n      \mathbf{C}=(C_{1},C_{2},\ldots,C_{n})   where each     C  i      subscript  C  i    C_{i}\,   is a compact  metric space corresponding to the    i    i   i\,    th player's set of pure strategies,      𝐔  =   (   u  1   ,   u  2   ,  …  ,   u  n   )       𝐔    subscript  u  1    subscript  u  2   normal-…   subscript  u  n      \mathbf{U}=(u_{1},u_{2},\ldots,u_{n})   where     u  i   :   𝐂  →   \R       normal-:   subscript  u  i    normal-→  𝐂  \R     u_{i}:\mathbf{C}\to\R   is the utility function of player    i    i   i\,       We define     Δ  i      subscript  normal-Δ  i    \Delta_{i}\,   to be the set of Borel probability measures on     C  i      subscript  C  i    C_{i}\,   , giving us the mixed strategy space of player i .  Define the strategy profile    𝝈  =   (   σ  1   ,   σ  2   ,  …  ,   σ  n   )       𝝈    subscript  σ  1    subscript  σ  2   normal-…   subscript  σ  n      \boldsymbol{\sigma}=(\sigma_{1},\sigma_{2},\ldots,\sigma_{n})   where     σ  i   ∈    Δ  i         subscript  σ  i    subscript  normal-Δ  i     \sigma_{i}\in\Delta_{i}\,      Let    𝝈   -  i      subscript  𝝈    i     \boldsymbol{\sigma}_{-i}   be a strategy profile of all players except for player   i   i   i   . As with discrete games, we can define a best response  correspondence for player    i    i   i\,   ,    b  i     subscript  b  i    b_{i}   .     b  i      subscript  b  i    b_{i}\,   is a relation from the set of all probability distributions over opponent player profiles to a set of player   i   i   i   's strategies, such that each element of       b  i    (   σ   -  i    )        subscript  b  i    subscript  σ    i      b_{i}(\sigma_{-i})\,   is a best response to    σ   -  i      subscript  σ    i     \sigma_{-i}   . Define       𝐛   (  𝝈  )    =        b  1    (   σ   -  1    )    ×   b  2     (   σ   -  2    )    ×  ⋯  ×   b  n     (   σ   -  n    )          𝐛  𝝈              subscript  b  1    subscript  σ    1      subscript  b  2     subscript  σ    2     normal-⋯   subscript  b  n     subscript  σ    n       \mathbf{b}(\boldsymbol{\sigma})=b_{1}(\sigma_{-1})\times b_{2}(\sigma_{-2})%
 \times\cdots\times b_{n}(\sigma_{-n})   . A strategy profile    𝝈  *     fragments  σ     \boldsymbol{\sigma}*   is a Nash equilibrium if and only if    𝝈  *  ∈  𝐛   (  𝝈  *  )      fragments  σ    b   fragments  normal-(  σ   normal-)     \boldsymbol{\sigma}*\in\mathbf{b}(\boldsymbol{\sigma}*)   The existence of a Nash equilibrium for any continuous game with continuous utility functions can been proven using Irving Glicksberg 's generalization of the Kakutani fixed point theorem . 1 In general, there may not be a solution if we allow strategy spaces,     C  i      subscript  C  i    C_{i}\,   's which are not compact, or if we allow non-continuous utility functions.  Separable games  A separable game is a continuous game where, for any i, the utility function     u  i   :   𝐂  →   \R       normal-:   subscript  u  i    normal-→  𝐂  \R     u_{i}:\mathbf{C}\to\R   can be expressed in the sum-of-products form:        u  i    (  𝐬  )    =    ∑    k  1   =  1    m  1     …    ∑    k  n   =  1    m  n      a    i   ,    k  1   …   k  n       f  1    (   s  1   )   …   f  n    (   s  n   )              subscript  u  i   𝐬     superscript   subscript      subscript  k  1   1     subscript  m  1      normal-…    superscript   subscript      subscript  k  n   1     subscript  m  n       subscript  a   i     subscript  k  1   normal-…   subscript  k  n       subscript  f  1    subscript  s  1   normal-…   subscript  f  n    subscript  s  n         u_{i}(\mathbf{s})=\sum_{k_{1}=1}^{m_{1}}\ldots\sum_{k_{n}=1}^{m_{n}}a_{i\,,\,k%
 _{1}\ldots k_{n}}f_{1}(s_{1})\ldots f_{n}(s_{n})   , where    𝐬  ∈  𝐂      𝐬  𝐂    \mathbf{s}\in\mathbf{C}   ,     s  i   ∈   C  i        subscript  s  i    subscript  C  i     s_{i}\in C_{i}   ,     a    i   ,    k  1   …   k  n      ∈   \R        subscript  a   i     subscript  k  1   normal-…   subscript  k  n      \R    a_{i\,,\,k_{1}\ldots k_{n}}\in\R   , and the functions     f    i   ,  k    :    C  i   →   \R       normal-:   subscript  f   i  k     normal-→   subscript  C  i   \R     f_{i\,,\,k}:C_{i}\to\R   are continuous. A polynomial game is a separable game where each     C  i      subscript  C  i    C_{i}\,   is a compact interval on    \R    \R   \R\,   and each utility function can be written as a multivariate polynomial.  In general, mixed Nash equilibria of separable games are easier to compute than non-separable games as implied by the following theorem:   For any separable game there exists at least one Nash equilibrium where player i mixes at most     m  i   +   1        subscript  m  i   1    m_{i}+1\,   pure strategies. 2    Whereas an equilibrium strategy for a non-separable game may require an uncountably infinite  support , a separable game is guaranteed to have at least one Nash equilibrium with finitely supported mixed strategies.  Examples  Separable games  A polynomial game  Consider a zero-sum 2-player game between players X and Y , with     C  X   =   C  Y   =   [  0  ,  1  ]          subscript  C  X    subscript  C  Y         0  1      C_{X}=C_{Y}=\left[0,1\right]   . Denote elements of     C  X      subscript  C  X    C_{X}\,   and     C  Y      subscript  C  Y    C_{Y}\,   as    x    x   x\,   and    y    y   y\,   respectively. Define the utility functions     H   (  x  ,  y  )    =    u  x    (  x  ,  y  )    =   -    u  y    (  x  ,  y  )             H   x  y       subscript  u  x    x  y              subscript  u  y    x  y        H(x,y)=u_{x}(x,y)=-u_{y}(x,y)\,   where       H   (  x  ,  y  )    =     (   x  -  y   )   2          H   x  y     superscript    x  y   2     H(x,y)=(x-y)^{2}\,   .  The pure strategy best response relations are:        b  X    (  y  )    =   {      1  ,       if  y   ∈   [  0  ,   1  /  2   )          0  or  1   ,       if  y   =   1  /  2         0  ,       if  y   ∈   (   1  /  2   ,  1  ]               subscript  b  X   y    cases  1      if  y    0    1  2       0  or  1       if  y     1  2    0      if  y      1  2   1       b_{X}(y)=\begin{cases}1,&\mbox{if }y\in\left[0,1/2\right)\\
 0\text{ or }1,&\mbox{if }y=1/2\\
 0,&\mbox{if }y\in\left(1/2,1\right]\par
 \end{cases}           b  Y    (  x  )    =   x          subscript  b  Y   x   x    b_{Y}(x)=x\,        b  X    (  y  )        subscript  b  X   y    b_{X}(y)\,   and     b  Y    (  x  )        subscript  b  Y   x    b_{Y}(x)\,   do not intersect, so there is  no pure strategy Nash equilibrium. However, there should be a mixed strategy equilibrium. To find it, express the expected value,    v  =   𝔼   [   H   (  x  ,  y  )    ]        v    𝔼   delimited-[]    H   x  y        v=\mathbb{E}[H(x,y)]   as a linear combination of the first and second moments of the probability distributions of X and Y :      v  =     μ   X  2    -   2   μ   X  1     μ   Y  1      +    μ   Y  2          v       subscript  μ    X  2      2   subscript  μ    X  1     subscript  μ    Y  1       subscript  μ    Y  2       v=\mu_{X2}-2\mu_{X1}\mu_{Y1}+\mu_{Y2}\,     (where     μ   X  N    =   𝔼   [   x  N   ]         subscript  μ    X  N      𝔼   delimited-[]   superscript  x  N       \mu_{XN}=\mathbb{E}[x^{N}]   and similarly for Y ).  The constraints on     μ   X  1       subscript  μ    X  1     \mu_{X1}\,   and    μ   X  2      subscript  μ    X  2     \mu_{X2}   (with similar constraints for y ,) are given by Hausdorff as:           μ   X  1    ≥   μ   X  2           μ   X  1   2   ≤   μ   X  2             μ   Y  1    ≥   μ   Y  2           μ   Y  1   2   ≤   μ   Y  2                subscript  μ    X  1     subscript  μ    X  2          superscript   subscript  μ    X  1    2    subscript  μ    X  2            subscript  μ    Y  1     subscript  μ    Y  2          superscript   subscript  μ    Y  1    2    subscript  μ    Y  2         \begin{aligned}\displaystyle\mu_{X1}\geq\mu_{X2}\\
 \displaystyle\mu_{X1}^{2}\leq\mu_{X2}\end{aligned}\qquad\begin{aligned}%
 \displaystyle\mu_{Y1}\geq\mu_{Y2}\\
 \displaystyle\mu_{Y1}^{2}\leq\mu_{Y2}\end{aligned}     Each pair of constraints defines a compact convex subset in the plane. Since    v    v   v\,   is linear, any extrema with respect to a player's first two moments will lie on the boundary of this subset. Player i's equilibrium strategy will lie on       μ   i  1    =    μ   i  2    or   μ   i  1   2    =   μ   i  2           subscript  μ    i  1       subscript  μ    i  2    or   superscript   subscript  μ    i  1    2          subscript  μ    i  2       \mu_{i1}=\mu_{i2}\text{ or }\mu_{i1}^{2}=\mu_{i2}     Note that the first equation only permits mixtures of 0 and 1 whereas the second equation only permits pure strategies. Moreover, if the best response at a certain point to player i lies on     μ   i  1    =    μ   i  2          subscript  μ    i  1     subscript  μ    i  2      \mu_{i1}=\mu_{i2}\,   , it will lie on the whole line, so that both 0 and 1 are a best response.     b  Y    (   μ   X  1    ,   μ   X  2    )        subscript  b  Y     subscript  μ    X  1     subscript  μ    X  2       b_{Y}(\mu_{X1},\mu_{X2})\,   simply gives the pure strategy    y  =    μ   X  1         y   subscript  μ    X  1      y=\mu_{X1}\,   , so     b  Y      subscript  b  Y    b_{Y}\,   will never give both 0 and 1. However     b  x      subscript  b  x    b_{x}\,   gives both 0 and 1 when y = 1/2. A Nash equilibrium exists when:       (   μ   X  1    *  ,   μ   X  2    *  ,   μ   Y  1    *  ,   μ   Y  2    *  )   =   (  1  /  2  ,  1  /  2  ,  1  /  2  ,  1  /  4  )      fragments   fragments  normal-(   subscript  μ    X  1     normal-,   subscript  μ    X  2     normal-,   subscript  μ    Y  1     normal-,   subscript  μ    Y  2     normal-)     fragments  normal-(  1   2  normal-,  1   2  normal-,  1   2  normal-,  1   4  normal-)     (\mu_{X1}*,\mu_{X2}*,\mu_{Y1}*,\mu_{Y2}*)=(1/2,1/2,1/2,1/4)\,     This determines one unique equilibrium where Player X plays a random mixture of 0 for 1/2 of the time and 1 the other 1/2 of the time. Player Y plays the pure strategy of 1/2. The value of the game is 1/4.  Non-Separable Games  A rational pay-off function  Consider a zero-sum 2-player game between players X and Y , with     C  X   =   C  Y   =   [  0  ,  1  ]          subscript  C  X    subscript  C  Y         0  1      C_{X}=C_{Y}=\left[0,1\right]   . Denote elements of     C  X      subscript  C  X    C_{X}\,   and     C  Y      subscript  C  Y    C_{Y}\,   as    x    x   x\,   and    y    y   y\,   respectively. Define the utility functions     H   (  x  ,  y  )    =    u  x    (  x  ,  y  )    =   -    u  y    (  x  ,  y  )             H   x  y       subscript  u  x    x  y              subscript  u  y    x  y        H(x,y)=u_{x}(x,y)=-u_{y}(x,y)\,   where        H   (  x  ,  y  )    =     (   1  +  x   )    (   1  +  y   )    (   1  -   x  y    )      (   1  +   x  y    )   2     .        H   x  y          1  x     1  y     1    x  y      superscript    1    x  y    2      H(x,y)=\frac{(1+x)(1+y)(1-xy)}{(1+xy)^{2}}.     This game has no pure strategy Nash equilibrium. It can be shown 3 that a unique mixed strategy Nash equilibrium exists with the following pair of probability density functions :          f  *    (  x  )    =   2   π   x    (   1  +  x   )         g  *    (  y  )    =   2   π   y    (   1  +  y   )       .     formulae-sequence       superscript  f    x     2    π    x     1  x           superscript  g    y     2    π    y     1  y        f^{*}(x)=\frac{2}{\pi\sqrt{x}(1+x)}\qquad g^{*}(y)=\frac{2}{\pi\sqrt{y}(1+y)}.     The value of the game is    4  /  π      4  π    4/\pi   .  Requiring a Cantor distribution  Consider a zero-sum 2-player game between players X and Y , with     C  X   =   C  Y   =   [  0  ,  1  ]          subscript  C  X    subscript  C  Y         0  1      C_{X}=C_{Y}=\left[0,1\right]   . Denote elements of     C  X      subscript  C  X    C_{X}\,   and     C  Y      subscript  C  Y    C_{Y}\,   as    x    x   x\,   and    y    y   y\,   respectively. Define the utility functions     H   (  x  ,  y  )    =    u  x    (  x  ,  y  )    =   -    u  y    (  x  ,  y  )             H   x  y       subscript  u  x    x  y              subscript  u  y    x  y        H(x,y)=u_{x}(x,y)=-u_{y}(x,y)\,   where       H   (  x  ,  y  )    =    ∑   n  =  0   ∞     1   2  n     (    2   x  n    -   (     (   1  -   x  3    )   n   -    (   x  3   )   n    )    )    (    2   y  n    -   (     (   1  -   y  3    )   n   -    (   y  3   )   n    )    )           H   x  y      superscript   subscript     n  0          1   superscript  2  n        2   superscript  x  n       superscript    1    x  3    n    superscript    x  3   n         2   superscript  y  n       superscript    1    y  3    n    superscript    y  3   n         H(x,y)=\sum_{n=0}^{\infty}\frac{1}{2^{n}}\left(2x^{n}-\left(\left(1-\frac{x}{3%
 }\right)^{n}-\left(\frac{x}{3}\right)^{n}\right)\right)\left(2y^{n}-\left(%
 \left(1-\frac{y}{3}\right)^{n}-\left(\frac{y}{3}\right)^{n}\right)\right)   . This game has a unique mixed strategy equilibrium where each player plays a mixed strategy with the cantor singular function as the cumulative distribution function . 4  Further reading   H. W. Kuhn and A. W. Tucker, eds. (1950). Contributions to the Theory of Games: Vol. II. Annals of Mathematics Studies 28 . Princeton University Press. ISBN 0-691-07935-8.   See also   Graph continuous   References    "  Category:Game theory     I.L. Glicksberg. A further generalization of the Kakutani fixed point theorem, with application to Nash equilibrium points. Proceedings of the American Mathematical Society, 3(1):170–174, February 1952. ↩  N. Stein, A. Ozdaglar and P.A. Parrilo. "Separable and Low-Rank Continuous Games". International Journal of Game Theory , 37(4):475–504, December 2008. http://arxiv.org/abs/0707.3462 ↩  Glicksberg, I. & Gross, O. (1950). "Notes on Games over the Square." Kuhn, H.W. & Tucker, A.W. eds. Contributions to the Theory of Games: Volume II. Annals of Mathematics Studies 28 , p.173–183. Princeton University Press. ↩  Gross, O. (1952). "A rational payoff characterization of the Cantor distribution." Technical Report D-1349, The RAND Corporation. ↩     