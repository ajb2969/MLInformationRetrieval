   HÃ¡jekâ€“Le Cam convolution theorem      HÃ¡jekâ€“Le Cam convolution theorem   In statistics , the HÃ¡jekâ€“Le Cam convolution theorem states that any regular estimator in a parametric model is asymptotically equivalent to a sum of two independent random variables, one of which is normal with asymptotic variance equal to the inverse of Fisher information , and the other having arbitrary distribution.  The obvious corollary from this theorem is that the â€œbestâ€ among regular estimators are those with the second component identically equal to zero. Such estimators are called efficient and are known to always exist for regular parametric models .  The theorem is named after Jaroslav HÃ¡jek and Lucien Le Cam .  Theorem statement  Let â„˜ = { P Î¸ | Î¸ âˆˆÂ Î˜Â âŠ‚Â â„ k } be a regular parametric model , and q ( Î¸ ): Î˜Â â†’Â â„ m be a parameter in this model (typically a parameter is just one of the components of vector Î¸ ). Assume that function q is differentiable on Î˜, with the mÂ Ã—Â k matrix of derivatives denotes as qÌ‡ Î¸ . Define       I   q   (  Î¸  )     -  1    =    q  Ë™    (  Î¸  )    I   -  1     (  Î¸  )    q  Ë™     (  Î¸  )   â€²         superscript   subscript  I    q  Î¸      1       normal-Ë™  q   Î¸   superscript  I    1    Î¸   normal-Ë™  q    superscript  Î¸  normal-â€²      I_{q(\theta)}^{-1}=\dot{q}(\theta)I^{-1}(\theta)\dot{q}(\theta)^{\prime}   â€” the information bound for q ,       Ïˆ   q   (  Î¸  )     =    q  Ë™    (  Î¸  )    I   -  1     (  Î¸  )    â„“  Ë™    (  Î¸  )         subscript  Ïˆ    q  Î¸       normal-Ë™  q   Î¸   superscript  I    1    Î¸   normal-Ë™  normal-â„“   Î¸     \psi_{q(\theta)}=\dot{q}(\theta)I^{-1}(\theta)\dot{\ell}(\theta)   â€” the efficient influence function for q ,  where I ( Î¸ ) is the Fisher information matrix for model â„˜,     â„“  Ë™    (  Î¸  )        normal-Ë™  normal-â„“   Î¸    \scriptstyle\dot{\ell}(\theta)   is the score function , and â€² denotes matrix transpose .   Theorem . Suppose T n is a uniformly (locally) regular estimator of the parameter q . Then   There exist independent random m -vectors      Z  Î¸    âˆ¼   ğ’©   (  0  ,   I   q   (  Î¸  )     -  1    )       similar-to   subscript  Z  Î¸     ğ’©   0   subscript   superscript  I    1      q  Î¸        \scriptstyle Z_{\theta}\,\sim\,\mathcal{N}(0,\,I^{-1}_{q(\theta)})   and Î” Î¸ such that        n    (    T  n   -   q   (  Î¸  )     )      â†’  ğ‘‘      Z  Î¸   +   Î”  Î¸     ,      d  normal-â†’       n      subscript  T  n     q  Î¸        subscript  Z  Î¸    subscript  normal-Î”  Î¸      \sqrt{n}(T_{n}-q(\theta))\ \xrightarrow{d}\ Z_{\theta}+\Delta_{\theta},   where d denotes convergence in distribution . More specifically,         (        n    (    T  n   -   q   (  Î¸  )     )    -     1   n        âˆ‘   i  =  1   n      Ïˆ   q   (  Î¸  )      (   x  i   )              1   n        âˆ‘   i  =  1   n      Ïˆ   q   (  Î¸  )      (   x  i   )         )      â†’  ğ‘‘     (      Î”  Î¸        Z  Î¸      )    .      d  normal-â†’           n      subscript  T  n     q  Î¸         1    n      superscript   subscript     i  1    n      subscript  Ïˆ    q  Î¸     subscript  x  i             1    n      superscript   subscript     i  1    n      subscript  Ïˆ    q  Î¸     subscript  x  i           subscript  normal-Î”  Î¸      subscript  Z  Î¸       \begin{pmatrix}\sqrt{n}(T_{n}-q(\theta))-\tfrac{1}{\sqrt{n}}\sum_{i=1}^{n}\psi%
 _{q(\theta)}(x_{i})\\
 \tfrac{1}{\sqrt{n}}\sum_{i=1}^{n}\psi_{q(\theta)}(x_{i})\end{pmatrix}\ %
 \xrightarrow{d}\ \begin{pmatrix}\Delta_{\theta}\\
 Z_{\theta}\end{pmatrix}.     If the map Î¸ â†’ qÌ‡ Î¸ is continuous, then the convergence in (A) holds uniformly on compact subsets of Î˜. Moreover, in that case Î” Î¸ = 0 for all Î¸ if and only if T n is uniformly (locally) asymptotically linear with influence function Ïˆ q ( Î¸ )   References     "  Category:Statistical theorems   