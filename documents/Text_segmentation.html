<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="1277">Text segmentation</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>Text segmentation</h1>
<hr/>

<p><strong>Text segmentation</strong> is the process of dividing <a href="writing" title="wikilink">written text</a> into meaningful units, such as <a href="word" title="wikilink">words</a>, <a href="Sentence_(linguistics)" title="wikilink">sentences</a>, or <a href="topic_(linguistics)" title="wikilink">topics</a>. The term applies both to <a href="human_mind" title="wikilink">mental</a> processes used by humans when reading text, and to artificial processes implemented in <a class="uri" href="computers" title="wikilink">computers</a>, which are the subject of <a href="natural_language_processing" title="wikilink">natural language processing</a>. The problem is non-trivial, because while some written languages have explicit word boundary markers, such as the word spaces of written <a href="English_language" title="wikilink">English</a> and the distinctive initial, medial and final letter shapes of <a href="Arabic_language" title="wikilink">Arabic</a>, such signals are sometimes ambiguous and not present in all written languages.</p>

<p>Compare <a href="speech_segmentation" title="wikilink">speech segmentation</a>, the process of dividing speech into linguistically meaningful portions.</p>
<h2 id="segmentation-problems">Segmentation problems</h2>
<h3 id="word-segmentation">Word segmentation</h3>
<dl>
<dd>''See also: <a href="Word#Word_boundaries" title="wikilink">Word &gt; Word boundary</a>
</dd>
</dl>

<p>Word segmentation is the problem of dividing a string of written language into its component <a href="word" title="wikilink">words</a>.</p>

<p>In <a href="English_language" title="wikilink">English</a> and many other languages using some form of the <a href="Latin_alphabet" title="wikilink">Latin alphabet</a>, the <a href="Space_(punctuation)" title="wikilink">space</a> is a good approximation of a <a href="word_divider" title="wikilink">word divider</a> (word <a class="uri" href="delimiter" title="wikilink">delimiter</a>). (Some examples where the space character alone may not be sufficient include contractions like <em>can't</em> for <em>can not</em>.)</p>

<p>However the equivalent to this character is not found in all written scripts, and without it word segmentation is a difficult problem. Languages which do not have a trivial word segmentation process include <a href="Chinese_language" title="wikilink">Chinese</a>, <a href="Japanese_language" title="wikilink">Japanese</a>, where <a class="uri" href="sentences" title="wikilink">sentences</a> but not words are delimited, <a href="Thai_language" title="wikilink">Thai</a> and <a href="Lao_language" title="wikilink">Lao</a>, where phrases and sentences but not words are delimited, and <a href="Vietnamese_language" title="wikilink">Vietnamese</a>, where syllables but not words are delimited.</p>

<p>In some writing systems however, such as the <a href="Ge'ez_script" title="wikilink">Ge'ez script</a> used for <a class="uri" href="Amharic" title="wikilink">Amharic</a> and <a href="Tigrinya_language" title="wikilink">Tigrinya</a> among other languages, words are explicitly delimited (at least historically) with a non-<a href="Space_(punctuation)" title="wikilink">whitespace</a> character.</p>

<p>The <a href="Unicode_Consortium" title="wikilink">Unicode Consortium</a> has published a <a href="http://www.unicode.org/reports/tr29/">Standard Annex</a> on Text Segmentation, exploring the issues of segmentation in multiscript texts.</p>

<p><strong>Word splitting</strong> is the process of <a class="uri" href="parsing" title="wikilink">parsing</a> <a class="uri" href="concatenated" title="wikilink">concatenated</a> text (i.e. text that contains no spaces or other word separators) to infer where word breaks exist.</p>

<p>Word splitting may also refer to the process of <a href="Syllabification" title="wikilink">hyphenation</a>.</p>
<h3 id="sentence-segmentation">Sentence segmentation</h3>

<p>Sentence segmentation is the problem of dividing a string of written language into its component <a class="uri" href="sentences" title="wikilink">sentences</a>. In English and some other languages, using punctuation, particularly the <a href="full_stop" title="wikilink">full stop</a> character is a reasonable approximation. However even in English this problem is not trivial due to the use of the full stop character for abbreviations, which may or may not also terminate a sentence. For example <em>Mr.</em> is not its own sentence in "<em>Mr. Smith went to the shops in Jones Street."</em> When processing plain text, tables of abbreviations that contain periods can help prevent incorrect assignment of sentence boundaries.</p>

<p>As with word segmentation, not all written languages contain punctuation characters which are useful for approximating sentence boundaries.</p>
<h3 id="topic-segmentation">Topic segmentation</h3>

<p>Topic analysis consists of two main tasks: topic identiﬁcation and text segmentation. While the first is a simple <a href="machine_learning" title="wikilink">classification</a> of a specific text, the latter case implies that a document may contain multiple topics, and the task of computerized text segmentation may be to discover these topics automatically and segment the text accordingly. The topic boundaries may be apparent from section titles and paragraphs. In other cases, one needs to use techniques similar to those used in <a href="document_classification" title="wikilink">document classification</a>.</p>

<p>Segmenting the text into <a href="topic_(linguistics)" title="wikilink">topics</a> or <a class="uri" href="discourse" title="wikilink">discourse</a> turns might be useful in some natural processing tasks: it can improve information retrieval or speech recognition significantly (by indexing/recognizing documents more precisely or by giving the specific part of a document corresponding to the query as a result). It is also needed in <a href="Topic_detection" title="wikilink">Topic detection</a> and Tracking systems and <a href="text_summarization" title="wikilink">text summarizing</a> problems.</p>

<p>Many different approaches have been tried:<a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a><a class="footnoteRef" href="#fn2" id="fnref2"><sup>2</sup></a> e.g. <a href="Hidden_Markov_model" title="wikilink">HMM</a>, <a href="lexical_chains" title="wikilink">lexical chains</a>, passage similarity using word <a class="uri" href="co-occurrence" title="wikilink">co-occurrence</a>, <a href="cluster_analysis" title="wikilink">clustering</a> etc.</p>

<p>It is quite an ambiguous task — people evaluating the text segmentation systems often differ in topic boundaries. Hence, text segment evaluation is also a challenging problem.</p>
<h3 id="other-segmentation-problems">Other segmentation problems</h3>

<p>Processes may be required to segment text into segments besides mentioned, including <a href="morpheme" title="wikilink">morphemes</a> (a task usually called <a href="morphology_(linguistics)" title="wikilink">morphological analysis</a>) or <a href="paragraph" title="wikilink">paragraphs</a>.</p>
<h2 id="automatic-segmentation-approaches">Automatic segmentation approaches</h2>

<p>Automatic segmentation is the problem in <a href="natural_language_processing" title="wikilink">natural language processing</a> of implementing a computer process to segment text.</p>

<p>When punctuation and similar clues are not consistently available, the segmentation task often requires fairly non-trivial techniques, such as statistical decision-making, large dictionaries, as well as consideration of syntactic and semantic constraints. Effective natural language processing systems and text segmentation tools usually operate on text in specific domains and sources. As an example, processing text used in medical records is a very different problem than processing news articles or real estate advertisements.</p>

<p>The process of developing text segmentation tools starts with collecting a large corpus of text in an application domain. There are two general approaches:</p>
<ul>
<li>Manual analysis of text and writing custom software</li>
<li>Annotate the sample corpus with boundary information and use <a href="Machine_Learning" title="wikilink">Machine Learning</a></li>
</ul>

<p>Some text segmentation systems take advantage of any markup like HTML and know document formats like PDF to provide additional evidence for sentence and paragraph boundaries.</p>
<h2 id="see-also">See also</h2>
<ul>
<li><a href="Syllabification" title="wikilink">Hyphenation</a></li>
<li><a href="Natural_language_processing" title="wikilink">Natural language processing</a></li>
<li><a href="Speech_segmentation" title="wikilink">Speech segmentation</a></li>
<li><a href="Lexical_analysis" title="wikilink">Lexical analysis</a></li>
<li><a href="Word_count" title="wikilink">Word count</a></li>
</ul>
<h2 id="references">References</h2>
<h2 id="external-links">External links</h2>
<ul>
<li><a href="http://wordseg.codeplex.com/">Word Segment</a> An open source software tool for word segmentation in Chinese.</li>
<li><a href="http://www.whitemagicsoftware.com/software/java/wordsplit/">Word Split</a> An open source software tool designed to split conjoined words into human-readable text.</li>
<li><a href="http://nlp.stanford.edu/software/segmenter.shtml">Stanford Segmenter</a> An open source software tool for word segmentation in Chinese or morpheme segmentation in Arabic.</li>
<li><a href="http://www.phontron.com/kytea">KyTea</a> An open source software tool for word segmentation in Japanese and Chinese.</li>
<li><a href="http://chinesenotes.com/">Chinese Notes</a> A Chinese-English dictionary that also does word segmentation.</li>
<li><a href="http://www.zhihuita.org/service/tokenizer">Zhihuita Segmentor</a> A high precision and high performance Chinese segmentation freeware.</li>
</ul>

<p>"</p>

<p><a href="Category:Tasks_of_natural_language_processing" title="wikilink">Category:Tasks of natural language processing</a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1"><a href="#fnref1">↩</a></li>
<li id="fn2"><a href="#fnref2">↩</a></li>
</ol>
</section>
</body>
</html>
