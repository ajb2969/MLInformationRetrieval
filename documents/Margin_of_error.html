<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="1643">Margin of error</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>Margin of error</h1>
<hr/>
<figure><b>(Figure)</b>
<figcaption>The top portion of this graphic depicts <a href="probability_density_function" title="wikilink">probability densities</a> that show the relative likelihood that the "true" percentage is in a particular area given a reported percentage of 50%. The bottom portion shows the 95% <a href="confidence_interval" title="wikilink">confidence intervals</a> (horizontal <a href="line_segment" title="wikilink">line segments</a>), the corresponding margins of error (on the left), and sizes of <a href="Sample_(statistics)#Kinds_of_samples" title="wikilink">unbiased samples</a> (on the right). In other words, for each sample size, one is 95% confident that the "true" percentage is in the region indicated by the corresponding segment. The larger an unbiased sample is, the smaller its margin of error.</figcaption>
</figure>

<p>The <strong>margin of error</strong> is a statistic expressing the amount of random <a href="sampling_error" title="wikilink">sampling error</a> in a <a href="statistical_survey" title="wikilink">survey</a>'s results. It asserts a likelihood (not a certainty) that the result from a <a href="Sample_(statistics)" title="wikilink">sample</a> is close to the number one would get if the whole <a href="Statistical_population" title="wikilink">population</a> had been queried. The likelihood of a result being "within the margin of error" is itself a probability, commonly 95%, though other values are sometimes used. The larger the margin of error, the less confidence one should have that the poll's reported results are close to the true figures; that is, the figures for the whole population. Margin of error applies whenever a population is incompletely sampled.</p>

<p>Margin of error is often used in non-survey contexts to indicate <a href="observational_error" title="wikilink">observational error</a> in reporting measured quantities. In <a class="uri" href="astronomy" title="wikilink">astronomy</a>, for example, the convention is to report the margin of error as, for example, 4.2421(16) light-years (the distance to Proxima Centauri), with the number in parentheses indicating the expected range of values in the matching digits preceding; in this case, 4.2421(16) is equivalent to 4.2421 ± 0.0016.<a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a> The latter notation, with the "±", is more commonly seen in most other science and engineering fields.</p>
<h2 id="explanation">Explanation</h2>

<p>The margin of error is usually defined as the "radius" (or half the width) of a <a href="confidence_interval" title="wikilink">confidence interval</a> for a particular <a class="uri" href="statistic" title="wikilink">statistic</a> from a survey. One example is the percent of people who prefer product A versus product B. When a single, global margin of error is reported for a survey, it refers to the maximum margin of error for all reported <a href="percentage" title="wikilink">percentages</a> using the full sample from the survey. If the statistic is a percentage, this maximum margin of error can be calculated as the radius of the confidence interval for a reported percentage of 50%.</p>

<p>The margin of error has been described as an "absolute" quantity, equal to a confidence interval radius for the statistic. For example, if the true value is 50 percentage points, and the statistic has a confidence interval radius of 5 percentage points, then we say the margin of error is 5 percentage points. As another example, if the true value is 50 people, and the statistic has a confidence interval radius of 5 people, then we might say the margin of error is 5 people.</p>

<p>In some cases, the margin of error is not expressed as an "absolute" quantity; rather it is expressed as a "relative" quantity. For example, suppose the true value is 50 people, and the statistic has a confidence interval radius of 5 people. If we use the "absolute" definition, the margin of error would be 5 people. If we use the "relative" definition, then we express this absolute margin of error as a percent of the true value. So in this case, the absolute margin of error is 5 people, but the "percent relative" margin of error is 10% (because 5 people are ten percent of 50 people). Often, however, the distinction is not explicitly made, yet usually is apparent from context.</p>

<p>Like confidence intervals, the margin of error can be defined for any desired confidence level, but usually a level of 90%, 95% or 99% is chosen (typically 95%). This level is the <a class="uri" href="probability" title="wikilink">probability</a> that a margin of error around the reported percentage would include the "true" percentage. Along with the confidence level, the <a href="sampling_(statistics)" title="wikilink">sample design</a> for a survey, and in particular its <a href="sample_size" title="wikilink">sample size</a>, determines the magnitude of the margin of error. A larger sample size produces a smaller margin of error, all else remaining equal.</p>

<p>If the exact confidence intervals are used, then the margin of error takes into account both sampling error and non-sampling error. If an approximate confidence interval is used (for example, by assuming the distribution is normal and then modeling the confidence interval accordingly), then the margin of error may only take random <a href="sampling_error" title="wikilink">sampling error</a> into account. It does not represent other potential sources of error or <a href="Bias_(statistics)" title="wikilink">bias</a> such as a non-representative sample-design, <a href="Questionnaire_construction" title="wikilink">poorly phrased questions</a>, people lying or refusing to respond, the exclusion of people who could not be contacted, or miscounts and miscalculations.</p>
<h2 id="concept">Concept</h2>

<p>An example from the <a href="U.S._presidential_election,_2004" title="wikilink">2004 U.S. presidential campaign</a> will be used to illustrate concepts throughout this article. According to an October 2, 2004 survey by <em><a class="uri" href="Newsweek" title="wikilink">Newsweek</a></em>, 47% of registered voters would vote for <a href="John_Kerry" title="wikilink">John Kerry</a>/<a href="John_Edwards" title="wikilink">John Edwards</a> if the election were held on that day, 45% would vote for <a href="George_W._Bush" title="wikilink">George W. Bush</a>/<a href="Dick_Cheney" title="wikilink">Dick Cheney</a>, and 2% would vote for <a href="Ralph_Nader" title="wikilink">Ralph Nader</a>/<a href="Peter_Camejo" title="wikilink">Peter Camejo</a>. The <a href="Sample_size" title="wikilink">size of the sample</a> was 1,013.<a class="footnoteRef" href="#fn2" id="fnref2"><sup>2</sup></a> Unless otherwise stated, the remainder of this article uses a 95% level of confidence.</p>
<h3 id="basic-concept">Basic concept</h3>

<p>Polls basically involve taking a sample from a certain population. In the case of the <em>Newsweek</em> poll, the population of interest is the population of people who will vote. Because it is impractical to poll everyone who will vote, pollsters take smaller samples that are intended to be representative, that is, a <a href="random_sample" title="wikilink">random sample</a> of the population.<a class="footnoteRef" href="#fn3" id="fnref3"><sup>3</sup></a> It is possible that pollsters sample 1,013 voters who happen to vote for Bush when in fact the population is evenly split between Bush and Kerry, but this is extremely unlikely (<em>p</em> = 2<sup>−1013</sup> ≈ 1.1 × 10<sup>−305</sup>) given that the sample is random.</p>

<p><a href="Sampling_(statistics)" title="wikilink">Sampling theory</a> provides methods for calculating the probability that the poll results differ from reality by more than a certain amount, simply due to chance; for instance, that the poll reports 47% for Kerry but his support is actually as high as 50%, or is really as low as 44%. This theory and some <a href="Bayesian_probability" title="wikilink">Bayesian</a> assumptions suggest that the "true" percentage will probably be fairly close to 47%. The more people that are sampled, the more confident pollsters can be that the "true" percentage is close to the observed percentage. The margin of error is a measure of how close the results are likely to be.</p>

<p>However, the margin of error only accounts for random sampling error, so it is blind to systematic errors that may be introduced by <a href="response_rate" title="wikilink">non-response</a> or by interactions between the survey and subjects' memory, motivation, communication and knowledge.<a class="footnoteRef" href="#fn4" id="fnref4"><sup>4</sup></a></p>
<h3 id="calculations-assuming-random-sampling">Calculations assuming random sampling</h3>

<p>This section will briefly discuss the <a href="standard_error_(statistics)" title="wikilink">standard error</a> of a percentage, the <a href="Binomial_proportion_confidence_interval" title="wikilink">corresponding confidence interval</a>, and connect these two concepts to the margin of error. For simplicity, the calculations here assume the poll was based on a simple random sample from a large population.</p>

<p>The standard error of a reported proportion or percentage <em>p</em> measures its accuracy, and is the estimated standard deviation of that percentage. It can be estimated from just <em>p</em> and the sample size, <em>n</em>, if <em>n</em> is small relative to the population size, using the following formula:<a class="footnoteRef" href="#fn5" id="fnref5"><sup>5</sup></a></p>

<p>

<math display="block" id="Margin_of_error:0">
 <semantics>
  <mrow>
   <mtext>Standard error</mtext>
   <mo>≈</mo>
   <msqrt>
    <mfrac>
     <mrow>
      <mi>p</mi>
      <mrow>
       <mo stretchy="false">(</mo>
       <mrow>
        <mn>1</mn>
        <mo>-</mo>
        <mi>p</mi>
       </mrow>
       <mo stretchy="false">)</mo>
      </mrow>
     </mrow>
     <mi>n</mi>
    </mfrac>
   </msqrt>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <approx></approx>
    <mtext>Standard error</mtext>
    <apply>
     <root></root>
     <apply>
      <divide></divide>
      <apply>
       <times></times>
       <ci>p</ci>
       <apply>
        <minus></minus>
        <cn type="integer">1</cn>
        <ci>p</ci>
       </apply>
      </apply>
      <ci>n</ci>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \text{Standard error}\approx\sqrt{\frac{p(1-p)}{n}}
  </annotation>
 </semantics>
</math>

</p>

<p>When the sample is not a <a href="simple_random_sample" title="wikilink">simple random sample</a> from a large population, the standard error and the confidence interval must be estimated through more advanced calculations. <a class="uri" href="Linearization" title="wikilink">Linearization</a> and <a href="resampling_(statistics)" title="wikilink">resampling</a> are widely used techniques for data from complex sample designs.</p>

<p>Note that there is not necessarily a strict connection between the true confidence interval, and the true standard error. The true <em>p</em> percent confidence interval is the interval [<em>a</em>, <em>b</em>] that contains <em>p</em> percent of the distribution, and where (100 − <em>p</em>)/2 percent of the distribution lies below <em>a</em>, and (100 − <em>p</em>)/2 percent of the distribution lies above <em>b</em>. The true standard error of the statistic is the square root of the true sampling variance of the statistic. These two may not be directly related, although in general, for large distributions that look like normal curves, there is a direct relationship.</p>

<p>In the <em>Newsweek</em> poll, Kerry's level of support <em>p</em> = 0.47 and <em>n</em> = 1,013. The standard error (.016 or 1.6%) helps to give a sense of the accuracy of Kerry's estimated percentage (47%). A <a href="Bayesian_inference" title="wikilink">Bayesian</a> interpretation of the standard error is that although we do not know the "true" percentage, it is highly likely to be located within two standard errors of the estimated percentage (47%). The standard error can be used to create a confidence interval within which the "true" percentage should be to a certain level of confidence.</p>

<p>The estimated percentage <a href="Plus-minus_sign" title="wikilink">plus or minus</a> its margin of error is a confidence interval for the percentage. In other words, the margin of error is half the width of the confidence interval. It can be calculated as a multiple of the standard error, with the factor depending of the level of confidence desired; a margin of one standard error gives a 68% confidence interval, while the estimate plus or minus 1.96 standard errors is a 95% confidence interval, and a 99% confidence interval runs 2.58 standard errors on either side of the estimate.</p>
<h3 id="definition">Definition</h3>

<p>The margin of error for a particular statistic of interest is usually defined as the radius (or half the width) of the confidence interval for that statistic.<a class="footnoteRef" href="#fn6" id="fnref6"><sup>6</sup></a><a class="footnoteRef" href="#fn7" id="fnref7"><sup>7</sup></a> The term can also be used to mean sampling error in general. In media reports of poll results, the term usually refers to the maximum margin of error for any percentage from that poll.</p>
<h3 id="different-confidence-levels">Different confidence levels</h3>

<p>For a <a href="simple_random_sample" title="wikilink">simple random sample</a> from a large population, the maximum margin of error is a simple re-expression of the sample size <em>n</em>. The numerators of these equations are rounded to two decimal places.</p>
<dl>
<dd>Margin of error at 99% confidence 

<math display="inline" id="Margin_of_error:1">
 <semantics>
  <mrow>
   <mi></mi>
   <mo>≈</mo>
   <mrow>
    <mn>1.29</mn>
    <mo>/</mo>
    <mpadded width="+1.7pt">
     <msqrt>
      <mi>n</mi>
     </msqrt>
    </mpadded>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <approx></approx>
    <csymbol cd="latexml">absent</csymbol>
    <apply>
     <divide></divide>
     <cn type="float">1.29</cn>
     <apply>
      <root></root>
      <ci>n</ci>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \approx 1.29/\sqrt{n}\,
  </annotation>
 </semantics>
</math>



</dd>
</dl>
<dl>
<dd>Margin of error at 95% confidence 

<math display="inline" id="Margin_of_error:2">
 <semantics>
  <mrow>
   <mi></mi>
   <mo>≈</mo>
   <mrow>
    <mn>0.98</mn>
    <mo>/</mo>
    <mpadded width="+1.7pt">
     <msqrt>
      <mi>n</mi>
     </msqrt>
    </mpadded>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <approx></approx>
    <csymbol cd="latexml">absent</csymbol>
    <apply>
     <divide></divide>
     <cn type="float">0.98</cn>
     <apply>
      <root></root>
      <ci>n</ci>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \approx 0.98/\sqrt{n}\,
  </annotation>
 </semantics>
</math>


</dd>
</dl>
<dl>
<dd>Margin of error at 90% confidence 

<math display="inline" id="Margin_of_error:3">
 <semantics>
  <mrow>
   <mi></mi>
   <mo>≈</mo>
   <mrow>
    <mn>0.82</mn>
    <mo>/</mo>
    <mpadded width="+1.7pt">
     <msqrt>
      <mi>n</mi>
     </msqrt>
    </mpadded>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <approx></approx>
    <csymbol cd="latexml">absent</csymbol>
    <apply>
     <divide></divide>
     <cn type="float">0.82</cn>
     <apply>
      <root></root>
      <ci>n</ci>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \approx 0.82/\sqrt{n}\,
  </annotation>
 </semantics>
</math>


</dd>
</dl>
<dl>
<dd>Margin of error at X confidence 

<math display="inline" id="Margin_of_error:4">
 <semantics>
  <mrow>
   <mi></mi>
   <mo>=</mo>
   <mfrac>
    <mrow>
     <msup>
      <mtext>erf</mtext>
      <mrow>
       <mo>-</mo>
       <mn>1</mn>
      </mrow>
     </msup>
     <mrow>
      <mo stretchy="false">(</mo>
      <mi>X</mi>
      <mo stretchy="false">)</mo>
     </mrow>
    </mrow>
    <msqrt>
     <mrow>
      <mn>2</mn>
      <mi>n</mi>
     </mrow>
    </msqrt>
   </mfrac>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <csymbol cd="latexml">absent</csymbol>
    <apply>
     <divide></divide>
     <apply>
      <times></times>
      <apply>
       <csymbol cd="ambiguous">superscript</csymbol>
       <mtext>erf</mtext>
       <apply>
        <minus></minus>
        <cn type="integer">1</cn>
       </apply>
      </apply>
      <ci>X</ci>
     </apply>
     <apply>
      <root></root>
      <apply>
       <times></times>
       <cn type="integer">2</cn>
       <ci>n</ci>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   =\frac{\text{erf}^{-1}(X)}{\sqrt{2n}}
  </annotation>
 </semantics>
</math>

 (See <a href="Error_function#Inverse_functions" title="wikilink">Inverse error function</a>)
</dd>
</dl>

<p>If an article about a poll does not report the margin of error, but does state that a simple random sample of a certain size was used, the margin of error can be calculated for a desired degree of confidence using one of the above formulae. Also, if the 95% margin of error is given, one can find the 99% margin of error by increasing the reported margin of error by about 30%.</p>

<p>As an example of the above, a random sample of size 400 will give a margin of error, at a 95% confidence level, of 0.98/20 or 0.049 - just under 5%. A random sample of size 1600 will give a margin of error of 0.98/40, or 0.0245 - just under 2.5%. A random sample of size 10 000 will give a margin of error at the 95% confidence level of 0.98/100, or 0.0098 - just under 1%.</p>
<h3 id="maximum-and-specific-margins-of-error">Maximum and specific margins of error</h3>

<p>While the margin of error typically reported in the media is a poll-wide figure that reflects the maximum sampling variation of any percentage based on all respondents from that poll, the term <em>margin of error</em> also refers to the radius of the confidence interval for a particular statistic.</p>

<p>The margin of error for a particular individual percentage will usually be smaller than the maximum margin of error quoted for the survey. This maximum only applies when the observed percentage is 50%, and the margin of error shrinks as the percentage approaches the extremes of 0% or 100%.</p>

<p>In other words, the maximum margin of error is the radius of a 95% confidence interval for a reported percentage of 50%. If <em>p</em> moves away from 50%, the confidence interval for <em>p</em> will be shorter. Thus, the maximum margin of error represents an <a href="upper_bound" title="wikilink">upper bound</a> to the uncertainty; one is <em>at least</em> 95% certain that the "true" percentage is within the maximum margin of error of a reported percentage for any reported percentage.</p>
<h3 id="effect-of-population-size">Effect of population size</h3>

<p>The formula above for the margin of error assume that there is an infinitely large <a href="Statistical_population" title="wikilink">population</a> and thus do not depend on the size of the population of interest. According to <a href="Sampling_(statistics)" title="wikilink">sampling theory</a>, this assumption is reasonable when the <a href="sampling_fraction" title="wikilink">sampling fraction</a> is small. The margin of error for a particular sampling method is essentially the same regardless of whether the population of interest is the size of a school, city, state, or country, as long as the sampling fraction is less than 5%.</p>

<p>In cases where the sampling fraction exceeds 5%, analysts can adjust the margin of error using a "<a href="finite_population_correction" title="wikilink">finite population correction</a>", (FPC) to account for the added precision gained by sampling close to a larger percentage of the population. FPC can be calculated using the formula:<a class="footnoteRef" href="#fn8" id="fnref8"><sup>8</sup></a></p>

<p>

<math display="block" id="Margin_of_error:5">
 <semantics>
  <mrow>
   <mrow>
    <mo>FPC</mo>
    <mo>=</mo>
    <msqrt>
     <mfrac>
      <mrow>
       <mi>N</mi>
       <mo>-</mo>
       <mi>n</mi>
      </mrow>
      <mrow>
       <mi>N</mi>
       <mo>-</mo>
       <mn>1</mn>
      </mrow>
     </mfrac>
    </msqrt>
   </mrow>
   <mo>.</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <ci>FPC</ci>
    <apply>
     <root></root>
     <apply>
      <divide></divide>
      <apply>
       <minus></minus>
       <ci>N</ci>
       <ci>n</ci>
      </apply>
      <apply>
       <minus></minus>
       <ci>N</ci>
       <cn type="integer">1</cn>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \operatorname{FPC}=\sqrt{\frac{N-n}{N-1}}.
  </annotation>
 </semantics>
</math>

</p>

<p>To adjust for a large sampling fraction, the fpc factored into the calculation of the margin of error, which has the effect of narrowing the margin of error. It holds that the fpc approaches zero as the sample size (<em>n</em>) approaches the population size (<em>N</em>), which has the effect of eliminating the margin of error entirely. This makes intuitive sense because when <em>N</em> = <em>n</em>, the sample becomes a census and sampling error becomes moot.</p>

<p>Analysts should be mindful that the samples remain truly random as the sampling fraction grows, lest sampling bias be introduced.</p>
<h3 id="other-statistics">Other statistics</h3>

<p>Confidence intervals can be calculated, and so can margins of error, for a range of statistics including individual percentages, differences between percentages, means, medians,<a class="footnoteRef" href="#fn9" id="fnref9"><sup>9</sup></a> and totals.</p>

<p>The margin of error for the difference between two percentages is larger than the margins of error for each of these percentages, and may even be larger than the maximum margin of error for any individual percentage from the survey.</p>
<h2 id="comparing-percentages">Comparing percentages</h2>

<p>In a <a href="plurality_voting_system" title="wikilink">plurality voting system</a>, where the winner is the candidate with the most votes, it is important to know who is ahead. The terms "statistical tie" and "statistical dead heat" are sometimes used to describe reported percentages that differ by less than a margin of error, but these terms can be misleading.<a class="footnoteRef" href="#fn10" id="fnref10"><sup>10</sup></a><a class="footnoteRef" href="#fn11" id="fnref11"><sup>11</sup></a> For one thing, the margin of error as generally calculated is applicable to an <em>individual percentage</em> and not the difference between percentages, so the difference between two percentage estimates may not be <a href="Statistical_significance" title="wikilink">statistically significant</a> even when they differ by more than the reported margin of error. The survey results also often provide strong information even when there is not a statistically significant difference.</p>

<p>When comparing percentages, it can accordingly be useful to consider the probability that one percentage is higher than another.<a class="footnoteRef" href="#fn12" id="fnref12"><sup>12</sup></a> In simple situations, this probability can be derived with 1) the standard error calculation introduced earlier, 2) the <a class="uri" href="formula" title="wikilink">formula</a> for the <a class="uri" href="variance" title="wikilink">variance</a> of the difference of two <a href="random_variable" title="wikilink">random variables</a>, and 3) an assumption that if anyone does not choose Kerry they will choose Bush, and vice versa; they are perfectly negatively <a href="correlation" title="wikilink">correlated</a>. This may not be a tenable assumption when there are more than two possible poll responses. For more complex survey designs, different formulas for calculating the standard error of difference must be used.</p>

<p>The standard error of the difference of percentages <em>p</em> for Kerry and <em>q</em> for Bush, assuming that they are perfectly negatively correlated, follows:</p>

<p>

<math display="block" id="Margin_of_error:6">
 <semantics>
  <mrow>
   <mrow>
    <mtext>Standard error of difference</mtext>
    <mo>=</mo>
    <msqrt>
     <mfrac>
      <mrow>
       <mrow>
        <mi>p</mi>
        <mo>+</mo>
        <mi>q</mi>
       </mrow>
       <mo>-</mo>
       <msup>
        <mrow>
         <mo stretchy="false">(</mo>
         <mrow>
          <mi>p</mi>
          <mo>-</mo>
          <mi>q</mi>
         </mrow>
         <mo stretchy="false">)</mo>
        </mrow>
        <mn>2</mn>
       </msup>
      </mrow>
      <mi>n</mi>
     </mfrac>
    </msqrt>
    <mo>=</mo>
    <msqrt>
     <mfrac>
      <mrow>
       <mrow>
        <mrow>
         <mrow>
          <mi>p</mi>
          <mo>+</mo>
          <mi>q</mi>
         </mrow>
         <mo>-</mo>
         <msup>
          <mi>p</mi>
          <mn>2</mn>
         </msup>
        </mrow>
        <mo>+</mo>
        <mrow>
         <mn>2</mn>
         <mi>p</mi>
         <mi>q</mi>
        </mrow>
       </mrow>
       <mo>-</mo>
       <msup>
        <mi>q</mi>
        <mn>2</mn>
       </msup>
      </mrow>
      <mi>n</mi>
     </mfrac>
    </msqrt>
   </mrow>
   <mo>.</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <and></and>
    <apply>
     <eq></eq>
     <mtext>Standard error of difference</mtext>
     <apply>
      <root></root>
      <apply>
       <divide></divide>
       <apply>
        <minus></minus>
        <apply>
         <plus></plus>
         <ci>p</ci>
         <ci>q</ci>
        </apply>
        <apply>
         <csymbol cd="ambiguous">superscript</csymbol>
         <apply>
          <minus></minus>
          <ci>p</ci>
          <ci>q</ci>
         </apply>
         <cn type="integer">2</cn>
        </apply>
       </apply>
       <ci>n</ci>
      </apply>
     </apply>
    </apply>
    <apply>
     <eq></eq>
     <share href="#.cmml">
     </share>
     <apply>
      <root></root>
      <apply>
       <divide></divide>
       <apply>
        <minus></minus>
        <apply>
         <plus></plus>
         <apply>
          <minus></minus>
          <apply>
           <plus></plus>
           <ci>p</ci>
           <ci>q</ci>
          </apply>
          <apply>
           <csymbol cd="ambiguous">superscript</csymbol>
           <ci>p</ci>
           <cn type="integer">2</cn>
          </apply>
         </apply>
         <apply>
          <times></times>
          <cn type="integer">2</cn>
          <ci>p</ci>
          <ci>q</ci>
         </apply>
        </apply>
        <apply>
         <csymbol cd="ambiguous">superscript</csymbol>
         <ci>q</ci>
         <cn type="integer">2</cn>
        </apply>
       </apply>
       <ci>n</ci>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \text{Standard error of difference}=\sqrt{\frac{p+q-(p-q)^{2}}{n}}=\sqrt{\frac%
{p+q-p^{2}+2pq-q^{2}}{n}}.
  </annotation>
 </semantics>
</math>

</p>

<p>Given the observed percentage difference <em>p</em> − <em>q</em> (2% or 0.02) and the standard error of the difference calculated above (.03), any statistical calculator may be used to calculate the probability that a sample from a <a href="normal_distribution" title="wikilink">normal distribution</a> with <a class="uri" href="mean" title="wikilink">mean</a> 0.02 and <a href="standard_deviation" title="wikilink">standard deviation</a> 0.03 is greater than 0.</p>
<h2 id="see-also">See also</h2>
<ul>
<li><a href="Engineering_tolerance" title="wikilink">Engineering tolerance</a></li>
<li><a href="Key_relevance" title="wikilink">Key relevance</a></li>
<li><a href="Measurement_uncertainty" title="wikilink">Measurement uncertainty</a></li>
<li><a href="Random_error" title="wikilink">Random error</a></li>
<li><a href="Observational_error" title="wikilink">Observational error</a></li>
</ul>
<h2 id="notes">Notes</h2>
<h2 id="references">References</h2>
<ul>
<li>Sudman, Seymour and Bradburn, Norman (1982). <em>Asking Questions: A Practical Guide to Questionnaire Design</em>. San Francisco: Jossey Bass. ISBN 0-87589-546-8</li>
<li></li>
</ul>
<h2 id="external-links">External links</h2>
<ul>
<li></li>
<li></li>
<li></li>
</ul>

<p>"</p>

<p><a href="Category:Statistical_deviation_and_dispersion" title="wikilink">Category:Statistical deviation and dispersion</a> <a class="uri" href="Category:Error" title="wikilink">Category:Error</a> <a class="uri" href="Category:Measurement" title="wikilink">Category:Measurement</a> <a href="Category:Sampling_(statistics)" title="wikilink">Category:Sampling (statistics)</a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1"><a href="#fnref1">↩</a></li>
<li id="fn2"><a href="#fnref2">↩</a></li>
<li id="fn3">Wonnacott and Wonnacott (1990), pp. 4–8.<a href="#fnref3">↩</a></li>
<li id="fn4">Sudman, S.L. and Bradburn N.M. (1982) Asking Questions. Jossey-Bass: pp. 17-19<a href="#fnref4">↩</a></li>
<li id="fn5"><a href="http://www.researchsolutions.co.nz/sample_sizes.htm">Sample Sizes, Margin of Error, Quantitative Analysis</a><a href="#fnref5">↩</a></li>
<li id="fn6"><a href="#fnref6">↩</a></li>
<li id="fn7"><a href="#fnref7">↩</a></li>
<li id="fn8"> (Equation 1)<a href="#fnref8">↩</a></li>
<li id="fn9"><a href="http://www.census.gov/hhes/www/income/medincsizeandstate.html">Income - Median Family Income in the Past 12 Months by Family Size</a>, U.S. Census Bureau. Retrieved February 15, 2007.<a href="#fnref9">↩</a></li>
<li id="fn10">Braiker, Brian. <a href="http://www.msnbc.msn.com/id/6159637/site/newsweek/">"The Race is On: With voters widely viewing Kerry as the debate’s winner, Bush’s lead in the NEWSWEEK poll has evaporated".</a> MSNBC, October 2, 2004. Retrieved on 2 February 2007.<a href="#fnref10">↩</a></li>
<li id="fn11">Rogosa, D.R. (2005). A school accountability case study: California API awards and the Orange County Register margin of error folly. In R.P. Phelps (Ed.), Defending standardized testing (pp. 205–226). Mahwah, NJ: Lawrence Erlbaum Associates.<a href="#fnref11">↩</a></li>
<li id="fn12">Drum, Kevin. <a href="http://www.washingtonmonthly.com/archives/individual/2004_08/004536.php">Political Animal</a>, Washington Monthly, August 19, 2004. Retrieved on 15 February 2007.<a href="#fnref12">↩</a></li>
</ol>
</section>
</body>
</html>
