


Bernoulli distribution




Bernoulli distribution

|
 kurtosis   =

|
 entropy    =

|
 mgf        =

|
 char       =

|
 pgf =

|
 fisher = 

| 
}}
In probability theory and statistics, the Bernoulli distribution, named after Swiss scientist Jacob Bernoulli, is the probability distribution of a random variable which takes value 1 with success probability 
 
 
 
  and value 0 with failure probability 
 
 
 
 . It can be used, for example, to represent the toss of a (not necessarily fair) coin, where "1" is defined to mean "heads" and "0" is defined to mean "tails" (or vice versa).
The Bernoulli distribution is a special case of the two-point distribution, for which the two possible outcomes need not be 0 and 1.
Properties
If 
 
 
 
  is a random variable with this distribution, we have:



A classic example of a Bernoulli experiment is a single toss of a coin. The coin might come up heads with probability 
 
 
 
  and tails with probability 
 
 
 
 . The experiment is called fair if 
 
 
 
 , indicating the origin of the terminology in betting (the bet is fair if both possible outcomes have the same probability).
The probability mass function

 
  of this distribution, over possible outcomes k, is



This can also be expressed as



The expected value of a Bernoulli random variable 
 
 
 
  is



and its variance is



The Bernoulli distribution is a special case of the binomial distribution with 
 
 
 
 .1
The kurtosis goes to infinity for high and low values of 
 
 
 
 , but for 
 
 
 
  the two-point distributions including the Bernoulli distribution have a lower excess kurtosis than any other probability distribution, namely −2.
The Bernoulli distributions for 
 
 
 
  form an exponential family.
The maximum likelihood estimator of 
 
 
 
 
  based on a random sample is the sample mean.
Related distributions

If 
 
 
 
  are independent, identically distributed (i.i.d.) random variables, all Bernoulli distributed with success probability p, then



 
  (binomial distribution). The Bernoulli distribution is simply 
 
 
 
 .

The categorical distribution is the generalization of the Bernoulli distribution for variables with any constant number of discrete values.
The Beta distribution is the conjugate prior of the Bernoulli distribution.
The geometric distribution models the number of independent and identical Bernoulli trials needed to get one success.
If Y ~ Bernoulli(0.5), then (2Y-1) has a Rademacher distribution.

See also

Bernoulli process
Bernoulli sampling
Bernoulli trial
Binary entropy function

Notes
References




Johnson, N.L., Kotz, S., Kemp A. (1993) Univariate Discrete Distributions (2nd Edition). Wiley. ISBN 0-471-54897-9

External links



Interactive graphic: Univariate Distribution Relationships

"

Category:Discrete distributions Category:Distributions with conjugate priors Category:Exponential family distributions Category:Probability distributions



McCullagh and Nelder (1989), Section 4.2.2.




