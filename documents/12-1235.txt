   Minimum distance estimation      Minimum distance estimation   Minimum distance estimation (MDE) is a statistical method for fitting a mathematical model to data, usually the empirical distribution .  Definition  Let     X  1   ,  …  ,   X  n       subscript  X  1   normal-…   subscript  X  n     \displaystyle X_{1},\ldots,X_{n}   be an independent and identically distributed (iid) random  sample from a population with distribution      F   (  x  ;  θ  )    :   θ  ∈  Θ      normal-:    F   x  θ      θ  normal-Θ     F(x;\theta)\colon\theta\in\Theta   and    Θ  ⊆   ℝ  k    (  k  ≥  1  )      fragments  Θ    superscript  ℝ  k    fragments  normal-(  k   1  normal-)     \Theta\subseteq\mathbb{R}^{k}(k\geq 1)   .  Let     F  n    (  x  )        subscript  F  n   x    \displaystyle F_{n}(x)   be the empirical distribution function based on the sample.  Let    θ  ^     normal-^  θ    \hat{\theta}   be an estimator for   θ   θ   \displaystyle\theta   . Then    F   (  x  ;   θ  ^   )       F   x   normal-^  θ      F(x;\hat{\theta})   is an estimator for    F   (  x  ;  θ  )       F   x  θ     \displaystyle F(x;\theta)   .  Let    d   [  ⋅  ,  ⋅  ]       d   normal-⋅  normal-⋅     d[\cdot,\cdot]   be a functional returning some measure of "distance" between the two arguments . The functional   d   d   \displaystyle d   is also called the criterion function.  If there exists a     θ  ^   ∈  Θ       normal-^  θ   normal-Θ    \hat{\theta}\in\Theta   such that    d   [  F   (  x  ;   θ  ^   )   ,   F  n    (  x  )   ]   =  inf   {  d   [  F   (  x  ;  θ  )   ,   F  n    (  x  )   ]   ;  θ  ∈  Θ  }      fragments  d   fragments  normal-[  F   fragments  normal-(  x  normal-;   normal-^  θ   normal-)   normal-,   subscript  F  n    fragments  normal-(  x  normal-)   normal-]    infimum   fragments  normal-{  d   fragments  normal-[  F   fragments  normal-(  x  normal-;  θ  normal-)   normal-,   subscript  F  n    fragments  normal-(  x  normal-)   normal-]   normal-;  θ   Θ  normal-}     d[F(x;\hat{\theta}),F_{n}(x)]=\inf\{d[F(x;\theta),F_{n}(x)];\theta\in\Theta\}   , then    θ  ^     normal-^  θ    \hat{\theta}   is called the minimum distance estimate of   θ   θ   \displaystyle\theta   .  Statistics used in estimation  Most theoretical studies of minimum distance estimation, and most applications, make use of "distance" measures which underlie already-established goodness of fit tests: the test statistic used in one of these tests is used as the distance measure to be minimised. Below are some examples of statistical tests that have been used for minimum distance estimation.  Chi-square criterion  The chi-square test uses as its criterion the sum, over predefined groups, of the squared difference between the increases of the empirical distribution and the estimated distribution, weighted by the increase in the estimate for that group.  Cramér–von Mises criterion  The Cramér–von Mises criterion uses the integral of the squared difference between the empirical and the estimated distribution functions .  Kolmogorov–Smirnov criterion  The Kolmogorov–Smirnov test uses the supremum of the absolute difference between the empirical and the estimated distribution functions .  Anderson–Darling criterion  The Anderson–Darling test is similar to the Cramér–von Mises criterion except that the integral is of a weighted version of the squared difference, where the weighting relates the variance of the empirical distribution function .  Theoretical results  The theory of minimum distance estimation is related to that for the asymptotic distribution of the corresponding statistical goodness of fit tests. Often the cases of the Cramér–von Mises criterion , the Kolmogorov–Smirnov test and the Anderson–Darling test are treated simultaneously by treating them as special cases of a more general formulation of a distance measure. Examples of the theoretical results that are available are: consistency of the parameter estimates; the asymptotic covariance matrices of the parameter estimates.  See also   Maximum likelihood estimation  Maximum spacing estimation   References         "  Category:Estimation theory  Category:Statistical distance measures  Category:Mathematical modeling   