   Singular control      Singular control   In optimal control , problems of singular control are problems that are difficult to solve because a straightforward application of Pontryagin's minimum principle fails to yield a complete solution. Only a few such problems have been solved, such as Merton's portfolio problem in financial economics or trajectory optimization in aeronautics. A more technical explanation follows.  The most common difficulty in applying Pontryagin's principle arises when the Hamiltonian depends linearly on the control   u   u   u   , i.e., is of the form     H   (  u  )    =    ϕ   (  x  ,  λ  ,  t  )   u   +  ⋯         H  u       ϕ   x  λ  t   u   normal-⋯     H(u)=\phi(x,\lambda,t)u+\cdots   and the control is restricted to being between an upper and a lower bound    a  ≤   u   (  t  )    ≤  b        a    u  t        b     a\leq u(t)\leq b   . To minimize    H   (  u  )       H  u    H(u)   , we need to make   u   u   u   as big or as small as possible, depending on the sign of    ϕ   (  x  ,  λ  ,  t  )       ϕ   x  λ  t     \phi(x,\lambda,t)   , specifically:       u   (  t  )    =   {      b  ,       ϕ   (  x  ,  λ  ,  t  )    <  0        ?  ,       ϕ   (  x  ,  λ  ,  t  )    =  0        a  ,       ϕ   (  x  ,  λ  ,  t  )    >  0.             u  t    cases  b      ϕ   x  λ  t    0   normal-?      ϕ   x  λ  t    0   a      ϕ   x  λ  t    0.      u(t)=\begin{cases}b,&\phi(x,\lambda,t)<0\\
 ?,&\phi(x,\lambda,t)=0\\
 a,&\phi(x,\lambda,t)>0.\end{cases}     If   ϕ   ϕ   \phi   is positive at some times, negative at others and is only zero instantaneously, then the solution is straightforward and is a bang-bang control that switches from   b   b   b   to   a   a   a   at times when   ϕ   ϕ   \phi   switches from negative to positive.  The case when   ϕ   ϕ   \phi   remains at zero for a finite length of time     t  1   ≤  t  ≤   t  2          subscript  t  1   t        subscript  t  2      t_{1}\leq t\leq t_{2}   is called the singular control case. Between    t  1     subscript  t  1    t_{1}   and    t  2     subscript  t  2    t_{2}   the maximization of the Hamiltonian with respect to u gives us no useful information and the solution in that time interval is going to have to be found from other considerations. (One approach would be to repeatedly differentiate     ∂  H   /   ∂  u         H     u     \partial H/\partial u   with respect to time until the control u again explicitly appears, which is guaranteed to happen eventually. One can then set that expression to zero and solve for u. This amounts to saying that between    t  1     subscript  t  1    t_{1}   and    t  2     subscript  t  2    t_{2}   the control   u   u   u   is determined by the requirement that the singularity condition continues to hold. The resulting so-called singular arc will be optimal if it satisfies the Kelley condition :          (   -  1   )   k    ∂   ∂  u     [     (   d   d  t    )    2  k     H  u    ]    ≥  0   ,   k  =   0  ,  1  ,  ⋯       formulae-sequence       superscript    1   k        u     delimited-[]     superscript    d    d  t      2  k     subscript  H  u      0     k   0  1  normal-⋯      (-1)^{k}\frac{\partial}{\partial u}\left[{\left(\frac{d}{dt}\right)}^{2k}H_{u}%
 \right]\geq 0,\,k=0,1,\cdots     . 1 This condition is also called the generalized Legendre-Clebsch condition ).  The term bang-singular control refers to a control that has a bang-bang portion as well as a singular portion.  References  "  Category:Control theory     Bryson, Ho: Applied Optimal Control, Page 246 ↩     