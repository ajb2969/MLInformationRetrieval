   Fritz John conditions      Fritz John conditions   The Fritz John conditions (abbr. FJ conditions ), in mathematics , are a necessary condition for a solution in nonlinear programming to be optimal . They are used as lemma in the proof of the Karush–Kuhn–Tucker conditions , but they are relevant on their own.  We consider the following optimization problem :      f   (  x  )       f  x    \displaystyle f(x)     where ƒ is the function to be minimized,    g  i     subscript  g  i    g_{i}   the inequality constraints and    h  j     subscript  h  j    h_{j}   the equality constraints, and where, respectively,   ℐ   ℐ   \mathcal{I}   ,    ℐ  ′     superscript  ℐ  normal-′    \mathcal{I^{\prime}}   and   ℰ   ℰ   \mathcal{E}   are the indices  set of inactive, active and equality constraints and    x  *     superscript  x     x^{*}   is an optimal solution of   f   f   f   , then there exists a non-zero vector    λ  =   [   λ  0   ,   λ  1   ,   λ  2   ,  …  ,   λ  n   ]       λ    subscript  λ  0    subscript  λ  1    subscript  λ  2   normal-…   subscript  λ  n      \lambda=[\lambda_{0},\lambda_{1},\lambda_{2},\dots,\lambda_{n}]   such that:      {        λ  0    ∇  f    (   x  *   )    =      ∑   i  ∈   ℐ  ′        λ  i    ∇   g  i     (   x  *   )     +     ∑   i  ∈  ℰ       λ  i    ∇   h  i     (   x  *   )               λ  i   ≥  0   ,   i  ∈    ℐ  ′   ∪   {  0  }            ∃  i  ∈   (   {  0  ,  1  ,  …  ,  n  }   \  ℐ  )    (   λ  i   ≠  0  )           cases       subscript  λ  0    normal-∇  f    superscript  x         subscript     i   superscript  ℐ  normal-′        subscript  λ  i    normal-∇   subscript  g  i     superscript  x        subscript     i  ℰ       subscript  λ  i    normal-∇   subscript  h  i     superscript  x        otherwise   formulae-sequence     subscript  λ  i   0     i     superscript  ℐ  normal-′    0      otherwise   fragments   i    fragments  normal-(   fragments  normal-{  0  normal-,  1  normal-,  normal-…  normal-,  n  normal-}   normal-\  I  normal-)    fragments  normal-(   subscript  λ  i    0  normal-)    otherwise    \begin{cases}\lambda_{0}\nabla f(x^{*})=\sum\limits_{i\in\mathcal{I}^{\prime}}%
 \lambda_{i}\nabla g_{i}(x^{*})+\sum\limits_{i\in\mathcal{E}}\lambda_{i}\nabla h%
 _{i}(x^{*})\\
 \lambda_{i}\geq 0,\ i\in\mathcal{I}^{\prime}\cup\{0\}\\
 \exists i\in\left(\{0,1,\ldots,n\}\backslash\mathcal{I}\right)\left(\lambda_{i%
 }\neq 0\right)\end{cases}        λ  0   >  0       subscript  λ  0   0    \lambda_{0}>0    if the    ∇   g  i    (  i  ∈   ℐ  ′   )      fragments  normal-∇   subscript  g  i    fragments  normal-(  i    superscript  ℐ  normal-′   normal-)     \nabla g_{i}(i\in\mathcal{I}^{\prime})   and    ∇   h  i    (  i  ∈  ℰ  )      fragments  normal-∇   subscript  h  i    fragments  normal-(  i   E  normal-)     \nabla h_{i}(i\in\mathcal{E})   are linearly independent or, more generally, when a constraint qualification holds.  Named after Fritz John , these conditions are equivalent to the Karush–Kuhn–Tucker conditions in the case     λ  0   >  0       subscript  λ  0   0    \lambda_{0}>0   .  References     "  Category:Mathematical optimization   