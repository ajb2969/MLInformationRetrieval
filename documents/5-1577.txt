   Von Mises distribution      Von Mises distribution   {2\pi I_0(\kappa)}|  cdf        =(not analytic – see text)|  mean       =    μ   μ   \mu    |  median     =    μ   μ   \mu    |  mode       =    μ   μ   \mu    |  variance   =      var   (  x  )    =   1  -      I  1    (  κ  )    /   I  0     (  κ  )           var  x     1         subscript  I  1   κ    subscript  I  0    κ      \textrm{var}(x)=1-I_{1}(\kappa)/I_{0}(\kappa)    (circular)|  skewness   =|  kurtosis   =|  entropy    =      -   κ     I  1    (  κ  )      I  0    (  κ  )       +   ln   [   2  π   I  0    (  κ  )    ]            κ       subscript  I  1   κ      subscript  I  0   κ          2  π   subscript  I  0   κ      -\kappa\frac{I_{1}(\kappa)}{I_{0}(\kappa)}+\ln[2\pi I_{0}(\kappa)]    (differential)|  mgf        =|  char       =        I   |  n  |     (  κ  )      I  0    (  κ  )      e   i  n  μ             subscript  I    n    κ      subscript  I  0   κ     superscript  e    i  n  μ      \frac{I_{|n|}(\kappa)}{I_{0}(\kappa)}e^{in\mu}    |  }}  In probability theory and directional statistics , the von Mises distribution (also known as the circular normal distribution or Tikhonov distribution ) is a continuous probability distribution on the circle . It is a close approximation to the wrapped normal distribution , which is the circular analogue of the normal distribution . A freely diffusing angle   θ   θ   \theta   on a circle is a wrapped normally distributed random variable with an unwrapped variance that grows linearly in time. On the other hand, the von Mises distribution is the stationary distribution of a drift and diffusion process on the circle in a harmonic potential, i.e. with a preferred orientation. 1 The von Mises distribution is the maximum entropy distribution for a given expectation value of    z  =   e   i  θ        z   superscript  e    i  θ      z=e^{i\theta}   . The von Mises distribution is a special case of the von Mises–Fisher distribution on the N -dimensional sphere.  Definition  The von Mises probability density function for the angle x is given by: 2      f   (  x  ∣  μ  ,  κ  )   =    e   κ   cos   (   x  -  μ   )       2  π   I  0    (  κ  )        fragments  f   fragments  normal-(  x  normal-∣  μ  normal-,  κ  normal-)       superscript  e    κ      x  μ        2  π   subscript  I  0   κ      f(x\mid\mu,\kappa)=\frac{e^{\kappa\cos(x-\mu)}}{2\pi I_{0}(\kappa)}     where I 0 ( k ) is the modified Bessel function of order 0.  The parameters μ and 1/κ are analogous to μ and σ 2 (the mean and variance) in the normal distribution:   μ is a measure of location (the distribution is clustered around μ), and  κ is a measure of concentration (a reciprocal measure of dispersion , so 1/κ is analogous to σ 2 ).  If κ is zero, the distribution is uniform, and for small κ, it is close to uniform.  If κ is large, the distribution becomes very concentrated about the angle μ with κ being a measure of the concentration. In fact, as κ increases, the distribution approaches a normal distribution in x with mean μ and variance 1/κ.    The probability density can be expressed as a series of Bessel functions (see Abramowitz and Stegun §9.6.34 )      f   (  x  ∣  μ  ,  κ  )   =   1   2  π     (  1  +   2    I  0    (  κ  )      ∑   j  =  1   ∞    I  j    (  κ  )   cos   [  j   (  x  -  μ  )   ]   )      fragments  f   fragments  normal-(  x  normal-∣  μ  normal-,  κ  normal-)      1    2  π     fragments  normal-(  1     2     subscript  I  0   κ     superscript   subscript     j  1       subscript  I  j    fragments  normal-(  κ  normal-)     fragments  normal-[  j   fragments  normal-(  x   μ  normal-)   normal-]   normal-)     f(x\mid\mu,\kappa)=\frac{1}{2\pi}\left(1+\frac{2}{I_{0}(\kappa)}\sum_{j=1}^{%
 \infty}I_{j}(\kappa)\cos[j(x-\mu)]\right)     where I j ( x ) is the modified Bessel function of order j .  The cumulative distribution function is not analytic and is best found by integrating the above series. The indefinite integral of the probability density is:      Φ   (  x  ∣  μ  ,  κ  )   =  ∫  f   (  t  ∣  μ  ,  κ  )   d  t  =   1   2  π     (  x  +   2    I  0    (  κ  )      ∑   j  =  1   ∞    I  j    (  κ  )     sin   [   j   (   x  -  μ   )    ]    j   )   .     fragments  Φ   fragments  normal-(  x  normal-∣  μ  normal-,  κ  normal-)     f   fragments  normal-(  t  normal-∣  μ  normal-,  κ  normal-)   d  t     1    2  π     fragments  normal-(  x     2     subscript  I  0   κ     superscript   subscript     j  1       subscript  I  j    fragments  normal-(  κ  normal-)         j    x  μ     j   normal-)   normal-.    \Phi(x\mid\mu,\kappa)=\int f(t\mid\mu,\kappa)\,dt=\frac{1}{2\pi}\left(x+\frac{%
 2}{I_{0}(\kappa)}\sum_{j=1}^{\infty}I_{j}(\kappa)\frac{\sin[j(x-\mu)]}{j}%
 \right).     The cumulative distribution function will be a function of the lower limit of integration x 0 :      F   (  x  ∣  μ  ,  κ  )   =  Φ   (  x  ∣  μ  ,  κ  )   -  Φ   (   x  0   ∣  μ  ,  κ  )   .     fragments  F   fragments  normal-(  x  normal-∣  μ  normal-,  κ  normal-)    Φ   fragments  normal-(  x  normal-∣  μ  normal-,  κ  normal-)    Φ   fragments  normal-(   subscript  x  0   normal-∣  μ  normal-,  κ  normal-)   normal-.    F(x\mid\mu,\kappa)=\Phi(x\mid\mu,\kappa)-\Phi(x_{0}\mid\mu,\kappa).\,     Moments  The moments of the von Mises distribution are usually calculated as the moments of z = e ix rather than the angle x itself. These moments are referred to as "circular moments". The variance calculated from these moments is referred to as the "circular variance". The one exception to this is that the "mean" usually refers to the argument of the circular mean, rather than the circular mean itself.  The n th raw moment of z is:       m  n   =   ⟨   z  n   ⟩   =   ∫  Γ     z  n    f   (  x  |  μ  ,  κ  )   d  x     fragments   subscript  m  n     fragments  normal-⟨   superscript  z  n   normal-⟩     subscript   normal-Γ    superscript  z  n   f   fragments  normal-(  x  normal-|  μ  normal-,  κ  normal-)   d  x    m_{n}=\langle z^{n}\rangle=\int_{\Gamma}z^{n}\,f(x|\mu,\kappa)\,dx          =      I   |  n  |     (  κ  )      I  0    (  κ  )      e   i  n  μ         absent         subscript  I    n    κ      subscript  I  0   κ     superscript  e    i  n  μ       =\frac{I_{|n|}(\kappa)}{I_{0}(\kappa)}e^{in\mu}     where the integral is over any interval   Γ   normal-Γ   \Gamma   of length 2π. In calculating the above integral, we use the fact that z n = cos( n x) + i sin( nx ) and the Bessel function identity (See Abramowitz and Stegun §9.6.19 ):         I  n    (  κ  )    =    1  π     ∫  0  π     e   κ   cos   (  x  )       cos   (   n  x   )    d  x      .         subscript  I  n   κ       1  π     superscript   subscript   0   π      superscript  e    κ    x         n  x    d  x       I_{n}(\kappa)=\frac{1}{\pi}\int_{0}^{\pi}e^{\kappa\cos(x)}\cos(nx)\,dx.     The mean of z is then just       m  1   =      I  1    (  κ  )      I  0    (  κ  )      e   i  μ          subscript  m  1          subscript  I  1   κ      subscript  I  0   κ     superscript  e    i  μ       m_{1}=\frac{I_{1}(\kappa)}{I_{0}(\kappa)}e^{i\mu}     and the "mean" value of x is then taken to be the argument μ. This is the "average" direction of the angular random variables. The variance of z , or the circular variance of x is:        var   (  x  )    =   1  -   E   [   cos   (   x  -  μ   )    ]     =   1  -     I  1    (  κ  )      I  0    (  κ  )       .          var  x     1    E   delimited-[]      x  μ              1       subscript  I  1   κ      subscript  I  0   κ        \textrm{var}(x)=1-E[\cos(x-\mu)]=1-\frac{I_{1}(\kappa)}{I_{0}(\kappa)}.     Limiting behavior  In the limit of large κ the distribution becomes a normal distribution       lim   κ  →  ∞    f   (  x  ∣  μ  ,  κ  )   =   1   σ    2  π      exp   [    -    (   x  -  μ   )   2     2   σ  2     ]      fragments   subscript    normal-→  κ     f   fragments  normal-(  x  normal-∣  μ  normal-,  κ  normal-)      1    σ      2  π        fragments  normal-[       superscript    x  μ   2      2   superscript  σ  2     normal-]     \lim_{\kappa\rightarrow\infty}f(x\mid\mu,\kappa)=\frac{1}{\sigma\sqrt{2\pi}}%
 \exp\left[\dfrac{-(x-\mu)^{2}}{2\sigma^{2}}\right]     where σ 2 = 1/κ. In the limit of small κ it becomes a uniform distribution :       lim   κ  →  0    f   (  x  ∣  μ  ,  κ  )   =  U   (  x  )      fragments   subscript    normal-→  κ  0    f   fragments  normal-(  x  normal-∣  μ  normal-,  κ  normal-)    U   fragments  normal-(  x  normal-)     \lim_{\kappa\rightarrow 0}f(x\mid\mu,\kappa)=\mathrm{U}(x)     where the interval for the uniform distribution U ( x ) is the chosen interval of length 2π.  Estimation of parameters  A series of N measurements     z  n   =   e   i   θ  n          subscript  z  n    superscript  e    i   subscript  θ  n       z_{n}=e^{i\theta_{n}}   drawn from a von Mises distribution may be used to estimate certain parameters of the distribution. (Borradaile, 2003) The average of the series    z  ¯     normal-¯  z    \overline{z}   is defined as       z  ¯   =    1  N     ∑   n  =  1   N    z  n          normal-¯  z       1  N     superscript   subscript     n  1    N    subscript  z  n       \overline{z}=\frac{1}{N}\sum_{n=1}^{N}z_{n}     and its expectation value will be just the first moment:        ⟨   z  ¯   ⟩   =      I  1    (  κ  )      I  0    (  κ  )      e   i  μ      .       delimited-⟨⟩   normal-¯  z           subscript  I  1   κ      subscript  I  0   κ     superscript  e    i  μ       \langle\overline{z}\rangle=\frac{I_{1}(\kappa)}{I_{0}(\kappa)}e^{i\mu}.     In other words,    z  ¯     normal-¯  z    \overline{z}   is an unbiased estimator of the first moment. If we assume that the mean   μ   μ   \mu   lies in the interval    [   -  π   ,  π  )       π   π    [-\pi,\pi)   , then Arg    (   z  ¯   )     normal-¯  z    (\overline{z})   will be a (biased) estimator of the mean   μ   μ   \mu   .  Viewing the    z  n     subscript  z  n    z_{n}   as a set of vectors in the complex plane, the     R  ¯   2     superscript   normal-¯  R   2    \bar{R}^{2}   statistic is the square of the length of the averaged vector:        R  ¯   2   =     z  ¯      z  *   ¯    =     (    1  N     ∑   n  =  1   N    cos   θ  n      )   2   +    (    1  N     ∑   n  =  1   N    sin   θ  n      )   2           superscript   normal-¯  R   2      normal-¯  z    normal-¯   superscript  z              superscript      1  N     superscript   subscript     n  1    N      subscript  θ  n      2    superscript      1  N     superscript   subscript     n  1    N      subscript  θ  n      2       \bar{R}^{2}=\overline{z}\,\overline{z^{*}}=\left(\frac{1}{N}\sum_{n=1}^{N}\cos%
 \theta_{n}\right)^{2}+\left(\frac{1}{N}\sum_{n=1}^{N}\sin\theta_{n}\right)^{2}     and its expectation value is:        ⟨    R  ¯   2   ⟩   =    1  N   +      N  -  1   N       I  1     (  κ  )   2      I  0     (  κ  )   2        .       delimited-⟨⟩   superscript   normal-¯  R   2        1  N         N  1   N        subscript  I  1    superscript  κ  2       subscript  I  0    superscript  κ  2         \langle\bar{R}^{2}\rangle=\frac{1}{N}+\frac{N-1}{N}\,\frac{I_{1}(\kappa)^{2}}{%
 I_{0}(\kappa)^{2}}.     In other words, the statistic       R  e  2   =    N   N  -  1     (     R  ¯   2   -   1  N    )         superscript   subscript  R  e   2       N    N  1       superscript   normal-¯  R   2     1  N       R_{e}^{2}=\frac{N}{N-1}\left(\bar{R}^{2}-\frac{1}{N}\right)     will be an unbiased estimator of       I  1     (  κ  )   2      I  0     (  κ  )   2            subscript  I  1    superscript  κ  2       subscript  I  0    superscript  κ  2      \frac{I_{1}(\kappa)^{2}}{I_{0}(\kappa)^{2}}\,   and solving the equation     R  e   =      I  1    (  κ  )      I  0    (  κ  )           subscript  R  e        subscript  I  1   κ      subscript  I  0   κ      R_{e}=\frac{I_{1}(\kappa)}{I_{0}(\kappa)}\,   for    κ    κ   \kappa\,   will yield a (biased) estimator of    κ    κ   \kappa\,   . In analogy to the linear case, the solution to the equation     R  ¯   =      I  1    (  κ  )      I  0    (  κ  )           normal-¯  R        subscript  I  1   κ      subscript  I  0   κ      \bar{R}=\frac{I_{1}(\kappa)}{I_{0}(\kappa)}\,   will yield the maximum likelihood estimate of    κ    κ   \kappa\,   and both will be equal in the limit of large N . For approximate solution to    κ    κ   \kappa\,   refer to von Mises–Fisher distribution .  Distribution of the mean  The distribution of the sample mean      z  ¯   =    R  ¯    e   i   θ  ¯           normal-¯  z      normal-¯  R    superscript  e    i   normal-¯  θ        \overline{z}=\bar{R}e^{i\overline{\theta}}   for the von Mises distribution is given by: 3       P   (   R  ¯   ,   θ  ¯   )   d    R  ¯    d   θ  ¯    =    1    (   2  π   I  0    (  κ  )    )   N      ∫  Γ     ∏   n  =  1   N    (    e   κ   cos   (    θ  n   -  μ   )      d   θ  n    )      =     e   κ  N   R  ¯    cos   (    θ  ¯   -  μ   )        I  0     (  κ  )   N      (    1    (   2  π   )   N      ∫  Γ     ∏   n  =  1   N    d   θ  n       )            P    normal-¯  R    normal-¯  θ    d   normal-¯  R   d   normal-¯  θ        1   superscript    2  π   subscript  I  0   κ   N      subscript   normal-Γ     superscript   subscript  product    n  1    N      superscript  e    κ       subscript  θ  n   μ      d   subscript  θ  n                 superscript  e    κ  N   normal-¯  R        normal-¯  θ   μ         subscript  I  0    superscript  κ  N         1   superscript    2  π   N      subscript   normal-Γ     superscript   subscript  product    n  1    N     d   subscript  θ  n           P(\bar{R},\bar{\theta})\,d\bar{R}\,d\bar{\theta}=\frac{1}{(2\pi I_{0}(\kappa))%
 ^{N}}\int_{\Gamma}\prod_{n=1}^{N}\left(e^{\kappa\cos(\theta_{n}-\mu)}d\theta_{%
 n}\right)=\frac{e^{\kappa N\bar{R}\cos(\bar{\theta}-\mu)}}{I_{0}(\kappa)^{N}}%
 \left(\frac{1}{(2\pi)^{N}}\int_{\Gamma}\prod_{n=1}^{N}d\theta_{n}\right)     where N is the number of measurements and    Γ    normal-Γ   \Gamma\,   consists of intervals of    2  π      2  π    2\pi   in the variables, subject to the constraint that    R  ¯     normal-¯  R    \bar{R}   and    θ  ¯     normal-¯  θ    \bar{\theta}   are constant, where    R  ¯     normal-¯  R    \bar{R}   is the mean resultant:        R  ¯   2   =    |   z  ¯   |   2   =     (    1  N     ∑   n  =  1   N    cos   (   θ  n   )      )   2   +    (    1  N     ∑   n  =  1   N    sin   (   θ  n   )      )   2           superscript   normal-¯  R   2    superscript     normal-¯  z    2           superscript      1  N     superscript   subscript     n  1    N      subscript  θ  n      2    superscript      1  N     superscript   subscript     n  1    N      subscript  θ  n      2       \bar{R}^{2}=|\bar{z}|^{2}=\left(\frac{1}{N}\sum_{n=1}^{N}\cos(\theta_{n})%
 \right)^{2}+\left(\frac{1}{N}\sum_{n=1}^{N}\sin(\theta_{n})\right)^{2}     and    θ  ¯     normal-¯  θ    \overline{\theta}   is the mean angle:        θ  ¯   =   Arg   (   z  ¯   )     .       normal-¯  θ     Arg   normal-¯  z      \overline{\theta}=\mathrm{Arg}(\overline{z}).\,     Note that product term in parentheses is just the distribution of the mean for a circular uniform distribution . 4  This means that the distribution of the mean direction   μ   μ   \mu   of a von Mises distribution    V  M   (  μ  ,  κ  )       V  M   μ  κ     VM(\mu,\kappa)   is a von Mises distribution    V  M   (  μ  ,    R  ¯   N  κ   )       V  M   μ     normal-¯  R   N  κ      VM(\mu,\bar{R}N\kappa)   , or, equivalently,    V  M   (  μ  ,   R  κ   )       V  M   μ    R  κ      VM(\mu,R\kappa)   .  Entropy  The information entropy of the Von Mises distribution is defined as: 5      H  =   -    ∫  Γ    f   (  θ  ;  μ  ,  κ  )    ln   (   f   (  θ  ;  μ  ,  κ  )    )    d   θ          H      subscript   normal-Γ     f   θ  μ  κ       f   θ  μ  κ     d  θ       H=-\int_{\Gamma}f(\theta;\mu,\kappa)\,\ln(f(\theta;\mu,\kappa))\,d\theta\,     where   Γ   normal-Γ   \Gamma   is any interval of length    2  π      2  π    2\pi   . The logarithm of the density of the Von Mises distribution is straightforward:       ln   (   f   (  θ  ;  μ  ,  κ  )    )    =    -   ln   (   2  π   I  0    (  κ  )    )     +   κ   cos   (  θ  )              f   θ  μ  κ             2  π   subscript  I  0   κ       κ    θ       \ln(f(\theta;\mu,\kappa))=-\ln(2\pi I_{0}(\kappa))+\kappa\cos(\theta)\,     The characteristic function representation for the Von Mises distribution is:       f   (  θ  ;  μ  ,  κ  )    =    1   2  π     (   1  +   2    ∑   n  =  1   ∞     ϕ  n    cos   (   n  θ   )        )          f   θ  μ  κ        1    2  π      1    2    superscript   subscript     n  1         subscript  ϕ  n       n  θ           f(\theta;\mu,\kappa)=\frac{1}{2\pi}\left(1+2\sum_{n=1}^{\infty}\phi_{n}\cos(n%
 \theta)\right)     where     ϕ  n   =      I   |  n  |     (  κ  )    /   I  0     (  κ  )         subscript  ϕ  n          subscript  I    n    κ    subscript  I  0    κ     \phi_{n}=I_{|n|}(\kappa)/I_{0}(\kappa)   . Substituting these expressions into the entropy integral, exchanging the order of integration and summation, and using the orthogonality of the cosines, the entropy may be written:      H  =    ln   (   2  π   I  0    (  κ  )    )    -   κ   ϕ  1     =    ln   (   2  π   I  0    (  κ  )    )    -   κ     I  1    (  κ  )      I  0    (  κ  )             H        2  π   subscript  I  0   κ      κ   subscript  ϕ  1                2  π   subscript  I  0   κ      κ       subscript  I  1   κ      subscript  I  0   κ         H=\ln(2\pi I_{0}(\kappa))-\kappa\phi_{1}=\ln(2\pi I_{0}(\kappa))-\kappa\frac{I%
 _{1}(\kappa)}{I_{0}(\kappa)}     For    κ  =  0      κ  0    \kappa=0   , the von Mises distribution becomes the circular uniform distribution and the entropy attains its maximum value of    ln   (   2  π   )         2  π     \ln(2\pi)   .  See also   Bivariate von Mises distribution  Directional statistics  Von Mises–Fisher distribution  Kent distribution   References    Further reading   Abramowitz, M. and Stegun, I. A. (ed.), Handbook of Mathematical Functions , National Bureau of Standards, 1964; reprinted Dover Publications, 1965. ISBN 0-486-61272-4  "Algorithm AS 86: The von Mises Distribution Function", Mardia, Applied Statistics, 24, 1975 (pp. 268–272).  "Algorithm 518, Incomplete Bessel Function I0: The von Mises Distribution", Hill, ACM Transactions on Mathematical Software, Vol. 3, No. 3, September 1977, Pages 279–284.  Best, D. and Fisher, N. (1979). Efficient simulation of the von Mises distribution. Applied Statistics, 28, 152–157.  Evans, M., Hastings, N., and Peacock, B., "von Mises Distribution". Ch. 41 in Statistical Distributions, 3rd ed. New York. Wiley 2000.  Fisher, Nicholas I., Statistical Analysis of Circular Data. New York. Cambridge 1993.  "Statistical Distributions", 2nd. Edition, Evans, Hastings, and Peacock, John Wiley and Sons, 1993, (chapter 39). ISBN 0-471-55951-2    "  Category:Continuous distributions  Category:Directional statistics  Category:Exponential family distributions  Category:Probability distributions     ↩  ↩  ↩       