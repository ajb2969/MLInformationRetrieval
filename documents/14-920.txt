


Mean absolute scaled error




Mean absolute scaled error

In statistics, the mean absolute scaled error (MASE) is a measure of the accuracy of forecasts . It was proposed in 2006 by Australian statistician Rob J. Hyndman, who described it as a "generally applicable measurement of forecast accuracy without the problems seen in the other measurements."1
The mean absolute scaled error is given by


2 where the numerator et is the forecast error for a given period, defined as the actual value (Yt) minus the forecast value (Ft) for that period: et = Yt − Ft, and the denominator is the average forecast error of the one-step "naive forecast method", which uses the actual value from the prior period as the forecast: Ft = Yt−13
This scale-free error metric "can be used to compare forecast methods on a single series and also to compare forecast accuracy between series. This metric is well suited to intermittent-demand series because it never gives infinite or undefined values4 except in the irrelevant case where all historical data are equal.5
See also

Mean squared error
Mean absolute error
Mean absolute percentage error

References
"
Category:Point estimation performance Category:Statistical deviation and dispersion Category:Statistical terminology Category:Time series analysis












