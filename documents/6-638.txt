   Vector autoregression      Vector autoregression   The vector autoregression ( VAR ) is an econometric model used to capture the linear interdependencies among multiple time series . VAR models generalize the univariate autoregressive model (AR model) by allowing for more than one evolving variable. All variables in a VAR are treated symmetrically in a structural sense (although the estimated quantitative response coefficients will not in general be the same); each variable has an equation explaining its evolution based on its own lags and the lags of the other model variables. VAR modeling does not require as much knowledge about the forces influencing a variable as do structural models with simultaneous equations : The only prior knowledge required is a list of variables which can be hypothesized to affect each other intertemporally.  Specification  Definition  A VAR model describes the evolution of a set of k variables (called endogenous variables ) over the same sample period ( t = 1, ..., T ) as a linear function of only their past values. The variables are collected in a k × 1 vector  y t , which has as the i th element, y i , t , the observation at time "t" of the i th variable. For example, if the i th variable is GDP , then y i , t is the value of GDP at time t .  A p-th order VAR , denoted VAR( p ) , is        y  t   =   c  +    A  1    y   t  -  1     +    A  2    y   t  -  2     +  ⋯  +    A  p    y   t  -  p     +   e  t     ,       subscript  y  t     c     subscript  A  1    subscript  y    t  1        subscript  A  2    subscript  y    t  2     normal-⋯     subscript  A  p    subscript  y    t  p      subscript  e  t      y_{t}=c+A_{1}y_{t-1}+A_{2}y_{t-2}+\cdots+A_{p}y_{t-p}+e_{t},\,     where the l -periods back observation y t −l is called the l -th lag of y , c is a k × 1 vector of constants ( intercepts ), A i is a time-invariant k × k  matrix and e t is a k × 1 vector of error terms satisfying        E   (   e  t   )    =   0         normal-E   subscript  e  t    0    \mathrm{E}(e_{t})=0\,   — every error term has mean zero;       E   (    e  t    e  t  ′    )    =   Ω         normal-E     subscript  e  t    superscript   subscript  e  t   normal-′     normal-Ω    \mathrm{E}(e_{t}e_{t}^{\prime})=\Omega\,   — the contemporaneous covariance matrix of error terms is Ω (a k × k  positive-semidefinite matrix );       E   (    e  t    e   t  -  k   ′    )    =   0         normal-E     subscript  e  t    superscript   subscript  e    t  k    normal-′     0    \mathrm{E}(e_{t}e_{t-k}^{\prime})=0\,   for any non-zero k — there is no correlation across time; in particular, no serial correlation in individual error terms. 1   A p th-order VAR is also called a VAR with p lags . The process of choosing the maximum lag p in the VAR model requires special attention because inference is dependent on correctness of the selected lag order. 2 3  Order of integration of the variables  Note that all variables have to be of the same order of integration . The following cases are distinct:   All the variables are I(0) (stationary): one is in the standard case, i.e. a VAR in level  All the variables are I( d ) (non-stationary) with d > 0:  The variables are cointegrated : the error correction term has to be included in the VAR. The model becomes a Vector error correction model (VECM) which can be seen as a restricted VAR.  The variables are not cointegrated : the variables have first to be differenced d times and one has a VAR in difference.    Concise matrix notation  One can stack the vectors in order to write a VAR( p ) with a concise matrix notation:      Y  =    B  Z   +   U        Y      B  Z   U     Y=BZ+U\,     Details of the matrices are in a separate page .  Example  For a general example of a VAR( p ) with k variables, see General matrix notation of a VAR(p) .  A VAR(1) in two variables can be written in matrix form (more compact notation) as        [      y   1  ,  t         y   2  ,  t       ]   =    [      c  1        c  2      ]   +    [      A   1  ,  1       A   ;   1  ,  2          A   2  ,  1       A   ;   2  ,  2        ]    [      y   1  ,   t  -  1          y   2  ,   t  -  1        ]    +   [      e   1  ,  t         e   2  ,  t       ]     ,         subscript  y   1  t       subscript  y   2  t           subscript  c  1      subscript  c  2          subscript  A   1  1     fragments  A   subscript  normal-;   1  2        subscript  A   2  1     fragments  A   subscript  normal-;   2  2          subscript  y   1    t  1        subscript  y   2    t  1           subscript  e   1  t       subscript  e   2  t         \begin{bmatrix}y_{1,t}\\
 y_{2,t}\end{bmatrix}=\begin{bmatrix}c_{1}\\
 c_{2}\end{bmatrix}+\begin{bmatrix}A_{1,1}&A_{1,2}\\
 A_{2,1}&A_{2,2}\end{bmatrix}\begin{bmatrix}y_{1,t-1}\\
 y_{2,t-1}\end{bmatrix}+\begin{bmatrix}e_{1,t}\\
 e_{2,t}\end{bmatrix},     (in which only a single A matrix appears because this example has a maximum lag p equal to 1), or, equivalently, as the following system of two equations       y   1  ,  t    =    c  1   +    A   1  ,  1     y   1  ,   t  -  1      +    A   1  ,  2     y   2  ,   t  -  1      +    e   1  ,  t           subscript  y   1  t       subscript  c  1      subscript  A   1  1     subscript  y   1    t  1         subscript  A   1  2     subscript  y   2    t  1       subscript  e   1  t       y_{1,t}=c_{1}+A_{1,1}y_{1,t-1}+A_{1,2}y_{2,t-1}+e_{1,t}\,           y   2  ,  t    =    c  2   +    A   2  ,  1     y   1  ,   t  -  1      +    A   2  ,  2     y   2  ,   t  -  1      +   e   2  ,  t      .       subscript  y   2  t       subscript  c  2      subscript  A   2  1     subscript  y   1    t  1         subscript  A   2  2     subscript  y   2    t  1       subscript  e   2  t       y_{2,t}=c_{2}+A_{2,1}y_{1,t-1}+A_{2,2}y_{2,t-1}+e_{2,t}.\,     Each variable in the model has one equation. The current (time t ) observation of each variable depends on its own lagged values as well as on the lagged values of each other variable in the VAR.  Writing VAR( p ) as VAR(1)  A VAR with p lags can always be equivalently rewritten as a VAR with only one lag by appropriately redefining the dependent variable. The transformation amounts to stacking the lags of the VAR( p ) variable in the new VAR(1) dependent variable and appending identities to complete the number of equations.  For example, the VAR(2) model       y  t   =   c  +    A  1    y   t  -  1     +    A  2    y   t  -  2     +   e  t         subscript  y  t     c     subscript  A  1    subscript  y    t  1        subscript  A  2    subscript  y    t  2      subscript  e  t      y_{t}=c+A_{1}y_{t-1}+A_{2}y_{t-2}+e_{t}     can be recast as the VAR(1) model          [      y  t        y   t  -  1       ]   =    [     c      0     ]   +    [      A  1      A   ;  2        I    0     ]    [      y   t  -  1         y   t  -  2       ]    +   [      e  t       0     ]     ,         subscript  y  t      subscript  y    t  1          c    0         subscript  A  1    fragments  A   subscript  normal-;  2      I  0       subscript  y    t  1       subscript  y    t  2          subscript  e  t     0       \begin{bmatrix}y_{t}\\
 y_{t-1}\end{bmatrix}=\begin{bmatrix}c\\
 0\end{bmatrix}+\begin{bmatrix}A_{1}&A_{2}\\
 I&0\end{bmatrix}\begin{bmatrix}y_{t-1}\\
 y_{t-2}\end{bmatrix}+\begin{bmatrix}e_{t}\\
 0\end{bmatrix},        where I is the identity matrix .  The equivalent VAR(1) form is more convenient for analytical derivations and allows more compact statements.  Structural vs. reduced form  Structural VAR  A structural VAR with p lags (sometimes abbreviated SVAR ) is         B  0    y  t    =    c  0   +    B  1    y   t  -  1     +    B  2    y   t  -  2     +  ⋯  +    B  p    y   t  -  p     +   ϵ  t     ,         subscript  B  0    subscript  y  t       subscript  c  0      subscript  B  1    subscript  y    t  1        subscript  B  2    subscript  y    t  2     normal-⋯     subscript  B  p    subscript  y    t  p      subscript  ϵ  t      B_{0}y_{t}=c_{0}+B_{1}y_{t-1}+B_{2}y_{t-2}+\cdots+B_{p}y_{t-p}+\epsilon_{t},     where c 0 is a k × 1 vector of constants, B i is a k × k matrix (for every i = 0, ..., p ) and ε t is a k × 1 vector of error terms. The main diagonal terms of the B 0 matrix (the coefficients on the i th variable in the i th equation) are scaled to 1.  The error terms ε t ( structural shocks ) satisfy the conditions (1) - (3) in the definition above, with the particularity that all the elements off the main diagonal of the covariance matrix     E   (    ϵ  t    ϵ  t  ′    )    =  Σ        normal-E     subscript  ϵ  t    superscript   subscript  ϵ  t   normal-′     normal-Σ    \mathrm{E}(\epsilon_{t}\epsilon_{t}^{\prime})=\Sigma   are zero. That is, the structural shocks are uncorrelated.  For example, a two variable structural VAR(1) is:         [     1     B   ;   0  ;  1  ,  2          B   0  ;  2  ,  1      1     ]    [      y   1  ,  t         y   2  ,  t       ]    =    [      c   0  ;  1         c   0  ;  2       ]   +    [      B   1  ;  1  ,  1       B   ;   1  ;  1  ,  2          B   1  ;  2  ,  1       B   ;   1  ;  2  ,  2        ]    [      y   1  ,   t  -  1          y   2  ,   t  -  1        ]    +   [      ϵ   1  ,  t         ϵ   2  ,  t       ]     ,          1   fragments  B   subscript  normal-;   0  1  2        subscript  B   0  2  1    1       subscript  y   1  t       subscript  y   2  t            subscript  c   0  1       subscript  c   0  2           subscript  B   1  1  1     fragments  B   subscript  normal-;   1  1  2        subscript  B   1  2  1     fragments  B   subscript  normal-;   1  2  2          subscript  y   1    t  1        subscript  y   2    t  1           subscript  ϵ   1  t       subscript  ϵ   2  t         \begin{bmatrix}1&B_{0;1,2}\\
 B_{0;2,1}&1\end{bmatrix}\begin{bmatrix}y_{1,t}\\
 y_{2,t}\end{bmatrix}=\begin{bmatrix}c_{0;1}\\
 c_{0;2}\end{bmatrix}+\begin{bmatrix}B_{1;1,1}&B_{1;1,2}\\
 B_{1;2,1}&B_{1;2,2}\end{bmatrix}\begin{bmatrix}y_{1,t-1}\\
 y_{2,t-1}\end{bmatrix}+\begin{bmatrix}\epsilon_{1,t}\\
 \epsilon_{2,t}\end{bmatrix},     where       Σ  =   E   (    ϵ  t    ϵ  t  ′    )    =   [      σ  1  2     0      0     σ  2  2      ]    ;        normal-Σ    normal-E     subscript  ϵ  t    superscript   subscript  ϵ  t   normal-′             superscript   subscript  σ  1   2   0    0   superscript   subscript  σ  2   2        \Sigma=\mathrm{E}(\epsilon_{t}\epsilon_{t}^{\prime})=\begin{bmatrix}\sigma_{1}%
 ^{2}&0\\
 0&\sigma_{2}^{2}\end{bmatrix};     that is, the variances of the structural shocks are denoted     var   (   ϵ  i   )    =   σ  i  2         var   subscript  ϵ  i     superscript   subscript  σ  i   2     \mathrm{var}(\epsilon_{i})=\sigma_{i}^{2}   ( i = 1, 2) and the covariance is     cov   (   ϵ  1   ,   ϵ  2   )    =  0        cov    subscript  ϵ  1    subscript  ϵ  2     0    \mathrm{cov}(\epsilon_{1},\epsilon_{2})=0   .  Writing the first equation explicitly and passing y 2,t to the right hand side one obtains       y   1  ,  t    =     c   0  ;  1    -    B   0  ;  1  ,  2     y   2  ,  t      +    B   1  ;  1  ,  1     y   1  ,   t  -  1      +    B   1  ;  1  ,  2     y   2  ,   t  -  1      +    ϵ   1  ,  t           subscript  y   1  t         subscript  c   0  1       subscript  B   0  1  2     subscript  y   2  t         subscript  B   1  1  1     subscript  y   1    t  1         subscript  B   1  1  2     subscript  y   2    t  1       subscript  ϵ   1  t       y_{1,t}=c_{0;1}-B_{0;1,2}y_{2,t}+B_{1;1,1}y_{1,t-1}+B_{1;1,2}y_{2,t-1}+%
 \epsilon_{1,t}\,     Note that y 2, t can have a contemporaneous effect on y 1,t if B 0;1,2 is not zero. This is different from the case when B 0 is the identity matrix (all off-diagonal elements are zero — the case in the initial definition), when y 2, t can impact directly y 1, t +1 and subsequent future values, but not y 1, t .  Because of the parameter identification problem , ordinary least squares estimation of the structural VAR would yield inconsistent parameter estimates. This problem can be overcome by rewriting the VAR in reduced form.  From an economic point of view, if the joint dynamics of a set of variables can be represented by a VAR model, then the structural form is a depiction of the underlying, "structural", economic relationships. Two features of the structural form make it the preferred candidate to represent the underlying relations:   1. Error terms are not correlated . The structural, economic shocks which drive the dynamics of the economic variables are assumed to be independent , which implies zero correlation between error terms as a desired property. This is helpful for separating out the effects of economically unrelated influences in the VAR. For instance, there is no reason why an oil price shock (as an example of a supply shock ) should be related to a shift in consumers' preferences towards a style of clothing (as an example of a demand shock ); therefore one would expect these factors to be statistically independent.    2. Variables can have a contemporaneous impact on other variables . This is a desirable feature especially when using low frequency data. For example, an indirect tax rate increase would not affect tax revenues the day the decision is announced, but one could find an effect in that quarter's data.   Reduced-form VAR  By premultiplying the structural VAR with the inverse of B 0        y  t   =     B  0   -  1     c  0    +    B  0   -  1     B  1    y   t  -  1     +    B  0   -  1     B  2    y   t  -  2     +  ⋯  +    B  0   -  1     B  p    y   t  -  p     +    B  0   -  1     ϵ  t      ,       subscript  y  t        superscript   subscript  B  0     1     subscript  c  0       superscript   subscript  B  0     1     subscript  B  1    subscript  y    t  1        superscript   subscript  B  0     1     subscript  B  2    subscript  y    t  2     normal-⋯     superscript   subscript  B  0     1     subscript  B  p    subscript  y    t  p        superscript   subscript  B  0     1     subscript  ϵ  t       y_{t}=B_{0}^{-1}c_{0}+B_{0}^{-1}B_{1}y_{t-1}+B_{0}^{-1}B_{2}y_{t-2}+\cdots+B_{%
 0}^{-1}B_{p}y_{t-p}+B_{0}^{-1}\epsilon_{t},     and denoting          B  0   -  1     c  0    =  c   ,     B  0   -  1     B  i    =    A  i   for  i   =  1    ,    …  ,   p  and   B  0   -  1     ϵ  t     =   e  t       formulae-sequence   formulae-sequence       superscript   subscript  B  0     1     subscript  c  0    c          superscript   subscript  B  0     1     subscript  B  i       subscript  A  i   for  i        1        normal-…    p  and   superscript   subscript  B  0     1     subscript  ϵ  t      subscript  e  t      B_{0}^{-1}c_{0}=c,\quad B_{0}^{-1}B_{i}=A_{i}\text{ for }i=1,\dots,p\text{ and%
  }B_{0}^{-1}\epsilon_{t}=e_{t}     one obtains the p th order reduced VAR       y  t   =   c  +    A  1    y   t  -  1     +    A  2    y   t  -  2     +  ⋯  +    A  p    y   t  -  p     +   e  t         subscript  y  t     c     subscript  A  1    subscript  y    t  1        subscript  A  2    subscript  y    t  2     normal-⋯     subscript  A  p    subscript  y    t  p      subscript  e  t      y_{t}=c+A_{1}y_{t-1}+A_{2}y_{t-2}+\cdots+A_{p}y_{t-p}+e_{t}     Note that in the reduced form all right hand side variables are predetermined at time t . As there are no time t endogenous variables on the right hand side, no variable has a direct contemporaneous effect on other variables in the model.  However, the error terms in the reduced VAR are composites of the structural shocks e t = B 0 −1 ε t . Thus, the occurrence of one structural shock ε i,t can potentially lead to the occurrence of shocks in all error terms e j,t , thus creating contemporaneous movement in all endogenous variables. Consequently, the covariance matrix of the reduced VAR      Ω  =   E   (    e  t    e  t  ′    )    =   E   (    B  0   -  1     ϵ  t    ϵ  t  ′     (   B  0   -  1    )   ′    )    =    B  0   -  1    Σ     (   B  0   -  1    )   ′           normal-Ω    normal-E     subscript  e  t    superscript   subscript  e  t   normal-′            normal-E     superscript   subscript  B  0     1     subscript  ϵ  t    superscript   subscript  ϵ  t   normal-′    superscript   superscript   subscript  B  0     1    normal-′             superscript   subscript  B  0     1    normal-Σ   superscript   superscript   subscript  B  0     1    normal-′       \Omega=\mathrm{E}(e_{t}e_{t}^{\prime})=\mathrm{E}(B_{0}^{-1}\epsilon_{t}%
 \epsilon_{t}^{\prime}(B_{0}^{-1})^{\prime})=B_{0}^{-1}\Sigma(B_{0}^{-1})^{%
 \prime}\,     can have non-zero off-diagonal elements, thus allowing non-zero correlation between error terms.  Estimation  Estimation of the regression parameters  Starting from the concise matrix notation (for details see this annex ):      Y  =    B  Z   +   U        Y      B  Z   U     Y=BZ+U\,      The multivariate least squares (MLS) for B yields:        B  ^   =   Y   Z    ′      (   Z   Z    ′     )    -  1          normal-^  B     Y   superscript  Z   normal-′     superscript    Z   superscript  Z   normal-′       1       \hat{B}=YZ^{{}^{\prime}}(ZZ^{{}^{\prime}})^{-1}     It can be written alternatively as:       Vec   (   B  ^   )    =    (      (   Z   Z    ′     )    -  1    Z   ⊗   I  k    )    Vec   (  Y  )          Vec   normal-^  B       tensor-product     superscript    Z   superscript  Z   normal-′       1    Z    subscript  I  k     Vec  Y      \operatorname{Vec}(\hat{B})=((ZZ^{{}^{\prime}})^{-1}Z\otimes I_{k})\ %
 \operatorname{Vec}(Y)     Where   ⊗   tensor-product   \otimes   denotes the Kronecker product and Vec the vectorization of the matrix Y .  This estimator is consistent and asymptotically efficient . It is furthermore equal to the conditional maximum likelihood estimator . 4   As the explanatory variables are the same in each equation, the multivariate least squares estimator is equivalent to the ordinary least squares estimator applied to each equation separately. 5   Estimation of the covariance matrix of the errors  As in the standard case, the maximum likelihood estimator (MLE) of the covariance matrix differs from the ordinary least squares (OLS) estimator.  MLE estimator:     Σ  ^   =    1  T     ∑   t  =  1   T      ϵ  ^   t     ϵ  ^   t  ′           normal-^  normal-Σ       1  T     superscript   subscript     t  1    T      subscript   normal-^  ϵ   t    superscript   subscript   normal-^  ϵ   t   normal-′        \hat{\Sigma}=\frac{1}{T}\sum_{t=1}^{T}\hat{\epsilon}_{t}\hat{\epsilon}_{t}^{\prime}     OLS estimator:     Σ  ^   =    1   T  -   k  p   -  1      ∑   t  =  1   T      ϵ  ^   t     ϵ  ^   t  ′           normal-^  normal-Σ       1    T    k  p   1      superscript   subscript     t  1    T      subscript   normal-^  ϵ   t    superscript   subscript   normal-^  ϵ   t   normal-′        \hat{\Sigma}=\frac{1}{T-kp-1}\sum_{t=1}^{T}\hat{\epsilon}_{t}\hat{\epsilon}_{t%
 }^{\prime}   for a model with a constant, k variables and p lags.  In a matrix notation, this gives:        Σ  ^   =    1   T  -   k  p   -  1     (   Y  -    B  ^   Z    )     (   Y  -    B  ^   Z    )   ′     .       normal-^  normal-Σ       1    T    k  p   1      Y     normal-^  B   Z     superscript    Y     normal-^  B   Z    normal-′      \hat{\Sigma}=\frac{1}{T-kp-1}(Y-\hat{B}Z)(Y-\hat{B}Z)^{\prime}.     Estimation of the estimator's covariance matrix  The covariance matrix of the parameters can be estimated as         Cov  ^    (   Vec   (   B  ^   )    )    =     (   Z   Z  ′    )    -  1    ⊗   Σ  ^     .         normal-^  Cov     Vec   normal-^  B      tensor-product   superscript    Z   superscript  Z  normal-′      1     normal-^  normal-Σ      \widehat{\mbox{Cov}}(\mbox{Vec}(\hat{B}))=({ZZ^{\prime}})^{-1}\otimes\hat{%
 \Sigma}.\,     Interpretation of estimated model  Properties of the VAR model are usually summarized using structural analysis using Granger causality , Impulse responses , and forecast error variance decompositions .  Forecasting using an estimated VAR model  An estimated VAR model can be used for forecasting , and the quality of the forecasts can be judged, in ways that are completely analogous to the methods used in univariate autoregressive modelling.  Applications  Christopher Sims advocated VAR models, criticizing the claims and performance of earlier modeling in macroeconomic  econometrics . 6 He recommended VAR models, which had previously appeared in time series statistics and in system identification , a statistical specialty in control theory . Sims advocated VAR models as providing a theory-free method to estimate economic relationships, thus being an alternative to the "incredible identification restrictions" in structural models. 7  Software   R : there is a package called vars which deals with VAR models. 8  SAS: VARMAX  Stata : "var"  EViews : "VAR"  Gretl : "var"  Regression analysis of time series  Statistical Software Components   See also   Bayesian vector autoregression  Convergent cross mapping  Granger causality  Variance decomposition   Notes  Further reading        "  Category:Econometrics  Category:Time series models  Category:Multivariate time series analysis     For multivariate tests for autocorrelation in the VAR models, see ↩  ↩  ↩  ↩  ↩   ↩  Bernhard Pfaff VAR, SVAR and SVEC Models: Implementation Within R Package vars ↩     