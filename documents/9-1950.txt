   Expected value of sample information      Expected value of sample information   In decision theory , the expected value of sample information (EVSI) is the expected increase in utility that you could obtain from gaining access to a sample of additional observations before making a decision. The additional information obtained from the sample may allow you to make a more informed, and thus better, decision, thus resulting in an increase in expected utility. EVSI attempts to estimate what this improvement would be before seeing actual sample data; hence, EVSI is a form of what is known as preposterior analysis .  Formulation  Let         d  ∈  D      the decision being made, chosen from space  D        x  ∈  X      an uncertain state, with true value in space  X        z  ∈  Z      an observed sample composed of  n  observations   ⟨   z  1   ,   z  2   ,  .  .  ,   z  n   ⟩         U   (  d  ,  x  )       the utility of selecting decision  d  from  x        p   (  x  )       your prior subjective probability distribution (density function) on  x        p   (  z  |  x  )       the conditional prior probability of observing the sample  z           d  D     the decision being made, chosen from space  D       x  X     an uncertain state, with true value in space  X       z  Z    fragments  an observed sample composed of  n  observations   fragments  normal-⟨   subscript  z  1   normal-,   subscript  z  2   normal-,  normal-.  normal-.  normal-,   subscript  z  n   normal-⟩        U   d  x      the utility of selecting decision  d  from  x       p  x     your prior subjective probability distribution (density function) on  x      fragments  p   fragments  normal-(  z  normal-|  x  normal-)      the conditional prior probability of observing the sample  z      \begin{array}[]{ll}d\in D&\mbox{the decision being made, chosen from space }D%
 \\
 x\in X&\mbox{an uncertain state, with true value in space }X\\
 z\in Z&\mbox{an observed sample composed of }n\mbox{ observations }\langle z_{%
 1},z_{2},..,z_{n}\rangle\\
 U(d,x)&\mbox{the utility of selecting decision }d\mbox{ from }x\\
 p(x)&\mbox{your prior subjective probability distribution (density function) %
 on }x\\
 p(z|x)&\mbox{the conditional prior probability of observing the sample }z\end{array}     It is common (but not essential) in EVSI scenarios for     Z  i   =  X       subscript  Z  i   X    Z_{i}=X   ,    p   (  z  |  x  )   =  ∏  p   (   z  i   |  x  )      fragments  p   fragments  normal-(  z  normal-|  x  normal-)    product  p   fragments  normal-(   subscript  z  i   normal-|  x  normal-)     p(z|x)=\prod p(z_{i}|x)   and    ∫  z  p   (  z  |  x  )   d  z  =  x     fragments   z  p   fragments  normal-(  z  normal-|  x  normal-)   d  z   x    \int zp(z|x)dz=x   , which is to say that each observation is an unbiased sensor reading of the underlying state   x   x   x   , with each sensor reading being independent and identically distributed.  The utility from the optimal decision based only on your prior, without making any further observations, is given by       E   [  U  ]    =     max   d  ∈  D       ∫  X    U   (  d  ,  x  )   p   (  x  )   d  x           E   delimited-[]  U       subscript     d  D      subscript   X     U   d  x   p  x  d  x       E[U]=\max_{d\in D}~{}\int_{X}U(d,x)p(x)~{}dx     If you could gain access to a single sample,   z   z   z   , the optimal posterior utility would be:      E   [  U  |  z  ]   =    max   d  ∈  D      ∫  X   U   (  d  ,  x  )   p   (  x  |  z  )   d  x     fragments  E   fragments  normal-[  U  normal-|  z  normal-]     subscript     d  D     subscript   X   U   fragments  normal-(  d  normal-,  x  normal-)   p   fragments  normal-(  x  normal-|  z  normal-)   d  x    E[U|z]=\max_{d\in D}~{}\int_{X}U(d,x)p(x|z)~{}dx   where    p   (  x  |  z  )      fragments  p   fragments  normal-(  x  normal-|  z  normal-)     p(x|z)   is obtained from Bayes' rule :      p   (  x  |  z  )   =    p   (  z  |  x  )   p   (  x  )     p   (  z  )        fragments  p   fragments  normal-(  x  normal-|  z  normal-)       fragments  p   fragments  normal-(  z  normal-|  x  normal-)   p   fragments  normal-(  x  normal-)      p  z      p(x|z)={{p(z|x)p(x)}\over{p(z)}}         p   (  z  )   =  ∫  p   (  z  |  x  )   p   (  x  )   d  x     fragments  p   fragments  normal-(  z  normal-)     p   fragments  normal-(  z  normal-|  x  normal-)   p   fragments  normal-(  x  normal-)   d  x    p(z)=\int p(z|x)p(x)~{}dx     Since you don't know what sample would actually be obtained if you were to obtain a sample, you must average over all possible samples to obtain the expected utility given a sample:      E   [  U  |  S  I  ]   =   ∫  Z   E   [  U  |  z  ]   p   (  z  )   d  z  =   ∫  Z     max   d  ∈  D      ∫  X   U   (  d  ,  x  )   p   (  z  |  x  )   p   (  x  )   d   x   d  z     fragments  E   fragments  normal-[  U  normal-|  S  I  normal-]     subscript   Z   E   fragments  normal-[  U  normal-|  z  normal-]   p   fragments  normal-(  z  normal-)   d  z    subscript   Z    subscript     d  D     subscript   X   U   fragments  normal-(  d  normal-,  x  normal-)   p   fragments  normal-(  z  normal-|  x  normal-)   p   fragments  normal-(  x  normal-)   d  x  d  z    E[U|SI]=\int_{Z}E[U|z]p(z)dz=\int_{Z}\max_{d\in D}~{}\int_{X}U(d,x)p(z|x)p(x)~%
 {}dx~{}dz     The expected value of sample information is then defined as:         E  V  S  I      =  E   [  U  |  S  I  ]   -  E   [  U  ]          =   (   ∫  Z     max   d  ∈  D      ∫  X   U   (  d  ,  x  )   p   (  z  |  x  )   p   (  x  )   d   x   d  z  )   -   (    max   d  ∈  D      ∫  X   U   (  d  ,  x  )   p   (  x  )   d  x  )            E  V  S  I    fragments   E   fragments  normal-[  U  normal-|  S  I  normal-]    E   fragments  normal-[  U  normal-]       missing-subexpression    fragments    fragments  normal-(   subscript   Z    subscript     d  D     subscript   X   U   fragments  normal-(  d  normal-,  x  normal-)   p   fragments  normal-(  z  normal-|  x  normal-)   p   fragments  normal-(  x  normal-)   d  x  d  z  normal-)     fragments  normal-(   subscript     d  D     subscript   X   U   fragments  normal-(  d  normal-,  x  normal-)   p   fragments  normal-(  x  normal-)   d  x  normal-)       \begin{array}[]{rl}EVSI&=E[U|SI]-E[U]\\
 &=\left(\int_{Z}\max_{d\in D}~{}\int_{X}U(d,x)p(z|x)p(x)~{}dx~{}dz\right)-%
 \left(\max_{d\in D}~{}\int_{X}U(d,x)p(x)~{}dx\right)\end{array}     Computation  It is seldom feasible to carry out the integration over the space of possible observations in E[U|SI] analytically, so the computation of EVSI usually requires a Monte Carlo simulation . The method involves randomly simulating a sample,     z  i   =   ⟨   z  1  i   ,   z  2  i   ,  .  .  ,   z  n  i   ⟩      fragments   superscript  z  i     fragments  normal-⟨   subscript   superscript  z  i   1   normal-,   subscript   superscript  z  i   2   normal-,  normal-.  normal-.  normal-,   subscript   superscript  z  i   n   normal-⟩     z^{i}=\langle z^{i}_{1},z^{i}_{2},..,z^{i}_{n}\rangle   , then using it to compute the posterior    p   (  x  |   z  i   )      fragments  p   fragments  normal-(  x  normal-|   superscript  z  i   normal-)     p(x|z^{i})   and maximizing utility based on    p   (  x  |   z  i   )      fragments  p   fragments  normal-(  x  normal-|   superscript  z  i   normal-)     p(x|z^{i})   . This whole process is then repeated many times, for    i  =  1  ,  .  .  ,  M     fragments  i   1  normal-,  normal-.  normal-.  normal-,  M    i=1,..,M   to obtain a Monte Carlo sample if optimal utilities. These are averaged to obtain the expected utility given a hypothetical sample.  Example  A regulatory agency is to decide whether to approve a new treatment. Before making the final approve/reject decision, they ask what the value would be of conducting a further trial study on   n   n   n   subjects. This question is answered by the EVSI.  (Figure)  Analytica diagram of EVSI model   The diagram shows an influence diagram depiction of an Analytica model for computing the EVSI in this example. For the reader who wishes to study this computation in greater detail, [ http://www.AnalyticaWebPlayer.com/2.5/Client/AwpClient.aspx?inviteId=3&inviteCode; ;=7473&subName;=lchrisman%40lumina%2Ecom the model] can be viewed and evaluated from [ http://www.AnalyticaWebPlayer.com/2.5/Client/AwpClient.aspx?inviteId=3&inviteCode; ;=7473&subName;=lchrisman%40lumina%2Ecom Analytica Web Player].  The model classifies the outcome for any given subject into one of five categories:       Z  i   =        subscript  Z  i   absent    Z_{i}=   {"Cure", "Improvement", "Ineffective", "Mild side-effect", "Serious side-effect"} And for each of these outcomes, assigns a utility equal to an estimated patient-equivalent monetary value of the outcome.  A decision state,   x   x   x   in this example is a vector of five numbers between 0 and 1 that sum to 1, giving the proportion of future patients that will experience each of the five possible outcomes. For example, a state    x  =   [   5  %   ,   60  %   ,   20  %   ,   10  %   ,   5  %   ]       x    percent  5    percent  60    percent  20    percent  10    percent  5      x=[5\%,60\%,20\%,10\%,5\%]   denotes the case where 5% of patients are cured, 60% improve, 20% find the treatment ineffective, 10% experience mild side-effects and 5% experience dangerous side-effects.  The prior,    p   (  x  )       p  x    p(x)   is encoded using a Dirichlet distribution , requiring five numbers (that don't sum to 1) whose relative values capture the expected relative proportion of each outcome, and whose sum encodes the strength of this prior belief. In the diagram, the parameters of the Dirichlet distribution are contained in the variable dirichlet alpha prior , while the prior distribution itself is in the chance variable Prior . The probability density graph of the marginals is shown here:  (Figure)  EVSI prior marginals.png   In the chance variable Trial data , trial data is simulated as a Monte Carlo sample from a Multinomial distribution . For example, when Trial_size=100, each Monte Carlo sample of Trial_data contains a vector that sums to 100 showing the number of subjects in the simulated study that experienced each of the five possible outcomes. The following result table depicts the first 8 simulated trial outcomes:  (Figure)  EVSI trial data.png   Combining this trial data with a Dirichlet prior requires only adding the outcome frequencies to the Dirichlet prior alpha values, resulting in a Diriclet posterior distribution for each simulated trial. For each of these, the decision to approve is made based on whether the mean utility is positive, and using a utility of zero when the treatment is not approved, the Pre-posterior utility is obtained . Repeating the computation for a range of possible trial sizes, an EVSI is obtained at each possible candidate trial size as depicted in this graph:  (Figure)  EVSI result.png   Historical background  The 1961 book Applied Statistical Decision Theory 1 by Schlaifer and Raiffa was among the earliest to utilize EVSI extensively.  More historical background is needed here.  Comparison to related measures  Expected value of sample information (EVSI) is a relaxation of the expected value of perfect information (EVPI) metric, which encodes the increase of utility that would be obtained if one were to learn the true underlying state,   x   x   x   . Essentially EVPI indicates the value of perfect information, while EVSI indicates the value of some limited and incomplete information.  The expected value of including uncertainty (EVIU) compares the value of modeling uncertain information as compared to modeling a situation without taking uncertainty into account. Since the impact of uncertainty on computed results is often analysed using Monte Carlo methods , EVIU appears to be very similar to the value of carrying out an analysis using a Monte Carlo sample , which closely resembles in statement the notion captured with EVSI. However, EVSI and EVIU are quite distinct—a notable difference between the manner in which EVSI uses Bayesian updating to incorporate the simulated sample.  See also   Expected value of perfect information (EVPI)  Expected value of including uncertainty (EVIU)   References  "  Category:Decision theory  Category:Game theory  Category:Bayesian inference     Schlaifer & Raiffa (1961), "Applied Statistical Decision Theory" ↩     