<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="585">LogitBoost</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>LogitBoost</h1>
<hr/>

<p>In <a href="machine_learning" title="wikilink">machine learning</a> and <a href="computational_learning_theory" title="wikilink">computational learning theory</a>, <strong>LogitBoost</strong> is a <a href="Boosting_(meta-algorithm)" title="wikilink">boosting</a> algorithm formulated by <a href="Jerome_H._Friedman" title="wikilink">Jerome Friedman</a>, <a href="Trevor_Hastie" title="wikilink">Trevor Hastie</a>, and <a href="Robert_Tibshirani" title="wikilink">Robert Tibshirani</a>. The original paper<a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a> casts the <a class="uri" href="AdaBoost" title="wikilink">AdaBoost</a> algorithm into a statistical framework. Specifically, if one considers <a class="uri" href="AdaBoost" title="wikilink">AdaBoost</a> as a <a href="generalized_additive_model" title="wikilink">generalized additive model</a> and then applies the cost functional of <a href="logistic_regression" title="wikilink">logistic regression</a>, one can derive the LogitBoost algorithm.</p>
<h2 id="minimizing-the-logitboost-cost-function">Minimizing the LogitBoost cost function</h2>

<p>LogitBoost can be seen as a <a href="convex_optimization" title="wikilink">convex optimization</a>. Specifically, given that we seek an additive model of the form</p>

<p>

<math display="block" id="LogitBoost:0">
 <semantics>
  <mrow>
   <mi>f</mi>
   <mo>=</mo>
   <mrow>
    <munder>
     <mo largeop="true" movablelimits="false" symmetric="true">∑</mo>
     <mi>t</mi>
    </munder>
    <mrow>
     <msub>
      <mi>α</mi>
      <mi>t</mi>
     </msub>
     <msub>
      <mi>h</mi>
      <mi>t</mi>
     </msub>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <ci>f</ci>
    <apply>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <sum></sum>
      <ci>t</ci>
     </apply>
     <apply>
      <times></times>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>α</ci>
       <ci>t</ci>
      </apply>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>h</ci>
       <ci>t</ci>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   f=\sum_{t}\alpha_{t}h_{t}
  </annotation>
 </semantics>
</math>

</p>

<p>the LogitBoost algorithm minimizes the logistic loss:</p>

<p>

<math display="block" id="LogitBoost:1">
 <semantics>
  <mrow>
   <munder>
    <mo largeop="true" movablelimits="false" symmetric="true">∑</mo>
    <mi>i</mi>
   </munder>
   <mrow>
    <mi>log</mi>
    <mrow>
     <mo>(</mo>
     <mrow>
      <mn>1</mn>
      <mo>+</mo>
      <msup>
       <mi>e</mi>
       <mrow>
        <mo>-</mo>
        <mrow>
         <msub>
          <mi>y</mi>
          <mi>i</mi>
         </msub>
         <mi>f</mi>
         <mrow>
          <mo stretchy="false">(</mo>
          <msub>
           <mi>x</mi>
           <mi>i</mi>
          </msub>
          <mo stretchy="false">)</mo>
         </mrow>
        </mrow>
       </mrow>
      </msup>
     </mrow>
     <mo>)</mo>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <sum></sum>
     <ci>i</ci>
    </apply>
    <apply>
     <log></log>
     <apply>
      <plus></plus>
      <cn type="integer">1</cn>
      <apply>
       <csymbol cd="ambiguous">superscript</csymbol>
       <ci>e</ci>
       <apply>
        <minus></minus>
        <apply>
         <times></times>
         <apply>
          <csymbol cd="ambiguous">subscript</csymbol>
          <ci>y</ci>
          <ci>i</ci>
         </apply>
         <ci>f</ci>
         <apply>
          <csymbol cd="ambiguous">subscript</csymbol>
          <ci>x</ci>
          <ci>i</ci>
         </apply>
        </apply>
       </apply>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \sum_{i}\log\left(1+e^{-y_{i}f(x_{i})}\right)
  </annotation>
 </semantics>
</math>

</p>
<h2 id="references">References</h2>
<h2 id="see-also">See also</h2>
<ul>
<li><a href="Gradient_boosting" title="wikilink">Gradient boosting</a></li>
<li><a href="Logistic_model_tree" title="wikilink">Logistic model tree</a></li>
</ul>

<p>"</p>

<p><a href="Category:Classification_algorithms" title="wikilink">Category:Classification algorithms</a> <a href="Category:Ensemble_learning" title="wikilink">Category:Ensemble learning</a> <a href="Category:Machine_learning_algorithms" title="wikilink">Category:Machine learning algorithms</a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1">Jerome Friedman, Trevor Hastie and Robert Tibshirani. Additive logistic regression: a statistical view of boosting. Annals of Statistics 28(2), 2000. 337–407. <a class="uri" href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.51.9525">http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.51.9525</a><a href="#fnref1">↩</a></li>
</ol>
</section>
</body>
</html>
