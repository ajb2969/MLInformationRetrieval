<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="1448">Clique problem</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>Clique problem</h1>
<hr/>
<figure><b>(Figure)</b>
<figcaption>The <a href="Brute-force_search" title="wikilink">brute force algorithm</a> finds a 4-clique in this 7-vertex graph (the complement of the 7-vertex <a href="path_graph" title="wikilink">path graph</a>) by systematically checking all <a href="Combination" title="wikilink">C</a>(7,4)=35 4-vertex subgraphs for completeness.</figcaption>
</figure>

<p>In <a href="computer_science" title="wikilink">computer science</a>, the <strong>clique problem</strong> refers to any of the problems related to finding particular <a href="complete_graph" title="wikilink">complete</a> <a href="Glossary_of_graph_theory#Subgraphs" title="wikilink">subgraphs</a> ("<a href="clique_(graph_theory)" title="wikilink">cliques</a>") in a <a href="Graph_(mathematics)" title="wikilink">graph</a>, i.e., sets of elements where each pair of elements is connected.</p>

<p>For example, the <strong>maximum clique problem</strong> arises in the following real-world setting. Consider a <a href="social_network" title="wikilink">social network</a>, where the graph’s <a href="vertex_(graph_theory)" title="wikilink">vertices</a> represent people, and the graph’s <a href="edge_(graph_theory)" title="wikilink">edges</a> represent mutual acquaintance. To find a largest subset of people who all know each other, one can systematically inspect all subsets, a process that is too time-consuming to be practical for social networks comprising more than a few dozen people. Although this <a href="brute-force_search" title="wikilink">brute-force search</a> can be improved by more efficient <a href="algorithm" title="wikilink">algorithms</a>, all of these algorithms take <a href="exponential_time" title="wikilink">exponential time</a> to solve the problem. Therefore, much of the theory about the clique problem is devoted to identifying special types of graph that admit more efficient algorithms, or to establishing the computational difficulty of the general problem in various models of computation.<a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a> Along with its applications in social networks, the clique problem also has many applications in <a class="uri" href="bioinformatics" title="wikilink">bioinformatics</a> and <a href="computational_chemistry" title="wikilink">computational chemistry</a>.<a class="footnoteRef" href="#fn2" id="fnref2"><sup>2</sup></a></p>

<p>Clique problems include:</p>
<ul>
<li>finding a <a href="maximum_clique" title="wikilink">maximum clique</a> (largest clique by vertices),</li>
<li>finding a maximum weight clique in a weighted graph,</li>
<li>listing all <a href="maximal_clique" title="wikilink">maximal cliques</a> (cliques that cannot be enlarged)</li>
<li>solving the <a href="decision_problem" title="wikilink">decision problem</a> of testing whether a graph contains a clique larger than a given size.</li>
</ul>

<p>These problems are all hard: the clique decision problem is <a class="uri" href="NP-complete" title="wikilink">NP-complete</a> (one of <a href="Karp's_21_NP-complete_problems" title="wikilink">Karp's 21 NP-complete problems</a>), the problem of finding the maximum clique is both <a href="parameterized_complexity" title="wikilink">fixed-parameter intractable</a> and <a href="hardness_of_approximation" title="wikilink">hard to approximate</a>, and listing all maximal cliques may require <a href="exponential_time" title="wikilink">exponential time</a> as there exist graphs with exponentially many maximal cliques. Nevertheless, there are algorithms for these problems that run in exponential time or that handle certain more specialized input graphs in polynomial time.<a class="footnoteRef" href="#fn3" id="fnref3"><sup>3</sup></a></p>
<h2 id="history">History</h2>

<p>Although complete subgraphs have been studied for longer in mathematics,<a class="footnoteRef" href="#fn4" id="fnref4"><sup>4</sup></a> the term "clique" and the problem of algorithmically listing cliques both come from the social sciences, where complete subgraphs are used to model <a href="clique" title="wikilink">social cliques</a>, groups of people who all know each other. The "clique" terminology comes from , and the first algorithm for solving the clique problem is that of ,<a class="footnoteRef" href="#fn5" id="fnref5"><sup>5</sup></a> who were motivated by the sociological application.</p>

<p>Since the work of Harary and Ross, many others have devised algorithms for various versions of the clique problem.<a class="footnoteRef" href="#fn6" id="fnref6"><sup>6</sup></a> In the 1970s, researchers began studying these algorithms from the point of view of <a href="worst-case_analysis" title="wikilink">worst-case analysis</a>; see, for instance, , an early work on the worst-case complexity of the maximum clique problem. Also in the 1970s, beginning with the work of  and , researchers began finding mathematical justification for the perceived difficulty of the clique problem in the theory of <a href="NP-complete" title="wikilink">NP-completeness</a> and related intractability results. In the 1990s, a breakthrough series of papers beginning with  and reported at the time in major newspapers,<a class="footnoteRef" href="#fn7" id="fnref7"><sup>7</sup></a> showed that it is not even possible to approximate the problem accurately and efficiently.</p>
<h2 id="definitions">Definitions</h2>

<p> An <a href="undirected_graph" title="wikilink">undirected graph</a> is formed by a <a href="finite_set" title="wikilink">finite set</a> of <a href="vertex_(graph_theory)" title="wikilink">vertices</a> and a set of <a href="unordered_pair" title="wikilink">unordered pairs</a> of vertices, which are called <a href="edge_(graph_theory)" title="wikilink">edges</a>. By convention, in algorithm analysis, the number of vertices in the graph is denoted by <em>n</em> and the number of edges is denoted by <em>m</em>. A <a href="clique_(graph_theory)" title="wikilink">clique</a> in a graph <em>G</em> is a <a href="complete_graph" title="wikilink">complete</a> <a href="Glossary_of_graph_theory#Subgraphs" title="wikilink">subgraph</a> of <em>G</em>; that is, it is a subset <em>S</em> of the vertices such that every two vertices in <em>S</em> are connected by an edge in <em>G</em>. A <a href="maximal_clique" title="wikilink">maximal clique</a> is a clique to which no more vertices can be added; a <a href="maximum_clique" title="wikilink">maximum clique</a> is a clique that includes the largest possible number of vertices, and the clique number ω(<em>G</em>) is the number of vertices in a maximum clique of <em>G</em>.<a class="footnoteRef" href="#fn8" id="fnref8"><sup>8</sup></a></p>

<p>Several closely related clique-finding problems have been studied.</p>
<ul>
<li>In the maximum clique problem, the input is an undirected graph, and the output is a maximum clique in the graph. If there are multiple maximum cliques, only one need be output.</li>
<li>In the weighted maximum clique problem, the input is an undirected graph with weights on its vertices (or, less frequently, edges) and the output is a clique with maximum total weight. The maximum clique problem is the special case in which all weights are equal.</li>
<li>In the maximal clique listing problem, the input is an undirected graph, and the output is a list of all its maximal cliques. The maximum clique problem may be solved using as a subroutine an algorithm for the maximal clique listing problem, because the maximum clique must be included among all the maximal cliques.</li>
<li>In the <em>k</em>-clique problem, the input is an undirected graph and a number <em>k</em>, and the output is a clique of size <em>k</em> if one exists (or, sometimes, all cliques of size <em>k</em>).</li>
<li>In the clique decision problem, the input is an undirected graph and a number <em>k</em>, and the output is a <a href="truth_value" title="wikilink">Boolean value</a>: true if the graph contains a <em>k</em>-clique, and false otherwise.</li>
</ul>

<p>The first four of these problems are all important in practical applications; the clique decision problem is not, but is necessary in order to apply the theory of <a class="uri" href="NP-completeness" title="wikilink">NP-completeness</a> to clique-finding problems.</p>

<p>The clique problem and the <a href="independent_set_problem" title="wikilink">independent set problem</a> are complementary: a clique in <em>G</em> is an independent set in the <a href="complement_graph" title="wikilink">complement graph</a> of <em>G</em> and vice versa. Therefore, many computational results may be applied equally well to either problem, and some research papers do not clearly distinguish between the two problems. However, the two problems have different properties when applied to restricted families of graphs; for instance, the clique problem may be solved in polynomial time for <a href="planar_graph" title="wikilink">planar graphs</a><a class="footnoteRef" href="#fn9" id="fnref9"><sup>9</sup></a> while the independent set problem remains NP-hard on planar graphs.</p>
<h2 id="algorithms">Algorithms</h2>
<h3 id="maximal-versus-maximum">Maximal versus maximum</h3>

<p>A <a href="maximal_element" title="wikilink">maximal</a> clique, sometimes called inclusion-maximal, is a clique that is not included in a larger clique. Note, therefore, that every clique is contained in a maximal clique.</p>

<p>Maximal cliques can be very small. A graph may contain a non-maximal clique with many vertices and a separate clique of size 2 which is maximal. While a maximum (i.e., largest) clique is necessarily maximal, the converse does not hold. There are some types of graphs in which every maximal clique is maximum (the <a href="complement_(graph_theory)" title="wikilink">complements</a> of <a href="well-covered_graph" title="wikilink">well-covered graphs</a>, notably including <a href="complete_graph" title="wikilink">complete graphs</a>, <a href="triangle-free_graph" title="wikilink">triangle-free graphs</a> without <a href="isolated_vertex" title="wikilink">isolated vertices</a>, <a href="complete_multipartite_graph" title="wikilink">complete multipartite graphs</a>, and <a href="k-tree" title="wikilink">k-trees</a>) but other graphs have maximal cliques that are not maximum.</p>

<p>Finding a maximal clique is straightforward: Starting with an arbitrary clique (for instance, a single vertex), grow the current clique one vertex at a time by iterating over the graph’s remaining vertices, adding a vertex if it is connected to each vertex in the current clique, and discarding it otherwise. This algorithm runs in <a href="linear_time" title="wikilink">linear time</a>. Because of the ease of finding maximal cliques, and their potential small size, more attention has been given to the much harder algorithmic problem of finding a maximum or otherwise large clique than has been given to the problem of finding a single maximal clique.</p>
<h3 id="cliques-of-fixed-size">Cliques of fixed size</h3>

<p>A <a href="brute-force_search" title="wikilink">brute force algorithm</a> to test whether a graph <em>G</em> contains a <em>k</em>-vertex clique, and to find any such clique that it contains, is to examine each subgraph with <em>k</em> vertices and check to see whether it forms a clique. This algorithm takes time O(<em>n</em><sup><em>k</em></sup> <em>k</em><sup>2</sup>): there are O(<em>n</em><sup><em>k</em></sup>) subgraphs to check, each of which has O(<em>k</em><sup>2</sup>) edges whose presence in <em>G</em> needs to be checked. Thus, the problem may be solved in <a href="polynomial_time" title="wikilink">polynomial time</a> whenever <em>k</em> is a fixed constant. When <em>k</em> is part of the input to the problem, however, the time is exponential.<a class="footnoteRef" href="#fn10" id="fnref10"><sup>10</sup></a></p>

<p>The simplest nontrivial case of the clique-finding problem is finding a triangle in a graph, or equivalently determining whether the graph is <a href="triangle-free_graph" title="wikilink">triangle-free</a>. In a graph with <em>m</em> edges, there may be at most Θ(<em>m</em><sup>3/2</sup>) triangles; the worst case occurs when <em>G</em> is itself a clique. Therefore, algorithms for listing all triangles must take at least Ω(<em>m</em><sup>3/2</sup>) time in the worst case, and algorithms are known that match this time bound.<a class="footnoteRef" href="#fn11" id="fnref11"><sup>11</sup></a> For instance,  describe an algorithm that sorts the vertices in order from highest degree to lowest and then iterates through each vertex <em>v</em> in the sorted list, looking for triangles that include <em>v</em> and do not include any previous vertex in the list. To do so the algorithm marks all neighbors of <em>v</em>, searches through all edges incident to a neighbor of <em>v</em> outputting a triangle for every edge that has two marked endpoints, and then removes the marks and deletes <em>v</em> from the graph. As the authors show, the time for this algorithm is proportional to the <a class="uri" href="arboricity" title="wikilink">arboricity</a> of the graph (<em>a</em>(<em>G</em>)) times the number of edges, which is O(<em>m</em> <em>a</em>(<em>G</em>)). Since the arboricity is at most O(<em>m</em><sup>1/2</sup>), this algorithm runs in time O(<em>m</em><sup>3/2</sup>). More generally, all <em>k</em>-vertex cliques can be listed by a similar algorithm that takes time proportional to the number of edges times the (<em>k</em> − 2)nd power of the arboricity.<a class="footnoteRef" href="#fn12" id="fnref12"><sup>12</sup></a> For graphs of constant arboricity, such as planar graphs (or in general graphs from any non-trivial <a href="minor-closed_graph_family" title="wikilink">minor-closed graph family</a>), this algorithm takes O(<em>m</em>) time, which is optimal since it is linear in the size of the input.</p>

<p>If one desires only a single triangle, or an assurance that the graph is triangle-free, faster algorithms are possible. As  observe, the graph contains a triangle if and only if its <a href="adjacency_matrix" title="wikilink">adjacency matrix</a> and the square of the adjacency matrix contain nonzero entries in the same cell; therefore, fast matrix multiplication techniques such as the <a href="Coppersmith–Winograd_algorithm" title="wikilink">Coppersmith–Winograd algorithm</a> can be applied to find triangles in time O(<em>n</em><sup>2.376</sup>), which may be faster than O(<em>m</em><sup>3/2</sup>) for sufficiently <a href="dense_graph" title="wikilink">dense graphs</a>.  have improved the O(<em>m</em><sup>3/2</sup>) algorithm for finding triangles to O(<em>m</em><sup>1.41</sup>) by using fast matrix multiplication. This idea of using fast matrix multiplication to find triangles has also been extended to problems of finding <em>k</em>-cliques for larger values of <em>k</em>.<a class="footnoteRef" href="#fn13" id="fnref13"><sup>13</sup></a></p>
<h3 id="listing-all-maximal-cliques">Listing all maximal cliques</h3>

<p>By a result of , any <em>n</em>-vertex graph has at most 3<sup><em>n</em>/3</sup> maximal cliques. The <a href="Bron–Kerbosch_algorithm" title="wikilink">Bron–Kerbosch algorithm</a> is a recursive <a class="uri" href="backtracking" title="wikilink">backtracking</a> procedure of  that augments a candidate clique by considering one vertex at a time, either adding it to the candidate clique or to a set of excluded vertices that cannot be in the clique but must have some non-neighbor in the eventual clique; variants of this algorithm can be shown to have worst-case running time O(3<sup><em>n</em>/3</sup>).<a class="footnoteRef" href="#fn14" id="fnref14"><sup>14</sup></a> Therefore, this provides a worst-case-optimal solution to the problem of listing all maximal independent sets; further, the Bron–Kerbosch algorithm has been widely reported as being faster in practice than its alternatives.<a class="footnoteRef" href="#fn15" id="fnref15"><sup>15</sup></a></p>

<p>As  showed, it is also possible to list all maximal cliques in a graph in an amount of time that is polynomial per generated clique. An algorithm such as theirs in which the running time depends on the output size is known as an <a href="output-sensitive_algorithm" title="wikilink">output-sensitive algorithm</a>. Their algorithm is based on the following two observations, relating the maximal cliques of the given graph <em>G</em> to the maximal cliques of a graph <em>G</em> \ <em>v</em> formed by removing an arbitrary vertex <em>v</em> from <em>G</em>:</p>
<ul>
<li>For every maximal clique <em>C</em> of <em>G</em> \ <em>v</em>, either <em>C</em> continues to form a maximal clique in <em>G</em>, or <em>C</em> ⋃ {v} forms a maximal clique in <em>G</em>. Therefore, <em>G</em> has at least as many maximal cliques as <em>G</em> \ <em>v</em> does.</li>
<li>Each maximal clique in <em>G</em> that does not contain <em>v</em> is a maximal clique in <em>G</em> \ <em>v</em>, and each maximal clique in <em>G</em> that does contain <em>v</em> can be formed from a maximal clique <em>C</em> in <em>G</em> \ <em>v</em> by adding <em>v</em> and removing the non-neighbors of <em>v</em> from <em>C</em>.</li>
</ul>

<p>Using these observations they can generate all maximal cliques in <em>G</em> by a recursive algorithm that, for each maximal clique <em>C</em> in <em>G</em> \ <em>v</em>, outputs <em>C</em> and the clique formed by adding <em>v</em> to <em>C</em> and removing the non-neighbors of <em>v</em>. However, some cliques of <em>G</em> may be generated in this way from more than one parent clique of <em>G</em> \ <em>v</em>, so they eliminate duplicates by outputting a clique in <em>G</em> only when its parent in <em>G</em> \ <em>v</em> is lexicographically maximum among all possible parent cliques. On the basis of this principle, they show that all maximal cliques in <em>G</em> may be generated in time O(<em>mn</em>) per clique, where <em>m</em> is the number of edges in <em>G</em> and <em>n</em> is the number of vertices;  improve this to O(<em>ma</em>) per clique, where <em>a</em> is the <a class="uri" href="arboricity" title="wikilink">arboricity</a> of the given graph.  provide an alternative output-sensitive algorithm based on fast matrix multiplication, and  show that it is even possible to list all maximal cliques in <a href="lexicographic_order" title="wikilink">lexicographic order</a> with polynomial delay per clique, although the reverse of this order is <a class="uri" href="NP-hard" title="wikilink">NP-hard</a> to generate.</p>

<p>On the basis of this result, it is possible to list all maximal cliques in polynomial time, for families of graphs in which the number of cliques is polynomially bounded. These families include <a href="chordal_graph" title="wikilink">chordal graphs</a>, <a href="complete_graph" title="wikilink">complete graphs</a>, <a href="triangle-free_graph" title="wikilink">triangle-free graphs</a>, <a href="interval_graph" title="wikilink">interval graphs</a>, graphs of bounded <a class="uri" href="boxicity" title="wikilink">boxicity</a>, and <a href="planar_graph" title="wikilink">planar graphs</a>.<a class="footnoteRef" href="#fn16" id="fnref16"><sup>16</sup></a> In particular, the planar graphs, and more generally, any family of graphs that is both <a href="dense_graph" title="wikilink">sparse</a> (having a number of edges at most a constant times the number of vertices) and <a href="Closure_(mathematics)" title="wikilink">closed</a> under the operation of taking subgraphs, have O(<em>n</em>) cliques, of at most constant size, that can be listed in linear time.<a class="footnoteRef" href="#fn17" id="fnref17"><sup>17</sup></a><a class="footnoteRef" href="#fn18" id="fnref18"><sup>18</sup></a></p>
<h3 id="finding-maximum-cliques-in-arbitrary-graphs">Finding maximum cliques in arbitrary graphs</h3>

<p>It is possible to find the maximum clique, or the clique number, of an arbitrary <em>n</em>-vertex graph in time O(3<sup><em>n</em>/3</sup>) = O(1.4422<sup><em>n</em></sup>) by using one of the algorithms described above to list all maximal cliques in the graph and returning the largest one. However, for this variant of the clique problem better worst-case time bounds are possible. The algorithm of  solves this problem in time O(2<sup><em>n</em>/3</sup>) = O(1.2599<sup><em>n</em></sup>); it is a recursive backtracking scheme similar to that of the <a href="Bron–Kerbosch_algorithm" title="wikilink">Bron–Kerbosch algorithm</a>, but is able to eliminate some recursive calls when it can be shown that some other combination of vertices not used in the call is guaranteed to lead to a solution at least as good.  improved this to O(2<sup>0.304<em>n</em></sup>) = O(1.2346<sup><em>n</em></sup>).  improved this to O(2<sup>0.276<em>n</em></sup>) = O(1.2108<sup><em>n</em></sup>) time, at the expense of greater space usage, by a similar backtracking scheme with a more complicated case analysis, together with a <a href="dynamic_programming" title="wikilink">dynamic programming</a> technique in which the optimal solution is precomputed for all small connected subgraphs of the <a href="complement_graph" title="wikilink">complement graph</a> and these partials solutions are used to shortcut the backtracking recursion. The fastest algorithm known today is due to  which runs in time O(2<sup>0.249<em>n</em></sup>) = O(1.1888<sup><em>n</em></sup>).</p>

<p>There has also been extensive research on <a href="heuristic_algorithm" title="wikilink">heuristic algorithms</a> for solving maximum clique problems without worst-case runtime guarantees, based on methods including <a href="branch_and_bound" title="wikilink">branch and bound</a>,<a class="footnoteRef" href="#fn19" id="fnref19"><sup>19</sup></a> <a href="Local_search_(optimization)" title="wikilink">local search</a>,<a class="footnoteRef" href="#fn20" id="fnref20"><sup>20</sup></a> <a href="greedy_algorithm" title="wikilink">greedy algorithms</a>,<a class="footnoteRef" href="#fn21" id="fnref21"><sup>21</sup></a> and <a href="constraint_programming" title="wikilink">constraint programming</a>.<a class="footnoteRef" href="#fn22" id="fnref22"><sup>22</sup></a> Non-standard computing methodologies for finding cliques include <a href="DNA_computing" title="wikilink">DNA computing</a><a class="footnoteRef" href="#fn23" id="fnref23"><sup>23</sup></a> and <a href="adiabatic_quantum_computation" title="wikilink">adiabatic quantum computation</a>.<a class="footnoteRef" href="#fn24" id="fnref24"><sup>24</sup></a> The maximum clique problem was the subject of an implementation challenge sponsored by <a class="uri" href="DIMACS" title="wikilink">DIMACS</a> in 1992–1993,<a class="footnoteRef" href="#fn25" id="fnref25"><sup>25</sup></a> and a collection of graphs used as benchmarks for the challenge is publicly available.<a class="footnoteRef" href="#fn26" id="fnref26"><sup>26</sup></a></p>
<h3 id="special-classes-of-graphs">Special classes of graphs</h3>

<p> <a href="Planar_graph" title="wikilink">Planar graphs</a>, and other families of sparse graphs, have been discussed above: they have linearly many maximal cliques, of bounded size, that can be listed in linear time.<a class="footnoteRef" href="#fn27" id="fnref27"><sup>27</sup></a> In particular, for planar graphs, any clique can have at most four vertices, by <a href="Kuratowski's_theorem" title="wikilink">Kuratowski's theorem</a>.</p>

<p><a href="Perfect_graph" title="wikilink">Perfect graphs</a> are defined by the properties that their clique number equals their chromatic number, and that this equality holds also in each of their <a href="induced_subgraph" title="wikilink">induced subgraphs</a>. For perfect graphs, it is possible to find a maximum clique in polynomial time, using an algorithm based on <a href="semidefinite_programming" title="wikilink">semidefinite programming</a>.<a class="footnoteRef" href="#fn28" id="fnref28"><sup>28</sup></a> However, this method is complex and non-combinatorial, and specialized clique-finding algorithms have been developed for many subclasses of perfect graphs.<a class="footnoteRef" href="#fn29" id="fnref29"><sup>29</sup></a> In the <a href="complement_graph" title="wikilink">complement graphs</a> of <a href="bipartite_graph" title="wikilink">bipartite graphs</a>, <a href="König's_theorem_(graph_theory)" title="wikilink">König's theorem</a> allows the maximum clique problem to be solved using techniques for <a href="Matching_(graph_theory)" title="wikilink">matching</a>. In another class of perfect graphs, the <a href="permutation_graph" title="wikilink">permutation graphs</a>, a maximum clique is a <a href="Longest_increasing_subsequence" title="wikilink">longest decreasing subsequence</a> of the permutation defining the graph and can be found using known algorithms for the longest decreasing subsequence problem.<a class="footnoteRef" href="#fn30" id="fnref30"><sup>30</sup></a> In <a href="chordal_graph" title="wikilink">chordal graphs</a>, the maximal cliques are a subset of the <em>n</em> cliques formed as part of an elimination ordering.</p>

<p>In some cases, these algorithms can be extended to other, non-perfect, classes of graphs as well: for instance, in a <a href="circle_graph" title="wikilink">circle graph</a>, the <a href="neighborhood_(graph_theory)" title="wikilink">neighborhood</a> of each vertex is a permutation graph, so a maximum clique in a circle graph can be found by applying the permutation graph algorithm to each neighborhood.<a class="footnoteRef" href="#fn31" id="fnref31"><sup>31</sup></a> Similarly, in a <a href="unit_disk_graph" title="wikilink">unit disk graph</a> (with a known geometric representation), there is a polynomial time algorithm for maximum cliques based on applying the algorithm for complements of bipartite graphs to shared neighborhoods of pairs of vertices.<a class="footnoteRef" href="#fn32" id="fnref32"><sup>32</sup></a></p>

<p>The algorithmic problem of finding a maximum clique in a <a href="random_graph" title="wikilink">random graph</a> drawn from the <a href="Erdős–Rényi_model" title="wikilink">Erdős–Rényi model</a> (in which each edge appears with probability 1/2, independently from the other edges) was suggested by . Although the clique number of such graphs is very close to 2 log<sub>2</sub><em>n</em>, simple <a href="greedy_algorithm" title="wikilink">greedy algorithms</a> as well as more sophisticated randomized approximation techniques<a class="footnoteRef" href="#fn33" id="fnref33"><sup>33</sup></a> only find cliques with size log<sub>2</sub><em>n</em>, and the number of maximal cliques in such graphs is with high probability exponential in log<sup>2</sup><em>n</em> preventing a polynomial time solution that lists all of them. Because of the difficulty of this problem, several authors have investigated variants of the problem in which the random graph is augmented by adding large cliques. While <a href="Spectral_graph_theory" title="wikilink">spectral methods</a><a class="footnoteRef" href="#fn34" id="fnref34"><sup>34</sup></a> and <a href="semidefinite_programming" title="wikilink">semidefinite programming</a><a class="footnoteRef" href="#fn35" id="fnref35"><sup>35</sup></a> can detect hidden cliques of size Ω(√<em>n</em>), no polynomial-time algorithms are currently known to detect those of size <a href="Big_O_notation#Little-o_notation" title="wikilink">o</a>(√<em>n</em>).</p>
<h3 id="approximation-algorithms">Approximation algorithms</h3>

<p>Several authors have considered <a href="approximation_algorithm" title="wikilink">approximation algorithms</a> that attempt to find a clique or independent set that, although not maximum, has size as close to the maximum as can be found in polynomial time. Although much of this work has focused on independent sets in sparse graphs, a case that does not make sense for the complementary clique problem, there has also been work on approximation algorithms that do not use such sparsity assumptions.<a class="footnoteRef" href="#fn36" id="fnref36"><sup>36</sup></a>  describes a polynomial time algorithm that finds a clique of size Ω((log <em>n</em>/log log <em>n</em>)<sup>2</sup>) in any graph that has clique number Ω(<em>n</em>/log<sup><em>k</em></sup><em>n</em>) for any constant <em>k</em>. By combining this algorithm to find cliques in graphs with clique numbers between <em>n</em>/log <em>n</em> and <em>n</em>/log<sup>3</sup><em>n</em> with a different algorithm of  to find cliques in graphs with higher clique numbers, and choosing a two-vertex clique if both algorithms fail to find anything, <a href="Uriel_Feige" title="wikilink">Feige</a> provides an approximation algorithm that finds a clique with a number of vertices within a factor of O(<em>n</em>(log log <em>n</em>)<sup>2</sup>/log<sup>3</sup><em>n</em>) of the maximum. Although the <a href="approximation_ratio" title="wikilink">approximation ratio</a> of this algorithm is weak, it is the best known to date, and the results on <a href="hardness_of_approximation" title="wikilink">hardness of approximation</a> described below suggest that there can be no approximation algorithm with an approximation ratio significantly less than linear.</p>
<h2 id="lower-bounds">Lower bounds</h2>
<h3 id="np-completeness">NP-completeness</h3>

<p> The clique decision problem is <a class="uri" href="NP-complete" title="wikilink">NP-complete</a>. It was one of <a href="Karp's_21_NP-complete_problems" title="wikilink">Richard Karp's original 21 problems</a> shown NP-complete in his 1972 paper "Reducibility Among Combinatorial Problems". This problem was also mentioned in <a href="Stephen_Cook" title="wikilink">Stephen Cook</a>'s paper introducing the theory of NP-complete problems. Thus, the problem of finding a maximum clique is NP-hard: if one could solve it, one could also solve the decision problem, by comparing the size of the maximum clique to the size parameter given as input in the decision problem.</p>

<p>Karp's NP-completeness proof is a <a href="many-one_reduction" title="wikilink">many-one reduction</a> from the <a href="Boolean_satisfiability_problem" title="wikilink">Boolean satisfiability problem</a> for formulas in <a href="conjunctive_normal_form" title="wikilink">conjunctive normal form</a>, which was proved NP-complete in the <a href="Cook–Levin_theorem" title="wikilink">Cook–Levin theorem</a>.<a class="footnoteRef" href="#fn37" id="fnref37"><sup>37</sup></a> From a given CNF formula, Karp forms a graph that has a vertex for every pair (<em>v</em>,<em>c</em>), where <em>v</em> is a variable or its negation and <em>c</em> is a clause in the formula that contains <em>v</em>. Vertices are connected by an edge if they represent compatible variable assignments for different clauses: that is, there is an edge from (<em>v</em>,<em>c</em>) to (<em>u</em>,<em>d</em>) whenever <em>c</em> ≠ <em>d</em> and <em>u</em> and <em>v</em> are not each other's negations. If <em>k</em> denotes the number of clauses in the CNF formula, then the <em>k</em>-vertex cliques in this graph represent ways of assigning <a href="truth_values" title="wikilink">truth values</a> to some of its variables in order to satisfy the formula; therefore, the formula is satisfiable if and only if a <em>k</em>-vertex clique exists.</p>

<p>Some NP-complete problems (such as the <a href="travelling_salesman_problem" title="wikilink">travelling salesman problem</a> in <a href="planar_graph" title="wikilink">planar graphs</a>) may be solved in time that is exponential in a sublinear function of the input size parameter <em>n</em>.<a class="footnoteRef" href="#fn38" id="fnref38"><sup>38</sup></a> However, as  describe, it is unlikely that such bounds exist for the clique problem in arbitrary graphs, as they would imply similarly subexponential bounds for many other standard NP-complete problems.</p>
<h3 id="circuit-complexity">Circuit complexity</h3>

<p> The computational difficulty of the clique problem has led it to be used to prove several lower bounds in <a href="circuit_complexity" title="wikilink">circuit complexity</a>. Because the existence of a clique of a given size is a <a href="Hereditary_property" title="wikilink">monotone graph property</a> (if a clique exists in a given graph, it will exist in any supergraph) there must exist a monotone circuit, using only <a href="and_gate" title="wikilink">and gates</a> and <a href="or_gate" title="wikilink">or gates</a>, to solve the clique decision problem for a given fixed clique size. However, the size of these circuits can be proven to be a super-polynomial function of the number of vertices and the clique size, exponential in the cube root of the number of vertices.<a class="footnoteRef" href="#fn39" id="fnref39"><sup>39</sup></a> Even if a small number of <a href="NOT_gate" title="wikilink">NOT gates</a> are allowed, the complexity remains superpolynomial.<a class="footnoteRef" href="#fn40" id="fnref40"><sup>40</sup></a> Additionally, the depth of a monotone circuit for the clique problem using gates of bounded <a class="uri" href="fan-in" title="wikilink">fan-in</a> must be at least a polynomial in the clique size.<a class="footnoteRef" href="#fn41" id="fnref41"><sup>41</sup></a></p>
<h3 id="decision-tree-complexity">Decision tree complexity</h3>

<p> The (deterministic) <a href="decision_tree_complexity" title="wikilink">decision tree complexity</a> of determining a <a href="graph_property" title="wikilink">graph property</a> is the number of questions of the form "Is there an edge between vertex <em>u</em> and vertex <em>v</em>?" that have to be answered in the worst case to determine whether a graph has a particular property. That is, it is the minimum height of a boolean <a href="Decision_tree_model" title="wikilink">decision tree</a> for the problem. Since there are at most <em>n</em>(<em>n</em> − 1)/2 possible questions to be asked, any graph property can be determined with <em>n</em>(<em>n</em> − 1)/2 questions. It is also possible to define random and quantum decision tree complexity of a property, the expected number of questions (for a worst case input) that a randomized or quantum algorithm needs to have answered in order to correctly determine whether the given graph has the property.</p>

<p>Because the property of containing a clique is a monotone property (adding an edge can only cause more cliques to exist within the graph, not fewer), it is covered by the <a href="Aanderaa–Karp–Rosenberg_conjecture" title="wikilink">Aanderaa–Karp–Rosenberg conjecture</a>, which states that the deterministic decision tree complexity of determining any non-trivial monotone graph property is exactly <em>n</em>(<em>n</em> − 1)/2. For deterministic decision trees, the property of containing a <em>k</em>-clique (2 ≤ <em>k</em> ≤ <em>n</em>) was shown to have decision tree complexity exactly <em>n</em>(<em>n</em> − 1)/2 by . Deterministic decision trees also require exponential size to detect cliques, or large polynomial size to detect cliques of bounded size.<a class="footnoteRef" href="#fn42" id="fnref42"><sup>42</sup></a></p>

<p>The Aanderaa–Karp–Rosenberg conjecture also states that the randomized decision tree complexity of non-trivial monotone functions is Θ(n<sup>2</sup>). The conjecture is resolved for the property of containing a <em>k</em>-clique (2 ≤ <em>k</em> ≤ <em>n</em>), since it is known to have randomized decision tree complexity Θ(n<sup>2</sup>).<a class="footnoteRef" href="#fn43" id="fnref43"><sup>43</sup></a> For quantum decision trees, the best known lower bound is Ω(n), but no matching algorithm is known for the case of <em>k</em> ≥ 3.<a class="footnoteRef" href="#fn44" id="fnref44"><sup>44</sup></a></p>
<h3 id="fixed-parameter-intractability">Fixed-parameter intractability</h3>

<p><a href="Parameterized_complexity" title="wikilink">Parameterized complexity</a><a class="footnoteRef" href="#fn45" id="fnref45"><sup>45</sup></a> is the <a href="computational_complexity_theory" title="wikilink">complexity-theoretic</a> study of problems that are naturally equipped with a small integer parameter <em>k</em>, and for which the problem becomes more difficult as <em>k</em> increases, such as finding <em>k</em>-cliques in graphs. A problem is said to be fixed-parameter tractable if there is an algorithm for solving it on inputs of size <em>n</em> in time <em>f</em>(<em>k</em>) <em>n</em><sup>O(1)</sup>; that is, if it can be solved in polynomial time for any fixed value of <em>k</em> and moreover if the exponent of the polynomial does not depend on <em>k</em>.</p>

<p>For the clique problem, the brute force search algorithm has running time O(<em>n</em><sup><em>k</em></sup><em>k</em><sup>2</sup>), and although it can be improved by fast matrix multiplication the running time still has an exponent that is linear in <em>k</em>. Thus, although the running time of known algorithms for the clique problem is polynomial for any fixed <em>k</em>, these algorithms do not suffice for fixed-parameter tractability.  defined a hierarchy of parametrized problems, the W hierarchy, that they conjectured did not have fixed-parameter tractable algorithms; they proved that independent set (or, equivalently, clique) is hard for the first level of this hierarchy, <a href="W(1)" title="wikilink">W[1</a>]. Thus, according to their conjecture, clique is not fixed-parameter tractable. Moreover, this result provides the basis for proofs of <a href="W(1)" title="wikilink">W[1</a>]-hardness of many other problems, and thus serves as an analogue of the <a href="Cook–Levin_theorem" title="wikilink">Cook–Levin theorem</a> for parameterized complexity.</p>

<p>showed that the clique problem cannot be solved in time 

<math display="inline" id="Clique_problem:0">
 <semantics>
  <msup>
   <mi>n</mi>
   <mrow>
    <mi>o</mi>
    <mrow>
     <mo stretchy="false">(</mo>
     <mi>k</mi>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
  </msup>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">superscript</csymbol>
    <ci>n</ci>
    <apply>
     <times></times>
     <ci>o</ci>
     <ci>k</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   n^{o(k)}
  </annotation>
 </semantics>
</math>

 unless the <a href="exponential_time_hypothesis" title="wikilink">exponential time hypothesis</a> fails.</p>

<p>Although the problems of listing maximal cliques or finding maximum cliques are unlikely to be fixed-parameter tractable with the parameter <em>k</em>, they may be fixed-parameter tractable for other parameters of instance complexity. For instance, both problems are known to be fixed-parameter tractable when parametrized by the <a href="degeneracy_(graph_theory)" title="wikilink">degeneracy</a> of the input graph.<a class="footnoteRef" href="#fn46" id="fnref46"><sup>46</sup></a></p>
<h3 id="hardness-of-approximation">Hardness of approximation</h3>

<p> The computational complexity of approximating the clique problem has been studied for a long time; for instance,  observed that, because of the fact that the clique number takes on small integer values and is NP-hard to compute, it cannot have a <a href="Polynomial-time_approximation_scheme" title="wikilink">fully polynomial-time approximation scheme</a>. However, little more was known until the early 1990s, when several authors began to make connections between the approximation of maximum cliques and <a href="probabilistically_checkable_proof" title="wikilink">probabilistically checkable proofs</a>, and used these connections to prove <a href="hardness_of_approximation" title="wikilink">hardness of approximation</a> results for the maximum clique problem.<a class="footnoteRef" href="#fn47" id="fnref47"><sup>47</sup></a><a class="footnoteRef" href="#fn48" id="fnref48"><sup>48</sup></a> After many improvements to these results it is now known that, unless <a href="P_versus_NP_problem" title="wikilink">P = NP</a>, there can be no polynomial time algorithm that approximates the maximum clique to within a factor better than O(<em>n</em><sup>1 − ε</sup>), for any ε &gt; 0.<a class="footnoteRef" href="#fn49" id="fnref49"><sup>49</sup></a></p>

<p>The rough idea of these inapproximability results<a class="footnoteRef" href="#fn50" id="fnref50"><sup>50</sup></a> is to form a graph that represents a probabilistically checkable proof system for an NP-complete problem such as Satisfiability. A proof system of this type is defined by a family of proof strings (sequences of bits) and proof checkers: algorithms that, after a polynomial amount of computation over a given Satisfiability instance, examine a small number of randomly chosen bits of the proof string and on the basis of that examination either declare it to be a valid proof or declare it to be invalid. False negatives are not allowed: a valid proof must always be declared to be valid, but an invalid proof may be declared to be valid as long as the probability that a checker makes a mistake of this type is low. To transform a probabilistically checkable proof system into a clique problem, one forms a graph in which the vertices represent all the possible ways that a proof checker could read a sequence of proof string bits and end up accepting the proof. Two vertices are connected by an edge whenever the two proof checker runs that they describe agree on the values of the proof string bits that they both examine. The maximal cliques in this graph consist of the accepting proof checker runs for a single proof string, and one of these cliques is large if and only if there exists a proof string that many proof checkers accept. If the original Satisfiability instance is satisfiable, there will be a large clique defined by a valid proof string for that instance, but if the original instance is not satisfiable, then all proof strings are invalid, any proof string has only a small number of checkers that mistakenly accept it, and all cliques are small. Therefore, if one could distinguish in polynomial time between graphs that have large cliques and graphs in which all cliques are small, one could use this ability to distinguish the graphs generated from satisfiable and unsatisfiable instances of the Satisfiability problem, not possible unless P = NP. An accurate polynomial-time approximation to the clique problem would allow these two sets of graphs to be distinguished from each other, and is therefore also impossible. {{-}} </p>
<h2 id="notes">Notes</h2>
<h2 id="see-also">See also</h2>
<ul>
<li><a href="Intelligent_Water_Drops_algorithm" title="wikilink">Intelligent Water Drops algorithm</a></li>
</ul>
<h2 id="references">References</h2>
<ul>
<li>

<p>.</p></li>
<li>

<p>.</p></li>
<li>

<p>.</p></li>
<li>

<p>.</p></li>
<li>

<p>.</p></li>
<li>

<p>. Originally presented at the 1992 <a href="Symposium_on_Foundations_of_Computer_Science" title="wikilink">Symposium on Foundations of Computer Science</a>, .</p></li>
<li>

<p>. Originally presented at the 1992 <a href="Symposium_on_Foundations_of_Computer_Science" title="wikilink">Symposium on Foundations of Computer Science</a>, .</p></li>
<li>

<p>.</p></li>
<li>

<p>.</p></li>
<li>

<p>.</p></li>
<li>

<p>.</p></li>
<li>

<p>.</p></li>
<li>

<p>.</p></li>
<li>

<p>.</p></li>
<li>

<p>.</p></li>
<li></li>
<li>

<p>.</p></li>
<li>

<p>.</p></li>
<li>

<p>.</p></li>
<li></li>
<li>

<p>.</p></li>
<li>

<p>.</p></li>
<li>

<p>.</p></li>
<li>

<p>.</p></li>
<li>

<p>.</p></li>
<li>

<p>.</p></li>
<li>

<p>.</p></li>
<li>

<p>.</p></li>
<li>

<p>.</p></li>
<li>

<p>.</p></li>
<li>

<p>.</p></li>
<li>

<p>.</p></li>
<li>

<p>.</p></li>
<li>

<p>.</p></li>
<li>

<p>.</p></li>
<li>

<p>.</p></li>
<li></li>
<li>

<p>.</p></li>
<li>

<p>.</p></li>
<li>

<p>.</p></li>
<li>

<p>.</p></li>
<li>

<p>.</p></li>
<li><mtpl></mtpl>.</li>
<li>

<p>.</p></li>
<li>

<p>.</p></li>
<li>

<p>.</p></li>
<li><mtpl></mtpl>.</li>
<li>

<p>.</p></li>
<li>

<p>.</p></li>
<li>

<p>.</p></li>
<li>

<p>.</p></li>
<li>

<p>.</p></li>
<li>

<p>.</p></li>
<li>

<p>.</p></li>
<li>

<p>. <a href="http://www.sicmm.org/~konc/maxclique">Source code</a></p></li>
<li>

<p>.</p></li>
<li>

<p>.</p></li>
<li>

<p>.</p></li>
<li>

<p>.</p></li>
<li>

<p>.</p></li>
<li>

<p>.</p></li>
<li>

<p>.</p></li>
<li>

<p>.</p></li>
<li>

<p>.</p></li>
<li>

<p>.</p></li>
<li>

<p>.</p></li>
<li>

<p>.</p></li>
<li><mtpl></mtpl>.</li>
<li>

<p>.</p></li>
<li>

<p>.</p></li>
<li>

<p>.</p></li>
<li>

<p>.</p></li>
<li>

<p>.</p></li>
<li>

<p>.</p></li>
<li>

<p>.</p></li>
<li>

<p>.</p></li>
<li>

<p>.</p></li>
<li>

<p>.</p></li>
<li>

<p>.</p></li>
<li>

<p>.</p></li>
</ul>

<p><a href="fr:Clique_(théorie_des_graphes)#Problème_de_la_clique" title="wikilink">fr:Clique (théorie des graphes)#Problème de la clique</a>"</p>

<p><a href="Category:NP-complete_problems" title="wikilink">Category:NP-complete problems</a> <a href="Category:Computational_problems_in_graph_theory" title="wikilink">Category:Computational problems in graph theory</a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1"></li>
<li id="fn2">For more details and references, see <a href="clique_(graph_theory)" title="wikilink">clique (graph theory)</a>.<a href="#fnref2">↩</a></li>
<li id="fn3">For surveys of these algorithms, and basic definitions used in this article, see  and .<a href="#fnref3">↩</a></li>
<li id="fn4">Complete subgraphs make an early appearance in the mathematical literature in the graph-theoretic reformulation of <a href="Ramsey_theory" title="wikilink">Ramsey theory</a> by .<a href="#fnref4">↩</a></li>
<li id="fn5"></li>
<li id="fn6"></li>
<li id="fn7"></li>
<li id="fn8"></li>
<li id="fn9">.<a href="#fnref9">↩</a></li>
<li id="fn10">E.g., see .<a href="#fnref10">↩</a></li>
<li id="fn11"> provide an algorithm with O(<em>m</em><sup>3/2</sup>) running time that finds a triangle if one exists but does not list all triangles;  list all triangles in time O(<em>m</em><sup>3/2</sup>).<a href="#fnref11">↩</a></li>
<li id="fn12"></li>
<li id="fn13">; ; ; ; .<a href="#fnref13">↩</a></li>
<li id="fn14">.<a href="#fnref14">↩</a></li>
<li id="fn15">; .<a href="#fnref15">↩</a></li>
<li id="fn16">.<a href="#fnref16">↩</a></li>
<li id="fn17"></li>
<li id="fn18"></li>
<li id="fn19">; ; ; ; ; ; ; .<a href="#fnref19">↩</a></li>
<li id="fn20">; .<a href="#fnref20">↩</a></li>
<li id="fn21">; .<a href="#fnref21">↩</a></li>
<li id="fn22">.<a href="#fnref22">↩</a></li>
<li id="fn23">. Although the title refers to maximal cliques, the problem this paper solves is actually the maximum clique problem.<a href="#fnref23">↩</a></li>
<li id="fn24">.<a href="#fnref24">↩</a></li>
<li id="fn25">.<a href="#fnref25">↩</a></li>
<li id="fn26"><a href="ftp://dimacs.rutgers.edu/pub/challenge/graph/benchmarks/clique/">DIMACS challenge graphs for the clique problem</a>, accessed 2009-12-17.<a href="#fnref26">↩</a></li>
<li id="fn27"></li>
<li id="fn28">.<a href="#fnref28">↩</a></li>
<li id="fn29">.<a href="#fnref29">↩</a></li>
<li id="fn30">, p. 159.  provide an alternative quadratic-time algorithm for maximum cliques in <a href="comparability_graph" title="wikilink">comparability graphs</a>, a broader class of perfect graphs that includes the permutation graphs as a special case.<a href="#fnref30">↩</a></li>
<li id="fn31">; , p. 247.<a href="#fnref31">↩</a></li>
<li id="fn32">.<a href="#fnref32">↩</a></li>
<li id="fn33">.<a href="#fnref33">↩</a></li>
<li id="fn34">.<a href="#fnref34">↩</a></li>
<li id="fn35">.<a href="#fnref35">↩</a></li>
<li id="fn36">; ; .<a href="#fnref36">↩</a></li>
<li id="fn37"> gives essentially the same reduction, from <a class="uri" href="3-SAT" title="wikilink">3-SAT</a> instead of Satisfiability, to show that <a href="subgraph_isomorphism" title="wikilink">subgraph isomorphism</a> is NP-complete.<a href="#fnref37">↩</a></li>
<li id="fn38">.<a href="#fnref38">↩</a></li>
<li id="fn39">. For earlier and weaker bounds on monotone circuits for the clique problem, see  and .<a href="#fnref39">↩</a></li>
<li id="fn40">.<a href="#fnref40">↩</a></li>
<li id="fn41"> used <a href="communication_complexity" title="wikilink">communication complexity</a> to prove this result.<a href="#fnref41">↩</a></li>
<li id="fn42">.<a href="#fnref42">↩</a></li>
<li id="fn43">For instance, this follows from .<a href="#fnref43">↩</a></li>
<li id="fn44">; .<a href="#fnref44">↩</a></li>
<li id="fn45">.<a href="#fnref45">↩</a></li>
<li id="fn46">.<a href="#fnref46">↩</a></li>
<li id="fn47">.<a href="#fnref47">↩</a></li>
<li id="fn48">; ; .<a href="#fnref48">↩</a></li>
<li id="fn49"> showed inapproximability for this ratio using a stronger complexity theoretic assumption, the inequality of <a href="NP_(complexity)" title="wikilink">NP</a> and <a href="ZPP_(complexity)" title="wikilink">ZPP</a>;  described more precisely the inapproximation ratio, and  <a href="derandomization" title="wikilink">derandomized</a> the construction weakening its assumption to P ≠ NP.<a href="#fnref49">↩</a></li>
<li id="fn50">This reduction is originally due to  and used in all subsequent inapproximability proofs; the proofs differ in the strengths and details of the probabilistically checkable proof systems that they rely on.<a href="#fnref50">↩</a></li>
</ol>
</section>
</body>
</html>
