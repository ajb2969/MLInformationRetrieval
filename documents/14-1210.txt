   Q-Gaussian distribution      Q-Gaussian distribution   \right]  for    q  <  1      q  1    q<1   |  pdf        =       β    C  q     e  q    (   -   β   x  2     )           β    subscript  C  q     subscript  e  q       β   superscript  x  2       {\sqrt{\beta}\over C_{q}}e_{q}({-\beta x^{2}})    |  cdf        = |  mean       =      0  for  q   <  2        0  for  q   2    0\text{ for }q<2    , otherwise undefined|  median     =    0   0     |  mode       =    0   0     |  variance   =       1   β   (   5  -   3  q    )     for  q   <   5  3           1    β    5    3  q      for  q     5  3     {1\over{\beta(5-3q)}}\text{ for }q<{5\over 3}         ∞  for   5  3    ≤  q  <  2           for    5  3    q       2     \infty\text{ for }{5\over 3}\leq q<2         Undefined for  2   ≤  q  <  3          Undefined for  2   q       3     \text{Undefined for }2\leq q<3    |  skewness   =      0  for  q   <   3  2         0  for  q     3  2     0\text{ for }q<{3\over 2}    |  kurtosis   =      6    q  -  1    7  -   5  q     for  q   <   7  5         6      q  1     7    5  q     for  q     7  5     6{q-1\over 7-5q}\text{ for }q<{7\over 5}    |  entropy    =|  mgf        =|  cf         =|  }}  The q-Gaussian is a probability distribution arising from the maximization of the Tsallis entropy under appropriate constraints. It is one example of a Tsallis distribution . The q-Gaussian is a generalization of the Gaussian in the same way that Tsallis entropy is a generalization of standard Boltzmann–Gibbs entropy or Shannon entropy . 1 The normal distribution is recovered as    q  →  1     normal-→  q  1    q\rightarrow 1   .  The q-Gaussian has been applied to problems in the fields of statistical mechanics , geology , anatomy , astronomy , economics , finance , and machine learning . The distribution is often favored for its heavy tails in comparison to the Gaussian for    1  <  q  <  3        1  q       3     1   . There is generalized q-analog of the classical central limit theorem 2 in which the independence constraint for the i.i.d. variables is relaxed to an extent defined by the q parameter, with independence being recovered as q → 1. In analogy to the classical central limit theorem, an average of such random variables with fixed mean and variance tend towards the q-Gaussian distribution.  In the heavy tail regions, the distribution is equivalent to the Student's t-distribution with a direct mapping between q and the degrees of freedom . A practitioner using one of these distributions can therefore parameterize the same distribution in two different ways. The choice of the q-Gaussian form may arise if the system is non-extensive , or if there is lack of a connection to small samples sizes.  Characterization  Probability density function  The q-Gaussian has the probability density function 3       f   (  x  )    =     β    C  q     e  q    (   -   β   x  2     )          f  x         β    subscript  C  q     subscript  e  q       β   superscript  x  2        f(x)={\sqrt{\beta}\over C_{q}}e_{q}(-\beta x^{2})     where        e  q    (  x  )    =    [   1  +    (   1  -  q   )   x    ]    1   1  -  q            subscript  e  q   x    superscript   delimited-[]    1      1  q   x       1    1  q       e_{q}(x)=[1+(1-q)x]^{1\over 1-q}     is the q-exponential and the normalization factor    C  q     subscript  C  q    C_{q}   is given by       C  q   =      2   π   Γ   (   1   1  -  q    )      (   3  -  q   )     1  -  q    Γ   (    3  -  q    2   (   1  -  q   )     )     for   -  ∞   <  q  <  1         subscript  C  q           2    π   normal-Γ    1    1  q         3  q       1  q    normal-Γ      3  q     2    1  q       for          q       1     C_{q}={{2\sqrt{\pi}\Gamma\left({1\over 1-q}\right)}\over{(3-q)\sqrt{1-q}\Gamma%
 \left({3-q\over 2(1-q)}\right)}}\text{ for }-\infty          C  q   =    π   for  q   =   1          subscript  C  q       π   for  q        1     C_{q}=\sqrt{\pi}\text{ for }q=1\,          C  q   =      π   Γ   (    3  -  q    2   (   q  -  1   )     )       q  -  1    Γ   (   1   q  -  1    )     for  1   <  q  <  3.         subscript  C  q           π   normal-Γ      3  q     2    q  1            q  1    normal-Γ    1    q  1      for  1        q       3.     C_{q}={{\sqrt{\pi}\Gamma\left({3-q\over 2(q-1)}\right)}\over{\sqrt{q-1}\Gamma%
 \left({1\over q-1}\right)}}\text{ for }1     Entropy  Just as the normal distribution is the maximum information entropy distribution for fixed values of the first moment    E   (  X  )      normal-E  X    \operatorname{E}(X)   and second moment    E   (   X  2   )      normal-E   superscript  X  2     \operatorname{E}(X^{2})   (with the fixed zeroth moment     E   (   X  0   )    =  1       normal-E   superscript  X  0    1    \operatorname{E}(X^{0})=1   corresponding to the normalization condition), the q-Gaussian distribution is the maximum Tsallis entropy distribution for fixed values of these three moments.  Related distributions  Student's t-distribution  While it can be justified by an interesting alternative form of entropy, statistically it is a scaled reparametrization of the Student's t-distribution introduced by W. Gosset in 1908 to describe small-sample statistics. In Gosset's original presentation the degrees of freedom parameter   ν   ν   \nu   was constrained to be a positive integer related to the sample size, but it is readily observed that Gosset's density function is valid for all real values of   ν   ν   \nu   . The scaled reparametrization introduces the alternative parameters    q  and  β      q  and  β    q\text{ and }\beta   which are related to   ν   ν   \nu   .  Given a Student's t distribution with   ν   ν   \nu   degrees of freedom, the equivalent q-Gaussian has      q  =     ν  +  3    ν  +  1    with  β   =   1   3  -  q          q        ν  3     ν  1    with  β          1    3  q       q=\frac{\nu+3}{\nu+1}\text{ with }\beta=\frac{1}{3-q}     with inverse        ν  =    3  -  q    q  -  1     ,    but only if  β   =   1   3  -  q      .     formulae-sequence    ν      3  q     q  1         but only if  β     1    3  q       \nu=\frac{3-q}{q-1},\text{ but only if }\beta=\frac{1}{3-q}.     Whenever    β  ≠   1   3  -  q        β    1    3  q      \beta\neq{1\over{3-q}}   , the function is simply a scaled version of Student's t distribution.  It is sometimes argued that the distribution is a generalization of Student's t distribution to negative and or non-integer degrees of freedom. However, the theory of Student's t distribution extends trivially to all real degrees of freedom, where the support of the distribution is now compact rather than infinite in the case of    ν  <  0      ν  0    \nu<0   .  Three-parameter version  As with many distributions centered on zero, the q-gaussian can be trivially extended to include a location parameter   μ   μ   \mu   . The density then becomes defined by         β    C  q     e  q    (   -   β    (   x  -  μ   )   2     )    .          β    subscript  C  q     subscript  e  q       β   superscript    x  μ   2       {\sqrt{\beta}\over C_{q}}e_{q}({-\beta(x-\mu)^{2}}).     Generating random deviates  The Box–Muller transform has been generalized to allow random sampling from q-gaussians. 4 The standard Box–Muller technique generates pairs of independent normally distributed variables from equations of the following form.       Z  1   =     -   2   ln   (   U  1   )        cos   (   2  π   U  2    )          subscript  Z  1           2     subscript  U  1           2  π   subscript  U  2        Z_{1}=\sqrt{-2\ln(U_{1})}\cos(2\pi U_{2})          Z  2   =     -   2   ln   (   U  1   )        sin   (   2  π   U  2    )          subscript  Z  2           2     subscript  U  1           2  π   subscript  U  2        Z_{2}=\sqrt{-2\ln(U_{1})}\sin(2\pi U_{2})     The generalized Box–Muller technique can generates pairs of q-gaussian deviates that are not independent. In practice, only a single deviate will be generated from a pair of uniformly distributed variables. The following formula will generate deviates from a q-Gaussian with specified parameter q and    β  =   1   3  -  q        β    1    3  q      \beta={1\over{3-q}}         Z  =     -   2   ln   q  ′     (   U  1   )      cos   (   2  π   U  2    )        Z          2   subscript  ln   superscript  q  normal-′     subscript  U  1      cos    2  π   subscript  U  2       Z=\sqrt{-2\text{ ln}_{q^{\prime}}(U_{1})}\text{ cos}(2\pi U_{2})   Where    ln  q     subscript  ln  q    \text{ ln}_{q}   is the q-logarithm and     q  ′   =    1  +  q    3  -  q         superscript  q  normal-′       1  q     3  q      q^{\prime}={{1+q}\over{3-q}}     These deviates can be transformed to generate deviates from an arbitrary q-Gaussian by       Z  ′   =   μ  +   Z    β   (   3  -  q   )            superscript  Z  normal-′     μ    Z      β    3  q         Z^{\prime}=\mu+{Z\over\sqrt{\beta(3-q)}}     Applications  Physics  It has been shown that the momentum distribution of cold atoms in dissipative optical lattices is a q-Gaussian 5  Finance  Financial return distributions in the New York Stock Exchange, NASDAQ and elsewhere are often interpreted as q-Gaussians. 6 7  See also   Constantino Tsallis  Tsallis statistics  Tsallis entropy  Tsallis distribution  q-exponential distribution   Notes  Further reading   Juniper, J. (2007) "The Tsallis Distribution and Generalised Entropy: Prospects for Future Research into Decision-Making under Uncertainty" , Centre of Full Employment and Equity, The University of Newcastle, Australia   External links   Tsallis Statistics, Statistical Mechanics for Non-extensive Systems and Long-Range Interactions   "  Category:Statistical mechanics  Category:Continuous distributions  Category:Probability distributions with non-finite variance  Category:Probability distributions     Tsallis, C. Nonadditive entropy and nonextensive statistical mechanics-an overview after 20 years. Braz. J. Phys. 2009, 39, 337–356 ↩  ↩   W. Thistleton, J.A. Marsh, K. Nelson and C. Tsallis, Generalized Box–Muller method for generating q-Gaussian random deviates, IEEE Transactions on Information Theory 53, 4805 (2007) ↩  ↩  L.Borland, Option pricing formulas based on a non-Gaussian stock price model, Phys. Rev. Lett. 89, 098701 (2002) ↩  L. Borland, The pricing of stock options, in Nonextensive Entropy -Interdisciplinary Applications, eds. M. Gell-Mann and C. Tsallis (Oxford University Press, New York, 2004) ↩     