


Social cognitive optimization




Social cognitive optimization

Social cognitive optimization (SCO) is a population-based metaheuristic optimization algorithm which was developed in 2002.1 This algorithm is based on the social cognitive theory, and the key point of the ergodicity is the process of individual learning of a set of agents with their own memory and their social learning with the knowledge points in the social sharing library. It has been used for solving continuous optimization,23 integer programming,4 and combinatorial optimization problems. It has been incorporated into the NLPSolver extension of Calc in Apache OpenOffice.
Algorithm
Let 
 
 
 
  be a global optimization problem, where 
 
 
 
  is a state in the problem space 
 
 
 
 . In SCO, each state is called a knowledge point, and the function 
 
 
 
  is the goodness function.
In SCO, there are a population of 
 
 
 
  cognitive agents solving in parallel, with a social sharing library. Each agent holds a private memory containing one knowledge point, and the social sharing library contains a set of 
 
 
 
  knowledge points. The algorithm runs in T iterative learning cycles. By running as a Markov chain process, the system behavior in the tth cycle only depends on the system status in the (t − 1)th cycle. The process flow is in follows:

[1. Initialization]：Initialize the private knowledge point 
 
 
 
  in the memory of each agent 
 
 
 
 , and all knowledge points in the social sharing library 
 
 
 
 , normally at random in the problem space 
 
 
 
 .
[2. Learning cycle]： At each cycle 
 
 

 
 ：
 
[2.1. Observational learning] For each agent 
 
 

 
 ：
 
[2.1.1. Model selection]：Find a high-quality model point

 
  in 
 
 
 
  , normally realized using tournament selection, which returns the best knowledge point from randomly selected 
 
 
 
  points.
[2.1.2. Quality Evaluation]：Compare the private knowledge point 
 
 
 
  and the model point 
 
 
 
 ，and return the one with higher quality as the base point

 
 ，and another as the reference point

 
 。
[2.1.3. Learning]：Combine 
 
 
 
  and 
 
 
 
  to generate a new knowledge point 
 
 
 
 . Normally 
 
 
 
  should be around 
 
 
 
 ，and the distance with 
 
 
 
  is related to the distance between 
 
 
 
  and 
 
 
 
 , and boundary handling mechanism should be incorporated here to ensure that 
 
 
 
 .
[2.1.4. Knowledge sharing]：Share a knowledge point, normally 
 
 
 
 , to the social sharing library 
 
 
 
 .
[2.1.5. Individual update]：Update the private knowledge of agent 
 
 
 
 , normally replace 
 
 
 
  by 
 
 
 
 . Some Monte Carlo types might also be considered.

[2.2. Library Maintenance]：The social sharing library using all knowledge points submitted by agents to update 
 
 
 
  into 
 
 
 
 . A simple way is one by one tournament selection: for each knowledge point submitted by an agent, replace the worse one among 
 
 
 
  points randomly selected from 
 
 
 
 .

[3. Termination]：Return the best knowledge point found by the agents.

SCO has three main parameters, i.e., the number of agents 
 
 
 
 , the size of social sharing library 
 
 
 
 , and the learning cycle 
 
 
 
 . With the initialization process, the total number of knowledge points to be generated is 
 
 
 
 , and is not related too much with 
 
 
 
  if 
 
 
 
  is large.
Compared to traditional swarm algorithms, e.g. particle swarm optimization, SCO can achieving high-quality solutions as 
 
 
 
  is small, even as 
 
 
 
 . Nevertheless, smaller 
 
 
 
  and 
 
 
 
  might lead to premature convergence. Some variants 5 were proposed to guaranteed the global convergence.
References
"
Category:Heuristic algorithms Category:Optimization_algorithms_and_methods Category:Metaheuristics Category:Collective intelligence












