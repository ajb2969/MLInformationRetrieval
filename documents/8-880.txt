   Expander walk sampling      Expander walk sampling   In the mathematical discipline of graph theory , the expander walk sampling theorem states that sampling  vertices in an expander graph by doing a random walk is almost as good as sampling the vertices independently from a uniform distribution . The earliest version of this theorem is due to , and the more general version is typically attributed to .  Statement  Let    G  =   (  V  ,  E  )       G   V  E     G=(V,E)   be an expander graph with normalized second-largest eigenvalue    λ   λ   \lambda   . Let   n   n   n   denote the number of vertices in   G   G   G   . Let    f  :   V  →   [  0  ,  1  ]       normal-:  f   normal-→  V   0  1      f:V\rightarrow[0,1]   be a function on the vertices of   G   G   G   . Let    μ  =   E   [  f  ]        μ    E   delimited-[]  f      \mu=E[f]   denote the mean of   f   f   f   , i.e.    μ  =    1  n     ∑   v  ∈  V     f   (  v  )          μ      1  n     subscript     v  V      f  v       \mu=\frac{1}{n}\sum_{v\in V}f(v)   . Then, if we let     Y  0   ,   Y  1   ,  …  ,   Y  k       subscript  Y  0    subscript  Y  1   normal-…   subscript  Y  k     Y_{0},Y_{1},\ldots,Y_{k}   denote the vertices encountered in a   k   k   k   -step random walk on   G   G   G   starting at a random vertex    Y  0     subscript  Y  0    Y_{0}   , we have the following for all    γ  >  0      γ  0    \gamma>0   :        Pr   [      1  k     ∑   i  =  0   k    f   (   Y  i   )      -  μ   >  γ   ]    ≤   e   -   Ω   (    γ  2    (   1  -  λ   )   k   )       .       Pr          1  k     superscript   subscript     i  0    k     f   subscript  Y  i      μ   γ     superscript  e      normal-Ω     superscript  γ  2     1  λ   k        \Pr\left[\frac{1}{k}\sum_{i=0}^{k}f(Y_{i})-\mu>\gamma\right]\leq e^{-\Omega(%
 \gamma^{2}(1-\lambda)k)}.     Here the   Ω   normal-Ω   \Omega   hides an absolute constant     ≥   1  /  10       absent    1  10     \geq 1/10   . An identical bound holds in the other direction:        Pr   [      1  k     ∑   i  =  0   k    f   (   Y  i   )      -  μ   <   -  γ    ]    ≤   e   -   Ω   (    γ  2    (   1  -  λ   )   k   )       .       Pr          1  k     superscript   subscript     i  0    k     f   subscript  Y  i      μ     γ      superscript  e      normal-Ω     superscript  γ  2     1  λ   k        \Pr\left[\frac{1}{k}\sum_{i=0}^{k}f(Y_{i})-\mu<-\gamma\right]\leq e^{-\Omega(%
 \gamma^{2}(1-\lambda)k)}.     Uses  This theorem is useful in randomness reduction in the study of derandomization . Sampling from an expander walk is an example of a randomness-efficient sampler . Note that the number of bits used in sampling   k   k   k   independent samples from   f   f   f   is    k   log  n       k    n     k\log n   , whereas if we sample from an infinite family of constant-degree expanders this costs only     log  n   +   O   (  k  )          n     O  k     \log n+O(k)   . Such families exist and are efficiently constructible, e.g. the Ramanujan graphs of Lubotzky -Phillips-Sarnak.  Notes  References      External links   Proofs of the expander walk sampling theorem. 1  2   "  Category:Sampling (statistics)   