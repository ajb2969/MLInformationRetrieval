   Copula (probability theory)      Copula (probability theory)   In probability theory and statistics , a copula is a multivariate probability distribution for which the marginal probability distribution of each variable is uniform . Copulas are used to describe the dependence between random variables . They are named for their resemblance to grammatical copulas in linguistics .  Sklar's Theorem states that any multivariate joint distribution can be written in terms of univariate marginal distribution functions and a copula which describes the dependence structure between the variables.  Copulas are popular in high-dimensional statistical applications as they allow one to easily model and estimate the distribution of random vectors by estimating marginals and copulae separately. There are many parametric copula families available, which usually have parameters that control the strength of dependence. Some popular parametric copula models are outlined below.  Mathematical definition  Consider a random vector    (   X  1   ,   X  2   ,  ‚Ä¶  ,   X  d   )      subscript  X  1    subscript  X  2   normal-‚Ä¶   subscript  X  d     (X_{1},X_{2},\dots,X_{d})   . Suppose its margins are continuous, i.e. the marginal CDFs      F  i    (  x  )   =  ‚Ñô   [   X  i   ‚â§  x  ]      fragments   subscript  F  i    fragments  normal-(  x  normal-)    P   fragments  normal-[   subscript  X  i    x  normal-]     F_{i}(x)=\mathbb{P}[X_{i}\leq x]   are continuous functions. By applying the probability integral transform to each component, the random vector       (   U  1   ,   U  2   ,  ‚Ä¶  ,   U  d   )   =   (    F  1    (   X  1   )    ,    F  2    (   X  2   )    ,  ‚Ä¶  ,    F  d    (   X  d   )    )         subscript  U  1    subscript  U  2   normal-‚Ä¶   subscript  U  d        subscript  F  1    subscript  X  1       subscript  F  2    subscript  X  2    normal-‚Ä¶     subscript  F  d    subscript  X  d       (U_{1},U_{2},\dots,U_{d})=\left(F_{1}(X_{1}),F_{2}(X_{2}),\dots,F_{d}(X_{d})\right)   has uniformly distributed marginals.  The copula of    (   X  1   ,   X  2   ,  ‚Ä¶  ,   X  d   )      subscript  X  1    subscript  X  2   normal-‚Ä¶   subscript  X  d     (X_{1},X_{2},\dots,X_{d})   is defined as the joint cumulative distribution function of    (   U  1   ,   U  2   ,  ‚Ä¶  ,   U  d   )      subscript  U  1    subscript  U  2   normal-‚Ä¶   subscript  U  d     (U_{1},U_{2},\dots,U_{d})   :      C   (   u  1   ,   u  2   ,  ‚Ä¶  ,   u  d   )   =  ‚Ñô   [   U  1   ‚â§   u  1   ,   U  2   ‚â§   u  2   ,  ‚Ä¶  ,   U  d   ‚â§   u  d   ]   .     fragments  C   fragments  normal-(   subscript  u  1   normal-,   subscript  u  2   normal-,  normal-‚Ä¶  normal-,   subscript  u  d   normal-)    P   fragments  normal-[   subscript  U  1     subscript  u  1   normal-,   subscript  U  2     subscript  u  2   normal-,  normal-‚Ä¶  normal-,   subscript  U  d     subscript  u  d   normal-]   normal-.    C(u_{1},u_{2},\dots,u_{d})=\mathbb{P}[U_{1}\leq u_{1},U_{2}\leq u_{2},\dots,U_%
 {d}\leq u_{d}].     The copula C contains all information on the dependence structure between the components of    (   X  1   ,   X  2   ,  ‚Ä¶  ,   X  d   )      subscript  X  1    subscript  X  2   normal-‚Ä¶   subscript  X  d     (X_{1},X_{2},\dots,X_{d})   whereas the marginal cumulative distribution functions    F  i     subscript  F  i    F_{i}   contain all information on the marginal distributions.  The importance of the above is that the reverse of these steps can be used to generate pseudo-random samples from general classes of multivariate probability distributions . That is, given a procedure to generate a sample    (   U  1   ,   U  2   ,  ‚Ä¶  ,   U  d   )      subscript  U  1    subscript  U  2   normal-‚Ä¶   subscript  U  d     (U_{1},U_{2},\dots,U_{d})   from the copula distribution, the required sample can be constructed as        (   X  1   ,   X  2   ,  ‚Ä¶  ,   X  d   )   =   (    F  1   -  1     (   U  1   )    ,    F  2   -  1     (   U  2   )    ,  ‚Ä¶  ,    F  d   -  1     (   U  d   )    )    .        subscript  X  1    subscript  X  2   normal-‚Ä¶   subscript  X  d        superscript   subscript  F  1     1     subscript  U  1       superscript   subscript  F  2     1     subscript  U  2    normal-‚Ä¶     superscript   subscript  F  d     1     subscript  U  d       (X_{1},X_{2},\dots,X_{d})=\left(F_{1}^{-1}(U_{1}),F_{2}^{-1}(U_{2}),\dots,F_{d%
 }^{-1}(U_{d})\right).   The inverses    F  i   -  1      superscript   subscript  F  i     1     F_{i}^{-1}   are unproblematic as the    F  i     subscript  F  i    F_{i}   were assumed to be continuous. The above formula for the copula function can be rewritten to correspond to this as:      C   (   u  1   ,   u  2   ,  ‚Ä¶  ,   u  d   )   =  ‚Ñô   [   X  1   ‚â§   F  1   -  1     (   u  1   )   ,   X  2   ‚â§   F  2   -  1     (   u  2   )   ,  ‚Ä¶  ,   X  d   ‚â§   F  d   -  1     (   u  d   )   ]   .     fragments  C   fragments  normal-(   subscript  u  1   normal-,   subscript  u  2   normal-,  normal-‚Ä¶  normal-,   subscript  u  d   normal-)    P   fragments  normal-[   subscript  X  1     superscript   subscript  F  1     1     fragments  normal-(   subscript  u  1   normal-)   normal-,   subscript  X  2     superscript   subscript  F  2     1     fragments  normal-(   subscript  u  2   normal-)   normal-,  normal-‚Ä¶  normal-,   subscript  X  d     superscript   subscript  F  d     1     fragments  normal-(   subscript  u  d   normal-)   normal-]   normal-.    C(u_{1},u_{2},\dots,u_{d})=\mathbb{P}[X_{1}\leq F_{1}^{-1}(u_{1}),X_{2}\leq F_%
 {2}^{-1}(u_{2}),\dots,X_{d}\leq F_{d}^{-1}(u_{d})].     Definition  In probabilistic terms,    C  :     [  0  ,  1  ]   d   ‚Üí   [  0  ,  1  ]       normal-:  C   normal-‚Üí   superscript   0  1   d    0  1      C:[0,1]^{d}\rightarrow[0,1]   is a d -dimensional copula if C is a joint cumulative distribution function of a d -dimensional random vector on the unit cube      [  0  ,  1  ]   d     superscript   0  1   d    [0,1]^{d}   with uniform  marginals . 1  In analytic terms,    C  :     [  0  ,  1  ]   d   ‚Üí   [  0  ,  1  ]       normal-:  C   normal-‚Üí   superscript   0  1   d    0  1      C:[0,1]^{d}\rightarrow[0,1]   is a d -dimensional copula if  :*     C   (   u  1   ,  ‚Ä¶  ,   u   i  -  1    ,  0  ,   u   i  +  1    ,  ‚Ä¶  ,   u  d   )    =  0        C    subscript  u  1   normal-‚Ä¶   subscript  u    i  1    0   subscript  u    i  1    normal-‚Ä¶   subscript  u  d     0    C(u_{1},\dots,u_{i-1},0,u_{i+1},\dots,u_{d})=0   , the copula is zero if one of the arguments is zero,  :*     C   (  1  ,  ‚Ä¶  ,  1  ,  u  ,  1  ,  ‚Ä¶  ,  1  )    =  u        C   1  normal-‚Ä¶  1  u  1  normal-‚Ä¶  1    u    C(1,\dots,1,u,1,\dots,1)=u   , the copula is equal to u if one argument is u and all others 1,  :* C is d -increasing, i.e., for each hyperrectangle     B  =    ‚àè   i  =  1   d    [   x  i   ,   y  i   ]    ‚äÜ    [  0  ,  1  ]   d         B    superscript   subscript  product    i  1    d     subscript  x  i    subscript  y  i           superscript   0  1   d      B=\prod_{i=1}^{d}[x_{i},y_{i}]\subseteq[0,1]^{d}   the C -volume of B is non-negative:  :*       ‚à´  B    d  C   (  u  )     =    ‚àë   ùê≥  ‚àà     √ó   i  =  1   d    {   x  i   ,   y  i   }         (   -  1   )    N   (  ùê≥  )     C   (  ùê≥  )     ‚â•  0   ,          subscript   B     d  C  u      subscript    ùê≥     superscript   subscript     i  1    d   absent    subscript  x  i    subscript  y  i          superscript    1     N  ùê≥    C  ùê≥         0     \int_{B}dC(u)=\sum_{\mathbf{z}\in\times_{i=1}^{d}\{x_{i},y_{i}\}}(-1)^{N(%
 \mathbf{z})}C(\mathbf{z})\geq 0,       where the     N   (  ùê≥  )    =   #   {  k  :    z  k   =   x  k    }          N  ùê≥     normal-#   conditional-set  k     subscript  z  k    subscript  x  k        N(\mathbf{z})=\#\{k:z_{k}=x_{k}\}   .     For instance, in the bivariate case,    C  :     [  0  ,  1  ]   √ó   [  0  ,  1  ]    ‚Üí   [  0  ,  1  ]       normal-:  C   normal-‚Üí     0  1    0  1     0  1      C:[0,1]\times[0,1]\rightarrow[0,1]   is a bivariate copula if     C   (  0  ,  u  )    =   C   (  u  ,  0  )    =  0          C   0  u      C   u  0         0     C(0,u)=C(u,0)=0   ,     C   (  1  ,  u  )    =   C   (  u  ,  1  )    =  u          C   1  u      C   u  1         u     C(1,u)=C(u,1)=u   and       C   (   u  2   ,   v  2   )    -   C   (   u  2   ,   v  1   )    -   C   (   u  1   ,   v  2   )     +   C   (   u  1   ,   v  1   )     ‚â•  0            C    subscript  u  2    subscript  v  2       C    subscript  u  2    subscript  v  1       C    subscript  u  1    subscript  v  2        C    subscript  u  1    subscript  v  1      0    C(u_{2},v_{2})-C(u_{2},v_{1})-C(u_{1},v_{2})+C(u_{1},v_{1})\geq 0   for all    0  ‚â§   u  1   ‚â§   u  2   ‚â§  1        0   subscript  u  1         subscript  u  2        1     0\leq u_{1}\leq u_{2}\leq 1   and    0  ‚â§   v  1   ‚â§   v  2   ‚â§  1        0   subscript  v  1         subscript  v  2        1     0\leq v_{1}\leq v_{2}\leq 1   .  Sklar's theorem    Sklar's theorem, 2 named after Abe Sklar , provides the theoretical foundation for the application of copulas. Sklar's theorem states that every multivariate cumulative distribution function      H   (   x  1   ,  ‚Ä¶  ,   x  d   )   =  ‚Ñô   [   X  1   ‚â§   x  1   ,  ‚Ä¶  ,   X  d   ‚â§   x  d   ]      fragments  H   fragments  normal-(   subscript  x  1   normal-,  normal-‚Ä¶  normal-,   subscript  x  d   normal-)    P   fragments  normal-[   subscript  X  1     subscript  x  1   normal-,  normal-‚Ä¶  normal-,   subscript  X  d     subscript  x  d   normal-]     H(x_{1},\dots,x_{d})=\mathbb{P}[X_{1}\leq x_{1},\dots,X_{d}\leq x_{d}]   of a random vector    (   X  1   ,   X  2   ,  ‚Ä¶  ,   X  d   )      subscript  X  1    subscript  X  2   normal-‚Ä¶   subscript  X  d     (X_{1},X_{2},\dots,X_{d})   can be expressed by involving only the marginals     F  i    (  x  )   =  ‚Ñô   [   X  i   ‚â§  x  ]      fragments   subscript  F  i    fragments  normal-(  x  normal-)    P   fragments  normal-[   subscript  X  i    x  normal-]     F_{i}(x)=\mathbb{P}[X_{i}\leq x]   as        H   (   x  1   ,  ‚Ä¶  ,   x  d   )    =   C   (    F  1    (   x  1   )    ,  ‚Ä¶  ,    F  d    (   x  d   )    )     ,        H    subscript  x  1   normal-‚Ä¶   subscript  x  d       C      subscript  F  1    subscript  x  1    normal-‚Ä¶     subscript  F  d    subscript  x  d        H(x_{1},\dots,x_{d})=C\left(F_{1}(x_{1}),\dots,F_{d}(x_{d})\right),   where   C   C   C   is a copula.  The theorem also states that, given   H   H   H   , the copula is unique on     Ran   (   F  1   )    √ó  ‚ãØ  √ó   Ran   (   F  d   )         Ran   subscript  F  1    normal-‚ãØ   Ran   subscript  F  d      \operatorname{Ran}(F_{1})\times\cdots\times\operatorname{Ran}(F_{d})   , which is the cartesian product of the ranges of the marginal cdf's. This implies that the copula is unique if the marginals    F  i     subscript  F  i    F_{i}   are continuous.  The converse is also true: given a copula    C  :     [  0  ,  1  ]   d   ‚Üí   [  0  ,  1  ]       normal-:  C   normal-‚Üí   superscript   0  1   d    0  1      C:[0,1]^{d}\rightarrow[0,1]   and margins     F  i    (  x  )        subscript  F  i   x    F_{i}(x)   then    C   (    F  1    (   x  1   )    ,  ‚Ä¶  ,    F  d    (   x  d   )    )       C      subscript  F  1    subscript  x  1    normal-‚Ä¶     subscript  F  d    subscript  x  d       C\left(F_{1}(x_{1}),\dots,F_{d}(x_{d})\right)   defines a d -dimensional cumulative distribution function.  Fr√©chet‚ÄìHoeffding copula bounds  (Figure)  Graphs of the bivariate Fr√©chet‚ÄìHoeffding copula limits and of the independence copula (in the middle).   The Fr√©chet‚ÄìHoeffding Theorem (after Maurice Ren√© Fr√©chet and Wassily Hoeffding  3 ) states that for any Copula    C  :     [  0  ,  1  ]   d   ‚Üí   [  0  ,  1  ]       normal-:  C   normal-‚Üí   superscript   0  1   d    0  1      C:[0,1]^{d}\rightarrow[0,1]   and any     (   u  1   ,  ‚Ä¶  ,   u  d   )   ‚àà    [  0  ,  1  ]   d         subscript  u  1   normal-‚Ä¶   subscript  u  d     superscript   0  1   d     (u_{1},\dots,u_{d})\in[0,1]^{d}   the following bounds hold:        W   (   u  1   ,  ‚Ä¶  ,   u  d   )    ‚â§   C   (   u  1   ,  ‚Ä¶  ,   u  d   )    ‚â§   M   (   u  1   ,  ‚Ä¶  ,   u  d   )     .          W    subscript  u  1   normal-‚Ä¶   subscript  u  d       C    subscript  u  1   normal-‚Ä¶   subscript  u  d            M    subscript  u  1   normal-‚Ä¶   subscript  u  d        W(u_{1},\dots,u_{d})\leq C(u_{1},\dots,u_{d})\leq M(u_{1},\dots,u_{d}).   The function W is called lower Fr√©chet‚ÄìHoeffding bound and is defined as        W   (   u  1   ,  ‚Ä¶  ,   u  d   )    =   max   {    1  -  d   +    ‚àë   i  =  1   d    u  i     ,  0  }     .        W    subscript  u  1   normal-‚Ä¶   subscript  u  d           1  d     superscript   subscript     i  1    d    subscript  u  i     0     W(u_{1},\ldots,u_{d})=\max\left\{1-d+\sum\limits_{i=1}^{d}{u_{i}},0\right\}.   The function M is called upper Fr√©chet‚ÄìHoeffding bound and is defined as        M   (   u  1   ,  ‚Ä¶  ,   u  d   )    =   min   {   u  1   ,  ‚Ä¶  ,   u  d   }     .        M    subscript  u  1   normal-‚Ä¶   subscript  u  d        subscript  u  1   normal-‚Ä¶   subscript  u  d      M(u_{1},\ldots,u_{d})=\min\{u_{1},\dots,u_{d}\}.     The upper bound is sharp: M is always a copula, it corresponds to comonotone random variables .  The lower bound is point-wise sharp, in the sense that for fixed u , there is a copula    C  ~     normal-~  C    \tilde{C}   such that      C  ~    (  u  )    =   W   (  u  )           normal-~  C   u     W  u     \tilde{C}(u)=W(u)   . However, W is a copula only in two dimensions, in which case it corresponds to countermonotonic random variables.  In two dimensions, i.e. the bivariate case, the Fr√©chet‚ÄìHoeffding Theorem states       max   (    u  +  v   -  1   ,  0  )    ‚â§   C   (  u  ,  v  )    ‚â§   min   {  u  ,  v  }                u  v   1   0     C   u  v           u  v      \max(u+v-1,0)\leq C(u,v)\leq\min\{u,v\}     Families of copulas  Several families of copulae have been described.  Gaussian copula  (Figure)  Cumulative and density distribution of Gaussian copula with œÅ =¬†0.4   The Gaussian copula is a distribution over the unit cube     [  0  ,  1  ]   d     superscript   0  1   d    [0,1]^{d}   . It is constructed from a multivariate normal distribution over    ‚Ñù  d     superscript  ‚Ñù  d    \mathbb{R}^{d}   by using the probability integral transform .  For a given correlation matrix     R  ‚àà   ‚Ñù   d  √ó  d        R   superscript  ‚Ñù    d  d      R\in\mathbb{R}^{d\times d}   , the Gaussian copula with parameter matrix   R   R   R   can be written as         C  R  Gauss    (  u  )    =    Œ¶  R    (    Œ¶   -  1     (   u  1   )    ,  ‚Ä¶  ,    Œ¶   -  1     (   u  d   )    )     ,         superscript   subscript  C  R   Gauss   u      subscript  normal-Œ¶  R       superscript  normal-Œ¶    1     subscript  u  1    normal-‚Ä¶     superscript  normal-Œ¶    1     subscript  u  d        C_{R}^{\text{Gauss}}(u)=\Phi_{R}\left(\Phi^{-1}(u_{1}),\dots,\Phi^{-1}(u_{d})%
 \right),   where    Œ¶   -  1      superscript  normal-Œ¶    1     \Phi^{-1}   is the inverse cumulative distribution function of a standard normal and    Œ¶  R     subscript  normal-Œ¶  R    \Phi_{R}   is the joint cumulative distribution function of a multivariate normal distribution with mean vector zero and covariance matrix equal to the correlation matrix   R   R   R   .  The density can be written as 4         c  R  Gauss    (  u  )    =    1    det  R      exp   (   -     1  2     (       Œ¶   -  1     (   u  1   )        ‚ãÆ        Œ¶   -  1     (   u  d   )       )   T    ‚ãÖ   (    R   -  1    -  ùêà   )   ‚ãÖ   (       Œ¶   -  1     (   u  1   )        ‚ãÆ        Œ¶   -  1     (   u  d   )       )     )      ,         superscript   subscript  c  R   Gauss   u       1      R          normal-‚ãÖ      1  2    superscript       superscript  normal-Œ¶    1     subscript  u  1      normal-‚ãÆ       superscript  normal-Œ¶    1     subscript  u  d      T       superscript  R    1    ùêà        superscript  normal-Œ¶    1     subscript  u  1      normal-‚ãÆ       superscript  normal-Œ¶    1     subscript  u  d            c_{R}^{\text{Gauss}}(u)=\frac{1}{\sqrt{\det{R}}}\exp\left(-\frac{1}{2}\begin{%
 pmatrix}\Phi^{-1}(u_{1})\\
 \vdots\\
 \Phi^{-1}(u_{d})\end{pmatrix}^{T}\cdot\left(R^{-1}-\mathbf{I}\right)\cdot%
 \begin{pmatrix}\Phi^{-1}(u_{1})\\
 \vdots\\
 \Phi^{-1}(u_{d})\end{pmatrix}\right),   where   ùêà   ùêà   \mathbf{I}   is the identity matrix.  Archimedean copulas  Archimedean copulas are an associative class of copulas. Most common Archimedean copulas admit an explicit formula, something not possible for instance for the Gaussian copula. In practice, Archimedean copulas are popular because they allow modeling dependence in arbitrarily high dimensions with only one parameter, governing the strength of dependence.  A copula C is called Archimedean if it admits the representation 5       C   (   u  1   ,  ‚Ä¶  ,   u  d   ;  Œ∏  )    =    œà   [   -  1   ]     (    œà   (   u  1   ;  Œ∏  )    +  ‚ãØ  +   œà   (   u  d   ;  Œ∏  )     ;  Œ∏  )          C    subscript  u  1   normal-‚Ä¶   subscript  u  d   Œ∏       superscript  œà   delimited-[]    1          œà    subscript  u  1   Œ∏    normal-‚ãØ    œà    subscript  u  d   Œ∏     Œ∏      C(u_{1},\dots,u_{d};\theta)=\psi^{[-1]}\left(\psi(u_{1};\theta)+\cdots+\psi(u_%
 {d};\theta);\theta\right)\,     where     œà   :     [  0  ,  1  ]   √ó  Œò   ‚Üí   [  0  ,  ‚àû  )       normal-:  œà   normal-‚Üí     0  1   normal-Œò    0       \psi\!:[0,1]\times\Theta\rightarrow[0,\infty)   is a continuous, strictly decreasing and convex function such that     œà   (  1  ;  Œ∏  )    =  0        œà   1  Œ∏    0    \psi(1;\theta)=0   .   Œ∏   Œ∏   \theta   is a parameter within some parameter space   Œò   normal-Œò   \Theta   .   œà   œà   \psi   is the so-called generator function and    œà   [   -  1   ]      superscript  œà   delimited-[]    1      \psi^{[-1]}   is its pseudo-inverse defined by        œà   [   -  1   ]     (  t  ;  Œ∏  )    =   {        œà   -  1     (  t  ;  Œ∏  )        if  0   ‚â§  t  ‚â§   œà   (  0  ;  Œ∏  )         0       if  œà   (  0  ;  Œ∏  )    ‚â§  t  ‚â§  ‚àû   .                superscript  œà   delimited-[]    1      t  Œ∏     cases       superscript  œà    1     t  Œ∏          if  0   t         œà   0  Œ∏        0        if  œà   0  Œ∏    t               \psi^{[-1]}(t;\theta)=\left\{\begin{array}[]{ll}\psi^{-1}(t;\theta)&\mbox{if }%
 0\leq t\leq\psi(0;\theta)\\
 0&\mbox{if }\psi(0;\theta)\leq t\leq\infty.\end{array}\right.\,     Moreover, the above formula for C yields a copula for     œà   -  1       superscript  œà    1     \psi^{-1}\,   if and only if     œà   -  1       superscript  œà    1     \psi^{-1}\,   is d-monotone on    [  0  ,  ‚àû  )     0     [0,\infty)   . 6 That is, if it is    d  -  2      d  2    d-2   times differentiable and the derivatives satisfy         (   -  1   )   k    œà    -  1   ,   (  k  )      (  t  ;  Œ∏  )    ‚â•   0          superscript    1   k    superscript  œà     1   k     t  Œ∏    0    (-1)^{k}\psi^{-1,(k)}(t;\theta)\geq 0\,     for all    t  ‚â•  0      t  0    t\geq 0   and    k  =   0  ,  1  ,  ‚Ä¶  ,   d  -  2        k   0  1  normal-‚Ä¶    d  2      k=0,1,\dots,d-2   and      (   -  1   )    d  -  2     œà    -  1   ,   (   d  -  2   )      (  t  ;  Œ∏  )        superscript    1     d  2     superscript  œà     1     d  2      t  Œ∏     (-1)^{d-2}\psi^{-1,(d-2)}(t;\theta)   is nonincreasing and convex .  The following table highlights the most prominent bivariate Archimedean copulas with their corresponding generator. Note that not all of them are completely monotone , i.e. d -monotone for all    d  ‚àà  ‚Ñï      d  ‚Ñï    d\in\mathbb{N}   or d -monotone for certain    Œ∏  ‚àà  Œò      Œ∏  normal-Œò    \theta\in\Theta   only.      Table with the most important generators 7     name     Clayton 8     Ali -Mikhail-Haq 9     Gumbel     Frank     Joe     Independence     Empirical copulas  When studying multivariate data, one might want to investigate the underlying copula. Suppose we have observations         (   X  1  i   ,   X  2  i   ,  ‚Ä¶  ,   X  d  i   )   ,  i   =  1   ,   ‚Ä¶  ,  n      formulae-sequence       superscript   subscript  X  1   i    superscript   subscript  X  2   i   normal-‚Ä¶   superscript   subscript  X  d   i    i   1    normal-‚Ä¶  n     (X_{1}^{i},X_{2}^{i},\dots,X_{d}^{i}),\,i=1,\dots,n   from a random vector    (   X  1   ,   X  2   ,  ‚Ä¶  ,   X  d   )      subscript  X  1    subscript  X  2   normal-‚Ä¶   subscript  X  d     (X_{1},X_{2},\dots,X_{d})   with continuous margins. The corresponding "true" copula observations would be         (   U  1  i   ,   U  2  i   ,  ‚Ä¶  ,   U  d  i   )   =   (    F  1    (   X  1  i   )    ,    F  2    (   X  2  i   )    ,  ‚Ä¶  ,    F  d    (   X  d  i   )    )    ,   i  =   1  ,  ‚Ä¶  ,  n     .     formulae-sequence      superscript   subscript  U  1   i    superscript   subscript  U  2   i   normal-‚Ä¶   superscript   subscript  U  d   i        subscript  F  1    superscript   subscript  X  1   i       subscript  F  2    superscript   subscript  X  2   i    normal-‚Ä¶     subscript  F  d    superscript   subscript  X  d   i        i   1  normal-‚Ä¶  n      (U_{1}^{i},U_{2}^{i},\dots,U_{d}^{i})=\left(F_{1}(X_{1}^{i}),F_{2}(X_{2}^{i}),%
 \dots,F_{d}(X_{d}^{i})\right),\,i=1,\dots,n.   However, the marginal distribution functions    F  i     subscript  F  i    F_{i}   are usually not known. Therefore, one can construct pseudo copula observations by using the empirical distribution functions       F  k  n    (  x  )   =   1  n    ‚àë   i  =  1   n   ùüè   (   X  k  i   ‚â§  x  )      fragments   superscript   subscript  F  k   n    fragments  normal-(  x  normal-)      1  n    superscript   subscript     i  1    n   1   fragments  normal-(   superscript   subscript  X  k   i    x  normal-)     F_{k}^{n}(x)=\frac{1}{n}\sum_{i=1}^{n}\mathbf{1}(X_{k}^{i}\leq x)   instead. Then, the pseudo copula observations are defined as         (    U  ~   1  i   ,    U  ~   2  i   ,  ‚Ä¶  ,    U  ~   d  i   )   =   (    F  1  n    (   X  1  i   )    ,    F  2  n    (   X  2  i   )    ,  ‚Ä¶  ,    F  d  n    (   X  d  i   )    )    ,   i  =   1  ,  ‚Ä¶  ,  n     .     formulae-sequence      superscript   subscript   normal-~  U   1   i    superscript   subscript   normal-~  U   2   i   normal-‚Ä¶   superscript   subscript   normal-~  U   d   i        superscript   subscript  F  1   n    superscript   subscript  X  1   i       superscript   subscript  F  2   n    superscript   subscript  X  2   i    normal-‚Ä¶     superscript   subscript  F  d   n    superscript   subscript  X  d   i        i   1  normal-‚Ä¶  n      (\tilde{U}_{1}^{i},\tilde{U}_{2}^{i},\dots,\tilde{U}_{d}^{i})=\left(F_{1}^{n}(%
 X_{1}^{i}),F_{2}^{n}(X_{2}^{i}),\dots,F_{d}^{n}(X_{d}^{i})\right),\,i=1,\dots,n.   The corresponding empirical copula is then defined as       C  n    (   u  1   ,  ‚Ä¶  ,   u  d   )   =   1  n    ‚àë   i  =  1   n   ùüè   (    U  ~   1  i   ‚â§   u  1   ,  ‚Ä¶  ,    U  ~   d  i   ‚â§   u  d   )   .     fragments   superscript  C  n    fragments  normal-(   subscript  u  1   normal-,  normal-‚Ä¶  normal-,   subscript  u  d   normal-)      1  n    superscript   subscript     i  1    n   1   fragments  normal-(   superscript   subscript   normal-~  U   1   i     subscript  u  1   normal-,  normal-‚Ä¶  normal-,   superscript   subscript   normal-~  U   d   i     subscript  u  d   normal-)   normal-.    C^{n}(u_{1},\dots,u_{d})=\frac{1}{n}\sum_{i=1}^{n}\mathbf{1}\left(\tilde{U}_{1%
 }^{i}\leq u_{1},\dots,\tilde{U}_{d}^{i}\leq u_{d}\right).   The components of the pseudo copula samples can also be written as      U  ~   k  i   =    R  k  i   /  n        superscript   subscript   normal-~  U   k   i      superscript   subscript  R  k   i   n     \tilde{U}_{k}^{i}=R_{k}^{i}/n   , where    R  k  i     superscript   subscript  R  k   i    R_{k}^{i}   is the rank of the observation    X  k  i     superscript   subscript  X  k   i    X_{k}^{i}   :       R  k  i   =   ‚àë   j  =  1   n   ùüè   (   X  k  j   ‚â§   X  k  i   )      fragments   superscript   subscript  R  k   i     superscript   subscript     j  1    n   1   fragments  normal-(   superscript   subscript  X  k   j     superscript   subscript  X  k   i   normal-)     R_{k}^{i}=\sum_{j=1}^{n}\mathbf{1}(X_{k}^{j}\leq X_{k}^{i})   Therefore, the empirical copula can be seen as the empirical distribution of the rank transformed data.  Monte Carlo integration for copula models  In statistical applications, many problems can be formulated in the following way. One is interested in the expectation of a response function    g  :    ‚Ñù  d   ‚Üí  ‚Ñù      normal-:  g   normal-‚Üí   superscript  ‚Ñù  d   ‚Ñù     g:\mathbb{R}^{d}\rightarrow\mathbb{R}   applied to some random vector    (   X  1   ,  ‚Ä¶  ,   X  d   )      subscript  X  1   normal-‚Ä¶   subscript  X  d     (X_{1},\dots,X_{d})   . 10 If we denote the cdf of this random vector with   H   H   H   , the quantity of interest can thus be written as        ùîº   [   g   (   X  1   ,  ‚Ä¶  ,   X  d   )    ]    =    ‚à´   ‚Ñù  d     g   (   x  1   ,  ‚Ä¶  ,   x  d   )   d  H   (   x  1   ,  ‚Ä¶  ,   x  d   )      .        ùîº   delimited-[]    g    subscript  X  1   normal-‚Ä¶   subscript  X  d         subscript    superscript  ‚Ñù  d      g    subscript  x  1   normal-‚Ä¶   subscript  x  d    d  H    subscript  x  1   normal-‚Ä¶   subscript  x  d        \mathbb{E}\left[g(X_{1},\dots,X_{d})\right]=\int_{\mathbb{R}^{d}}g(x_{1},\dots%
 ,x_{d})\,dH(x_{1},\dots,x_{d}).     If   H   H   H   is given by a copula model, i.e.,       H   (   x  1   ,  ‚Ä¶  ,   x  d   )    =   C   (    F  1    (   x  1   )    ,  ‚Ä¶  ,    F  d    (   x  d   )    )          H    subscript  x  1   normal-‚Ä¶   subscript  x  d       C      subscript  F  1    subscript  x  1    normal-‚Ä¶     subscript  F  d    subscript  x  d        H(x_{1},\dots,x_{d})=C(F_{1}(x_{1}),\dots,F_{d}(x_{d}))     this expectation can be rewritten as        ùîº   [   g   (   X  1   ,  ‚Ä¶  ,   X  d   )    ]    =    ‚à´    [  0  ,  1  ]   d     g   (    F  1   -  1     (   u  1   )    ,  ‚Ä¶  ,    F  d   -  1     (   u  d   )    )   d  C   (   u  1   ,  ‚Ä¶  ,   u  d   )      .        ùîº   delimited-[]    g    subscript  X  1   normal-‚Ä¶   subscript  X  d         subscript    superscript   0  1   d      g      superscript   subscript  F  1     1     subscript  u  1    normal-‚Ä¶     superscript   subscript  F  d     1     subscript  u  d     d  C    subscript  u  1   normal-‚Ä¶   subscript  u  d        \mathbb{E}\left[g(X_{1},\dots,X_{d})\right]=\int_{[0,1]^{d}}g(F_{1}^{-1}(u_{1}%
 ),\dots,F_{d}^{-1}(u_{d}))\,dC(u_{1},\dots,u_{d}).     In case the copula C is absolutely continuous , i.e. C has a density c , this equation can be written as        ùîº   [   g   (   X  1   ,  ‚Ä¶  ,   X  d   )    ]    =    ‚à´    [  0  ,  1  ]   d     g   (    F  1   -  1     (   u  1   )    ,  ‚Ä¶  ,    F  d   -  1     (   u  d   )    )   c   (   u  1   ,  ‚Ä¶  ,   u  d   )   d   u  1   ‚ãØ  d   u  d      .        ùîº   delimited-[]    g    subscript  X  1   normal-‚Ä¶   subscript  X  d         subscript    superscript   0  1   d      g      superscript   subscript  F  1     1     subscript  u  1    normal-‚Ä¶     superscript   subscript  F  d     1     subscript  u  d     c    subscript  u  1   normal-‚Ä¶   subscript  u  d    d   subscript  u  1   normal-‚ãØ  d   subscript  u  d       \mathbb{E}\left[g(X_{1},\dots,X_{d})\right]=\int_{[0,1]^{d}}g(F_{1}^{-1}(u_{1}%
 ),\dots,F_{d}^{-1}(u_{d}))c(u_{1},\dots,u_{d})\,du_{1}\cdots du_{d}.     If copula and margins are known (or if they have been estimated), this expectation can be approximated through the following Monte Carlo algorithm:   Draw a sample     (   U  1  k   ,  ‚Ä¶  ,   U  d  k   )   ‚àº   C    (  k  =  1  ,  ‚Ä¶  ,  n  )      fragments   fragments  normal-(   superscript   subscript  U  1   k   normal-,  normal-‚Ä¶  normal-,   superscript   subscript  U  d   k   normal-)   similar-to  C   fragments  normal-(  k   1  normal-,  normal-‚Ä¶  normal-,  n  normal-)     (U_{1}^{k},\dots,U_{d}^{k})\sim C\;\;(k=1,\dots,n)   of size n from the copula C  By applying the inverse marginal cdf's, produce a sample of    (   X  1   ,  ‚Ä¶  ,   X  d   )      subscript  X  1   normal-‚Ä¶   subscript  X  d     (X_{1},\dots,X_{d})   by setting     (   X  1  k   ,  ‚Ä¶  ,   X  d  k   )   =   (   F  1   -  1     (   U  1  k   )   ,  ‚Ä¶  ,   F  d   -  1     (   U  d  k   )   )   ‚àº   H    (  k  =  1  ,  ‚Ä¶  ,  n  )      fragments   fragments  normal-(   superscript   subscript  X  1   k   normal-,  normal-‚Ä¶  normal-,   superscript   subscript  X  d   k   normal-)     fragments  normal-(   superscript   subscript  F  1     1     fragments  normal-(   superscript   subscript  U  1   k   normal-)   normal-,  normal-‚Ä¶  normal-,   superscript   subscript  F  d     1     fragments  normal-(   superscript   subscript  U  d   k   normal-)   normal-)   similar-to  H   fragments  normal-(  k   1  normal-,  normal-‚Ä¶  normal-,  n  normal-)     (X_{1}^{k},\dots,X_{d}^{k})=(F_{1}^{-1}(U_{1}^{k}),\dots,F_{d}^{-1}(U_{d}^{k})%
 )\sim H\;\;(k=1,\dots,n)     Approximate    ùîº   [   g   (   X  1   ,  ‚Ä¶  ,   X  d   )    ]       ùîº   delimited-[]    g    subscript  X  1   normal-‚Ä¶   subscript  X  d        \mathbb{E}\left[g(X_{1},\dots,X_{d})\right]   by its empirical value:          ùîº   [   g   (   X  1   ,  ‚Ä¶  ,   X  d   )    ]    ‚âà    1  n     ‚àë   k  =  1   n    g   (   X  1  k   ,  ‚Ä¶  ,   X  d  k   )            ùîº   delimited-[]    g    subscript  X  1   normal-‚Ä¶   subscript  X  d           1  n     superscript   subscript     k  1    n     g    superscript   subscript  X  1   k   normal-‚Ä¶   superscript   subscript  X  d   k         \mathbb{E}\left[g(X_{1},\dots,X_{d})\right]\approx\frac{1}{n}\sum_{k=1}^{n}g(X%
 _{1}^{k},\dots,X_{d}^{k})        Applications  Quantitative finance  In risk/portfolio management, copulas are used to perform stress-tests and robustness checks that are especially important during ‚Äúdownside/crisis/panic regimes‚Äù where extreme downside events may occur (e.g., the global financial crisis of 2007‚Äì2008).  The formula was also adapted for financial markets and was used to estimate the probability distribution of losses on pools of loans or bonds. The users of the formula have been criticized for creating "evaluation cultures" that continued to use simple copul√¶ despite the simple versions being acknowledged as inadequate for that purpose. 11 During a downside regime, a large number of investors who have held positions in riskier assets such as equities or real estate may seek refuge in ‚Äòsafer‚Äô investments such as cash or bonds. This is also known as a flight-to-quality effect and investors tend to exit their positions in riskier assets in large numbers in a short period of time. As a result, during downside regimes, correlations across equities are greater on the downside as opposed to the upside and this may have disastrous effects on the economy. 12  13 For example, anecdotally, we often read financial news headlines reporting the loss of hundreds of millions of dollars on the stock exchange in a single day; however, we rarely read reports of positive stock market gains of the same magnitude and in the same short time frame.  Copulas are useful in portfolio/risk management and help us analyse the effects of downside regimes by allowing the modelling of the marginals and dependence structure of a multivariate probability model separately. For example, consider the stock exchange as a market consisting of a large number of traders each operating with his/her own strategies to maximize profits. The individualistic behaviour of each trader can be described by modelling the marginals. However, as all traders operate on the same exchange, each traders‚Äô actions have an interaction effect with other traders'. This interaction effect can be described by modelling the dependence structure. Therefore, copulas allow us to analyse the interaction effects which are of particular interest during downside regimes as investors tend to herd their trading behaviour and decisions.  Previously, scalable copula models for large dimensions only allowed the modelling of elliptical dependence structures (i.e., Gaussian and Student-t copulas) that do not allow for correlation asymmetries where correlations differ on the upside or downside regimes. However, the recent development of vine copulas 14 (also known as pair copulas) enables the flexible modelling of the dependence structure for portfolios of large dimensions. 15 The Clayton canonical vine copula allows for the occurrence of extreme downside events and has been successfully applied in portfolio choice and risk management applications. The model is able to reduce the effects of extreme downside correlations and produces improved statistical and economic performance compared to scalable elliptical dependence copulas such as the Gaussian and Student-t copula. 16 Other models developed for risk management applications are panic copulas that are glued with market estimates of the marginal distributions to analyze the effects of panic regimes on the portfolio profit and loss distribution. Panic copulas are created by Monte Carlo simulation, mixed with a re-weighting of the probability of each scenario. 17  As far as derivatives pricing is concerned, dependence modelling with copula functions is widely used in applications of financial risk assessment and actuarial analysis ‚Äì for example in the pricing of collateralized debt obligations (CDOs). 18 Some believe the methodology of applying the Gaussian copula to credit derivatives to be one of the reasons behind the global financial crisis of 2008‚Äì2009 . 19 20 Despite this perception, there are documented attempts of the financial industry, occurring before the crisis, to address the limitations of the Gaussian copula and of copula functions more generally, specifically the lack of dependence dynamics and the poor representation of extreme events. 21 There have been attempts to propose models rectifying some of the copula limitations. 22 23 24  While the application of copulas in credit has gone through popularity as well as misfortune during the global financial crisis of 2008‚Äì2009, 25 it is arguably an industry standard model for pricing CDOs. Copulas have also been applied to other asset classes as a flexible tool in analyzing multi-asset derivative products. The first such application outside credit was to use a copula to construct an implied basket volatility surface, 26 taking into account the volatility smile of basket components. Copulas have since gained popularity in pricing and risk management 27 of options on multi-assets in the presence of volatility smile/skew, in equity, foreign exchange and fixed income derivative business. Some typical example applications of copulas are listed below:   Analyzing and pricing volatility smile/skew of exotic baskets, e.g. best/worst of;    Analyzing and pricing volatility smile/skew of less liquid FX cross, which is effectively a basket: C = S 1 / S 2 or C = S 1 ¬∑ S 2 ;    Analyzing and pricing spread options, in particular in fixed income constant maturity swap spread options.   Civil engineering  Recently, copula functions have been successfully applied to the database formulation for the reliability analysis of highway bridges, and to various multivariate simulation studies in civil, 28 mechanical and offshore engineering.Researchers are also trying these functions in field of transportation to understand interaction of individual driver behavior components which in totality shapes up the nature of an entire traffic flow.  Reliability engineering  Copulas are being used for reliability analysis of complex systems of machine components with competing failure modes. 29  Warranty data analysis  Copulas are being used for warranty data analysis in which the tail dependence is analysed 30  Turbulent combustion  Copulas are used in modelling turbulent partially premixed combustion, which is common in practical combustors. 31  32  Medicine  Copula functions have been successfully applied to the analysis of neuronal dependencies 33 and spike counts in neuroscience 34 .  Weather research  Copulas have been extensively used in climate- and weather-related research. 35  Random vector generation  Large synthetic traces of vectors and stationary time series can be generated using empirical copula while preserving the entire dependence structure of small datasets. 36 Such empirical traces are useful in various simulation-based performance studies. 37  References  Further reading   The standard reference for an introduction to copulas. Covers all fundamental aspects, summarizes the most popular copula classes, and provides proofs for the important theorems related to copulas     Roger B. Nelsen (1999), "An Introduction to Copulas", Springer. ISBN 978-0-387-98623-4      A book covering current topics in mathematical research on copulas:     Piotr Jaworski, Fabrizio Durante, Wolfgang Karl H√§rdle, Tomasz Rychlik (Editors): (2010): "Copula Theory and Its Applications" Lecture Notes in Statistics, Springer. ISBN 978-3-642-12464-8      A reference for sampling applications and stochastic models related to copulas is     Jan-Frederik Mai, Matthias Scherer (2012): Simulating Copulas (Stochastic Models, Sampling Algorithms and Applications). World Scientific. ISBN 978-1-84816-874-9      A paper covering the historic development of copula theory, by the person associated with the "invention" of copulas, Abe Sklar .     Abe Sklar (1997): "Random variables, distribution functions, and copulas ‚Äì a personal look backward and forward" in R√ºschendorf, L., Schweizer, B. und Taylor, M. (eds) Distributions With Fixed Marginals & Related Topics (Lecture Notes ‚Äì Monograph Series Number 28). ISBN 978-0-940600-40-9      The standard reference for multivariate models and copula theory in the context of financial and insurance models     Alexander J. McNeil, Rudiger Frey and Paul Embrechts (2005) "Quantitative Risk Management: Concepts, Techniques, and Tools", Princeton Series in Finance. ISBN 978-0-691-12255-7     External links    Copula Wiki: community portal for researchers with interest in copulas  A collection of Copula simulation and estimation codes  Thorsten Schmidt (2006) "Coping with Copulas"  Copulas & Correlation using Excel Simulation Articles  Chapter 1 of Jan-Frederik Mai, Matthias Scherer (2012) "Simulating Copulas: Stochastic Models, Sampling Algorithms, and Applications"   "  Category:Actuarial science  Category:Multivariate statistics  Category:Statistical dependence  Category:Systems of probability distributions     ‚Ü©  ‚Ü©  ‚Ü©  ‚Ü©  ‚Ü©  ‚Ü©   ‚Ü©  Ali, M.M., Mikhail, N.N. and Haq, M.S. (1978). A class of bivariate distributions including the bivariate logistic. J. Multivariate Anal. 8, 405-412 ‚Ü©  Alexander J. McNeil, Rudiger Frey and Paul Embrechts (2005) "Quantitative Risk Management: Concepts, Techniques, and Tools", Princeton Series in Finance ‚Ü©  ‚Ü©  ‚Ü©  ‚Ü©  ‚Ü©  ‚Ü©  ‚Ü©  ‚Ü©  ‚Ü©  Recipe for Disaster: The Formula That Killed Wall Street  Wired , 2/23/2009 ‚Ü©  ‚Ü©  ‚Ü©   ‚Ü©  ‚Ü©  ‚Ü©  ‚Ü©  ‚Ü©  ‚Ü©  ‚Ü©  ‚Ü©  ‚Ü©  ‚Ü©  ‚Ü©  ‚Ü©  ‚Ü©  ‚Ü©  ‚Ü©     