   Job shop scheduling      Job shop scheduling   Job shop scheduling (or job-shop problem) is an optimization problem in computer science and operations research in which ideal jobs are assigned to resources at particular times. The most basic version is as follows:  We are given n jobs J 1 , J 2 ,Â ..., J n of varying sizes, which need to be scheduled on m identical machines, while trying to minimize the makespan. The makespan is the total length of the schedule (that is, when all the jobs have finished processing). Nowadays, the problem is presented as an online problem (dynamic scheduling), that is, each job is presented, and the online algorithm needs to make a decision about that job before the next job is presented.  This problem is one of the best known online problems, and was the first problem for which competitive analysis was presented, by Graham in 1966. 1 Best problem instances for basic model with makespan objective are due to Taillard. 2  Problem variations  Many variations of the problem exist, including the following:   Machines can be related, independent, equal  Machines can require a certain gap between jobs or no idle-time  Machines can have sequence-dependent setups  Objective function can be to minimize the makespan, the L p norm, tardiness, maximum lateness etc. It can also be multi-objective optimization problem  Jobs may have constraints, for example a job i needs to finish before job j can be started (see workflow ). Also, the objective function can be multi-criteria. 3  Jobs and machines have mutual constraints, for example, certain jobs can be scheduled on some machines only  Set of jobs can relate to different set of machines  Deterministic (fixed) processing times or probabilistic processing times  There may also be some other side constraints   NP-hardness  If one already knows that the travelling salesman problem is NP-hard (as it is), then the job-shop problem with sequence-dependent setup is clearly also NP-hard , since the TSP is special case of the JSP with    m  =  1      m  1    m=1   (the salesman is the machine and the cities are the jobs).  Problem representation  The disjunctive graph  4 is one of the popular models used for describing the job shop scheduling problem instances. 5  A mathematical statement of the problem can be made as follows:  Let    M  =   {   M  1   ,   M  2   ,  â€¦  ,   M  m   }       M    subscript  M  1    subscript  M  2   normal-â€¦   subscript  M  m      M=\{M_{1},M_{2},\dots,M_{m}\}   and    J  =   {   J  1   ,   J  2   ,  â€¦  ,   J  n   }       J    subscript  J  1    subscript  J  2   normal-â€¦   subscript  J  n      J=\{J_{1},J_{2},\dots,J_{n}\}   be two finite  sets . On account of the industrial origins of the problem, the    M  i     subscript  M  i    \displaystyle M_{i}   are called machines and the    J  j     subscript  J  j    \displaystyle J_{j}   are called jobs .  Let    ð’³    ð’³   \displaystyle\ \mathcal{X}   denote the set of all sequential assignments of jobs to machines, such that every job is done by every machine exactly once; elements    x  âˆˆ  ð’³      x  ð’³    x\in\mathcal{X}   may be written as    n  Ã—  m      n  m    n\times m   matrices, in which column   i   i   \displaystyle i   lists the jobs that machine    M  i     subscript  M  i    \displaystyle M_{i}   will do, in order. For example, the matrix      x  =   (     1    2      2    3      3    1     )       x    1  2    2  3    3  1      x=\begin{pmatrix}1&2\\
 2&3\\
 3&1\end{pmatrix}     means that machine    M  1     subscript  M  1    \displaystyle M_{1}   will do the three jobs     J  1   ,   J  2   ,   J  3       subscript  J  1    subscript  J  2    subscript  J  3     \displaystyle J_{1},J_{2},J_{3}   in the order     J  1   ,   J  2   ,   J  3       subscript  J  1    subscript  J  2    subscript  J  3     \displaystyle J_{1},J_{2},J_{3}   , while machine    M  2     subscript  M  2    \displaystyle M_{2}   will do the jobs in the order     J  2   ,   J  3   ,   J  1       subscript  J  2    subscript  J  3    subscript  J  1     \displaystyle J_{2},J_{3},J_{1}   .  Suppose also that there is some cost function     C  :   ð’³  â†’   [  0  ,   +  âˆž   ]       normal-:  C   normal-â†’  ð’³   0          C:\mathcal{X}\to[0,+\infty]   . The cost function may be interpreted as a "total processing time", and may have some expression in terms of times     C   i  j    :    M  Ã—  J   â†’   [  0  ,   +  âˆž   ]       normal-:   subscript  C    i  j     normal-â†’    M  J    0          C_{ij}:M\times J\to[0,+\infty]   , the cost/time for machine    M  i     subscript  M  i    \displaystyle M_{i}   to do job    J  j     subscript  J  j    \displaystyle J_{j}   .  The job-shop problem is to find an assignment of jobs    x  âˆˆ  ð’³      x  ð’³    x\in\mathcal{X}   such that    C   (  x  )       C  x    \displaystyle C(x)   is a minimum, that is, there is no    y  âˆˆ  ð’³      y  ð’³    y\in\mathcal{X}   such that     C   (  x  )    >   C   (  y  )          C  x     C  y     \displaystyle C(x)>C(y)   .  The problem of infinite cost  One of the first problems that must be dealt with in the JSP is that many proposed solutions have infinite cost: i.e., there exists     x  âˆž   âˆˆ  ð’³       subscript  x    ð’³    x_{\infty}\in\mathcal{X}   such that     C   (   x  âˆž   )    =   +  âˆž         C   subscript  x           C(x_{\infty})=+\infty   . In fact, it is quite simple to concoct examples of such    x  âˆž     subscript  x     x_{\infty}   by ensuring that two machines will deadlock , so that each waits for the output of the other's next step.  Major results  Graham had already provided the List scheduling algorithm in 1966, which is    (    2  âˆ’  1   /  m   )        2  normal-âˆ’  1   m    (2âˆ’1/m)   -competitive, where m is the number of machines. 6 Also, it was proved that List scheduling is optimum online algorithm for 2 and 3 machines. The Coffmanâ€“Graham algorithm (1972) for uniform-length jobs is also optimum for two machines, and is    (    2  âˆ’  2   /  m   )        2  normal-âˆ’  2   m    (2âˆ’2/m)   -competitive. 7 8 In 1992, Bartal, Fiat, Karloff and Vohra presented an algorithm that is 1.986 competitive. 9 A 1.945-competitive algorithm was presented by Karger, Philips and Torng in 1994. 10 In 1992, Albers provided a different algorithm that is 1.923-competitive. 11 Currently, the best known result is an algorithm given by Fleischer and Wahl, which achieves a competitive ratio of 1.9201. 12  A lower bound of 1.852 was presented by Albers. 13 Taillard instances has an important role in developing job shop scheduling with makespan objective.  In 1976 Garey provided a proof 14 that this problem is NP-complete for m>2, that is, no optimal solution can be computed in polynomial time for three or more machines (unless P=NP ).  Offline makespan minimization  Atomic jobs  The simplest form of the offline makespan minimisation problem deals with atomic jobs, that is, jobs that are not subdivided into multiple operations. It is equivalent to packing a number of items of various different sizes into a fixed number of bins, such that the maximum bin size needed is as small as possible. (If instead the number of bins is to be minimised, and the bin size is fixed, the problem becomes a different problem, known as the bin packing problem .)  Dorit S. Hochbaum and David Shmoys presented a polynomial-time approximation scheme in 1987 that finds an approximate solution to the offline makespan minimisation problem with atomic jobs to any desired degree of accuracy. 15  Jobs consisting of multiple operations  The basic form of the problem of scheduling jobs with multiple (M) operations, over M machines, such that all of the first operations must be done on the first machine, all of the second operations on the second, etc., and a single job cannot be performed in parallel, is known as the open shop scheduling problem. Various algorithms exist, including genetic algorithms . 16  Johnson's algorithm  A heuristic algorithm by S. M. Johnson can be used to solve the case of a 2 machine N job problem when all jobs are to be processed in the same order. 17 The steps of algorithm are as follows:  Job P i has two operations, of duration P i1 , P i2 , to be done on Machine M1, M2 in that sequence.   Step 1. List A = { 1, 2, â€¦, N }, List L1 = {}, List L2 = {}.    Step 2. From all available operation durations, pick the minimum.   If the minimum belongs to P k1 ,  Remove K from list A; Add K to beginning of List L1.  If minimum belongs to P k2 ,  Remove K from list A; Add K to end of List L2.   Step 3. Repeat Step 2 until List A is empty.    Step 4. Join List L1, List L2. This is the optimum sequence.   Johnson's method only works optimally for two machines. However, since it is optimal, and easy to compute, some researchers have tried to adopt it for M machines, ( M >Â 2.)  The idea is as follows: Imagine that each job requires m operations in sequence, on M1, M2 â€¦ Mm. We combine the first m /2 machines into an (imaginary) Machining center, MC1, and the remaining Machines into a Machining Center MC2. Then the total processing time for a Job P on MC1 = sum( operation times on first m /2 machines), and processing time for Job P on MC2 = sum(operation times on last m /2 machines).  By doing so, we have reduced the m-Machine problem into a Two Machining center scheduling problem. We can solve this using Johnson's method.  Example  Here is an example of a job shop scheduling problem formulated in AMPL as a mixed-integer programming problem with indicator constraints:  paramÂ N_JOBS;  paramÂ N_MACHINES;   setÂ JOBSÂ orderedÂ =Â 1..N_JOBS;  setÂ MACHINESÂ orderedÂ =Â 1..N_MACHINES;   paramÂ ProcessingTime{JOBS,Â MACHINES}Â >Â 0;   paramÂ CumulativeTime{iÂ inÂ JOBS,Â jÂ inÂ MACHINES}Â =  sumÂ {jjÂ inÂ MACHINES:Â ord(jj) i2}Â =  maxÂ {jÂ inÂ MACHINES}  (CumulativeTime[i1,j]Â -Â CumulativeTime[i2,j]Â +Â ProcessingTime[i2,j]);   varÂ endÂ >=Â 0;  varÂ start{JOBS}Â >=Â 0;  varÂ precedes{i1Â inÂ JOBS,Â i2Â inÂ JOBS:Â ord(i1) =Â start[i]Â +Â sum{jÂ inÂ MACHINES}Â ProcessingTime[i,j];   subjÂ toÂ no12_conflict{i1Â inÂ JOBS,Â i2Â inÂ JOBS:Â ord(i1) start[i2]Â >=Â start[i1]Â +Â TimeOffset[i1,i2];   subjÂ toÂ no21_conflict{i1Â inÂ JOBS,Â i2Â inÂ JOBS:Â ord(i1) start[i1]Â >=Â start[i2]Â +Â TimeOffset[i2,i1];   data;   paramÂ N_JOBSÂ :=Â 4;  paramÂ N_MACHINESÂ :=Â 3;   paramÂ ProcessingTime:  1Â 2Â 3Â :=  1Â 4Â 2Â 1  2Â 3Â 6Â 2  3Â 7Â 2Â 3  4Â 1Â 5Â 8;  See also   Disjunctive graph  Dynamic programming  Flow shop scheduling  Genetic algorithm scheduling  List of NP-complete problems  Open shop scheduling  Optimal control  Scheduling (production processes)   References  External links   University of Vienna Directory of methodologies, systems and software for dynamic optimization.  Taillard instances   pt:Escalonamento de Job Shop "  Category:Operations research  Category:Mathematical optimization  Category:Optimization algorithms and methods  Category:Combinatorial optimization     â†©  â†©  â†©  B. Roy, B. Sussmann, Les problÃ¨mes dâ€™ordonnancement avec constraintes disjonctives, SEMA, Note D.S., No. 9, Paris, 1964. â†©  Jacek BÅ‚aÅ¼ewicz, Erwin Pesch, MaÅ‚gorzata Sterna, The disjunctive graph machine representation of the job shop scheduling problem, European Journal of Operational Research, Volume 127, Issue 2, 1 December 2000, Pages 317-331, ISSN 0377-2217, 10.1016/S0377-2217(99)00486-5. â†©   . â†©  . â†©  â†©  â†©  â†©  â†©  â†©  â†©  â†©  â†©  S.M. Johnson, Optimal two- and three-stage production schedules with setup times included, Naval Res. Log. Quart. I(1954)61-68. â†©     