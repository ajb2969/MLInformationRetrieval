<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title offset="1443">Product rule</title>
   <script type="text/javascript"
      src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js">
    </script>
</head>
<body>
<h1>Product rule</h1>
<hr/>
<p>In <a class="uri" href="calculus" title="wikilink">calculus</a>, the <strong>product rule</strong> is a formula used to find the <a href="derivative" title="wikilink">derivatives</a> of products of two or more <a href="Functions_(mathematics)" title="wikilink">functions</a>. It may be stated as</p>
<p><span class="LaTeX">$$(f\cdot g)'=f'\cdot g+f\cdot g' \,\!$$</span></p>
<p>or in the <a href="Leibniz_notation" title="wikilink">Leibniz notation</a></p>
<p><span class="LaTeX">$$\dfrac{d}{dx}(u\cdot v)=u\cdot \dfrac{dv}{dx}+v\cdot \dfrac{du}{dx}$$</span>.</p>
<p>In the notation of differentials this can be written as</p>
<p><span class="LaTeX">$$d(uv)=u\,dv+v\,du$$</span>.</p>
<p>In Leibniz notation, the derivative of the product of three functions (not to be confused with <a href="Triple_product_rule" title="wikilink">Euler's triple product rule</a>) is</p>
<p><span class="LaTeX">$$\dfrac{d}{dx}(u\cdot v \cdot w)=\dfrac{du}{dx} \cdot v \cdot w + u \cdot \dfrac{dv}{dx} \cdot w + u\cdot v\cdot \dfrac{dw}{dx}$$</span>.</p>
<h2 id="discovery">Discovery</h2>
<p>Discovery of this rule is credited to <a href="Gottfried_Leibniz" title="wikilink">Gottfried Leibniz</a>, who demonstrated it using <a href="differential_(calculus)" title="wikilink">differentials</a>.<a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a> (However, Child (2008) argues that it is due to <a href="Isaac_Barrow" title="wikilink">Isaac Barrow</a>). Here is Leibniz's argument: Let <em>u</em>(<em>x</em>) and <em>v</em>(<em>x</em>) be two <a href="differentiable_function" title="wikilink">differentiable functions</a> of <em>x</em>. Then the differential of <em>uv</em> is</p>
<p><span class="LaTeX">$$\begin{align}
d(u\cdot v) & {} = (u + du)\cdot (v + dv) - u\cdot v \\
& {} = u\cdot dv + v\cdot du + du\cdot dv.
\end{align}$$</span></p>
<p>Since the term <em>du</em>·<em>dv</em> is "negligible" (compared to <em>du</em> and <em>dv</em>), Leibniz concluded that</p>
<p><span class="LaTeX">$$d(u\cdot v) = v\cdot du + u\cdot dv \,\!$$</span></p>
<p>and this is indeed the differential form of the product rule. If we divide through by the differential <em>dx</em>, we obtain</p>
<p><span class="LaTeX">$$\frac{d}{dx} (u\cdot v) = v \cdot \frac{du}{dx} + u \cdot  \frac{dv}{dx} \,\!$$</span></p>
<p>which can also be written in <a href="Derivative#Lagrange.27s_notation" title="wikilink">Lagrange's notation</a> as</p>
<p><span class="LaTeX">$$(u\cdot v)' = v\cdot  u' + u\cdot  v'. \,\!$$</span></p>
<h2 id="examples">Examples</h2>
<ul>
<li>Suppose we want to differentiate <em>ƒ</em>(<em>x</em>) = <em>x</em><sup>2</sup> <a href="sine" title="wikilink">sin</a>(<em>x</em>). By using the product rule, one gets the derivative <em>ƒ</em> '(<em>x</em>) = 2<em>x</em> sin(<em>x</em>) + <em>x</em><sup>2</sup>cos(<em>x</em>) (since the derivative of <em>x</em><sup>2</sup> is 2<em>x</em> and the derivative of sin(<em>x</em>) is cos(<em>x</em>)).</li>
<li>One special case of the product rule is the <strong>constant multiple rule</strong> which states: if <em>c</em> is a <a href="real_number" title="wikilink">real number</a> and <em>ƒ</em>(<em>x</em>) is a differentiable function, then <em>cƒ</em>(<em>x</em>) is also differentiable, and its derivative is (<em>c</em> × <em>ƒ</em>)'(<em>x</em>) = <em>c</em> × <em>ƒ</em> '(<em>x</em>). This follows from the product rule since the derivative of any constant is zero. This, combined with the sum rule for derivatives, shows that differentiation is <a href="linear_transformation" title="wikilink">linear</a>.</li>
<li>The rule for <a href="integration_by_parts" title="wikilink">integration by parts</a> is derived from the product rule, as is (a weak version of) the <a href="quotient_rule" title="wikilink">quotient rule</a>. (It is a "weak" version in that it does not prove that the quotient is differentiable, but only says what its derivative is <em>if</em> it is differentiable.)</li>
</ul>
<h2 id="proofs">Proofs</h2>
<h3 id="simple-proof">Simple Proof</h3>
<p>Let <em>h(x) = f(x) g(x)</em>, and suppose that <em>f</em> and <em>g</em> are each differentiable at <em>x</em>. We want to prove that <em>h</em> is differentiable at <em>x</em> and that its derivative <em>h'(x)</em> is given by <em>f'(x) g(x) + f(x) g'(x)</em>.</p>
<p><span class="LaTeX">$h'(x) = \lim_{a\to 0} \frac{h(x+a)-h(x)}{a} = \lim_{a\to 0} \frac{f(x+a)g(x+a)-f(x)g(x)}{a}$</span></p>
<dl>
<dd><dl>
<dd><span class="LaTeX">$= \lim_{a\to 0} \frac{f(x+a)g(x+a)-f(x)g(x+a)+f(x)g(x+a)-f(x)g(x)}{a}$</span>
</dd>
<dd><span class="LaTeX">$= \lim_{a\to 0} \frac{[f(x+a)-f(x)] \cdot g(x+a) + f(x) \cdot [g(x+a)-g(x)]}{a}$</span>
</dd>
<dd><math> = \lim_{a\to 0} \frac{f(x+a)-f(x)}{a} \cdot \lim_{a\to 0} g(x+a)
</math></dd>
</dl>
</dd>
</dl>
<p>+ \lim_{a\to 0} f(x) \cdot \lim_{a\to 0} \frac{g(x+a)-g(x)}{a} </p>
<dl>
<dd><dl>
<dd><span class="LaTeX">$= f'(x)g(x)+f(x)g'(x)$</span>.
</dd>
</dl>
</dd>
</dl>
<h3 id="more-complicated-proof">More Complicated Proof</h3>
<p>A rigorous proof of the product rule can be given using the <a href="Derivative#Definition_via_difference_quotients" title="wikilink">definition of the derivative</a> as a <a href="limit_(mathematics)" title="wikilink">limit</a>, and the basic <a href="Limit_of_a_function#Properties" title="wikilink">properties of limits</a>.</p>
<p>Let <em>h(x) = f(x) g(x)</em>, and suppose that <em>f</em> and <em>g</em> are each differentiable at <em>x<sub>0</sub></em>. (Note that <em>x<sub>0</sub></em> will remain fixed throughout the proof). We want to prove that <em>h</em> is differentiable at <em>x<sub>0</sub></em> and that its derivative <em>h'(x<sub>0</sub>)</em> is given by <em>f'(x<sub>0</sub>) g(x<sub>0</sub>) + f(x<sub>0</sub>) g'(x<sub>0</sub>)</em>.</p>
<p>Let <em>Δh = h(x<sub>0</sub>+Δx) - h(x<sub>0</sub>)</em>; note that although <em>x<sub>0</sub></em> is fixed, <em>Δh</em> depends on the value of <em>Δx</em>, which is thought of as being "small."</p>
<p>The function <em>h</em> is differentiable at <em>x<sub>0</sub></em> if the limit</p>
<p><span class="LaTeX">$$\lim_{\Delta x\to 0}{ \Delta h \over \Delta x}$$</span></p>
<p>exists; when it does, <em>h'(x<sub>0</sub>)</em> is defined to be the value of the limit.</p>
<p>As with <em>Δh</em>, let <em>Δf = f(x<sub>0</sub>+Δx) - f(x<sub>0</sub>)</em> and <em>Δg = g(x<sub>0</sub>+Δx) - g(x<sub>0</sub>)</em> which, like <em>Δh</em>, also depends on <em>Δx</em>. Then <em>f(x<sub>0</sub>+Δx) = f(x<sub>0</sub>) + Δf</em> and <em>g(x<sub>0</sub>+Δx) = g(x<sub>0</sub>) + Δg</em>.</p>
<p>It follows that <em>h(x<sub>0</sub>+Δx) = f(x<sub>0</sub>+Δx) g(x<sub>0</sub>+Δx) = (f(x<sub>0</sub>) + Δf) (g(x<sub>0</sub>)+Δg)</em>; applying the distributive law, we see that</p>
<p><mtpl></mtpl></p>
<p>While it is not necessary for the proof, it can be helpful to understand this product geometrically as the area of the rectangle in this diagram:</p>
<figure><b>(Figure)</b>
<figcaption><em>h(x+Δx) as the area of a rectangle</em></figcaption>
</figure>
<p>To get the value of <em>Δh</em>, subtract <em>h(x<sub>0</sub>)=f(x<sub>0</sub>) g(x<sub>0</sub>)</em> from equation . This removes the area of the white rectangle, leaving three rectangles:</p>
<p><span class="LaTeX">$$\Delta h = \Delta f g(x_0) + f(x_0) \Delta g + \Delta f \Delta g$$</span></p>
<p>To find <em>h'(x<sub>0</sub>)</em>, we need to find the limit as <em>Δx</em> goes to 0 of</p>
<p>The first two terms of the right-hand side of this equation correspond to the areas of the blue rectangles; the third corresponds to the area of the gray rectangle. Using the basic <a href="Limit_of_a_function#Properties" title="wikilink">properties of limits</a> and the definition of the derivative, we can tackle this term-by term. First,</p>
<p><span class="LaTeX">$$\lim_{\Delta x\to 0}\left ( \frac{\Delta f}{\Delta x}g(x_0) \right ) = f'(x_0)g(x_0)$$</span>.</p>
<p>Similarly,</p>
<p><span class="LaTeX">$$\lim_{\Delta x\to 0} \left ( f(x_0)  \frac{\Delta g}{\Delta x} \right ) = f(x_0)g'(x_0)$$</span>.</p>
<p>The third term, corresponding to the small gray rectangle, winds up being negligible (i.e. going to 0 in the limit) because <em>Δf Δg</em> "vanishes to second order." Rigorously,</p>
<p><span class="LaTeX">$$\lim_{\Delta x\to 0} \frac{\Delta f\Delta g}{\Delta x} = \lim_{\Delta x\to 0} \left ( \frac{\Delta f}{\Delta x}\frac{\Delta g}{\Delta x}\Delta x  \right ) = \lim_{\Delta x\to 0}{\frac{\Delta f}{\Delta x}} \cdot \lim_{\Delta x\to 0}{\frac{\Delta g}{\Delta x}} \cdot \lim_{\Delta x\to 0}{\Delta x}= f'(x_0) g'(x_0) \cdot 0 = 0$$</span></p>
<p>We have shown that the limit of each of the three terms on the right-hand side of equation  exists, hence</p>
<p><span class="LaTeX">$$\lim_{\Delta x\to 0} \frac{\Delta h}{\Delta x}$$</span> exists and is equal to the sum of the three limits. Thus, the product <em>h(x)</em> is differentiable at <em>x<sub>0</sub></em> and its derivative is given by</p>
<p><span class="LaTeX">$$\begin{align}
h'(x_0) & = \lim_{\Delta x\to 0} \frac{\Delta h}{\Delta x}\\
&  =  \lim_{\Delta x\to 0}  \left ( \frac{\Delta f}{\Delta x}g(x_0) \right ) + \lim_{\Delta x\to 0}  \left ( f(x_0)  \frac{\Delta g}{\Delta x}\right )  +  \lim_{\Delta x\to 0}  \left ( \frac{\Delta f \Delta g}{\Delta x} \right ) \\
& = f'(x_0)g(x_0) + f(x_0)g'(x_0) + 0 \\
& = f'(x_0)g(x_0) + f(x_0)g'(x_0) \\
\end{align}$$</span> as was to be shown.</p>
<h3 id="brief-proof">Brief proof</h3>
<p>By definition, if <span class="LaTeX">$f, g: \mathbb{R} \rightarrow \mathbb{R}$</span> are differentiable at <span class="LaTeX">$x$</span> then we can write</p>
<p><span class="LaTeX">$$f(x+h) = f(x) + f'(x)h + \psi_1(h) \qquad \qquad g(x+h) = g(x) + g'(x)h + \psi_2(h)$$</span> such that <span class="LaTeX">$\lim_{h \to 0} \frac{\psi_1(h)}{h} = \lim_{h \to 0} \frac{\psi_2(h)}{h} = 0$</span>, <a href="Big_O_notation#Little-o_notation" title="wikilink">also written</a> <span class="LaTeX">$\psi_1, \psi_2 \sim o(h)$</span>. Then:</p>
<p><span class="LaTeX">$$\begin{align} fg(x+h) - fg(x) =  (f(x) + f'(x)h +\psi_1(h))(g(x) + g'(x)h + \psi_2(h)) - fg(x)= f'(x)g(x)h + f(x)g'(x)h + O(h) \\[12pt] \end{align}$$</span> Taking the limit for small <span class="LaTeX">$h$</span> gives the result.</p>
<h3 id="logarithms-and-quarter-squares">Logarithms and quarter squares</h3>
<p>Let <em>f</em> = <em>uv</em> and suppose <em>u</em> and <em>v</em> are positive functions of <em>x</em>. Then</p>
<p><span class="LaTeX">$$\ln f  =\ln (u\cdot v)=\ln u + \ln v.\,$$</span></p>
<p>Differentiating both sides:</p>
<p><span class="LaTeX">$${1 \over f} {df \over dx} = {1 \over u} {du \over dx} + {1 \over v} {dv \over dx}\,$$</span></p>
<p>and so, multiplying the left side by <em>f</em>, and the right side by <em>uv</em> (note: <em>f</em> = <em>uv</em>),</p>
<p><span class="LaTeX">$${df \over dx} = v {du \over dx} + u {dv \over dx}.\,$$</span></p>
<p>The proof appears in <a href="http://planetmath.org/encyclopedia/LogarithmicProofOfProductRule.html">1</a>. Note that since <em>u</em>, <em>v</em> need to be continuous, the assumption on positivity does not diminish the generality.</p>
<p>This proof relies on the <a href="chain_rule" title="wikilink">chain rule</a> and on the properties of the <a href="natural_logarithm" title="wikilink">natural logarithm</a> function, both of which are deeper than the product rule (however, information about the derivative of a logarithm that is sufficient to carry out a variant of the proof can be inferred by considering the derivative at <em>x</em> = <em>1</em> of the logarithm to any base of <em>cx</em>, where <em>c</em> is a constant, then generalising <em>c</em>). From one point of view, that is a disadvantage of this proof. On the other hand, the simplicity of the algebra in this proof perhaps makes it easier to understand than a proof using the definition of differentiation directly.</p>
<p>There is an analogous but arguably even easier proof (i.e., some people may find it easier as it can be used before being able to differentiate logarithms), using <a href="Multiplication_algorithm#Quarter_square_multiplication" title="wikilink">quarter square multiplication</a>, which similarly relies on the <a href="chain_rule" title="wikilink">chain rule</a> and on the properties of the quarter square function (shown here as <em>q</em>, i.e., with <span class="LaTeX">$q(x)={x^2 \over 4}$</span>):</p>
<p><span class="LaTeX">$$f=q(u+v)-q(u-v),$$</span></p>
<p>Differentiating both sides:</p>
<p><span class="LaTeX">$$f'=q'(u+v)(u'+v') - q'(u-v)(u'-v')$$</span></p>
<p><span class="LaTeX">$$=\left({1 \over 2}(u+v)(u'+v')\right) - \left({1 \over 2}(u-v)(u'-v')\right)$$</span></p>
<p><span class="LaTeX">$$={1 \over 2}(uu' + vu' + uv' + vv') - {1 \over 2}(uu' - vu' - uv' + vv')$$</span></p>
<p><span class="LaTeX">$$=vu'+uv'$$</span></p>
<p><span class="LaTeX">$$=uv'+u'v. \,$$</span></p>
<p>This does not present issues of whether the values are positive or negative, and the function's properties are much simpler to demonstrate (indeed, it can be differentiated without using first principles by considering the derivative at <em>x</em> = <em>0</em> of <em>cx</em>, where <em>c</em> is a constant, then generalising <em>c</em>).</p>
<p>Note also, these proofs are only valid for numbers or similar, whereas proofs from first principles are also valid for matrices and such like.</p>
<h3 id="chain-rule">Chain rule</h3>
<p>The product rule can be considered a special case of the <a href="chain_rule" title="wikilink">chain rule</a> for several variables.</p>
<p><span class="LaTeX">$${d (ab) \over dx} = \frac{\partial(ab)}{\partial a}\frac{da}{dx}+\frac{\partial (ab)}{\partial b}\frac{db}{dx} = b \frac{da}{dx} + a \frac{db}{dx}. \,$$</span></p>
<h3 id="non-standard-analysis">Non-standard analysis</h3>
<p>Let <em>u</em> and <em>v</em> be continuous functions in <em>x</em>, and let d<em>x</em>, d<em>u</em> and d<em>v</em> be <a href="infinitesimal" title="wikilink">infinitesimals</a> within the framework of <a href="non-standard_analysis" title="wikilink">non-standard analysis</a>, specifically the <a href="hyperreal_number" title="wikilink">hyperreal numbers</a>. Using st to denote the <a href="standard_part_function" title="wikilink">standard part function</a> that associates to a <a href="wiktionary:Finite_number" title="wikilink">finite</a> hyperreal number the real infinitely close to it, this gives</p>
<dl>
<dd>
<table>
<tbody>
<tr class="odd">
<td style="text-align: left;"><p><span class="LaTeX">$\frac{d(uv)}{dx}\,$</span></p></td>
<td style="text-align: left;"><p><span class="LaTeX">$=\operatorname{st}\left(\frac{(u + \mathrm du)(v + \mathrm dv) - uv}{\mathrm dx}\right)$</span></p></td>
</tr>
<tr class="even">
<td style="text-align: left;"></td>
<td style="text-align: left;"><p><span class="LaTeX">$=\operatorname{st}\left(\frac{uv + u \cdot \mathrm dv + v \cdot \mathrm du + \mathrm dv \cdot \mathrm du -uv}{\mathrm dx}\right)$</span></p></td>
</tr>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;"><p><span class="LaTeX">$=\operatorname{st}\left(\frac{u \cdot \mathrm dv + (v + \mathrm dv) \cdot \mathrm du}{\mathrm dx}\right)$</span></p></td>
</tr>
<tr class="even">
<td style="text-align: left;"></td>
<td style="text-align: left;"><p><span class="LaTeX">$={u}\frac{dv}{dx} + {v}\frac{du}{dx}$</span>.</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>
<p>This was essentially <a class="uri" href="Leibniz" title="wikilink">Leibniz</a>'s proof exploiting the <a href="transcendental_law_of_homogeneity" title="wikilink">transcendental law of homogeneity</a> (in place of the standard part above).</p>
<h3 id="smooth-infinitesimal-analysis">Smooth infinitesimal analysis</h3>
<p>In the context of Lawvere's approach to infinitesimals, let dx be a nilsquare infinitesimal. Then du = u' dx and dv = v' dx, so that</p>
<p><span class="LaTeX">$$\begin{align}
d(uv) & {} = (u + du)(v + dv)  -uv \\
 & {} = uv + u\cdot dv + v\cdot du + du\cdot dv - uv \\
 & {} = u\cdot dv + v\cdot du + du\cdot dv \\
 & {} = u\cdot dv + v\cdot du\,\!
\end{align}$$</span></p>
<p>since</p>
<p><span class="LaTeX">$$du \cdot dv = u' v' (dx)^2 = 0\,\!$$</span></p>
<h2 id="generalizations">Generalizations</h2>
<h3 id="a-product-of-more-than-two-factors">A product of more than two factors</h3>
<p>The product rule can be generalized to products of more than two factors. For example, for three factors we have</p>
<p><span class="LaTeX">$$\frac{d(uvw)}{dx} = \frac{du}{dx}vw + u\frac{dv}{dx}w + uv\frac{dw}{dx}\,\!$$</span>.</p>
<p>For a collection of functions <span class="LaTeX">$f_1, \dots, f_k$</span>, we have</p>
<p><span class="LaTeX">$$\frac{d}{dx} \left [ \prod_{i=1}^k f_i(x) \right ]
 = \sum_{i=1}^k \left(\frac{d}{dx} f_i(x) \prod_{j\ne i} f_j(x) \right)
= \left(  \prod_{i=1}^k f_i(x) \right) \left( \sum_{i=1}^k \frac{f'_i(x)}{f_i(x)} \right).$$</span></p>
<h3 id="higher-derivatives">Higher derivatives</h3>
<p>It can also be generalized to the <a href="Leibniz_rule_(generalized_product_rule)" title="wikilink">Leibniz rule</a> for the <em>n</em>th derivative of a product of two factors:</p>
<p><span class="LaTeX">$$(uv)^{(n)}(x) = \sum_{k=0}^n {n \choose k} \cdot u^{(n-k)}(x)\cdot  v^{(k)}(x).$$</span></p>
<p>See also <a href="binomial_coefficient" title="wikilink">binomial coefficient</a> and the formally quite similar <a href="binomial_theorem" title="wikilink">binomial theorem</a>. See also <a href="General_Leibniz_rule" title="wikilink">General Leibniz rule</a>.</p>
<p>Furthermore, for the <em>n</em>th derivative of an arbitrary number of factors:</p>
<p><span class="LaTeX">$$\left(\prod_{i=1}^kf_i\right)^{(n)}=\sum_{j_1+j_2+...+j_k=n}{n\choose j_1,j_2,...,j_k}\prod_{i=1}^kf_i^{(j_i)}.$$</span></p>
<h3 id="higher-partial-derivatives">Higher partial derivatives</h3>
<p>For <a href="partial_derivative" title="wikilink">partial derivatives</a>, we have</p>
<p><span class="LaTeX">$${\partial^n \over \partial x_1\,\cdots\,\partial x_n} (uv)
= \sum_S {\partial^{|S|} u \over \prod_{i\in S} \partial x_i} \cdot {\partial^{n-|S|} v \over \prod_{i\not\in S} \partial x_i}$$</span></p>
<p>where the index <em>S</em> runs through the whole list of 2<sup><em>n</em></sup> subsets of {1, ..., <em>n</em>}. For example, when <em>n</em> = 3, then</p>
<p><span class="LaTeX">$$\begin{align} &{}\quad {\partial^3 \over \partial x_1\,\partial x_2\,\partial x_3} (uv)  \\  \\
&{}= u \cdot{\partial^3 v \over \partial x_1\,\partial x_2\,\partial x_3} + {\partial u \over \partial x_1}\cdot{\partial^2 v \over \partial x_2\,\partial x_3} +  {\partial u \over \partial x_2}\cdot{\partial^2 v \over \partial x_1\,\partial x_3} + {\partial u \over \partial x_3}\cdot{\partial^2 v \over \partial x_1\,\partial x_2} \\  \\
&{}\qquad + {\partial^2 u \over \partial x_1\,\partial x_2}\cdot{\partial v \over \partial x_3}
+ {\partial^2 u \over \partial x_1\,\partial x_3}\cdot{\partial v \over \partial x_2}
+ {\partial^2 u \over \partial x_2\,\partial x_3}\cdot{\partial v \over \partial x_1}
+ {\partial^3 u \over \partial x_1\,\partial x_2\,\partial x_3}\cdot v. \end{align}$$</span></p>
<h3 id="banach-space">Banach space</h3>
<p>Suppose <em>X</em>, <em>Y</em>, and <em>Z</em> are <a href="Banach_space" title="wikilink">Banach spaces</a> (which includes <a href="Euclidean_space" title="wikilink">Euclidean space</a>) and <em>B</em> : <em>X</em> × <em>Y</em> → <em>Z</em> is a <a href="continuous_function_(topology)" title="wikilink">continuous</a> <a href="bilinear_operator" title="wikilink">bilinear operator</a>. Then <em>B</em> is differentiable, and its derivative at the point (<em>x</em>,<em>y</em>) in <em>X</em> × <em>Y</em> is the <a href="linear_map" title="wikilink">linear map</a> <em>D</em><sub>(<em>x</em>,<em>y</em>)</sub><em>B</em> : <em>X</em> × <em>Y</em> → <em>Z</em> given by</p>
<p><span class="LaTeX">$$(D_\left( x,y \right)\,B)\left( u,v \right) = B\left( u,y \right) + B\left( x,v \right)\qquad\forall (u,v)\in X \times Y.$$</span></p>
<h3 id="derivations-in-abstract-algebra">Derivations in abstract algebra</h3>
<p>In <a href="abstract_algebra" title="wikilink">abstract algebra</a>, the product rule is used to <em>define</em> what is called a <a href="derivation_(abstract_algebra)" title="wikilink">derivation</a>, not vice versa.</p>
<h3 id="vector-functions">Vector functions</h3>
<p>The product rule extends to <a href="scalar_multiplication" title="wikilink">scalar multiplication</a>, <a href="dot_product" title="wikilink">dot products</a>, and <a href="cross_product" title="wikilink">cross products</a> of vector functions.</p>
<p>For scalar multiplication: <span class="LaTeX">$(f \cdot \bold g)' = f\;'\cdot \bold g + f \cdot \bold g\;' \,$</span></p>
<p>For dot products: <span class="LaTeX">$(\bold f \cdot \bold g)' = \bold f\;'\cdot \bold g + \bold f \cdot \bold g\;' \,$</span></p>
<p>For cross products: <span class="LaTeX">$(\bold f \times \bold g)' = \bold f\;' \times \bold g + \bold f \times \bold g\;' \,$</span></p>
<p>Note: cross products are not commutative, i.e. <span class="LaTeX">$(f \times x)' \neq f' \times g + g \times f'$</span>, instead products are anticommutative, so it can be written as <span class="LaTeX">$(f \times x)' = f' \times g - g \times f'$</span></p>
<h3 id="scalar-fields">Scalar fields</h3>
<p>For scalar fields the concept of <a class="uri" href="gradient" title="wikilink">gradient</a> is the analog of the derivative:</p>
<p><span class="LaTeX">$\nabla (f \cdot g) = \nabla f \cdot g + f \cdot \nabla g \,$</span></p>
<h2 id="applications">Applications</h2>
<p>Among the applications of the product rule is a proof that</p>
<p><span class="LaTeX">$${d \over dx} x^n = nx^{n-1}\,\!$$</span></p>
<p>when <em>n</em> is a positive integer (this rule is true even if <em>n</em> is not positive or is not an integer, but the proof of that must rely on other methods). The proof is by <a href="mathematical_induction" title="wikilink">mathematical induction</a> on the exponent <em>n</em>. If <em>n</em> = 0 then <em>x</em><sup><em>n</em></sup> is constant and <em>nx</em><sup><em>n</em> − 1</sup> = 0. The rule holds in that case because the derivative of a constant function is 0. If the rule holds for any particular exponent <em>n</em>, then for the next value, <em>n</em> + 1, we have</p>
<p><span class="LaTeX">$$\begin{align}
{d \over dx}x^{n+1} &{}= {d \over dx}\left( x^n\cdot x\right) \\[12pt]
&{}= x{d \over dx} x^n + x^n{d \over dx}x \qquad\mbox{(the product rule is used here)} \\[12pt]
&{}= x\left(nx^{n-1}\right) + x^n\cdot 1\qquad\mbox{(the induction hypothesis is used here)} \\[12pt]
&{}= (n + 1)x^n.
\end{align}$$</span></p>
<p>Therefore if the proposition is true of <em>n</em>, it is true also of <em>n</em> + 1.</p>
<h3 id="definition-of-tangent-space">Definition of tangent space</h3>
<p>Product rule is also used in <a href="Tangent_space#Definition_via_derivations" title="wikilink">definition</a> of abstract <a href="tangent_space" title="wikilink">tangent space</a> of some abstract geometric figure (<a href="smooth_manifold" title="wikilink">smooth manifold</a>). This definition we can use if we cannot or wish to not use surrounding ambient space where our chosen geometric figure lives (since there might be no such surrounding space). It uses the fact that it is possible to define derivatives of real-valued functions on that geometric figure at a point p solely with the product rule and that the set of all such derivations in fact forms a <a href="vector_space" title="wikilink">vector space</a> that is the desired tangent space.</p>
<h2 id="see-also">See also</h2>
<ul>
<li><a href="Derivation_(differential_algebra)" title="wikilink">Derivation (differential algebra)</a></li>
<li><a href="Differential_(mathematics)" title="wikilink">Differential (mathematics)</a></li>
<li><a href="General_Leibniz_rule" title="wikilink">General Leibniz rule</a></li>
<li><a href="Quotient_rule" title="wikilink">Quotient rule</a></li>
<li><a href="Reciprocal_rule" title="wikilink">Reciprocal rule</a></li>
</ul>
<h2 id="references">References</h2>
<ul>
<li>Child, J. M. (2008) "The early mathematical manuscripts of Leibniz", Gottfried Wilhelm Leibniz, translated by J. M. Child; page 29, footnote 58.</li>
</ul>
<h2 id="external-links">External links</h2>
<ul>
<li><a href="http://www.math.ucdavis.edu/~kouba/CalcOneDIRECTORY/productruledirectory/ProductRule.html">Product Rule Practice Problems [Kouba, University of California: Davis]</a></li>
</ul>
<p>"</p>
<p><a href="Category:Differentiation_rules" title="wikilink">Category:Differentiation rules</a> <a href="Category:Articles_containing_proofs" title="wikilink">Category:Articles containing proofs</a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1"><a href="#fnref1">↩</a></li>
</ol>
</section>
</body>
</html>
