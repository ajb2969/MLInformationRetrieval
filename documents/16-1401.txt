   Bradley‚ÄìTerry model      Bradley‚ÄìTerry model   The Bradley‚ÄìTerry model is a probability model that can predict the outcome of a comparison. Given a pair of individuals   i   i   i   and   j   j   j   drawn from some population , it estimates the probability that the pairwise comparison     i  >  j      i  j    i>j   turns out true, as      P   (  i  >  j  )   =    p  i     p  i   +   p  j        fragments  P   fragments  normal-(  i   j  normal-)       subscript  p  i      subscript  p  i    subscript  p  j       P(i>j)=\frac{p_{i}}{p_{i}+p_{j}}     where is a positive real-valued score assigned to individual   i   i   i   . The comparison    i  >  j      i  j    i>j   can be read as "   i   i   i   is preferred to   j   j   j   ", "   i   i   i   ranks higher than   j   j   j   ", or "   i   i   i   beats   j   j   j   ", depending on the application.  For example, may represent the skill of a team in a sports tournament, estimated from the number of times   i   i   i   has won a match.    P   (  i  >  j  )      fragments  P   fragments  normal-(  i   j  normal-)     P(i>j)   then represents the probability that   i   i   i   will win a match against   j   j   j   . 1 2 Another example used to explain the model's purpose is that of scoring products in a certain category by quality. While it's hard for a person to draft a direct ranking of (many) brands of wine, it may be feasible to compare a sample of pairs of wines and say, for each pair, which one is better. The Bradley‚ÄìTerry model can then be used to derive a full ranking. 3  History and applications  The model is named after R. A. Bradley and M. E. Terry, 4 who presented it in 1952, 5 although it had already been studied by Zermelo in the 1920s. 6 7 8  Real-world applications of the model include estimation of the influence of statistical  journals , or ranking documents by relevance in machine-learned  search engines . 9 In the latter application,    P   (  i  >  j  )      fragments  P   fragments  normal-(  i   j  normal-)     P(i>j)   may reflect that document   i   i   i   is more relevant to the user's query than document   j   j   j   , so it should be displayed earlier in the results list. The individual then express the relevance of the document, and can be estimated from the frequency with which users click particular "hits" when presented with a result list. 10  Definition  The Bradley‚ÄìTerry model can be parametrized in various ways. One way to do so is to pick a single parameter per observation, leading to a model of   n   n   n   parameters . 11 Another variant, in fact the version considered by Bradley and Terry, 12 uses exponential score functions     p  i   =   e   Œ≤  i         subscript  p  i    superscript  e   subscript  Œ≤  i      p_{i}=e^{\beta_{i}}   so that      P   (  i  >  j  )   =    e   Œ≤  i      e   Œ≤  i    +   e   Œ≤  j         fragments  P   fragments  normal-(  i   j  normal-)       superscript  e   subscript  Œ≤  i       superscript  e   subscript  Œ≤  i     superscript  e   subscript  Œ≤  j        P(i>j)=\frac{e^{\beta_{i}}}{e^{\beta_{i}}+e^{\beta_{j}}}     or, using the logit (and disallowing ties), 13        P   (  i  >  j  )     P   (  j  >  i  )     =    Œ≤  i   -   Œ≤  j           fragments  P   fragments  normal-(  i   j  normal-)     fragments  P   fragments  normal-(  j   i  normal-)        subscript  Œ≤  i    subscript  Œ≤  j      \frac{P(i>j)}{P(j>i)}=\beta_{i}-\beta_{j}     reducing the model to logistic regression on pairs of individuals.  Estimating the parameters  The following algorithm computes the parameters of the basic version of the model from a sample of observations. Formally, it computes a maximum likelihood estimate , i.e., it maximizes the likelihood of the observed data. The algorithm dates back to the work of Zermelo. 14  The observations required are the outcomes of previous comparisons, for example, pairs    (  i  ,  j  )     i  j    (i,j)   where   i   i   i   beats   j   j   j   . Summarizing these outcomes as , the number of times   i   i   i   has beaten   j   j   j   , we obtain the log-likelihood of the parameter vector  p 1 , ..., p n }} as 15        L   (  ùê©  )    =     ‚àë  i  n     ‚àë  j  n     w   i  j     ln   p  i       -    w   i  j     ln   (    p  i   +   p  j    )       .        L  ùê©       superscript   subscript   i   n     superscript   subscript   j   n      subscript  w    i  j       subscript  p  i          subscript  w    i  j         subscript  p  i    subscript  p  j         L(\mathbf{p})=\sum_{i}^{n}\sum_{j}^{n}w_{ij}\ln p_{i}-w_{ij}\ln(p_{i}+p_{j}).     Denote the number of comparisons "won" by   i   i   i   as , and the number of comparisons made between   i   i   i   and   j   j   j   as . Starting from an arbitrary vector   ùê©   ùê©   \mathbf{p}   , the algorithm iteratively performs the update       p  i  ‚Ä≤   =    W  i     (    ‚àë   j  ‚â†  i      N   i  j      p  i   +   p  j      )    -  1          subscript   superscript  p  normal-‚Ä≤   i      subscript  W  i    superscript    subscript     j  i       subscript  N    i  j       subscript  p  i    subscript  p  j        1       p^{\prime}_{i}=W_{i}\left(\sum_{j\neq i}\frac{N_{ij}}{p_{i}+p_{j}}\right)^{-1}     for all   i   i   i   . After computing all of the new parameters, they should be renormalized,        p  i   ‚Üê    p  i  ‚Ä≤     ‚àë  j  n    p  j  ‚Ä≤      .     normal-‚Üê   subscript  p  i      subscript   superscript  p  normal-‚Ä≤   i     superscript   subscript   j   n    subscript   superscript  p  normal-‚Ä≤   j       p_{i}\leftarrow\frac{p^{\prime}_{i}}{\sum_{j}^{n}p^{\prime}_{j}}.     This estimation procedure improves the log-likelihood in every iteration, and eventually converges to a unique minimum.  See also   Ordinal regression  Rasch model  Scale (social sciences)   References  "  Category:Machine learning  Category:Probability theory  Category:Regression analysis        ‚Ü©  ‚Ü©  ‚Ü©  ‚Ü©  ‚Ü©  ‚Ü©  ‚Ü©  ‚Ü©  ‚Ü©        