<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="1519">Fuzzy retrieval</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>Fuzzy retrieval</h1>
<hr/>

<p><strong>Fuzzy retrieval</strong> techniques are based on the <a href="Extended_Boolean_model" title="wikilink">Extended Boolean model</a> and the <a href="Fuzzy_set" title="wikilink">Fuzzy set</a> theory. There are two classical fuzzy retrieval models: Mixed Min and Max (MMM) and the Paice model. Both models do not provide a way of evaluating query weights, however this is considered by the <a href="Extended_Boolean_model" title="wikilink">P-norms</a> algorithm.</p>
<h2 id="mixed-min-and-max-model-mmm">Mixed Min and Max model (MMM)</h2>

<p>In fuzzy-set theory, an element has a varying degree of membership, say <em>d<sub>A</sub></em>, to a given set <em>A</em> instead of the traditional membership choice (is an element/is not an element).<br/>
In MMM<a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a> each index term has a fuzzy set associated with it. A document's weight with respect to an index term <em>A</em> is considered to be the degree of membership of the document in the fuzzy set associated with <em>A</em>. The degree of membership for union and intersection are defined as follows in Fuzzy set theory:<br/>


<math display="block" id="Fuzzy_retrieval:0">
 <semantics>
  <mrow>
   <msub>
    <mi>d</mi>
    <mrow>
     <mi>A</mi>
     <mo>∩</mo>
     <mi>B</mi>
    </mrow>
   </msub>
   <mo>=</mo>
   <mrow>
    <mi>m</mi>
    <mi>i</mi>
    <mi>n</mi>
    <mrow>
     <mo stretchy="false">(</mo>
     <msub>
      <mi>d</mi>
      <mi>A</mi>
     </msub>
     <mo>,</mo>
     <msub>
      <mi>d</mi>
      <mi>B</mi>
     </msub>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>d</ci>
     <apply>
      <intersect></intersect>
      <ci>A</ci>
      <ci>B</ci>
     </apply>
    </apply>
    <apply>
     <times></times>
     <ci>m</ci>
     <ci>i</ci>
     <ci>n</ci>
     <interval closure="open">
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>d</ci>
       <ci>A</ci>
      </apply>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>d</ci>
       <ci>B</ci>
      </apply>
     </interval>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   d_{A\cap B}=min(d_{A},d_{B})
  </annotation>
 </semantics>
</math>

</p>

<p>

<math display="block" id="Fuzzy_retrieval:1">
 <semantics>
  <mrow>
   <msub>
    <mi>d</mi>
    <mrow>
     <mi>A</mi>
     <mo>∪</mo>
     <mi>B</mi>
    </mrow>
   </msub>
   <mo>=</mo>
   <mrow>
    <mi>m</mi>
    <mi>a</mi>
    <mi>x</mi>
    <mrow>
     <mo stretchy="false">(</mo>
     <msub>
      <mi>d</mi>
      <mi>A</mi>
     </msub>
     <mo>,</mo>
     <msub>
      <mi>d</mi>
      <mi>B</mi>
     </msub>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>d</ci>
     <apply>
      <union></union>
      <ci>A</ci>
      <ci>B</ci>
     </apply>
    </apply>
    <apply>
     <times></times>
     <ci>m</ci>
     <ci>a</ci>
     <ci>x</ci>
     <interval closure="open">
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>d</ci>
       <ci>A</ci>
      </apply>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>d</ci>
       <ci>B</ci>
      </apply>
     </interval>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   d_{A\cup B}=max(d_{A},d_{B})
  </annotation>
 </semantics>
</math>

</p>

<p>According to this, documents that should be retrieved for a query of the form <em>A or B</em>, should be in the fuzzy set associated with the union of the two sets <em>A</em> and <em>B</em>. Similarly, the documents that should be retrieved for a query of the form <em>A and B</em>, should be in the fuzzy set associated with the intersection of the two sets. Hence, it is possible to define the similarity of a document to the <em>or</em> query to be <em>max(d<sub>A</sub>, d<sub>B</sub>)</em> and the similarity of the document to the <em>and</em> query to be <em>min(d<sub>A</sub>, d<sub>B</sub>)</em>. The MMM model tries to soften the Boolean operators by considering the query-document similarity to be a linear combination of the <em>min</em> and <em>max</em> document weights.</p>

<p>Given a document <em>D</em> with index-term weights <em>d<sub>A1</sub>, d<sub>A2</sub>, ..., d<sub>An</sub></em> for terms <em>A<sub>1</sub>, A<sub>2</sub>, ..., A<sub>n</sub></em>, and the queries:</p>

<p><em>Q<sub>or</sub> = (A<sub>1</sub> or A<sub>2</sub> or ... or A<sub>n</sub>)</em><br/>
<em>Q<sub>and</sub> = (A<sub>1</sub> and A<sub>2</sub> and ... and A<sub>n</sub>)</em></p>

<p>the query-document similarity in the MMM model is computed as follows:</p>

<p><em>SlM(Q<sub>or</sub>, D) = C<sub>or1</sub> * max(d<sub>A1</sub>, d<sub>A2</sub>, ..., d<sub>An</sub>) + C<sub>or2</sub> * min(d<sub>A1</sub>, d<sub>A2</sub>, ..., d<sub>An</sub>)</em><br/>
<em>SlM(Q<sub>and</sub>, D) = C<sub>and1</sub> * min(d<sub>A1</sub>, d<sub>A2</sub>, ..., d<sub>An</sub>) + C<sub>and2</sub> * max(d<sub>A1</sub>, d<sub>A2</sub> ..., d<sub>An</sub>)</em></p>

<p>where <em>C<sub>or1</sub>, C<sub>or2</sub></em> are "softness" coefficients for the <em>or</em> operator, and <em>C<sub>and1</sub>, C<sub>and2</sub></em> are softness coefficients for the <em>and</em> operator. Since we would like to give the maximum of the document weights more importance while considering an <em>or</em> query and the minimum more importance while considering an <em>and</em> query, generally we have <em>C<sub>or1</sub> &gt; C<sub>or2</sub> and C<sub>and1</sub> &gt; C<sub>and2</sub></em>. For simplicity it is generally assumed that <em>C<sub>or1</sub> = 1 - C<sub>or2</sub></em> and <em>C<sub>and1</sub> = 1 - C<sub>and2</sub></em>.</p>

<p>Lee and Fox<a class="footnoteRef" href="#fn2" id="fnref2"><sup>2</sup></a> experiments indicate that the best performance usually occurs with <em>C<sub>and1</sub></em> in the range [0.5, 0.8] and with <em>C<sub>or1</sub></em> &gt; 0.2. In general, the computational cost of MMM is low, and retrieval effectiveness is much better than with the <a href="Standard_Boolean_model" title="wikilink">Standard Boolean model</a>.</p>
<h2 id="paice-model">Paice model</h2>

<p>The Paice model<a class="footnoteRef" href="#fn3" id="fnref3"><sup>3</sup></a> is a general extension to the MMM model. In comparison to the MMM model that considers only the minimum and maximum weights for the index terms, the Paice model incorporates all of the term weights when calculating the similarity:</p>

<p>

<math display="block" id="Fuzzy_retrieval:2">
 <semantics>
  <mrow>
   <mrow>
    <mi>S</mi>
    <mrow>
     <mo stretchy="false">(</mo>
     <mi>D</mi>
     <mo>,</mo>
     <mi>Q</mi>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
   <mo>=</mo>
   <mrow>
    <munderover>
     <mo largeop="true" movablelimits="false" symmetric="true">∑</mo>
     <mrow>
      <mi>i</mi>
      <mo>=</mo>
      <mn>1</mn>
     </mrow>
     <mi>n</mi>
    </munderover>
    <mfrac>
     <mrow>
      <msup>
       <mi>r</mi>
       <mrow>
        <mi>i</mi>
        <mo>-</mo>
        <mn>1</mn>
       </mrow>
      </msup>
      <mo>*</mo>
      <msub>
       <mi>w</mi>
       <mrow>
        <mi>d</mi>
        <mi>i</mi>
       </mrow>
      </msub>
     </mrow>
     <mrow>
      <msubsup>
       <mo largeop="true" symmetric="true">∑</mo>
       <mrow>
        <mi>j</mi>
        <mo>=</mo>
        <mn>1</mn>
       </mrow>
       <mi>n</mi>
      </msubsup>
      <msup>
       <mi>r</mi>
       <mrow>
        <mi>j</mi>
        <mo>-</mo>
        <mn>1</mn>
       </mrow>
      </msup>
     </mrow>
    </mfrac>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <times></times>
     <ci>S</ci>
     <interval closure="open">
      <ci>D</ci>
      <ci>Q</ci>
     </interval>
    </apply>
    <apply>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <sum></sum>
       <apply>
        <eq></eq>
        <ci>i</ci>
        <cn type="integer">1</cn>
       </apply>
      </apply>
      <ci>n</ci>
     </apply>
     <apply>
      <divide></divide>
      <apply>
       <times></times>
       <apply>
        <csymbol cd="ambiguous">superscript</csymbol>
        <ci>r</ci>
        <apply>
         <minus></minus>
         <ci>i</ci>
         <cn type="integer">1</cn>
        </apply>
       </apply>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <ci>w</ci>
        <apply>
         <times></times>
         <ci>d</ci>
         <ci>i</ci>
        </apply>
       </apply>
      </apply>
      <apply>
       <apply>
        <csymbol cd="ambiguous">superscript</csymbol>
        <apply>
         <csymbol cd="ambiguous">subscript</csymbol>
         <sum></sum>
         <apply>
          <eq></eq>
          <ci>j</ci>
          <cn type="integer">1</cn>
         </apply>
        </apply>
        <ci>n</ci>
       </apply>
       <apply>
        <csymbol cd="ambiguous">superscript</csymbol>
        <ci>r</ci>
        <apply>
         <minus></minus>
         <ci>j</ci>
         <cn type="integer">1</cn>
        </apply>
       </apply>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   S(D,Q)=\sum_{i=1}^{n}\frac{r^{i-1}*w_{di}}{\sum_{j=1}^{n}r^{j-1}}
  </annotation>
 </semantics>
</math>

</p>

<p>where <em>r</em> is a constant coefficient and <em>w<sub>di</sub></em> is arranged in ascending order for <em>and</em> queries and descending order for <em>or</em> queries. When n = 2 the Paice model shows the same behavior as the MMM model.</p>

<p>The experiments of Lee and Fox<a class="footnoteRef" href="#fn4" id="fnref4"><sup>4</sup></a> have shown that setting the <em>r</em> to 1.0 for <em>and</em> queries and 0.7 for <em>or</em> queries gives good retrieval effectiveness. The computational cost for this model is higher than that for the MMM model. This is because the MMM model only requires the determination of <em>min</em> or <em>max</em> of a set of term weights each time an <em>and</em> or <em>or</em> clause is considered, which can be done in <em>O(n)</em>. The Paice model requires the term weights to be sorted in ascending or descending order, depending on whether an <em>and</em> clause or an <em>or</em> clause is being considered. This requires at least an <em>0(n log n)</em> sorting algorithm. A good deal of floating point calculation is needed too.</p>
<h2 id="improvements-over-the-standard-boolean-model">Improvements over the Standard Boolean model</h2>

<p>Lee and Fox<a class="footnoteRef" href="#fn5" id="fnref5"><sup>5</sup></a> compared the Standard Boolean model with MMM and Paice models with three test collections, CISI, CACM and INSPEC. These are the reported results for average mean precision improvement:</p>
<table>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">
<p>CISI</p></th>
<th style="text-align: left;">
<p>CACM</p></th>
<th style="text-align: left;">
<p>INSPEC</p></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">
<p>MMM</p></td>
<td style="text-align: left;">
<p>68%</p></td>
<td style="text-align: left;">
<p>109%</p></td>
<td style="text-align: left;">
<p>195%</p></td>
</tr>
<tr class="even">
<td style="text-align: left;">
<p>Paice</p></td>
<td style="text-align: left;">
<p>77%</p></td>
<td style="text-align: left;">
<p>104%</p></td>
<td style="text-align: left;">
<p>206%</p></td>
</tr>
</tbody>
</table>

<p>These are very good improvements over the Standard model. MMM is very close to Paice and P-norm results which indicates that it can be a very good technique, and is the most efficient of the three.</p>
<h2 id="recent-work">Recent work</h2>

<p>Recently '''Kang <em>et al.</em>'.<a class="footnoteRef" href="#fn6" id="fnref6"><sup>6</sup></a> have devised a fuzzy retrieval system indexed by concept identification.</p>

<p>If we look at documents on a pure <a class="uri" href="Tf-idf" title="wikilink">Tf-idf</a> approach, even eliminating stop words, there will be words more relevant to the topic of the document than others and they will have the same weight because they have the same term frequency. If we take into account the user intent on a query we can better weight the terms of a document. Each term can be identified as a concept in a certain lexical chain that translates the importance of that concept for that document.<br/>
They report improvements over Paice and P-norm on the average precision and recall for the Top-5 retrieved documents.</p>

<p>Zadrozny<a class="footnoteRef" href="#fn7" id="fnref7"><sup>7</sup></a> revisited the fuzzy information retrieval model. He further extends the fuzzy extended Boolean model by:</p>
<ul>
<li>assuming linguistic terms as importance weights of keywords also in documents</li>
<li>taking into account the uncertainty concerning the representation of documents and queries</li>
<li>interpreting the linguistic terms in the representation of documents and queries as well as their matching in terms of the Zadeh’s fuzzy logic (calculus of linguistic statements)</li>
<li>addressing some pragmatic aspects of the proposed model, notably the techniques of indexing documents and queries</li>
</ul>

<p>The proposed model makes it possible to grasp both imprecision and uncertainty concerning the textual information representation and retrieval.</p>
<h2 id="see-also">See also</h2>
<ul>
<li><a href="Information_retrieval" title="wikilink">Information retrieval</a></li>
</ul>
<h2 id="further-reading">Further reading</h2>
<ul>
<li></li>
</ul>
<h2 id="references">References</h2>

<p>"</p>

<p><a href="Category:Information_retrieval_techniques" title="wikilink">Category:Information retrieval techniques</a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1"><a href="#fnref1">↩</a></li>
<li id="fn2"><a href="#fnref2">↩</a></li>
<li id="fn3"><a href="#fnref3">↩</a></li>
<li id="fn4"></li>
<li id="fn5"></li>
<li id="fn6"><a href="#fnref6">↩</a></li>
<li id="fn7"><a href="#fnref7">↩</a></li>
</ol>
</section>
</body>
</html>
