<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="350">Word lists by frequency</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>Word lists by frequency</h1>
<hr/>

<p><strong>Word lists by frequency</strong> are lists of a language's words grouped by frequency of occurrence within some given <a href="text_corpus" title="wikilink">text corpus</a>, either by levels or as a ranked list, serving the purpose of <a href="vocabulary_acquisition" title="wikilink">vocabulary acquisition</a>. A word list by frequency "provides a rational basis for making sure that learners get the best return for their vocabulary learning effort", () but is mainly intended for course writers, not directly for learners. Some major pitfalls are the corpus content, the corpus <a href="register_(sociolinguistics)" title="wikilink">register</a>, and the definition of "<a class="uri" href="word" title="wikilink">word</a>". While word counting is a thousand years old, with still gigantic analysis done by hand in the mid-20th century, <a href="natural_language_processing" title="wikilink">natural language electronic processing</a> of large corpora such as movie subtitles (SUBTLEX megastudy) has accelerated the research field.</p>

<p>In <a href="computational_linguistics" title="wikilink">computational linguistics</a>, a <strong>frequency list</strong> is a sorted list of <a href="word" title="wikilink">words</a> (word types) together with their <a class="uri" href="frequency" title="wikilink">frequency</a>, where frequency here usually means the number of occurrences in a given <a href="text_corpus" title="wikilink">corpus</a>, from which the rank, less meaningful, can be derived</p>
<table>
<thead>
<tr class="header">
<th style="text-align: left;">
<p>Type</p></th>
<th style="text-align: left;">
<p>Occurrences</p></th>
<th style="text-align: left;">
<p>Rank</p></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">
<p>the</p></td>
<td style="text-align: left;">
<p>3789654</p></td>
<td style="text-align: left;">
<p>1st</p></td>
</tr>
<tr class="even">
<td style="text-align: left;">
<p>he</p></td>
<td style="text-align: left;">
<p>2098762</p></td>
<td style="text-align: left;">
<p>2nd</p></td>
</tr>
<tr class="odd">
<td style="text-align: left;">
<p>[...]</p></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">
<p>king</p></td>
<td style="text-align: left;">
<p>57897</p></td>
<td style="text-align: left;">
<p>1,356th</p></td>
</tr>
<tr class="odd">
<td style="text-align: left;">
<p>boy</p></td>
<td style="text-align: left;">
<p>56975</p></td>
<td style="text-align: left;">
<p>1,357th</p></td>
</tr>
<tr class="even">
<td style="text-align: left;">
<p>[...]</p></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">
<p>stringyfy</p></td>
<td style="text-align: left;">
<p>5</p></td>
<td style="text-align: left;">
<p>34,589th</p></td>
</tr>
<tr class="even">
<td style="text-align: left;">
<p>[...]</p></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">
<p>transducionalify</p></td>
<td style="text-align: left;">
<p>1</p></td>
<td style="text-align: left;">
<p>123,567th</p></td>
</tr>
</tbody>
</table>
<h2 id="methodology">Methodology</h2>
<h3 id="factors">Factors</h3>

<p>Nation () noted the incredible help provided by computing capabilities, making corpus analysis much easier. He cited several key issues which influence the construction of frequency lists:</p>
<ul>
<li>corpus representativeness</li>
<li>word frequency and range</li>
<li>treatment of word families</li>
<li>treatment of idioms and fixed expressions</li>
<li>range of information</li>
<li>various other criteria</li>
</ul>
<h3 id="corpora">Corpora</h3>
<dl>
<dt>Traditional written corpus</dt>
</dl>

<p>Most of currently available studies are based on written texts.</p>
<dl>
<dt>SUBTLEX movement</dt>
</dl>

<p>However,  proposed to tap into the large number of subtitles available online to analyse large numbers of speeches.  made a long critical evaluation of this traditional textual analysis approach, and support a move toward speech analysis and analysis of film subtitles available online. This has recently been followed by a handful of copy-cat studies, providing valuable frequency count analysis for various languages. Indeed, the SUBTLEX movement completed in five years full studies for French (), American English (; ), Dutch (), Chinese (), Spanish (), Greek (), Vietnamese (), and Polish<a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a></p>
<h3 id="lexical-unit">Lexical unit</h3>

<p>In any case, the basic "word" unit should be defined. For Latin scripts, words are usually one or several characters separated either by spaces or punctuation. But exceptions can arise, such as English "can't", French "aujourd'hui", or idioms. It may also be preferable to group words of a <a href="word_family" title="wikilink">word family</a> under the representation of its <a href="base_word" title="wikilink">base word</a>. Thus, <em>possible, impossible, possibility</em> are words of the same word family, represented by the base word <em>*possib*</em>. For statistical purpose, all these words are summed up under the base word form *possib*, allowing the ranking of a concept and form occurrence. Moreover, other languages may present specific difficulties. Such is the case of Chinese, which does not use spaces between words, and where a specified chain of several characters can be interpreted as either a phrase of unique-character words, or as a multi-character unique word.</p>
<h3 id="statistics">Statistics</h3>

<p>It seems that <a href="Zipf's_law" title="wikilink">Zipf's law</a> holds for frequency lists drawn from longer texts of any natural language. Frequency lists are a useful tool when building an electronic dictionary, which is a prerequisite for a wide range of applications in <a href="computational_linguistics" title="wikilink">computational linguistics</a>.</p>

<p>German linguists define the <em>Häufigkeitsklasse</em> (frequency class) 

<math display="inline" id="Word_lists_by_frequency:0">
 <semantics>
  <mi>N</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>N</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   N
  </annotation>
 </semantics>
</math>

 of an item in the list using the <a href="binary_logarithm" title="wikilink">base 2 logarithm</a> of the ratio between its frequency and the frequency of the most frequent item. The most common item belongs to frequency class 0 (zero) and any item that is approximately half as frequent belongs in class 1. In the example list above, the misspelled word <em>outragious</em> has a ratio of 76/3789654 and belongs in class 16.</p>

<p>

<math display="block" id="Word_lists_by_frequency:1">
 <semantics>
  <mrow>
   <mi>N</mi>
   <mo>=</mo>
   <mrow>
    <mo>⌊</mo>
    <mrow>
     <mn>0.5</mn>
     <mo>-</mo>
     <mrow>
      <msub>
       <mi>log</mi>
       <mn>2</mn>
      </msub>
      <mrow>
       <mo>(</mo>
       <mfrac>
        <mtext>Frequency of this item</mtext>
        <mtext>Frequency of most common item</mtext>
       </mfrac>
       <mo>)</mo>
      </mrow>
     </mrow>
    </mrow>
    <mo>⌋</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <ci>N</ci>
    <apply>
     <floor></floor>
     <apply>
      <minus></minus>
      <cn type="float">0.5</cn>
      <apply>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <log></log>
        <cn type="integer">2</cn>
       </apply>
       <apply>
        <divide></divide>
        <mtext>Frequency of this item</mtext>
        <mtext>Frequency of most common item</mtext>
       </apply>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   N=\left\lfloor 0.5-\log_{2}\left(\frac{\text{Frequency of this item}}{\text{%
Frequency of most common item}}\right)\right\rfloor
  </annotation>
 </semantics>
</math>

 where 

<math display="inline" id="Word_lists_by_frequency:2">
 <semantics>
  <mrow>
   <mo stretchy="false">⌊</mo>
   <mi mathvariant="normal">…</mi>
   <mo stretchy="false">⌋</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <floor></floor>
    <ci>normal-…</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \lfloor\ldots\rfloor
  </annotation>
 </semantics>
</math>

 is the <a href="floor_function" title="wikilink">floor function</a>.</p>

<p>Frequency lists, together with <a href="semantic_network" title="wikilink">semantic networks</a>, are used to identify the least common, specialized terms to be replaced by their <a href="hypernym" title="wikilink">hypernyms</a> in a process of <a href="semantic_compression" title="wikilink">semantic compression</a>.</p>
<h3 id="pedagogy">Pedagogy</h3>

<p>Those lists are not intended to be given directly to students, but rather to serve as a guideline for teachers and book makers (). <a href="Paul_Nation" title="wikilink">Paul Nation</a>'s modern language teaching summary encourages first to "move from high frequency vocabulary and special purposes [thematic] vocabulary to low frequency vocabulary, then to teach learners strategies to sustain autonomous vocabulary expansion" ().</p>
<h2 id="effects-of-words-frequency">Effects of words frequency</h2>

<p>Word frequency is known to have various effects (; ). Memorization is positively affected by higher word frequency, likely because the learner is subject to more exposures (). Lexical access is positively influenced by high word frequency ().</p>
<h2 id="languages">Languages</h2>

<p>Below is a review of available resources.</p>
<h3 id="english">English</h3>

<p>Word counting dates back to <a class="uri" href="Hellenistic" title="wikilink">Hellenistic</a> time. Thorndike &amp; Lorge, assisted by their colleagues, counted 18,000,000 running words to provide the first large scale frequency list in 1944, before modern computers made such projects far easier ().</p>
<h4 id="traditional-lists">Traditional lists</h4>

<p>These all suffer from their age. In particular, words relating to technology, such as "blog," which, in 2014, was #7665 in frequency<a class="footnoteRef" href="#fn2" id="fnref2"><sup>2</sup></a> in the Corpus of Contemporary American English,<a class="footnoteRef" href="#fn3" id="fnref3"><sup>3</sup></a> was first attested to in 1999,<a class="footnoteRef" href="#fn4" id="fnref4"><sup>4</sup></a><a class="footnoteRef" href="#fn5" id="fnref5"><sup>5</sup></a><a class="footnoteRef" href="#fn6" id="fnref6"><sup>6</sup></a> and does not appear in any of these three lists.</p>
<dl>
<dt>The Teachers Word Book of 30,000 words (Thorndike and Lorge, 1944)</dt>
</dl>

<p>The TWB contains 30,000 lemmas or ~13,000 word families (Goulden, Nation and Read, 1990). A corpus of 18,000,000 written words was hand analysed. The size of its source corpus increased its usefulness, but its age, and language changes, have reduced its applicability ().</p>
<dl>
<dt><a href="General_Service_List" title="wikilink">The General Service List</a> (West, 1953)</dt>
</dl>

<p>The GSL contains 2,000 headwords divided into two sets of 1,000 words. A corpus of 5,000,000 written words was analyzed in the 1940s. The rate of occurrence (%) for different meanings, and parts of speech, of the headword are provided. Various criteria, other than frequence and range, were carefully applied to the corpus. Thus, despite its age, some errors, and its corpus being entirely written text, it is still an excellent database of word frequency, frequency of meanings, and reduction of noise ().</p>
<dl>
<dt>The American Heritage Word Frequency Book (Carroll, Davies and Richman, 1971)</dt>
</dl>

<p>A corpus of 5,000,000 running words, from written texts used in United States schools (various grades, various subject areas). Its value is in its focus on school teaching materials, and its tagging of words by the frequency of each word, in each of the school grade, and in each of the subject areas ().</p>
<dl>
<dt>The Brown (Francis and Kucera, 1982) LOB and related corpora</dt>
</dl>

<p>These now contain 1,000,000 words from a written corpora representing different dialects of English. These sources are used to produce frequency lists ().</p>
<h3 id="french">French</h3>
<dl>
<dt>Traditional datasets</dt>
</dl>

<p>A review has been made by . An attempt was made in the 1950s–60s with the <a href=":fr:Français_fondamental" title="wikilink">Français fondamental</a>. It includes the F.F.1 list with 1,500 high-frequency words, completed by a later F.F.2 list with 1,700 mid-frequency words, and the most used syntax rules.<a class="footnoteRef" href="#fn7" id="fnref7"><sup>7</sup></a> It is claimed that 70 grammatical words constitute 50% of the communicatives sentence,<a class="footnoteRef" href="#fn8" id="fnref8"><sup>8</sup></a> while 3,680 words make about 95~98% of coverage.<a class="footnoteRef" href="#fn9" id="fnref9"><sup>9</sup></a> A list of 3,000 frequent words is available.<a class="footnoteRef" href="#fn10" id="fnref10"><sup>10</sup></a></p>

<p>The French Ministry of the Education also provide a ranked list of the 1,500 most frequent <a href="word_family" title="wikilink">word families</a>, provided by the lexicologue <a href="Étienne_Brunet" title="wikilink">Étienne Brunet</a>.<a class="footnoteRef" href="#fn11" id="fnref11"><sup>11</sup></a> Jean Baudot made a study on the model of the American Brown study, entitled "Fréquences d'utilisation des mots en français écrit contemporain".<a class="footnoteRef" href="#fn12" id="fnref12"><sup>12</sup></a></p>

<p>More recently, the project <a href="Lexique_3" title="wikilink">Lexique 3</a> provided a list of 135,000 French words, with <a class="uri" href="orthography" title="wikilink">orthography</a>, <a class="uri" href="phonetic" title="wikilink">phonetic</a>, <a class="uri" href="syllabation" title="wikilink">syllabation</a>, <a href="part_of_speech" title="wikilink">part of speech</a>, <a href="gender_(linguistic)" title="wikilink">gender</a>, number, frequency, associated <a href="lexeme" title="wikilink">lexemes</a>, etc., available under an open-source license<a class="footnoteRef" href="#fn13" id="fnref13"><sup>13</sup></a></p>
<dl>
<dt>Subtlex</dt>
</dl>

<p>made a completely new counting based on online film subtitles.</p>
<h3 id="spanish">Spanish</h3>

<p>There have been several studies of Spanish word frequency ().<a class="footnoteRef" href="#fn14" id="fnref14"><sup>14</sup></a></p>
<h3 id="chinese">Chinese</h3>

<p>As a frequency toolkit, Da () and the Taiwanese Ministry of Education () provided large databases with frequency ranks for characters and words. The <a href="Hanyu_Shuiping_Kaoshi" title="wikilink">HSK</a> list of 8,848 high and medium frequency words in the <a href="People's_Republic_of_China" title="wikilink">People's Republic of China</a>, and the <a href="Republic_of_China" title="wikilink">Republic of China (Taiwan)</a>'s <a href="Test_of_Proficiency-Huayu" title="wikilink">TOP</a> list of about 8,600 common traditional Chinese words are two other lists displaying common Chinese words and characters. Following the SUBTLEX movement,  recently made a rich study of Chinese word and character frequencies.</p>
<h2 id="references">References</h2>
<references>
</references>
<h2 id="see-also">See also</h2>
<ul>
<li><a href="Letter_frequency" title="wikilink">Letter frequency</a></li>
<li><a href="Most_common_words_in_English" title="wikilink">Most common words in English</a></li>
<li><a href="Long_tail" title="wikilink">Long tail</a></li>
</ul>
<h2 id="sources">Sources</h2>
<dl>
<dt>Theoretical concepts</dt>
</dl>
<ul>
<li></li>
<li></li>
<li>

<p>.</p></li>
<li></li>
<li></li>
<li></li>
</ul>
<ul>
<li><a href="Helmut_Meier" title="wikilink">Helmut Meier</a>: <em>Deutsche Sprachstatistik</em>. Hildesheim: Olms 1967. (frequency list of German words)</li>
</ul>
<dl>
<dt>Written texts-based databases</dt>
</dl>
<ul>
<li>

<p>[Accessed August 21, 2010].</p></li>
<li>

<p>[Accessed August 21, 2010].</p></li>
<li></li>
</ul>
<dl>
<dt>SUBTLEX movement</dt>
</dl>
<ul>
<li></li>
<li></li>
<li></li>
<li></li>
<li></li>
<li></li>
<li></li>
<li>

<p>(<a href="http://expsy.ugent.be/subtlexus/">databases</a>)</p></li>
<li>SUBTLEX-DE: [Not yet puclished: :]  <a href="http://crr.ugent.be/subtlex-de/">database</a></li>
</ul>

<p><a class="uri" href="de:Häufigkeitsklasse" title="wikilink">de:Häufigkeitsklasse</a> <a href="hy:Հաճախականության_բառարաններ" title="wikilink">hy:Հաճախականության բառարաններ</a>"</p>

<p><a href="Category:Language_acquisition" title="wikilink">Category:Language acquisition</a> <a href="Category:Quantitative_linguistics" title="wikilink">Category:Quantitative linguistics</a> <a href="Category:Computational_linguistics" title="wikilink">Category:Computational linguistics</a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1"><a class="uri" href="http://www.ncbi.nlm.nih.gov/pubmed/24942246">http://www.ncbi.nlm.nih.gov/pubmed/24942246</a><a href="#fnref1">↩</a></li>
<li id="fn2"><a class="uri" href="http://www.wordandphrase.info/frequencylist.asp">http://www.wordandphrase.info/frequencylist.asp</a><a href="#fnref2">↩</a></li>
<li id="fn3"><a class="uri" href="http://corpus.byu.edu/coca/">http://corpus.byu.edu/coca/</a><a href="#fnref3">↩</a></li>
<li id="fn4"><a href="#fnref4">↩</a></li>
<li id="fn5"><a href="#fnref5">↩</a></li>
<li id="fn6"><a href="#fnref6">↩</a></li>
<li id="fn7"><a href="#fnref7">↩</a></li>
<li id="fn8"> - Citing V.A.C Henmon<a href="#fnref8">↩</a></li>
<li id="fn9"><a href="#fnref9">↩</a></li>
<li id="fn10"><a href="#fnref10">↩</a></li>
<li id="fn11"><a href="#fnref11">↩</a></li>
<li id="fn12"><a href="#fnref12">↩</a></li>
<li id="fn13"><a class="uri" href="http://www.lexique.org/">http://www.lexique.org/</a><a href="#fnref13">↩</a></li>
<li id="fn14"><a href="#fnref14">↩</a></li>
</ol>
</section>
</body>
</html>
