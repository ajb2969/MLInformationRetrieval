   Succinct data structure      Succinct data structure   In computer science , a succinct data structure is a data structure which uses an amount of space that is "close" to the information-theoretic lower bound, but (unlike other compressed representations) still allows for efficient query operations. The concept was originally introduced by Jacobson 1 to encode bit vectors , (unlabeled) trees , and planar graphs . Unlike general lossless data compression algorithms, succinct data structures retain the ability to use them in-place, without decompressing them first. A related notion is that of a compressed data structure , in which the size of the data structure depends upon the particular data being represented.  Suppose that   Z   Z   Z   is the information-theoretical optimal number of bits needed to store some data. A representation of this data is called:   implicit if it takes    Z  +   O   (  1  )        Z    O  1     Z+O(1)   bits of space,  succinct if it takes    Z  +   o   (  Z  )        Z    o  Z     Z+o(Z)   bits of space, and  compact if it takes    O   (  Z  )       O  Z    O(Z)   bits of space.   For example, a data structure that uses    2  Z      2  Z    2Z   bits of storage is compact,    Z  +   Z       Z    Z     Z+\sqrt{Z}   bits is succinct,    Z  +   lg  Z       Z   lg  Z     Z+\lg Z   bits is also succinct, and    Z  +  3      Z  3    Z+3   bits is implicit.  Implicit structures are thus usually reduced to storing information using some permutation of the input data; the most well-known example of this is the heap .  Succinct dictionaries  Succinct indexable dictionaries, also called rank/select dictionaries, form the basis of a number of succinct representation techniques, including binary trees ,   k   k   k   -ary trees and multisets , 2 as well as suffix trees and arrays . 3 The basic problem is to store a subset   S   S   S   of a universe    U  =   [  0  …  n  )   =   {  0  ,  1  ,  …  ,  n  -  1  }      fragments  U    fragments  normal-[  0  normal-…  n  normal-)     fragments  normal-{  0  normal-,  1  normal-,  normal-…  normal-,  n   1  normal-}     U=[0\dots n)=\{0,1,\dots,n-1\}   , usually represented as a bit array    B   [  0  …  n  )      fragments  B   fragments  normal-[  0  normal-…  n  normal-)     B[0\dots n)   where     B   [  i  ]    =  1        B   delimited-[]  i    1    B[i]=1   iff    i  ∈  S      i  S    i\in S   . An indexable dictionary supports the usual methods on dictionaries (queries, and insertions/deletions in the dynamic case) as well as the following operations:         𝐫𝐚𝐧𝐤  q    (  x  )    =   |   {   k  ∈   [   0  …  x   ]    :    B   [  k  ]    =  q   }   |          subscript  𝐫𝐚𝐧𝐤  q   x      conditional-set    k   delimited-[]    0  normal-…  x         B   delimited-[]  k    q       \mathbf{rank}_{q}(x)=|\{k\in[0\dots x]:B[k]=q\}|          𝐬𝐞𝐥𝐞𝐜𝐭  q    (  x  )   =  min   {  k  ∈   [  0  …  n  )   :   𝐫𝐚𝐧𝐤  q    (  k  )   =  x  }      fragments   subscript  𝐬𝐞𝐥𝐞𝐜𝐭  q    fragments  normal-(  x  normal-)      fragments  normal-{  k    fragments  normal-[  0  normal-…  n  normal-)   normal-:   subscript  𝐫𝐚𝐧𝐤  q    fragments  normal-(  k  normal-)    x  normal-}     \mathbf{select}_{q}(x)=\min\{k\in[0\dots n):\mathbf{rank}_{q}(k)=x\}      for    q  ∈   {  0  ,  1  }       q   0  1     q\in\{0,1\}   .  In other words,     𝐫𝐚𝐧𝐤  q    (  x  )        subscript  𝐫𝐚𝐧𝐤  q   x    \mathbf{rank}_{q}(x)   returns the number of elements equal to   q   q   q   up to position   x   x   x   while     𝐬𝐞𝐥𝐞𝐜𝐭  q    (  x  )        subscript  𝐬𝐞𝐥𝐞𝐜𝐭  q   x    \mathbf{select}_{q}(x)   returns the position of the   x   x   x   -th occurrence of   q   q   q   .  There is a simple representation 4 which uses    n  +   o   (  n  )        n    o  n     n+o(n)   bits of storage space (the original bit array and an    o   (  n  )       o  n    o(n)   auxiliary structure) and supports rank and select in constant time. It uses an idea similar to that for range-minimum queries ; there are a constant number of recursions before stopping at a subproblem of a limited size. The bit array   B   B   B   is partitioned into large blocks of size    l  =    lg  2   n       l    superscript  lg  2   n     l=\lg^{2}n   bits and small blocks of size    s  =   lg   n  /  2        s   lg    n  2      s=\lg n/2   bits. For each large block, the rank of its first bit is stored in a separate table     R  l    [  0  …  n  /  l  )      fragments   subscript  R  l    fragments  normal-[  0  normal-…  n   l  normal-)     R_{l}[0\dots n/l)   ; each such entry takes    lg  n     lg  n    \lg n   bits for a total of      (   n  /  l   )    lg  n    =   n  /   lg  n            n  l    lg  n      n   lg  n      (n/l)\lg n=n/\lg n   bits of storage. Within a large block, another directory     R  s    [  0  …  l  /  s  )      fragments   subscript  R  s    fragments  normal-[  0  normal-…  l   s  normal-)     R_{s}[0\dots l/s)   stores the rank of each of the     l  /  s   =   2   lg  n          l  s     2   lg  n      l/s=2\lg n   small blocks it contains. The difference here is that it only needs     lg  l   =   lg    lg  2   n    =   2   lg   lg  n            lg  l    lg    superscript  lg  2   n           2   lg   lg  n        \lg l=\lg\lg^{2}n=2\lg\lg n   bits for each entry, since only the differences from the rank of the first bit in the containing large block need to be stored. Thus, this table takes a total of      (   n  /  s   )    lg  l    =   4  n   lg   lg   n  /   lg  n               n  s    lg  l      4  n   lg   lg    n   lg  n         (n/s)\lg l=4n\lg\lg n/\lg n   bits. A lookup table    R  p     subscript  R  p    R_{p}   can then be used that stores the answer to every possible rank query on a bit string of length   s   s   s   for    i  ∈   [  0  ,  s  )       i   0  s     i\in[0,s)   ; this requires      2  s   s   lg  s    =   O   (    n    lg   n   lg   lg  n       )           superscript  2  s   s   lg  s      O      n    lg    n   lg   lg  n          2^{s}s\lg s=O(\sqrt{n}\lg n\lg\lg n)   bits of storage space. Thus, since each of these auxiliary tables take    o   (  n  )       o  n    o(n)   space, this data structure supports rank queries in    O   (  1  )       O  1    O(1)   time and    n  +   o   (  n  )        n    o  n     n+o(n)   bits of space.  To answer a query for     𝐫𝐚𝐧𝐤  1    (  x  )        subscript  𝐫𝐚𝐧𝐤  1   x    \mathbf{rank}_{1}(x)   in constant time, a constant time algorithm computes:         𝐫𝐚𝐧𝐤  1    (  x  )    =     R  l    [   ⌊   x  /  l   ⌋   ]    +    R  s    [   ⌊   x  /  s   ⌋   ]    +    R  p    [   x   ⌊   x  /  s   ⌋    ,   x  mod  s   ]            subscript  𝐫𝐚𝐧𝐤  1   x        subscript  R  l    delimited-[]      x  l         subscript  R  s    delimited-[]      x  s         subscript  R  p      x      x  s       x  mod  s        \mathbf{rank}_{1}(x)=R_{l}[\lfloor x/l\rfloor]+R_{s}[\lfloor x/s\rfloor]+R_{p}%
 [x\lfloor x/s\rfloor,x\text{ mod }s]      In practice, the lookup table    R  p     subscript  R  p    R_{p}   can be replaced by bitwise operations and smaller tables to perform find the number of bits set in the small blocks. This is often beneficial, since succinct data structures find their uses in large data sets, in which case cache misses become much more frequent and the chances of the lookup table being evicted from closer CPU caches becomes higher. 5 Select queries can be easily supported by doing a binary search on the same auxiliary structure used for rank ; however, this takes    O   (   lg  n   )       O   lg  n     O(\lg n)   time in the worst case. A more complicated structure using       3  n   /   lg   lg  n     +   O   (    n    lg   n   lg   lg  n       )     =   o   (  n  )              3  n    lg   lg  n       O      n    lg    n   lg   lg  n           o  n     3n/\lg\lg n+O(\sqrt{n}\lg n\lg\lg n)=o(n)   bits of additional storage can be used to support select in constant time. 6 In practice, many of these solutions have hidden constants in the    O   (  ⋅  )       O  normal-⋅    O(\cdot)   notation which dominate before any asymptotic advantage becomes apparent; implementations using broadword operations and word-aligned blocks often perform better in practice. 7  Entropy-compressed dictionaries  The    n  +   o   (  n  )        n    o  n     n+o(n)   space approach can be improved by noting that there are    (      n      m      )     binomial  n  m    \textstyle{\left({{n}\atop{m}}\right)}   distinct   m   m   m   -subsets of    [  n  )     delimited-[)  n    [n)   (or binary strings of length   n   n   n   with exactly   m   m   m   1’s), and thus     ℬ   (  m  ,  n  )    =   ⌈   lg   (      n      m      )    ⌉         ℬ   m  n       lg   binomial  n  m       \textstyle\mathcal{B}(m,n)=\lceil\lg{\left({{n}\atop{m}}\right)}\rceil   is an information theoretic lower bound on the number of bits needed to store   B   B   B   . There is a succinct (static) dictionary which attains this bound, namely using     ℬ   (  m  ,  n  )    +   o   (   ℬ   (  m  ,  n  )    )          ℬ   m  n      o    ℬ   m  n       \mathcal{B}(m,n)+o(\mathcal{B}(m,n))   space. 8 This structure can be extended to support rank and select queries and takes     ℬ   (  m  ,  n  )    +   O   (   m  +   n   lg   lg   n  /   lg  n        )          ℬ   m  n      O    m    n   lg   lg    n   lg  n           \mathcal{B}(m,n)+O(m+n\lg\lg n/\lg n)   space. 9 This bound can be reduced to a space/time tradeoff by reducing the storage space of the dictionary to     ℬ   (  m  ,  n  )    +   O   (     n   t  t    /    lg  t   n    +   n   3  /  4     )          ℬ   m  n      O        n   superscript  t  t      superscript  lg  t   n     superscript  n    3  4        \mathcal{B}(m,n)+O(nt^{t}/\lg^{t}n+n^{3/4})   with queries taking    O   (  t  )       O  t    O(t)   time. 10  Examples  A null-terminated string ( C string ) takes Z + 1 space, and is thus implicit. A string with an arbitrary length ( Pascal string ) takes Z + log( Z ) space, and is thus succinct. If there is a maximum length – which is the case in practice, since 2 32 = 4 GiB of data is a very long string, and 2 64 = 16 EiB of data is larger than any string in practice – then a string with a length is also implicit, taking Z + k space, where k is the number of data to represent the maximum length (e.g., bytes in a word).  When a sequence of variable-length items (such as strings) needs to be encoded, there are various possibilities. A direct approach is to store a length and an item in each record – these can then be placed one after another. This allows efficient next, but not finding the k th item. An alternative is to place the items in order with a delimiter (e.g., null-terminated string ). This use a delimiter instead of a length, and is substantially slower, since the entire sequence must be scanned for delimiters. Both of these are space-efficient. An alternative approach is out-of-band separation: the items can simply be placed one after another, with no delimiters. Item bounds can then be stored as a sequence of length, or better, offsets into this sequence. Alternatively, a separate binary string consisting of 1s in the positions where an item begins, and 0s everywhere else is encoded along with it. Given this string, the    s  e  l  e  c  t      s  e  l  e  c  t    select   function can quickly determine where each item begins, given its index. 11 This is compact but not succinct, as it takes 2 Z space, which is O( Z ).  Another example is the representation of a binary tree : an arbitrary binary tree on   n   n   n   nodes can be represented in     2  n   +   o   (  n  )          2  n     o  n     2n+o(n)   bits while supporting a variety of operations on any node, which includes finding its parent, its left and right child, and returning the size of its subtree, each in constant time. The number of different binary trees on   n   n   n   nodes is    (       2  n       n      )     binomial    2  n   n    {{\textstyle\left({{2n}\atop{n}}\right)}}        /   (   n  +  1   )       absent    n  1     /(n+1)   . For large   n   n   n   , this is about    4  n     superscript  4  n    4^{n}   ; thus we need at least about      log  2    (   4  n   )    =   2  n         subscript   2    superscript  4  n      2  n     \log_{2}(4^{n})=2n   bits to encode it. A succinct binary tree therefore would occupy only   2   2   2   bits per node.  See also   Minimal perfect hash function   References   12  13  14  15  16  17  18  19  20   "  Category:Data structures               ↩  ↩  ↩  ↩  ↩  ↩  ↩  ↩  ↩  ↩     