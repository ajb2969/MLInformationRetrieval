   Multivariate stable distribution      Multivariate stable distribution   The multivariate stable distribution is a multivariate probability distribution that is a multivariate generalisation of the univariate stable distribution . The multivariate stable distribution defines linear relations between stable distribution marginals. In the same way as for the univariate case, the distribution is defined in terms of its characteristic function .  The multivariate stable distribution can also be thought as an extension of the multivariate normal distribution . It has parameter, Î± , which is defined over the range 0Â  \mathbb{S}  be the unit sphere in     â„  d   :   ğ•Š  =   {   u  âˆˆ   â„  d    :    |  u  |   =  1   }       normal-:   superscript  â„  d     ğ•Š   conditional-set    u   superscript  â„  d        u   1       \mathbb{R}^{d}:\mathbb{S}=\{u\in\mathbb{R}^{d}:|u|=1\}   . A random vector ,   X   X   X   , has a multivariate stable distribution - denoted as    X  âˆ¼   S   (  Î±  ,  Î›  ,  Î´  )       similar-to  X    S   Î±  normal-Î›  Î´      X\sim S(\alpha,\Lambda,\delta)   -, if the joint characteristic function of   X   X   X   is 1        E  exp    (    u  T   X   )    =   exp   {    -    âˆ«   s  âˆˆ  ğ•Š      {     |    u  T   s   |   Î±   +   i  Î½   (    u  T   s   ,  Î±  )     }   Î›   (   d  s   )      +   i   u  T   Î´    }          normal-E       superscript  u  T   X            subscript     s  ğ•Š          superscript       superscript  u  T   s    Î±     i  Î½      superscript  u  T   s   Î±      normal-Î›    d  s        i   superscript  u  T   Î´       \operatorname{E}\exp(u^{T}X)=\exp\left\{-\int\limits_{s\in\mathbb{S}}\left\{|u%
 ^{T}s|^{\alpha}+i\nu(u^{T}s,\alpha)\right\}\,\Lambda(ds)+iu^{T}\delta\right\}     where 0Â  y\in\mathbb R       Î½   (  y  ,  Î±  )    =   {      -   ğ¬ğ¢ğ ğ§   (  y  )    tan   (    Ï€  Î±   /  2   )      |  y  |   Î±         Î±  â‰   1   ,         (   2  /  Ï€   )   y   ln   |  y  |        Î±  =  1.             Î½   y  Î±     cases      ğ¬ğ¢ğ ğ§  y        Ï€  Î±   2     superscript    y   Î±       Î±  1       2  Ï€   y      y       Î±  1.      \nu(y,\alpha)=\begin{cases}-\mathbf{sign}(y)\tan(\pi\alpha/2)|y|^{\alpha}&%
 \alpha\neq 1,\\
 (2/\pi)y\ln|y|&\alpha=1.\end{cases}     This is essentially the result of Feldheim, 2 that any stable random vector can be characterized by a spectral measure   Î›   normal-Î›   \Lambda   (a finite measure on   ğ•Š   ğ•Š   \mathbb{S}   ) and a shift vector    Î´  âˆˆ   â„  d       Î´   superscript  â„  d     \delta\in\mathbb{R}^{d}   .  Parametrization using projections  Another way to describe a stable random vector is in terms of projections. For any vector   u   u   u   , the projection     u  T   X       superscript  u  T   X    u^{T}X   is univariate    Î±  -     limit-from  Î±     \alpha-   stable with some skewness    Î²   (  u  )       Î²  u    \beta(u)   , scale    Î³   (  u  )       Î³  u    \gamma(u)   and some shift    Î´   (  u  )       Î´  u    \delta(u)   . The notation    X  âˆ¼   S   (  Î±  ,   Î²   (  â‹…  )    ,   Î³   (  â‹…  )    ,   Î´   (  â‹…  )    )       similar-to  X    S   Î±    Î²  normal-â‹…     Î³  normal-â‹…     Î´  normal-â‹…       X\sim S(\alpha,\beta(\cdot),\gamma(\cdot),\delta(\cdot))   is used if X is stable with      u  T   X   âˆ¼   s   (  Î±  ,   Î²   (  â‹…  )    ,   Î³   (  â‹…  )    ,   Î´   (  â‹…  )    )       similar-to     superscript  u  T   X     s   Î±    Î²  normal-â‹…     Î³  normal-â‹…     Î´  normal-â‹…       u^{T}X\sim s(\alpha,\beta(\cdot),\gamma(\cdot),\delta(\cdot))   for every    u  âˆˆ   â„  d       u   superscript  â„  d     u\in\mathbb{R}^{d}   . This is called the projection parameterization.  The spectral measure determines the projection parameter functions by:       Î³   (  u  )    =    âˆ«   s  âˆˆ  ğ•Š       |    u  T   s   |   Î±   Î›   (   d  s   )           Î³  u     subscript     s  ğ•Š       superscript       superscript  u  T   s    Î±   normal-Î›    d  s       \gamma(u)=\int_{s\in\mathbb{S}}|u^{T}s|^{\alpha}\Lambda(ds)          Î²   (  u  )    =    âˆ«   s  âˆˆ  ğ•Š       |    u  T   s   |   Î±   ğ¬ğ¢ğ ğ§   (    u  T   s   )   Î›   (   d  s   )           Î²  u     subscript     s  ğ•Š       superscript       superscript  u  T   s    Î±   ğ¬ğ¢ğ ğ§     superscript  u  T   s   normal-Î›    d  s       \beta(u)=\int_{s\in\mathbb{S}}|u^{T}s|^{\alpha}\mathbf{sign}(u^{T}s)\Lambda(ds)          Î´   (  u  )    =   {       u  T   Î´      Î±  â‰   1          u  T   Î´   -     âˆ«   s  âˆˆ  ğ•Š        Ï€  2     u  T   s   ln    |    u  T   s   |   Î›     (   d  s   )         Î±  =  1             Î´  u    cases     superscript  u  T   Î´     Î±  1        superscript  u  T   Î´     subscript     s  ğ•Š        Ï€  2    superscript  u  T   s           superscript  u  T   s    normal-Î›      d  s        Î±  1      \delta(u)=\begin{cases}u^{T}\delta&\alpha\neq 1\\
 u^{T}\delta-\int_{s\in\mathbb{S}}\tfrac{\pi}{2}u^{T}s\ln|u^{T}s|\Lambda(ds)&%
 \alpha=1\end{cases}     Special cases  There are special cases where the multivariate characteristic function takes a simpler form. Define the characteristic function of a stable marginal as      Ï‰   (  y  |  Î±  ,  Î²  )   =   {        |  y  |   Î±    [   1  -   i  Î²   (   tan     Ï€  Î±   2     )   ğ¬ğ¢ğ ğ§   (  y  )     ]       Î±  â‰   1         |  y  |    [   1  +   i  Î²    2  Ï€    ğ¬ğ¢ğ ğ§   (  y  )    ln   |  y  |      ]       Î±  =  1          fragments  Ï‰   fragments  normal-(  y  normal-|  Î±  normal-,  Î²  normal-)     cases     superscript    y   Î±    delimited-[]    1    i  Î²        Ï€  Î±   2    ğ¬ğ¢ğ ğ§  y        Î±  1       y    delimited-[]    1    i  Î²    2  Ï€   ğ¬ğ¢ğ ğ§  y      y          Î±  1      \omega(y|\alpha,\beta)=\begin{cases}|y|^{\alpha}\left[1-i\beta(\tan\tfrac{\pi%
 \alpha}{2})\mathbf{sign}(y)\right]&\alpha\neq 1\\
 |y|\left[1+i\beta\tfrac{2}{\pi}\mathbf{sign}(y)\ln|y|\right]&\alpha=1\end{cases}     Isotropic multivariate stable distribution  The characteristic function is    E  exp   (  i   u  T   X  )   =  exp   {  -   Î³  0   |  u   |  Î±   +  i   u  T   Î´  )   }     fragments  E    fragments  normal-(  i   superscript  u  T   X  normal-)      fragments  normal-{    subscript  Î³  0   normal-|  u   superscript  normal-|  Î±    i   superscript  u  T   Î´  normal-)   normal-}    E\exp(iu^{T}X)=\exp\{-\gamma_{0}|u|^{\alpha}+iu^{T}\delta)\}   The spectral measure is continuous and uniform, leading to radial/isotropic symmetry. 3 For the multinormal case    Î±  =  2      Î±  2    \alpha=2   , this corresponds to independent components, but so is not the case when    Î±  =  2      Î±  2    \alpha=2   . Isotropy is a special case of ellipticity (see the next paragraph) â€“ just take   Î£   normal-Î£   \Sigma   to be a multiple of the identity matrix.  Elliptically contoured multivariate stable distribution  Elliptically contoured m.v. stable distribution is a special symmetric case of the multivariate stable distribution. If X is Î± -stable and elliptically contoured, then it has joint characteristic function     E  exp   (  i   u  T   X  )   =  exp   {  -    (   u  T   Î£  u  )    Î±  /  2    +  i   u  T   Î´  )   }     fragments  E    fragments  normal-(  i   superscript  u  T   X  normal-)      fragments  normal-{    superscript   fragments  normal-(   superscript  u  T   Î£  u  normal-)     Î±  2     i   superscript  u  T   Î´  normal-)   normal-}    E\exp(iu^{T}X)=\exp\{-(u^{T}\Sigma u)^{\alpha/2}+iu^{T}\delta)\}   for some shift vector    Î´  âˆˆ   R  d       Î´   superscript  R  d     \delta\in R^{d}   (equal to the mean when it exists) and some positive definite matrix   Î£   normal-Î£   \Sigma   (akin to a correlation matrix, although the usual definition of correlation fails to be meaningful). Note the relation to characteristic function of the multivariate normal distribution     E  exp   (  i   u  T   X  )   =  exp   {  -   (   u  T   Î£  u  )   +  i   u  T   Î´  )   }     fragments  E    fragments  normal-(  i   superscript  u  T   X  normal-)      fragments  normal-{    fragments  normal-(   superscript  u  T   Î£  u  normal-)    i   superscript  u  T   Î´  normal-)   normal-}    E\exp(iu^{T}X)=\exp\{-(u^{T}\Sigma u)+iu^{T}\delta)\}   obtained when Î± =Â 2.  Independent components  The marginals are independent with     X  j   âˆ¼   S   (  Î±  ,   Î²  j   ,   Î³  j   ,   Î´  j   )       similar-to   subscript  X  j     S   Î±   subscript  Î²  j    subscript  Î³  j    subscript  Î´  j       X_{j}\sim S(\alpha,\beta_{j},\gamma_{j},\delta_{j})   , then the characteristic function is      E  exp   (  i   u  T   X  )   =  exp   {  -   âˆ‘   j  =  1   m   Ï‰   (   u  j   |  Î±  ,   Î²  j   )    Î³  j  Î±   +  i   u  T   Î´  )   }     fragments  E    fragments  normal-(  i   superscript  u  T   X  normal-)      fragments  normal-{    superscript   subscript     j  1    m   Ï‰   fragments  normal-(   subscript  u  j   normal-|  Î±  normal-,   subscript  Î²  j   normal-)    superscript   subscript  Î³  j   Î±    i   superscript  u  T   Î´  normal-)   normal-}    E\exp(iu^{T}X)=\exp\left\{-\sum_{j=1}^{m}\omega(u_{j}|\alpha,\beta_{j})\gamma_%
 {j}^{\alpha}+iu^{T}\delta)\right\}   Observe that when Î± =Â 2 this reduces again to the multivariate normal; note that the iid case and the isotropic case do not coincide when Î±  Heatmap showing a multivariate (bivariate) independent stable distribution with Î± =Â 1 || |  Heatmap showing a multivariate (bivariate) independent stable distribution with Î± =Â 2 . |}  Discrete  If the spectral measure is discrete with mass    Î»  j     subscript  Î»  j    \lambda_{j}   at      s  j   âˆˆ  ğ•Š   ,   j  =   1  ,  â€¦  ,  m       formulae-sequence     subscript  s  j   ğ•Š     j   1  normal-â€¦  m      s_{j}\in\mathbb{S},j=1,\ldots,m   the characteristic function is      E  exp   (  i   u  T   X  )   =  exp   {  -   âˆ‘   j  =  1   m   Ï‰   (   u  T    s  j   |  Î±  ,  1  )    Î³  j  Î±   +  i   u  T   Î´  )   }     fragments  E    fragments  normal-(  i   superscript  u  T   X  normal-)      fragments  normal-{    superscript   subscript     j  1    m   Ï‰   fragments  normal-(   superscript  u  T    subscript  s  j   normal-|  Î±  normal-,  1  normal-)    superscript   subscript  Î³  j   Î±    i   superscript  u  T   Î´  normal-)   normal-}    E\exp(iu^{T}X)=\exp\left\{-\sum_{j=1}^{m}\omega(u^{T}s_{j}|\alpha,1)\gamma_{j}%
 ^{\alpha}+iu^{T}\delta)\right\}     Linear properties  if    X  âˆ¼   S   (  Î±  ,   Î²   (  â‹…  )    ,   Î³   (  â‹…  )    ,   Î´   (  â‹…  )    )       similar-to  X    S   Î±    Î²  normal-â‹…     Î³  normal-â‹…     Î´  normal-â‹…       X\sim S(\alpha,\beta(\cdot),\gamma(\cdot),\delta(\cdot))   is d-dim, and A is a m x d matrix,    b  âˆˆ   â„  m       b   superscript  â„  m     b\in\mathbb{R}^{m}   then AX + b is m dim.   Î±   Î±   \alpha   -stable with scale function    Î³   (   A  T   â‹…  )      fragments  Î³   fragments  normal-(   superscript  A  T   normal-â‹…  normal-)     \gamma(A^{T}\cdot)   , skewness function    Î²   (   A  T   â‹…  )      fragments  Î²   fragments  normal-(   superscript  A  T   normal-â‹…  normal-)     \beta(A^{T}\cdot)   , and location function    Î´   (   A  T   â‹…  )   +   b  T   â‹…     fragments  Î´   fragments  normal-(   superscript  A  T   normal-â‹…  normal-)     superscript  b  T   normal-â‹…    \delta(A^{T}\cdot)+b^{T}\cdot     Inference in the independent component model  Recently 4 it was shown how to compute inference in closed-form in a linear model (or equivalently a factor analysis model),involving independent component models.  More specifically, let      X  i   âˆ¼   S   (  Î±  ,   Î²   x  i    ,   Î³   x  i    ,   Î´   x  i    )     ,   i  =   1  ,  â€¦  ,  n       formulae-sequence   similar-to   subscript  X  i     S   Î±   subscript  Î²   subscript  x  i     subscript  Î³   subscript  x  i     subscript  Î´   subscript  x  i         i   1  normal-â€¦  n      X_{i}\sim S(\alpha,\beta_{x_{i}},\gamma_{x_{i}},\delta_{x_{i}}),i=1,\ldots,n   be a set of i.i.d. unobserved univariate drawn from a stable distribution . Given a known linear relation matrix A of size    n  Ã—  n      n  n    n\times n   , the observation     Y  i   =    âˆ‘   i  =  1   n     A   i  j     X  j          subscript  Y  i     superscript   subscript     i  1    n      subscript  A    i  j     subscript  X  j       Y_{i}=\sum_{i=1}^{n}A_{ij}X_{j}   are assumed to be distributed as a convolution of the hidden factors    X  i     subscript  X  i    X_{i}   .     Y  i   =   S   (  Î±  ,   Î²   y  i    ,   Î³   y  i    ,   Î´   y  i    )         subscript  Y  i     S   Î±   subscript  Î²   subscript  y  i     subscript  Î³   subscript  y  i     subscript  Î´   subscript  y  i        Y_{i}=S(\alpha,\beta_{y_{i}},\gamma_{y_{i}},\delta_{y_{i}})   . The inference task is to compute the most probable    X  i     subscript  X  i    X_{i}   , given the linear relation matrix A and the observations    Y  i     subscript  Y  i    Y_{i}   . This task can be computed in closed-form inÂ O( n 3 ).  An application for this construction is multiuser detection with stable, non-Gaussian noise.  Resources   Mark Veillette's stable distribution matlab package http://www.mathworks.com/matlabcentral/fileexchange/37514  The plots in this page where plotted using Danny Bickson's inference in linear-stable model Matlab package: http://www.cs.cmu.edu/~bickson/stable   Notes  "  Category:Multivariate continuous distributions  Category:Probability distributions with non-finite variance  Category:Probability distributions     J. Nolan, Multivariate stable densities and distribution functions: general and elliptical case, BundesBank Conference, Eltville, Germany, 11 November 2005. See also http://academic2.american.edu/~jpnolan/stable/stable.html â†©  Feldheim, E. (1937). Etude de la stabilitÃ© des lois de probabilitÃ© . Ph. D. thesis, FacultÃ© des Sciences de Paris, Paris, France. â†©  User manual for STABLE 5.1 Matlab version, Robust Analysis Inc., http://www.RobustAnalysis.com â†©  D. Bickson and C. Guestrin. Inference in linear models with multivariate heavy-tails. In Neural Information Processing Systems (NIPS) 2010, Vancouver, Canada, Dec. 2010. http://www.cs.cmu.edu/~bickson/stable/ â†©     