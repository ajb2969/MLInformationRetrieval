   Multivariate stable distribution      Multivariate stable distribution   The multivariate stable distribution is a multivariate probability distribution that is a multivariate generalisation of the univariate stable distribution . The multivariate stable distribution defines linear relations between stable distribution marginals. In the same way as for the univariate case, the distribution is defined in terms of its characteristic function .  The multivariate stable distribution can also be thought as an extension of the multivariate normal distribution . It has parameter, α , which is defined over the range 0  \mathbb{S}  be the unit sphere in     ℝ  d   :   𝕊  =   {   u  ∈   ℝ  d    :    |  u  |   =  1   }       normal-:   superscript  ℝ  d     𝕊   conditional-set    u   superscript  ℝ  d        u   1       \mathbb{R}^{d}:\mathbb{S}=\{u\in\mathbb{R}^{d}:|u|=1\}   . A random vector ,   X   X   X   , has a multivariate stable distribution - denoted as    X  ∼   S   (  α  ,  Λ  ,  δ  )       similar-to  X    S   α  normal-Λ  δ      X\sim S(\alpha,\Lambda,\delta)   -, if the joint characteristic function of   X   X   X   is 1        E  exp    (    u  T   X   )    =   exp   {    -    ∫   s  ∈  𝕊      {     |    u  T   s   |   α   +   i  ν   (    u  T   s   ,  α  )     }   Λ   (   d  s   )      +   i   u  T   δ    }          normal-E       superscript  u  T   X            subscript     s  𝕊          superscript       superscript  u  T   s    α     i  ν      superscript  u  T   s   α      normal-Λ    d  s        i   superscript  u  T   δ       \operatorname{E}\exp(u^{T}X)=\exp\left\{-\int\limits_{s\in\mathbb{S}}\left\{|u%
 ^{T}s|^{\alpha}+i\nu(u^{T}s,\alpha)\right\}\,\Lambda(ds)+iu^{T}\delta\right\}     where 0  y\in\mathbb R       ν   (  y  ,  α  )    =   {      -   𝐬𝐢𝐠𝐧   (  y  )    tan   (    π  α   /  2   )      |  y  |   α         α  ≠  1   ,         (   2  /  π   )   y   ln   |  y  |        α  =  1.             ν   y  α     cases      𝐬𝐢𝐠𝐧  y        π  α   2     superscript    y   α       α  1       2  π   y      y       α  1.      \nu(y,\alpha)=\begin{cases}-\mathbf{sign}(y)\tan(\pi\alpha/2)|y|^{\alpha}&%
 \alpha\neq 1,\\
 (2/\pi)y\ln|y|&\alpha=1.\end{cases}     This is essentially the result of Feldheim, 2 that any stable random vector can be characterized by a spectral measure   Λ   normal-Λ   \Lambda   (a finite measure on   𝕊   𝕊   \mathbb{S}   ) and a shift vector    δ  ∈   ℝ  d       δ   superscript  ℝ  d     \delta\in\mathbb{R}^{d}   .  Parametrization using projections  Another way to describe a stable random vector is in terms of projections. For any vector   u   u   u   , the projection     u  T   X       superscript  u  T   X    u^{T}X   is univariate    α  -     limit-from  α     \alpha-   stable with some skewness    β   (  u  )       β  u    \beta(u)   , scale    γ   (  u  )       γ  u    \gamma(u)   and some shift    δ   (  u  )       δ  u    \delta(u)   . The notation    X  ∼   S   (  α  ,   β   (  ⋅  )    ,   γ   (  ⋅  )    ,   δ   (  ⋅  )    )       similar-to  X    S   α    β  normal-⋅     γ  normal-⋅     δ  normal-⋅       X\sim S(\alpha,\beta(\cdot),\gamma(\cdot),\delta(\cdot))   is used if X is stable with      u  T   X   ∼   s   (  α  ,   β   (  ⋅  )    ,   γ   (  ⋅  )    ,   δ   (  ⋅  )    )       similar-to     superscript  u  T   X     s   α    β  normal-⋅     γ  normal-⋅     δ  normal-⋅       u^{T}X\sim s(\alpha,\beta(\cdot),\gamma(\cdot),\delta(\cdot))   for every    u  ∈   ℝ  d       u   superscript  ℝ  d     u\in\mathbb{R}^{d}   . This is called the projection parameterization.  The spectral measure determines the projection parameter functions by:       γ   (  u  )    =    ∫   s  ∈  𝕊       |    u  T   s   |   α   Λ   (   d  s   )           γ  u     subscript     s  𝕊       superscript       superscript  u  T   s    α   normal-Λ    d  s       \gamma(u)=\int_{s\in\mathbb{S}}|u^{T}s|^{\alpha}\Lambda(ds)          β   (  u  )    =    ∫   s  ∈  𝕊       |    u  T   s   |   α   𝐬𝐢𝐠𝐧   (    u  T   s   )   Λ   (   d  s   )           β  u     subscript     s  𝕊       superscript       superscript  u  T   s    α   𝐬𝐢𝐠𝐧     superscript  u  T   s   normal-Λ    d  s       \beta(u)=\int_{s\in\mathbb{S}}|u^{T}s|^{\alpha}\mathbf{sign}(u^{T}s)\Lambda(ds)          δ   (  u  )    =   {       u  T   δ      α  ≠  1          u  T   δ   -     ∫   s  ∈  𝕊        π  2     u  T   s   ln    |    u  T   s   |   Λ     (   d  s   )         α  =  1             δ  u    cases     superscript  u  T   δ     α  1        superscript  u  T   δ     subscript     s  𝕊        π  2    superscript  u  T   s           superscript  u  T   s    normal-Λ      d  s        α  1      \delta(u)=\begin{cases}u^{T}\delta&\alpha\neq 1\\
 u^{T}\delta-\int_{s\in\mathbb{S}}\tfrac{\pi}{2}u^{T}s\ln|u^{T}s|\Lambda(ds)&%
 \alpha=1\end{cases}     Special cases  There are special cases where the multivariate characteristic function takes a simpler form. Define the characteristic function of a stable marginal as      ω   (  y  |  α  ,  β  )   =   {        |  y  |   α    [   1  -   i  β   (   tan     π  α   2     )   𝐬𝐢𝐠𝐧   (  y  )     ]       α  ≠  1         |  y  |    [   1  +   i  β    2  π    𝐬𝐢𝐠𝐧   (  y  )    ln   |  y  |      ]       α  =  1          fragments  ω   fragments  normal-(  y  normal-|  α  normal-,  β  normal-)     cases     superscript    y   α    delimited-[]    1    i  β        π  α   2    𝐬𝐢𝐠𝐧  y        α  1       y    delimited-[]    1    i  β    2  π   𝐬𝐢𝐠𝐧  y      y          α  1      \omega(y|\alpha,\beta)=\begin{cases}|y|^{\alpha}\left[1-i\beta(\tan\tfrac{\pi%
 \alpha}{2})\mathbf{sign}(y)\right]&\alpha\neq 1\\
 |y|\left[1+i\beta\tfrac{2}{\pi}\mathbf{sign}(y)\ln|y|\right]&\alpha=1\end{cases}     Isotropic multivariate stable distribution  The characteristic function is    E  exp   (  i   u  T   X  )   =  exp   {  -   γ  0   |  u   |  α   +  i   u  T   δ  )   }     fragments  E    fragments  normal-(  i   superscript  u  T   X  normal-)      fragments  normal-{    subscript  γ  0   normal-|  u   superscript  normal-|  α    i   superscript  u  T   δ  normal-)   normal-}    E\exp(iu^{T}X)=\exp\{-\gamma_{0}|u|^{\alpha}+iu^{T}\delta)\}   The spectral measure is continuous and uniform, leading to radial/isotropic symmetry. 3 For the multinormal case    α  =  2      α  2    \alpha=2   , this corresponds to independent components, but so is not the case when    α  =  2      α  2    \alpha=2   . Isotropy is a special case of ellipticity (see the next paragraph) – just take   Σ   normal-Σ   \Sigma   to be a multiple of the identity matrix.  Elliptically contoured multivariate stable distribution  Elliptically contoured m.v. stable distribution is a special symmetric case of the multivariate stable distribution. If X is α -stable and elliptically contoured, then it has joint characteristic function     E  exp   (  i   u  T   X  )   =  exp   {  -    (   u  T   Σ  u  )    α  /  2    +  i   u  T   δ  )   }     fragments  E    fragments  normal-(  i   superscript  u  T   X  normal-)      fragments  normal-{    superscript   fragments  normal-(   superscript  u  T   Σ  u  normal-)     α  2     i   superscript  u  T   δ  normal-)   normal-}    E\exp(iu^{T}X)=\exp\{-(u^{T}\Sigma u)^{\alpha/2}+iu^{T}\delta)\}   for some shift vector    δ  ∈   R  d       δ   superscript  R  d     \delta\in R^{d}   (equal to the mean when it exists) and some positive definite matrix   Σ   normal-Σ   \Sigma   (akin to a correlation matrix, although the usual definition of correlation fails to be meaningful). Note the relation to characteristic function of the multivariate normal distribution     E  exp   (  i   u  T   X  )   =  exp   {  -   (   u  T   Σ  u  )   +  i   u  T   δ  )   }     fragments  E    fragments  normal-(  i   superscript  u  T   X  normal-)      fragments  normal-{    fragments  normal-(   superscript  u  T   Σ  u  normal-)    i   superscript  u  T   δ  normal-)   normal-}    E\exp(iu^{T}X)=\exp\{-(u^{T}\Sigma u)+iu^{T}\delta)\}   obtained when α = 2.  Independent components  The marginals are independent with     X  j   ∼   S   (  α  ,   β  j   ,   γ  j   ,   δ  j   )       similar-to   subscript  X  j     S   α   subscript  β  j    subscript  γ  j    subscript  δ  j       X_{j}\sim S(\alpha,\beta_{j},\gamma_{j},\delta_{j})   , then the characteristic function is      E  exp   (  i   u  T   X  )   =  exp   {  -   ∑   j  =  1   m   ω   (   u  j   |  α  ,   β  j   )    γ  j  α   +  i   u  T   δ  )   }     fragments  E    fragments  normal-(  i   superscript  u  T   X  normal-)      fragments  normal-{    superscript   subscript     j  1    m   ω   fragments  normal-(   subscript  u  j   normal-|  α  normal-,   subscript  β  j   normal-)    superscript   subscript  γ  j   α    i   superscript  u  T   δ  normal-)   normal-}    E\exp(iu^{T}X)=\exp\left\{-\sum_{j=1}^{m}\omega(u_{j}|\alpha,\beta_{j})\gamma_%
 {j}^{\alpha}+iu^{T}\delta)\right\}   Observe that when α = 2 this reduces again to the multivariate normal; note that the iid case and the isotropic case do not coincide when α  Heatmap showing a multivariate (bivariate) independent stable distribution with α = 1 || |  Heatmap showing a multivariate (bivariate) independent stable distribution with α = 2 . |}  Discrete  If the spectral measure is discrete with mass    λ  j     subscript  λ  j    \lambda_{j}   at      s  j   ∈  𝕊   ,   j  =   1  ,  …  ,  m       formulae-sequence     subscript  s  j   𝕊     j   1  normal-…  m      s_{j}\in\mathbb{S},j=1,\ldots,m   the characteristic function is      E  exp   (  i   u  T   X  )   =  exp   {  -   ∑   j  =  1   m   ω   (   u  T    s  j   |  α  ,  1  )    γ  j  α   +  i   u  T   δ  )   }     fragments  E    fragments  normal-(  i   superscript  u  T   X  normal-)      fragments  normal-{    superscript   subscript     j  1    m   ω   fragments  normal-(   superscript  u  T    subscript  s  j   normal-|  α  normal-,  1  normal-)    superscript   subscript  γ  j   α    i   superscript  u  T   δ  normal-)   normal-}    E\exp(iu^{T}X)=\exp\left\{-\sum_{j=1}^{m}\omega(u^{T}s_{j}|\alpha,1)\gamma_{j}%
 ^{\alpha}+iu^{T}\delta)\right\}     Linear properties  if    X  ∼   S   (  α  ,   β   (  ⋅  )    ,   γ   (  ⋅  )    ,   δ   (  ⋅  )    )       similar-to  X    S   α    β  normal-⋅     γ  normal-⋅     δ  normal-⋅       X\sim S(\alpha,\beta(\cdot),\gamma(\cdot),\delta(\cdot))   is d-dim, and A is a m x d matrix,    b  ∈   ℝ  m       b   superscript  ℝ  m     b\in\mathbb{R}^{m}   then AX + b is m dim.   α   α   \alpha   -stable with scale function    γ   (   A  T   ⋅  )      fragments  γ   fragments  normal-(   superscript  A  T   normal-⋅  normal-)     \gamma(A^{T}\cdot)   , skewness function    β   (   A  T   ⋅  )      fragments  β   fragments  normal-(   superscript  A  T   normal-⋅  normal-)     \beta(A^{T}\cdot)   , and location function    δ   (   A  T   ⋅  )   +   b  T   ⋅     fragments  δ   fragments  normal-(   superscript  A  T   normal-⋅  normal-)     superscript  b  T   normal-⋅    \delta(A^{T}\cdot)+b^{T}\cdot     Inference in the independent component model  Recently 4 it was shown how to compute inference in closed-form in a linear model (or equivalently a factor analysis model),involving independent component models.  More specifically, let      X  i   ∼   S   (  α  ,   β   x  i    ,   γ   x  i    ,   δ   x  i    )     ,   i  =   1  ,  …  ,  n       formulae-sequence   similar-to   subscript  X  i     S   α   subscript  β   subscript  x  i     subscript  γ   subscript  x  i     subscript  δ   subscript  x  i         i   1  normal-…  n      X_{i}\sim S(\alpha,\beta_{x_{i}},\gamma_{x_{i}},\delta_{x_{i}}),i=1,\ldots,n   be a set of i.i.d. unobserved univariate drawn from a stable distribution . Given a known linear relation matrix A of size    n  ×  n      n  n    n\times n   , the observation     Y  i   =    ∑   i  =  1   n     A   i  j     X  j          subscript  Y  i     superscript   subscript     i  1    n      subscript  A    i  j     subscript  X  j       Y_{i}=\sum_{i=1}^{n}A_{ij}X_{j}   are assumed to be distributed as a convolution of the hidden factors    X  i     subscript  X  i    X_{i}   .     Y  i   =   S   (  α  ,   β   y  i    ,   γ   y  i    ,   δ   y  i    )         subscript  Y  i     S   α   subscript  β   subscript  y  i     subscript  γ   subscript  y  i     subscript  δ   subscript  y  i        Y_{i}=S(\alpha,\beta_{y_{i}},\gamma_{y_{i}},\delta_{y_{i}})   . The inference task is to compute the most probable    X  i     subscript  X  i    X_{i}   , given the linear relation matrix A and the observations    Y  i     subscript  Y  i    Y_{i}   . This task can be computed in closed-form in O( n 3 ).  An application for this construction is multiuser detection with stable, non-Gaussian noise.  Resources   Mark Veillette's stable distribution matlab package http://www.mathworks.com/matlabcentral/fileexchange/37514  The plots in this page where plotted using Danny Bickson's inference in linear-stable model Matlab package: http://www.cs.cmu.edu/~bickson/stable   Notes  "  Category:Multivariate continuous distributions  Category:Probability distributions with non-finite variance  Category:Probability distributions     J. Nolan, Multivariate stable densities and distribution functions: general and elliptical case, BundesBank Conference, Eltville, Germany, 11 November 2005. See also http://academic2.american.edu/~jpnolan/stable/stable.html ↩  Feldheim, E. (1937). Etude de la stabilité des lois de probabilité . Ph. D. thesis, Faculté des Sciences de Paris, Paris, France. ↩  User manual for STABLE 5.1 Matlab version, Robust Analysis Inc., http://www.RobustAnalysis.com ↩  D. Bickson and C. Guestrin. Inference in linear models with multivariate heavy-tails. In Neural Information Processing Systems (NIPS) 2010, Vancouver, Canada, Dec. 2010. http://www.cs.cmu.edu/~bickson/stable/ ↩     