


Kuder–Richardson Formula 20




Kuder–Richardson Formula 20

In statistics, the Kuder–Richardson Formula 20 (KR-20) first published in 19371 is a measure of internal consistency reliability for measures with dichotomous choices. It is analogous to Cronbach's α, except Cronbach's α is also used for non-dichotomous (continuous) measures.2 It is often claimed that a high KR-20 coefficient (e.g., > 0.90) indicates a homogeneous test. However, like Cronbach's α, homogeneity (that is, unidimensionality) is actually an assumption, not a conclusion, of reliability coefficients. It is possible, for example, to have a high KR-20 with a multidimensional scale, especially with a large number of items.
Values can range from 0.00 to 1.00 (sometimes expressed as 0 to 100), with high values indicating that the examination is likely to correlate with alternate forms (a desirable characteristic). The KR-20 may be affected by difficulty of the test, the spread in scores and the length of the examination.
In the case when scores are not tau-equivalent (for example when there is not homogeneous but rather examination items of increasing difficulty) then the KR-20 is an indication of the lower bound of internal consistency (reliability).
The formula for KR-20 for a test with K test items numbered i=1 to K is



where pi is the proportion of correct responses to test item i, qi is the proportion of incorrect responses to test item i (so that pi + qi = 1), and the variance for the denominator is



where n is the total sample size.
If it is important to use unbiased operators then the sum of squares should be divided by degrees of freedom (n − 1) and the probabilities are multiplied by



Since Cronbach's α was published in 1951, there has been no known advantage to KR-20 over Cronbach. KR-20 is seen as a derivative of the Cronbach formula, with the advantage to Cronbach that it can handle both dichotomous and continuous variables. The KR-20 formula can't be used when multiple-choice questions involve partial credit, and it requires detailed item analysis.3
References
External links

Statistical analysis of multiple choice exams
Quality of assessment chapter in Illinois State Assessment handbook (1995)

"
Category:Comparison of assessments Category:Psychometrics Category:Educational psychology research methods



Kuder, G. F., & Richardson, M. W. (1937). The theory of the estimation of test reliability. Psychometrika, 2(3), 151–160.↩
Cortina, J. M., (1993). What Is Coefficient Alpha? An Examination of Theory and Applications. Journal of Applied Psychology, 78(1), 98–104.↩
http://chemed.chem.purdue.edu/chemed/stats.html (as of 3/27/2013↩




