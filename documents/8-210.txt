   Statistical signal processing      Statistical signal processing   Statistical signal processing is an area of Applied Mathematics and Signal Processing that treats signals as stochastic processes , dealing with their statistical properties (e.g., mean , covariance , etc.). Because of its very broad range of application Statistical signal processing is taught at the graduate level in either Electrical Engineering , Applied Mathematics , Pure Mathematics / Statistics , or even Biomedical Engineering and Physics departments around the world, although important applications exist in almost all scientific fields.  Basic Signal Model  In many applications, a signal is modeled as functions consisting of both a deterministic and a stochastic component. A simple example and also a common model of many statistical systems is a signal    y   (  t  )       y  t    y(t)   that consists of a deterministic part    x   (  t  )       x  t    x(t)   added to noise which can be modeled in many situations as white Gaussian noise     w   (  t  )       w  t    w(t)   :       y   (  t  )    =    x   (  t  )    +   w   (  t  )           y  t       x  t     w  t      y(t)=x(t)+w(t)\,     where       w   (  t  )    ‚àº   ùí©   (  0  ,   œÉ  2   )       similar-to    w  t     ùí©   0   superscript  œÉ  2       w(t)\sim\mathcal{N}(0,\sigma^{2})     White noise simply means that the noise process is completely uncorrelated. As a result, its autocorrelation function is an impulse :        R   w  w     (  œÑ  )    =    œÉ  2   Œ¥   (  œÑ  )           subscript  R    w  w    œÑ      superscript  œÉ  2   Œ¥  œÑ     R_{ww}(\tau)=\sigma^{2}\delta(\tau)\,     where      Œ¥   (  œÑ  )       Œ¥  œÑ    \delta(\tau)\,   is the Dirac delta function .  Given information about a statistical system and the random variable from which it is derived, we can increase our knowledge of the output signal; conversely, given the statistical properties of the output signal, we can infer the properties of the underlying random variable. These statistical techniques are developed in the fields of estimation theory , detection theory , and numerous related fields that rely on statistical information to maximize their efficiency.  Example  The Computation of Average Transients (CAT) is used routinely in FT- NMR spectroscopy ( nuclear magnetic resonance ) to improve the signal-noise ratio of nmr spectra. The signal is measured repeatedly n times and then averaged.       y  ¬Ø   =    1  n     ‚àë  i    y    (  t  )   i      =    x   (  t  )    +    1  n     ‚àë  i    w    (  t  )   i              normal-¬Ø  y       1  n     subscript   i     y   subscript  t  i               x  t       1  n     subscript   i     w   subscript  t  i          \bar{y}=\frac{1}{n}\sum_{i}y(t)_{i}=x(t)+\frac{1}{n}\sum_{i}w(t)_{i}   Assuming that the noise is white and that its variance is constant in time it follows by error propagation that       œÉ   (   y  ¬Ø   )    =    1   n    œÉ         œÉ   normal-¬Ø  y        1    n    œÉ     \sigma(\bar{y})=\frac{1}{\sqrt{n}}\sigma   Thus, if 10,000 measurements are averaged the signal to noise ratio is increased by a factor of 100, enabling the measurement of 13 C NMR spectra at natural abundance (1.1%) of 13 C.  See also   Wiener filter  Kalman filter  Particle filter   Further reading        Kainam Thomas Wong 1 : Statistical Signal Processing lecture notes at the University of Waterloo, Canada.    Ali H. Sayed , Adaptive Filters, Wiley, NJ, 2008, ISBN 978-0-470-25388-5.  Thomas Kailath , Ali H. Sayed , and Babak Hassibi , Linear Estimation, Prentice-Hall, NJ, 2000, ISBN 978-0-13-022464-4.   "  Category:Signal processing  Category:Time series analysis   