   Empirical measure      Empirical measure   In probability theory , an empirical measure is a random measure arising from a particular realization of a (usually finite) sequence of random variables . The precise definition is found below. Empirical measures are relevant to mathematical statistics .  The motivation for studying empirical measures is that it is often impossible to know the true underlying probability measure    P   P   P   . We collect observations     X  1   ,   X  2   ,  …  ,   X  n       subscript  X  1    subscript  X  2   normal-…   subscript  X  n     X_{1},X_{2},\dots,X_{n}   and compute relative frequencies . We can estimate   P   P   P   , or a related distribution function   F   F   F   by means of the empirical measure or empirical distribution function, respectively. These are uniformly good estimates under certain conditions. Theorems in the area of empirical processes provide rates of this convergence.  Definition  Let     X  1   ,   X  2   ,  …      subscript  X  1    subscript  X  2   normal-…    X_{1},X_{2},\dots   be a sequence of independent identically distributed random variables with values in the state space S with probability measure  P .  Definition   The empirical measure  P n is defined for measurable subsets of S and given by       P  n    (  A  )    =    1  n     ∑   i  =  1   n     I  A    (   X  i   )      =    1  n     ∑   i  =  1   n     δ   X  i     (  A  )               subscript  P  n   A       1  n     superscript   subscript     i  1    n      subscript  I  A    subscript  X  i               1  n     superscript   subscript     i  1    n      subscript  δ   subscript  X  i    A        P_{n}(A)={1\over n}\sum_{i=1}^{n}I_{A}(X_{i})=\frac{1}{n}\sum_{i=1}^{n}\delta_%
 {X_{i}}(A)      where    I  A     subscript  I  A    I_{A}   is the indicator function and    δ  X     subscript  δ  X    \delta_{X}   is the Dirac measure .   For a fixed measurable set A , nP n ( A ) is a binomial random variable with mean nP ( A ) and variance nP ( A )(1 − P ( A )). In particular, P n ( A ) is an unbiased estimator of P ( A ).  Definition       (    P  n    (  c  )    )    c  ∈  𝒞      subscript     subscript  P  n   c     c  𝒞     \bigl(P_{n}(c)\bigr)_{c\in\mathcal{C}}   is the empirical measure indexed by   𝒞   𝒞   \mathcal{C}   , a collection of measurable subsets of S .  To generalize this notion further, observe that the empirical measure    P  n     subscript  P  n    P_{n}   maps measurable functions     f  :   S  →  ℝ      normal-:  f   normal-→  S  ℝ     f:S\to\mathbb{R}   to their empirical mean ,      f  ↦    P  n   f   =    ∫  S     f   d   P  n     =    1  n     ∑   i  =  1   n    f   (   X  i   )           maps-to  f     subscript  P  n   f          subscript   S     f  d   subscript  P  n              1  n     superscript   subscript     i  1    n     f   subscript  X  i         f\mapsto P_{n}f=\int_{S}f\,dP_{n}=\frac{1}{n}\sum_{i=1}^{n}f(X_{i})     In particular, the empirical measure of A is simply the empirical mean of the indicator function, P n ( A ) = P n  I A .  For a fixed measurable function   f   f   f   ,     P  n   f       subscript  P  n   f    P_{n}f   is a random variable with mean    𝔼  f      𝔼  f    \mathbb{E}f   and variance     1  n   𝔼    (   f  -   𝔼  f    )   2         1  n   𝔼   superscript    f    𝔼  f    2     \frac{1}{n}\mathbb{E}(f-\mathbb{E}f)^{2}   .  By the strong law of large numbers , P n ( A ) converges to P ( A ) almost surely for fixed A . Similarly     P  n   f       subscript  P  n   f    P_{n}f   converges to    𝔼  f      𝔼  f    \mathbb{E}f   almost surely for a fixed measurable function   f   f   f   . The problem of uniform convergence of P n to P was open until Vapnik and Chervonenkis solved it in 1968. 1  If the class   𝒞   𝒞   \mathcal{C}   (or   ℱ   ℱ   \mathcal{F}   ) is Glivenko–Cantelli with respect to P then ''P n converges to P uniformly over    c  ∈  𝒞      c  𝒞    c\in\mathcal{C}   (or    f  ∈  ℱ      f  ℱ    f\in\mathcal{F}   ). In other words, with probability 1 we have         ∥    P  n   -  P   ∥   𝒞   =    sup   c  ∈  𝒞     |     P  n    (  c  )    -   P   (  c  )     |    →  0   ,         subscript   norm     subscript  P  n   P    𝒞     subscript  supremum    c  𝒞           subscript  P  n   c     P  c        normal-→    0     \|P_{n}-P\|_{\mathcal{C}}=\sup_{c\in\mathcal{C}}|P_{n}(c)-P(c)|\to 0,           ∥    P  n   -  P   ∥   ℱ   =    sup   f  ∈  ℱ     |     P  n   f   -   𝔼  f    |    →  0.         subscript   norm     subscript  P  n   P    ℱ     subscript  supremum    f  ℱ           subscript  P  n   f     𝔼  f        normal-→    0.     \|P_{n}-P\|_{\mathcal{F}}=\sup_{f\in\mathcal{F}}|P_{n}f-\mathbb{E}f|\to 0.     Empirical distribution function  The empirical distribution function provides an example of empirical measures. For real-valued iid random variables     X  1   ,  …  ,   X  n       subscript  X  1   normal-…   subscript  X  n     X_{1},\dots,X_{n}   it is given by         F  n    (  x  )    =    P  n    (   (   -  ∞   ,  x  ]   )    =    P  n    I   (   -  ∞   ,  x  ]      .           subscript  F  n   x      subscript  P  n        x            subscript  P  n    subscript  I       x        F_{n}(x)=P_{n}((-\infty,x])=P_{n}I_{(-\infty,x]}.     In this case, empirical measures are indexed by a class     𝒞  =   {   (   -  ∞   ,  x  ]   :   x  ∈  ℝ   }    .      𝒞   conditional-set       x     x  ℝ      \mathcal{C}=\{(-\infty,x]:x\in\mathbb{R}\}.   It has been shown that   𝒞   𝒞   \mathcal{C}   is a uniform Glivenko–Cantelli class , in particular,        sup  F     ∥     F  n    (  x  )    -   F   (  x  )     ∥   ∞    →  0     normal-→    subscript  supremum  F    subscript   norm       subscript  F  n   x     F  x        0    \sup_{F}\|F_{n}(x)-F(x)\|_{\infty}\to 0     with probability 1.  See also   Poisson random measure   References  Further reading         "  Category:Probability theory  Category:Measures (measure theory)  Category:Empirical process     ↩     