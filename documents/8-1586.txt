   Monotone likelihood ratio      Monotone likelihood ratio     A monotonic likelihood ratio in distributions    f   (  x  )       f  x    f(x)   and    g   (  x  )       g  x    g(x)       (Figure)  MLRP-illustration.png    The ratio of the density functions above is increasing in the parameter   x   x   x   , so      f   (  x  )    /  g    (  x  )           f  x   g   x    f(x)/g(x)   satisfies the monotone likelihood ratio property.   In statistics , the monotone likelihood ratio property is a property of the ratio of two probability density functions (PDFs). Formally, distributions ƒ ( x ) and g ( x ) bear the property if        for every   x  1    >   x  0    ,     f   (   x  1   )     g   (   x  1   )     ≥    f   (   x  0   )     g   (   x  0   )         formulae-sequence      for every   subscript  x  1     subscript  x  0          f   subscript  x  1      g   subscript  x  1         f   subscript  x  0      g   subscript  x  0        \text{for every }x_{1}>x_{0},\quad\frac{f(x_{1})}{g(x_{1})}\geq\frac{f(x_{0})}%
 {g(x_{0})}     that is, if the ratio is nondecreasing in the argument   x   x   x   .  If the functions are first-differentiable, the property may sometimes be stated        ∂   ∂  x     (    f   (  x  )     g   (  x  )     )    ≥  0             x        f  x     g  x     0    \frac{\partial}{\partial x}\left(\frac{f(x)}{g(x)}\right)\geq 0     For two distributions that satisfy the definition with respect to some argument x, we say they "have the MLRP in x ." For a family of distributions that all satisfy the definition with respect to some statistic T ( X ), we say they "have the MLR in T ( X )."  Intuition  The MLRP is used to represent a data-generating process that enjoys a straightforward relationship between the magnitude of some observed variable and the distribution it draws from. If    f   (  x  )       f  x    f(x)   satisfies the MLRP with respect to    g   (  x  )       g  x    g(x)   , the higher the observed value   x   x   x   , the more likely it was drawn from distribution   f   f   f   rather than   g   g   g   . As usual for monotonic relationships, the likelihood ratio's monotonicity comes in handy in statistics, particularly when using maximum-likelihood  estimation . Also, distribution families with MLR have a number of well-behaved stochastic properties, such as first-order stochastic dominance and increasing hazard ratios . Unfortunately, as is also usual, the strength of this assumption comes at the price of realism. Many processes in the world do not exhibit a monotonic correspondence between input and output.  Example: Working hard or slacking off  Suppose you are working on a project, and you can either work hard or slack off. Call your choice of effort   e   e   e   and the quality of the resulting project   q   q   q   . If the MLRP holds for the distribution of q conditional on your effort   e   e   e   , the higher the quality the more likely you worked hard. Conversely, the lower the quality the more likely you slacked off.   Choose effort    e  ∈   {  H  ,  L  }       e   H  L     e\in\{H,L\}   where H means high, L means low  Observe   q   q   q   drawn from    f   (  q  ∣  e  )      fragments  f   fragments  normal-(  q  normal-∣  e  normal-)     f(q\mid e)   . By Bayes' law with a uniform prior,     P  r   [  e  =  H  ∣  q  ]   =    f   (  q  ∣  H  )     f   (  q  ∣  H  )   +  f   (  q  ∣  L  )        fragments  P  r   fragments  normal-[  e   H  normal-∣  q  normal-]       fragments  f   fragments  normal-(  q  normal-∣  H  normal-)     fragments  f   fragments  normal-(  q  normal-∣  H  normal-)    f   fragments  normal-(  q  normal-∣  L  normal-)       Pr[e=H\mid q]=\frac{f(q\mid H)}{f(q\mid H)+f(q\mid L)}     Suppose    f   (  q  ∣  e  )      fragments  f   fragments  normal-(  q  normal-∣  e  normal-)     f(q\mid e)   satisfies the MLRP. Rearranging, the probability the worker worked hard is         1   1  +  f   (  q  ∣  L  )   /  f   (  q  ∣  H  )        1   fragments  1   f   fragments  normal-(  q  normal-∣  L  normal-)    f   fragments  normal-(  q  normal-∣  H  normal-)      \frac{1}{1+f(q\mid L)/f(q\mid H)}       which, thanks to the MLRP, is monotonically increasing in   q   q   q   . Hence if some employer is doing a "performance review" he can infer his employee's behavior from the merits of his work.   Families of distributions satisfying MLR  Statistical models often assume that data are generated by a distribution from some family of distributions and seek to determine that distribution. This task is simplified if the family has the Monotone Likelihood Ratio Property (MLRP).  A family of density functions     {    f  θ    (  x  )    }    θ  ∈  Θ      subscript      subscript  f  θ   x      θ  normal-Θ     \{f_{\theta}(x)\}_{\theta\in\Theta}   indexed by a parameter   θ   θ   \theta   taking values in an ordered set   Θ   normal-Θ   \Theta   is said to have a monotone likelihood ratio (MLR) in the statistic     T   (  X  )       T  X    T(X)   if for any     θ  1   <   θ  2        subscript  θ  1    subscript  θ  2     \theta_{1}<\theta_{2}   ,        f   θ  2     (  X  =   x  1   ,   x  2   ,   x  3   ,  …  )      f   θ  1     (  X  =   x  1   ,   x  2   ,   x  3   ,  …  )         fragments   subscript  f   subscript  θ  2     fragments  normal-(  X    subscript  x  1   normal-,   subscript  x  2   normal-,   subscript  x  3   normal-,  normal-…  normal-)     fragments   subscript  f   subscript  θ  1     fragments  normal-(  X    subscript  x  1   normal-,   subscript  x  2   normal-,   subscript  x  3   normal-,  normal-…  normal-)      \frac{f_{\theta_{2}}(X=x_{1},x_{2},x_{3},\dots)}{f_{\theta_{1}}(X=x_{1},x_{2},%
 x_{3},\dots)}   is a non-decreasing function of    T   (  X  )       T  X    T(X)   .  Then we say the family of distributions "has MLR in    T   (  X  )       T  X    T(X)   ".  List of families      Family       T   (  X  )       T  X    T(X)   in which     f  θ    (  X  )        subscript  f  θ   X    f_{\theta}(X)   has the MLR       Exponential    [  λ  ]     delimited-[]  λ    [\lambda]          ∑   x  i        subscript  x  i     \sum x_{i}   observations     Binomial    [  n  ,  p  ]     n  p    [n,p]          ∑   x  i        subscript  x  i     \sum x_{i}   observations     Poisson    [  λ  ]     delimited-[]  λ    [\lambda]          ∑   x  i        subscript  x  i     \sum x_{i}   observations     Normal    [  μ  ,  σ  ]     μ  σ    [\mu,\sigma]      if   σ   σ   \sigma   known,    ∑   x  i        subscript  x  i     \sum x_{i}   observations     Hypothesis testing  If the family of random variables has the MLRP in    T   (  X  )       T  X    T(X)   , a uniformly most powerful test can easily be determined for the hypotheses     H  0   :   θ  ≤   θ  0       normal-:   subscript  H  0     θ   subscript  θ  0      H_{0}:\theta\leq\theta_{0}   versus     H  1   :   θ  >   θ  0       normal-:   subscript  H  1     θ   subscript  θ  0      H_{1}:\theta>\theta_{0}   .  Example: Effort and output  Example: Let   e   e   e   be an input into a stochastic technology --- worker's effort, for instance --- and   y   y   y   its output, the likelihood of which is described by a probability density function     f   (  y  ;  e  )    .      f   y  e     f(y;e).   Then the monotone likelihood ratio property (MLRP) of the family   f   f   f   is expressed as follows: for any     e  1   ,   e  2       subscript  e  1    subscript  e  2     e_{1},e_{2}   , the fact that     e  2   >   e  1        subscript  e  2    subscript  e  1     e_{2}>e_{1}   implies that the ratio      f   (  y  ;   e  2   )    /  f    (  y  ;   e  1   )           f   y   subscript  e  2     f    y   subscript  e  1      f(y;e_{2})/f(y;e_{1})   is increasing in   y   y   y   .  Relation to other statistical properties  If a family of distributions     f  θ    (  x  )        subscript  f  θ   x    f_{\theta}(x)   has the monotone likelihood ratio property in    T   (  X  )       T  X    T(X)   ,   the family has monotone decreasing hazard rates in   θ   θ   \theta   (but not necessarily in    T   (  X  )       T  X    T(X)   )  the family exhibits the first-order (and hence second-order) stochastic dominance in   x   x   x   , and the best Bayesian update of   θ   θ   \theta   is increasing in    T   (  X  )       T  X    T(X)   .   But not conversely: neither monotone hazard rates nor stochastic dominance imply the MLRP.  Proofs  Let distribution family    f  θ     subscript  f  θ    f_{\theta}   satisfy MLR in x , so that for     θ  1   >   θ  0        subscript  θ  1    subscript  θ  0     \theta_{1}>\theta_{0}   and     x  1   >   x  0        subscript  x  1    subscript  x  0     x_{1}>x_{0}   :          f   θ  1     (   x  1   )      f   θ  0     (   x  1   )     ≥     f   θ  1     (   x  0   )      f   θ  0     (   x  0   )      ,           subscript  f   subscript  θ  1     subscript  x  1       subscript  f   subscript  θ  0     subscript  x  1          subscript  f   subscript  θ  1     subscript  x  0       subscript  f   subscript  θ  0     subscript  x  0       \frac{f_{\theta_{1}}(x_{1})}{f_{\theta_{0}}(x_{1})}\geq\frac{f_{\theta_{1}}(x_%
 {0})}{f_{\theta_{0}}(x_{0})},     or equivalently:         f   θ  1     (   x  1   )    f   θ  0     (   x  0   )    ≥    f   θ  1     (   x  0   )    f   θ  0     (   x  1   )     .         subscript  f   subscript  θ  1     subscript  x  1    subscript  f   subscript  θ  0     subscript  x  0       subscript  f   subscript  θ  1     subscript  x  0    subscript  f   subscript  θ  0     subscript  x  1      f_{\theta_{1}}(x_{1})f_{\theta_{0}}(x_{0})\geq f_{\theta_{1}}(x_{0})f_{\theta_%
 {0}}(x_{1}).\,     Integrating this epression twice, we obtain:      1. To    x  1     subscript  x  1    x_{1}   with respect to    x  0     subscript  x  0    x_{0}          ∫    min  x   ∈  X    x  1      f   θ  1     (   x  1   )    f   θ  0     (   x  0   )   d   x  0        superscript   subscript      subscript   x   X     subscript  x  1       subscript  f   subscript  θ  1     subscript  x  1    subscript  f   subscript  θ  0     subscript  x  0   d   subscript  x  0      \int_{\min_{x}\in X}^{x_{1}}f_{\theta_{1}}(x_{1})f_{\theta_{0}}(x_{0})\,dx_{0}          ≥    ∫    min  x   ∈  X    x  1      f   θ  1     (   x  0   )    f   θ  0     (   x  1   )   d   x  0         absent    superscript   subscript      subscript   x   X     subscript  x  1       subscript  f   subscript  θ  1     subscript  x  0    subscript  f   subscript  θ  0     subscript  x  1   d   subscript  x  0       \geq\int_{\min_{x}\in X}^{x_{1}}f_{\theta_{1}}(x_{0})f_{\theta_{0}}(x_{1})\,dx%
 _{0}   integrate and rearrange to obtain         f   θ  1     f   θ  0      (  x  )    ≥     F   θ  1     F   θ  0      (  x  )             subscript  f   subscript  θ  1     subscript  f   subscript  θ  0     x        subscript  F   subscript  θ  1     subscript  F   subscript  θ  0     x     \frac{f_{\theta_{1}}}{f_{\theta_{0}}}(x)\geq\frac{F_{\theta_{1}}}{F_{\theta_{0%
 }}}(x)       2. From    x  0     subscript  x  0    x_{0}   with respect to    x  1     subscript  x  1    x_{1}          ∫   x  0     max  x   ∈  X      f   θ  1     (   x  1   )    f   θ  0     (   x  0   )   d   x  1        superscript   subscript    subscript  x  0       subscript   x   X       subscript  f   subscript  θ  1     subscript  x  1    subscript  f   subscript  θ  0     subscript  x  0   d   subscript  x  1      \int_{x_{0}}^{\max_{x}\in X}f_{\theta_{1}}(x_{1})f_{\theta_{0}}(x_{0})\,dx_{1}          ≥    ∫   x  0     max  x   ∈  X      f   θ  1     (   x  0   )    f   θ  0     (   x  1   )   d   x  1         absent    superscript   subscript    subscript  x  0       subscript   x   X       subscript  f   subscript  θ  1     subscript  x  0    subscript  f   subscript  θ  0     subscript  x  1   d   subscript  x  1       \geq\int_{x_{0}}^{\max_{x}\in X}f_{\theta_{1}}(x_{0})f_{\theta_{0}}(x_{1})\,dx%
 _{1}   integrate and rearrange to obtain        1  -    F   θ  1     (  x  )      1  -    F   θ  0     (  x  )      ≥     f   θ  1     f   θ  0      (  x  )            1     subscript  F   subscript  θ  1    x      1     subscript  F   subscript  θ  0    x          subscript  f   subscript  θ  1     subscript  f   subscript  θ  0     x     \frac{1-F_{\theta_{1}}(x)}{1-F_{\theta_{0}}(x)}\geq\frac{f_{\theta_{1}}}{f_{%
 \theta_{0}}}(x)        First-order stochastic dominance  Combine the two inequalities above to get first-order dominance:        F   θ  1     (  x  )    ≤    F   θ  0     (  x  )    ∀  x           subscript  F   subscript  θ  1    x      subscript  F   subscript  θ  0    x   for-all  x      F_{\theta_{1}}(x)\leq F_{\theta_{0}}(x)\ \forall x     Monotone hazard rate  Use only the second inequality above to get a monotone hazard rate:         f   θ  1     (  x  )     1  -    F   θ  1     (  x  )      ≤       f   θ  0     (  x  )     1  -    F   θ  0     (  x  )        ∀  x             subscript  f   subscript  θ  1    x     1     subscript  F   subscript  θ  1    x            subscript  f   subscript  θ  0    x     1     subscript  F   subscript  θ  0    x      for-all  x      \frac{f_{\theta_{1}}(x)}{1-F_{\theta_{1}}(x)}\leq\frac{f_{\theta_{0}}(x)}{1-F_%
 {\theta_{0}}(x)}\ \forall x     Example  Uses  Economics  The MLR is an important condition on the type distribution of agents in mechanism design . Most solutions to mechanism design models assume a type distribution to satisfy the MLR to take advantage of a common solution method.  "  Category:Theory of probability distributions  Category:Hypothesis testing   