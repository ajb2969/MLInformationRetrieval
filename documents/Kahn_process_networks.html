<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="905">Kahn process networks</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>Kahn process networks</h1>
<hr>'''Kahn process networks''' (''KPNs'', or ''process networks'') is a [[Distributed computing|distributed]] ''[[m
<p>odel of computation]]'' (<em>MoC</em>) where a group of deterministic sequential <a href="process_(computing)" title="wikilink">processes</a> are communicating through unbounded <a href="FIFO_(computing_and_electronics)" title="wikilink">FIFO</a> channels. The resulting process network exhibits deterministic behavior that does not depend on the various computation or communication delays. The model was originally developed for modeling <a href="distributed_systems" title="wikilink">distributed systems</a> but has proven its convenience for modeling <a href="signal_processing" title="wikilink">signal processing</a> systems. As such, KPNs have found many applications in modeling <a href="embedded_systems" title="wikilink">embedded systems</a>, <a href="high-performance_computing" title="wikilink">high-performance computing</a> systems, and other computational tasks. KPNs were first introduced by <a href="Gilles_Kahn" title="wikilink">Gilles Kahn</a>.<a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a> </p>
<h2 id="execution-model">Execution model</h2>

<p>KPN is a common model for describing <a href="signal_processing" title="wikilink">signal processing</a> systems where infinite streams of data are incrementally transformed by processes executing in sequence or parallel. Despite parallel processes, <a href="Computer_multitasking" title="wikilink">multitasking</a> or <a href="parallel_computing" title="wikilink">parallelism</a> are not required for executing this model.</p>

<p>In a KPN, processes communicate via unbounded <a href="FIFO_(computing_and_electronics)" title="wikilink">FIFO</a> channels. Processes read and write atomic <a href="data_element" title="wikilink">data elements</a>, or alternatively called <a href="Token_(parser)" title="wikilink">tokens</a>, from and to channels. Writing to a channel is <a href="Non-blocking_I/O" title="wikilink">non-blocking</a>, i.e. it always succeeds and does not stall the process, while reading from a channel is <em>blocking</em>, i.e. a process that reads from an empty channel will stall and can only continue when the channel contains sufficient data items (<em>tokens</em>). Processes are not allowed to test an input channel for existence of tokens without consuming them. Given a specific input (token) history for a process, the process must be deterministic so that it always produces the same outputs (tokens). Timing or execution order of processes must not affect the result and therefore testing input channels for tokens is forbidden.</p>
<h3 id="notes-on-processes">Notes on processes</h3>
<ul>
<li>A process need not read any input or have any input channels as it may act as a pure data source</li>
<li>A process need not write any output or have any output channels</li>
<li>Testing input channels for emptiness (or <em>non-blocking reads</em>) could be allowed for optimization purposes, but it should not affect outputs. It can be beneficial and/or possible to do something in advance rather than wait for a channel. For example, assume there were 2 reads from different channels. If the first read would stall (wait for a token) but the second read could be read a token directly, it could be beneficial to read the second one first to save time, because the reading itself often consumes some time (e.g. time for memory allocation or copying).</li>
</ul>
<h3 id="process-firing-semantics-as-petri-nets">Process firing semantics as Petri nets</h3>

<p> Assuming process <em>P</em> in the KPN above is constructed so that it first reads data from channel <em>A</em>, then channel <em>B</em>, computes something and then writes data to channel <em>C</em>, the execution model of the process can be modeled with the <a href="Petri_net" title="wikilink">Petri net</a> shown on the right. The single token in the <em>PE resource</em> place forbids that the process is executed simultaneously for different input data. When data arrives at channel <em>A</em> or <em>B</em>, tokens are placed into places <em>FIFO A</em> and <em>FIFO B</em> respectively. The transitions of the Petri net are associated with the respective I/O operations and computation. When the data has been written to channel <em>C</em>, <em>PE resource</em> is filled with its initial marking again allowing new data to be read.</p>
<h3 id="process-as-a-finite-state-machine">Process as a finite state machine</h3>

<p> A process can be modeled as a finite state machine that is in one of two states:</p>
<ul>
<li>Active; the process computes or writes data</li>
<li>Wait; the process is blocked (waiting) for data</li>
</ul>

<p>Assuming the finite state machine reads program elements associated with the process, it may read three kinds of tokens, which are "Compute", "Read" and "Write token". Additionally, in the <em>Wait</em> state it can only come back to <em>Active</em> state by reading a special "Get token" which means the communication channel associated with the wait contains readable data.</p>
<h2 id="properties">Properties</h2>
<h3 id="boundedness-of-channels">Boundedness of channels</h3>

<p>A channel is <em>strictly bounded</em> by 

<math display="inline" id="Kahn_process_networks:0">
 <semantics>
  <mi>b</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>b</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   b
  </annotation>
 </semantics>
</math>

 if it has at most 

<math display="inline" id="Kahn_process_networks:1">
 <semantics>
  <mi>b</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>b</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   b
  </annotation>
 </semantics>
</math>

 unconsumed tokens for any possible execution. A KPN is <em>strictly bounded</em> by 

<math display="inline" id="Kahn_process_networks:2">
 <semantics>
  <mi>b</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>b</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   b
  </annotation>
 </semantics>
</math>

 if all channels are strictly bounded by 

<math display="inline" id="Kahn_process_networks:3">
 <semantics>
  <mi>b</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>b</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   b
  </annotation>
 </semantics>
</math>

.</p>

<p>The number of unconsumed tokens depends on the execution order (<strong>scheduling</strong>) of processes. A spontaneous data source could produce arbitrarily many tokens into a channel if the scheduler would not execute processes consuming those tokens.</p>

<p>A real application can not have unbounded FIFOs and therefore scheduling and maximum capacity of FIFOs must be designed into a practical implementation. The maximum capacity of FIFOs can be handled in several ways:</p>
<ul>
<li>FIFO bounds can be mathematically derived in design to avoid FIFO overflows. This is however not possible for all KPNs. It is an undecidable problem to test whether a KPN is strictly bounded by 

<math display="inline" id="Kahn_process_networks:4">
 <semantics>
  <mi>b</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>b</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   b
  </annotation>
 </semantics>
</math>

. Moreover, in practical situations, the bound may be data dependent.</li>
<li>FIFO bounds can be grown on demand.<a class="footnoteRef" href="#fn2" id="fnref2"><sup>2</sup></a></li>
<li>Blocking writes can be used so that a process blocks if a FIFO is full. This approach may unfortunately lead to an artificial deadlock unless the designer properly derives safe bounds for FIFOs (Parks, 1995). Local artificial detection at run-time may be necessary to guarantee the production of the correct output.<a class="footnoteRef" href="#fn3" id="fnref3"><sup>3</sup></a></li>
</ul>
<h3 id="closed-and-open-systems">Closed and open systems</h3>

<p>A <em>closed KPN</em> has no external input or output channels. Processes that have no input channels act as data sources and processes that have no output channels act as data sinks. In an <em>open KPN</em> each process has at least one input and output channel.</p>
<h3 id="determinism">Determinism</h3>

<p>Processes of a KPN are <a class="uri" href="deterministic" title="wikilink">deterministic</a>. For the same input history they must always produce exactly the same output. Processes can be modeled as sequential programs that do reads and writes to ports in any order or quantity as long as determinism property is preserved. As a consequence, KPN model is deterministic so that following factors entirely determine outputs of the system:</p>
<ul>
<li>processes</li>
<li>the network</li>
<li>initial tokens</li>
</ul>

<p>Hence, timing of the processes does not affect outputs of the system.</p>
<h3 id="monotonicity">Monotonicity</h3>

<p>KPN processes are <em>monotonic</em>, which means that they only need partial information of the input stream in order to produce partial information of the output stream. <a class="uri" href="Monotonicity" title="wikilink">Monotonicity</a> allows parallelism. In a KPN there is a <a href="total_order" title="wikilink">total order</a> of events inside a signal. However, there is no order relation between events in different signals. Thus, KPNs are only partially ordered, which classifies them as <a href="untimed_model" title="wikilink">untimed model</a>.</p>
<h2 id="applications">Applications</h2>

<p>Due to its high expressiveness and succinctness, KPNs as underlying the model of computation are applied in several academic modeling tools to represent streaming applications, which have certain properties (e.g., dataflow-oriented, stream-based).</p>

<p>The open source Daedalus framework<a class="footnoteRef" href="#fn4" id="fnref4"><sup>4</sup></a> maintained by Leiden Embedded Research Center at <a href="Leiden_university" title="wikilink">Leiden university</a> accepts sequential programs written in C and generates a corresponding KPN. This KPN could, for example, be used to map the KPN onto an <a class="uri" href="FPGA" title="wikilink">FPGA</a>-based platform systematically.</p>

<p>The <a class="uri" href="Ambric" title="wikilink">Ambric</a> Am2045 <a href="massively_parallel_processor_array" title="wikilink">massively parallel processor array</a> is a KPN implemented in actual silicon.<a class="footnoteRef" href="#fn5" id="fnref5"><sup>5</sup></a> Its 336 32-bit processors are connected by a programmable interconnect of dedicated FIFOs. Thus its channels are strictly bounded with blocking writes.</p>
<h2 id="see-also">See also</h2>
<ul>
<li><a href="Flow-based_programming" title="wikilink">Flow-based programming</a></li>
</ul>
<h2 id="references">References</h2>
<h2 id="further-reading">Further reading</h2>
<ul>
<li>Lee, E. and Park, T. (1995). <a href="http://ptolemy.eecs.berkeley.edu/papers/95/processNets/proceedings.pdf">Dataflow Process Networks</a>. In Proceedings of the IEEE, volume 83, pages 773-799.</li>
<li>Josephs, M.B. (2005). <a href="http://dx.doi.org/10.1007/11423348_6">Models for Data-Flow Sequential Processes</a>. In: Communicating Sequential Processes, The First 25 Years, LNCS 3525, pages 85–97.</li>
</ul>

<p>"</p>

<p><a href="Category:Models_of_computation" title="wikilink">Category:Models of computation</a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1"><a href="#fnref1">↩</a></li>
<li id="fn2"><a href="#fnref2">↩</a></li>
<li id="fn3"><a href="#fnref3">↩</a></li>
<li id="fn4"><a class="uri" href="http://daedalus.liacs.nl">http://daedalus.liacs.nl</a> LIACS Daedalus framework<a href="#fnref4">↩</a></li>
<li id="fn5">Mike Butts, Anthony Mark Jones, Paul Wasson, "A Structural Object Programming Model, Architecture, Chip and Tools for Reconfigurable Computing", Proceedings of <a class="uri" href="FCCM" title="wikilink">FCCM</a>, April 2007, <a href="IEEE_Computer_Society" title="wikilink">IEEE Computer Society</a><a href="#fnref5">↩</a></li>
</ol>
</section>
</hr></body>
</html>
