<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="275">Regression discontinuity design</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>Regression discontinuity design</h1>
<hr>In [[statistics]], [[econometrics]], [[political science]], [[epidemiology]], and related disciplines, a '''regression discontinuity design (RDD)''' is a quasi-experimental pretest-posttest design that elicits the [[causality|causal effects]] of interventions by assigning a cutoff or threshold above or below w
<p>hich an intervention is assigned. By comparing observations lying closely on either side of the threshold, it is possible to estimate the local <a href="Average_treatment_effect" title="wikilink">Average treatment effect</a> in environments in which <a class="uri" href="randomization" title="wikilink">randomization</a> was unfeasible. First applied by <a href="Donald_Thistlewaite" title="wikilink">Donald Thistlewaite</a> and <a href="Donald_T._Campbell" title="wikilink">Donald Campbell</a> to the evaluation of scholarship programs,<a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a> the RDD has become increasingly popular in recent years.<a class="footnoteRef" href="#fn2" id="fnref2"><sup>2</sup></a></p>
<h2 id="example">Example</h2>

<p>The intuition behind the RDD is well illustrated using the evaluation of merit-based scholarships. The main problem with estimating the causal effect of such an intervention is the <a href="endogeneity_(econometrics)" title="wikilink">endogeneity</a> of assignment to <a href="Design_of_experiments" title="wikilink">treatment</a> (e.g. scholarship award): Since high-performing students are more likely to be awarded the merit scholarship <em>and</em> continue performing well at the same time, comparing the outcomes of awardees and non-recipients would lead to an upward <a href="selection_bias" title="wikilink">bias</a> of the estimates. Even <em>if</em> the scholarship did not improve grades at all, awardees would have performed better than non-recipients, simply because scholarships were given to students who were performing well <a href="ex_ante" title="wikilink">ex ante</a>.</p>

<p>Despite the absence of an <a href="experimental_design" title="wikilink">experimental design</a>, a RDD can exploit <a class="uri" href="exogenous" title="wikilink">exogenous</a> characteristics of the intervention to elicit <a href="causality" title="wikilink">causal effects</a>. If all students above a given grade—for example 80%—are given the scholarship, it is possible to elicit the local treatment effect by comparing students around the 80% cut-off: The intuition here is that a student scoring 79% is likely to be very similar to a student scoring 81%—given the pre-defined threshold of 80%, however, one student will receive the scholarship while the other will not. Comparing the outcome of the awardee (treatment group) to the <a href="Counterfactual_conditional" title="wikilink">counterfactual</a> outcome of the non-recipient (control group) will hence deliver the local treatment effect.</p>
<h2 id="methodology">Methodology</h2>

<p>The two most common approaches to estimation using a RDD are <a href="nonparametric_regression" title="wikilink">nonparametric</a> and parametric (normally <a href="polynomial_regression" title="wikilink">polynomial regression</a>).</p>
<h3 id="non-parametric-estimation">Non-parametric estimation</h3>

<p>The most common non-parametric method used in the RDD context is a local linear regression. This is of the form:</p>

<p>

<math display="block" id="Regression_discontinuity_design:0">
 <semantics>
  <mrow>
   <mi>Y</mi>
   <mo>=</mo>
   <mrow>
    <mi>α</mi>
    <mo>+</mo>
    <mrow>
     <mi>τ</mi>
     <mi>D</mi>
    </mrow>
    <mo>+</mo>
    <mrow>
     <msub>
      <mi>β</mi>
      <mn>1</mn>
     </msub>
     <mrow>
      <mo stretchy="false">(</mo>
      <mrow>
       <mi>X</mi>
       <mo>-</mo>
       <mi>c</mi>
      </mrow>
      <mo stretchy="false">)</mo>
     </mrow>
    </mrow>
    <mo>+</mo>
    <mrow>
     <msub>
      <mi>β</mi>
      <mn>2</mn>
     </msub>
     <mi>D</mi>
     <mrow>
      <mo stretchy="false">(</mo>
      <mrow>
       <mi>X</mi>
       <mo>-</mo>
       <mi>c</mi>
      </mrow>
      <mo stretchy="false">)</mo>
     </mrow>
    </mrow>
    <mo>+</mo>
    <mi>ε</mi>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <ci>Y</ci>
    <apply>
     <plus></plus>
     <ci>α</ci>
     <apply>
      <times></times>
      <ci>τ</ci>
      <ci>D</ci>
     </apply>
     <apply>
      <times></times>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>β</ci>
       <cn type="integer">1</cn>
      </apply>
      <apply>
       <minus></minus>
       <ci>X</ci>
       <ci>c</ci>
      </apply>
     </apply>
     <apply>
      <times></times>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>β</ci>
       <cn type="integer">2</cn>
      </apply>
      <ci>D</ci>
      <apply>
       <minus></minus>
       <ci>X</ci>
       <ci>c</ci>
      </apply>
     </apply>
     <ci>ε</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   Y=\alpha+\tau D+\beta_{1}(X-c)+\beta_{2}D(X-c)+\varepsilon
  </annotation>
 </semantics>
</math>

</p>

<p>where 

<math display="inline" id="Regression_discontinuity_design:1">
 <semantics>
  <mrow>
   <mrow>
    <mi>c</mi>
    <mo>-</mo>
    <mi>h</mi>
   </mrow>
   <mo>≤</mo>
   <mi>X</mi>
   <mo>≤</mo>
   <mrow>
    <mi>c</mi>
    <mo>+</mo>
    <mi>h</mi>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <and></and>
    <apply>
     <leq></leq>
     <apply>
      <minus></minus>
      <ci>c</ci>
      <ci>h</ci>
     </apply>
     <ci>X</ci>
    </apply>
    <apply>
     <leq></leq>
     <share href="#.cmml">
     </share>
     <apply>
      <plus></plus>
      <ci>c</ci>
      <ci>h</ci>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   c-h\leq X\leq c+h
  </annotation>
 </semantics>
</math>

 Where 

<math display="inline" id="Regression_discontinuity_design:2">
 <semantics>
  <mi>c</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>c</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   c
  </annotation>
 </semantics>
</math>

 is the treatment cut-off, 

<math display="inline" id="Regression_discontinuity_design:3">
 <semantics>
  <mi>D</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>D</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   D
  </annotation>
 </semantics>
</math>

 is a binary variable equal to one if 

<math display="inline" id="Regression_discontinuity_design:4">
 <semantics>
  <mrow>
   <mi>X</mi>
   <mo>≥</mo>
   <mi>c</mi>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <geq></geq>
    <ci>X</ci>
    <ci>c</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   X\geq c
  </annotation>
 </semantics>
</math>

, and 

<math display="inline" id="Regression_discontinuity_design:5">
 <semantics>
  <mi>h</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>h</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   h
  </annotation>
 </semantics>
</math>

 is the bandwidth of data used. Different slopes and intercepts fit data on either side of the cutoff. Typically either a rectangular <a href="Kernel_(statistics)" title="wikilink">kernel</a> (no weighting) or a triangular kernel are used. Research favors the triangular kernel<a class="footnoteRef" href="#fn3" id="fnref3"><sup>3</sup></a> but the rectangular kernel has a more straightforward interpretation.<a class="footnoteRef" href="#fn4" id="fnref4"><sup>4</sup></a></p>

<p>The major benefit of using non-parametric methods in a RDD is that they provide estimates based on data closer to the cut-off, which is intuitively appealing. This reduces some bias that can result from using data farther away from the cutoff to estimate the discontinuity at the cutoff.<a class="footnoteRef" href="#fn5" id="fnref5"><sup>5</sup></a> More formally, local linear regressions are preferred because they have better bias properties<a class="footnoteRef" href="#fn6" id="fnref6"><sup>6</sup></a> and have better convergence.<a class="footnoteRef" href="#fn7" id="fnref7"><sup>7</sup></a> However, the use of both types estimation, if feasible, is a useful way to argue that the estimated results do not rely too heavily on the particular approach taken.</p>
<h2 id="parametric-estimation">Parametric estimation</h2>
<h3 id="other-examples">Other examples</h3>
<ul>
<li>Policies in which treatment is determined by an age eligibility criterion (e.g. pensions, minimum legal drinking age).<a class="footnoteRef" href="#fn8" id="fnref8"><sup>8</sup></a><a class="footnoteRef" href="#fn9" id="fnref9"><sup>9</sup></a></li>
</ul>
<ul>
<li>Elections in which one politician wins by a marginal majority.<a class="footnoteRef" href="#fn10" id="fnref10"><sup>10</sup></a></li>
</ul>
<ul>
<li>Placement scores within education that sort students into treatment programs.<a class="footnoteRef" href="#fn11" id="fnref11"><sup>11</sup></a></li>
</ul>
<h2 id="required-assumptions">Required assumptions</h2>

<p>Regression discontinuity design requires that treatment assignment is "as good as random" at the threshold for treatment.<a class="footnoteRef" href="#fn12" id="fnref12"><sup>12</sup></a> If this holds, then it guarantees that those who just barely received treatment are comparable to those who just barely did not receive treatment, as treatment status is effectively random.</p>

<p>Treatment assignment at the threshold can be "as good as random" if there is randomness in the assignment variable and the agents considered (individuals, firms, etc.) cannot perfectly manipulate their treatment status. For example, if the treatment is passing an exam, where a grade of 50% is required, then this example is a valid regression discontinuity design so long as grades are somewhat random, due either to randomness of grading or randomness of student performance.</p>

<p>Students must not also be able to perfectly manipulate their grade so as to perfectly determine their treatment status. Two examples include students being able to convince teachers to "mercy pass" them, or students being allowed to re-take the exam until they pass. In the former case, those students who barely fail but are able to secure a "mercy pass" may differ from those who just barely fail but cannot secure a "mercy pass". This leads to <a href="selection_bias" title="wikilink">selection bias</a>, as the treatment and control groups now differ. In the later case, some students may decide to retake the exam, stopping once they pass. This also leads to <a href="selection_bias" title="wikilink">selection bias</a> since only some students will decide to retake the exam.<a class="footnoteRef" href="#fn13" id="fnref13"><sup>13</sup></a></p>
<h3 id="testing-the-validity-of-the-assumptions">Testing the validity of the assumptions</h3>

<p>It is impossible to definitively test for if agents are able to perfectly determine their treatment status. However, there are some tests that can provide evidence that either supports or discounts the validity of the regression discontinuity design.</p>
<h4 id="density-test">Density test</h4>

<p> McCrary (2008) suggested examining the density of observations of the assignment variable.<a class="footnoteRef" href="#fn14" id="fnref14"><sup>14</sup></a> If there is a discontinuity in the density of the assignment variable at the threshold for treatment, then this may suggest that some agents were able to perfectly manipulate their treatment status.</p>

<p>For example, if several students are able to get a "mercy pass", then there will be more students who just barely passed the exam than who just barely failed. Similarly, if students are allowed to retake the exam until they pass, then there will be a similar result. In both cases, this will likely show up when the density of exam grades is examined. "Gaming the system" in this manner could bias the treatment effect estimate.</p>
<h4 id="continuity-of-observable-variables">Continuity of observable variables</h4>

<p>Since the validity of the regression discontinuity design relies on those who were just barely treated being the same as those who were just barely not treated, it makes sense to examine if these groups are similar based on observable variables. For the earlier example, one could test if those who just barely passed have different characteristics (demographics, family income, etc.) than those who just barely failed. Although some variables may differ for the two groups based on random chance, most of these variables should be the same.<a class="footnoteRef" href="#fn15" id="fnref15"><sup>15</sup></a></p>
<h4 id="falsification-tests">Falsification tests</h4>
<h5 id="predetermined-variables">Predetermined variables</h5>

<p>Similar to the continuity of observable variables, one would expect there to be continuity in predetermined variables at the treatment cut-off. Since these variables were determined before the treatment decision, treatment status should have no effect on them. Consider the earlier merit-based scholarship example. If the outcome of interest is future grades, then we would not expect the scholarship to affect earlier grades. If a discontinuity in predetermined variables is present at the treatment cut-off, then this puts the validity of the regression discontinuity design into question.</p>
<h5 id="other-discontinuities">Other discontinuities</h5>

<p>If discontinuities are present at other points of the assignment variable, where these are not expected, then this may make the regression discontinuity design suspect. Consider the example of Carpenter and Dobkin (2011) who studied the effect of legal access to alcohol in the United States.<a class="footnoteRef" href="#fn16" id="fnref16"><sup>16</sup></a> As access to alcohol increases at age 21, this leads to changes in various outcomes, such as mortality rates and morbidity rates. If mortality and morbidity rates also increase discontinuously at other ages, then it throws the interpretation of the discontinuity at age 21 into question.</p>
<h4 id="inclusion-and-exclusion-of-covariates">Inclusion and exclusion of covariates</h4>

<p>If parameter estimates are sensitive to removing or adding <a href="covariate" title="wikilink">covariates</a> to the model, then this may cast doubt on the validity of the regression discontinuity design. A significant change may suggest that those who just barely got treatment differ in these <a href="covariate" title="wikilink">covariates</a> from those who just barely did not get treatment. Including <a href="covariate" title="wikilink">covariates</a> would remove some of this bias. If a large amount of bias is present, and the <a href="covariate" title="wikilink">covariates</a> explain a significant amount of this, then their inclusion or exclusion would significantly change the parameter estimate.<a class="footnoteRef" href="#fn17" id="fnref17"><sup>17</sup></a></p>
<h2 id="advantages">Advantages</h2>
<ul>
<li>When properly implemented and analyzed, the RDD yields an unbiased estimate of the local treatment effect.<a class="footnoteRef" href="#fn18" id="fnref18"><sup>18</sup></a> The RDD can be almost as good as a randomised experiment in measuring a treatment effect.</li>
<li>RDD, as a <a class="uri" href="quasi-experiment" title="wikilink">quasi-experiment</a>, does not require <a href="ex_ante" title="wikilink">ex ante</a> randomization and circumvents ethical issues of <a href="randomization" title="wikilink">random assignment</a>.</li>
<li>Well-executed RDD studies can generate treatment effect estimates similar to estimates from randomized studies.<a class="footnoteRef" href="#fn19" id="fnref19"><sup>19</sup></a><a class="footnoteRef" href="#fn20" id="fnref20"><sup>20</sup></a></li>
</ul>
<h2 id="disadvantages">Disadvantages</h2>
<ul>
<li>The <a href="statistical_power" title="wikilink">statistical power</a> is considerably lower than a randomized experiment of the same <a href="sample_size" title="wikilink">sample size</a>, increasing the risk of erroneously dismissing significant effects of the treatment (<a href="Type_II_error" title="wikilink">Type II error</a>)<a class="footnoteRef" href="#fn21" id="fnref21"><sup>21</sup></a></li>
<li>The estimated effects are only <a class="uri" href="unbiased" title="wikilink">unbiased</a> if the <a href="functional_form" title="wikilink">functional form</a> of the relationship between the treatment and outcome is correctly modelled. The most popular caveats are non-linear relationships that are mistaken as a discontinuity.</li>
<li>Contamination by other treatments. If another treatment occurs at the same cut-off value of the same assignment variable, then the measured discontinuity in the outcome variable may be partially attributed to this other treatment. For example, suppose a researcher wishes to study the impact of legal access to alcohol on mental health using a regression discontinuity design at the minimum legal drinking age. The measured impact could be confused with legal access to gambling, which may occur at the same age.</li>
</ul>
<h2 id="extensions">Extensions</h2>
<h3 id="fuzzy-rdd">Fuzzy RDD</h3>

<p>The <a href="identifiability" title="wikilink">identification</a> of causal effects hinges on the crucial assumption that there is indeed a sharp cut-off, around which there is a discontinuity in the probability of assignment from 0 to 1. In reality, however, cut-offs are often not strictly implemented (e.g. exercised discretion for students who just fell short of passing the threshold) and the estimates will hence be <a href="statistical_bias" title="wikilink">biased</a>.</p>

<p>In contrast to the sharp regression discontinuity design, a <strong>fuzzy regression discontinuity design</strong> (FRDD) does not require a sharp discontinuity in the probability of assignment but is applicable as long as the probability of assignment is different. The intuition behind it is related to the <a href="instrumental_variable" title="wikilink">instrumental variable</a> strategy and <a href="intention_to_treat" title="wikilink">intention to treat</a>.</p>
<h3 id="regression-kink-design">Regression kink design</h3>

<p>When the assignment variable is continuous (e.g. student aid) and depends predictably on another observed variable (e.g. family income), one can identify treatment effects using sharp changes in the slope of the treatment function. This technique was coined <em>regression kink design</em> by Nielsen, Sørensen, and Tabe (2010), though they cite similar earlier analyses.<a class="footnoteRef" href="#fn22" id="fnref22"><sup>22</sup></a> They write, "This approach resembles the regression discontinuity idea. Instead of a discontinuity of in the level of the stipend-income function, we have a discontinuity in the slope of the function." Rigorous theoretical foundations were provided by Card et al. (2012).<a class="footnoteRef" href="#fn23" id="fnref23"><sup>23</sup></a></p>

<p>Note that <em>regression kinks</em> (or <em>kinked regression</em>) can also mean a type of <a href="segmented_regression" title="wikilink">segmented regression</a>, which is a different type of analysis.</p>
<h2 id="see-also">See also</h2>
<ul>
<li><a class="uri" href="Quasi-experiment" title="wikilink">Quasi-experiment</a></li>
<li><a href="Design_of_quasi-experiments" title="wikilink">Design of quasi-experiments</a></li>
</ul>
<h2 id="references">References</h2>
<h2 id="further-reading">Further reading</h2>
<ul>
<li></li>
<li></li>
</ul>
<h2 id="external-links">External links</h2>
<ul>
<li><a href="http://www.socialresearchmethods.net/kb/statrd.php"><em>Regression-Discontinuity Analysis</em></a> at Research Methods Knowledge Base</li>
</ul>

<p>"</p>

<p><a href="Category:Design_of_experiments" title="wikilink">Category:Design of experiments</a> <a class="uri" href="Category:Econometrics" title="wikilink">Category:Econometrics</a> <a href="Category:Statistical_terminology" title="wikilink">Category:Statistical terminology</a> <a href="Category:Observational_study" title="wikilink">Category:Observational study</a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1"><a href="#fnref1">↩</a></li>
<li id="fn2"><a href="#fnref2">↩</a></li>
<li id="fn3"><a href="#fnref3">↩</a></li>
<li id="fn4"></li>
<li id="fn5"></li>
<li id="fn6"></li>
<li id="fn7"><a href="#fnref7">↩</a></li>
<li id="fn8"><a href="#fnref8">↩</a></li>
<li id="fn9"><a href="#fnref9">↩</a></li>
<li id="fn10"><a href="#fnref10">↩</a></li>
<li id="fn11"><a href="#fnref11">↩</a></li>
<li id="fn12"></li>
<li id="fn13"><a href="#fnref13">↩</a></li>
<li id="fn14"><a href="#fnref14">↩</a></li>
<li id="fn15"><a href="#fnref15">↩</a></li>
<li id="fn16"></li>
<li id="fn17"></li>
<li id="fn18"><a href="#fnref18">↩</a></li>
<li id="fn19"><a href="#fnref19">↩</a></li>
<li id="fn20"><a href="#fnref20">↩</a></li>
<li id="fn21"><a href="#fnref21">↩</a></li>
<li id="fn22"><a href="#fnref22">↩</a></li>
<li id="fn23"><a href="#fnref23">↩</a></li>
</ol>
</section>
</hr></body>
</html>
