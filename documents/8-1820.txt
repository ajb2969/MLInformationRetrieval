   Sequential probability ratio test      Sequential probability ratio test   The sequential probability ratio test (SPRT) is a specific sequential hypothesis test , developed by Abraham Wald . 1  Neyman and Pearson's 1933 result inspired Wald to reformulate it as a sequential analysis problem. The Neyman-Pearson lemma, by contrast, offers a rule of thumb for when all the data is collected (and its likelihood ratio known).  While originally developed for use in quality control studies in the realm of manufacturing, SPRT has been formulated for use in the computerized testing of human examinees as a termination criterion. 2 3 4  Theory  As in classical hypothesis testing , SPRT starts with a pair of hypotheses, say    H  0     subscript  H  0    H_{0}   and    H  1     subscript  H  1    H_{1}   for the null hypothesis and alternative hypothesis respectively. They must be specified as follows:       H  0   :   p  =   p  0       normal-:   subscript  H  0     p   subscript  p  0      H_{0}:p=p_{0}          H  1   :   p  =   p  1       normal-:   subscript  H  1     p   subscript  p  1      H_{1}:p=p_{1}     The next step is calculate the cumulative sum of the log- likelihood ratio ,    log   Λ  i        subscript  normal-Λ  i     \log\Lambda_{i}   , as new data arrive: with     S  0   =  0       subscript  S  0   0    S_{0}=0   , then, for i=1,2,...,       S  i   =    S   i  -  1    +   log   Λ  i          subscript  S  i      subscript  S    i  1       subscript  normal-Λ  i       S_{i}=S_{i-1}+\log\Lambda_{i}     The stopping rule is a simple thresholding scheme:       a  <   S  i   <  b        a   subscript  S  i        b     a   : continue monitoring ( critical inequality )       S  i   ≥  b       subscript  S  i   b    S_{i}\geq b   : Accept    H  1     subscript  H  1    H_{1}          S  i   ≤  a       subscript  S  i   a    S_{i}\leq a   : Accept    H  0     subscript  H  0    H_{0}      where a and b (   β   β   \beta   and    a  ≈   log   β   1  -  α         a      β    1  α       a\approx\log\frac{\beta}{1-\alpha}   . They may be chosen as follows:      b  ≈   log    1  -  β   α        b        1  β   α      b\approx\log\frac{1-\beta}{\alpha}   and   α   α   \alpha     In other words,   β   β   \beta   and       f  θ    (  x  )    =     θ   -  1     exp   (   -   x  /  θ    )     ,  x    ,   θ  >  0      formulae-sequence       subscript  f  θ   x       superscript  θ    1          x  θ      x      θ  0     f_{\theta}(x)=\theta^{-1}\exp\left(-x/\theta\right),x,\theta>0   must be decided beforehand in order to set the thresholds appropriately. The numerical value will depend on the application. The reason for using approximation signs is that, in the discrete case, the signal may cross the threshold between samples. Thus, depending on the penalty of making an error and the sampling frequency , one might set the thresholds more aggressively. Of course, the exact bounds may be used in the continuous case.  Example  A textbook example is parameter estimation of a probability distribution function . Let us consider the exponential distribution :       H  0   :   θ  =   θ  0       normal-:   subscript  H  0     θ   subscript  θ  0      H_{0}:\theta=\theta_{0}     The hypotheses are simply     H  1   :   θ  =   θ  1       normal-:   subscript  H  1     θ   subscript  θ  1      H_{1}:\theta=\theta_{1}   and     θ  1   >   θ  0        subscript  θ  1    subscript  θ  0     \theta_{1}>\theta_{0}   , with        log  Λ    (  x  )      =     log   [      θ  1   -  1     exp   (   -   x  /   θ  1     )       θ  0   -  1     exp   (   -   x  /   θ  0     )       ]           =     log   [      θ  0    θ  1      exp   (    x  /   θ  0    -   x  /   θ  1     )     ]           =          θ  1   -   θ  0      θ  0    θ  1      x   -   log     θ  1    θ  0                 normal-Λ   x           superscript   subscript  θ  1     1          x   subscript  θ  1          superscript   subscript  θ  0     1          x   subscript  θ  0           absent          subscript  θ  0    subscript  θ  1          x   subscript  θ  0      x   subscript  θ  1          absent            subscript  θ  1    subscript  θ  0       subscript  θ  0    subscript  θ  1     x        subscript  θ  1    subscript  θ  0         \begin{matrix}\log\Lambda(x)&=&\log\left[\frac{\theta_{1}^{-1}\exp\left(-x/%
 \theta_{1}\right)}{\theta_{0}^{-1}\exp\left(-x/\theta_{0}\right)}\right]\\
 &=&\log\left[\frac{\theta_{0}}{\theta_{1}}\exp\left(x/\theta_{0}-x/\theta_{1}%
 \right)\right]\\
 &=&\frac{\theta_{1}-\theta_{0}}{\theta_{0}\theta_{1}}x-\log\frac{\theta_{1}}{%
 \theta_{0}}\end{matrix}   . Then the log-likelihood function (LLF) for one sample is       S  n   =    ∑   i  =  1   n     log  Λ    (   x  i   )     =       θ  1   -   θ  0      θ  0    θ  1       ∑   i  =  1   n    x  i     -   n   log    θ  1    θ  0              subscript  S  n     superscript   subscript     i  1    n       normal-Λ    subscript  x  i                   subscript  θ  1    subscript  θ  0       subscript  θ  0    subscript  θ  1       superscript   subscript     i  1    n    subscript  x  i       n       subscript  θ  1    subscript  θ  0          S_{n}=\sum_{i=1}^{n}\log\Lambda(x_{i})=\frac{\theta_{1}-\theta_{0}}{\theta_{0}%
 \theta_{1}}\sum_{i=1}^{n}x_{i}-n\log\frac{\theta_{1}}{\theta_{0}}     The cumulative sum of the LLFs for all x is      log   (    θ  1   /   θ  0    )          subscript  θ  1    subscript  θ  0      \log(\theta_{1}/\theta_{0})     Accordingly, the stopping rule is  $$a<\frac{\theta_1-\theta_0}{\theta_0 \theta_1} \sum_{i=1}^n x_i - n \log \frac{\theta_1}{\theta_0} After re-arranging we finally find
 : a+n \log \frac{\theta_1}{\theta_0} < \frac{\theta_1-\theta_0}{\theta_0 \theta_1} \sum_{i=1}^n x_i < b+n \log \frac{\theta_1}{\theta_0}$$  The thresholds are simply two parallel lines with slope  $\log ( \theta_1/\theta_0 )$ . Sampling should stop when the sum of the samples makes an excursion outside the continue-sampling region .  Applications  Manufacturing  The test is done on the proportion metric, and tests that a variable p is equal to one of two desired points, p 1 or p 2 . The region between these two points is known as the indifference region (IR). For example, suppose you are performing a quality control study on a factory lot of widgets. Management would like the lot to have 3% or less defective widgets, but 1% or less is the ideal lot that would pass with flying colors. In this example, p 1 = 0.01 and p 2 = 0.03 and the region between them is the IR because management considers these lots to be marginal and is OK with them being classified either way. Widgets would be sampled one at a time from the lot (sequential analysis) until the test determines, within an acceptable error level, that the lot is ideal or should be rejected.  Testing of human examinees  The SPRT is currently the predominant method of classifying examinees in a variable-length computerized classification test (CCT). The two parameters are p 1 and p 2 are specified by determining a cutscore (threshold) for examinees on the proportion correct metric, and selecting a point above and below that cutscore. For instance, suppose the cutscore is set at 70% for a test. We could select p 1 = 0.65 and p 2 = 0.75 . The test then evaluates the likelihood that an examinee's true score on that metric is equal to one of those two points. If the examinee is determined to be at 75%, they pass, and they fail if they are determined to be at 65%.  These points are not specified completely arbitrarily. A cutscore should always be set with a legally defensible method, such as a modified Angoff procedure . Again, the indifference region represents the region of scores that the test designer is OK with going either way (pass or fail). The upper parameter p 2 is conceptually the highest level that the test designer is willing to accept for a Fail (because everyone below it has a good chance of failing), and the lower parameter p 1 is the lowest level that the test designer is willing to accept for a pass (because everyone above it has a decent chance of passing). While this definition may seem to be a relatively small burden, consider the high-stakes case of a licensing test for medical doctors: at just what point should we consider somebody to be at one of these two levels?  While the SPRT was first applied to testing in the days of classical test theory , as is applied in the previous paragraph, Reckase (1983) suggested that item response theory be used to determine the p 1 and p 2 parameters. The cutscore and indifference region are defined on the latent ability (theta) metric, and translated onto the proportion metric for computation. Research on CCT since then has applied this methodology for several reasons:   Large item banks tend to be calibrated with IRT  This allows more accurate specification of the parameters  By using the item response function for each item, the parameters are easily allowed to vary between items.   Detection of anomalous medical outcomes  Spiegelhalter et al. 5 have shown that SPRT can be used to monitor the performance of doctors, surgeons and other medical practitioners in such a way as to give early warning of potentially anomalous results. In their 2003 paper, they showed how it could have helped identify Harold Shipman as a murderer well before he was actually identified.  Extensions  MaxSPRT  More recently, in 2011, an extension of the SPRT method called Maximized Sequential Probability Ratio Test (MaxSPRT) 6 was introduced. The salient feature of MaxSPRT is the allowance of a composite, one-sided alternative hypothesis, and the introduction of an upper stopping boundary. The method has been used in several medical research studies 7  See also   CUSUM  Computerized classification test  Wald test  Likelihood-ratio test   References      Holger Wilker: Sequential-Statistik in der Praxis , BoD, Norderstedt 2012, ISBN 978-3848232529.   External links   R Package: Wald's Sequential Probability Ratio Test by [ http://onlinemarketr.com : OnlineMarketr.com]   "  Category:Statistical tests  Category:Psychometrics  Category:Sequential methods  Category:Mathematical psychology     ↩  Ferguson, Richard L. (1969). [ http://eric.ed.gov/ERICWebPortal/custom/portlets/recordDetails/detailmini.jsp?_nfpb=true&_&ERICExtSearch;_SearchValue_0=ED034406&ERICExtSearch;_SearchType_0=no&accno; ;=ED034406 The development, implementation, and evaluation of a computer-assisted branched test for a program of individually prescribed instruction]. Unpublished doctoral dissertation, University of Pittsburgh. ↩  Reckase, M. D. (1983). A procedure for decision making using tailored testing. In D. J. Weiss (Ed.), New horizons in testing: Latent trait theory and computerized adaptive testing (pp. 237-254). New York: Academic Press. ↩  ↩  Risk-adjusted sequential probability ratio tests: application to Bristol, Shipman and adult cardiac surgery Spiegelhalter, D. et al Int J Qual Health Care vol 15 7-13 (2003) ↩  http://www.tandfonline.com/doi/full/10.1080/07474946.2011.539924 A Maximized Sequential Probability Ratio Test for Drug and Vaccine Safety Surveillance Kulldorff, M. et al Sequential Analysis: Design Methods and Applications vol 30, issue 1 ↩  2nd to last paragraph of section 1: http://www.tandfonline.com/doi/full/10.1080/07474946.2011.539924 A Maximized Sequential Probability Ratio Test for Drug and Vaccine Safety Surveillance Kulldorff, M. et al Sequential Analysis: Design Methods and Applications vol 30, issue 1 ↩     