   Inverse-variance weighting      Inverse-variance weighting   In statistics , inverse-variance weighting is a method of aggregating two or more random variables to minimize the variance of the weighted average. Each random variable is weighted in inverse proportion to its variance.  Given a sequence of independent observations with variances , the inverse-variance weighted average is given by 1        y  ^   =     ∑  i     y  i   /   σ  i  2       ∑  i    1  /   σ  i  2       .       normal-^  y       subscript   i      subscript  y  i    superscript   subscript  σ  i   2       subscript   i     1   superscript   subscript  σ  i   2        \hat{y}=\frac{\sum_{i}y_{i}/\sigma_{i}^{2}}{\sum_{i}1/\sigma_{i}^{2}}.     The inverse-variance weighted average has the least variance among all weighted averages, which can be calculated as         D  2    (   y  ^   )    =   1    ∑  i    1  /   σ  i  2       .         superscript  D  2    normal-^  y      1    subscript   i     1   superscript   subscript  σ  i   2        D^{2}(\hat{y})=\frac{1}{\sum_{i}1/\sigma_{i}^{2}}.     If the variances of the measurements are all equal, then the inverse-variance weighted average becomes the simple average.  Inverse-variance weighting is typically used in statistical meta-analysis to combine the results from independent measurements.  See also   Weighted least squares   References  "  Category:Data analysis  Category:Meta-analysis  Category:Estimation theory     ↩     