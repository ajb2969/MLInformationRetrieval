   Intensity of counting processes      Intensity of counting processes   The intensity    λ   λ   \lambda   of a counting process is a measure of the rate of change of its predictable part. If a stochastic process     {     N   (  t  )    ,  t   ≥  0   }          N  t   t   0     \{N(t),t\geq 0\}   is a counting process, then it is a submartingale , and in particular its Doob-Meyer decomposition is       N   (  t  )    =    M   (  t  )    +   Λ   (  t  )           N  t       M  t     normal-Λ  t      N(t)=M(t)+\Lambda(t)     where    M   (  t  )       M  t    M(t)   is a martingale and    Λ   (  t  )       normal-Λ  t    \Lambda(t)   is a predictable increasing process.    Λ   (  t  )       normal-Λ  t    \Lambda(t)   is called the cumulative intensity of    N   (  t  )       N  t    N(t)   and it is related to   λ   λ   \lambda   by       Λ   (  t  )    =    ∫  0  t    λ   (  s  )   d  s          normal-Λ  t     superscript   subscript   0   t     λ  s  d  s      \Lambda(t)=\int_{0}^{t}\lambda(s)ds   .  Definition  Given probability space    (  Ω  ,  ℱ  ,  ℙ  )     normal-Ω  ℱ  ℙ    (\Omega,\mathcal{F},\mathbb{P})   and a counting process    {     N   (  t  )    ,  t   ≥  0   }          N  t   t   0     \{N(t),t\geq 0\}   which is adapted to the filtration    {     ℱ  t   ,  t   ≥  0   }         subscript  ℱ  t   t   0     \{\mathcal{F}_{t},t\geq 0\}   , the intensity of   N   N   N   is the process    {     λ   (  t  )    ,  t   ≥  0   }          λ  t   t   0     \{\lambda(t),t\geq 0\}   defined by the following limit:      λ   (  t  )   =   lim   h  ↓  0     1  h   𝔼   [  N   (  t  +  h  )   -  N   (  t  )   |   ℱ  t   ]      fragments  λ   fragments  normal-(  t  normal-)     subscript    normal-↓  h  0      1  h   E   fragments  normal-[  N   fragments  normal-(  t   h  normal-)    N   fragments  normal-(  t  normal-)   normal-|   subscript  ℱ  t   normal-]     \lambda(t)=\lim_{h\downarrow 0}\frac{1}{h}\mathbb{E}[N(t+h)-N(t)|\mathcal{F}_{%
 t}]   .  The right-continuity property of counting processes allows us to take this limit from the right. 1  Estimation  In statistical learning , the variation between   λ   λ   \lambda   and its estimator     λ  ^     normal-^  λ    \hat{\lambda}   can be bounded with the use of oracle inequalities.  If a counting process    N   (  t  )       N  t    N(t)   is restricted to    t  ∈   [  0  ,  1  ]       t   0  1     t\in[0,1]   and   n   n   n    i.i.d. copies are observed on that interval,     N  1   ,   N  2   ,  …  ,   N  n       subscript  N  1    subscript  N  2   normal-…   subscript  N  n     N_{1},N_{2},\ldots,N_{n}   , then the least squares functional for the intensity is        R  n    (  λ  )    =     ∫  0  1    λ    (  t  )   2   d  t    -    2  n     ∑   i  =  1   n     ∫  0  1    λ   (  t  )   d   N  i    (  t  )               subscript  R  n   λ       superscript   subscript   0   1     λ   superscript  t  2   d  t        2  n     superscript   subscript     i  1    n     superscript   subscript   0   1     λ  t  d   subscript  N  i   t         R_{n}(\lambda)=\int_{0}^{1}\lambda(t)^{2}dt-\frac{2}{n}\sum_{i=1}^{n}\int_{0}^%
 {1}\lambda(t)dN_{i}(t)     which involves an Ito integral . If the assumption is made that    λ   (  t  )       λ  t    \lambda(t)   is piecewise constant on    [  0  ,  1  ]     0  1    [0,1]   , i.e. it depends on a vector of constants    β  =   (   β  1   ,   β  2   ,  …  ,   β  m   )   ∈    \R   +  m         β    subscript  β  1    subscript  β  2   normal-…   subscript  β  m          superscript   subscript  \R    m      \beta=(\beta_{1},\beta_{2},\ldots,\beta_{m})\in\R_{+}^{m}   and can be written        λ  β   =    ∑   j  =  1   m     β  j    λ   j  ,  m       ,    λ   j  ,  m    =    m    𝟏   (    j  -  1   m   ,   j  m   ]         formulae-sequence     subscript  λ  β     superscript   subscript     j  1    m      subscript  β  j    subscript  λ   j  m          subscript  λ   j  m        m    subscript  1       j  1   m     j  m         \lambda_{\beta}=\sum_{j=1}^{m}\beta_{j}\lambda_{j,m},\;\;\;\;\;\;\lambda_{j,m}%
 =\sqrt{m}\mathbf{1}_{(\frac{j-1}{m},\frac{j}{m}]}   ,  where the    λ   j  ,  m      subscript  λ   j  m     \lambda_{j,m}   have a factor of    m      m    \sqrt{m}   so that they are orthonormal under the standard    L  2     superscript  L  2    L^{2}   norm, then by choosing appropriate data-driven weights     w  ^   j     subscript   normal-^  w   j    \hat{w}_{j}   which depend on a parameter    x  >  0      x  0    x>0   and introducing the weighted norm        ∥  β  ∥    w  ^    =    ∑   j  =  2   m      w  ^   j    |    β  j   -   β   j  -  1     |          subscript   norm  β    normal-^  w      superscript   subscript     j  2    m      subscript   normal-^  w   j        subscript  β  j    subscript  β    j  1          \|\beta\|_{\hat{w}}=\sum_{j=2}^{m}\hat{w}_{j}|\beta_{j}-\beta_{j-1}|   ,  the estimator for   β   β   \beta   can be given:       β  ^   =   arg    min   β  ∈    \R   +  m      {     R  n    (   λ  β   )    +    ∥  β  ∥    w  ^     }          normal-^  β       subscript     β   superscript   subscript  \R    m          subscript  R  n    subscript  λ  β     subscript   norm  β    normal-^  w         \hat{\beta}=\arg\min_{\beta\in\R_{+}^{m}}\left\{R_{n}(\lambda_{\beta})+\|\beta%
 \|_{\hat{w}}\right\}   .  Then, the estimator    λ  ^     normal-^  λ    \hat{\lambda}   is just    λ   β  ^      subscript  λ   normal-^  β     \lambda_{\hat{\beta}}   . With these preliminaries, an oracle inequality bounding the    L  2     superscript  L  2    L^{2}   norm    ∥    λ  ^   -  λ   ∥     norm     normal-^  λ   λ     \|\hat{\lambda}-\lambda\|   is as follows: for appropriate choice of      w  ^   j    (  x  )        subscript   normal-^  w   j   x    \hat{w}_{j}(x)   ,        ∥    λ  ^   -  λ   ∥   2   ≤    inf   β  ∈    \R   +  m      {     ∥    λ  β   -  λ   ∥   2   +   2    ∥  β  ∥    w  ^      }         superscript   norm     normal-^  λ   λ    2     subscript  infimum    β   superscript   subscript  \R    m         superscript   norm     subscript  λ  β   λ    2     2   subscript   norm  β    normal-^  w          \|\hat{\lambda}-\lambda\|^{2}\leq\inf_{\beta\in\R_{+}^{m}}\left\{\|\lambda_{%
 \beta}-\lambda\|^{2}+2\|\beta\|_{\hat{w}}\right\}     with probability greater than or equal to    1  -   12.85   e   -  x         1    12.85   superscript  e    x       1-12.85e^{-x}   . 2  References        "     Aalen, O. (1978). Nonparametric inference for a family of counting processes. The Annals of Statistics , 6(4):701-726. ↩  Alaya, E., S. Gaiffas, and A. Guilloux (2014) Learning the intensity of time events with change-points ↩     