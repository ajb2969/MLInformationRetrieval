   Orthonormality      Orthonormality   In linear algebra , two vectors in an inner product space are orthonormal if they are orthogonal and unit vectors . A set of vectors form an orthonormal set if all vectors in the set are mutually orthogonal and all of unit length. An orthonormal set which forms a basis is called an orthonormal basis .  Intuitive overview  The construction of orthogonality of vectors is motivated by a desire to extend the intuitive notion of perpendicular vectors to higher-dimensional spaces. In the Cartesian plane , two vectors are said to be perpendicular if the angle between them is 90Â° (i.e. if they form a right angle ). This definition can be formalized in Cartesian space by defining the dot product and specifying that two vectors in the plane are orthogonal if their dot product is zero.  Similarly, the construction of the norm of a vector is motivated by a desire to extend the intuitive notion of the length of a vector to higher-dimensional spaces. In Cartesian space, the norm of a vector is the square root of the vector dotted with itself. That is,       âˆ¥  ğ±  âˆ¥   =    ğ±  â‹…  ğ±         norm  ğ±      normal-â‹…  ğ±  ğ±      \|\mathbf{x}\|=\sqrt{\mathbf{x}\cdot\mathbf{x}}     Many important results in linear algebra deal with collections of two or more orthogonal vectors. But often, it is easier to deal with vectors of unit length . That is, it often simplifies things to only consider vectors whose norm equals 1. The notion of restricting orthogonal pairs of vectors to only those of unit length is important enough to be given a special name. Two vectors which are orthogonal and of length 1 are said to be orthonormal .  Simple example  What does a pair of orthonormal vectors in 2-D Euclidean space look like?  Let u = (x 1 , y 1 ) and v = (x 2 , y 2 ). Consider the restrictions on x 1 , x 2 , y 1 , y 2 required to make u and v form an orthonormal pair.   From the orthogonality restriction, u â€¢ v = 0.  From the unit length restriction on u , || u || = 1.  From the unit length restriction on v , || v || = 1.   Expanding these terms gives 3 equations:           x  1    x  2    +    y  1    y  2     =  0            subscript  x  1    subscript  x  2       subscript  y  1    subscript  y  2     0    x_{1}x_{2}+y_{1}y_{2}=0\quad            x  1    2   +   y  1    2     =  1           superscript   subscript  x  1   2    superscript   subscript  y  1   2     1    \sqrt{{x_{1}}^{2}+{y_{1}}^{2}}=1            x  2    2   +   y  2    2     =  1           superscript   subscript  x  2   2    superscript   subscript  y  2   2     1    \sqrt{{x_{2}}^{2}+{y_{2}}^{2}}=1    Converting from Cartesian to polar coordinates , and considering Equation    (  2  )    2   (2)   and Equation    (  3  )    3   (3)   immediately gives the result r 1 = r 2 = 1. In other words, requiring the vectors be of unit length restricts the vectors to lie on the unit circle .  After substitution, Equation    (  1  )    1   (1)   becomes       cos   Î¸  1     cos   Î¸  2     +    sin   Î¸  1     sin   Î¸  2      =  0             subscript  Î¸  1       subscript  Î¸  2          subscript  Î¸  1       subscript  Î¸  2      0    \cos\theta_{1}\cos\theta_{2}+\sin\theta_{1}\sin\theta_{2}=0   . Rearranging gives     tan   Î¸  1    =   -   cot   Î¸  2            subscript  Î¸  1         subscript  Î¸  2       \tan\theta_{1}=-\cot\theta_{2}   . Using a trigonometric identity to convert the cotangent term gives       tan   (   Î¸  1   )    =   tan   (    Î¸  2   +    Ï€  2     )           subscript  Î¸  1         subscript  Î¸  2     Ï€  2       \tan(\theta_{1})=\tan\left(\theta_{2}+\tfrac{\pi}{2}\right)          â‡’   Î¸  1   =    Î¸  2   +    Ï€  2          normal-â‡’  absent   subscript  Î¸  1           subscript  Î¸  2     Ï€  2       \Rightarrow\theta_{1}=\theta_{2}+\tfrac{\pi}{2}     It is clear that in the plane, orthonormal vectors are simply radii of the unit circle whose difference in angles equals 90Â°.  Definition  Let   ğ’±   ğ’±   \mathcal{V}   be an inner-product space . A set of vectors       {   u  1   ,   u  2   ,  â€¦  ,   u  n   ,  â€¦  }   âˆˆ  ğ’±        subscript  u  1    subscript  u  2   normal-â€¦   subscript  u  n   normal-â€¦   ğ’±    \left\{u_{1},u_{2},\ldots,u_{n},\ldots\right\}\in\mathcal{V}   is called orthonormal  if and only if        âˆ€  i   ,  j   :    âŸ¨   u  i   ,   u  j   âŸ©   =   Î´   i  j        normal-:    for-all  i   j       subscript  u  i    subscript  u  j     subscript  Î´    i  j       \forall i,j:\langle u_{i},u_{j}\rangle=\delta_{ij}   where     Î´   i  j       subscript  Î´    i  j     \delta_{ij}\,   is the Kronecker delta and    âŸ¨  â‹…  ,  â‹…  âŸ©     normal-â‹…  normal-â‹…    \langle\cdot,\cdot\rangle   is the inner product defined over   ğ’±   ğ’±   \mathcal{V}   .  Significance  Orthonormal sets are not especially significant on their own. However, they display certain features that make them fundamental in exploring the notion of diagonalizability of certain operators on vector spaces.  Properties  Orthonormal sets have certain very appealing properties, which make them particularly easy to work with.   Theorem . If { e 1 , e 2 ,..., e n } is an orthonormal list of vectors, then           ||     a  1    e  1    +    a  2    e  2    +  â‹¯  +    a  n    e  n     ||   2   =     |   a  1   |   2   +    |   a  2   |   2   +  â‹¯  +    |   a  n   |   2         superscript   norm       subscript  a  1    subscript  e  1       subscript  a  2    subscript  e  2    normal-â‹¯     subscript  a  n    subscript  e  n      2      superscript     subscript  a  1    2    superscript     subscript  a  2    2   normal-â‹¯   superscript     subscript  a  n    2      ||a_{1}e_{1}+a_{2}e_{2}+\cdots+a_{n}e_{n}||^{2}=|a_{1}|^{2}+|a_{2}|^{2}+\cdots%
 +|a_{n}|^{2}         Theorem . Every orthonormal list of vectors is linearly independent .   Existence   Gram-Schmidt theorem . If { v 1 , v 2 ,..., v n } is a linearly independent list of vectors in an inner-product space   ğ’±   ğ’±   \mathcal{V}   , then there exists an orthonormal list { e 1 , e 2 ,..., e n } of vectors in   ğ’±   ğ’±   \mathcal{V}   such that span ( e 1 , e 2 ,..., e n ) = span ( v 1 , v 2 ,..., v n ).   Proof of the Gram-Schmidt theorem is constructive , and discussed at length elsewhere. The Gram-Schmidt theorem, together with the axiom of choice , guarantees that every vector space admits an orthonormal basis. This is possibly the most significant use of orthonormality, as this fact permits operators on inner-product spaces to be discussed in terms of their action on the space's orthonormal basis vectors. What results is a deep relationship between the diagonalizability of an operator and how it acts on the orthonormal basis vectors. This relationship is characterized by the Spectral Theorem .  Examples  Standard basis  The standard basis for the coordinate space  F n is        { e 1 , e 2 ,..., e n }Â Â Â where    e 1 = (1, 0, ..., 0)       e 2 = (0, 1, ..., 0)         â‹®   normal-â‹®   \vdots           e n = (0, 0, ..., 1)       Any two vectors e i , e j where iâ‰ j are orthogonal, and all vectors are clearly of unit length. So { e 1 , e 2 ,..., e n } forms an orthonormal basis.  Real-valued functions  When referring to real -valued functions , usually the LÂ² inner product is assumed unless otherwise stated. Two functions    Ï•   (  x  )       Ï•  x    \phi(x)   and    Ïˆ   (  x  )       Ïˆ  x    \psi(x)   are orthonormal over the interval     [  a  ,  b  ]     a  b    [a,b]   if         (  1  )    âŸ¨   Ï•   (  x  )    ,   Ïˆ   (  x  )    âŸ©    =    âˆ«  a  b    Ï•   (  x  )   Ïˆ   (  x  )   d  x    =  0   ,  and     formulae-sequence       1     Ï•  x     Ïˆ  x       superscript   subscript   a   b     Ï•  x  Ïˆ  x  d  x         0    and    (1)\quad\langle\phi(x),\psi(x)\rangle=\int_{a}^{b}\phi(x)\psi(x)dx=0,\quad{\rm
 and}           (  2  )     ||   Ï•   (  x  )    ||   2    =    ||   Ïˆ   (  x  )    ||   2   =    [    âˆ«  a  b      |   Ï•   (  x  )    |   2   d  x    ]    1  2    =    [    âˆ«  a  b      |   Ïˆ   (  x  )    |   2   d  x    ]    1  2    =  1.         2   subscript   norm    Ï•  x    2     subscript   norm    Ïˆ  x    2         superscript   delimited-[]    superscript   subscript   a   b      superscript      Ï•  x    2   d  x       1  2          superscript   delimited-[]    superscript   subscript   a   b      superscript      Ïˆ  x    2   d  x       1  2         1.     (2)\quad||\phi(x)||_{2}=||\psi(x)||_{2}=\left[\int_{a}^{b}|\phi(x)|^{2}dx%
 \right]^{\frac{1}{2}}=\left[\int_{a}^{b}|\psi(x)|^{2}dx\right]^{\frac{1}{2}}=1.     Fourier series  The Fourier series is a method of expressing a periodic function in terms of sinusoidal basis functions. Taking C [âˆ’Ï€,Ï€] to be the space of all real-valued functions continuous on the interval [âˆ’Ï€,Ï€] and taking the inner product to be       âŸ¨  f  ,  g  âŸ©   =    âˆ«   -  Ï€   Ï€    f   (  x  )   g   (  x  )   d  x         f  g     superscript   subscript     Ï€    Ï€     f  x  g  x  d  x      \langle f,g\rangle=\int_{-\pi}^{\pi}f(x)g(x)dx   It can be shown that        {   1    2  Ï€     ,    sin   (  x  )     Ï€    ,    sin   (   2  x   )     Ï€    ,  â€¦  ,    sin   (   n  x   )     Ï€    ,    cos   (  x  )     Ï€    ,    cos   (   2  x   )     Ï€    ,  â€¦  ,    cos   (   n  x   )     Ï€    }   ,  n   âˆˆ  â„•          1      2  Ï€         x     Ï€          2  x      Ï€    normal-â€¦        n  x      Ï€        x     Ï€          2  x      Ï€    normal-â€¦        n  x      Ï€     n   â„•    \left\{\frac{1}{\sqrt{2\pi}},\frac{\sin(x)}{\sqrt{\pi}},\frac{\sin(2x)}{\sqrt{%
 \pi}},\ldots,\frac{\sin(nx)}{\sqrt{\pi}},\frac{\cos(x)}{\sqrt{\pi}},\frac{\cos%
 (2x)}{\sqrt{\pi}},\ldots,\frac{\cos(nx)}{\sqrt{\pi}}\right\},\quad n\in\mathbb%
 {N}       forms an orthonormal set.  However, this is of little consequence, because C [âˆ’Ï€,Ï€] is infinite-dimensional, and a finite set of vectors cannot span it. But, removing the restriction that n be finite makes the set dense in C [âˆ’Ï€,Ï€] and therefore an orthonormal basis of C [âˆ’Ï€,Ï€].  See also   Orthogonalization   References     "  Category:Linear algebra  Category:Functional analysis   