   Energy distance      Energy distance   Energy distance is a statistical distance between probability distributions . If X and Y are independent random vectors in R d with cumulative distribution functions F and G respectively, then the energy distance between the distributions F and G is defined to be the square root of         D  2    (  F  ,  G  )    =    2  ğ”¼   âˆ¥   X  -  Y   âˆ¥    -   ğ”¼   âˆ¥   X  -   X  â€²    âˆ¥    -   ğ”¼   âˆ¥   Y  -   Y  â€²    âˆ¥     â‰¥  0   ,           superscript  D  2    F  G        2  ğ”¼   norm    X  Y       ğ”¼   norm    X   superscript  X  normal-â€²        ğ”¼   norm    Y   superscript  Y  normal-â€²            0     D^{2}(F,G)=2\mathbb{E}\|X-Y\|-\mathbb{E}\|X-X^{\prime}\|-\mathbb{E}\|Y-Y^{%
 \prime}\|\geq 0,     where X, X' are independent and identically distributed (iid), Y, Y' are iid,   ğ”¼   ğ”¼   \mathbb{E}   is expected value, and || . || denotes the length of a vector. Energy distance satisfies all axioms of a metric thus energy distance characterizes the equality of distributions: D(F,G) = 0 if and only if F = G. Energy distance for statistical applications was introduced in 1985 by GÃ¡bor J. SzÃ©kely , who proved that for real-valued random variables this distance is exactly twice Harald CramÃ©r 's distance: 1       âˆ«   -  âˆ   âˆ       (    F   (  x  )    -   G   (  x  )     )   2    d  x       superscript   subscript             superscript      F  x     G  x    2   d  x     \int_{-\infty}^{\infty}(F(x)-G(x))^{2}\,dx   .  For a simple proof of this equivalence, see SzÃ©kely and Rizzo (2005). 2 In higher dimensions, however, the two distances are different because the energy distance is rotation invariant while CramÃ©r's distance is not. (Notice that CramÃ©r's distance is not the same as the distribution-free  Cramer-von-Mises criterion .)  Generalization to metric spaces  One can generalize the notion of energy distance to probability distributions on metric spaces. Let    (  M  ,  d  )     M  d    (M,d)   be a metric space with its Borel sigma algebra     â„¬   (  M  )       â„¬  M    \mathcal{B}(M)   . Let    ğ’«   (  M  )       ğ’«  M    \mathcal{P}(M)   denote the collection of all probability measures on the measurable space     (  M  ,   â„¬   (  M  )    )     M    â„¬  M     (M,\mathcal{B}(M))   . If Î¼ and Î½ are probability measures in    ğ’«   (  M  )       ğ’«  M    \mathcal{P}(M)   , then the energy-distance   D   D   D   of Î¼ and Î½ can be defined as the square root of         D  2    (  Î¼  ,  Î½  )    =    2  ğ”¼   [   d   (  X  ,  Y  )    ]    -   ğ”¼   [   d   (  X  ,   X  â€²   )    ]    -   ğ”¼   [   d   (  Y  ,   Y  â€²   )    ]      .         superscript  D  2    Î¼  Î½        2  ğ”¼   delimited-[]    d   X  Y        ğ”¼   delimited-[]    d   X   superscript  X  normal-â€²         ğ”¼   delimited-[]    d   Y   superscript  Y  normal-â€²          D^{2}(\mu,\nu)=2\mathbb{E}[d(X,Y)]-\mathbb{E}[d(X,X^{\prime})]-\mathbb{E}[d(Y,%
 Y^{\prime})].     This is not necessarily non-negative, however. If    (  M  ,  d  )     M  d    (M,d)   is a strongly negative definite kernel, then   D   D   D   is a metric , and conversely. 3 This condition is expressed by saying that    (  M  ,  d  )     M  d    (M,d)   has negative type. Negative type is not sufficient for   D   D   D   to be a metric; the latter condition is expressed by saying that    (  M  ,  d  )     M  d    (M,d)   has strong negative type. In this situation, the energy distance is zero if and only if X and Y are identically distributed. An example of a metric of negative type but not of strong negative type is the plane with the taxicab metric . All Euclidean spaces and even separable Hilbert spaces have strong negative type. 4  In the literature on kernel methods for machine learning , these generalized notions of energy distance are studied under the name of maximum mean discrepancy. 5  Energy statistics  A related statistical concept, the notion of E-statistic or energy-statistic 6 was introduced by GÃ¡bor J. SzÃ©kely in the 1980s when he was giving colloquium lectures in Budapest, Hungary and at MIT, Yale, and Columbia. This concept is based on the notion of Newtonâ€™s potential energy . 7 The idea is to consider statistical observations as heavenly bodies governed by a statistical potential energy which is zero only when an underlying statistical null hypothesis is true. Energy statistics are functions of distances between statistical observations.  Energy distance and E-statistic were considered as N -distances and N-statistic in Zinger A.A., Kakosyan A.V., Klebanov L.B. Characterization of distributions by means of mean values of some statistics in connection with some probability metrics, Stability Problems for Stochastic Models. Moscow, VNIISI, 1989,47-55. (in Russian), English Translation: A characterization of distributions by mean values of statistics and certain probabilistic metrics A. A. Zinger, A. V. Kakosyan, L. B. Klebanov in Journal of Soviet Mathematics (1992). In the same paper there was given a definition of strongly negative definite kernel, and provided a generalization on metric spaces, discussed above. The book 8 gives these results and their applications to statistical testing as well. The book contains also some applications to recovering the measure from its potential.  Testing for equal distributions  Consider the null hypothesis that two random variables, X and Y, have the same probability distributions: Î¼ = v . For statistical samples from X and Y:   x 1 ,â€¦,x n and y 1 ,â€¦,y m ,   the following arithmetic averages of distances are computed between the X and the Y samples:   A:= (1/nm)âˆ‘|x i â€“ y j |, B:= (1/n 2 )âˆ‘|x i â€“ x j |, C:= (1/m 2 )âˆ‘|y i â€“ y j |.   The E-statistic of the underlying null hypothesis is defined as follows:   Î• n,m (X,Y):= 2A â€“ B â€“ C.   One can prove 9 10 that Î• n,m (X,Y) â‰¥ 0 and that the corresponding population value, E(X,Y):= D(Î¼,Î½), is zero if and only if X and Y have the same distribution (Î¼=Î½). Under this null hypothesis the test statistic      T  =     n  m    n  +  m     E   n  ,  m     (  X  ,  Y  )        T        n  m     n  m     subscript  E   n  m     X  Y      T=\frac{nm}{n+m}E_{n,m}(X,Y)     converges in distribution to a quadratic form of independent standard normal random variables . Under the alternative hypothesis T tends to infinity. This makes it possible to construct a consistent statistical test , the energy test for equal distributions. 11  The E-coefficient of inhomogeneity can also be introduced. This is always between 0 and 1 and is defined as       H  =     D  2    (   F  X   ,   F  Y   )     2   ğ”¼   âˆ¥   X  -  Y   âˆ¥      =     2  ğ”¼   âˆ¥   X  -  Y   âˆ¥    -   ğ”¼   âˆ¥   X  -   X  â€²    âˆ¥    -   ğ”¼   âˆ¥   Y  -   Y  â€²    âˆ¥      2   ğ”¼   âˆ¥   X  -  Y   âˆ¥       ,        H       superscript  D  2     subscript  F  X    subscript  F  Y       2   ğ”¼   norm    X  Y                  2  ğ”¼   norm    X  Y       ğ”¼   norm    X   superscript  X  normal-â€²        ğ”¼   norm    Y   superscript  Y  normal-â€²         2   ğ”¼   norm    X  Y          H=\frac{D^{2}(F_{X},F_{Y})}{2\operatorname{\mathbb{E}}\|X-Y\|}=\frac{2\mathbb{%
 E}\|X-Y\|-\mathbb{E}\|X-X^{\prime}\|-\mathbb{E}\|Y-Y^{\prime}\|}{2%
 \operatorname{\mathbb{E}}\|X-Y\|},     where   ğ”¼   ğ”¼   \mathbb{E}   denotes the expected value . H =Â 0Â exactly when X and Y have the same distribution.  Goodness-of-fit  A multivariate goodness-of-fit measure is defined for distributions in arbitrary dimension (not restricted by sample size). The energy goodness-of-fit statistic is        Q  n   =   n   (     2  n     âˆ‘   i  =  1   n    ğ”¼    âˆ¥    x  i   -  X   âˆ¥   Î±      -   ğ”¼    âˆ¥   X  -   X  â€²    âˆ¥   Î±    -    1   n  2      âˆ‘   i  =  1   n     âˆ‘   j  =  1   n     âˆ¥    x  i   -   x  j    âˆ¥   Î±       )     ,       subscript  Q  n     n        2  n     superscript   subscript     i  1    n     ğ”¼   superscript   norm     subscript  x  i   X    Î±        ğ”¼   superscript   norm    X   superscript  X  normal-â€²     Î±        1   superscript  n  2      superscript   subscript     i  1    n     superscript   subscript     j  1    n    superscript   norm     subscript  x  i    subscript  x  j     Î±          Q_{n}=n\left(\frac{2}{n}\sum_{i=1}^{n}\mathbb{E}\|x_{i}-X\|^{\alpha}-\mathbb{E%
 }\|X-X^{\prime}\|^{\alpha}-\frac{1}{n^{2}}\sum_{i=1}^{n}\sum_{j=1}^{n}\|x_{i}-%
 x_{j}\|^{\alpha}\right),   where X and X' are independent and identically distributed according to the hypothesized distribution, and    Î±  âˆˆ   (  0  ,  2  )       Î±   0  2     \alpha\in(0,2)   . The only required condition is that X has finite   Î±   Î±   \alpha   moment under the null hypothesis. Under the null hypothesis     ğ”¼   Q  n    =   ğ”¼    âˆ¥   X  -   X  â€²    âˆ¥   Î±          ğ”¼   subscript  Q  n      ğ”¼   superscript   norm    X   superscript  X  normal-â€²     Î±      \mathbb{E}Q_{n}=\mathbb{E}\|X-X^{\prime}\|^{\alpha}   , and the asymptotic distribution of Q n is a quadratic form of centered Gaussian random variables. Under an alternative hypothesis, Q n tends to infinity stochastically, and thus determines a statistically consistent test. For most applications the exponent 1 (Euclidean distance) can be applied. The important special case of testing multivariate normality 12 is implemented in the energy package for R. Tests are also developed for heavy tailed distributions such as Pareto ( power law ), or stable distributions by application of exponents in (0,1).  Applications  Applications include   Hierarchical clustering (a generalization of Ward's method) 13 14  Testing multivariate normality 15  Testing the multi-sample hypothesis of equal distributions, 16 17   PDF   Change point detection   4  Preprint:TR534 .   Multivariate independence:  distance correlation , 18  Brownian covariance . 19   Scoring rules :    Gneiting and Raftery    Reprint apply energy distance to develop a new and very general type of proper scoring rule for probabilistic predictions, the energy score.   Robust statistics 20  Gene selection 21  Microarray data analysis 22  Material structure analysis 23   Applications of energy statistics are implemented in the open source energy package 24 for R .  References  "  Category:Statistical distance measures  Category:Statistical inference  Category:Multivariate statistics     CramÃ©r, H. (1928) On the composition of elementary errors, Skandinavisk Aktuarietidskrift, 11, 141â€“180. â†©   Reprint â†©  Klebanov, L. B. (2005) N-distances and their Applications, Karolinum Press, Charles University, Prague. â†©   1 â†©  Sejdinovic, D., Gretton, A., Sriperumbudur, B. and Fukumizu, K. (2012) Hypothesis testing using pairwise distances and associated kernels, Proc. of the 29th International Conference on Machine Learning, Edinburgh, Scotland, UK, 2012. 2 â†©  G. J. Szekely and M. L. Rizzo (2013). Energy statistics: statistics based on distances. Journal of Statistical Planning and Inference Volume 143, Issue 8, August 2013, pp. 1249-1272. 3 â†©  SzÃ©kely, G.J. (2002) E-statistics: The Energy of Statistical Samples, Technical Report BGSU No 02-16. â†©     G. J. Szekely and M. L. Rizzo (2004). Testing for Equal Distributions in High Dimension, InterStat , Nov. (5). Reprint . â†©   SzÃ©kely, G. J. and Rizzo, M. L. (2005) Hierarchical Clustering via Joint Between-Within Distances: Extending Ward's Minimum Variance Method, Journal of Classification, 22(2) 151â€“183 â†©   "eprint" . â†©   M. L. Rizzo and G. J. SzÃ©kely (2010). DISCO Analysis: A Nonparametric Extension of Analysis of Variance, Annals of Applied Statistics Vol. 4, No. 2, 1034â€“1055. PDF â†©  Szekely, G. J. and Rizzo, M. L. (2004) Testing for Equal Distributions in High Dimension, InterStat, Nov. (5). Reprint . â†©  SzÃ©kely, G. J., Rizzo M. L. and Bakirov, N. K. (2007). "Measuring and testing independence by correlation of distances", The Annals of Statistics , 35, 2769â€“2794. PDF â†©  SzÃ©kely, G. J. and Rizzo, M. L. (2009). "Brownian distance covariance", The Annals of Applied Statistics , 3/4, 1233â€“1308. PDF â†©  Klebanov L.B. A class of Probability Metrics and its Statistical Applications, Statistics in Industry and Technology: Statistical Data Analysis, Yadolah Dodge, Ed. Birkhauser, Basel, Boston, Berlin, 2002,241-252. â†©  Statistics and Data Analysis, 2006, 50, 12, 3619-3628Rui Hu, Xing Qiu, Galina Glazko, Lev Klebanov, Andrei Yakovlev Detecting intergene correlation changes in microarray analysis: a new approach to gene selection, BMCBioinformatics, Vol.10, 20 (2009), 1-15. â†©  Yuanhui Xiao, Robert Frisina, Alexander Gordon, Lev Klebanov, Andrei Yakovlev Multivariate Search for Diferentially Expressed Gene Combinations BMC Bioinformatics, 2004, 5:164; Antoni Almudevar, Lev Klebanov, Xing Qiu, Andrei Yakovlev Utility of correlation measures in analysis of gene expression, In: NeuroRX, 2006, 3, 3, 384-395; Klebanov Lev, Gordon Alexander, Land Hartmut, Yakovlev Andrei A permutation test motivated by microarray data analysis â†©  Viktor Benes, Radka Lechnerova, Lev Klebanov, Margarita Slamova, Peter Slama Statistical comparison of the geometry of second-phase particles, Materials Characterization , Vol. 60 (2009 ), 1076 - 1081. â†©  â†©     