   Sliding mode control      Sliding mode control   In control system , sliding mode control , or SMC , is a nonlinear control method that alters the dynamics of a nonlinear system by application of a discontinuous control signal that forces the system to "slide" along a cross-section of the system's normal behavior. The state - feedback control law is not a continuous function of time. Instead, it can switch from one continuous structure to another based on the current position in the state space. Hence, sliding mode control is a variable structure control method. The multiple control structures are designed so that trajectories always move toward an adjacent region with a different control structure, and so the ultimate trajectory will not exist entirely within one control structure. Instead, it will slide along the boundaries of the control structures. The motion of the system as it slides along these boundaries is called a sliding mode 1 and the geometrical locus consisting of the boundaries is called the sliding (hyper)surface . In the context of modern control theory, any variable structure system , like a system under SMC, may be viewed as a special case of a hybrid dynamical system as the system both flows through a continuous state space but also moves through different discrete control modes.  Introduction  (Figure)  Figure 1: Phase plane trajectory of a system being stabilized by a sliding mode controller. After the initial reaching phase, the system states "slides" along the line    s  =  0      s  0    s=0   . The particular    s  =  0      s  0    s=0   surface is chosen because it has desirable reduced-order dynamics when constrained to it. In this case, the    s  =    x  1   +    x  ˙   1    =  0        s     subscript  x  1    subscript   normal-˙  x   1         0     s=x_{1}+\dot{x}_{1}=0   surface corresponds to the first-order LTI system       x  ˙   1   =   -   x  1         subscript   normal-˙  x   1      subscript  x  1      \dot{x}_{1}=-x_{1}   , which has an exponentially stable origin.   Figure 1 shows an example trajectory of a system under sliding mode control. The sliding surface is described by    s  =  0      s  0    s=0   , and the sliding mode along the surface commences after the finite time when system trajectories have reached the surface. In the theoretical description of sliding modes, the system stays confined to the sliding surface and need only be viewed as sliding along the surface. However, real implementations of sliding mode control approximate this theoretical behavior with a high-frequency and generally non-deterministic switching control signal that causes the system to "chatter" in a tight neighborhood of the sliding surface. This chattering behavior is evident in Figure 1, which chatters along the    s  =  0      s  0    s=0   surface as the system asymptotically approaches the origin, which is an asymptotically stable equilibrium of the system when confined to the sliding surface. In fact, although the system is nonlinear in general, the idealized (i.e., non-chattering) behavior of the system in Figure 1 when confined to the    s  =  0      s  0    s=0   surface is an LTI system with an exponentially stable origin.  Intuitively, sliding mode control uses practically infinite gain to force the trajectories of a dynamic system to slide along the restricted sliding mode subspace. Trajectories from this reduced-order sliding mode have desirable properties (e.g., the system naturally slides along it until it comes to rest at a desired equilibrium ). The main strength of sliding mode control is its robustness . Because the control can be as simple as a switching between two states (e.g., "on"/"off" or "forward"/"reverse"), it need not be precise and will not be sensitive to parameter variations that enter into the control channel. Additionally, because the control law is not a continuous function , the sliding mode can be reached in finite time (i.e., better than asymptotic behavior). Under certain common conditions, optimality requires the use of bang–bang control ; hence, sliding mode control describes the optimal controller for a broad set of dynamic systems.  One application of sliding mode controller is the control of electric drives operated by switching power converters. 2 Because of the discontinuous operating mode of those converters, a discontinuous sliding mode controller is a natural implementation choice over continuous controllers that may need to be applied by means of pulse-width modulation or a similar technique 3 of applying a continuous signal to an output that can only take discrete states. Sliding mode control has many applications in robotics. In particular, this control algorithm has been used for tracking control of unmanned surface vessels in simulated rough seas with high degree of success. 4 5  Sliding mode control must be applied with more care than other forms of nonlinear control that have more moderate control action. In particular, because actuators have delays and other imperfections, the hard sliding-mode-control action can lead to chatter, energy loss, plant damage, and excitation of unmodeled dynamics. 6 Continuous control design methods are not as susceptible to these problems and can be made to mimic sliding-mode controllers. 7  Control scheme  Consider a nonlinear dynamical system described by            𝐱  ˙    (  t  )    =    f   (  𝐱  ,  t  )    +   B   (  𝐱  ,  t  )   𝐮   (  t  )            normal-˙  𝐱   t       f   𝐱  t      B   𝐱  t   𝐮  t      \dot{\mathbf{x}}(t)=f(\mathbf{x},t)+B(\mathbf{x},t)\,\mathbf{u}(t)          (  1  )    1   (1)\,        where       𝐱   (  t  )    ≜   [       x  1    (  t  )          x  2    (  t  )        ⋮        x   n  -  1     (  t  )          x  n    (  t  )       ]   ∈   ℝ  n        normal-≜    𝐱  t        subscript  x  1   t        subscript  x  2   t     normal-⋮       subscript  x    n  1    t        subscript  x  n   t           superscript  ℝ  n      \mathbf{x}(t)\triangleq\begin{bmatrix}x_{1}(t)\\
 x_{2}(t)\\
 \vdots\\
 x_{n-1}(t)\\
 x_{n}(t)\end{bmatrix}\in\mathbb{R}^{n}   is an   n   n   n   -dimensional state  vector and       𝐮   (  t  )    ≜   [       u  1    (  t  )          u  2    (  t  )        ⋮        u   m  -  1     (  t  )          u  m    (  t  )       ]   ∈   ℝ  m        normal-≜    𝐮  t        subscript  u  1   t        subscript  u  2   t     normal-⋮       subscript  u    m  1    t        subscript  u  m   t           superscript  ℝ  m      \mathbf{u}(t)\triangleq\begin{bmatrix}u_{1}(t)\\
 u_{2}(t)\\
 \vdots\\
 u_{m-1}(t)\\
 u_{m}(t)\end{bmatrix}\in\mathbb{R}^{m}   is an   m   m   m   -dimensional input vector that will be used for state feedback . The functions     f  :     ℝ  n   ×  ℝ   ↦   ℝ  n       normal-:  f   maps-to     superscript  ℝ  n   ℝ    superscript  ℝ  n      f:\mathbb{R}^{n}\times\mathbb{R}\mapsto\mathbb{R}^{n}   and    B  :     ℝ  n   ×  ℝ   ↦   ℝ   n  ×  m        normal-:  B   maps-to     superscript  ℝ  n   ℝ    superscript  ℝ    n  m       B:\mathbb{R}^{n}\times\mathbb{R}\mapsto\mathbb{R}^{n\times m}   are assumed to be continuous and sufficiently smooth so that the Picard–Lindelöf theorem can be used to guarantee that solution    𝐱   (  t  )       𝐱  t    \mathbf{x}(t)   to Equation (1) exists and is unique .  A common task is to design a state-feedback control law     𝐮   (   𝐱   (  t  )    )       𝐮    𝐱  t     \mathbf{u}(\mathbf{x}(t))   (i.e., a mapping from current state    𝐱   (  t  )       𝐱  t    \mathbf{x}(t)   at time   t   t   t   to the input   𝐮   𝐮   \mathbf{u}   ) to stabilize the dynamical system in Equation (1) around the origin     𝐱  =    [  0  ,  0  ,  …  ,  0  ]   T       𝐱   superscript   0  0  normal-…  0   T     \mathbf{x}=[0,0,\ldots,0]^{\text{T}}   . That is, under the control law, whenever the system is started away from the origin, it will return to it. For example, the component    x  1     subscript  x  1    x_{1}   of the state vector   𝐱   𝐱   \mathbf{x}   may represent the difference some output is away from a known signal (e.g., a desirable sinusoidal signal); if the control   𝐮   𝐮   \mathbf{u}   can ensure that    x  1     subscript  x  1    x_{1}   quickly returns to     x  1   =  0       subscript  x  1   0    x_{1}=0   , then the output will track the desired sinusoid. In sliding-mode control, the designer knows that the system behaves desirably (e.g., it has a stable equilibrium ) provided that it is constrained to a subspace of its configuration space . Sliding mode control forces the system trajectories into this subspace and then holds them there so that they slide along it. This reduced-order subspace is referred to as a sliding (hyper)surface , and when closed-loop feedback forces trajectories to slide along it, it is referred to as a sliding mode of the closed-loop system. Trajectories along this subspace can be likened to trajectories along eigenvectors (i.e., modes) of LTI systems ; however, the sliding mode is enforced by creasing the vector field with high-gain feedback. Like a marble rolling along a crack, trajectories are confined to the sliding mode.  The sliding-mode control scheme involves   Selection of a hypersurface or a manifold (i.e., the sliding surface) such that the system trajectory exhibits desirable behavior when confined to this manifold.  Finding feedback gains so that the system trajectory intersects and stays on the manifold.   Because sliding mode control laws are not continuous , it has the ability to drive trajectories to the sliding mode in finite time (i.e., stability of the sliding surface is better than asymptotic). However, once the trajectories reach the sliding surface, the system takes on the character of the sliding mode (e.g., the origin    𝐱  =  𝟎      𝐱  0    \mathbf{x}=\mathbf{0}   may only have asymptotic stability on this surface).  The sliding-mode designer picks a switching function     σ  :    ℝ  n   ↦   ℝ  m       normal-:  σ   maps-to   superscript  ℝ  n    superscript  ℝ  m      \sigma:\mathbb{R}^{n}\mapsto\mathbb{R}^{m}   that represents a kind of "distance" that the states   𝐱   𝐱   \mathbf{x}   are away from a sliding surface.   A state   𝐱   𝐱   \mathbf{x}   that is outside of this sliding surface has     σ   (  𝐱  )    ≠  0        σ  𝐱   0    \sigma(\mathbf{x})\neq 0   .  A state that is on this sliding surface has     σ   (  𝐱  )    =  0        σ  𝐱   0    \sigma(\mathbf{x})=0   .   The sliding-mode-control law switches from one state to another based on the sign of this distance. So the sliding-mode control acts like a stiff pressure always pushing in the direction of the sliding mode where     σ   (  𝐱  )    =  0        σ  𝐱   0    \sigma(\mathbf{x})=0   . Desirable    𝐱   (  t  )       𝐱  t    \mathbf{x}(t)   trajectories will approach the sliding surface, and because the control law is not continuous (i.e., it switches from one state to another as trajectories move across this surface), the surface is reached in finite time. Once a trajectory reaches the surface, it will slide along it and may, for example, move toward the    𝐱  =  𝟎      𝐱  0    \mathbf{x}=\mathbf{0}   origin. So the switching function is like a topographic map with a contour of constant height along which trajectories are forced to move.  The sliding (hyper)surface is of dimension    n  ×  m      n  m    n\times m   where   n   n   n   is the number of states in   𝐱   𝐱   \mathbf{x}   and   m   m   m   is the number of input signals (i.e., control signals) in   𝐮   𝐮   \mathbf{u}   . For each control index    1  ≤  k  ≤  m        1  k       m     1\leq k\leq m   , there is an    n  ×  1      n  1    n\times 1   sliding surface given by          {   𝐱  ∈   ℝ  n    :     σ  k    (  𝐱  )    =  0   }     conditional-set    𝐱   superscript  ℝ  n         subscript  σ  k   𝐱   0     \left\{\mathbf{x}\in\mathbb{R}^{n}:\sigma_{k}(\mathbf{x})=0\right\}          (  2  )    2   (2)\,        The vital part of SMC design is to choose a control law so that the sliding mode (i.e., this surface given by     σ   (  𝐱  )    =  𝟎        σ  𝐱   0    \sigma(\mathbf{x})=\mathbf{0}   ) exists and is reachable along system trajectories. The principle of sliding mode control is to forcibly constrain the system, by suitable control strategy, to stay on the sliding surface on which the system will exhibit desirable features. When the system is constrained by the sliding control to stay on the sliding surface, the system dynamics are governed by reduced-order system obtained from Equation (2).  To force the system states   𝐱   𝐱   \mathbf{x}   to satisfy     σ   (  𝐱  )    =  𝟎        σ  𝐱   0    \sigma(\mathbf{x})=\mathbf{0}   , one must:   Ensure that the system is capable of reaching     σ   (  𝐱  )    =  𝟎        σ  𝐱   0    \sigma(\mathbf{x})=\mathbf{0}   from any initial condition  Having reached     σ   (  𝐱  )    =  𝟎        σ  𝐱   0    \sigma(\mathbf{x})=\mathbf{0}   , the control action is capable of maintaining the system at     σ   (  𝐱  )    =  𝟎        σ  𝐱   0    \sigma(\mathbf{x})=\mathbf{0}      Existence of closed-loop solutions  Note that because the control law is not continuous , it is certainly not locally Lipschitz continuous , and so existence and uniqueness of solutions to the closed-loop system is not guaranteed by the Picard–Lindelöf theorem . Thus the solutions are to be understood in the Filippov sense. 8 9 Roughly speaking, the resulting closed-loop system moving along     σ   (  𝐱  )    =  𝟎        σ  𝐱   0    \sigma(\mathbf{x})=\mathbf{0}   is approximated by the smooth dynamics       σ  ˙    (  𝐱  )    =  𝟎         normal-˙  σ   𝐱   0    \dot{\sigma}(\mathbf{x})=\mathbf{0}   ; however, this smooth behavior may not be truly realizable. Similarly, high-speed pulse-width modulation or delta-sigma modulation produces outputs that only assume two states, but the effective output swings through a continuous range of motion. These complications can be avoided by using a different nonlinear control design method that produces a continuous controller. In some cases, sliding-mode control designs can be approximated by other continuous control designs. 10  Theoretical foundation  The following theorems form the foundation of variable structure control.  Theorem 1: Existence of Sliding Mode  Consider a Lyapunov function candidate           V   (   σ   (  𝐱  )    )    =    1  2    σ  T    (  𝐱  )   σ   (  𝐱  )    =    1  2     ∥   σ   (  𝐱  )    ∥   2  2            V    σ  𝐱        1  2    superscript  σ  T   𝐱  σ  𝐱            1  2    superscript   subscript   norm    σ  𝐱    2   2       V(\sigma(\mathbf{x}))=\frac{1}{2}\sigma^{\text{T}}(\mathbf{x})\sigma(\mathbf{x%
 })=\frac{1}{2}\|\sigma(\mathbf{x})\|_{2}^{2}          (  3  )    3   (3)\,        where    ∥  ⋅  ∥     norm  normal-⋅    \|\mathord{\cdot}\|   is the Euclidean norm (i.e.,     ∥   σ   (  𝐱  )    ∥   2     subscript   norm    σ  𝐱    2    \|\sigma(\mathbf{x})\|_{2}   is the distance away from the sliding manifold where     σ   (  𝐱  )    =  𝟎        σ  𝐱   0    \sigma(\mathbf{x})=\mathbf{0}   ). For the system given by Equation (1) and the sliding surface given by Equation (2), a sufficient condition for the existence of a sliding mode is that             σ  T   ⏞      ∂  V    ∂  σ         σ  ˙   ⏞      d  σ    d  t       ⏟      d  V    d  t      <  0     (i.e.,     d  V    d  t      <   0  )       formulae-sequence     subscript   normal-⏟     superscript   normal-⏞   superscript  σ  T        V     σ      superscript   normal-⏞   normal-˙  σ       normal-d  σ    normal-d  t          normal-d  V    normal-d  t     0       (i.e.,     normal-d  V    normal-d  t       0  )      \underbrace{\overbrace{\sigma^{\text{T}}}^{\tfrac{\partial V}{\partial\sigma}}%
 \overbrace{\dot{\sigma}}^{\tfrac{\operatorname{d}\sigma}{\operatorname{d}t}}}_%
 {\tfrac{\operatorname{d}V}{\operatorname{d}t}}<0\qquad\text{(i.e., }\tfrac{%
 \operatorname{d}V}{\operatorname{d}t}<0\text{)}   in a neighborhood of the surface given by     σ   (  𝐱  )    =  0        σ  𝐱   0    \sigma(\mathbf{x})=0   .  Roughly speaking (i.e., for the scalar control case when    m  =  1      m  1    m=1   ), to achieve      σ  T    σ  ˙    <  0         superscript  σ  T    normal-˙  σ    0    \sigma^{\text{T}}\dot{\sigma}<0   , the feedback control law    u   (  𝐱  )       u  𝐱    u(\mathbf{x})   is picked so that   σ   σ   \sigma   and    σ  ˙     normal-˙  σ    \dot{\sigma}   have opposite signs. That is,       u   (  𝐱  )       u  𝐱    u(\mathbf{x})   makes     σ  ˙    (  𝐱  )        normal-˙  σ   𝐱    \dot{\sigma}(\mathbf{x})   negative when    σ   (  𝐱  )       σ  𝐱    \sigma(\mathbf{x})   is positive.      u   (  𝐱  )       u  𝐱    u(\mathbf{x})   makes     σ  ˙    (  𝐱  )        normal-˙  σ   𝐱    \dot{\sigma}(\mathbf{x})   positive when    σ   (  𝐱  )       σ  𝐱    \sigma(\mathbf{x})   is negative.   Note that       σ  ˙   =     ∂  σ    ∂  𝐱       𝐱  ˙   ⏞      d  𝐱    d  t       =     ∂  σ    ∂  𝐱       (    f   (  𝐱  ,  t  )    +   B   (  𝐱  ,  t  )   𝐮    )   ⏞    𝐱  ˙            normal-˙  σ         σ     𝐱     superscript   normal-⏞   normal-˙  𝐱       normal-d  𝐱    normal-d  t                 σ     𝐱     superscript   normal-⏞      f   𝐱  t      B   𝐱  t   𝐮      normal-˙  𝐱        \dot{\sigma}=\frac{\partial\sigma}{\partial\mathbf{x}}\overbrace{\dot{\mathbf{%
 x}}}^{\tfrac{\operatorname{d}\mathbf{x}}{\operatorname{d}t}}=\frac{\partial%
 \sigma}{\partial\mathbf{x}}\overbrace{\left(f(\mathbf{x},t)+B(\mathbf{x},t)%
 \mathbf{u}\right)}^{\dot{\mathbf{x}}}   and so the feedback control law    𝐮   (  𝐱  )       𝐮  𝐱    \mathbf{u}(\mathbf{x})   has a direct impact on    σ  ˙     normal-˙  σ    \dot{\sigma}   .  Reachability: Attaining sliding manifold in finite time  To ensure that the sliding mode     σ   (  𝐱  )    =  𝟎        σ  𝐱   0    \sigma(\mathbf{x})=\mathbf{0}   is attained in finite time,     d  V   /   d  t        normal-d  V    normal-d  t     \operatorname{d}V/{\operatorname{d}t}   must be more strongly bounded away from zero. That is, if it vanishes too quickly, the attraction to the sliding mode will only be asymptotic. To ensure that the sliding mode is entered in finite time, 11        d  V    d  t    ≤   -   μ    (   V   )   α            normal-d  V    normal-d  t        μ   superscript    V   α       \frac{\operatorname{d}V}{\operatorname{d}t}\leq-\mu(\sqrt{V})^{\alpha}   where    μ  >  0      μ  0    \mu>0   and    0  <  α  ≤  1        0  α       1     0<\alpha\leq 1   are constants.   Explanation by comparison lemma   This condition ensures that for the neighborhood of the sliding mode    V  ∈   [  0  ,  1  ]       V   0  1     V\in[0,1]   ,         d  V    d  t    ≤   -   μ    (   V   )   α     ≤   -   μ   V      .           normal-d  V    normal-d  t        μ   superscript    V   α              μ    V        \frac{\operatorname{d}V}{\operatorname{d}t}\leq-\mu(\sqrt{V})^{\alpha}\leq-\mu%
 \sqrt{V}.   So, for    V  ∈   (  0  ,  1  ]       V   0  1     V\in(0,1]   ,         1   V      d  V    d  t     ≤   -  μ    ,          1    V       normal-d  V    normal-d  t       μ     \frac{1}{\sqrt{V}}\frac{\operatorname{d}V}{\operatorname{d}t}\leq-\mu,   which, by the chain rule (i.e.,     d  W   /   d  t        normal-d  W    normal-d  t     \operatorname{d}W/{\operatorname{d}t}   with    W  ≜   2   V       normal-≜  W    2    V      W\triangleq 2\sqrt{V}   ), means          D  +    (     2     V   ⏞     ∝    ∥  σ  ∥   2      ⏟   W   )    ⏟      D  +    W    ≜   Upper right-hand   W  ˙      =    1   V      d  V    d  t     ≤   -  μ              D  +    (     2     V   ⏞     ∝    ∥  σ  ∥   2      ⏟   W   )    ⏟      D  +    W    ≜   Upper right-hand   W  ˙           1    V       normal-d  V    normal-d  t            μ      \mathord{\underbrace{D^{+}\Bigl(\mathord{\underbrace{2\mathord{\overbrace{%
 \sqrt{V}}^{{}\propto\|\sigma\|_{2}}}}_{W}}\Bigr)}_{D^{+}W\,\triangleq\,%
 \mathord{\text{Upper right-hand }\dot{W}}}}=\frac{1}{\sqrt{V}}\frac{%
 \operatorname{d}V}{\operatorname{d}t}\leq-\mu   where    D  +     superscript  D     D^{+}   is the upper right-hand derivative of    2   V       2    V     2\sqrt{V}   and the symbol   ∝   proportional-to   \propto   denotes proportionality . So, by comparison to the curve     z   (  t  )    =    z  0   -   μ  t          z  t      subscript  z  0     μ  t      z(t)=z_{0}-\mu t   which is represented by differential equation     z  ˙   =   -  μ        normal-˙  z     μ     \dot{z}=-\mu   with initial condition     z   (  0  )    =   z  0         z  0    subscript  z  0     z(0)=z_{0}   , it must be the case that     2    V   (  t  )      ≤    V  0   -   μ  t          2      V  t        subscript  V  0     μ  t      2\sqrt{V(t)}\leq V_{0}-\mu t   for all   t   t   t   . Moreover, because     V   ≥  0        V   0    \sqrt{V}\geq 0   ,    V      V    \sqrt{V}   must reach     V   =  0        V   0    \sqrt{V}=0   in finite time, which means that   V   V   V   must reach    V  =  0      V  0    V=0   (i.e., the system enters the sliding mode) in finite time. 12 Because    V      V    \sqrt{V}   is proportional to the Euclidean norm      ∥  ⋅  ∥   2     subscript   norm  normal-⋅   2    \|\mathord{\cdot}\|_{2}   of the switching function   σ   σ   \sigma   , this result implies that the rate of approach to the sliding mode must be firmly bounded away from zero.   Consequences for sliding mode control   In the context of sliding mode control, this condition means that            σ  T   ⏞      ∂  V    ∂  σ         σ  ˙   ⏞      d  σ    d  t       ⏟      d  V    d  t      ≤   -   μ    (      ∥  σ  ∥   2   ⏞    V    )   α          subscript   normal-⏟     superscript   normal-⏞   superscript  σ  T        V     σ      superscript   normal-⏞   normal-˙  σ       normal-d  σ    normal-d  t          normal-d  V    normal-d  t         μ   superscript       ∥  σ  ∥   2   ⏞    V     α       \underbrace{\overbrace{\sigma^{\text{T}}}^{\tfrac{\partial V}{\partial\sigma}}%
 \overbrace{\dot{\sigma}}^{\tfrac{\operatorname{d}\sigma}{\operatorname{d}t}}}_%
 {\tfrac{\operatorname{d}V}{\operatorname{d}t}}\leq-\mu(\mathord{\overbrace{\|%
 \sigma\|_{2}}^{\sqrt{V}}})^{\alpha}   where    ∥  ⋅  ∥     norm  normal-⋅    \|\mathord{\cdot}\|   is the Euclidean norm . For the case when switching function   σ   σ   \sigma   is scalar valued, the sufficient condition becomes       σ   σ  ˙    ≤   -   μ    |  σ  |   α           σ   normal-˙  σ        μ   superscript    σ   α       \sigma\dot{\sigma}\leq-\mu|\sigma|^{\alpha}   . Taking    α  =  1      α  1    \alpha=1   , the scalar sufficient condition becomes        sgn   (  σ  )     σ  ˙    ≤   -  μ         sgn  σ    normal-˙  σ      μ     \operatorname{sgn}(\sigma)\dot{\sigma}\leq-\mu   which is equivalent to the condition that        sgn   (  σ  )    ≠    sgn   (   σ  ˙   )    and      |   σ  ˙   |   ≥  μ  >  0      formulae-sequence     sgn  σ     sgn   normal-˙  σ    and           normal-˙  σ    μ       0      \operatorname{sgn}(\sigma)\neq\operatorname{sgn}(\dot{\sigma})\qquad\text{and}%
 \qquad|\dot{\sigma}|\geq\mu>0   . That is, the system should always be moving toward the switching surface    σ  =  0      σ  0    \sigma=0   , and its speed    |   σ  ˙   |       normal-˙  σ     |\dot{\sigma}|   toward the switching surface should have a non-zero lower bound. So, even though   σ   σ   \sigma   may become vanishingly small as   𝐱   𝐱   \mathbf{x}   approaches the     σ   (  𝐱  )    =  𝟎        σ  𝐱   0    \sigma(\mathbf{x})=\mathbf{0}   surface,    σ  ˙     normal-˙  σ    \dot{\sigma}   must always be bounded firmly away from zero. To ensure this condition, sliding mode controllers are discontinuous across the    σ  =  0      σ  0    \sigma=0   manifold; they switch from one non-zero value to another as trajectories cross the manifold.  Theorem 2: Region of Attraction  For the system given by Equation (1) and sliding surface given by Equation (2), the subspace for which the    {   𝐱  ∈   ℝ  n    :    σ   (  𝐱  )    =  𝟎   }     conditional-set    𝐱   superscript  ℝ  n        σ  𝐱   0     \{\mathbf{x}\in\mathbb{R}^{n}:\sigma(\mathbf{x})=\mathbf{0}\}   surface is reachable is given by      {   𝐱  ∈   ℝ  n    :     σ  T    (  𝐱  )    σ  ˙    (  𝐱  )    <  0   }     conditional-set    𝐱   superscript  ℝ  n         superscript  σ  T   𝐱   normal-˙  σ   𝐱   0     \{\mathbf{x}\in\mathbb{R}^{n}:\sigma^{\text{T}}(\mathbf{x})\dot{\sigma}(%
 \mathbf{x})<0\}   That is, when initial conditions come entirely from this space, the Lyapunov function candidate    V   (  σ  )       V  σ    V(\sigma)   is a Lyapunov function and   𝐱   𝐱   \mathbf{x}   trajectories are sure to move toward the sliding mode surface where     σ   (  𝐱  )    =  𝟎        σ  𝐱   0    \sigma(\mathbf{x})=\mathbf{0}   . Moreover, if the reachability conditions from Theorem 1 are satisfied, the sliding mode will enter the region where    V  ˙     normal-˙  V    \dot{V}   is more strongly bounded away from zero in finite time. Hence, the sliding mode    σ  =  0      σ  0    \sigma=0   will be attained in finite time.  Theorem 3: Sliding Motion  Let        ∂  σ    ∂  𝐱    B   (  𝐱  ,  t  )           σ     𝐱    B   𝐱  t     \frac{\partial\sigma}{\partial{\mathbf{x}}}B(\mathbf{x},t)   be nonsingular . That is, the system has a kind of controllability that ensures that there is always a control that can move a trajectory to move closer to the sliding mode. Then, once the sliding mode where     σ   (  𝐱  )    =  𝟎        σ  𝐱   0    \sigma(\mathbf{x})=\mathbf{0}   is achieved, the system will stay on that sliding mode. Along sliding mode trajectories,    σ   (  𝐱  )       σ  𝐱    \sigma(\mathbf{x})   is constant, and so sliding mode trajectories are described by the differential equation       σ  ˙   =  𝟎       normal-˙  σ   0    \dot{\sigma}=\mathbf{0}   . If an   𝐱   𝐱   \mathbf{x}   - equilibrium is stable with respect to this differential equation, then the system will slide along the sliding mode surface toward the equilibrium.  The equivalent control law on the sliding mode can be found by solving        σ  ˙    (  𝐱  )    =  0         normal-˙  σ   𝐱   0    \dot{\sigma}(\mathbf{x})=0   for the equivalent control law    𝐮   (  𝐱  )       𝐮  𝐱    \mathbf{u}(\mathbf{x})   . That is,         ∂  σ    ∂  𝐱       (    f   (  𝐱  ,  t  )    +   B   (  𝐱  ,  t  )   𝐮    )   ⏞    𝐱  ˙     =  𝟎            σ     𝐱     superscript   normal-⏞      f   𝐱  t      B   𝐱  t   𝐮      normal-˙  𝐱     0    \frac{\partial\sigma}{\partial\mathbf{x}}\overbrace{\left(f(\mathbf{x},t)+B(%
 \mathbf{x},t)\mathbf{u}\right)}^{\dot{\mathbf{x}}}=\mathbf{0}   and so the equivalent control      𝐮  =   -     (     ∂  σ    ∂  𝐱    B   (  𝐱  ,  t  )    )    -  1      ∂  σ    ∂  𝐱    f   (  𝐱  ,  t  )         𝐮       superscript        σ     𝐱    B   𝐱  t      1        σ     𝐱    f   𝐱  t       \mathbf{u}=-\left(\frac{\partial\sigma}{\partial\mathbf{x}}B(\mathbf{x},t)%
 \right)^{-1}\frac{\partial\sigma}{\partial\mathbf{x}}f(\mathbf{x},t)   That is, even though the actual control   𝐮   𝐮   \mathbf{u}   is not continuous , the rapid switching across the sliding mode where     σ   (  𝐱  )    =  𝟎        σ  𝐱   0    \sigma(\mathbf{x})=\mathbf{0}   forces the system to act as if it were driven by this continuous control.  Likewise, the system trajectories on the sliding mode behave as if       𝐱  ˙   =      f   (  𝐱  ,  t  )    -   B   (  𝐱  ,  t  )     (     ∂  σ    ∂  𝐱    B   (  𝐱  ,  t  )    )    -  1      ∂  σ    ∂  𝐱    f   (  𝐱  ,  t  )     ⏞     f   (  𝐱  ,  t  )    +   B   (  𝐱  ,  t  )   u     =   f   (  𝐱  ,  t  )    (   𝐈  -   B   (  𝐱  ,  t  )     (     ∂  σ    ∂  𝐱    B   (  𝐱  ,  t  )    )    -  1      ∂  σ    ∂  𝐱      )           normal-˙  𝐱    superscript   normal-⏞      f   𝐱  t      B   𝐱  t    superscript        σ     𝐱    B   𝐱  t      1        σ     𝐱    f   𝐱  t          f   𝐱  t      B   𝐱  t   u            f   𝐱  t     𝐈    B   𝐱  t    superscript        σ     𝐱    B   𝐱  t      1        σ     𝐱          \dot{\mathbf{x}}=\overbrace{f(\mathbf{x},t)-B(\mathbf{x},t)\left(\frac{%
 \partial\sigma}{\partial\mathbf{x}}B(\mathbf{x},t)\right)^{-1}\frac{\partial%
 \sigma}{\partial\mathbf{x}}f(\mathbf{x},t)}^{f(\mathbf{x},t)+B(\mathbf{x},t)u}%
 =f(\mathbf{x},t)\left(\mathbf{I}-B(\mathbf{x},t)\left(\frac{\partial\sigma}{%
 \partial\mathbf{x}}B(\mathbf{x},t)\right)^{-1}\frac{\partial\sigma}{\partial%
 \mathbf{x}}\right)   The resulting system matches the sliding mode differential equation        σ  ˙    (  𝐱  )    =  𝟎         normal-˙  σ   𝐱   0    \dot{\sigma}(\mathbf{x})=\mathbf{0}   and so as long as the sliding mode surface where     σ   (  𝐱  )    =  𝟎        σ  𝐱   0    \sigma(\mathbf{x})=\mathbf{0}   is stable (in the sense of Lyapunov) , the system can be assumed to follow the simpler     σ  ˙   =  0       normal-˙  σ   0    \dot{\sigma}=0   condition after some initial transient during the period while the system finds the sliding mode. The same motion is approximately maintained provided the equality     σ   (  𝐱  )    =  𝟎        σ  𝐱   0    \sigma(\mathbf{x})=\mathbf{0}   only approximately holds.  It follows from these theorems that the sliding motion is invariant (i.e., insensitive) to sufficiently small disturbances entering the system through the control channel. That is, as long as the control is large enough to ensure that      σ  T    σ  ˙    <  0         superscript  σ  T    normal-˙  σ    0    \sigma^{\text{T}}\dot{\sigma}<0   and    σ  ˙     normal-˙  σ    \dot{\sigma}   is uniformly bounded away from zero, the sliding mode will be maintained as if there was no disturbance. The invariance property of sliding mode control to certain disturbances and model uncertainties is its most attractive feature; it is strongly robust .  As discussed in an example below, a sliding mode control law can keep the constraint        x  ˙   +  x   =  0         normal-˙  x   x   0    \dot{x}+x=0   in order to asymptotically stabilize any system of the form       x  ¨   =    a   (  t  ,  x  ,   x  ˙   )    +  u        normal-¨  x       a   t  x   normal-˙  x     u     \ddot{x}=a(t,x,\dot{x})+u   when    a   (  ⋅  )       a  normal-⋅    a(\cdot)   has a finite upper bound. In this case, the sliding mode is where       x  ˙   =   -  x        normal-˙  x     x     \dot{x}=-x   (i.e., where      x  ˙   +  x   =  0         normal-˙  x   x   0    \dot{x}+x=0   ). That is, when the system is constrained this way, it behaves like a simple stable  linear system , and so it has a globally exponentially stable equilibrium at the     (  x  ,   x  ˙   )   =   (  0  ,  0  )        x   normal-˙  x     0  0     (x,\dot{x})=(0,0)   origin.  Control design examples   Consider a plant described by Equation (1) with single input   u   u   u   (i.e.,    m  =  1      m  1    m=1   ). The switching function is picked to be the linear combination             \sigma(\mathbf{x}) \triangleq s_1 x_1 + s_2 x_2 + \cdots + s_{n-1} x_{n-1} + s_n x_n       (  4  )    4   (4)\,         where the weight     s  i   >  0       subscript  s  i   0    s_{i}>0   for all    1  ≤  i  ≤  n        1  i       n     1\leq i\leq n   . The sliding surface is the simplex where     σ   (  𝐱  )    =  0        σ  𝐱   0    \sigma(\mathbf{x})=0   . When trajectories are forced to slide along this surface,       σ  ˙    (  𝐱  )    =  0         normal-˙  σ   𝐱   0    \dot{\sigma}(\mathbf{x})=0      and so        s  1     x  ˙   1    +    s  2     x  ˙   2    +  ⋯  +    s   n  -  1      x  ˙    n  -  1     +    s  n     x  ˙   n     =  0           subscript  s  1    subscript   normal-˙  x   1       subscript  s  2    subscript   normal-˙  x   2    normal-⋯     subscript  s    n  1     subscript   normal-˙  x     n  1        subscript  s  n    subscript   normal-˙  x   n     0    s_{1}\dot{x}_{1}+s_{2}\dot{x}_{2}+\cdots+s_{n-1}\dot{x}_{n-1}+s_{n}\dot{x}_{n}=0      which is a reduced-order system (i.e., the new system is of order    n  -  1      n  1    n-1   because the system is constrained to this    (   n  -  1   )      n  1    (n-1)   -dimensional sliding mode simplex). This surface may have favorable properties (e.g., when the plant dynamics are forced to slide along this surface, they move toward the origin    𝐱  =  𝟎      𝐱  0    \mathbf{x}=\mathbf{0}   ). Taking the derivative of the Lyapunov function in Equation (3), we have :    \dot{V}(\sigma(\mathbf{x})) = \overbrace{\sigma(\mathbf{x})^{\text{T}}}^{\tfrac{\partial \sigma}{\partial \mathbf{x}}} \overbrace{\dot{\sigma}(\mathbf{x})}^{\tfrac{\operatorname{d} \sigma}{\operatorname{d} t}}   To ensure    V  ˙     normal-˙  V    \dot{V}   is a negative-definite function (i.e.,     V  ˙   <  0       normal-˙  V   0    \dot{V}<0   for Lyapunov stability of the surface    σ  =  0      σ  0    \mathbf{\sigma}=0   ), the feedback control law    u   (  𝐱  )       u  𝐱    u(\mathbf{x})   must be chosen so that : \begin{cases}    \dot{\sigma}  0\\ \dot{\sigma} > 0 &\text{if } \sigma   Hence, the product     σ   σ  ˙    <  0        σ   normal-˙  σ    0    \sigma\dot{\sigma}<0   because it is the product of a negative and a positive number. Note that        \dot{\sigma}(\mathbf{x})     \overbrace{\frac{\partial{\sigma(\mathbf{x})}}{\partial{\mathbf{x}}} \dot{\mathbf{x}}}^{\dot{\sigma}(\mathbf{x})}  \frac{\partial{\sigma(\mathbf{x})}}{\partial{\mathbf{x}}}  \overbrace{\left( f(\mathbf{x},t) + B(\mathbf{x},t) u \right)}^{\dot{\mathbf{x}}}  = \overbrace{[s_1, s_2, \ldots, s_n]}^{\frac{\partial{\sigma(\mathbf{x})}}{\partial{\mathbf{x}}}}  \underbrace{\overbrace{\left( f(\mathbf{x},t) + B(\mathbf{x},t) u \right)}^{\dot{\mathbf{x}}}}_{\text{( i.e., an } n \times 1 \text{ vector )}}       (  5  )    5   (5)\,         The control law    u   (  𝐱  )       u  𝐱    u(\mathbf{x})   is chosen so that : u(\mathbf{x})    = \begin{cases} u^+(\mathbf{x}) &\text{if } \sigma(\mathbf{x}) > 0 \\ u^-(\mathbf{x}) &\text{if } \sigma(\mathbf{x})   where       u  +    (  𝐱  )        superscript  u    𝐱    u^{+}(\mathbf{x})   is some control (e.g., possibly extreme, like "on" or "forward") that ensures Equation (5) (i.e.,    σ  ˙     normal-˙  σ    \dot{\sigma}   ) is negative at   𝐱   𝐱   \mathbf{x}          u  -    (  𝐱  )        superscript  u    𝐱    u^{-}(\mathbf{x})   is some control (e.g., possibly extreme, like "off" or "reverse") that ensures Equation (5) (i.e.,    σ  ˙     normal-˙  σ    \dot{\sigma}   ) is positive at   𝐱   𝐱   \mathbf{x}       The resulting trajectory should move toward the sliding surface where     σ   (  𝐱  )    =  0        σ  𝐱   0    \sigma(\mathbf{x})=0   . Because real systems have delay, sliding mode trajectories often chatter back and forth along this sliding surface (i.e., the true trajectory may not smoothly follow     σ   (  𝐱  )    =  0        σ  𝐱   0    \sigma(\mathbf{x})=0   , but it will always return to the sliding mode after leaving it).    Consider the dynamic system          x  ¨   =    a   (  t  ,  x  ,   x  ˙   )    +  u        normal-¨  x       a   t  x   normal-˙  x     u     \ddot{x}=a(t,x,\dot{x})+u       which can be expressed in a 2-dimensional state space (with     x  1   =  x       subscript  x  1   x    x_{1}=x   and     x  2   =   x  ˙        subscript  x  2    normal-˙  x     x_{2}=\dot{x}   ) as :    \begin{cases} \dot{x}_1 = x_2\\ \dot{x}_2 = a(t,x_1,x_2) + u \end{cases}   Also assume that     sup   {   |   a   (  ⋅  )    |   }    ≤  k       supremum       a  normal-⋅      k    \sup\{|a(\cdot)|\}\leq k   (i.e.,    |  a  |      a    |a|   has a finite upper bound   k   k   k   that is known). For this system, choose the switching function      σ   (   x  1   ,   x  2   )    =    x  1   +   x  2    =   x  +   x  ˙            σ    subscript  x  1    subscript  x  2        subscript  x  1    subscript  x  2           x   normal-˙  x       \sigma(x_{1},x_{2})=x_{1}+x_{2}=x+\dot{x}      By the previous example, we must choose the feedback control law    u   (  x  ,   x  ˙   )       u   x   normal-˙  x      u(x,\dot{x})   so that     σ   σ  ˙    <  0        σ   normal-˙  σ    0    \sigma\dot{\sigma}<0   . Here,      σ  ˙   =     x  ˙   1   +    x  ˙   2    =    x  ˙   +   x  ¨    =     x  ˙    +      a   (  t  ,  x  ,   x  ˙   )    +  u   ⏞    x  ¨            normal-˙  σ      subscript   normal-˙  x   1    subscript   normal-˙  x   2            normal-˙  x    normal-¨  x            normal-˙  x    superscript   normal-⏞      a   t  x   normal-˙  x     u     normal-¨  x        \dot{\sigma}=\dot{x}_{1}+\dot{x}_{2}=\dot{x}+\ddot{x}=\dot{x}\,+\,\overbrace{a%
 (t,x,\dot{x})+u}^{\ddot{x}}      When     x  +   x  ˙    <  0        x   normal-˙  x    0    x+\dot{x}<0   (i.e., when    σ  <  0      σ  0    \sigma<0   ), to make     σ  ˙   >  0       normal-˙  σ   0    \dot{\sigma}>0   , the control law should be picked so that    u  >   |    x  ˙   +   a   (  t  ,  x  ,   x  ˙   )     |       u       normal-˙  x     a   t  x   normal-˙  x         u>|\dot{x}+a(t,x,\dot{x})|     When     x  +   x  ˙    >  0        x   normal-˙  x    0    x+\dot{x}>0   (i.e., when    σ  >  0      σ  0    \sigma>0   ), to make     σ  ˙   <  0       normal-˙  σ   0    \dot{\sigma}<0   , the control law should be picked so that    u  <   -   |    x  ˙   +   a   (  t  ,  x  ,   x  ˙   )     |        u         normal-˙  x     a   t  x   normal-˙  x          u<-|\dot{x}+a(t,x,\dot{x})|       However, by the triangle inequality ,       |   x  ˙   |   +   |   a   (  t  ,  x  ,   x  ˙   )    |    ≥   |    x  ˙   +   a   (  t  ,  x  ,   x  ˙   )     |            normal-˙  x        a   t  x   normal-˙  x            normal-˙  x     a   t  x   normal-˙  x         |\dot{x}|+|a(t,x,\dot{x})|\geq|\dot{x}+a(t,x,\dot{x})|      and by the assumption about    |  a  |      a    |a|   ,       |   x  ˙   |   +  k  +  1   >    |   x  ˙   |   +   |   a   (  t  ,  x  ,   x  ˙   )    |             normal-˙  x    k  1        normal-˙  x        a   t  x   normal-˙  x         |\dot{x}|+k+1>|\dot{x}|+|a(t,x,\dot{x})|      So the system can be feedback stabilized (to return to the sliding mode) by means of the control law : u(x,\dot{x})    = \begin{cases}  |\dot{x}| + k + 1 &\text{if } \underbrace{x + \dot{x}} 0  \end{cases}   which can be expressed in closed form as      u   (  x  ,   x  ˙   )    =   -    (    |   x  ˙   |   +  k  +  1   )      sgn   (      x  ˙   +  x   ⏞   σ   )    ⏟     (i.e., tests  σ   >   0  )             u   x   normal-˙  x              normal-˙  x    k  1    subscript   normal-⏟   sgn   superscript   normal-⏞     normal-˙  x   x    σ         (i.e., tests  σ     0  )         u(x,\dot{x})=-(|\dot{x}|+k+1)\underbrace{\operatorname{sgn}(\overbrace{\dot{x}%
 +x}^{\sigma})}_{\text{(i.e., tests }\sigma>0\text{)}}      Assuming that the system trajectories are forced to move so that     σ   (  𝐱  )    =  0        σ  𝐱   0    \sigma(\mathbf{x})=0   , then       x  ˙   =   -  x      (i.e.,  σ   (  x  ,   x  ˙   )    =   x  +   x  ˙    =   0  )       formulae-sequence     normal-˙  x     x          (i.e.,  σ   x   normal-˙  x       x   normal-˙  x           0  )       \dot{x}=-x\qquad\text{(i.e., }\sigma(x,\dot{x})=x+\dot{x}=0\text{)}      So once the system reaches the sliding mode, the system's 2-dimensional dynamics behave like this 1-dimensional system, which has a globally exponentially stable equilibrium at     (  x  ,   x  ˙   )   =   (  0  ,  0  )        x   normal-˙  x     0  0     (x,\dot{x})=(0,0)   .   Automated design solutions  Although various theories exist for sliding mode control system design, there is a lack of a highly effective design methodology due to practical difficulties encountered in analytical and numerical methods. A reusable computing paradigm such as a genetic algorithm can, however, be utilized to transform a 'unsolvable problem' of optimal design into a practically solvable 'non-deterministic polynomial problem'. This results in computer-automated designs for sliding model control. 13  Sliding mode observer  Sliding mode control can be used in the design of state observers . These non-linear high-gain observers have the ability to bring coordinates of the estimator error dynamics to zero in finite time. Additionally, switched-mode observers have attractive measurement noise resilience that is similar to a Kalman filter . 14 15 For simplicity, the example here uses a traditional sliding mode modification of a Luenberger observer for an LTI system . In these sliding mode observers, the order of the observer dynamics are reduced by one when the system enters the sliding mode. In this particular example, the estimator error for a single estimated state is brought to zero in finite time, and after that time the other estimator errors decay exponentially to zero. However, as first described by Drakunov, 16 a sliding mode observer for non-linear systems can be built that brings the estimation error for all estimated states to zero in a finite (and arbitrarily small) time.  Here, consider the LTI system      {       𝐱  ˙   =    A  𝐱   +   B  𝐮           y  =    [     1    0    0    ⋯        ]   𝐱   =   x  1           cases     normal-˙  𝐱       A  𝐱     B  𝐮     otherwise      y      1  0  0  normal-⋯  absent    𝐱         subscript  x  1     otherwise    \begin{cases}\dot{\mathbf{x}}=A\mathbf{x}+B\mathbf{u}\\
 y=\begin{bmatrix}1&0&0&\cdots&\end{bmatrix}\mathbf{x}=x_{1}\end{cases}   where state vector    𝐱  ≜   (   x  1   ,   x  2   ,  …  ,   x  n   )   ∈   ℝ  n        normal-≜  𝐱    subscript  x  1    subscript  x  2   normal-…   subscript  x  n          superscript  ℝ  n      \mathbf{x}\triangleq(x_{1},x_{2},\dots,x_{n})\in\mathbb{R}^{n}   ,    𝐮  ≜   (   u  1   ,   u  2   ,  …  ,   u  r   )   ∈   ℝ  r        normal-≜  𝐮    subscript  u  1    subscript  u  2   normal-…   subscript  u  r          superscript  ℝ  r      \mathbf{u}\triangleq(u_{1},u_{2},\dots,u_{r})\in\mathbb{R}^{r}   is a vector of inputs, and output   y   y   y   is a scalar equal to the first state of the   𝐱   𝐱   \mathbf{x}   state vector. Let      A  ≜   [      a  11      A  12        A  21      A  22      ]      normal-≜  A     subscript  a  11    subscript  A  12      subscript  A  21    subscript  A  22       A\triangleq\begin{bmatrix}a_{11}&A_{12}\\
 A_{21}&A_{22}\end{bmatrix}   where       a  11     subscript  a  11    a_{11}   is a scalar representing the influence of the first state    x  1     subscript  x  1    x_{1}   on itself,       A  21   ∈   ℝ   (   n  -  1   )         subscript  A  21    superscript  ℝ    n  1      A_{21}\in\mathbb{R}^{(n-1)}   is a column vector representing the influence of the other states on the first state,       A  22   ∈   ℝ    (   n  -  1   )   ×   (   n  -  1   )          subscript  A  22    superscript  ℝ      n  1     n  1       A_{22}\in\mathbb{R}^{(n-1)\times(n-1)}   is a matrix representing the influence of the other states on themselves, and       A  12   ∈   ℝ   1  ×   (   n  -  1   )          subscript  A  12    superscript  ℝ    1    n  1       A_{12}\in\mathbb{R}^{1\times(n-1)}   is a row vector corresponding to the influence of the first state on the other states.   The goal is to design a high-gain state observer that estimates the state vector   𝐱   𝐱   \mathbf{x}   using only information from the measurement    y  =   x  1       y   subscript  x  1     y=x_{1}   . Hence, let the vector     𝐱  ^   =   (    x  ^   1   ,    x  ^   2   ,  …  ,    x  ^   n   )   ∈   ℝ  n          normal-^  𝐱     subscript   normal-^  x   1    subscript   normal-^  x   2   normal-…   subscript   normal-^  x   n          superscript  ℝ  n      \hat{\mathbf{x}}=(\hat{x}_{1},\hat{x}_{2},\dots,\hat{x}_{n})\in\mathbb{R}^{n}   be the estimates of the   n   n   n   states. The observer takes the form        𝐱  ^   ˙   =    A   𝐱  ^    +   B  𝐮   +   L  v   (     x  ^   1   -   x  1    )          normal-˙   normal-^  𝐱        A   normal-^  𝐱      B  𝐮     L  v     subscript   normal-^  x   1    subscript  x  1        \dot{\hat{\mathbf{x}}}=A\hat{\mathbf{x}}+B\mathbf{u}+Lv(\hat{x}_{1}-x_{1})   where    v  :    \R   ↦   \R       normal-:  v   maps-to  \R  \R     v:\R\mapsto\R   is a nonlinear function of the error between estimated state     x  ^   1     subscript   normal-^  x   1    \hat{x}_{1}   and the output    y  =   x  1       y   subscript  x  1     y=x_{1}   , and    L  ∈   ℝ  n       L   superscript  ℝ  n     L\in\mathbb{R}^{n}   is an observer gain vector that serves a similar purpose as in the typical linear Luenberger observer . Likewise, let      L  =   [      -  1        L  2      ]       L      1      subscript  L  2       L=\begin{bmatrix}-1\\
 L_{2}\end{bmatrix}   where     L  2   ∈   ℝ   (   n  -  1   )         subscript  L  2    superscript  ℝ    n  1      L_{2}\in\mathbb{R}^{(n-1)}   is a column vector. Additionally, let    𝐞  =   (   e  1   ,   e  2   ,  …  ,   e  n   )   ∈   ℝ  n         𝐞    subscript  e  1    subscript  e  2   normal-…   subscript  e  n          superscript  ℝ  n      \mathbf{e}=(e_{1},e_{2},\dots,e_{n})\in\mathbb{R}^{n}   be the state estimator error. That is,    𝐞  =    𝐱  ^   -  𝐱       𝐞     normal-^  𝐱   𝐱     \mathbf{e}=\hat{\mathbf{x}}-\mathbf{x}   . The error dynamics are then      {       𝐞  ˙   =     𝐱  ^   ˙   -   𝐱  ˙            =     A   𝐱  ^    +   B  𝐮   +   L  v   (     x  ^   1   -   x  1    )     -   A  𝐱   -   B  𝐮            =    A   (    𝐱  ^   -  𝐱   )    +   L  v   (     x  ^   1   -   x  1    )             =    A  𝐞   +   L  v   (   e  1   )             cases     normal-˙  𝐞      normal-˙   normal-^  𝐱     normal-˙  𝐱     otherwise    absent        A   normal-^  𝐱      B  𝐮     L  v     subscript   normal-^  x   1    subscript  x  1        A  𝐱     B  𝐮     otherwise    absent      A     normal-^  𝐱   𝐱      L  v     subscript   normal-^  x   1    subscript  x  1       otherwise    absent      A  𝐞     L  v   subscript  e  1      otherwise    \begin{cases}\dot{\mathbf{e}}=\dot{\hat{\mathbf{x}}}-\dot{\mathbf{x}}\\
 =A\hat{\mathbf{x}}+B\mathbf{u}+Lv(\hat{x}_{1}-x_{1})-A\mathbf{x}-B\mathbf{u}\\
 =A(\hat{\mathbf{x}}-\mathbf{x})+Lv(\hat{x}_{1}-x_{1})\\
 =A\mathbf{e}+Lv(e_{1})\end{cases}   where     e  1   =     x  ^   1   -   x  1         subscript  e  1      subscript   normal-^  x   1    subscript  x  1      e_{1}=\hat{x}_{1}-x_{1}   is the estimator error for the first state estimate. The nonlinear control law   v   v   v   can be designed to enforce the sliding manifold      0  =     x  ^   1   -   x  1        0     subscript   normal-^  x   1    subscript  x  1      0=\hat{x}_{1}-x_{1}   so that estimate     x  ^   1     subscript   normal-^  x   1    \hat{x}_{1}   tracks the real state    x  1     subscript  x  1    x_{1}   after some finite time (i.e.,      x  ^   1   =   x  1        subscript   normal-^  x   1    subscript  x  1     \hat{x}_{1}=x_{1}   ). Hence, the sliding mode control switching function        σ   (    x  ^   1   ,   x  ^   )    ≜   e  1   =     x  ^   1   -   x  1     .       normal-≜    σ    subscript   normal-^  x   1    normal-^  x      subscript  e  1           subscript   normal-^  x   1    subscript  x  1       \sigma(\hat{x}_{1},\hat{x})\triangleq e_{1}=\hat{x}_{1}-x_{1}.   To attain the sliding manifold,    σ  ˙     normal-˙  σ    \dot{\sigma}   and   σ   σ   \sigma   must always have opposite signs (i.e.,     σ   σ  ˙    <  0        σ   normal-˙  σ    0    \sigma\dot{\sigma}<0   for essentially all   𝐱   𝐱   \mathbf{x}   ). However,       σ  ˙   =    e  ˙   1   =      a  11    e  1    +    A  12    𝐞  2     -   v   (   e  1   )     =      a  11    e  1    +    A  12    𝐞  2     -   v   (  σ  )            normal-˙  σ    subscript   normal-˙  e   1               subscript  a  11    subscript  e  1       subscript  A  12    subscript  𝐞  2       v   subscript  e  1                 subscript  a  11    subscript  e  1       subscript  A  12    subscript  𝐞  2       v  σ       \dot{\sigma}=\dot{e}_{1}=a_{11}e_{1}+A_{12}\mathbf{e}_{2}-v(e_{1})=a_{11}e_{1}%
 +A_{12}\mathbf{e}_{2}-v(\sigma)   where     𝐞  2   ≜   (   e  2   ,   e  3   ,  …  ,   e  n   )   ∈   ℝ   (   n  -  1   )         normal-≜   subscript  𝐞  2     subscript  e  2    subscript  e  3   normal-…   subscript  e  n          superscript  ℝ    n  1       \mathbf{e}_{2}\triangleq(e_{2},e_{3},\ldots,e_{n})\in\mathbb{R}^{(n-1)}   is the collection of the estimator errors for all of the unmeasured states. To ensure that     σ   σ  ˙    <  0        σ   normal-˙  σ    0    \sigma\dot{\sigma}<0   , let       v   (  σ  )    =   M   sgn   (  σ  )           v  σ     M   sgn  σ      v(\sigma)=M\operatorname{sgn}(\sigma)   where       M  >   max   {   |     a  11    e  1    +    A  12    𝐞  2     |   }     .      M           subscript  a  11    subscript  e  1       subscript  A  12    subscript  𝐞  2         M>\max\{|a_{11}e_{1}+A_{12}\mathbf{e}_{2}|\}.   That is, positive constant   M   M   M   must be greater than a scaled version of the maximum possible estimator errors for the system (i.e., the initial errors, which are assumed to be bounded so that   M   M   M   can be picked large enough; al). If   M   M   M   is sufficiently large, it can be assumed that the system achieves     e  1   =  0       subscript  e  1   0    e_{1}=0   (i.e.,      x  ^   1   =   x  1        subscript   normal-^  x   1    subscript  x  1     \hat{x}_{1}=x_{1}   ). Because    e  1     subscript  e  1    e_{1}   is constant (i.e., 0) along this manifold,      e  ˙   1   =  0       subscript   normal-˙  e   1   0    \dot{e}_{1}=0   as well. Hence, the discontinuous control    v   (  σ  )       v  σ    v(\sigma)   may be replaced with the equivalent continuous control    v  eq     subscript  v  eq    v_{\text{eq}}   where       0  =   σ  ˙   =      a  11      e  1   ⏞     =  0     +    A  12    𝐞  2     -     v  eq   ⏞    v   (  σ  )      =     A  12    𝐞  2    -   v  eq     .        0   normal-˙  σ               subscript  a  11       e  1   ⏞     =  0         subscript  A  12    subscript  𝐞  2         v  eq   ⏞    v   (  σ  )                 subscript  A  12    subscript  𝐞  2     subscript  v  eq       0=\dot{\sigma}=a_{11}\mathord{\overbrace{e_{1}}^{{}=0}}+A_{12}\mathbf{e}_{2}-%
 \mathord{\overbrace{v_{\text{eq}}}^{v(\sigma)}}=A_{12}\mathbf{e}_{2}-v_{\text{%
 eq}}.   So          v  eq   ⏞   scalar   =      A  12   ⏞     1  ×   (   n  -  1   )    vector       𝐞  2   ⏞      (   n  -  1   )   ×  1   vector      .          v  eq   ⏞   scalar          A  12   ⏞     1  ×   (   n  -  1   )    vector         𝐞  2   ⏞      (   n  -  1   )   ×  1   vector        \mathord{\overbrace{v_{\text{eq}}}^{\text{scalar}}}=\mathord{\overbrace{A_{12}%
 }^{1\times(n-1)\text{ vector}}}\mathord{\overbrace{\mathbf{e}_{2}}^{(n-1)%
 \times 1\text{ vector}}}.   This equivalent control    v  eq     subscript  v  eq    v_{\text{eq}}   represents the contribution from the other    (   n  -  1   )      n  1    (n-1)   states to the trajectory of the output state    x  1     subscript  x  1    x_{1}   . In particular, the row    A  12     subscript  A  12    A_{12}   acts like an output vector for the error subsystem          [       e  ˙   2         e  ˙   3       ⋮        e  ˙   n      ]   ⏞     𝐞  ˙   2    =     A  2      [      e  2        e  3       ⋮       e  n      ]   ⏞    𝐞  2     +    L  2   v   (   e  1   )     =     A  2    𝐞  2    +    L  2    v  eq     =     A  2    𝐞  2    +    L  2    A  12    𝐞  2     =    (    A  2   +    L  2    A  12     )    𝐞  2     .            [       e  ˙   2         e  ˙   3       ⋮        e  ˙   n      ]   ⏞     𝐞  ˙   2          subscript  A  2       [      e  2        e  3       ⋮       e  n      ]   ⏞    𝐞  2         subscript  L  2   v   subscript  e  1               subscript  A  2    subscript  𝐞  2       subscript  L  2    subscript  v  eq               subscript  A  2    subscript  𝐞  2       subscript  L  2    subscript  A  12    subscript  𝐞  2               subscript  A  2      subscript  L  2    subscript  A  12      subscript  𝐞  2       \mathord{\overbrace{\begin{bmatrix}\dot{e}_{2}\\
 \dot{e}_{3}\\
 \vdots\\
 \dot{e}_{n}\end{bmatrix}}^{\dot{\mathbf{e}}_{2}}}=A_{2}\mathord{\overbrace{%
 \begin{bmatrix}e_{2}\\
 e_{3}\\
 \vdots\\
 e_{n}\end{bmatrix}}^{\mathbf{e}_{2}}}+L_{2}v(e_{1})=A_{2}\mathbf{e}_{2}+L_{2}v%
 _{\text{eq}}=A_{2}\mathbf{e}_{2}+L_{2}A_{12}\mathbf{e}_{2}=(A_{2}+L_{2}A_{12})%
 \mathbf{e}_{2}.   So, to ensure the estimator error    𝐞  2     subscript  𝐞  2    \mathbf{e}_{2}   for the unmeasured states converges to zero, the     (   n  -  1   )   ×  1        n  1   1    (n-1)\times 1   vector    L  2     subscript  L  2    L_{2}   must be chosen so that the     (   n  -  1   )   ×   (   n  -  1   )         n  1     n  1     (n-1)\times(n-1)   matrix    (    A  2   +    L  2    A  12     )       subscript  A  2      subscript  L  2    subscript  A  12      (A_{2}+L_{2}A_{12})   is Hurwitz (i.e., the real part of each of its eigenvalues must be negative). Hence, provided that it is observable , this    𝐞  2     subscript  𝐞  2    \mathbf{e}_{2}   system can be stabilized in exactly the same way as a typical linear state observer when    A  12     subscript  A  12    A_{12}   is viewed as the output matrix (i.e., "   C   C   C   "). That is, the    v  eq     subscript  v  eq    v_{\text{eq}}   equivalent control provides measurement information about the unmeasured states that can continually move their estimates asymptotically closer to them. Meanwhile, the discontinuous control    v  =   M   sgn   (     x  ^   1   -  x   )         v    M   sgn     subscript   normal-^  x   1   x       v=M\operatorname{sgn}(\hat{x}_{1}-x)   forces the estimate of the measured state to have zero error in finite time. Additionally, white zero-mean symmetric measurement noise (e.g., Gaussian noise ) only affects the switching frequency of the control   v   v   v   , and hence the noise will have little effect on the equivalent sliding mode control    v  eq     subscript  v  eq    v_{\text{eq}}   . Hence, the sliding mode observer has Kalman filter –like features. 17  The final version of the observer is thus      {        𝐱  ^   ˙   =    A   𝐱  ^    +   B  𝐮   +   L  M   sgn   (     x  ^   1   -   x  1    )              =    A   𝐱  ^    +   B  𝐮   +    [      -  1        L  2      ]   M   sgn   (     x  ^   1   -   x  1    )              =    A   𝐱  ^    +   B  𝐮   +    [      -  M         L  2   M      ]    sgn   (     x  ^   1   -   x  1    )              =    A   𝐱  ^    +    [     B     [      -  M         L  2   M      ]      ]    [     𝐮       sgn   (     x  ^   1   -   x  1    )       ]             =     A  obs    𝐱  ^    +    B  obs    𝐮  obs             cases     normal-˙   normal-^  𝐱        A   normal-^  𝐱      B  𝐮     L  M   sgn     subscript   normal-^  x   1    subscript  x  1        otherwise    absent      A   normal-^  𝐱      B  𝐮         1      subscript  L  2     M   sgn     subscript   normal-^  x   1    subscript  x  1        otherwise    absent      A   normal-^  𝐱      B  𝐮         M        subscript  L  2   M      sgn     subscript   normal-^  x   1    subscript  x  1        otherwise    absent      A   normal-^  𝐱        B      M        subscript  L  2   M         𝐮     sgn     subscript   normal-^  x   1    subscript  x  1          otherwise    absent       subscript  A  obs    normal-^  𝐱       subscript  B  obs    subscript  𝐮  obs      otherwise    \begin{cases}\dot{\hat{\mathbf{x}}}=A\hat{\mathbf{x}}+B\mathbf{u}+LM%
 \operatorname{sgn}(\hat{x}_{1}-x_{1})\\
 =A\hat{\mathbf{x}}+B\mathbf{u}+\begin{bmatrix}-1\\
 L_{2}\end{bmatrix}M\operatorname{sgn}(\hat{x}_{1}-x_{1})\\
 =A\hat{\mathbf{x}}+B\mathbf{u}+\begin{bmatrix}-M\\
 L_{2}M\end{bmatrix}\operatorname{sgn}(\hat{x}_{1}-x_{1})\\
 =A\hat{\mathbf{x}}+\begin{bmatrix}B&\begin{bmatrix}-M\\
 L_{2}M\end{bmatrix}\end{bmatrix}\begin{bmatrix}\mathbf{u}\\
 \operatorname{sgn}(\hat{x}_{1}-x_{1})\end{bmatrix}\\
 =A_{\text{obs}}\hat{\mathbf{x}}+B_{\text{obs}}\mathbf{u}_{\text{obs}}\end{cases}   where        A  obs   ≜  A     normal-≜   subscript  A  obs   A    A_{\text{obs}}\triangleq A   ,       B  obs   ≜   [     B     [      -  M         L  2   M      ]      ]      normal-≜   subscript  B  obs     B      M        subscript  L  2   M         B_{\text{obs}}\triangleq\begin{bmatrix}B&\begin{bmatrix}-M\\
 L_{2}M\end{bmatrix}\end{bmatrix}   , and       u  obs   ≜   [     𝐮       sgn   (     x  ^   1   -   x  1    )       ]      normal-≜   subscript  u  obs     𝐮     sgn     subscript   normal-^  x   1    subscript  x  1         u_{\text{obs}}\triangleq\begin{bmatrix}\mathbf{u}\\
 \operatorname{sgn}(\hat{x}_{1}-x_{1})\end{bmatrix}   .   That is, by augmenting the control vector   𝐮   𝐮   \mathbf{u}   with the switching function    sgn   (     x  ^   1   -   x  1    )      sgn     subscript   normal-^  x   1    subscript  x  1      \operatorname{sgn}(\hat{x}_{1}-x_{1})   , the sliding mode observer can be implemented as an LTI system. That is, the discontinuous signal    sgn   (     x  ^   1   -   x  1    )      sgn     subscript   normal-^  x   1    subscript  x  1      \operatorname{sgn}(\hat{x}_{1}-x_{1})   is viewed as a control input to the 2-input LTI system.  For simplicity, this example assumes that the sliding mode observer has access to a measurement of a single state (i.e., output    y  =   x  1       y   subscript  x  1     y=x_{1}   ). However, a similar procedure can be used to design a sliding mode observer for a vector of weighted combinations of states (i.e., when output    𝐲  =   C  𝐱       𝐲    C  𝐱     \mathbf{y}=C\mathbf{x}   uses a generic matrix   C   C   C   ). In each case, the sliding mode will be the manifold where the estimated output    𝐲  ^     normal-^  𝐲    \hat{\mathbf{y}}   follows the measured output   𝐲   𝐲   \mathbf{y}   with zero error (i.e., the manifold where     σ   (  𝐱  )    ≜    𝐲  ^   -  𝐲   =  𝟎       normal-≜    σ  𝐱      normal-^  𝐲   𝐲        0     \sigma(\mathbf{x})\triangleq\hat{\mathbf{y}}-\mathbf{y}=\mathbf{0}   ).  See also   Variable structure control  Variable structure system  Hybrid system  Nonlinear control  Robust control  Optimal control  Bang–bang control – Sliding mode control is often implemented as a bang–bang control. In some cases, such control is necessary for optimality .  H-bridge – A topology that combines four switches forming the four legs of an "H". Can be used to drive a motor (or other electrical device) forward or backward when only a single supply is available. Often used in actuator in sliding-mode controlled systems.  Switching amplifier – Uses switching-mode control to drive continuous outputs  Delta-sigma modulation – Another (feedback) method of encoding a continuous range of values in a signal that rapidly switches between two states (i.e., a kind of specialized sliding-mode control)  Pulse-density modulation – A generalized form of delta-sigma modulation.  Pulse-width modulation – Another modulation scheme that produces continuous motion through discontinuous switching.   Notes  References  Further reading          "    Category:Nonlinear control     ↩  ↩  Other pulse-type modulation techniques include delta-sigma modulation . ↩  "Autonomous Navigation and Obstacle Avoidance of Unmanned Vessels in Simulated Rough Sea States - Villanova University" ↩  ↩     ↩   ↩  ↩  ↩  ↩  ↩  ↩      