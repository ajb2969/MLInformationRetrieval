   Silhouette (clustering)      Silhouette (clustering)   Silhouette refers to a method of interpretation and validation of consistency within clusters of data . The technique provides a succinct graphical representation of how well each object lies within its cluster. It was first described by Peter J. Rousseeuw in 1986. 1  Definition  Assume the data have been clustered via any technique, such as k-means , into   k   k   k   clusters. For each datum    i   i   i   , let    a   (  i  )       a  i    a(i)   be the average dissimilarity of   i   i   i   with all other data within the same cluster. We can interpret    a   (  i  )       a  i    a(i)   as how well   i   i   i   is assigned to its cluster (the smaller the value, the better the assignment). We then define the average dissimilarity of point   i   i   i   to a cluster   c   c   c   as the average of the distance from   i   i   i   to points in   c   c   c   .  Let    b   (  i  )       b  i    b(i)   be the lowest average dissimilarity of   i   i   i   to any other cluster, of which   i   i   i   is not a member. The cluster with this lowest average dissimilarity is said to be the "neighbouring cluster" of   i   i   i   because it is the next best fit cluster for point   i   i   i   . We now define a silhouette:       s   (  i  )    =     b   (  i  )    -   a   (  i  )      max   {   a   (  i  )    ,   b   (  i  )    }           s  i         b  i     a  i        a  i     b  i       s(i)=\frac{b(i)-a(i)}{\max\{a(i),b(i)\}}     Which can be written as:       s   (  i  )    =   {       1  -     a   (  i  )    /  b    (  i  )     ,       if  a   (  i  )    <   b   (  i  )          0  ,       if  a   (  i  )    =   b   (  i  )              b   (  i  )    /  a    (  i  )    -  1   ,       if  a   (  i  )    >   b   (  i  )               s  i    cases    1        a  i   b   i        if  a  i     b  i    0      if  a  i     b  i            b  i   a   i   1       if  a  i     b  i       s(i)=\begin{cases}1-a(i)/b(i),&\mbox{if }a(i) b(i)\\
 \end{cases}     From the above definition it is clear that       -  1   ≤   s   (  i  )    ≤  1          1     s  i        1     -1\leq s(i)\leq 1     For    s   (  i  )       s  i    s(i)   to be close to 1 we require     a   (  i  )    ≪   b   (  i  )       much-less-than    a  i     b  i     a(i)\ll b(i)   . As    a   (  i  )       a  i    a(i)   is a measure of how dissimilar   i   i   i   is to its own cluster, a small value means it is well matched. Furthermore, a large    b   (  i  )       b  i    b(i)   implies that   i   i   i   is badly matched to its neighbouring cluster. Thus an    s   (  i  )       s  i    s(i)   close to one means that the datum is appropriately clustered. If    s   (  i  )       s  i    s(i)   is close to negative one, then by the same logic we see that   i   i   i   would be more appropriate if it was clustered in its neighbouring cluster. An    s   (  i  )       s  i    s(i)   near zero means that the datum is on the border of two natural clusters.  The average    s   (  i  )       s  i    s(i)   over all data of a cluster is a measure of how tightly grouped all the data in the cluster are. Thus the average    s   (  i  )       s  i    s(i)   over all data of the entire dataset is a measure of how appropriately the data has been clustered. If there are too many or too few clusters, as may occur when a poor choice of   k   k   k   is used in the k-means algorithm, some of the clusters will typically display much narrower silhouettes than the rest. Thus silhouette plots and averages may be used to determine the natural number of clusters within a dataset.  References    "  Category:Cluster analysis     ↩     