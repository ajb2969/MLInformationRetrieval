   Proofs of convergence of random variables      Proofs of convergence of random variables   This article is supplemental for â€œ Convergence of random variables â€ and provides proofs for selected results.  Several results will be established using the portmanteau lemma : A sequence { X n } converges in distribution to X if and only if any of the following conditions are met:   E[ f ( X n )] â†’ E[ f ( X )] for all bounded , continuous functions  f ;  E[ f ( X n )] â†’ E[ f ( X )] for all bounded, Lipschitz functions  f ;  limsup{Pr( X n âˆˆ C )} â‰¤ Pr( X âˆˆ C ) for all closed sets  C ;   Convergence almost surely implies convergence in probability         X  n      â†’   a  s      X  â‡’       X  n      â†’  ğ‘    X      formulae-sequence      a  s   normal-â†’    subscript  X  n    X  normal-â‡’      p  normal-â†’    subscript  X  n   X     X_{n}\ \xrightarrow{as}\ X\quad\Rightarrow\quad X_{n}\ \xrightarrow{p}\ X    Proof: If { X n } converges to X almost surely, it means that the set of points {Ï‰: lim X n (Ï‰) â‰  X (Ï‰)} has measure zero; denote this set O . Now fix Îµ > 0 and consider a sequence of sets       A  n   =   â‹ƒ   m  â‰¥  n     {  |   X  m   -  X  |  >  Îµ  }      fragments   subscript  A  n     subscript     m  n     fragments  normal-{  normal-|   subscript  X  m    X  normal-|   Îµ  normal-}     A_{n}=\bigcup_{m\geq n}\left\{\left|X_{m}-X\right|>\varepsilon\right\}     This sequence of sets is decreasing: A n âŠ‡ A n +1 âŠ‡ ..., and it decreases towards the set        A  âˆ   =    â‹‚   n  â‰¥  1     A  n     .       subscript  A      subscript     n  1     subscript  A  n      A_{\infty}=\bigcap_{n\geq 1}A_{n}.     For this decreasing sequence of events, their probabilities are also a decreasing sequence, and it decreases towards the Pr( A âˆ ); we shall show now that this number is equal to zero. Now any point Ï‰ in the complement of O is such that lim X n (Ï‰) = X (Ï‰), which implies that | X n (Ï‰) âˆ’ X (Ï‰)| n'', and consequently it will not belong to A âˆ . This means that A âˆ is disjoint with O , or equivalently, A âˆ is a subset of O and therefore Pr( A âˆ ) = 0.  Finally, consider        Pr   (    |    X  n   -  X   |   >  Îµ   )    â‰¤    Pr   (   A  n   )      â†’   n  â†’  âˆ    0     ,       Pr         subscript  X  n   X    Îµ      Pr   subscript  A  n        normal-â†’  n    normal-â†’   0      \operatorname{Pr}\left(|X_{n}-X|>\varepsilon\right)\leq\operatorname{Pr}(A_{n}%
 )\ \underset{n\to\infty}{\rightarrow}0,   which by definition means that X n converges in probability to X .  Convergence in probability does not imply almost sure convergence in the discrete case  If X n are independent random variables assuming value one with probability 1/ n and zero otherwise, then X n converges to zero in probability but not almost surely. This can be verified using the Borelâ€“Cantelli lemmas .  Convergence in probability implies convergence in distribution          X  n      â†’  ğ‘     X  â‡’       X  n      â†’  ğ‘‘    X    ,     formulae-sequence    p  normal-â†’    subscript  X  n    X  normal-â‡’      d  normal-â†’    subscript  X  n   X     X_{n}\ \xrightarrow{p}\ X\quad\Rightarrow\quad X_{n}\ \xrightarrow{d}\ X,     Proof for the case of scalar random variables  Lemma. Let X , Y be random variables, a a real number and Îµ > 0. Then        Pr   (   Y  â‰¤  a   )    â‰¤    Pr   (   X  â‰¤   a  +  Îµ    )    +   Pr   (    |   Y  -  X   |   >  Îµ   )      .       Pr    Y  a       Pr    X    a  Îµ      Pr        Y  X    Îµ       \operatorname{Pr}(Y\leq a)\leq\operatorname{Pr}(X\leq a+\varepsilon)+%
 \operatorname{Pr}(|Y-X|>\varepsilon).   (or     {  Y  â‰¤  a  }   âŠ‚   {  X  â‰¤  a  +  Îµ  }   âˆª   {  |  Y  -  X  |  >  Îµ  }   .     fragments   fragments  normal-{  Y   a  normal-}     fragments  normal-{  X   a   Îµ  normal-}     fragments  normal-{  normal-|  Y   X  normal-|   Îµ  normal-}   normal-.    \{Y\leq a\}\subset\{X\leq a+\varepsilon\}\cup\{|Y-X|>\varepsilon\}.   )  Proof of lemma:      Pr   (   Y  â‰¤  a   )      Pr    Y  a     \displaystyle\operatorname{Pr}(Y\leq a)     Proof of the theorem: Recall that in order to prove convergence in distribution, one must show that the sequence of cumulative distribution functions converges to the F X at every point where F X is continuous. Let a be such a point. For every Îµ > 0, due to the preceding lemma, we have:      Pr   (    X  n   â‰¤  a   )      Pr     subscript  X  n   a     \displaystyle\operatorname{Pr}(X_{n}\leq a)     So, we have         Pr   (   X  â‰¤   a  -  Îµ    )    -   Pr   (    |    X  n   -  X   |   >  Îµ   )     â‰¤   Pr   (    X  n   â‰¤  a   )    â‰¤    Pr   (   X  â‰¤   a  +  Îµ    )    +   Pr   (    |    X  n   -  X   |   >  Îµ   )      .           Pr    X    a  Îµ      Pr         subscript  X  n   X    Îµ      Pr     subscript  X  n   a            Pr    X    a  Îµ      Pr         subscript  X  n   X    Îµ        \operatorname{Pr}(X\leq a-\varepsilon)-\operatorname{Pr}\left(\left|X_{n}-X%
 \right|>\varepsilon\right)\leq\operatorname{Pr}\left(X_{n}\leq a\right)\leq%
 \operatorname{Pr}(X\leq a+\varepsilon)+\operatorname{Pr}\left(\left|X_{n}-X%
 \right|>\varepsilon\right).     Taking the limit as n â†’ âˆ, we obtain:         F  X    (   a  -  Îµ   )    â‰¤    lim   n  â†’  âˆ     Pr   (    X  n   â‰¤  a   )     â‰¤    F  X    (   a  +  Îµ   )     ,           subscript  F  X     a  Îµ      subscript    normal-â†’  n      Pr     subscript  X  n   a             subscript  F  X     a  Îµ       F_{X}(a-\varepsilon)\leq\lim_{n\to\infty}\operatorname{Pr}(X_{n}\leq a)\leq F_%
 {X}(a+\varepsilon),   where F X ( a ) = Pr( X â‰¤ a ) is the cumulative distribution function of X . This function is continuous at a by assumption, and therefore both F X ( a âˆ’Îµ) and F X ( a +Îµ) converge to F X ( a ) as Îµ â†’ 0 + . Taking this limit, we obtain         lim   n  â†’  âˆ     Pr   (    X  n   â‰¤  a   )     =   Pr   (   X  â‰¤  a   )     ,        subscript    normal-â†’  n      Pr     subscript  X  n   a      Pr    X  a      \lim_{n\to\infty}\operatorname{Pr}(X_{n}\leq a)=\operatorname{Pr}(X\leq a),   which means that { X n } converges to X in distribution.  Proof for the generic case  We see that | X n âˆ’ X | converges in probability to zero, and also X converges to X in distribution trivially. Applying the property proved later on this page we conclude that X n converges to X in distribution.  Convergence in distribution to a constant implies convergence in probability          X  n      â†’  ğ‘‘     c  â‡’       X  n      â†’  ğ‘    c    ,     formulae-sequence    d  normal-â†’    subscript  X  n    c  normal-â‡’      p  normal-â†’    subscript  X  n   c     X_{n}\ \xrightarrow{d}\ c\quad\Rightarrow\quad X_{n}\ \xrightarrow{p}\ c,    provided c is a constant.  Proof: Fix Îµ > 0. Let B Îµ ( c ) be the open ball of radius Îµ around point c , and B Îµ c ( c ) its complement. Then        Pr   (    |    X  n   -  c   |   â‰¥  Îµ   )    =   Pr   (    X  n   âˆˆ    B  Îµ  c    (  c  )     )     .       Pr         subscript  X  n   c    Îµ     Pr     subscript  X  n      superscript   subscript  B  Îµ   c   c       \operatorname{Pr}\left(|X_{n}-c|\geq\varepsilon\right)=\operatorname{Pr}\left(%
 X_{n}\in B_{\varepsilon}^{c}(c)\right).   By the portmanteau lemma (part C), if X n converges in distribution to c , then the limsup of the latter probability must be less than or equal to Pr( c âˆˆ B Îµ c ( c )), which is obviously equal to zero. Therefore       lim   n  â†’  âˆ     Pr   (    |    X  n   -  c   |   â‰¥  Îµ   )        subscript    normal-â†’  n      Pr         subscript  X  n   c    Îµ      \displaystyle\lim_{n\to\infty}\operatorname{Pr}\left(\left|X_{n}-c\right|\geq%
 \varepsilon\right)     which by definition means that X n converges to c in probability.  Convergence in probability to a sequence converging in distribution implies convergence to the same distribution        |    Y  n   -   X  n    |    â†’  ğ‘   0   ,      X  n      â†’  ğ‘‘     X  â‡’       Y  n      â†’  ğ‘‘    X       formulae-sequence    p  normal-â†’        subscript  Y  n    subscript  X  n     0    formulae-sequence    d  normal-â†’    subscript  X  n    X  normal-â‡’      d  normal-â†’    subscript  Y  n   X      |Y_{n}-X_{n}|\ \xrightarrow{p}\ 0,\ \ X_{n}\ \xrightarrow{d}\ X\ \quad%
 \Rightarrow\quad Y_{n}\ \xrightarrow{d}\ X     Proof: We will prove this theorem using the portmanteau lemma, part B. As required in that lemma, consider any bounded function f (i.e. | f ( x )| â‰¤ M ) which is also Lipschitz:      âˆƒ  K  >  0  ,  âˆ€  x  ,  y  :  |  f   (  x  )   -  f   (  y  )   |  â‰¤  K  |  x  -  y  |  .     fragments   K   0  normal-,  for-all  x  normal-,  y  normal-:   normal-|  f   fragments  normal-(  x  normal-)    f   fragments  normal-(  y  normal-)   normal-|   K  normal-|  x   y  normal-|  normal-.    \exists K>0,\forall x,y:\quad|f(x)-f(y)|\leq K|x-y|.     Take some Îµ > 0 and majorize the expression |E[ f ( Y n )] âˆ’ E[ f ( X n )]| as      |    E   [   f   (   Y  n   )    ]    -   E   [   f   (   X  n   )    ]     |         normal-E    f   subscript  Y  n      normal-E    f   subscript  X  n        \displaystyle\left|\operatorname{E}\left[f(Y_{n})\right]-\operatorname{E}\left%
 [f(X_{n})\right]\right|     (here 1 {...} denotes the indicator function ; the expectation of the indicator function is equal to the probability of corresponding event). Therefore      |    E   [   f   (   Y  n   )    ]    -   E   [   f   (  X  )    ]     |         normal-E    f   subscript  Y  n      normal-E    f  X       \displaystyle\left|\operatorname{E}\left[f(Y_{n})\right]-\operatorname{E}\left%
 [f(X)\right]\right|   If we take the limit in this expression as n â†’â€‰âˆ, the second term will go to zero since { Y n âˆ’X n } converges to zero in probability; and the third term will also converge to zero, by the portmanteau lemma and the fact that X n converges to X in distribution. Thus         lim   n  â†’  âˆ     |    E   [   f   (   Y  n   )    ]    -   E   [   f   (  X  )    ]     |    â‰¤   K  Îµ    .        subscript    normal-â†’  n          normal-E    f   subscript  Y  n      normal-E    f  X         K  Îµ     \lim_{n\to\infty}\left|\operatorname{E}\left[f(Y_{n})\right]-\operatorname{E}%
 \left[f(X)\right]\right|\leq K\varepsilon.   Since Îµ was arbitrary, we conclude that the limit must in fact be equal to zero, and therefore E[ f ( Y n )] â†’ E[ f ( X )], which again by the portmanteau lemma implies that { Y n } converges to X in distribution. QED.  Convergence of one sequence in distribution and another to a constant implies joint convergence in distribution         X  n      â†’  ğ‘‘    X   ,      Y  n      â†’  ğ‘‘     c  â‡’      (   X  n   ,   Y  n   )     â†’  ğ‘‘     (  X  ,  c  )        formulae-sequence    d  normal-â†’    subscript  X  n   X    formulae-sequence    d  normal-â†’    subscript  Y  n    c  normal-â‡’      d  normal-â†’     subscript  X  n    subscript  Y  n     X  c       X_{n}\ \xrightarrow{d}\ X,\ \ Y_{n}\ \xrightarrow{d}\ c\ \quad\Rightarrow\quad%
 (X_{n},Y_{n})\ \xrightarrow{d}\ (X,c)    provided c is a constant.  Proof: We will prove this statement using the portmanteau lemma, part A.  First we want to show that ( X n , c ) converges in distribution to ( X , c ). By the portmanteau lemma this will be true if we can show that E[ f ( X n , c )] â†’ E[ f ( X , c )] for any bounded continuous function f ( x , y ). So let f be such arbitrary bounded continuous function. Now consider the function of a single variable g ( x ) := f ( x , c ). This will obviously be also bounded and continuous, and therefore by the portmanteau lemma for sequence { X n } converging in distribution to X , we will have that E[ g ( X n )] â†’ E[ g ( X )]. However the latter expression is equivalent to â€œE[ f ( X n , c )] â†’ E[ f ( X , c )]â€, and therefore we now know that ( X n , c ) converges in distribution to ( X , c ).  Secondly, consider |( X n , Y n ) âˆ’ ( X n , c )| = | Y n âˆ’ c |. This expression converges in probability to zero because Y n converges in probability to c . Thus we have demonstrated two facts:      {        |    (   X  n   ,   Y  n   )   -   (   X  n   ,  c  )    |    â†’  ğ‘   0   ,           (   X  n   ,  c  )     â†’  ğ‘‘     (  X  ,  c  )    .          cases    p  normal-â†’         subscript  X  n    subscript  Y  n      subscript  X  n   c     0   otherwise    d  normal-â†’     subscript  X  n   c    X  c    otherwise    \begin{cases}\left|(X_{n},Y_{n})-(X_{n},c)\right|\ \xrightarrow{p}\ 0,\\
 (X_{n},c)\ \xrightarrow{d}\ (X,c).\end{cases}   By the property proved earlier , these two facts imply that ( X n , Y n ) converge in distribution to ( X , c ).  Convergence of two sequences in probability implies joint convergence in probability         X  n      â†’  ğ‘    X   ,      Y  n      â†’  ğ‘     Y  â‡’      (   X  n   ,   Y  n   )     â†’  ğ‘     (  X  ,  Y  )        formulae-sequence    p  normal-â†’    subscript  X  n   X    formulae-sequence    p  normal-â†’    subscript  Y  n    Y  normal-â‡’      p  normal-â†’     subscript  X  n    subscript  Y  n     X  Y       X_{n}\ \xrightarrow{p}\ X,\ \ Y_{n}\ \xrightarrow{p}\ Y\ \quad\Rightarrow\quad%
 (X_{n},Y_{n})\ \xrightarrow{p}\ (X,Y)     Proof:      Pr   (    |    (   X  n   ,   Y  n   )   -   (  X  ,  Y  )    |   â‰¥  Îµ   )      Pr          subscript  X  n    subscript  Y  n     X  Y     Îµ     \displaystyle\operatorname{Pr}\left(\left|(X_{n},Y_{n})-(X,Y)\right|\geq%
 \varepsilon\right)   Each of the probabilities on the right-hand side converge to zero as n â†’ âˆ by definition of the convergence of { X n } and { Y n } in probability to X and Y respectively. Taking the limit we conclude that the left-hand side also converges to zero, and therefore the sequence {( X n , Y n )} converges in probability to {( X , Y )}.  See also   Convergence of random variables   References     "  Category:Article proofs  Category:Probability theory   