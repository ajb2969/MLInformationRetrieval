   Differential dynamic programming      Differential dynamic programming   Differential dynamic programming (DDP) is an optimal control algorithm of the trajectory optimization class. The algorithm was introduced in 1966 by Mayne 1 and subsequently analysed in Jacobson and Mayne's eponymous book. 2 The algorithm uses locally-quadratic models of the dynamics and cost functions, and displays quadratic convergence . It is closely related to Pantoja's step-wise Newton's method. 3 4  Finite-horizon discrete-time problems  The dynamics  describe the evolution of the state   𝐱   𝐱   \textstyle\mathbf{x}   given the control   𝐮   𝐮   \mathbf{u}   from time   i   i   i   to time    i  +  1      i  1    i+1   . The total cost     J  0     subscript  J  0    J_{0}   is the sum of running costs   ℓ   normal-ℓ   \textstyle\ell   and final cost    ℓ  f     subscript  normal-ℓ  f    \ell_{f}   , incurred when starting from state   𝐱   𝐱   \mathbf{x}   and applying the control sequence    𝐔  ≡   {   𝐮  0   ,    𝐮  1   …   ,   𝐮   N  -  1    }       𝐔    subscript  𝐮  0      subscript  𝐮  1   normal-…    subscript  𝐮    N  1       \mathbf{U}\equiv\{\mathbf{u}_{0},\mathbf{u}_{1}\dots,\mathbf{u}_{N-1}\}   until the horizon is reached:         J  0    (  𝐱  ,  𝐔  )    =     ∑   i  =  0    N  -  1     ℓ   (   𝐱  i   ,   𝐮  i   )     +    ℓ  f    (   𝐱  N   )      ,         subscript  J  0    𝐱  𝐔        superscript   subscript     i  0      N  1      normal-ℓ    subscript  𝐱  i    subscript  𝐮  i         subscript  normal-ℓ  f    subscript  𝐱  N       J_{0}(\mathbf{x},\mathbf{U})=\sum_{i=0}^{N-1}\ell(\mathbf{x}_{i},\mathbf{u}_{i%
 })+\ell_{f}(\mathbf{x}_{N}),     where     𝐱  0   ≡  𝐱       subscript  𝐱  0   𝐱    \mathbf{x}_{0}\equiv\mathbf{x}   , and the    𝐱  i     subscript  𝐱  i    \mathbf{x}_{i}   for    i  >  0      i  0    i>0   are given by . The solution of the optimal control problem is the minimizing control sequence       𝐔  *    (  𝐱  )    ≡     argmin  𝐔    J  0     (  𝐱  ,  𝐔  )     .         superscript  𝐔    𝐱       subscript  argmin  𝐔    subscript  J  0     𝐱  𝐔      \mathbf{U}^{*}(\mathbf{x})\equiv\operatorname{argmin}_{\mathbf{U}}J_{0}(%
 \mathbf{x},\mathbf{U}).    Trajectory optimization means finding     𝐔  *    (  𝐱  )        superscript  𝐔    𝐱    \mathbf{U}^{*}(\mathbf{x})   for a particular   𝐱   𝐱   \mathbf{x}   , rather than for all possible initial states.  Dynamic programming  Let    𝐔  i     subscript  𝐔  i    \mathbf{U}_{i}   be the partial control sequence     𝐔  i   ≡   {   𝐮  i   ,    𝐮   i  +  1    …   ,   𝐮   N  -  1    }        subscript  𝐔  i     subscript  𝐮  i      subscript  𝐮    i  1    normal-…    subscript  𝐮    N  1       \mathbf{U}_{i}\equiv\{\mathbf{u}_{i},\mathbf{u}_{i+1}\dots,\mathbf{u}_{N-1}\}   and define the cost-to-go     J  i     subscript  J  i    J_{i}   as the partial sum of costs from   i   i   i   to   N   N   N   :         J  i    (  𝐱  ,   𝐔  i   )    =     ∑   j  =  i    N  -  1     ℓ   (   𝐱  j   ,   𝐮  j   )     +    ℓ  f    (   𝐱  N   )      .         subscript  J  i    𝐱   subscript  𝐔  i         superscript   subscript     j  i      N  1      normal-ℓ    subscript  𝐱  j    subscript  𝐮  j         subscript  normal-ℓ  f    subscript  𝐱  N       J_{i}(\mathbf{x},\mathbf{U}_{i})=\sum_{j=i}^{N-1}\ell(\mathbf{x}_{j},\mathbf{u%
 }_{j})+\ell_{f}(\mathbf{x}_{N}).     The optimal cost-to-go or value function at time   i   i   i   is the cost-to-go given the minimizing control sequence:        V   (  𝐱  ,  i  )    ≡     min   𝐔  i     J  i     (  𝐱  ,   𝐔  i   )     .        V   𝐱  i        subscript    subscript  𝐔  i     subscript  J  i     𝐱   subscript  𝐔  i       V(\mathbf{x},i)\equiv\min_{\mathbf{U}_{i}}J_{i}(\mathbf{x},\mathbf{U}_{i}).     Setting     V   (  𝐱  ,  N  )    ≡    ℓ  f    (   𝐱  N   )          V   𝐱  N       subscript  normal-ℓ  f    subscript  𝐱  N      V(\mathbf{x},N)\equiv\ell_{f}(\mathbf{x}_{N})   , the dynamic programming principle reduces the minimization over an entire sequence of controls to a sequence of minimizations over a single control, proceeding backwards in time:  [\ell(\mathbf{x},\mathbf{u}) + V(\mathbf{f}(\mathbf{x},\mathbf{u}),i+1)].| 2 }}  This is the Bellman equation .  Differential dynamic programming  DDP proceeds by iteratively performing a backward pass on the nominal trajectory to generate a new control sequence, and then a forward-pass to compute and evaluate a new nominal trajectory. We begin with the backward pass. If       ℓ   (  𝐱  ,  𝐮  )    +   V   (   𝐟   (  𝐱  ,  𝐮  )    ,   i  +  1   )          normal-ℓ   𝐱  𝐮      V     𝐟   𝐱  𝐮      i  1       \ell(\mathbf{x},\mathbf{u})+V(\mathbf{f}(\mathbf{x},\mathbf{u}),i+1)     is the argument of the    min   [  ]           \min[]   operator in , let   Q   Q   Q   be the variation of this quantity around the   i   i   i   -th    (  𝐱  ,  𝐮  )     𝐱  𝐮    (\mathbf{x},\mathbf{u})   pair:       Q   (   δ  𝐱   ,   δ  𝐮   )    ≡         Q     δ  𝐱     δ  𝐮     absent    \displaystyle Q(\delta\mathbf{x},\delta\mathbf{u})\equiv     and expand to second order  & Q_{\mathbf{x}\mathbf{u}}\\ Q_\mathbf{u} & Q_{\mathbf{u}\mathbf{x}} & Q_{\mathbf{u}\mathbf{u}} \end{bmatrix} \begin{bmatrix} 1\\ \delta\mathbf{x}\\ \delta\mathbf{u} \end{bmatrix} | 3 }}  The   Q   Q   Q   notation used here is a variant of the notation of Morimoto where subscripts denote differentiation in denominator layout. 5  Dropping the index   i   i   i   for readability, primes denoting the next time-step     V  ′   ≡   V   (   i  +  1   )         superscript  V  normal-′     V    i  1      V^{\prime}\equiv V(i+1)   , the expansion coefficients are      Q  𝐱     subscript  Q  𝐱    \displaystyle Q_{\mathbf{x}}     The last terms in the last three equations denote contraction of a vector with a tensor. Minimizing the quadratic approximation  with respect to    δ  𝐮      δ  𝐮    \delta\mathbf{u}   we have  ^* = \operatorname{argmin}\limits_{\delta \mathbf{u}}Q(\delta \mathbf{x},\delta \mathbf{u})=-Q_{\mathbf{u}\mathbf{u}}^{-1}(Q_\mathbf{u}+Q_{\mathbf{u}\mathbf{x}}\delta \mathbf{x}), | 4 }}  giving an open-loop term    𝐤  =   -    Q  𝐮𝐮   -  1     Q  𝐮         𝐤       superscript   subscript  Q  𝐮𝐮     1     subscript  Q  𝐮       \mathbf{k}=-Q_{\mathbf{u}\mathbf{u}}^{-1}Q_{\mathbf{u}}   and a feedback gain term    𝐊  =   -    Q  𝐮𝐮   -  1     Q  𝐮𝐱         𝐊       superscript   subscript  Q  𝐮𝐮     1     subscript  Q  𝐮𝐱       \mathbf{K}=-Q_{\mathbf{u}\mathbf{u}}^{-1}Q_{\mathbf{u}\mathbf{x}}   . Plugging the result back into , we now have a quadratic model of the value at time   i   i   i   :      Δ  V   (  i  )       normal-Δ  V  i    \displaystyle\Delta V(i)     Recursively computing the local quadratic models of    V   (  i  )       V  i    V(i)   and the control modifications    {   𝐤   (  i  )    ,   𝐊   (  i  )    }       𝐤  i     𝐊  i     \{\mathbf{k}(i),\mathbf{K}(i)\}   , from    i  =   N  -  1       i    N  1     i=N-1   down to    i  =  1      i  1    i=1   , constitutes the backward pass. As above, the Value is initialized with     V   (  𝐱  ,  N  )    ≡    ℓ  f    (   𝐱  N   )          V   𝐱  N       subscript  normal-ℓ  f    subscript  𝐱  N      V(\mathbf{x},N)\equiv\ell_{f}(\mathbf{x}_{N})   . Once the backward pass is completed, a forward pass computes a new trajectory:       𝐱  ^    (  1  )        normal-^  𝐱   1    \displaystyle\hat{\mathbf{x}}(1)     The backward passes and forward passes are iterated until convergence.  Regularization and line-search  Differential dynamic programming is a second-order algorithm like Newton's method . It therefore takes large steps toward the minimum and often requires regularization and/or line-search to achieve convergence 6 . 7 Regularization in the DDP context means ensuring that the    Q  𝐮𝐮     subscript  Q  𝐮𝐮    Q_{\mathbf{u}\mathbf{u}}   matrix in  is positive definite . Line-search in DDP amounts to scaling the open-loop control modification   𝐤   𝐤   \mathbf{k}   by some    0  <  α  <  1        0  α       1     0<\alpha<1   .  See also   Optimal control   References  External links   A Python implementation of DDP  A MATLAB implementation of DDP   "  Category:Articles created via the Article Wizard  Category:Dynamic programming     ↩  ↩  ↩  ↩  ↩  ↩  ↩     