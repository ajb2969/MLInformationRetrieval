<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="1229">Statistical proof</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>Statistical proof</h1>
<hr>'''Statistical proof''' is the rational demonstration of degree of certainty for a [[proposition]], [[hypothesis]] or [[scientific theory|theory]] that is used to convince others subsequent to
<p><code>a </code><a href="statistical_test" title="wikilink"><code>statistical</code> <code>test</code></a><code> of the supporting </code><a href="evidence" title="wikilink"><code>evidence</code></a><code> and the types of </code><a href="inference" title="wikilink"><code>inferences</code></a><code> that can be drawn from the test scores. Statistical methods are used to increase the understanding of the facts and the proof demonstrates the </code><a href="Validity_(statistics)" title="wikilink"><code>validity</code></a><code> and logic of inference with explicit reference to a hypothesis, the </code><a href="experimental_data" title="wikilink"><code>experimental</code> <code>data</code></a><code>, the facts, the test, and the </code><a href="odds" title="wikilink"><code>odds</code></a><code>. </code><a href="Proof_(truth)" title="wikilink"><code>Proof</code></a><code> has two essential aims: the first is to convince and the second is to explain the proposition through peer and public review.</code><a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a></p>

<p>The <a href="Philosophic_burden_of_proof" title="wikilink">burden of proof</a> rests on the demonstrable application of the statistical method, the disclosure of the assumptions, and the relevance that the test has with respect to a genuine understanding of the data relative to the external world. There are adherents to several different statistical philosophies of inference, such as <a href="Bayes_theorem" title="wikilink">Bayes theorem</a> versus the <a href="likelihood_function" title="wikilink">likelihood function</a>, or <a class="uri" href="positivism" title="wikilink">positivism</a> versus <a href="critical_rationalism" title="wikilink">critical rationalism</a>. These methods of reason have direct bearing on statistical proof and its interpretations in the broader philosophy of science.<a class="footnoteRef" href="#fn2" id="fnref2"><sup>2</sup></a><a class="footnoteRef" href="#fn3" id="fnref3"><sup>3</sup></a></p>

<p>A common demarcation between science and non-science is the <a class="uri" href="hypothetico-deductive" title="wikilink">hypothetico-deductive</a> proof of falsification developed by <a href="Karl_Popper" title="wikilink">Karl Popper</a>, which is a well-established practice in the tradition of statistics. Other modes of inference, however, may include the <a href="inductive_reasoning" title="wikilink">inductive</a> and <a href="abductive_reasoning" title="wikilink">abductive</a> modes of proof.<a class="footnoteRef" href="#fn4" id="fnref4"><sup>4</sup></a> Scientists do not use statistical proof as a means to attain certainty, but to <a href="Falsifiability" title="wikilink">falsify</a> claims and explain theory. Science cannot achieve absolute certainty nor is it a continuous march toward an objective truth as the vernacular as opposed to the scientific meaning of the term "proof" might imply. Statistical proof offers a kind of proof of a theory's falsity and the means to learn <a href="heuristics" title="wikilink">heuristically</a> through repeated statistical trials and experimental error.<a class="footnoteRef" href="#fn5" id="fnref5"><sup>5</sup></a> Statistical proof also has applications in legal matters with implications for the <a href="legal_burden_of_proof" title="wikilink">legal burden of proof</a>.<a class="footnoteRef" href="#fn6" id="fnref6"><sup>6</sup></a></p>
<h2 id="axioms">Axioms</h2>

<p>There are two kinds of <a class="uri" href="axioms" title="wikilink">axioms</a>, 1) conventions that are taken as true that should be avoided because they cannot be tested, and 2) hypotheses.<a class="footnoteRef" href="#fn7" id="fnref7"><sup>7</sup></a> Proof in the theory of probability was built on four axioms developed in the late 17th century:</p>
<ol>
<li>The probability of a hypotheses is a non-negative real number

<math display="block" id="Statistical_proof:0">
 <semantics>
  <mrow>
   <mo maxsize="210%" minsize="210%">{</mo>
   <mrow>
    <mrow>
     <mi>Pr</mi>
     <mrow>
      <mo stretchy="false">(</mo>
      <mi>h</mi>
      <mo stretchy="false">)</mo>
     </mrow>
    </mrow>
    <mo>≧</mo>
    <mn>0</mn>
   </mrow>
   <mo maxsize="210%" minsize="210%">}</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <set>
    <apply>
     <geq></geq>
     <apply>
      <ci>Pr</ci>
      <ci>h</ci>
     </apply>
     <cn type="integer">0</cn>
    </apply>
   </set>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \bigg\{\Pr(h)\geqq 0\bigg\}
  </annotation>
 </semantics>
</math>

;</li>
<li>The probability of necessary truth equals one

<math display="block" id="Statistical_proof:1">
 <semantics>
  <mrow>
   <mo maxsize="210%" minsize="210%">{</mo>
   <mrow>
    <mrow>
     <mi>Pr</mi>
     <mrow>
      <mo stretchy="false">(</mo>
      <mi>t</mi>
      <mo stretchy="false">)</mo>
     </mrow>
    </mrow>
    <mo>=</mo>
    <mn>1</mn>
   </mrow>
   <mo maxsize="210%" minsize="210%">}</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <set>
    <apply>
     <eq></eq>
     <apply>
      <ci>Pr</ci>
      <ci>t</ci>
     </apply>
     <cn type="integer">1</cn>
    </apply>
   </set>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \bigg\{\Pr(t)=1\bigg\}
  </annotation>
 </semantics>
</math>

;</li>
<li>If two hypotheses h<sub>1</sub> and h<sub>2</sub> are mutually exclusive, then the sum of their probabilities is equal to the probability of their <a href="Logical_disjunction" title="wikilink">disjunction</a>

<math display="block" id="Statistical_proof:2">
 <semantics>
  <mrow>
   <mo maxsize="210%" minsize="210%">{</mo>
   <mrow>
    <mrow>
     <mrow>
      <mi>Pr</mi>
      <mrow>
       <mo>(</mo>
       <msub>
        <mi>h</mi>
        <mn>1</mn>
       </msub>
       <mo>)</mo>
      </mrow>
     </mrow>
     <mo>+</mo>
     <mrow>
      <mi>Pr</mi>
      <mrow>
       <mo>(</mo>
       <msub>
        <mi>h</mi>
        <mn>2</mn>
       </msub>
       <mo>)</mo>
      </mrow>
     </mrow>
    </mrow>
    <mo>=</mo>
    <mrow>
     <mi>Pr</mi>
     <mrow>
      <mo>(</mo>
      <mrow>
       <msub>
        <mi>h</mi>
        <mn>1</mn>
       </msub>
       <mi>o</mi>
       <mi>r</mi>
       <msub>
        <mi>h</mi>
        <mn>2</mn>
       </msub>
      </mrow>
      <mo>)</mo>
     </mrow>
    </mrow>
   </mrow>
   <mo maxsize="210%" minsize="210%">}</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <set>
    <apply>
     <eq></eq>
     <apply>
      <plus></plus>
      <apply>
       <ci>Pr</ci>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <ci>h</ci>
        <cn type="integer">1</cn>
       </apply>
      </apply>
      <apply>
       <ci>Pr</ci>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <ci>h</ci>
        <cn type="integer">2</cn>
       </apply>
      </apply>
     </apply>
     <apply>
      <ci>Pr</ci>
      <apply>
       <times></times>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <ci>h</ci>
        <cn type="integer">1</cn>
       </apply>
       <ci>o</ci>
       <ci>r</ci>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <ci>h</ci>
        <cn type="integer">2</cn>
       </apply>
      </apply>
     </apply>
    </apply>
   </set>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \bigg\{\Pr\left(h_{1}\right)+\Pr\left(h_{2}\right)=\Pr\left(h_{1}orh_{2}\right%
)\bigg\}
  </annotation>
 </semantics>
</math>

;</li>
<li>The conditional probability of h<sub>1</sub> given h<sub>2</sub> 

<math display="inline" id="Statistical_proof:3">
 <semantics>
  <mrow>
   <mo maxsize="260%" minsize="260%">{</mo>
   <mrow>
    <mi>Pr</mi>
    <mrow>
     <mo stretchy="false">(</mo>
     <msub>
      <mi>h</mi>
      <mn>1</mn>
     </msub>
     <mo stretchy="false">|</mo>
     <msub>
      <mi>h</mi>
      <mn>2</mn>
     </msub>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
   <mo maxsize="260%" minsize="260%">}</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <set>
    <apply>
     <ci>Pr</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>h</ci>
      <cn type="integer">1</cn>
     </apply>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>h</ci>
      <cn type="integer">2</cn>
     </apply>
    </apply>
   </set>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \Bigg\{\Pr(h_{1}|h_{2})\Bigg\}
  </annotation>
 </semantics>
</math>

 is equal to the unconditional probability 

<math display="inline" id="Statistical_proof:4">
 <semantics>
  <mrow>
   <mo maxsize="210%" minsize="210%">{</mo>
   <mrow>
    <mi>Pr</mi>
    <mrow>
     <mo stretchy="false">(</mo>
     <mrow>
      <msub>
       <mi>h</mi>
       <mn>1</mn>
      </msub>
      <mo>&</mo>
      <msub>
       <mi>h</mi>
       <mn>2</mn>
      </msub>
     </mrow>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
   <mo maxsize="210%" minsize="210%">}</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <set>
    <apply>
     <ci>Pr</ci>
     <apply>
      <and></and>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>h</ci>
       <cn type="integer">1</cn>
      </apply>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>h</ci>
       <cn type="integer">2</cn>
      </apply>
     </apply>
    </apply>
   </set>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \bigg\{\Pr(h_{1}\And h_{2})\bigg\}
  </annotation>
 </semantics>
</math>

 of the conjunction h<sub>1</sub> and h<sub>2</sub>, divided by the unconditional probability 

<math display="inline" id="Statistical_proof:5">
 <semantics>
  <mrow>
   <mo maxsize="210%" minsize="210%">{</mo>
   <mrow>
    <mi>Pr</mi>
    <mrow>
     <mo stretchy="false">(</mo>
     <msub>
      <mi>h</mi>
      <mn>2</mn>
     </msub>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
   <mo maxsize="210%" minsize="210%">}</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <set>
    <apply>
     <ci>Pr</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>h</ci>
      <cn type="integer">2</cn>
     </apply>
    </apply>
   </set>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \bigg\{\Pr(h_{2})\bigg\}
  </annotation>
 </semantics>
</math>

 of h<sub>2</sub> where that probability is positive 

<math display="inline" id="Statistical_proof:6">
 <semantics>
  <mrow>
   <mo maxsize="210%" minsize="210%">{</mo>
   <mfrac>
    <mrow>
     <mrow>
      <mi>Pr</mi>
      <mrow>
       <mo stretchy="false">(</mo>
       <msub>
        <mi>h</mi>
        <mn>1</mn>
       </msub>
       <mo stretchy="false">|</mo>
       <msub>
        <mi>h</mi>
        <mn>2</mn>
       </msub>
       <mo stretchy="false">)</mo>
      </mrow>
     </mrow>
     <mo>=</mo>
     <mrow>
      <mi>Pr</mi>
      <mrow>
       <mo stretchy="false">(</mo>
       <mrow>
        <msub>
         <mi>h</mi>
         <mn>1</mn>
        </msub>
        <mo>&</mo>
        <msub>
         <mi>h</mi>
         <mn>2</mn>
        </msub>
       </mrow>
       <mo stretchy="false">)</mo>
      </mrow>
     </mrow>
    </mrow>
    <mrow>
     <mi>Pr</mi>
     <mrow>
      <mo stretchy="false">(</mo>
      <msub>
       <mi>h</mi>
       <mn>2</mn>
      </msub>
      <mo stretchy="false">)</mo>
     </mrow>
    </mrow>
   </mfrac>
   <mo maxsize="210%" minsize="210%">}</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <set>
    <apply>
     <divide></divide>
     <apply>
      <eq></eq>
      <apply>
       <ci>Pr</ci>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <ci>h</ci>
        <cn type="integer">1</cn>
       </apply>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <ci>h</ci>
        <cn type="integer">2</cn>
       </apply>
      </apply>
      <apply>
       <ci>Pr</ci>
       <apply>
        <and></and>
        <apply>
         <csymbol cd="ambiguous">subscript</csymbol>
         <ci>h</ci>
         <cn type="integer">1</cn>
        </apply>
        <apply>
         <csymbol cd="ambiguous">subscript</csymbol>
         <ci>h</ci>
         <cn type="integer">2</cn>
        </apply>
       </apply>
      </apply>
     </apply>
     <apply>
      <ci>Pr</ci>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>h</ci>
       <cn type="integer">2</cn>
      </apply>
     </apply>
    </apply>
   </set>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \bigg\{\frac{\Pr(h_{1}|h_{2})=\Pr(h_{1}\And h_{2})}{\Pr(h_{2})}\bigg\}
  </annotation>
 </semantics>
</math>

, where 

<math display="inline" id="Statistical_proof:7">
 <semantics>
  <mrow>
   <mo maxsize="210%" minsize="210%">{</mo>
   <mrow>
    <mrow>
     <mi>Pr</mi>
     <mrow>
      <mo stretchy="false">(</mo>
      <msub>
       <mi>h</mi>
       <mn>2</mn>
      </msub>
      <mo stretchy="false">)</mo>
     </mrow>
    </mrow>
    <mo>></mo>
    <mn>0</mn>
   </mrow>
   <mo maxsize="210%" minsize="210%">}</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <set>
    <apply>
     <gt></gt>
     <apply>
      <ci>Pr</ci>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>h</ci>
       <cn type="integer">2</cn>
      </apply>
     </apply>
     <cn type="integer">0</cn>
    </apply>
   </set>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \bigg\{\Pr(h_{2})>0\bigg\}
  </annotation>
 </semantics>
</math>

.</li>
</ol>

<p>The preceding axioms provide the statistical proof and basis for the <a href="scientific_law" title="wikilink">laws</a> of randomness, or objective chance from where modern statistical theory has advanced. Experimental data, however, can never prove that the hypotheses (h) is true, but relies on an inductive inference by measuring the probability of the hypotheses relative to the empirical data. The proof is in the rational demonstration of using the <a href="Statistical_inference" title="wikilink">logic of inference</a>, <a href="mathematical_proof" title="wikilink">math</a>, <a href="Statistical_hypothesis_testing" title="wikilink">testing</a>, and <a class="uri" href="deductive" title="wikilink">deductive</a> <a href="reason" title="wikilink">reasoning</a> of <a href="Statistical_significance" title="wikilink">significance</a>.<a class="footnoteRef" href="#fn8" id="fnref8"><sup>8</sup></a><a class="footnoteRef" href="#fn9" id="fnref9"><sup>9</sup></a><a class="footnoteRef" href="#fn10" id="fnref10"><sup>10</sup></a></p>
<h2 id="test-and-proof">Test and proof</h2>

<p>The term <em>proof</em> descended from its Latin roots (provable, probable, <em>probare</em> L.) meaning <em>to test</em>.<a class="footnoteRef" href="#fn11" id="fnref11"><sup>11</sup></a><a class="footnoteRef" href="#fn12" id="fnref12"><sup>12</sup></a> Hence, proof is a form of inference by means of a statistical test. Statistical tests are formulated on models that generate <a href="probability_distributions" title="wikilink">probability distributions</a>. Examples of probability distributions might include the <a href="Bernoulli_distribution" title="wikilink">binary</a>, <a href="normal_distribution" title="wikilink">normal</a>, or <a href="poisson_distribution" title="wikilink">poisson distribution</a> that give exact descriptions of variables that behave according to <a href="natural_law" title="wikilink">natural laws</a> of <a href="Randomness" title="wikilink">random chance</a>. When a <a href="statistical_test" title="wikilink">statistical test</a> is applied to samples of a population, the test determines if the sample statistics are significantly different from the assumed <a href="null-hypothesis" title="wikilink">null-model</a>. True values of a population, which are unknowable in practice, are called parameters of the population. Researchers sample from populations, which provide estimates of the parameters, to calculate the mean or standard deviation. If the entire population is sampled, then the sample statistic mean and distribution will converge with the parametric distribution.<a class="footnoteRef" href="#fn13" id="fnref13"><sup>13</sup></a></p>

<p>Using the scientific method of falsification, the <a href="P-value" title="wikilink">probability value</a> that the sample statistic is sufficiently different from the null-model than can be explained by chance alone is given prior to the test. Most statisticians set the prior probability value at 0.05 or 0.1, which means if the sample statistics diverge from the parametric model more than 5 (or 10) times out of 100, then the discrepancy is unlikely to be explained by chance alone and the null-hypothesis is rejected. Statistical models provide exact outcomes of the parametric and estimates of the sample statistics. Hence, the <a href="Philosophic_burden_of_proof" title="wikilink">burden of proof</a> rests in the sample statistics that provide estimates of a statistical model. Statistical models contain the <a href="mathematical_proof" title="wikilink">mathematical proof</a> of the parametric values and their probability distributions.<a class="footnoteRef" href="#fn14" id="fnref14"><sup>14</sup></a><a class="footnoteRef" href="#fn15" id="fnref15"><sup>15</sup></a></p>
<h2 id="bayes-theorem">Bayes theorem</h2>

<p></p>

<p><a href="Bayesian_statistics" title="wikilink">Bayesian statistics</a> are based on a different philosophical approach for proof of <a href="Statistical_inference" title="wikilink">inference</a>. The mathematical formula for Bayes's theorem is:</p>

<p>

<math display="inline" id="Statistical_proof:8">
 <semantics>
  <mrow>
   <mi>P</mi>
   <mi>r</mi>
   <mrow>
    <mo stretchy="false">[</mo>
    <mi>P</mi>
    <mi>a</mi>
    <mi>r</mi>
    <mi>a</mi>
    <mi>m</mi>
    <mi>e</mi>
    <mi>t</mi>
    <mi>e</mi>
    <mi>r</mi>
    <mo stretchy="false">|</mo>
    <mi>D</mi>
    <mi>a</mi>
    <mi>t</mi>
    <mi>a</mi>
    <mo stretchy="false">]</mo>
   </mrow>
   <mo>=</mo>
   <mfrac>
    <mrow>
     <mi>P</mi>
     <mi>r</mi>
     <mrow>
      <mo stretchy="false">[</mo>
      <mi>D</mi>
      <mi>a</mi>
      <mi>t</mi>
      <mi>a</mi>
      <mo stretchy="false">|</mo>
      <mi>P</mi>
      <mi>a</mi>
      <mi>r</mi>
      <mi>a</mi>
      <mi>m</mi>
      <mi>e</mi>
      <mi>t</mi>
      <mi>e</mi>
      <mi>r</mi>
      <mo stretchy="false">]</mo>
     </mrow>
     <mo>×</mo>
     <mi>P</mi>
     <mi>r</mi>
     <mrow>
      <mo stretchy="false">[</mo>
      <mi>P</mi>
      <mi>a</mi>
      <mi>r</mi>
      <mi>a</mi>
      <mi>m</mi>
      <mi>e</mi>
      <mi>t</mi>
      <mi>e</mi>
      <mi>r</mi>
      <mo stretchy="false">]</mo>
     </mrow>
    </mrow>
    <mrow>
     <mi>P</mi>
     <mi>r</mi>
     <mrow>
      <mo stretchy="false">[</mo>
      <mrow>
       <mi>D</mi>
       <mi>a</mi>
       <mi>t</mi>
       <mi>a</mi>
      </mrow>
      <mo stretchy="false">]</mo>
     </mrow>
    </mrow>
   </mfrac>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <cerror>
    <csymbol cd="ambiguous">fragments</csymbol>
    <csymbol cd="unknown">P</csymbol>
    <csymbol cd="unknown">r</csymbol>
    <cerror>
     <csymbol cd="ambiguous">fragments</csymbol>
     <ci>normal-[</ci>
     <csymbol cd="unknown">P</csymbol>
     <csymbol cd="unknown">a</csymbol>
     <csymbol cd="unknown">r</csymbol>
     <csymbol cd="unknown">a</csymbol>
     <csymbol cd="unknown">m</csymbol>
     <csymbol cd="unknown">e</csymbol>
     <csymbol cd="unknown">t</csymbol>
     <csymbol cd="unknown">e</csymbol>
     <csymbol cd="unknown">r</csymbol>
     <ci>normal-|</ci>
     <csymbol cd="unknown">D</csymbol>
     <csymbol cd="unknown">a</csymbol>
     <csymbol cd="unknown">t</csymbol>
     <csymbol cd="unknown">a</csymbol>
     <ci>normal-]</ci>
    </cerror>
    <eq></eq>
    <apply>
     <divide></divide>
     <cerror>
      <csymbol cd="ambiguous">fragments</csymbol>
      <csymbol cd="unknown">P</csymbol>
      <csymbol cd="unknown">r</csymbol>
      <cerror>
       <csymbol cd="ambiguous">fragments</csymbol>
       <ci>normal-[</ci>
       <csymbol cd="unknown">D</csymbol>
       <csymbol cd="unknown">a</csymbol>
       <csymbol cd="unknown">t</csymbol>
       <csymbol cd="unknown">a</csymbol>
       <ci>normal-|</ci>
       <csymbol cd="unknown">P</csymbol>
       <csymbol cd="unknown">a</csymbol>
       <csymbol cd="unknown">r</csymbol>
       <csymbol cd="unknown">a</csymbol>
       <csymbol cd="unknown">m</csymbol>
       <csymbol cd="unknown">e</csymbol>
       <csymbol cd="unknown">t</csymbol>
       <csymbol cd="unknown">e</csymbol>
       <csymbol cd="unknown">r</csymbol>
       <ci>normal-]</ci>
      </cerror>
      <times></times>
      <csymbol cd="unknown">P</csymbol>
      <csymbol cd="unknown">r</csymbol>
      <cerror>
       <csymbol cd="ambiguous">fragments</csymbol>
       <ci>normal-[</ci>
       <csymbol cd="unknown">P</csymbol>
       <csymbol cd="unknown">a</csymbol>
       <csymbol cd="unknown">r</csymbol>
       <csymbol cd="unknown">a</csymbol>
       <csymbol cd="unknown">m</csymbol>
       <csymbol cd="unknown">e</csymbol>
       <csymbol cd="unknown">t</csymbol>
       <csymbol cd="unknown">e</csymbol>
       <csymbol cd="unknown">r</csymbol>
       <ci>normal-]</ci>
      </cerror>
     </cerror>
     <apply>
      <times></times>
      <ci>P</ci>
      <ci>r</ci>
      <apply>
       <csymbol cd="latexml">delimited-[]</csymbol>
       <apply>
        <times></times>
        <ci>D</ci>
        <ci>a</ci>
        <ci>t</ci>
        <ci>a</ci>
       </apply>
      </apply>
     </apply>
    </apply>
   </cerror>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   Pr[Parameter|Data]=\frac{Pr[Data|Parameter]\times Pr[Parameter]}{Pr[Data]}
  </annotation>
 </semantics>
</math>

</p>

<p>The formula is read as the probability of the parameter (or hypothesis <em>=h</em>, as used in the notation on <a href="Statistical_proof#Axioms" title="wikilink">axioms</a>) “given” the data (or empirical observation), where the horizontal bar refers to "given". The right hand side of the formula calculates the prior probability of a statistical model (Pr [Parameter]) with the <a href="Likelihood_function" title="wikilink">likelihood</a> (Pr [Data | Parameter]) to produce a posterior probability distribution of the parameter (Pr [Parameter | Data]). The posterior probability is the likelihood that the parameter is correct given the observed data or samples statistics.<a class="footnoteRef" href="#fn16" id="fnref16"><sup>16</sup></a> Hypotheses can be compared using Bayesian inference by means of the Bayes factor, which is the ratio of the posterior odds to the prior odds. It provides a measure of the data and if it has increased or decreased the likelihood of one hypotheses relative to another.<a class="footnoteRef" href="#fn17" id="fnref17"><sup>17</sup></a></p>

<p>The statistical proof is the Bayesian demonstration that one hypothesis has a higher (weak, strong, positive) likelihood.<a class="footnoteRef" href="#fn18" id="fnref18"><sup>18</sup></a> There is considerable debate if the Bayesian method aligns with Karl Poppers method of proof of falsification, where some have suggested that "...there is no such thing as "accepting" hypotheses at all. All that one does in science is assign degrees of belief..."<a class="footnoteRef" href="#fn19" id="fnref19"><sup>19</sup></a> According to Popper, hypotheses that have withstood testing and have yet to be falsified are not verified but <a href="Corroborating_evidence" title="wikilink">corroborated</a>. Some researches have suggested that Popper's quest to define corroboration on the premise of probability put his philosophy in line with the Bayesian approach. In this context, the likelihood of one hypothesis relative to another may be an index of corroboration, not confirmation, and thus statistically proven through rigorous objective standing.<a class="footnoteRef" href="#fn20" id="fnref20"><sup>20</sup></a><a class="footnoteRef" href="#fn21" id="fnref21"><sup>21</sup></a></p>
<h2 id="in-legal-proceedings">In legal proceedings</h2>

<p> | width = 25% | align = right}}</p>

<p>Statistical proof in a legal proceeding can be sorted into three categories of evidence:</p>
<ol>
<li>The occurrence of an event, act, or type of conduct,</li>
<li>The identity the individual(s) responsible</li>
<li>The intent or psychological responsibility<a class="footnoteRef" href="#fn22" id="fnref22"><sup>22</sup></a></li>
</ol>

<p>Statistical proof was not regularly applied in decisions concerning United States legal proceedings until the mid 1970's following a landmark jury discrimination case in <em>Castaneda v. Partida</em>. The US Supreme Court ruled that gross statistical disparities constitutes "<em><a href="prima_facie" title="wikilink">prima facie</a></em> proof" of discrimination, resulting in a shift of the burden of proof from plaintiff to defendant. Since that ruling, statistical proof has been used in many other cases on inequality, discrimination, and DNA evidence.<a class="footnoteRef" href="#fn23" id="fnref23"><sup>23</sup></a><a class="footnoteRef" href="#fn24" id="fnref24"><sup>24</sup></a><a class="footnoteRef" href="#fn25" id="fnref25"><sup>25</sup></a> However, there is not a one-to-one correspondence between statistical proof and the legal burden of proof. "The Supreme Court has stated that the degrees of rigor required in the fact finding processes of law and science do not necessarily correspond."<a class="footnoteRef" href="#fn26" id="fnref26"><sup>26</sup></a></p>

<p>In an example of a death row sentence (<em>McCleskey v. Kemp</em><mtpl>{{#tag:ref|481 U.S. 279 (1987).<a class="footnoteRef" href="#fn27" id="fnref27"><sup>27</sup></a>|group="nb"}}</mtpl>) concerning racial discrimination, the petitioner, a black man named McCleskey was charged with the murder of a white police officer during a robbery. Expert testimony for McClesky introduced a statistical proof showing that "defendants charged with killing white victims were 4.3 times as likely to receive a death sentence as charged with killing blacks.".<a class="footnoteRef" href="#fn28" id="fnref28"><sup>28</sup></a> Nonetheless, the statistics was insufficient "to prove that the decisionmakers in his case acted with discriminatory purpose."<a class="footnoteRef" href="#fn29" id="fnref29"><sup>29</sup></a> It was further argued that there were "inherent limitations of the statistical proof",<a class="footnoteRef" href="#fn30" id="fnref30"><sup>30</sup></a> because it did not refer to the specifics of the individual. Despite the statistical demonstration of an increased probability of discrimination, the legal burden of proof (it was argued) had to be examined on a case by case basis.<a class="footnoteRef" href="#fn31" id="fnref31"><sup>31</sup></a></p>
<h2 id="see-also">See also</h2>
<ul>
<li><a href="Mathematical_proof" title="wikilink">Mathematical proof</a></li>
<li><a href="Data_analysis" title="wikilink">Data analysis</a></li>
</ul>
<h2 id="references">References</h2>
<references>
</references>
<h2 id="notes">Notes</h2>

<p>"</p>

<p><a href="Category:Statistical_terminology" title="wikilink">Category:Statistical terminology</a> <a href="Category:Logic_and_statistics" title="wikilink">Category:Logic and statistics</a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1"><a href="#fnref1">↩</a></li>
<li id="fn2"></li>
<li id="fn3"><a href="#fnref3">↩</a></li>
<li id="fn4"><a href="#fnref4">↩</a></li>
<li id="fn5"></li>
<li id="fn6"><a href="#fnref6">↩</a></li>
<li id="fn7"><a href="#fnref7">↩</a></li>
<li id="fn8"></li>
<li id="fn9"></li>
<li id="fn10"><a href="#fnref10">↩</a></li>
<li id="fn11"><a href="#fnref11">↩</a></li>
<li id="fn12"><a href="#fnref12">↩</a></li>
<li id="fn13"><a href="#fnref13">↩</a></li>
<li id="fn14"><a href="#fnref14">↩</a></li>
<li id="fn15"><a href="#fnref15">↩</a></li>
<li id="fn16"><a href="#fnref16">↩</a></li>
<li id="fn17"><a href="#fnref17">↩</a></li>
<li id="fn18"></li>
<li id="fn19"><a href="#fnref19">↩</a></li>
<li id="fn20"></li>
<li id="fn21"><a href="#fnref21">↩</a></li>
<li id="fn22"><a href="#fnref22">↩</a></li>
<li id="fn23"></li>
<li id="fn24"><a href="#fnref24">↩</a></li>
<li id="fn25"><a href="#fnref25">↩</a></li>
<li id="fn26"></li>
<li id="fn27"></li>
<li id="fn28"><a href="#fnref28">↩</a></li>
<li id="fn29"></li>
<li id="fn30"></li>
<li id="fn31"></li>
</ol>
</section>
</hr></body>
</html>
