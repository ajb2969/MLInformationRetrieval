   Jackknife resampling      Jackknife resampling   In statistics , the jackknife is a resampling technique especially useful for variance and bias estimation. The jackknife predates other common resampling methods such as the bootstrap . The jackknife estimator of a parameter is found by systematically leaving out each observation from a dataset and calculating the estimate and then finding the average of these calculations. Given a sample of size   N   N   N   , the jackknife estimate is found by aggregating the estimates of each    N  -  1      N  1    N-1   estimate in the sample.  The jackknife technique was developed by Maurice Quenouille (1949, 1956). John W. Tukey (1958) expanded on the technique and proposed the name "jackknife" since, like a Boy Scout's jackknife, it is a "rough and ready" tool that can solve a variety of problems even though specific problems may be more efficiently solved with a purpose-designed tool.  The jackknife is a linear approximation of the bootstrap.  Estimation  The jackknife estimate of a parameter can be found by estimating the parameter for each subsample omitting the i th observation to estimate the previously unknown value of a parameter (say     x  ¯   i     subscript   normal-¯  x   i    \bar{x}_{i}   ).        x  ¯   i   =    1   n  -  1      ∑   j  ≠  i   n    (    x  ¯   j   )          subscript   normal-¯  x   normal-i       1    n  1      superscript   subscript     j  i    n    subscript   normal-¯  x   j       \bar{x}_{\mathrm{i}}=\frac{1}{n-1}\sum_{j\neq i}^{n}(\bar{x}_{j})     Variance estimation  An estimate of the variance of an estimator can be calculated using the jackknife technique.       Var   (  jackknife  )    =     n  -  1   n     ∑   i  =  1   n     (     x  ¯   i   -    x  ¯    (  .  )     )   2          subscript  Var  jackknife         n  1   n     superscript   subscript     i  1    n    superscript     subscript   normal-¯  x   i    subscript   normal-¯  x    fragments  normal-(  normal-.  normal-)     2       \operatorname{Var}_{\mathrm{(jackknife)}}=\frac{n-1}{n}\sum_{i=1}^{n}(\bar{x}_%
 {i}-\bar{x}_{\mathrm{(.)}})^{2}     where     x  ¯   i     subscript   normal-¯  x   i    \bar{x}_{i}   is the parameter estimate based on leaving out the i th observation, and     x  ¯    (  .  )      subscript   normal-¯  x    fragments  normal-(  normal-.  normal-)     \bar{x}_{\mathrm{(.)}}   is the estimator based on all of the samples.  Bias estimation and correction  The jackknife technique can be used to estimate the bias of an estimator calculated over the entire sample. Say    θ  ^     normal-^  θ    \hat{\theta}   is the calculated parameter of interest based on all   n   n   {n}   observations. Here,        θ  ^    (  .  )    =    1  n     ∑   i  =  1   n     θ  ^    (  i  )           subscript   normal-^  θ    fragments  normal-(  normal-.  normal-)        1  n     superscript   subscript     i  1    n    subscript   normal-^  θ   normal-i       \hat{\theta}_{\mathrm{(.)}}=\frac{1}{n}\sum_{i=1}^{n}\hat{\theta}_{\mathrm{(i)}}   where     θ  ^    (  i  )      subscript   normal-^  θ   normal-i    \hat{\theta}_{\mathrm{(i)}}   is the estimation of parameter of interest based on sample omitting ith observation (jackknife estimator), and     θ  ^    (  .  )      subscript   normal-^  θ    fragments  normal-(  normal-.  normal-)     \hat{\theta}_{\mathrm{(.)}}   is the mean jackknife estimator. The parameter bias estimate is,         B  I  A  S   ^    (  θ  )    =    (   n  -  1   )    (     θ  ^    (  .  )    -   θ  ^    )         subscript   normal-^    B  I  A  S    θ       n  1      subscript   normal-^  θ    fragments  normal-(  normal-.  normal-)     normal-^  θ       \hat{BIAS}_{\mathrm{(\theta)}}=(n-1)(\hat{\theta}_{\mathrm{(.)}}-\hat{\theta})     This reduces bias by an order of magnitude, from    O   (   N   -  1    )       O   superscript  N    1      O(N^{-1})   to    O   (   N   -  2    )       O   superscript  N    2      O(N^{-2})   .  This provides an estimated correction of bias due to the estimation method. The jackknife does not correct for a biased sample.  Notes  References         .   "  Category:Statistical terminology  Category:Computational statistics  Category:Data analysis  Category:Statistical inference  Category:Resampling (statistics)   