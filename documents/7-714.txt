   Lucas–Kanade method      Lucas–Kanade method   In computer vision , the Lucas–Kanade method is a widely used differential method for optical flow estimation developed by Bruce D. Lucas and Takeo Kanade . It assumes that the flow is essentially constant in a local neighbourhood of the pixel under consideration, and solves the basic optical flow equations for all the pixels in that neighbourhood, by the least squares criterion .  B. D. Lucas and T. Kanade (1981), An  iterative  image  registration  technique  with  an  application  to  stereo  vision. Proceedings of Imaging Understanding Workshop, pages 121--130  1  By combining information from several nearby pixels, the Lucas–Kanade method can often resolve the inherent ambiguity of the optical flow equation. It is also less sensitive to image noise than point-wise methods. On the other hand, since it is a purely local method, it cannot provide flow information in the interior of uniform regions of the image.  Concept  The Lucas–Kanade method assumes that the displacement of the image contents between two nearby instants (frames) is small and approximately constant within a neighborhood of the point p under consideration. Thus the optical flow equation can be assumed to hold for all pixels within a window centered at p . Namely, the local image flow (velocity) vector    (   V  x   ,   V  y   )      subscript  V  x    subscript  V  y     (V_{x},V_{y})   must satisfy         I  x    (   q  1   )    V  x    +    I  y    (   q  1   )    V  y     =   -    I  t    (   q  1   )              subscript  I  x    subscript  q  1    subscript  V  x       subscript  I  y    subscript  q  1    subscript  V  y          subscript  I  t    subscript  q  1       I_{x}(q_{1})V_{x}+I_{y}(q_{1})V_{y}=-I_{t}(q_{1})            I  x    (   q  2   )    V  x    +    I  y    (   q  2   )    V  y     =   -    I  t    (   q  2   )              subscript  I  x    subscript  q  2    subscript  V  x       subscript  I  y    subscript  q  2    subscript  V  y          subscript  I  t    subscript  q  2       I_{x}(q_{2})V_{x}+I_{y}(q_{2})V_{y}=-I_{t}(q_{2})        ⋮   normal-⋮   \vdots            I  x    (   q  n   )    V  x    +    I  y    (   q  n   )    V  y     =   -    I  t    (   q  n   )              subscript  I  x    subscript  q  n    subscript  V  x       subscript  I  y    subscript  q  n    subscript  V  y          subscript  I  t    subscript  q  n       I_{x}(q_{n})V_{x}+I_{y}(q_{n})V_{y}=-I_{t}(q_{n})     where     q  1   ,   q  2   ,  …  ,   q  n       subscript  q  1    subscript  q  2   normal-…   subscript  q  n     q_{1},q_{2},\dots,q_{n}   are the pixels inside the window, and      I  x    (   q  i   )    ,    I  y    (   q  i   )    ,    I  t    (   q  i   )          subscript  I  x    subscript  q  i       subscript  I  y    subscript  q  i       subscript  I  t    subscript  q  i      I_{x}(q_{i}),I_{y}(q_{i}),I_{t}(q_{i})   are the partial derivatives of the image   I   I   I   with respect to position x , y and time t , evaluated at the point    q  i     subscript  q  i    q_{i}   and at the current time.  These equations can be written in matrix form     A  v   =  b        A  v   b    Av=b   , where       A  =   [       I  x    (   q  1   )        I  y    (   q  1   )          I  x    (   q  2   )        I  y    (   q  2   )        ⋮    ⋮        I  x    (   q  n   )        I  y    (   q  n   )       ]    ,    v  =    [      V  x        V  y      ]   ,  and     b  =   [      -    I  t    (   q  1   )          -    I  t    (   q  2   )         ⋮       -    I  t    (   q  n   )        ]        formulae-sequence    A       subscript  I  x    subscript  q  1       subscript  I  y    subscript  q  1         subscript  I  x    subscript  q  2       subscript  I  y    subscript  q  2      normal-⋮  normal-⋮       subscript  I  x    subscript  q  n       subscript  I  y    subscript  q  n        formulae-sequence    v      subscript  V  x      subscript  V  y     and      b         subscript  I  t    subscript  q  1            subscript  I  t    subscript  q  2       normal-⋮         subscript  I  t    subscript  q  n           A=\begin{bmatrix}I_{x}(q_{1})&I_{y}(q_{1})\\
 I_{x}(q_{2})&I_{y}(q_{2})\\
 \vdots&\vdots\\
 I_{x}(q_{n})&I_{y}(q_{n})\end{bmatrix},\quad\quad v=\begin{bmatrix}V_{x}\\
 V_{y}\end{bmatrix},\quad\mbox{and}\quad b=\begin{bmatrix}-I_{t}(q_{1})\\
 -I_{t}(q_{2})\\
 \vdots\\
 -I_{t}(q_{n})\end{bmatrix}     This system has more equations than unknowns and thus it is usually over-determined. The Lucas–Kanade method obtains a compromise solution by the least squares principle. Namely, it solves the 2×2 system        A  T   A  v   =    A  T   b          superscript  A  T   A  v      superscript  A  T   b     A^{T}Av=A^{T}b   or      v  =     (    A  T   A   )    -  1     A  T   b       normal-v     superscript     superscript  A  T   A     1     superscript  A  T   b     \mathrm{v}=(A^{T}A)^{-1}A^{T}b   where    A  T     superscript  A  T    A^{T}   is the transpose of matrix   A   A   A   . That is, it computes       [      V  x        V  y      ]   =     [        ∑  i      I  x     (   q  i   )   2          ∑  i      I  x    (   q  i   )    I  y    (   q  i   )            ∑  i      I  y    (   q  i   )    I  x    (   q  i   )          ∑  i      I  y     (   q  i   )   2        ]    -  1     [      -     ∑  i      I  x    (   q  i   )    I  t    (   q  i   )           -     ∑  i      I  y    (   q  i   )    I  t    (   q  i   )         ]           subscript  V  x      subscript  V  y        superscript      subscript   i      subscript  I  x    superscript   subscript  q  i   2       subscript   i      subscript  I  x    subscript  q  i    subscript  I  y    subscript  q  i         subscript   i      subscript  I  y    subscript  q  i    subscript  I  x    subscript  q  i       subscript   i      subscript  I  y    superscript   subscript  q  i   2         1          subscript   i      subscript  I  x    subscript  q  i    subscript  I  t    subscript  q  i            subscript   i      subscript  I  y    subscript  q  i    subscript  I  t    subscript  q  i           \begin{bmatrix}V_{x}\\
 V_{y}\end{bmatrix}=\begin{bmatrix}\sum_{i}I_{x}(q_{i})^{2}&\sum_{i}I_{x}(q_{i}%
 )I_{y}(q_{i})\\
 \sum_{i}I_{y}(q_{i})I_{x}(q_{i})&\sum_{i}I_{y}(q_{i})^{2}\end{bmatrix}^{-1}%
 \begin{bmatrix}-\sum_{i}I_{x}(q_{i})I_{t}(q_{i})\\
 -\sum_{i}I_{y}(q_{i})I_{t}(q_{i})\end{bmatrix}   with the sums running from i =1 to n .  The matrix     A  T   A       superscript  A  T   A    A^{T}A   is often called the structure tensor of the image at the point p .  Weighted window  The plain least squares solution above gives the same importance to all n pixels    q  i     subscript  q  i    q_{i}   in the window. In practice it is usually better to give more weight to the pixels that are closer to the central pixel p . For that, one uses the weighted version of the least squares equation,        A  T   W  A  v   =    A  T   W  b          superscript  A  T   W  A  v      superscript  A  T   W  b     A^{T}WAv=A^{T}Wb   or      v  =     (    A  T   W  A   )    -  1     A  T   W  b       normal-v     superscript     superscript  A  T   W  A     1     superscript  A  T   W  b     \mathrm{v}=(A^{T}WA)^{-1}A^{T}Wb   where   W   W   W   is an n × n  diagonal matrix containing the weights     W   i  i    =   w  i        subscript  W    i  i     subscript  w  i     W_{ii}=w_{i}   to be assigned to the equation of pixel    q  i     subscript  q  i    q_{i}   . That is, it computes       [      V  x        V  y      ]   =     [        ∑  i      w  i    I  x     (   q  i   )   2          ∑  i      w  i    I  x    (   q  i   )    I  y    (   q  i   )            ∑  i      w  i    I  x    (   q  i   )    I  y    (   q  i   )          ∑  i      w  i    I  y     (   q  i   )   2        ]    -  1     [      -     ∑  i      w  i    I  x    (   q  i   )    I  t    (   q  i   )           -     ∑  i      w  i    I  y    (   q  i   )    I  t    (   q  i   )         ]           subscript  V  x      subscript  V  y        superscript      subscript   i      subscript  w  i    subscript  I  x    superscript   subscript  q  i   2       subscript   i      subscript  w  i    subscript  I  x    subscript  q  i    subscript  I  y    subscript  q  i         subscript   i      subscript  w  i    subscript  I  x    subscript  q  i    subscript  I  y    subscript  q  i       subscript   i      subscript  w  i    subscript  I  y    superscript   subscript  q  i   2         1          subscript   i      subscript  w  i    subscript  I  x    subscript  q  i    subscript  I  t    subscript  q  i            subscript   i      subscript  w  i    subscript  I  y    subscript  q  i    subscript  I  t    subscript  q  i           \begin{bmatrix}V_{x}\\
 V_{y}\end{bmatrix}=\begin{bmatrix}\sum_{i}w_{i}I_{x}(q_{i})^{2}&\sum_{i}w_{i}I%
 _{x}(q_{i})I_{y}(q_{i})\\
 \sum_{i}w_{i}I_{x}(q_{i})I_{y}(q_{i})&\sum_{i}w_{i}I_{y}(q_{i})^{2}\end{%
 bmatrix}^{-1}\begin{bmatrix}-\sum_{i}w_{i}I_{x}(q_{i})I_{t}(q_{i})\\
 -\sum_{i}w_{i}I_{y}(q_{i})I_{t}(q_{i})\end{bmatrix}     The weight    w  i     subscript  w  i    w_{i}   is usually set to a Gaussian function of the distance between    q  i     subscript  q  i    q_{i}   and p .  Use conditions and techniques  In order for equation      A  T   A  v   =    A  T   b          superscript  A  T   A  v      superscript  A  T   b     A^{T}Av=A^{T}b   to be solvable,     A  T   A       superscript  A  T   A    A^{T}A   should be invertible, or     A  T   A       superscript  A  T   A    A^{T}A   's eigenvalues satisfy     λ  1   ≥   λ  2   >  0         subscript  λ  1    subscript  λ  2        0     \lambda_{1}\geq\lambda_{2}>0   . To avoid noise issue, usually    λ  2     subscript  λ  2    \lambda_{2}   is required not too small. Also, if     λ  1   /   λ  2        subscript  λ  1    subscript  λ  2     \lambda_{1}/\lambda_{2}   is too large, this means the point p is on an edge, and this method suffers from the aperture problem . So for this method to work properly, the condition is    λ  1     subscript  λ  1    \lambda_{1}   and    λ  2     subscript  λ  2    \lambda_{2}   are large enough and have similar magnitude. This condition is also the one for Corner detection . This observation shows that one can easily tell which pixel is suitable for Lucas–Kanade method to work on by inspecting a single image.  One main assumption for this method is that the motion is small (less than 1 pixel between two images for example). If the motion is large and violates this assumption, one technique is to reduce the resolution of images first and then apply the Lucas-Kanade method. 2  Improvements and extensions  The least-squares approach implicitly assumes that the errors in the image data have a Gaussian distribution with zero mean. If one expects the window to contain a certain percentage of " outliers " (grossly wrong data values, that do not follow the "ordinary" Gaussian error distribution), one may use statistical analysis to detect them, and reduce their weight accordingly.  The Lucas–Kanade method per se can be used only when the image flow vector     V  x   ,   V  y       subscript  V  x    subscript  V  y     V_{x},V_{y}   between the two frames is small enough for the differential equation of the optical flow to hold, which is often less than the pixel spacing. When the flow vector may exceed this limit, such as in stereo matching or warped document registration, the Lucas–Kanade method may still be used to refine some coarse estimate of the same, obtained by other means; for example, by extrapolating the flow vectors computed for previous frames, or by running the Lucas-Kanade algorithm on reduced-scale versions of the images. Indeed, the latter method is the basis of the popular Kanade-Lucas-Tomasi (KLT) feature matching algorithm.  A similar technique can be used to compute differential affine deformations of the image contents.  See also   Optical flow  Horn–Schunck method  The Shi and Tomasi corner detection algorithm  Kanade–Lucas–Tomasi feature tracker   References  External links   The image stabilizer plugin for ImageJ based on the Lucas–Kanade method  Mathworks Lucas-Kanade Matlab implementation of inverse and normal affine Lucas-Kanade  FolkiGPU : GPU implementation of an iterative Lucas-Kanade based optical flow  KLT : An Implementation of the Kanade–Lucas–Tomasi Feature Tracker  Takeo Kanade  C++ example using the Lucas-Kanade optical flow algorithm  Python example using the Lucas-Kanade optical flow algorithm  Python example using the Lucas-Kanade tracker for homography matching  MATLAB quick example of Lucas-Kanade method to show optical flow field  MATLAB quick example of Lucas-Kanade method to show velocity vector of objects   "  Category:Motion in computer vision     Bruce D. Lucas (1984) Generalized Image Matching by the Method of Differences (doctoral dissertation) ↩  J. Y. Bouguet, (2001) . Pyramidal implementation of the affine lucas kanade feature tracker description of the algorithm. Intel Corporation, 5. ↩     