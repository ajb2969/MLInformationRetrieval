


Sylvester's determinant theorem




Sylvester's determinant theorem

In matrix theory, Sylvester's determinant theorem is a theorem useful for evaluating certain types of determinants. It is named after James Joseph Sylvester, who stated this theorem without proof in 1851.1
The theorem states that if A, B are matrices of size p × n and n × p respectively, then



where Ia is the identity matrix of order a.23
This can be seen for invertible A, B by conjugating I + AB by A−1, then extended to arbitrary square matrices by density of invertible matrices, and then to arbitrary rectangular matrices by adding zero column or row vectors as necessary.
It is closely related to the Matrix determinant lemma and its generalization. It is the determinant analogue of the Woodbury matrix identity for matrix inverses.
Proof
The theorem may be proven as follows.4 Let 
 
 
 
  be a matrix comprising the four blocks 
 
 
 
 , 
 
 
 
 , 
 
 
 
  and 
 
 



 
 . Block LU decomposition of 
 
 
 
  yields


 
  from which


 
  follows. Decomposing 
 
 
 
  to an upper and a lower triangular matrix instead,


 
 , yields


 
 . This proves


 
 .
Applications
This theorem is useful in developing a Bayes estimator for multivariate Gaussian distributions.
The identity also finds applications in random matrix theory by relating determinants of large matrices to determinants of smaller ones.5
References
"
Category:Determinants Category:Matrix theory Category:Linear algebra Category:Theorems in algebra




  Cited in ↩
 page 416↩
↩
.↩
http://terrytao.wordpress.com/2010/12/17/the-mesoscopic-structure-of-gue-eigenvalues/↩




