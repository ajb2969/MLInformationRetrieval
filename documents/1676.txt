   Block matrix pseudoinverse      Block matrix pseudoinverse   In mathematics, block matrix pseudoinverse is a formula of pseudoinverse of a partitioned matrix . This is useful for decomposing or approximating many algorithms updating parameters in signal processing , which are based on least squares method.  Derivation  Consider a column-wise partitioned matrix:          [  ğ€  ,  ğ  ]   ,  ğ€   âˆˆ    \reals    m  Ã—  n     ,    ğ  âˆˆ    \reals    m  Ã—  p     ,   m  â‰¥   n  +  p      .     formulae-sequence      ğ€  ğ   ğ€    superscript  \reals    m  n      formulae-sequence    ğ   superscript  \reals    m  p       m    n  p       [\mathbf{A},\mathbf{B}],\qquad\mathbf{A}\in\reals^{m\times n},\qquad\mathbf{B}%
 \in\reals^{m\times p},\qquad m\geq n+p.     If the above matrix is full rank, the pseudoinverse matrices of it and its transpose are as follows.         [      ğ€  ,     ğ     ]   +   =     (     [  ğ€  ,  ğ  ]   T    [  ğ€  ,  ğ  ]    )    -  1      [  ğ€  ,  ğ  ]   T     ,       superscript    ğ€  ğ         superscript     superscript   ğ€  ğ   T    ğ€  ğ      1     superscript   ğ€  ğ   T      \begin{bmatrix}\mathbf{A},&\mathbf{B}\end{bmatrix}^{+}=([\mathbf{A},\mathbf{B}%
 ]^{T}[\mathbf{A},\mathbf{B}])^{-1}[\mathbf{A},\mathbf{B}]^{T},            [      ğ€  T        ğ  T      ]   +   =    [  ğ€  ,  ğ  ]     (     [  ğ€  ,  ğ  ]   T    [  ğ€  ,  ğ  ]    )    -  1      .       superscript     superscript  ğ€  T      superscript  ğ  T          ğ€  ğ    superscript     superscript   ğ€  ğ   T    ğ€  ğ      1       \begin{bmatrix}\mathbf{A}^{T}\\
 \mathbf{B}^{T}\end{bmatrix}^{+}=[\mathbf{A},\mathbf{B}]([\mathbf{A},\mathbf{B}%
 ]^{T}[\mathbf{A},\mathbf{B}])^{-1}.   The pseudoinverse requires ( n + p )-square matrix inversion.  To reduce complexity and introduce parallelism, we derive the following decomposed formula. From a block matrix inverse     (     [  ğ€  ,  ğ  ]   T    [  ğ€  ,  ğ  ]    )    -  1      superscript     superscript   ğ€  ğ   T    ğ€  ğ      1     \mathbf{(}[\mathbf{A},\mathbf{B}]^{T}[\mathbf{A},\mathbf{B}])^{-1}   , we can have         [      ğ€  ,     ğ     ]   +   =    [    ğ  B  âŸ‚   ğ€    (    ğ€  T    ğ  B  âŸ‚   ğ€   )    -  1     ,    ğ  A  âŸ‚   ğ    (    ğ  T    ğ  A  âŸ‚   ğ   )    -  1     ]   T    ,       superscript    ğ€  ğ       superscript      superscript   subscript  ğ  B   perpendicular-to   ğ€   superscript     superscript  ğ€  T    superscript   subscript  ğ  B   perpendicular-to   ğ€     1        superscript   subscript  ğ  A   perpendicular-to   ğ   superscript     superscript  ğ  T    superscript   subscript  ğ  A   perpendicular-to   ğ     1      T     \begin{bmatrix}\mathbf{A},&\mathbf{B}\end{bmatrix}^{+}=\left[\mathbf{P}_{B}^{%
 \perp}\mathbf{A}(\mathbf{A}^{T}\mathbf{P}_{B}^{\perp}\mathbf{A})^{-1},\quad%
 \mathbf{P}_{A}^{\perp}\mathbf{B}(\mathbf{B}^{T}\mathbf{P}_{A}^{\perp}\mathbf{B%
 })^{-1}\right]^{T},            [      ğ€  T        ğ  T      ]   +   =   [    ğ  B  âŸ‚   ğ€    (    ğ€  T    ğ  B  âŸ‚   ğ€   )    -  1     ,    ğ  A  âŸ‚   ğ    (    ğ  T    ğ  A  âŸ‚   ğ   )    -  1     ]    ,       superscript     superscript  ğ€  T      superscript  ğ  T           superscript   subscript  ğ  B   perpendicular-to   ğ€   superscript     superscript  ğ€  T    superscript   subscript  ğ  B   perpendicular-to   ğ€     1        superscript   subscript  ğ  A   perpendicular-to   ğ   superscript     superscript  ğ  T    superscript   subscript  ğ  A   perpendicular-to   ğ     1        \begin{bmatrix}\mathbf{A}^{T}\\
 \mathbf{B}^{T}\end{bmatrix}^{+}=\left[\mathbf{P}_{B}^{\perp}\mathbf{A}(\mathbf%
 {A}^{T}\mathbf{P}_{B}^{\perp}\mathbf{A})^{-1},\quad\mathbf{P}_{A}^{\perp}%
 \mathbf{B}(\mathbf{B}^{T}\mathbf{P}_{A}^{\perp}\mathbf{B})^{-1}\right],   where orthogonal projection matrices are defined by         \begin{align} \mathbf P_A^\perp & = \mathbf I - \mathbf A (\mathbf A^T \mathbf A)^{-1} \mathbf A^T, \\ \mathbf P_B^\perp & = \mathbf I - \mathbf B (\mathbf B^T \mathbf B)^{-1} \mathbf B^T. \end{align}  Interestingly, from the idempotence of projection matrix, we can verify that the pseudoinverse of block matrix consists of pseudoinverse of projected matrices:         [      ğ€  ,     ğ     ]   +   =   [       (    ğ  B  âŸ‚   ğ€   )   +         (    ğ  A  âŸ‚   ğ   )   +      ]    ,       superscript    ğ€  ğ         superscript     superscript   subscript  ğ  B   perpendicular-to   ğ€        superscript     superscript   subscript  ğ  A   perpendicular-to   ğ         \begin{bmatrix}\mathbf{A},&\mathbf{B}\end{bmatrix}^{+}=\begin{bmatrix}(\mathbf%
 {P}_{B}^{\perp}\mathbf{A})^{+}\\
 (\mathbf{P}_{A}^{\perp}\mathbf{B})^{+}\end{bmatrix},            [      ğ€  T        ğ  T      ]   +   =   [    (    ğ€  T    ğ  B  âŸ‚    )   +   ,    (    ğ  T    ğ  A  âŸ‚    )   +   ]    .       superscript     superscript  ğ€  T      superscript  ğ  T         superscript     superscript  ğ€  T    superscript   subscript  ğ  B   perpendicular-to       superscript     superscript  ğ  T    superscript   subscript  ğ  A   perpendicular-to         \begin{bmatrix}\mathbf{A}^{T}\\
 \mathbf{B}^{T}\end{bmatrix}^{+}=[(\mathbf{A}^{T}\mathbf{P}_{B}^{\perp})^{+},%
 \quad(\mathbf{B}^{T}\mathbf{P}_{A}^{\perp})^{+}].     Thus, we decomposed the block matrix pseudoinverse into two submatrix pseudoinverses, which cost n - and p -square matrix inversions, respectively.  Note that the above formulae are not necessarily valid if    [  ğ€  ,  ğ  ]     ğ€  ğ    [\mathbf{A},\mathbf{B}]   does not have full rank â€“ for example, if    ğ€  â‰   0      ğ€  0    \mathbf{A}\neq 0   , then        [      ğ€  ,     ğ€     ]   +   =    1  2    [      ğ€  +        ğ€  +      ]    â‰    [       (    ğ  A  âŸ‚   ğ€   )   +         (    ğ  A  âŸ‚   ğ€   )   +      ]   =  0         superscript    ğ€  ğ€          1  2      superscript  ğ€       superscript  ğ€               superscript     superscript   subscript  ğ  A   perpendicular-to   ğ€        superscript     superscript   subscript  ğ  A   perpendicular-to   ğ€            0     \begin{bmatrix}\mathbf{A},&\mathbf{A}\end{bmatrix}^{+}=\frac{1}{2}\begin{%
 bmatrix}\mathbf{A}^{+}\\
 \mathbf{A}^{+}\end{bmatrix}\neq\begin{bmatrix}(\mathbf{P}_{A}^{\perp}\mathbf{A%
 })^{+}\\
 (\mathbf{P}_{A}^{\perp}\mathbf{A})^{+}\end{bmatrix}=0     Application to least squares problems  Given the same matrices as above, we consider the following least squares problems, which appear as multiple objective optimizations or constrained problems in signal processing. Eventually, we can implement a parallel algorithm for least squares based on the following results.  Column-wise partitioning in over-determined least squares  Suppose a solution    ğ±  =   [      ğ±  1        ğ±  2      ]       ğ±     subscript  ğ±  1      subscript  ğ±  2       \mathbf{x}=\begin{bmatrix}\mathbf{x}_{1}\\
 \mathbf{x}_{2}\\
 \end{bmatrix}   solves an over-determined system:          [      ğ€  ,     ğ     ]    [      ğ±  1        ğ±  2      ]    =  ğ   ,   ğ  âˆˆ    \reals    m  Ã—  1      .     formulae-sequence        ğ€  ğ       subscript  ğ±  1      subscript  ğ±  2      ğ     ğ   superscript  \reals    m  1       \begin{bmatrix}\mathbf{A},&\mathbf{B}\end{bmatrix}\begin{bmatrix}\mathbf{x}_{1%
 }\\
 \mathbf{x}_{2}\\
 \end{bmatrix}=\mathbf{d},\qquad\mathbf{d}\in\reals^{m\times 1}.     Using the block matrix pseudoinverse, we have       ğ±  =      [      ğ€  ,     ğ     ]   +    ğ   =    [       (    ğ  B  âŸ‚   ğ€   )   +         (    ğ  A  âŸ‚   ğ   )   +      ]   ğ    .        ğ±     superscript    ğ€  ğ      ğ             superscript     superscript   subscript  ğ  B   perpendicular-to   ğ€        superscript     superscript   subscript  ğ  A   perpendicular-to   ğ       ğ      \mathbf{x}=\begin{bmatrix}\mathbf{A},&\mathbf{B}\end{bmatrix}^{+}\,\mathbf{d}=%
 \begin{bmatrix}(\mathbf{P}_{B}^{\perp}\mathbf{A})^{+}\\
 (\mathbf{P}_{A}^{\perp}\mathbf{B})^{+}\end{bmatrix}\mathbf{d}.   Therefore, we have a decomposed solution:         ğ±  1   =      (    ğ  B  âŸ‚   ğ€   )   +    ğ    ,    ğ±  2   =      (    ğ  A  âŸ‚   ğ   )   +    ğ     .     formulae-sequence     subscript  ğ±  1      superscript     superscript   subscript  ğ  B   perpendicular-to   ğ€     ğ       subscript  ğ±  2      superscript     superscript   subscript  ğ  A   perpendicular-to   ğ     ğ      \mathbf{x}_{1}=(\mathbf{P}_{B}^{\perp}\mathbf{A})^{+}\,\mathbf{d},\qquad%
 \mathbf{x}_{2}=(\mathbf{P}_{A}^{\perp}\mathbf{B})^{+}\,\mathbf{d}.     Row-wise partitioning in under-determined least squares  Suppose a solution   ğ±   ğ±   \mathbf{x}   solves an under-determined system:          [      ğ€  T        ğ  T      ]   ğ±   =   [     ğ      ğŸ     ]    ,    ğ  âˆˆ    \reals    n  Ã—  1     ,   ğŸ  âˆˆ    \reals    p  Ã—  1       .     formulae-sequence         superscript  ğ€  T      superscript  ğ  T     ğ±     ğ    ğŸ      formulae-sequence    ğ   superscript  \reals    n  1       ğŸ   superscript  \reals    p  1        \begin{bmatrix}\mathbf{A}^{T}\\
 \mathbf{B}^{T}\end{bmatrix}\mathbf{x}=\begin{bmatrix}\mathbf{e}\\
 \mathbf{f}\end{bmatrix},\qquad\mathbf{e}\in\reals^{n\times 1},\qquad\mathbf{f}%
 \in\reals^{p\times 1}.     The minimum-norm solution is given by       ğ±  =      [      ğ€  T        ğ  T      ]   +     [     ğ      ğŸ     ]     .      ğ±     superscript     superscript  ğ€  T      superscript  ğ  T         ğ    ğŸ       \mathbf{x}=\begin{bmatrix}\mathbf{A}^{T}\\
 \mathbf{B}^{T}\end{bmatrix}^{+}\,\begin{bmatrix}\mathbf{e}\\
 \mathbf{f}\end{bmatrix}.     Using the block matrix pseudoinverse, we have       ğ±  =    [    (    ğ€  T    ğ  B  âŸ‚    )   +   ,    (    ğ  T    ğ  A  âŸ‚    )   +   ]    [     ğ      ğŸ     ]    =       (    ğ€  T    ğ  B  âŸ‚    )   +    ğ   +      (    ğ  T    ğ  A  âŸ‚    )   +    ğŸ     .        ğ±      superscript     superscript  ğ€  T    superscript   subscript  ğ  B   perpendicular-to       superscript     superscript  ğ  T    superscript   subscript  ğ  A   perpendicular-to         ğ    ğŸ               superscript     superscript  ğ€  T    superscript   subscript  ğ  B   perpendicular-to      ğ      superscript     superscript  ğ  T    superscript   subscript  ğ  A   perpendicular-to      ğŸ       \mathbf{x}=[(\mathbf{A}^{T}\mathbf{P}_{B}^{\perp})^{+},\quad(\mathbf{B}^{T}%
 \mathbf{P}_{A}^{\perp})^{+}]\begin{bmatrix}\mathbf{e}\\
 \mathbf{f}\end{bmatrix}=(\mathbf{A}^{T}\mathbf{P}_{B}^{\perp})^{+}\,\mathbf{e}%
 +(\mathbf{B}^{T}\mathbf{P}_{A}^{\perp})^{+}\,\mathbf{f}.     Comments on matrix inversion  Instead of     (     [  ğ€  ,  ğ  ]   T    [  ğ€  ,  ğ  ]    )    -  1      superscript     superscript   ğ€  ğ   T    ğ€  ğ      1     \mathbf{(}[\mathbf{A},\mathbf{B}]^{T}[\mathbf{A},\mathbf{B}])^{-1}   , we need to calculate directly or indirectly         (    ğ€  T   ğ€   )    -  1    ,    (    ğ  T   ğ   )    -  1    ,    (    ğ€  T    ğ  B  âŸ‚   ğ€   )    -  1    ,    (    ğ  T    ğ  A  âŸ‚   ğ   )    -  1     .      superscript     superscript  ğ€  T   ğ€     1     superscript     superscript  ğ  T   ğ     1     superscript     superscript  ğ€  T    superscript   subscript  ğ  B   perpendicular-to   ğ€     1     superscript     superscript  ğ  T    superscript   subscript  ğ  A   perpendicular-to   ğ     1      \quad(\mathbf{A}^{T}\mathbf{A})^{-1},\quad(\mathbf{B}^{T}\mathbf{B})^{-1},%
 \quad(\mathbf{A}^{T}\mathbf{P}_{B}^{\perp}\mathbf{A})^{-1},\quad(\mathbf{B}^{T%
 }\mathbf{P}_{A}^{\perp}\mathbf{B})^{-1}.     In a dense and small system, we can use singular value decomposition , QR decomposition , or Cholesky decomposition to replace the matrix inversions with numerical routines. In a large system, we may employ iterative methods such as Krylov subspace methods.  Considering parallel algorithms , we can compute     (    ğ€  T   ğ€   )    -  1      superscript     superscript  ğ€  T   ğ€     1     (\mathbf{A}^{T}\mathbf{A})^{-1}   and     (    ğ  T   ğ   )    -  1      superscript     superscript  ğ  T   ğ     1     (\mathbf{B}^{T}\mathbf{B})^{-1}   in parallel. Then, we finish to compute     (    ğ€  T    ğ  B  âŸ‚   ğ€   )    -  1      superscript     superscript  ğ€  T    superscript   subscript  ğ  B   perpendicular-to   ğ€     1     (\mathbf{A}^{T}\mathbf{P}_{B}^{\perp}\mathbf{A})^{-1}   and     (    ğ  T    ğ  A  âŸ‚   ğ   )    -  1      superscript     superscript  ğ  T    superscript   subscript  ğ  A   perpendicular-to   ğ     1     (\mathbf{B}^{T}\mathbf{P}_{A}^{\perp}\mathbf{B})^{-1}   also in parallel.  Block matrix inversion  Let a block matrix be       [     A    B      C    D     ]   .      A  B    C  D     \begin{bmatrix}A&B\\
 C&D\end{bmatrix}.   We can get an inverse formula by combining the previous results in. 1         [     A    B      C    D     ]    -  1    =   [       (   A  -   B   D   -  1    C    )    -  1       -    A   -  1    B    (   D  -   C   A   -  1    B    )    -  1           -    D   -  1    C    (   A  -   B   D   -  1    C    )    -  1          (   D  -   C   A   -  1    B    )    -  1       ]   =   [      S  D   -  1       -    A   -  1    B   S  A   -  1           -    D   -  1    C   S  D   -  1         S  A   -  1       ]    ,         superscript    A  B    C  D      1       superscript    A    B   superscript  D    1    C      1         superscript  A    1    B   superscript    D    C   superscript  A    1    B      1             superscript  D    1    C   superscript    A    B   superscript  D    1    C      1       superscript    D    C   superscript  A    1    B      1              subscript   superscript  S    1    D        superscript  A    1    B   subscript   superscript  S    1    A            superscript  D    1    C   subscript   superscript  S    1    D      subscript   superscript  S    1    A        \begin{bmatrix}A&B\\
 C&D\end{bmatrix}^{-1}=\begin{bmatrix}(A-BD^{-1}C)^{-1}&-A^{-1}B(D-CA^{-1}B)^{-%
 1}\\
 -D^{-1}C(A-BD^{-1}C)^{-1}&(D-CA^{-1}B)^{-1}\end{bmatrix}=\begin{bmatrix}S^{-1}%
 _{D}&-A^{-1}BS^{-1}_{A}\\
 -D^{-1}CS^{-1}_{D}&S^{-1}_{A}\end{bmatrix},   where    S  A     subscript  S  A    S_{A}   and    S  D     subscript  S  D    S_{D}   , respectively, Schur complements of   A   A   A   and   D   D   D   , are defined by     S  A   =   D  -   C   A   -  1    B         subscript  S  A     D    C   superscript  A    1    B      S_{A}=D-CA^{-1}B   , and     S  D   =   A  -   B   D   -  1    C         subscript  S  D     A    B   superscript  D    1    C      S_{D}=A-BD^{-1}C   . This relation is derived by using Block Triangular Decomposition. It is called simple block matrix inversion. 2  Now we can obtain the inverse of the symmetric block matrix:        [       ğ€  T   ğ€       ğ€  T   ğ         ğ  T   ğ€       ğ  T   ğ      ]    -  1    =   [       (     ğ€  T   ğ€   -    ğ€  T   ğ    (    ğ  T   ğ   )    -  1     ğ  T   ğ€    )    -  1       -     (    ğ€  T   ğ€   )    -  1     ğ€  T   ğ    (     ğ  T   ğ   -    ğ  T   ğ€    (    ğ€  T   ğ€   )    -  1     ğ€  T   ğ    )    -  1           -     (    ğ  T   ğ   )    -  1     ğ  T   ğ€    (     ğ€  T   ğ€   -    ğ€  T   ğ    (    ğ  T   ğ   )    -  1     ğ  T   ğ€    )    -  1          (     ğ  T   ğ   -    ğ  T   ğ€    (    ğ€  T   ğ€   )    -  1     ğ€  T   ğ    )    -  1       ]        superscript       superscript  ğ€  T   ğ€      superscript  ğ€  T   ğ        superscript  ğ  T   ğ€      superscript  ğ  T   ğ       1       superscript       superscript  ğ€  T   ğ€      superscript  ğ€  T   ğ   superscript     superscript  ğ  T   ğ     1     superscript  ğ  T   ğ€      1         superscript     superscript  ğ€  T   ğ€     1     superscript  ğ€  T   ğ   superscript       superscript  ğ  T   ğ      superscript  ğ  T   ğ€   superscript     superscript  ğ€  T   ğ€     1     superscript  ğ€  T   ğ      1             superscript     superscript  ğ  T   ğ     1     superscript  ğ  T   ğ€   superscript       superscript  ğ€  T   ğ€      superscript  ğ€  T   ğ   superscript     superscript  ğ  T   ğ     1     superscript  ğ  T   ğ€      1       superscript       superscript  ğ  T   ğ      superscript  ğ  T   ğ€   superscript     superscript  ğ€  T   ğ€     1     superscript  ğ€  T   ğ      1        \begin{bmatrix}\mathbf{A}^{T}\mathbf{A}&\mathbf{A}^{T}\mathbf{B}\\
 \mathbf{B}^{T}\mathbf{A}&\mathbf{B}^{T}\mathbf{B}\end{bmatrix}^{-1}=\begin{%
 bmatrix}(\mathbf{A}^{T}\mathbf{A}-\mathbf{A}^{T}\mathbf{B}(\mathbf{B}^{T}%
 \mathbf{B})^{-1}\mathbf{B}^{T}\mathbf{A})^{-1}&-(\mathbf{A}^{T}\mathbf{A})^{-1%
 }\mathbf{A}^{T}\mathbf{B}(\mathbf{B}^{T}\mathbf{B}-\mathbf{B}^{T}\mathbf{A}(%
 \mathbf{A}^{T}\mathbf{A})^{-1}\mathbf{A}^{T}\mathbf{B})^{-1}\\
 -(\mathbf{B}^{T}\mathbf{B})^{-1}\mathbf{B}^{T}\mathbf{A}(\mathbf{A}^{T}\mathbf%
 {A}-\mathbf{A}^{T}\mathbf{B}(\mathbf{B}^{T}\mathbf{B})^{-1}\mathbf{B}^{T}%
 \mathbf{A})^{-1}&(\mathbf{B}^{T}\mathbf{B}-\mathbf{B}^{T}\mathbf{A}(\mathbf{A}%
 ^{T}\mathbf{A})^{-1}\mathbf{A}^{T}\mathbf{B})^{-1}\end{bmatrix}            = \begin{bmatrix}  (\mathbfÂ A^TÂ \mathbfÂ P_B^\perpÂ \mathbfÂ A)^{-1}  &Â -(\mathbfÂ A^TÂ \mathbfÂ A)^{-1}\mathbfÂ A^TÂ \mathbfÂ B(\mathbfÂ B^TÂ \mathbfÂ P_A^\perpÂ \mathbfÂ B)^{-1}  \\  -(\mathbfÂ B^TÂ \mathbfÂ B)^{-1}\mathbfÂ B^TÂ \mathbfÂ A(\mathbfÂ A^TÂ \mathbfÂ P_B^\perpÂ \mathbfÂ A)^{-1}  &Â (\mathbfÂ B^TÂ \mathbfÂ P_A^{\perp}Â \mathbfÂ B)^{-1}  \end{bmatrix}  Since the block matrix is symmetric, we also have         [       ğ€  T   ğ€       ğ€  T   ğ         ğ  T   ğ€       ğ  T   ğ      ]    -  1    =   [       (    ğ€  T    ğ  B  âŸ‚   ğ€   )    -  1       -     (    ğ€  T    ğ  B  âŸ‚   ğ€   )    -  1     ğ€  T   ğ    (    ğ  T   ğ   )    -  1           -     (    ğ  T    ğ  A  âŸ‚   ğ   )    -  1     ğ  T   ğ€    (    ğ€  T   ğ€   )    -  1          (    ğ  T    ğ  A  âŸ‚   ğ   )    -  1       ]    .       superscript       superscript  ğ€  T   ğ€      superscript  ğ€  T   ğ        superscript  ğ  T   ğ€      superscript  ğ  T   ğ       1       superscript     superscript  ğ€  T    superscript   subscript  ğ  B   perpendicular-to   ğ€     1         superscript     superscript  ğ€  T    superscript   subscript  ğ  B   perpendicular-to   ğ€     1     superscript  ğ€  T   ğ   superscript     superscript  ğ  T   ğ     1             superscript     superscript  ğ  T    superscript   subscript  ğ  A   perpendicular-to   ğ     1     superscript  ğ  T   ğ€   superscript     superscript  ğ€  T   ğ€     1       superscript     superscript  ğ  T    superscript   subscript  ğ  A   perpendicular-to   ğ     1        \begin{bmatrix}\mathbf{A}^{T}\mathbf{A}&\mathbf{A}^{T}\mathbf{B}\\
 \mathbf{B}^{T}\mathbf{A}&\mathbf{B}^{T}\mathbf{B}\end{bmatrix}^{-1}=\begin{%
 bmatrix}(\mathbf{A}^{T}\mathbf{P}_{B}^{\perp}\mathbf{A})^{-1}&-(\mathbf{A}^{T}%
 \mathbf{P}_{B}^{\perp}\mathbf{A})^{-1}\mathbf{A}^{T}\mathbf{B}(\mathbf{B}^{T}%
 \mathbf{B})^{-1}\\
 -(\mathbf{B}^{T}\mathbf{P}_{A}^{\perp}\mathbf{B})^{-1}\mathbf{B}^{T}\mathbf{A}%
 (\mathbf{A}^{T}\mathbf{A})^{-1}&(\mathbf{B}^{T}\mathbf{P}_{A}^{\perp}\mathbf{B%
 })^{-1}\end{bmatrix}.     Then, we can see how the Schur complements are connected to the projection matrices of the symmetric, partitioned matrix.  See also   Invertible matrix#Blockwise inversion   References  External links   The Matrix Reference Manual by Mike Brookes  Linear Algebra Glossary by John Burkardt  The Matrix Cookbook by Kaare Brandt Petersen  Lecture 8: Least-norm solutions of undetermined equations by Stephen P. Boyd   "  Category:Numerical linear algebra  Category:Matrix theory     â†©  [ http://ieeexplore.ieee.org/xpls/abs_all.jsp?isnumber=30419&arnumber; ;=1399280&count;=249&index;=181 S. Jo, S. W. Kim and T. J. Park, "Equally constrained affine projection algorithm," in Conference Record of the Thirty-Eighth Asilomar Conference on Signals, Systems and Computers, vol. 1, pp. 955â€“959, Nov. 7â€“10, 2004.] â†©     