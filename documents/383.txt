   Stationary subspace analysis      Stationary subspace analysis   Stationary Subspace Analysis (SSA) 1 is a blind source separation  algorithm which factorizes a multivariate  time series into stationary and non-stationary components.  Introduction  In many settings, the measured time series contains contributions from various underlying sources that cannot be measured directly. For instance, in EEG analysis, the electrodes on the scalp record the activity of a large number of sources located inside the brain. 2 These sources can be stationary or non-stationary, but they are not discernible in the electrode signals, which are a mixture of these sources. SSA allows the separation of the stationary from the non-stationary sources in an observed time series.  According to the SSA model, 3 the observed multivariate time series    x   (  t  )       x  t    x(t)   is assumed to be generated as a linear superposition of stationary sources     s  𝔰    (  t  )        superscript  s  𝔰   t    s^{\mathfrak{s}}(t)   and non-stationary sources     s  𝔫    (  t  )        superscript  s  𝔫   t    s^{\mathfrak{n}}(t)   ,        x   (  t  )    =   A  s   (  t  )    =    [      A  𝔰      A  𝔫      ]    [       s  𝔰    (  t  )          s  𝔫    (  t  )       ]     ,          x  t     A  s  t             superscript  A  𝔰    superscript  A  𝔫          superscript  s  𝔰   t        superscript  s  𝔫   t         x(t)=As(t)=\begin{bmatrix}A^{\mathfrak{s}}&A^{\mathfrak{n}}\end{bmatrix}\begin%
 {bmatrix}s^{\mathfrak{s}}(t)\\
 s^{\mathfrak{n}}(t)\\
 \end{bmatrix},   where   A   A   A   is an unknown but time-constant mixing matrix;    A  𝔰     superscript  A  𝔰    A^{\mathfrak{s}}   and    A  𝔫     superscript  A  𝔫    A^{\mathfrak{n}}   are the basis of the stationary and non-stationary subspace respectively.  Given samples from the time series    x   (  t  )       x  t    x(t)   , the aim of Stationary Subspace Analysis is to estimate the inverse mixing matrix    A   -  1      superscript  A    1     A^{-1}   separating the stationary from non-stationary sources in the mixture    x   (  t  )       x  t    x(t)   .  Identifiability of the solution  The true stationary sources     s  𝔰    (  t  )        superscript  s  𝔰   t    s^{\mathfrak{s}}(t)   are identifiable (up to a linear transformation) and the true non-stationary subspace    A  𝔫     superscript  A  𝔫    A^{\mathfrak{n}}   is identifiable. The true non-stationary sources     s  𝔫    (  t  )        superscript  s  𝔫   t    s^{\mathfrak{n}}(t)   and the true stationary subspace    A  𝔰     superscript  A  𝔰    A^{\mathfrak{s}}   cannot be identified, because arbitrary contributions from the stationary sources do not change the non-stationary nature of a non-stationary source 4  Applications and extensions  Stationary subspace analysis has been successfully applied to Brain-computer interfacing , 5  computer vision 6 and temporal segmentation. There are variants of the SSA problem that can be solved analytically in closed form, without numerical optimization. 7  See also   Blind signal separation (BSS)  Factor analysis  Independent component analysis  Cointegration   References  "  Category:Multivariate time series analysis  Category:Signal processing  Category:Data analysis  Category:Statistical models  Category:Articles created via the Article Wizard     von Bünau P, Meinecke F C, Király F J, Müller K-R (2009). Finding Stationary Subspaces in Multivariate Time Series  Phys. Rev. Letter 103, 214101. ↩  Niedermeyer E, da Silva F L. Electroencephalography: Basic Principles, Clinical Applications, and Related Fields. Lippincott Williams & Wilkins, 2004. ISBN 0-7817-5126-8 ↩    von Bünau P, Meinecke F C, Scholler S, Müller K-R. Finding Stationary Brain Sources in EEG Data , IEEE EMBC 2010, Buenos Aires ↩  Meinecke F, von Bünau P, Kawanabe M, Müller K-R. "Learning Invariances with Stationary Subspace Analysis" , Proc. Subspace Workshop of the ICCV 2009, Kyoto ↩  Hara S, Kawahara Y, Washio T, von Bünau P. "Stationary Subspace Analysis as a Generalized Eigenvalue Problem"  Lecture Notes in Computer Science , 2010, Volume 6443/2010, 422-429 ↩     