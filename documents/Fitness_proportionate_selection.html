<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title offset="428">Fitness proportionate selection</title>
   <script type="text/javascript"
      src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js">
    </script>
</head>
<body>
<h1>Fitness proportionate selection</h1>
<style>
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
<style>
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
  </style>
</head>
<body>
<hr/>
<p> <strong>Fitness proportionate selection</strong>, also known as <strong>roulette wheel selection</strong>, is a <a href="genetic_operator" title="wikilink">genetic operator</a> used in <a href="genetic_algorithm" title="wikilink">genetic algorithms</a> for selecting potentially useful solutions for recombination.</p>
<p>In fitness proportionate selection, as in all selection methods, the <a href="fitness_function" title="wikilink">fitness function</a> assigns a fitness to possible solutions or <a href="chromosome" title="wikilink">chromosomes</a>. This fitness level is used to associate a <a class="uri" href="probability" title="wikilink">probability</a> of selection with each individual chromosome. If <span class="LaTeX">$f_i$</span> is the fitness of individual <span class="LaTeX">$i$</span> in the population, its probability of being selected is <span class="LaTeX">$p_i = \frac{f_i}{\Sigma_{j=1}^{N} f_j}$</span>, where <span class="LaTeX">$N$</span> is the number of individuals in the population.</p>
<p>This could be imagined similar to a Roulette wheel in a casino. Usually a proportion of the wheel is assigned to each of the possible selections based on their fitness value. This could be achieved by dividing the fitness of a selection by the total fitness of all the selections, thereby normalizing them to 1. Then a random selection is made similar to how the roulette wheel is rotated.</p>
<p>While candidate solutions with a higher fitness will be less likely to be eliminated, there is still a chance that they may be. Contrast this with a less sophisticated selection algorithm, such as <a href="truncation_selection" title="wikilink">truncation selection</a>, which will eliminate a fixed percentage of the weakest candidates. With fitness proportionate selection there is a chance some weaker solutions may survive the selection process; this is an advantage, as though a solution may be weak, it may include some component which could prove useful following the recombination process.</p>
<p>The analogy to a roulette wheel can be envisaged by imagining a roulette wheel in which each candidate solution represents a pocket on the wheel; the size of the pockets are proportionate to the probability of selection of the solution. Selecting N chromosomes from the population is equivalent to playing N games on the roulette wheel, as each candidate is drawn independently.</p>
<p>Other selection techniques, such as <a href="stochastic_universal_sampling" title="wikilink">stochastic universal sampling</a><a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a> or <a href="tournament_selection" title="wikilink">tournament selection</a>, are often used in practice. This is because they have less stochastic noise, or are fast, easy to implement and have a constant selection pressure [Blickle, 1996].</p>
<p>The naive implementation is carried out by first generating the <a href="Cumulative_probability_distribution_function" title="wikilink">cumulative probability distribution</a> (CDF) over the list of individuals using a probability proportional to the fitness of the individual. A <a href="uniform_distribution_(continuous)" title="wikilink">uniform random</a> number from the range [0,1) is chosen and the inverse of the CDF for that number gives an individual. This corresponds to the roulette ball falling in the bin of an individual with a probability proportional to its width. The "bin" corresponding to the inverse of the uniform random number can be found most quickly by using a <a href="Binary_search_algorithm" title="wikilink">binary search</a> over the elements of the CDF. It takes in the <a href="Big_O_notation" title="wikilink">O(log n)</a> time to choose an individual. A faster alternative that generates individuals in O(1) time will be to use the <a href="alias_method" title="wikilink">alias method</a>.</p>
<p>Recently, a very simple O(1) algorithm was introduced that is based on "stochastic acceptance".<a class="footnoteRef" href="#fn2" id="fnref2"><sup>2</sup></a> The algorithm randomly selects an individual (say <span class="LaTeX">$i$</span>) and accepts the selection with probability <span class="LaTeX">$f_i/f_M$</span>, where <span class="LaTeX">$f_M$</span> is the maximum fitness in the population.</p>
<h2 id="pseudocode">Pseudocode</h2>
<p>For example, if you have a population with fitnesses [1, 2, 3, 4], then the sum is 10 (1 + 2 + 3 + 4). Therefore, you would want the probabilities or chances to be [1/10, 2/10, 3/10, 4/10] or [0.1, 0.2, 0.3, 0.4]. If you were to visually normalize this between 0.0 and 1.0, it would be grouped like below with [red = 1/10, green = 2/10, blue = 3/10, black = 4/10]:</p>
<p><span style="color:red"><br/>
<code>0.1 ]</code></span></p>
<p><span style="color:green"></span></p>
<p><code>0.2 \</code><br/>
<code>0.3 /</code></p>
<p><span style="color:blue"></span></p>
<p><code>0.4 \</code><br/>
<code>0.5 |</code><br/>
<code>0.6 /</code></p>
<p><span style="color:black"></span></p>
<p><code>0.7 \</code><br/>
<code>0.8 |</code><br/>
<code>0.9 |</code><br/>
<code>1.0 /</code></p>
<p>Using the above example numbers, this is how to determine the probabilities:</p>
<p><code>sum_of_fitness = 10</code><br/>
<code>previous_probability = 0.0</code><br/>
<br/>
<code>[1] = previous_probability + (fitness / sum_of_fitness) = 0.0 + (1 / 10) = 0.1</code><br/>
<code>previous_probability = 0.1</code><br/>
<br/>
<code>[2] = previous_probability + (fitness / sum_of_fitness) = 0.1 + (2 / 10) = 0.3</code><br/>
<code>previous_probability = 0.3</code><br/>
<br/>
<code>[3] = previous_probability + (fitness / sum_of_fitness) = 0.3 + (3 / 10) = 0.6</code><br/>
<code>previous_probability = 0.6</code><br/>
<br/>
<code>[4] = previous_probability + (fitness / sum_of_fitness) = 0.6 + (4 / 10) = 1.0</code></p>
<p>The last index should always be 1.0 or close to it. Then this is how to randomly select an individual:</p>
<p><code>random_number # Between 0.0 and 1.0</code><br/>
<br/>
<code>if random_number </code></p>
<p>// Returns the selected index based on the weights(probabilities) int rouletteSelect(double[] weight) {</p>
<p><code>   // calculate the total weight</code><br/>
<code>   double weight_sum = 0;</code><br/>
<code>   for(int i=0; i<weight.length; *="" +="weight[i];" -="" 0.0="" 1.0="" 1;="" </code></p>
<h3 id="java---stochastic-acceptance-o1-version">Java - stochastic acceptance O(1) version</h3>
<div class="sourceCode"><pre class="sourceCode Java"><code class="sourceCode java"><span class="kw">public</span> <span class="kw">class</span> roulette {
    <span class="co">/* program n_select=1000 times selects one of n=4 elements with weights weight[i].</span>
<span class="co">     * Selections are summed up in counter[i]. For the weights as given in the example </span>
<span class="co">     * below one expects that elements 0,1,2 and 3 will be selected (on average) </span>
<span class="co">     * 200, 150, 600 and 50 times, respectively.  In good agreement with exemplary run.</span>
<span class="co">     */</span>
<span class="kw">public</span> <span class="dt">static</span> <span class="dt">void</span> <span class="fu">main</span>(String [] args) {
    <span class="dt">int</span> n=<span class="dv">4</span>;
    <span class="dt">double</span> [] weight = <span class="kw">new</span> <span class="dt">double</span> [n];
    weight[<span class="dv">0</span>]=<span class="fl">0.4</span>;
    weight[<span class="dv">1</span>]=<span class="fl">0.3</span>;
    weight[<span class="dv">2</span>]=<span class="fl">1.2</span>;
    weight[<span class="dv">3</span>]=<span class="fl">0.1</span>;
    <span class="dt">double</span> max_weight=<span class="fl">1.2</span>;
    <span class="dt">int</span>  [] counter = <span class="kw">new</span> <span class="dt">int</span>[n];
    <span class="dt">int</span> n_select=<span class="dv">1000</span>;
    <span class="dt">int</span> index=<span class="dv">0</span>;
    <span class="dt">boolean</span> notaccepted;
    <span class="kw">for</span> (<span class="dt">int</span> i=<span class="dv">0</span>; i<n_select; (<span class="dt">int</span>=<span class="st">""</span> (notaccepted){=<span class="st">""</span> counter[index]++;=<span class="st">""</span> <span class="kw">for</span>=<span class="st">""</span> i=<span class="st">"0;"</span> i++){=<span class="st">""</span> i<n;=<span class="st">""</span> <span class="kw">if</span>(math.<span class="fu">random</span>()<weight[index]=<span class="st">""</span> index=<span class="st">"(int)(n*Math.random());"</span> max_weight)=<span class="st">""</span> notaccepted=<span class="st">"true;"</span> ruby<span class="st">"="" system.out.println("</span>counter[<span class="st">"+i+"</span>]=<span class="st">"+counter[i]);</span>
    }
}
<span class="co">/* The program uses stochastic acceptance instead of linear (or binary) search. </span>
<span class="co"> * More on http://arxiv.org/abs/1109.3627</span>
<span class="co"> */</span>
}
# Exemplary output:
# counter[<span class="dv">0</span>]=<span class="dv">216</span>
# counter[<span class="dv">1</span>]=<span class="dv">135</span>
# counter[<span class="dv">2</span>]=<span class="dv">595</span>
# counter[<span class="dv">3</span>]=<span class="dv">54</span></code></pre></div>
<h3 id="ruby---linear-on-search">Ruby - linear O(n) search</h3>
<p><source lang=" while="" {notaccepted="false;}" }=""></p>
<ol>
<li>Normalizes an array that potentially contains negative numbers by shifting</li>
<li>all of them up to be positive (0 is left alone).</li>
<li></li>
<li>+pop_fit+ array of each individual's fitness in a population to normalize</li>
</ol>
<p>def norm_pop(pop_fit)</p>
<p><code> least_fit = pop_fit.min.abs + 1 # Absolute value so can shift up</code><br/>
<code>                                 # +1 so that it doesn't become 0</code><br/>
<code> </code><br/>
<code> pop_fit.map! do |f|</code><br/>
<code>   (f != 0) ? (f + least_fit) : f</code><br/>
<code> end</code><br/>
<code> </code><br/>
<code> return pop_fit</code></p>
<p>end</p>
<ol>
<li>Returns an array of each individual's probability between 0.0 and 1.0 fitted</li>
<li>onto an imaginary roulette wheel (or pie).</li>
<li></li>
<li>This will NOT work for negative fitness numbers, as a negative piece of a pie</li>
<li>(i.e., roulette wheel) does not make sense. Therefore, if you have negative</li>
<li>numbers, you will have to normalize the population first before using this.</li>
<li></li>
<li>+pop_fit+ array of each individual's fitness in the population</li>
<li>+is_high_fit+ true if high fitness is best or false if low fitness is best</li>
</ol>
<p>def get_probs(pop_fit,is_high_fit=true)</p>
<p><code> fit_sum  = 0.0 # Sum of each individual's fitness in the population</code><br/>
<code> prob_sum = 0.0 # You can think of this in 2 ways; either...</code><br/>
<code>                # 1) Current sum of each individual's probability in the</code><br/>
<code>                #    population</code><br/>
<code>                # or...</code><br/>
<code>                # 2) Last (most recently processed) individual's probability</code><br/>
<code>                #    in the population</code><br/>
<code> probs    = []</code><br/>
<code> best_fit = nil # Only used if is_high_fit is false</code></p>
<p><code> # Get fitness sum and best fitness</code><br/>
<code> pop_fit.each do |f|</code><br/>
<code>   fit_sum += f</code><br/>
<code>   </code><br/>
<code>   if best_fit == nil or f > best_fit</code><br/>
<code>     best_fit = f</code><br/>
<code>   end</code><br/>
<code> end</code><br/>
<code> </code><br/>
<code> puts "Best fitness: #{best_fit}"</code><br/>
<code> puts "Fitness sum:  #{fit_sum}"</code><br/>
<code> </code><br/>
<code> best_fit += 1 # So that we don't get best_fit-best_fit=0</code><br/>
<code> </code><br/>
<code> # Get probabilities</code><br/>
<code> pop_fit.each_index do |i|</code><br/>
<code>   f = pop_fit[i]</code><br/>
<code>   </code><br/>
<code>   if is_high_fit</code><br/>
<code>     probs[i] = prob_sum + (f / fit_sum)</code><br/>
<code>   else</code><br/>
<code>     probs[i] = (f != 0) ? (prob_sum + ((best_fit - f) / fit_sum)) : 0.0</code><br/>
<code>   end</code><br/>
<code>   </code><br/>
<code>   prob_sum = probs[i]</code><br/>
<code> end</code><br/>
<code> </code><br/>
<code> probs[probs.size - 1] = 1.0 # Ensure that the last individual is 1.0 due to</code><br/>
<code>                             #   decimal problems in computers (can be 0.99...)</code><br/>
<code> return probs</code></p>
<p>end</p>
<ol>
<li>Selects and returns a random index using an array of probabilities that were</li>
<li>created to mirror a roulette wheel type of selection.</li>
<li></li>
<li>+probs+ array of probabilities between 0.0 and 1.0 that total to 1.0</li>
</ol>
<p>def roulette_select(probs)</p>
<p><code> r = rand # Random number between 0.0 and 1.0</code><br/>
<code> </code><br/>
<code> probs.each_index do |i|</code><br/>
<code>   if r </code></p>
<h2 id="see-also">See also</h2>
<ul>
<li><a href="Stochastic_universal_sampling" title="wikilink">Stochastic universal sampling</a></li>
<li><a href="Tournament_selection" title="wikilink">Tournament selection</a></li>
<li><a href="Reward-based_selection" title="wikilink">Reward-based selection</a></li>
</ul>
<h2 id="external-links">External links</h2>
<ul>
<li><a href="http://www.cs.ucl.ac.uk/staff/W.Langdon/ftp/gp-code/GProc-1.8b.tar.gz">C implementation</a> (.tar.gz; see selector.cxx) WBL</li>
<li><a href="http://www.edc.ncl.ac.uk/highlight/rhjanuary2007g02.php/">Example on Roulette wheel selection</a></li>
<li><a href="http://www.staff.amu.edu.pl/~lipowski/roulette.html/">An outline of implementation of the O(1) version</a></li>
<li><a href="http://jbn.github.io/fast_proportional_selection/">Implementation and comparison of different versions (in Python)</a></li>
</ul>
<h2 id="references">References</h2>
<p>"</p>
<p><a href="Category:Genetic_algorithms" title="wikilink">Category:Genetic algorithms</a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1">Bäck, Thomas, <em>Evolutionary Algorithms in Theory and Practice</em> (1996), p. 120, Oxford Univ. Press<a href="#fnref1">↩</a></li>
<li id="fn2">A. Lipowski, Roulette-wheel selection via stochastic acceptance (arXiv:1109.3627)<a href="http://arxiv.org/abs/1109.3627">1</a><a href="#fnref2">↩</a></li>
</ol>
</section>
</body>
</html>
