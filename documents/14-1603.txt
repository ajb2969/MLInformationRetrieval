   Absorbing Markov chain      Absorbing Markov chain   In the mathematical theory of probability , an absorbing Markov chain is a Markov chain in which every state can reach an absorbing state. An absorbing state is a state that, once entered, cannot be left.  Like general Markov chains, there can be continuous-time absorbing Markov chains with an infinite state space. However, this article concentrates on the discrete-time discrete-state-space case.  Formal definition  A Markov chain is an absorbing chain if 1 2   there is at least one absorbing state and  it is possible to go from any state to at least one absorbing state in a finite number of steps.   In an absorbing Markov chain, a state that is not absorbing is called transient.  Canonical form  Let an absorbing Markov chain with transition matrix P have t transient states and r absorbing states. Then       P  =   (     Q    R      ùüé     I  r      )    ,      P    Q  R    0   subscript  I  r       P=\left(\begin{array}[]{cc}Q&R\\
 \mathbf{0}&I_{r}\end{array}\right),   where Q is a t -by- t matrix, R is a nonzero t -by- r matrix, 0 is an r -by- t zero matrix, and I r is the r -by- r identity matrix. Thus, Q describes the probability of transitioning from some transient state to another while R describes the probability of transitioning from some transient state to some absorbing state.  Fundamental matrix  A basic property about an absorbing Markov chain is the expected number of visits to a transient state j starting from a transient state i (before being absorbed). The probability of transitioning from i to j in exactly k steps is the ( i , j )-entry of Q k . Summing this for all k (from 0 to ‚àû) yields the fundamental matrix, denoted by N . It is easy to prove that       N  =    ‚àë   k  =  0   ‚àû    Q  k    =    (    I  t   -  Q   )    -  1     ,        N    superscript   subscript     k  0       superscript  Q  k          superscript     subscript  I  t   Q     1       N=\sum_{k=0}^{\infty}Q^{k}=(I_{t}-Q)^{-1},     where I t is the t -by- t identity matrix. The ( i , j ) entry of matrix N is the expected number of times the chain is in state j , given that the chain started in state i . With the matrix N in hand, other properties of the Markov chain are easy to obtain. 3  Variance on number of visits  The variance on the number of visits to a transient state j with starting at a transient state i (before being absorbed) is the ( i , j )-entry of the matrix        N  2   =    N   (    2   N  dg    -   I  t    )    -   N  sq     ,       subscript  N  2       N      2   subscript  N  dg     subscript  I  t      subscript  N  sq      N_{2}=N(2N_{\operatorname{dg}}-I_{t})-N_{\operatorname{sq}},   where N dg is the diagonal matrix with the same diagonal as N and N sq is the Hadamard product of N with itself (i.e. each entry of N is squared).  Expected number of steps  The expected number of steps before being absorbed when starting in transient state i is the i th entry of the vector       ùê≠  =   N  ùüè    ,      ùê≠    N  1     \mathbf{t}=N\mathbf{1},   where 1 is a length- t column vector whose entries are all 1.  Variance on number of steps  The variance on the number of steps before being absorbed when starting in transient state i is the i th entry of the vector         (    2  N   -   I  t    )   ùê≠   -   ùê≠  sq    ,            2  N    subscript  I  t    ùê≠    subscript  ùê≠  sq     (2N-I_{t})\mathbf{t}-\mathbf{t}_{\operatorname{sq}},   where t sq is the Hadamard product of t with itself (i.e. each entry of t is squared).  Transient probabilities  The probability of visiting transient state j when starting at a transient state i is the ( i , j )-entry of the matrix       H  =    (   N  -   I  t    )    N  dg   -  1      .      H      N   subscript  I  t     superscript   subscript  N  dg     1       H=(N-I_{t})N_{\operatorname{dg}}^{-1}.     Absorbing probabilities  Another property is the probability of being absorbed in the absorbing state j when starting from transient state i , which is the ( i , j )-entry of the matrix       B  =   N  R    .      B    N  R     B=NR.     Examples  String generation  Consider the process of repeatedly flipping a fair coin until the sequence (heads, tails, heads) appears. This process is modeled by an absorbing Markov chain with transition matrix       P  =   [      1  /  2      1  /  2     0    0      0     1  /  2      1  /  2     0       1  /  2     0    0     1  /  2       0    0    0    1     ]    .      P      1  2     1  2   0  0    0    1  2     1  2   0      1  2   0  0    1  2     0  0  0  1      P=\begin{bmatrix}1/2&1/2&0&0\\
 0&1/2&1/2&0\\
 1/2&0&0&1/2\\
 0&0&0&1\end{bmatrix}.   The first state represents the empty string , the second state the string "H", the third state the string "HT", and the fourth state the string "HTH". Although in reality, the coin flips cease after the string "HTH" is generated, the perspective of the absorbing Markov chain is that the process has transitioned into the absorbing state representing the string "HTH" and, therefore, cannot leave.  For this absorbing Markov chain, the fundamental matrix is       N  =    (   I  -  Q   )    -  1    =    (    [     1    0    0      0    1    0      0    0    1     ]   -   [      1  /  2      1  /  2     0      0     1  /  2      1  /  2        1  /  2     0    0     ]    )    -  1    =    [      1  /  2      -   1  /  2      0      0     1  /  2      -   1  /  2         -   1  /  2      0    1     ]    -  1    =   [     4    4    2      2    4    2      2    2    2     ]    .        N   superscript    I  Q     1          superscript      1  0  0    0  1  0    0  0  1        1  2     1  2   0    0    1  2     1  2       1  2   0  0       1          superscript      1  2       1  2    0    0    1  2       1  2          1  2    0  1      1           4  4  2    2  4  2    2  2  2       N=(I-Q)^{-1}=\left(\begin{bmatrix}1&0&0\\
 0&1&0\\
 0&0&1\end{bmatrix}-\begin{bmatrix}1/2&1/2&0\\
 0&1/2&1/2\\
 1/2&0&0\end{bmatrix}\right)^{-1}=\begin{bmatrix}1/2&-1/2&0\\
 0&1/2&-1/2\\
 -1/2&0&1\end{bmatrix}^{-1}=\begin{bmatrix}4&4&2\\
 2&4&2\\
 2&2&2\end{bmatrix}.     The expected number of steps starting from each of the transient states is       ùê≠  =   N  ùüè   =    [     4    4    2      2    4    2      2    2    2     ]    [     1      1      1     ]    =   [     10      8      6     ]    .        ùê≠    N  1            4  4  2    2  4  2    2  2  2      1    1    1            10    8    6       \mathbf{t}=N\mathbf{1}=\begin{bmatrix}4&4&2\\
 2&4&2\\
 2&2&2\end{bmatrix}\begin{bmatrix}1\\
 1\\
 1\end{bmatrix}=\begin{bmatrix}10\\
 8\\
 6\end{bmatrix}.   Therefore, the expected number of coin flips before observing the sequence (heads, tails, heads) is 10, the entry for the state representing the empty string.  Games of chance  Games based entirely on chance can be modeled by an absorbing Markov chain. A classic example of this is the ancient Indian board game Snakes and Ladders . The graph on the right 4 plots the probability mass in the lone absorbing state that represents the final square as the transition matrix is raised to larger and larger powers. To determine the expected number of turns to complete the game, compute the vector t as described above and examine t start , which is approximately 39.2.  See also   Discrete phase-type distribution  Absorbing set (random dynamical systems)   References  External links   Wolfram Demonstration Project: Absorbing Markov Chain  Monopoly as a Markov chain   "  Category:Markov processes  Category:Markov models       ‚Ü©  Based on the definition found in ‚Ü©     