   Quantum algorithm for linear systems of equations      Quantum algorithm for linear systems of equations   The quantum algorithm for linear systems of equations , designed by Aram Harrow, Avinatan Hassidim, and Seth Lloyd , is a quantum algorithm for solving linear systems formulated in 2009. The algorithm estimates the result of a scalar measurement on the solution vector to a given linear system of equations. 1  The algorithm is one of the main fundamental algorithms expected to provide an exponential speedup over their classical counterparts, along with Shor's factoring algorithm , Grover's search algorithm and quantum simulation . Provided the linear system is a sparse and has a low condition number    Œ∫   Œ∫   \kappa   , and that the user is interested in the result of a scalar measurement on the solution vector, instead of the values of the solution vector itself, then the algorithm has a runtime of    O   (    log   (  N  )     Œ∫  2    )       O      N    superscript  Œ∫  2      O(\log(N)\kappa^{2})   , where   N   N   N   is the number of variables in the linear system.. This offers an exponential speedup over the fastest classical algorithm, which runs in    O   (   N  Œ∫   )       O    N  Œ∫     O(N\kappa)   (or    O   (   N   Œ∫    )       O    N    Œ∫      O(N\sqrt{\kappa})   for positive semidefinite matrices).  An implementation of the quantum algorithm for linear systems of equations was first demonstrated in 2013 by Cai et al., Barz et al.and Pan et al. in parallel. The demonstrations consisted of simple linear equations on specially designed quantum devices. 2 3 4  Due to the prevalence of linear systems in virtually all areas of science and engineering, the quantum algorithm for linear systems of equations has the potential for widespread applicability. 5  Procedure  The problem we are trying to solve is: given a Hermitian    N  √ó  N      N  N    N\times N   matrix   A   A   A   and a unit vector    b  ‚Üí     normal-‚Üí  b    \overrightarrow{b}   , find the solution vector    x  ‚Üí     normal-‚Üí  x    \overrightarrow{x}   satisfying     A   x  ‚Üí    =   b  ‚Üí         A   normal-‚Üí  x     normal-‚Üí  b     A\overrightarrow{x}=\overrightarrow{b}   . This algorithm assumes that the user is not interested in the values of    x  ‚Üí     normal-‚Üí  x    \overrightarrow{x}   itself, but rather the result of applying some operator   M   M   M   onto x,    ‚ü®  x  |  M  |  x  ‚ü©     quantum-operator-product  x  M  x    \langle x|M|x\rangle   .  First, the algorithm represents the vector    b  ‚Üí     normal-‚Üí  b    \overrightarrow{b}   as a quantum state of the form:        |  b  ‚ü©   =    ‚àë   i   =  1    N     b  i    |  i  ‚ü©      .       ket  b     superscript   subscript     i    1     N      subscript  b  i    ket  i       |b\rangle=\sum_{i\mathop{=}1}^{N}b_{i}|i\rangle.     Next, Hamiltonian simulation techniques are used to apply the unitary operator    e   i  A  t      superscript  e    i  A  t     e^{iAt}   to    |  b  ‚ü©     ket  b    |b\rangle   for a superposition of different times   t   t   t   . The ability to decompose    |  b  ‚ü©     ket  b    |b\rangle   into the eigenbasis of   A   A   A   and to find the corresponding eigenvalues    Œª  j     subscript  Œª  j    \lambda_{j}   is facilitated by the use of quantum phase estimation .  The state of the system after this decomposition is approximately:        ‚àë   j   =  1    N     Œ≤  j    |   u  j   ‚ü©    |   Œª  j   ‚ü©     ,      superscript   subscript     j    1     N      subscript  Œ≤  j    ket   subscript  u  j     ket   subscript  Œª  j       \sum_{j\mathop{=}1}^{N}\beta_{j}|u_{j}\rangle|\lambda_{j}\rangle,     where    u  j     subscript  u  j    u_{j}   is the eigenvector basis of   A   A   A   , and     |  b  ‚ü©   =    ‚àë   j   =  1    N     Œ≤  j    |   u  j   ‚ü©          ket  b     superscript   subscript     j    1     N      subscript  Œ≤  j    ket   subscript  u  j        |b\rangle=\sum_{j\mathop{=}1}^{N}\beta_{j}|u_{j}\rangle   .  We would then like to perform the linear map taking    |   Œª  j   ‚ü©     ket   subscript  Œª  j     |\lambda_{j}\rangle   to    C   Œª  j   -  1     |   Œª  j   ‚ü©       C   subscript   superscript  Œª    1    j    ket   subscript  Œª  j      C\lambda^{-1}_{j}|\lambda_{j}\rangle   , where   C   C   C   is a normalizing constant. The linear mapping operation is not unitary and thus will require a number of repetitions as it has some probability of failing. After it succeeds, we uncompute the    |   Œª  j   ‚ü©     ket   subscript  Œª  j     |\lambda_{j}\rangle   register and are left with a state proportional to:         ‚àë   i   =  1    N     Œ≤  i    Œª  j   -  1     |   u  j   ‚ü©     =    A   -  1     |  b  ‚ü©    =   |  x  ‚ü©    ,          superscript   subscript     i    1     N      subscript  Œ≤  i    subscript   superscript  Œª    1    j    ket   subscript  u  j         superscript  A    1     ket  b          ket  x      \sum_{i\mathop{=}1}^{N}\beta_{i}\lambda^{-1}_{j}|u_{j}\rangle=A^{-1}|b\rangle=%
 |x\rangle,     Where    |  x  ‚ü©     ket  x    |x\rangle   is a quantum-mechanical representation of the desired solution vector x . To read out all components of x would require the procedure be repeated at least N times. However, it is often the case that one is not interested in   x   x   x   itself, but rather some expectation value of a linear operator M acting on x . By mapping M to a quantum-mechanical operator and performing the quantum measurement corresponding to M , we obtain an estimate of the expectation value    ‚ü®  x  |  M  |  x  ‚ü©     quantum-operator-product  x  M  x    \langle x|M|x\rangle   . This allows for a wide variety of features of the vector x to be extracted including normalization, weights in different parts of the state space, and moments without actually computing all the values of the solution vector x .  Explanation of the algorithm  Initialization  Firstly, the algorithm requires that the matrix   A   A   A   be Hermitian so that it can be converted into a unitary operator . In the case were   A   A   A   is not Hermitian, define       ùêÇ  =   [     0    A       A  t     0     ]    .      ùêÇ    0  A     superscript  A  t   0      \mathbf{C}=\begin{bmatrix}0&A\\
 A^{t}&0\end{bmatrix}.     As   C   C   C   is Hermitian, the algorithm can now be used to solve      C  y   =   [     b      0     ]    .        C  y     b    0      Cy=\begin{bmatrix}b\\
 0\end{bmatrix}.   to obtain    y  =   [     0      x     ]       y    0    x      y=\begin{bmatrix}0\\
 x\end{bmatrix}   .  Secondly, The algorithm requires an efficient procedure to prepare    |  b  ‚ü©     ket  b    |b\rangle   , the quantum representation of b. It is assumed that there exists some linear operator   B   B   B   that can take some arbitrary quantum state    |  initial  ‚ü©     ket  initial    |\mathrm{initial}\rangle   to    |  b  ‚ü©     ket  b    |b\rangle   efficiently or that this algorithm is a subroutine in a larger algorithm and is given    |  b  ‚ü©     ket  b    |b\rangle   as input. Any error in the preparation of state    |  b  ‚ü©     ket  b    |b\rangle   is ignored.  Finally, the algorithm assumes that the state    |   œà  0   ‚ü©     ket   subscript  œà  0     |\psi_{0}\rangle   can be prepared efficiently. Where       |   œà  0   ‚ü©   :=     2  /  T      ‚àë   œÑ   =  0     T  -  1      sin  œÄ    (     œÑ  +    1  2     T    )    |  œÑ  ‚ü©         assign   ket   subscript  œà  0          2  T      superscript   subscript     œÑ    0       T  1        œÄ       œÑ    1  2    T    ket  œÑ        |\psi_{0}\rangle:=\sqrt{2/T}\sum_{\tau\mathop{=}0}^{T-1}\sin\pi\left(\tfrac{%
 \tau+\tfrac{1}{2}}{T}\right)|\tau\rangle     for some large   T   T   T   . The coefficients of    |   œà  0   ‚ü©     ket   subscript  œà  0     |\psi_{0}\rangle   are chosen to minimize a certain quadratic loss function which induces error in the    U  invert     subscript  U  invert    U_{\mathrm{invert}}   subroutine described below.  Phase estimation  Phase estimation is used to transform the Hermitian matrix   A   A   A   into a unitary operator, which can then be applied at will. This is possible if A is s -sparse and efficiently row computable, meaning it has at most s nonzero entries per row and given a row index these entries can be computed in time¬†O( s ). Under these assumptions, quantum phase estimation allows     e  i   A  t       superscript  e  i   A  t    e^{i}At   to be simulated in time    O   (    log   (  N  )     s  2   t   )       O      N    superscript  s  2   t     O(\log(N)s^{2}t)   .  Uinvert subroutine  The key subroutine to the algorithm, denoted    U  invert     subscript  U  invert    U_{\mathrm{invert}}   , is defined as follows:  1. Prepare     |   œà  0   ‚ü©   C     superscript   ket   subscript  œà  0    C    |\psi_{0}\rangle^{C}   on register C  2. Apply the conditional Hamiltonian evolution (sum)  3. Apply the Fourier transform to the register C . Denote the resulting basis states with    |  k  ‚ü©     ket  k    |k\rangle   for k =¬†0,¬†..., T ‚àí¬†1. Define     Œª  k   :=    2  œÄ  k   /   t  0       assign   subscript  Œª  k       2  œÄ  k    subscript  t  0      \lambda_{k}:=2\pi k/t_{0}   .  4. Adjoin a three-dimensional register S in the state         |   h   (   Œª  k   )    ‚ü©   S   :=      1  -   f    (   Œª  k   )   2    -   g    (   Œª  k   )   2        |  nothing  ‚ü©   S    +   f   (   Œª  k   )     |  well  ‚ü©   S    +   g   (   Œª  k   )     |  ill  ‚ü©   S      ,     assign   superscript   ket    h   subscript  Œª  k     S           1    f   superscript   subscript  Œª  k   2      g   superscript   subscript  Œª  k   2       superscript   ket  nothing   S      f   subscript  Œª  k    superscript   ket  well   S      g   subscript  Œª  k    superscript   ket  ill   S       |h(\lambda_{k})\rangle^{S}:=\sqrt{1-f(\lambda_{k})^{2}-g(\lambda_{k})^{2}}|%
 \mathrm{nothing}\rangle^{S}+f(\lambda_{k})|\mathrm{well}\rangle^{S}+g(\lambda_%
 {k})|\mathrm{ill}\rangle^{S},     5. Reverse steps 1‚Äì3, uncomputing any garbage produced along the way.  where functions f , g , are filter functions. The states 'nothing', 'well' and 'ill' are used to instruct the loop body on how to proceed; 'nothing' indicates that the desired matrix inversion has not yet taken place, 'well' indicates that the inversion has taken place and the loop should halt, and 'ill' indicates that part of    |  b  ‚ü©     ket  b    |b\rangle   is in the ill-conditioned subspace of A and the algorithm will not be able to produce the desired inversion.  Main loop  The body of the algorithm follows the amplitude amplification procedure: starting with     U  invert   B   |  initial  ‚ü©        subscript  U  invert   B   ket  initial     U_{\mathrm{invert}}B|\mathrm{initial}\rangle   , the following operation is repeatedly applied:       U  invert   B   R  init    B  ‚Ä†    U  invert  ‚Ä†    R  succ        subscript  U  invert   B   subscript  R  init    superscript  B  normal-‚Ä†    subscript   superscript  U  normal-‚Ä†   invert    subscript  R  succ     U_{\mathrm{invert}}BR_{\mathrm{init}}B^{\dagger}U^{\dagger}_{\mathrm{invert}}R%
 _{\mathrm{succ}}     where        R  succ   =    I  2   -   2   |  well  ‚ü©     ‚ü®  well  |   2      ,       subscript  R  succ      superscript  I  2     2   ket  well    superscript   bra  well   2       R_{\mathrm{succ}}=I^{2}-2|\mathrm{well}\rangle\langle\mathrm{well}|^{2},     and        R  init   =    I  2   -   2   |  initial  ‚ü©    ‚ü®  initial  |      .       subscript  R  init      superscript  I  2     2   ket  initial    bra  initial       R_{\mathrm{init}}=I^{2}-2|\mathrm{initial}\rangle\langle\mathrm{initial}|.     After each repetition,   S   S   S   is measured and will produce a value of 'nothing', 'well', or 'ill' as described above. This loop is repeated until   S   S   S   is measured, which occurs with a probability   p   p   p   . Rather than repeating    1  p      1  p    \frac{1}{p}   times to minimize error, amplitude amplification is used to achieve the same error resilience using only    O   (   1   p    )       O    1    p      O\left(\frac{1}{\sqrt{p}}\right)   repetitions.  Scalar measurement  After successfully measuring 'well' on   S   S   S   the system will be in a state proportional to:         ‚àë   i   =  1    N     Œ≤  i    Œª  j   -  1     |   u  j   ‚ü©     =    A   -  1     |  b  ‚ü©    =   |  x  ‚ü©    .          superscript   subscript     i    1     N      subscript  Œ≤  i    subscript   superscript  Œª    1    j    ket   subscript  u  j         superscript  A    1     ket  b          ket  x      \sum_{i\mathop{=}1}^{N}\beta_{i}\lambda^{-1}_{j}|u_{j}\rangle=A^{-1}|b\rangle=%
 |x\rangle.     Finally, we perform the quantum-mechanical operator corresponding to M and obtain an estimate of the value of    ‚ü®  x  |  M  |  x  ‚ü©     quantum-operator-product  x  M  x    \langle x|M|x\rangle   .  Run time analysis  Classical efficiency  The best classical algorithm which produces the actual solution vector    x  ‚Üí     normal-‚Üí  x    \overrightarrow{x}   is Gaussian elimination , which runs in    O   (   N  3   )       O   superscript  N  3     O(N^{3})   time.  If A is s -sparse and positive semi-definite, then the Conjugate Gradient method can be used to find the solution vector    x  ‚Üí     normal-‚Üí  x    \overrightarrow{x}   can be found in    O   (   N  s  Œ∫   )       O    N  s  Œ∫     O(Ns\kappa)   time by minimizing the quadratic function     |    A   x  ‚Üí    -   b  ‚Üí    |   2     superscript        A   normal-‚Üí  x     normal-‚Üí  b     2    |A\overrightarrow{x}-\overrightarrow{b}|^{2}   .  When only a summary statistic of the solution vector    x  ‚Üí     normal-‚Üí  x    \overrightarrow{x}   is needed, as is the case for the quantum algorithm for linear systems of equations, a classical computer can find an estimate of      x  ‚Üí   ‚Ä†   M   x  ‚Üí        superscript   normal-‚Üí  x   normal-‚Ä†   M   normal-‚Üí  x     \overrightarrow{x}^{\dagger}M\overrightarrow{x}   in    O   (   N   Œ∫    )       O    N    Œ∫      O(N\sqrt{\kappa})   .  Quantum efficiency  The quantum algorithm for solving linear systems of equations originally proposed by Harrow et al. was shown to be    O   (    Œ∫  2    log  N    )       O     superscript  Œ∫  2     N      O(\kappa^{2}\log N)   . The runtime of this algorithm was subsequently improved to    O   (   Œ∫    log  3    Œ∫   log  N      )       O    Œ∫    superscript   3     Œ∫    N        O(\kappa\log^{3}\kappa\log N)   by Andris Ambainis. 6  Optimality  An important factor in the performance of the matrix inversion algorithm is the condition number of   A   A   A      Œ∫   Œ∫   \kappa   , which represents the ratio of   A   A   A   's largest and smallest eigenvalues. As the condition number increases, the ease with which the solution vector can be found using gradient descent methods such as the conjugate gradient method decreases, as   A   A   A   becomes closer to a matrix which cannot be inverted and the solution vector becomes less stable. This algorithm assumes that all elements of the matrix   A   A   A   lie between    1  Œ∫      1  Œ∫    \frac{1}{\kappa}   and 1, in which case the claimed run-time proportional to    Œ∫  2     superscript  Œ∫  2    \kappa^{2}   will be achieved. Therefore, the speedup over classical algorithms is increased further when   Œ∫   Œ∫   \kappa   is a    poly   (   log   (  N  )    )       poly    N     \mathrm{poly}(\log(N))   . 7  If the run-time of the algorithm were made poly-logarithmic in   Œ∫   Œ∫   \kappa   then problems solvable on n qubits could be solved in poly( n ) time, causing the complexity class BQP to be equal to PSPACE . 8  Error analysis  Performing the phase estimation, which is the dominant source of error, is done by simulating    e   i  A  t      superscript  e    i  A  t     e^{iAt}   . Assuming that   A   A   A   is s-sparse, this can be done with an error bounded by a constant   Œµ   Œµ   \varepsilon   , which will translate to the additive error achieved in the output state    |  x  ‚ü©     ket  x    |x\rangle   .  The phase estimation step errs by    O   (   1   t  0    )       O    1   subscript  t  0      O\left(\frac{1}{t_{0}}\right)   in estimating   Œª   Œª   \lambda   , which translates into a relative error of    O   (   1   Œª   t  0     )       O    1    Œª   subscript  t  0       O\left(\frac{1}{\lambda t_{0}}\right)   in    Œª   -  1      superscript  Œª    1     \lambda^{-1}   . If    Œª  ‚â•   1  /  Œ∫       Œª    1  Œ∫     \lambda\geq 1/\kappa   , taking     t  0   =   O   (   Œ∫  Œµ   )         subscript  t  0     O    Œ∫  Œµ      t_{0}=O(\kappa\varepsilon)   induces a final error of   Œµ   Œµ   \varepsilon   . This requires that the overall run-time efficiency be increased proportional to    O   (   1  Œµ   )       O    1  Œµ     O\left(\frac{1}{\varepsilon}\right)   to minimize error.  Experimental realization  While there does not yet exist a quantum computer that can truly offer a speedup over a classical computer, implementation of a "proof of concept" remains an important milestone in the development of a new quantum algorithm. Demonstrating the quantum algorithm for linear systems of equations remained a challenge for years after its proposal until 2013 when it was demonstrated by Cai et al., Barz et al. and Pan et al. in parallel.  Cai et al.  Published in Physical Review Letters 110, 230501 (2013), Cai et al. reported an experimental demonstration of the simplest meaningful instance of this algorithm, that is, solving 2*2 linear equations for various input vectors. The quantum circuit is optimized and compiled into a linear optical network with four photonic quantum bits (qubits) and four controlled logic gates, which is used to coherently implement every subroutine for this algorithm. For various input vectors, the quantum computer gives solutions for the linear equations with reasonably high precision, ranging from fidelities of 0.825 to 0.993.  Barz et al.  On February 5, 2013, Barz et al. demonstrated the quantum algorithm for linear systems of equations on a photonic quantum computing architecture. This implementation used two consecutive entangling gates on the same pair of polarization-encoded qubits. Two separately controlled NOT gates were realized where the successful operation of the first was heralded by a measurement of two ancillary photons. Barz et al. found that the fidelity in the obtained output state ranged from 64.7% to 98.1% due to the influence of higher-order emissions from spontaneous parametric down-conversion. 9  Pan et al.  On February 8, 2013 Pan et al. reported a proof-of-concept experimental demonstration of the quantum algorithm using a 4-qubit nuclear magnetic resonance quantum information processor. The implementation was tested using simple linear systems of only 2 variables. Across three experiments they obtain the solution vector with over 96% fidelity. 10  Applications  Quantum computers are devices that harness quantum mechanics to perform computations in ways that classical computers cannot. For certain problems, quantum algorithms supply exponential speedups over their classical counterparts, the most famous example being Shor's factoring algorithm. Few such exponential speedups are known, and those that are (such as the use of quantum computers to simulate other quantum systems) have so far found limited use outside the domain of quantum mechanics. This algorithm provides an exponentially faster method of estimating features of the solution of a set of linear equations, which is a problem ubiquitous in science an engineering, both on its own and as a subroutine in more complex problems.  Linear differential equation solving  Dominic Berry proposed a new algorithm for solving linear time dependent differential equations as an extension of the quantum algorithm for solving linear systems of equations. Berry provides an efficient algorithm for solving the full-time evolution under sparse linear differential equations on a quantum computer. 11  Least-squares fitting  Wiebe et al. provide a new quantum algorithm to determine the quality of a least-squares fit in which a continuous function is used to approximate a set of discrete points by extending the quantum algorithm for linear systems of equations. As the amount of discrete points increases, the time required to produce a least-squares fit using even a quantum computer running a quantum state tomography algorithm becomes very large. Wiebe et al. find that in many cases, their algorithm can efficiently find a concise approximation of the data points, eliminating the need for the higher-complexity tomography algorithm. 12  Machine learning and big data analysis  Machine learning is the study of systems that can identify trends in data. Tasks in machine learning frequently involve manipulating and classifying a large volume of data in high-dimensional vector spaces. The runtime of classical machine learning algorithms is limited by a polynomial dependence on both the volume of data and the dimensions of the space. Quantum computers are capable of manipulating high-dimensional vectors using tensor product spaces are thus the perfect platform for machine learning algorithms. 13  The quantum algorithm for linear systems of equations has been applied to a support vector machine, which is an optimized linear or non-linear binary classifier. A support vector machine can be used for supervised machine learning, in which training set of already classified data is available, or unsupervised machine learning, in which all data given to the system is unclassified. Rebentrost et al. show that a quantum support vector machine can be used for big data classification and achieve an exponential speedup over classical computers. 14  References  "  Category:Quantum algorithms  Category:Integer factorization algorithms  Category:Quantum information science  Category:Articles containing proofs     Quantum algorithm for solving linear systems of equations, by Harrow et al. . ‚Ü©  Experimental quantum computing to solve systems of linear equations by Cai et al. . ‚Ü©  Solving systems of linear equations on a quantum computer by Barz et al. . ‚Ü©  Experimental realization of quantum algorithm for solving linear systems of equations, by Pan et al. . ‚Ü©  Quantum Computer Runs The Most Practically Useful Quantum Algorithm, by Lu and Pan . ‚Ü©  [ http://arxiv.org/abs/1010.4458 Variable time amplitude amplification and a faster quantum algorithm for solving systems of linear equations by Adris Ambainis]. ‚Ü©  Quantum algorithm for solving linear systems of equations, by Harrow et al. . ‚Ü©  Quantum algorithm for solving linear systems of equations, by Harrow et al. . ‚Ü©  Solving systems of linear equations on a quantum computer, by Barz et al. . ‚Ü©  Experimental realization of quantum algorithm for solving linear systems of equations, by Pan et al. . ‚Ü©  [ http://arxiv.org/abs/1010.2745 High-order quantum algorithm for solving linear differential equations by Dominic Berry]. ‚Ü©  Quantum Data Fitting by Wiebe et al. . ‚Ü©  Quantum algorithms for supervised and unsupervised machine learning, by Lloyd et al. . ‚Ü©  Quantum support vector machine for big feature and big data classification, by Rebentrost et al. . ‚Ü©     