<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title offset="1207">Wolfe conditions</title>
   <script type="text/javascript"
      src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js">
    </script>
</head>
<body>
<h1>Wolfe conditions</h1>
<hr/>
<p>In the unconstrained <a href="optimization_(mathematics)" title="wikilink">minimization</a> problem, the <strong>Wolfe conditions</strong> are a set of inequalities for performing <strong>inexact</strong> <a href="line_search" title="wikilink">line search</a>, especially in <a href="quasi-Newton_methods" title="wikilink">quasi-Newton methods</a>, first published by Philip Wolfe in 1969.<a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a><a class="footnoteRef" href="#fn2" id="fnref2"><sup>2</sup></a></p>
<p>In these methods the idea is to find</p>
<dl>
<dd><dl>
<dd><span class="LaTeX">$\min_x f(\mathbf{x})$</span>
</dd>
</dl>
</dd>
</dl>
<p>for some <a href="smooth_function" title="wikilink">smooth</a> <span class="LaTeX">$f:\mathbb R^n\to\mathbb R$</span>. Each step often involves approximately solving the subproblem</p>
<dl>
<dd><dl>
<dd><span class="LaTeX">$\min_{\alpha} f(\mathbf{x}_k + \alpha \mathbf{p}_k)$</span>
</dd>
</dl>
</dd>
</dl>
<p>where <span class="LaTeX">$\mathbf{x}_k$</span> is the current best guess, <span class="LaTeX">$\mathbf{p}_k \in \mathbb R^n$</span> is a search direction, and <span class="LaTeX">$\alpha \in \mathbb R$</span> is the step length.</p>
<p>The inexact line searches provide an efficient way of computing an acceptable step length <span class="LaTeX">$\alpha$</span> that reduces the <a href="objective_function" title="wikilink">objective function</a> 'sufficiently', rather than minimizing the objective function over <span class="LaTeX">$\alpha\in\mathbb R^+$</span> exactly. A line search algorithm can use Wolfe conditions as a requirement for any guessed <span class="LaTeX">$\alpha$</span>, before finding a new search direction <span class="LaTeX">$\mathbf{p}_k$</span>.</p>
<h2 id="armijo-rule-and-curvature">Armijo rule and curvature</h2>
<p>Denote a univariate function <span class="LaTeX">$\phi$</span> restricted to the direction <span class="LaTeX">$\mathbf{p}_k$</span> as <span class="LaTeX">$\phi(\alpha)=f(\mathbf{x}_k+\alpha\mathbf{p}_k)$</span>. A step length <span class="LaTeX">$\alpha_k$</span> is said to satisfy the <em>Wolfe conditions</em> if the following two inequalities hold:</p>
<dl>
<dd>i) <span class="LaTeX">$f(\mathbf{x}_k+\alpha_k\mathbf{p}_k)\leq f(\mathbf{x}_k)+c_1\alpha_k\mathbf{p}_k^{\mathrm T}\nabla f(\mathbf{x}_k)$</span>,
</dd>
<dd>ii) <span class="LaTeX">$\mathbf{p}_k^{\mathrm T}\nabla f(\mathbf{x}_k+\alpha_k\mathbf{p}_k) \geq c_2\mathbf{p}_k^{\mathrm T}\nabla f(\mathbf{x}_k)$</span>,
</dd>
</dl>
<p>with <span class="LaTeX">$0<c_1<c_2<1< math="">. (In examining condition (ii), recall that to ensure that <math>\mathbf{p}_k$</span> is a descent direction, we have <span class="LaTeX">$\mathbf{p}_k^{\mathrm T}\nabla f(\mathbf{x}_k) < 0$</span>.)</p>
<p><span class="LaTeX">$c_1$</span> is usually chosen to be quite small while <span class="LaTeX">$c_2$</span> is much larger; Nocedal<a class="footnoteRef" href="#fn3" id="fnref3"><sup>3</sup></a> gives example values of <span class="LaTeX">$c_1=10^{-4}$</span> and <span class="LaTeX">$c_2=0.9$</span> for Newton or quasi-Newton methods and <span class="LaTeX">$c_2=0.1$</span> for the nonlinear <a href="conjugate_gradient_method" title="wikilink">conjugate gradient method</a>. Inequality i) is known as the <strong>Armijo rule</strong><a class="footnoteRef" href="#fn4" id="fnref4"><sup>4</sup></a> and ii) as the <strong>curvature condition</strong>; i) ensures that the step length <span class="LaTeX">$\alpha_k$</span> decreases <span class="LaTeX">$f$</span> 'sufficiently', and ii) ensures that the slope has been reduced sufficiently.</p>
<h2 id="strong-wolfe-condition-on-curvature">Strong Wolfe condition on curvature</h2>
<p>The Wolfe conditions, however, can result in a value for the step length that is not close to a minimizer of <span class="LaTeX">$\phi$</span>. If we modify the curvature condition to the following,</p>
<dl>
<dd>iia) <span class="LaTeX">$\big|\mathbf{p}_k^{\mathrm T}\nabla f(\mathbf{x}_k+\alpha_k\mathbf{p}_k)\big|\leq c_2\big|\mathbf{p}_k^{\mathrm T}\nabla f(\mathbf{x}_k)\big|$</span>
</dd>
</dl>
<p>then i) and iia) together form the so-called <strong>strong Wolfe conditions</strong>, and force <span class="LaTeX">$\alpha_k$</span> to lie close to a <a href="critical_point_(mathematics)" title="wikilink">critical point</a> of <span class="LaTeX">$\phi$</span>.</p>
<h2 id="rationale">Rationale</h2>
<p>The principal reason for imposing the Wolfe conditions in an optimization algorithm where <span class="LaTeX">$\mathbf{x}_{k+1} = \mathbf{x}_k + \alpha \mathbf{p}_k$</span> is to ensure convergence of the gradient to zero. In particular, if the cosine of the angle between <span class="LaTeX">$\mathbf{p}_k$</span> and the gradient,</p>
<dl>
<dd><dl>
<dd><span class="LaTeX">$\cos \theta_k = \frac {\nabla f(\mathbf{x}_k)^{\mathrm T}\mathbf{p}_k }{\| \nabla f(\mathbf{x}_k)\| \|\mathbf{p}_k\| }$</span>
</dd>
</dl>
</dd>
</dl>
<p>is bounded away from zero and the i) and ii) conditions hold, then <span class="LaTeX">$\nabla f(\mathbf{x}_k) \rightarrow 0$</span>.</p>
<p>An additional motivation, in the case of a <a href="quasi-Newton_method" title="wikilink">quasi-Newton method</a> is that if <span class="LaTeX">$\mathbf{p}_k = -B_k^{-1} \nabla f(\mathbf{x}_k)$</span>, where the matrix <span class="LaTeX">$B_k$</span> is updated by the <a class="uri" href="BFGS" title="wikilink">BFGS</a> or <a href="Davidon-Fletcher-Powell_formula" title="wikilink">DFP</a> formula, then if <span class="LaTeX">$B_k$</span> is positive definite ii) implies <span class="LaTeX">$B_{k+1}$</span> is also positive definite.</p>
<h2 id="references">References</h2>
<ul>
<li></li>
<li></li>
</ul>
<references>
</references>
<p>"</p>
<p><a href="Category:Mathematical_optimization" title="wikilink">Category:Mathematical optimization</a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1"><a href="#fnref1">↩</a></li>
<li id="fn2"><a href="#fnref2">↩</a></li>
<li id="fn3"><a href="#fnref3">↩</a></li>
<li id="fn4"><a href="#fnref4">↩</a></li>
</ol>
</section>
</body>
</html>
