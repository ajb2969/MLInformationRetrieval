<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title offset="1767">Draft:Apprentissage des intérêts</title>
   <script type="text/javascript"
      src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js">
    </script>
</head>
<body>
<h1>Draft:Apprentissage des intérêts</h1>
<hr/>
<p><strong>L'apprentissage des intérêts</strong> est un sous-domaine du <a href="machine_learning" title="wikilink">machine learning</a> dont le but est d'apprendre les modèles d'intérêts à partir de données caractérisant des préférences observées.<a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a> Pour le cas de l'<a href="apprentissage_supervisé" title="wikilink">apprentissage supervisé</a>, l'apprentissage des intérêts à partir d'un ensemble de produits étant plus ou moins appréciés par les consommateurs, l'intérêt du marchand étant de prédire un taux intérêts potentiels des acheteurs sur ses autres produits.</p>
<p>Alors le concept d'apprentissage des intérêts avait déjà vu le jour dans différents domaines tel qu'en <a class="uri" href="économie" title="wikilink">économie</a>,<a class="footnoteRef" href="#fn2" id="fnref2"><sup>2</sup></a> il s'agit d'un sujet relativement nouveau en recherche d'<a href="Intelligence_Artificielle" title="wikilink">Intelligence Artificielle</a>. PLusieurs groupes de travail ont abordé l'apprentissage des intérêts et sujets liés durant les années 2000 à 2010.<a class="footnoteRef" href="#fn3" id="fnref3"><sup>3</sup></a></p>
<h2 id="tasks">Tasks</h2>
<p>Le principal objectif de l'apprentissage des intérêts est de s’atteller aux problématiques pour l'"<a href="apprentissage_de_classements" title="wikilink">apprentissage de classements</a>" (ranking). A partir des types de données observées caractérisant les goûts et préférences, les auteurs du livre <em>Preference Learning</em>:<a class="footnoteRef" href="#fn4" id="fnref4"><sup>4</sup></a> distinguent pour cette tâche, 3 problématiques majeures.</p>
<h3 id="label-ranking">Label ranking</h3>
<p>In label ranking, the model has an instance space <span class="LaTeX">$X=\{x_i\}\,\!$</span> and a finite set of labels <span class="LaTeX">$Y=\{y_i|i=1,2,\cdots,k\}\,\!$</span>. The preference information is given in the form <span class="LaTeX">$y_i \succ_{x} y_j\,\!$</span> indicating instance <span class="LaTeX">$x\,\!$</span> shows preference in <span class="LaTeX">$y_i\,\!$</span> rather than <span class="LaTeX">$y_j\,\!$</span>. A set of preference information is used as training data in the model. The task of this model is to find a preference ranking among the labels for any instance.</p>
<p>It was observed some conventional <a href="Classification_in_machine_learning" title="wikilink">classification</a> problems can be generalized in the framework of label ranking problem:<a class="footnoteRef" href="#fn5" id="fnref5"><sup>5</sup></a> if a training instance <span class="LaTeX">$x\,\!$</span> is labeled as class <span class="LaTeX">$y_i\,\!$</span>, it implies that <span class="LaTeX">$\forall j \neq i, y_i \succ_{x} y_j\,\!$</span>. In <a href="Multi-label_classification" title="wikilink">multi-label</a> situation, <span class="LaTeX">$x\,\!$</span> is associated with a set of labels <span class="LaTeX">$L \subseteq Y\,\!$</span> and thus the model can extract a set of preference information <span class="LaTeX">$\{y_i \succ_{x} y_j | y_i \in L, y_j \in Y\backslash L\}\,\!$</span>. Training a preference model on this preference information and the classification result of an instance is just the corresponding top ranking label.</p>
<h3 id="instance-ranking">Instance ranking</h3>
<p>Instance ranking also has the instance space <span class="LaTeX">$X\,\!$</span> and label set <span class="LaTeX">$Y\,\!$</span>. In this task, labels are defined to have a fixed order <span class="LaTeX">$y_1 \succ y_2 \succ \cdots \succ y_k\,\!$</span> and each instance <span class="LaTeX">$x_l\,\!$</span> is associated with a label <span class="LaTeX">$y_l\,\!$</span>. Giving a set of instances as training data, the goal of this task is to find the ranking order for a new set of instances.</p>
<h3 id="object-ranking">Object ranking</h3>
<p>Object ranking is similar to instance ranking except that no labels are associated with instances. Given a set of pairwise preference information in the form <span class="LaTeX">$x_i \succ x_j\,\!$</span> and the model should find out a ranking order among instances.</p>
<h2 id="techniques">Techniques</h2>
<p>There are two practical representations of the preference information <span class="LaTeX">$A \succ B\,\!$</span>. One is assigning <span class="LaTeX">$A\,\!$</span> and <span class="LaTeX">$B\,\!$</span> with two real numbers <span class="LaTeX">$a\,\!$</span> and <span class="LaTeX">$b\,\!$</span> respectively such that <span class="LaTeX">$a > b\,\!$</span>. Another one is assigning a binary value <span class="LaTeX">$V(A,B) \in \{0,1\}\,\!$</span> for all pairs <span class="LaTeX">$(A,B)\,\!$</span> denoting whether <span class="LaTeX">$A \succ B\,\!$</span> or <span class="LaTeX">$B \succ A\,\!$</span>. Corresponding to these two different representations, there are two different techniques applied to the learning process.</p>
<h3 id="utility-function">Utility function</h3>
<p>If we can find a mapping from data to real numbers, ranking the data can be solved by ranking the real numbers. This mapping is called <a href="utility_function" title="wikilink">utility function</a>. For label ranking the mapping is a function <span class="LaTeX">$f: X \times Y \rightarrow \mathbb{R}\,\!$</span> such that <span class="LaTeX">$y_i \succ_x y_j \Rightarrow f(x,y_i) > f(x,y_j)\,\!$</span>. For instance ranking and object ranking, the mapping is a function <span class="LaTeX">$f: X \rightarrow \mathbb{R}\,\!$</span>.</p>
<p>Finding the utility function is a <a href="Regression_analysis" title="wikilink">regression</a> learning problem which is well developed in machine learning.</p>
<h3 id="preference-relations">Preference relations</h3>
<p>The binary representation of preference information is called preference relation. For each pair of alternatives (instances or labels), a binary predicate can be learned by conventional supervising learning approach. Fürnkranz, Johannes and Hüllermeier proposed this approach in label ranking problem.<a class="footnoteRef" href="#fn6" id="fnref6"><sup>6</sup></a> For object ranking, there is an early approach by Cohen et al.<a class="footnoteRef" href="#fn7" id="fnref7"><sup>7</sup></a></p>
<p>Using preference relations to predict the ranking will not be so intuitive. Since preference relation is not transitive, it implies that the solution of ranking satisfying those relations would sometimes be unreachable, or there could be more than one solution. A more common approach is to find a ranking solution which is maximally consistent with the preference relations. This approach is a natural extension of pairwise classification.<a class="footnoteRef" href="#fn8" id="fnref8"><sup>8</sup></a></p>
<h2 id="uses">Uses</h2>
<p>Preference learning can be used in ranking search results according to feedback of user preference. Given a query and a set of documents, a learning model is used to find the ranking of documents corresponding to the relevance with this query. More discussions on research in this field can be found in Tie-Yan Liu's survey paper.<a class="footnoteRef" href="#fn9" id="fnref9"><sup>9</sup></a></p>
<p>Another application of preference learning is <a href="recommender_systems" title="wikilink">recommender systems</a>.<a class="footnoteRef" href="#fn10" id="fnref10"><sup>10</sup></a> Online store may analyze customer's purchase record to learn a preference model and then recommend similar products to customers. Internet content providers can make use of user's ratings to provide more user preferred contents.</p>
<h2 id="see-also">See also</h2>
<ul>
<li><a href="Learning_to_rank" title="wikilink">Learning to rank</a></li>
</ul>
<h2 id="references">References</h2>
<p> <a class="footnoteRef" href="#fn11" id="fnref11"><sup>11</sup></a> <a class="footnoteRef" href="#fn12" id="fnref12"><sup>12</sup></a> <a class="footnoteRef" href="#fn13" id="fnref13"><sup>13</sup></a> <a class="footnoteRef" href="#fn14" id="fnref14"><sup>14</sup></a> <a class="footnoteRef" href="#fn15" id="fnref15"><sup>15</sup></a> <a class="footnoteRef" href="#fn16" id="fnref16"><sup>16</sup></a> <a class="footnoteRef" href="#fn17" id="fnref17"><sup>17</sup></a></p>
<p>}}</p>
<h2 id="external-links">External links</h2>
<ul>
<li><a href="http://www.preference-learning.org/">Preference Learning site</a></li>
</ul>
<p><a href=":Category:Information_retrieval" title="wikilink">:Category:Information retrieval</a> <a href=":Category:Machine_learning" title="wikilink">:Category:Machine learning</a>"</p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1"><a href="Mehryar_Mohri" title="wikilink">Mehryar Mohri</a>, Afshin Rostamizadeh, Ameet Talwalkar (2012) <em>Foundations of Machine Learning</em>, The MIT Press ISBN 9780262018258.<a href="#fnref1">↩</a></li>
<li id="fn2"></li>
<li id="fn3"></li>
<li id="fn4"></li>
<li id="fn5"></li>
<li id="fn6"></li>
<li id="fn7"></li>
<li id="fn8"></li>
<li id="fn9"></li>
<li id="fn10"></li>
<li id="fn11">{{ cite web |title = Preference learning workshops |url = <a class="uri" href="http://www.preference-learning.org/#Workshops">http://www.preference-learning.org/#Workshops</a> }}<a href="#fnref11">↩</a></li>
<li id="fn12">{{ cite book |last = Fürnkranz |first = Johannes |coauthors = Hüllermeier, Eyke |year = 2011 |title = Preference Learning |url = <a class="uri" href="http://books.google.com/books?id=nc3XcH9XSgYC">http://books.google.com/books?id=nc3XcH9XSgYC</a> |chapter = Preference Learning: An Introduction |chapterurl = <a class="uri" href="http://books.google.com/books?id=nc3XcH9XSgYC&pg">http://books.google.com/books?id=nc3XcH9XSgYC&pg</a>;=PA4 |publisher = Springer-Verlag New York, Inc. |pages = 3–8 |isbn = 978-3-642-14124-9 }}<a href="#fnref12">↩</a></li>
<li id="fn13">{{ cite journal |last = Har-peled |first = Sariel |coauthors = Roth, Dan; Zimak, Dav |year = 2003 |title = Constraint classification for multiclass classification and ranking |journal = In Proceedings of the 16th Annual Conference on Neural Information Processing Systems, NIPS-02 |pages = 785–792 }}<a href="#fnref13">↩</a></li>
<li id="fn14">{{ cite journal |last = Fürnkranz |first = Johannes |coauthors = Hüllermeier, Eyke |year = 2003 |title = Pairwise Preference Learning and Ranking |journal = Proceedings of the 14th European Conference on Machine Learning |pages = 145–156 }}<a href="#fnref14">↩</a></li>
<li id="fn15">{{ cite journal |last = Cohen |first = William W. |coauthors = Schapire, Robert E.; Singer, Yoram |year = 1998 |title = Learning to order things |url = <a class="uri" href="http://dl.acm.org/citation.cfm?id=302528.302736">http://dl.acm.org/citation.cfm?id=302528.302736</a> |journal = In Proceedings of the 1997 Conference on Advances in Neural Information Processing Systems |pages = 451–457 }}<a href="#fnref15">↩</a></li>
<li id="fn16">{{ cite journal |last = Liu |first = Tie-Yan |year = 2009 |title = Learning to Rank for Information Retrieval |url = <a class="uri" href="http://dl.acm.org/citation.cfm?id=1618303.1618304">http://dl.acm.org/citation.cfm?id=1618303.1618304</a> |journal = Foundations and Trends in Information Retrieval |volume = 3 |issue = 3 |pages = 225–331 |doi = 10.1561/1500000016 }}<a href="#fnref16">↩</a></li>
<li id="fn17">{{ cite journal |last = Gemmis |first = Marco De |author2=Iaquinta, Leo |author3=Lops, Pasquale |author4=Musto, Cataldo |author5=Narducci, Fedelucio |author6= Semeraro,Giovanni |year = 2009 |title = Preference Learning in Recommender Systems |url = <a class="uri" href="http://www.ecmlpkdd2009.net/wp-content/uploads/2008/09/preference-learning.pdf#page=45">http://www.ecmlpkdd2009.net/wp-content/uploads/2008/09/preference-learning.pdf#page=45</a> |journal = PREFERENCE LEARNING |volume = 41 |pages = 387–407 |doi=10.1007/978-3-642-14125-6_18 }}<a href="#fnref17">↩</a></li>
</ol>
</section>
</body>
</html>
