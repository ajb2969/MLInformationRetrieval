   Z-channel (information theory)      Z-channel (information theory)   A Z-channel is a communications channel used in coding theory and information theory to model the behaviour of some data storage systems.  Definition  A Z-channel (or a binary asymmetric channel ) is a channel with binary input and binary output where the crossover 1 â†’ 0 occurs with nonnegative probability p , whereas the crossover 0 â†’ 1 never occurs. In other words, if X and Y are the random variables describing the probability distributions of the input and the output of the channel, respectively, then the crossovers of the channel are characterized by the conditional probabilities   Prob{ Y = 0 | X = 0} = 1  Prob{ Y = 0 | X = 1} = p   Prob{ Y = 1 | X = 0} = 0  Prob{ Y = 1 | X = 1} = 1âˆ’ p    Capacity  The capacity     ð–¼ð–ºð—‰   (  â„¤  )       ð–¼ð–ºð—‰  â„¤    \mathsf{cap}(\mathbb{Z})   of the Z-channel   â„¤   â„¤   \mathbb{Z}   with the crossover 1 â†’ 0 probability p , when the input random variable X is distributed according to the Bernoulli distribution with probability Î± for the occurrence of 0, is calculated as follows.      ð–¼ð–ºð—‰   (  â„¤  )   =   max  Î±    {  ð–§   (  Y  )   -  ð–§   (  Y  âˆ£  X  )   }   =   max  Î±    {  ð–§   (  Y  )   -   âˆ‘   x  âˆˆ   {  0  ,  1  }     ð–§   (  Y  âˆ£  X  =  x  )   ð–¯ð—‹ð—ˆð–»   {  X  =  x  }   }      fragments  cap   fragments  normal-(  Z  normal-)     subscript   Î±    fragments  normal-{  H   fragments  normal-(  Y  normal-)    H   fragments  normal-(  Y  normal-âˆ£  X  normal-)   normal-}     subscript   Î±    fragments  normal-{  H   fragments  normal-(  Y  normal-)     subscript     x   0  1     H   fragments  normal-(  Y  normal-âˆ£  X   x  normal-)   Prob   fragments  normal-{  X   x  normal-}   normal-}     \mathsf{cap}(\mathbb{Z})=\max_{\alpha}\{\mathsf{H}(Y)-\mathsf{H}(Y\mid X)\}=%
 \max_{\alpha}\Bigl\{\mathsf{H}(Y)-\sum_{x\in\{0,1\}}\mathsf{H}(Y\mid X=x)%
 \mathsf{Prob}\{X=x\}\Bigr\}           =   max  Î±    {  ð–§   (   (  1  -  Î±  )    (  1  -  p  )   )   -  ð–§   (  Y  âˆ£  X  =  1  )   ð–¯ð—‹ð—ˆð–»   {  X  =  1  }   }      fragments    subscript   Î±    fragments  normal-{  H   fragments  normal-(   fragments  normal-(  1   Î±  normal-)    fragments  normal-(  1   p  normal-)   normal-)    H   fragments  normal-(  Y  normal-âˆ£  X   1  normal-)   Prob   fragments  normal-{  X   1  normal-}   normal-}     =\max_{\alpha}\{\mathsf{H}((1-\alpha)(1-p))-\mathsf{H}(Y\mid X=1)\mathsf{Prob}%
 \{X=1\}\}           =    max  Î±    {    ð–§   (    (   1  -  Î±   )    (   1  -  p   )    )    -    (   1  -  Î±   )   ð–§   (  p  )     }     ,      absent    subscript   Î±       ð–§      1  Î±     1  p         1  Î±   ð–§  p       =\max_{\alpha}\{\mathsf{H}((1-\alpha)(1-p))-(1-\alpha)\mathsf{H}(p)\},        where    ð–§   (  â‹…  )       ð–§  normal-â‹…    \mathsf{H}(\cdot)   is the binary entropy function .  The maximum is attained for       Î±  =   1  -   1    (   1  -  p   )    (   1  +   2    ð–§   (  p  )    /   (   1  -  p   )      )       ,      Î±    1    1      1  p     1   superscript  2      ð–§  p     1  p           \alpha=1-\frac{1}{(1-p)(1+2^{\mathsf{H}(p)/(1-p)})},   yielding the following value of    ð–¼ð–ºð—‰   (  â„¤  )       ð–¼ð–ºð—‰  â„¤    \mathsf{cap}(\mathbb{Z})   as a function of p        ð–¼ð–ºð—‰   (  â„¤  )    =    ð–§   (   1   1  +   2   ð—Œ   (  p  )       )    -    ð—Œ   (  p  )     1  +   2   ð—Œ   (  p  )        =    log  2    (   1  +   2   -   ð—Œ   (  p  )       )    =     log  2    (   1  +    (   1  -  p   )    p   p  /   (   1  -  p   )       )     where   ð—Œ   (  p  )    =    ð–§   (  p  )     1  -  p     .          ð–¼ð–ºð—‰  â„¤       ð–§    1    1   superscript  2    ð—Œ  p           ð—Œ  p     1   superscript  2    ð—Œ  p              subscript   2     1   superscript  2      ð—Œ  p                subscript   2     1      1  p    superscript  p    p    1  p        where  ð—Œ  p            ð–§  p     1  p       \mathsf{cap}(\mathbb{Z})=\mathsf{H}\left(\frac{1}{1+2^{\mathsf{s}(p)}}\right)-%
 \frac{\mathsf{s}(p)}{1+2^{\mathsf{s}(p)}}=\log_{2}(1{+}2^{-\mathsf{s}(p)})=%
 \log_{2}\left(1+(1-p)p^{p/(1-p)}\right)\;\textrm{ where }\;\mathsf{s}(p)=\frac%
 {\mathsf{H}(p)}{1-p}.     For small p , the capacity is approximated by       ð–¼ð–ºð—‰   (  â„¤  )    â‰ˆ   1  -   0.5  ð–§   (  p  )           ð–¼ð–ºð—‰  â„¤     1    0.5  ð–§  p      \mathsf{cap}(\mathbb{Z})\approx 1-0.5\mathsf{H}(p)\,   as compared to the capacity    1  -   ð–§   (  p  )        1    ð–§  p     1{-}\mathsf{H}(p)   of the binary symmetric channel with crossover probability p .  Bounds on the size of an asymmetric-error-correcting code  Define the following distance function     ð–½  A    (  ð±  ,  ð²  )        subscript  ð–½  A    ð±  ð²     \mathsf{d}_{A}(\mathbf{x},\mathbf{y})   on the words     ð±  ,  ð²   âˆˆ    {  0  ,  1  }   n        ð±  ð²    superscript   0  1   n     \mathbf{x},\mathbf{y}\in\{0,1\}^{n}   of length n transmitted via a Z-channel         ð–½  A    (  ð±  ,  ð²  )     =  â–³    max   {   |   {  i  âˆ£     x  i   =  0   ,    y  i   =  1    }   |   ,   |   {  i  âˆ£     x  i   =  1   ,    y  i   =  0    }   |   }     .      superscript   normal-â–³      subscript  ð–½  A    ð±  ð²         conditional-set  i   formulae-sequence     subscript  x  i   0      subscript  y  i   1         conditional-set  i   formulae-sequence     subscript  x  i   1      subscript  y  i   0         \mathsf{d}_{A}(\mathbf{x},\mathbf{y})\stackrel{\vartriangle}{=}\max\left\{\big%
 |\{i\mid x_{i}=0,y_{i}=1\}\big|,\big|\{i\mid x_{i}=1,y_{i}=0\}\big|\right\}.   Define the sphere     V  t    (  ð±  )        subscript  V  t   ð±    V_{t}(\mathbf{x})   of radius t around a word    ð±  âˆˆ    {  0  ,  1  }   n       ð±   superscript   0  1   n     \mathbf{x}\in\{0,1\}^{n}   of length n as the set of all the words at distance t or less from   ð±   ð±   \mathbf{x}   , in other words,         V  t    (  ð±  )    =   {   ð²  âˆˆ    {  0  ,  1  }   n    âˆ£     ð–½  A    (  ð±  ,  ð²  )    â‰¤  t   }    .         subscript  V  t   ð±    conditional-set    ð²   superscript   0  1   n         subscript  ð–½  A    ð±  ð²    t      V_{t}(\mathbf{x})=\{\mathbf{y}\in\{0,1\}^{n}\mid\mathsf{d}_{A}(\mathbf{x},%
 \mathbf{y})\leq t\}.   A code    ð’ž   ð’ž   \mathcal{C}   of length n is said to be t -asymmetric-error-correcting if for any two codewords    ðœ  â‰    ðœ  â€²   âˆˆ    {  0  ,  1  }   n         ðœ   superscript  ðœ  normal-â€²         superscript   0  1   n      \mathbf{c}\neq\mathbf{c}^{\prime}\in\{0,1\}^{n}   , one has       V  t    (  ðœ  )    âˆ©    V  t    (   ðœ  â€²   )     =  âˆ…           subscript  V  t   ðœ      subscript  V  t    superscript  ðœ  normal-â€²        V_{t}(\mathbf{c})\cap V_{t}(\mathbf{c}^{\prime})=\emptyset   . Denote by    M   (  n  ,  t  )       M   n  t     M(n,t)   the maximum number of codewords in a t -asymmetric-error-correcting code of length n .  The Varshamov bound . For n â‰¥1 and t â‰¥1,        M   (  n  ,  t  )    â‰¤    2   n  +  1      âˆ‘   j  =  0   t    (    (       âŒŠ   n  /  2   âŒ‹       j      )   +   (       âŒˆ   n  /  2   âŒ‰       j      )    )      .        M   n  t       superscript  2    n  1      superscript   subscript     j  0    t      binomial      n  2    j    binomial      n  2    j        M(n,t)\leq\frac{2^{n+1}}{\sum_{j=0}^{t}{\left({\left({{\lfloor n/2\rfloor}%
 \atop{j}}\right)}+{\left({{\lceil n/2\rceil}\atop{j}}\right)}\right)}}.     The constant-weight code bound . For n > 2t â‰¥ 2 , let the sequence B 0 , B 1 , ..., B n-2t-1 be defined as        B  0   =  2   ,    B  i   =    min   0  â‰¤  j  <  i     {    B  j   +   A   (    n  +  t  +  i   -  j  -  1   ,    2  t   +  2   ,   t  +  i   )     }        formulae-sequence     subscript  B  0   2      subscript  B  i     subscript       0  j       i        subscript  B  j     A       n  t  i   j  1       2  t   2     t  i          B_{0}=2,\quad B_{i}=\min_{0\leq j   for    i  >  0      i  0    i>0   . Then      M   (  n  ,  t  )    â‰¤   B   n  -   2  t   -  1     .        M   n  t     subscript  B    n    2  t   1      M(n,t)\leq B_{n-2t-1}.     References    Error correcting codes for the asymmetric channel, Technical Report 18â€“09â€“07â€“81, Department of Informatics, University of Bergen, Norway, 1981.   On the capacity and codes for the Z-channel, Proceedings of the IEEE International Symposium on Information Theory, Lausanne, Switzerland, 2002, p.Â 422.   "  Category:Coding theory  Category:Information theory  Category:Inequalities   