<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="1454">Chessboard detection</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>Chessboard detection</h1>
<style>
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
<style>
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
  </style>
</body></html>
<body>
<hr/>

<p>Chessboards arise frequently in <a href="computer_vision" title="wikilink">computer vision</a> theory and practice because their highly structured geometry is well-suited for algorithmic <a class="uri" href="detection" title="wikilink">detection</a> and processing. The appearance of chessboards in computer vision can be divided into two main areas: <a href="Camera_resectioning" title="wikilink">camera calibration</a> and <a href="Feature_(computer_vision)" title="wikilink">feature extraction</a>. This article provides a unified discussion of the role that chessboards play in the canonical methods from these two areas, including references to the seminal literature, examples, and pointers to software implementations.</p>
<h2 id="chessboard-camera-calibration">Chessboard camera calibration</h2>

<p>A classical problem in computer vision is <a href="3D_reconstruction_from_multiple_images" title="wikilink">three-dimensional (3D) reconstruction</a>, where one seeks to infer 3D structure about a scene from two-dimensional (2D) images of it.<a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a> Practical cameras are complex devices, and <a class="uri" href="photogrammetry" title="wikilink">photogrammetry</a> is needed to model the relationship between image sensor measurements and the 3D world. In the standard <a href="pinhole_camera_model" title="wikilink">pinhole camera model</a>, one models the relationship between world coordinates 

<math display="inline" id="Chessboard_detection:0">
 <semantics>
  <mi>ùêó</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>ùêó</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \mathbf{X}
  </annotation>
 </semantics>
</math>

 and image (pixel) coordinates 

<math display="inline" id="Chessboard_detection:1">
 <semantics>
  <mi>ùê±</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>ùê±</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \mathbf{x}
  </annotation>
 </semantics>
</math>

 via the <a href="3D_projection" title="wikilink">perspective transformation</a></p>

<p>

<math display="block" id="Chessboard_detection:2">
 <semantics>
  <mrow>
   <mi>ùê±</mi>
   <mo>=</mo>
   <mi>K</mi>
   <mrow>
    <mo>[</mo>
    <mtable displaystyle="true">
     <mtr>
      <mtd columnalign="center">
       <mi>R</mi>
      </mtd>
      <mtd columnalign="center">
       <mi>t</mi>
      </mtd>
     </mtr>
    </mtable>
    <mo>]</mo>
   </mrow>
   <mi>ùêó</mi>
   <mo rspace="12.5pt">,</mo>
   <mi>ùê±</mi>
   <mo>‚àà</mo>
   <msup>
    <mi>‚Ñô</mi>
    <mn>2</mn>
   </msup>
   <mo rspace="12.5pt">,</mo>
   <mi>ùêó</mi>
   <mo>‚àà</mo>
   <msup>
    <mi>‚Ñô</mi>
    <mn>3</mn>
   </msup>
   <mo>,</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <cerror>
    <csymbol cd="ambiguous">fragments</csymbol>
    <csymbol cd="unknown">x</csymbol>
    <eq></eq>
    <csymbol cd="unknown">K</csymbol>
    <matrix>
     <matrixrow>
      <ci>R</ci>
      <ci>t</ci>
     </matrixrow>
    </matrix>
    <csymbol cd="unknown">X</csymbol>
    <ci></ci>
    <ci>normal-,</ci>
    <csymbol cd="unknown">x</csymbol>
    <in></in>
    <apply>
     <csymbol cd="ambiguous">superscript</csymbol>
     <ci>‚Ñô</ci>
     <cn type="integer">2</cn>
    </apply>
    <ci></ci>
    <ci>normal-,</ci>
    <csymbol cd="unknown">X</csymbol>
    <in></in>
    <apply>
     <csymbol cd="ambiguous">superscript</csymbol>
     <ci>‚Ñô</ci>
     <cn type="integer">3</cn>
    </apply>
    <ci>normal-,</ci>
   </cerror>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \mathbf{x}=K\begin{bmatrix}R&t\end{bmatrix}\mathbf{X}\quad,\quad\mathbf{x}\in%
\mathbb{P}^{2}\quad,\quad\mathbf{X}\in\mathbb{P}^{3},
  </annotation>
 </semantics>
</math>

</p>

<p>where 

<math display="inline" id="Chessboard_detection:3">
 <semantics>
  <msup>
   <mi>‚Ñô</mi>
   <mi>n</mi>
  </msup>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">superscript</csymbol>
    <ci>‚Ñô</ci>
    <ci>n</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \mathbb{P}^{n}
  </annotation>
 </semantics>
</math>

 is the <a href="projective_space" title="wikilink">projective space</a> of dimension 

<math display="inline" id="Chessboard_detection:4">
 <semantics>
  <mi>n</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>n</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   n
  </annotation>
 </semantics>
</math>

.</p>

<p>In this setting, <a href="Camera_resectioning" title="wikilink">camera calibration</a> is the process of estimating the parameters of the 

<math display="inline" id="Chessboard_detection:5">
 <semantics>
  <mrow>
   <mn>3</mn>
   <mo>√ó</mo>
   <mn>4</mn>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <cn type="integer">3</cn>
    <cn type="integer">4</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   3\times 4
  </annotation>
 </semantics>
</math>

 matrix 

<math display="inline" id="Chessboard_detection:6">
 <semantics>
  <mrow>
   <mi>M</mi>
   <mo>=</mo>
   <mrow>
    <mi>K</mi>
    <mrow>
     <mo>[</mo>
     <mtable>
      <mtr>
       <mtd columnalign="center">
        <mi>R</mi>
       </mtd>
       <mtd columnalign="center">
        <mi>t</mi>
       </mtd>
      </mtr>
     </mtable>
     <mo>]</mo>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <ci>M</ci>
    <apply>
     <times></times>
     <ci>K</ci>
     <matrix>
      <matrixrow>
       <ci>R</ci>
       <ci>t</ci>
      </matrixrow>
     </matrix>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   M=K\begin{bmatrix}R&t\end{bmatrix}
  </annotation>
 </semantics>
</math>

 of the perspective model. Camera calibration is an important step in the computer vision pipeline because many subsequent algorithms require knowledge of camera parameters as input.<a class="footnoteRef" href="#fn2" id="fnref2"><sup>2</sup></a> Chessboards are often used during camera calibration because they are simple to construct, and their planar grid structure defines many natural <a href="Interest_point_detection" title="wikilink">interest points</a> in an image. The following two methods are classic calibration techniques that often employ chessboards.</p>
<h3 id="direct-linear-transformation">Direct linear transformation</h3>

<p>Direct linear transformation (DLT) calibration uses correspondences between world points and camera image points to estimate camera parameters. In particular, DLT calibration exploits the fact that the perspective pinhole camera model defines a set of similarity relations that can be solved via the <a href="direct_linear_transformation" title="wikilink">direct linear transformation</a> algorithm.<a class="footnoteRef" href="#fn3" id="fnref3"><sup>3</sup></a> To employ this approach, one requires accurate coordinates of a non-degenerate set of points in 3D space. A common way to achieve this is to construct a camera calibration rig (example below) built from three mutually perpendicular chessboards. Since the corners of each square are equidistant, it is straightforward to compute the 3D coordinates of each corner given the width of each square. The advantage of DLT calibration is its simplicity; arbitrary cameras can be calibrated by solving a single <a href="System_of_linear_equations#Homogeneous_systems" title="wikilink">homogeneous linear system</a>. However, the practical use of DLT calibration is limited by the necessity of a 3D calibration rig and the fact that extremely accurate 3D coordinates are required to avoid <a href="Numerical_stability" title="wikilink">numerical instability</a>.<a class="footnoteRef" href="#fn4" id="fnref4"><sup>4</sup></a></p>
<h3 id="multiplane-calibration">Multiplane calibration</h3>

<p>Multiplane calibration is a variant of <a href="camera_auto-calibration" title="wikilink">camera auto-calibration</a> that allows one to compute the parameters of a camera from two or more views of a planar surface. The seminal work in multiplane calibration is due to Zhang.<a class="footnoteRef" href="#fn5" id="fnref5"><sup>5</sup></a> <a href="Camera_resectioning#Zhang.27s_method" title="wikilink">Zhang's method</a> calibrates cameras by solving a particular <a href="System_of_linear_equations#Homogeneous_systems" title="wikilink">homogeneous linear system</a> that captures the homographic relationships between multiple perspective views of the same plane. This multiview approach is popular because, in practice, it is more natural to capture multiple views of a single planar surface - like a chessboard - than to construct a precise 3D calibration rig, as required by DLT calibration. The following figures demonstrate a practical application of multiplane camera calibration from multiple views of a chessboard.<a class="footnoteRef" href="#fn6" id="fnref6"><sup>6</sup></a></p>
<h2 id="chessboard-feature-extraction">Chessboard feature extraction</h2>

<p>The second context in which chessboards arise in computer vision is to demonstrate several canonical <a href="feature_extraction" title="wikilink">feature extraction</a> algorithms. In <a href="feature_extraction" title="wikilink">feature extraction</a>, one seeks to identify image <a href="Interest_point_detection" title="wikilink">interest points</a>, which summarize the semantic content of an image and, hence, offer a <a href="Dimensionality_reduction" title="wikilink">reduced dimensionality</a> representation of one's data.<a class="footnoteRef" href="#fn7" id="fnref7"><sup>7</sup></a> Chessboards - in particular - are often used to demonstrate feature extraction algorithms because their regular geometry naturally exhibits local image features like edges, lines, and corners. The following sections demonstrate the application of common feature extraction algorithms to a <a href=":Image:Perspective_chessboard.png" title="wikilink">chessboard image</a>.</p>
<h3 id="corners">Corners</h3>

<p>Corners are a natural local image feature exploited in many computer vision systems. Loosely speaking, one can define a <em>corner</em> as the intersection of two edges. A variety of <a href="corner_detection" title="wikilink">corner detection</a> algorithms exist that formalize this notion into concrete algorithms. Corners are a useful image feature because they are necessarily distinct from their neighboring pixels. The <a href="Corner_detection#The_Harris_.26_Stephens_.2F_Plessey_.2F_Shi.E2.80.93Tomasi_corner_detection_algorithm" title="wikilink">Harris corner detector</a> is a standard algorithm for corner detection in computer vision.<a class="footnoteRef" href="#fn8" id="fnref8"><sup>8</sup></a> The algorithm works by analyzing the <a href="Eigenvalues_and_eigenvectors" title="wikilink">eigenvalues</a> of the 2D discrete <a href="structure_tensor" title="wikilink">structure tensor</a> matrix at each image pixel and flagging a pixel as a corner when the eigenvalues of its structure tensor are sufficiently large. Intuitively, the eigenvalues of the structure tensor matrix associated with a given pixel describe the gradient strength in a neighborhood of that pixel. As such, a structure tensor matrix with large eigenvalues corresponds to an image neighborhood with large gradients in orthogonal directions - <em>i.e.,</em> a corner.</p>

<p>A chessboard contains natural corners at the boundaries between board squares, so one would expect corner detection algorithms to successfully detect them in practice. Indeed, the following figure demonstrates Harris corner detection applied to a perspective-transformed <a href=":Image:Perspective_chessboard.png" title="wikilink">chessboard image</a>. Clearly, the Harris detector is able to accurately detect the corners of the board.</p>

<p>The following <a class="uri" href="MATLAB" title="wikilink">MATLAB</a> code generates the above image using the <a href="http://www.mathworks.com/products/image/">Image Processing Toolbox</a>:</p>
<div class="sourceCode"><pre class="sourceCode matlab"><code class="sourceCode matlab"><span class="co">% Load image</span>
I = imread(<span class="st">'Perspective_chessboard.png'</span>);

<span class="co">% Detect corners</span>
C = corner(I,<span class="st">'Harris'</span>);

<span class="co">%--------------------------------------------------------------------------</span>
<span class="co">% Display results</span>
<span class="co">%--------------------------------------------------------------------------</span>
<span class="co">% Original image</span>
figure; imshow(I);

<span class="co">% Detected corners</span>

figure; imshow(I); hold on;
plot(C(:,<span class="fl">1</span>),C(:,<span class="fl">2</span>),<span class="st">'ro'</span>);
<span class="co">%--------------------------------------------------------------------------</span></code></pre></div>
<h3 id="lines">Lines</h3>

<p>Lines are another natural local <a href="Feature_(computer_vision)" title="wikilink">image feature</a> exploited in many computer vision systems. Geometrically, the set of all lines in a 2D image can be parametrized by <a href="Polar_coordinate_system" title="wikilink">polar coordinates</a> 

<math display="inline" id="Chessboard_detection:7">
 <semantics>
  <mrow>
   <mo stretchy="false">(</mo>
   <mi>œÅ</mi>
   <mo>,</mo>
   <mi>Œ∏</mi>
   <mo stretchy="false">)</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <interval closure="open">
    <ci>œÅ</ci>
    <ci>Œ∏</ci>
   </interval>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   (\rho,\theta)
  </annotation>
 </semantics>
</math>

 describing the distance and angle, respectively, of their <a href="Normal_(geometry)" title="wikilink">normal vectors</a> with respect to the origin. The discrete <a href="Hough_transform" title="wikilink">Hough transform</a> exploits this idea by transforming a spatial image into a matrix in 

<math display="inline" id="Chessboard_detection:8">
 <semantics>
  <mrow>
   <mo stretchy="false">(</mo>
   <mi>œÅ</mi>
   <mo>,</mo>
   <mi>Œ∏</mi>
   <mo stretchy="false">)</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <interval closure="open">
    <ci>œÅ</ci>
    <ci>Œ∏</ci>
   </interval>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   (\rho,\theta)
  </annotation>
 </semantics>
</math>

-space whose 

<math display="inline" id="Chessboard_detection:9">
 <semantics>
  <mrow>
   <mo stretchy="false">(</mo>
   <mi>i</mi>
   <mo>,</mo>
   <mi>j</mi>
   <mo stretchy="false">)</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <interval closure="open">
    <ci>i</ci>
    <ci>j</ci>
   </interval>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   (i,j)
  </annotation>
 </semantics>
</math>

-th entry counts the number of image edge points that lie on the line parametrized by 

<math display="inline" id="Chessboard_detection:10">
 <semantics>
  <mrow>
   <mo stretchy="false">(</mo>
   <msub>
    <mi>œÅ</mi>
    <mi>i</mi>
   </msub>
   <mo>,</mo>
   <msub>
    <mi>Œ∏</mi>
    <mi>j</mi>
   </msub>
   <mo stretchy="false">)</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <interval closure="open">
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>œÅ</ci>
     <ci>i</ci>
    </apply>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>Œ∏</ci>
     <ci>j</ci>
    </apply>
   </interval>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   (\rho_{i},\theta_{j})
  </annotation>
 </semantics>
</math>

.<a class="footnoteRef" href="#fn9" id="fnref9"><sup>9</sup></a><a class="footnoteRef" href="#fn10" id="fnref10"><sup>10</sup></a><a class="footnoteRef" href="#fn11" id="fnref11"><sup>11</sup></a> As such, one can detect lines in an image by simply searching for <a href="Maxima_and_minima" title="wikilink">local maxima</a> of its discrete Hough transform.</p>

<p>The grid structure of a chessboard naturally defines two sets of parallel lines in an image of it. Therefore, one expects that line detection algorithms should successfully detect these lines in practice. Indeed, the following figure demonstrates Hough transform-based line detection applied to a perspective-transformed <a href=":Image:Perspective_chessboard.png" title="wikilink">chessboard image</a>. Clearly, the Hough transform is able to accurately detect the lines induced by the board squares.</p>

<p>The following <a class="uri" href="MATLAB" title="wikilink">MATLAB</a> code generates the above images using the <a href="http://www.mathworks.com/products/image/">Image Processing Toolbox</a>:</p>
<div class="sourceCode"><pre class="sourceCode matlab"><code class="sourceCode matlab"><span class="co">% Load image</span>
I = imread(<span class="st">'Perspective_chessboard.png'</span>);

<span class="co">% Compute edge image</span>
BW = edge(I,<span class="st">'canny'</span>);

<span class="co">% Compute Hough transform</span>
[H theta rho] = hough(BW);

<span class="co">% Find local maxima of Hough transform</span>
numpeaks = <span class="fl">19</span>;
thresh = ceil(<span class="fl">0.1</span> * max(H(:)));
P = houghpeaks(H,numpeaks,<span class="st">'threshold'</span>,thresh);

<span class="co">% Extract image lines</span>
lines = houghlines(BW,theta,rho,P,<span class="st">'FillGap'</span>,<span class="fl">50</span>,<span class="st">'MinLength'</span>,<span class="fl">60</span>);

<span class="co">%--------------------------------------------------------------------------</span>
<span class="co">% Display results</span>
<span class="co">%--------------------------------------------------------------------------</span>
<span class="co">% Original image</span>
figure; imshow(I);

<span class="co">% Edge image</span>
figure; imshow(BW);

<span class="co">% Hough transform</span>
figure; image(theta,rho,imadjust(mat2gray(H)),<span class="st">'CDataMapping'</span>,<span class="st">'scaled'</span>);
hold on; colormap(gray(<span class="fl">256</span>));
plot(theta(P(:,<span class="fl">2</span>)),rho(P(:,<span class="fl">1</span>)),<span class="st">'o'</span>,<span class="st">'color'</span>,<span class="st">'r'</span>);

<span class="co">% Detected lines</span>
figure; imshow(I); hold on; n = size(I,<span class="fl">2</span>);
for k = <span class="fl">1</span>:length(lines)
    <span class="co">% Overlay kth line</span>
    x = [lines(k).point1(<span class="fl">1</span>) lines(k).point2(<span class="fl">1</span>)];
    y = [lines(k).point1(<span class="fl">2</span>) lines(k).point2(<span class="fl">2</span>)];
    line = @(z) ((y(<span class="fl">2</span>) - y(<span class="fl">1</span>)) / (x(<span class="fl">2</span>) - x(<span class="fl">1</span>))) * (z - x(<span class="fl">1</span>)) + y(<span class="fl">1</span>);
    plot([<span class="fl">1</span> n],line([<span class="fl">1</span> n]),<span class="st">'Color'</span>,<span class="st">'r'</span>);
end
<span class="co">%--------------------------------------------------------------------------</span></code></pre></div>
<h2 id="conclusion">Conclusion</h2>

<p>Chessboards are ubiquitous is computer vision because they provide a convenient way to benchmark/verify many common calibration and feature extraction algorithms.</p>
<h2 id="see-also">See also</h2>
<ul>
<li><a href="Computer_vision" title="wikilink">Computer vision</a></li>
<li><a href="Projective_geometry" title="wikilink">Projective geometry</a></li>
<li><a href="Pinhole_camera" title="wikilink">Pinhole camera</a></li>
<li><a class="uri" href="Photogrammetry" title="wikilink">Photogrammetry</a></li>
<li><a href="Camera_resectioning" title="wikilink">Camera calibration</a></li>
<li><a href="Feature_detection_(computer_vision)" title="wikilink">Feature detection</a></li>
<li><a href="Feature_extraction" title="wikilink">Feature extraction</a></li>
<li><a href="Canny_edge_detector" title="wikilink">Canny edge detection</a></li>
<li><a href="Corner_detection" title="wikilink">Corner detection</a></li>
<li><a href="Structure_tensor" title="wikilink"> Structure tensor matrix</a></li>
<li><a href="Hough_transform" title="wikilink">Hough transform</a></li>
</ul>
<h2 id="further-reading">Further reading</h2>
<ol>
<li>M. Rufli, D. Scaramuzza, and R. Siegwart. "Automatic detection of checkerboards on blurred and distorted images." IEEE/RSJ International Conference on Intelligent Robots and Systems. (2008).</li>
<li>Z. Weixing, et al. "A fast and accurate algorithm for chessboard corner detection." 2nd International Congress on Image and Signal Processing. (2009).</li>
<li>A. De la Escalera and J. Armingol. "Automatic chessboard detection for intrinsic and extrinsic camera parameter calibration." Sensors. vol. 10(3), pp.¬†2027‚Äì2044 (2010).</li>
<li>S. Bennett and J. Lasenby. "ChESS - quick and robust detection of chess-board features." Computer Vision and Image Understanding. vol. 118, pp.¬†197‚Äì210 (2014).</li>
<li>J. Ha. "Automatic detection of chessboard and its applications." Opt. Eng. vol. 48(6) (2009).</li>
<li>F. Zhao, et al. "An automated x-corner detection algorithm (axda)." Journal of Software. vol. 6(5), pp.¬†791‚Äì797 (2011).</li>
<li>S. Arca, E. Casiraghi, and G. Lombardi. "Corner localization in chessboards for camera calibration." IADAT. (2005).</li>
<li>X. Hu, P. Du, and Y. Zhou. "Automatic corner detection of chess board for medical endoscopy camera calibration." Proceedings of the 10th International Conference on Virtual Reality Continuum and Its Applications in Industry. ACM. (2011).</li>
<li>S. Malek, et al. "Tracking chessboard corners using projective transformation for augmented reality. International Conference on Communications, Computing and Control Applications. (2011).</li>
</ol>
<h2 id="references">References</h2>
<references>
</references>
<h2 id="external-links">External links</h2>

<p>The following links are pointers to popular <a class="uri" href="MATLAB" title="wikilink">MATLAB</a> and <a class="uri" href="OpenCV" title="wikilink">OpenCV</a> implementations of chessboard-related computer vision algorithms.</p>
<ul>
<li><a href="http://www.vision.caltech.edu/bouguetj/calib_doc/">Camera Calibration Toolbox for MATLAB</a> - MATLAB toolbox implementing many common camera calibration methods</li>
<li><a href="http://docs.opencv.org/modules/calib3d/doc/camera_calibration_and_3d_reconstruction.html">Camera Calibration and 3D Reconstruction</a> - OpenCV implementation of many common camera calibration methods</li>
<li><a href="http://www.vision.caltech.edu/bouguetj/calib_doc/htmls/example.html">Multiplane Camera Calibration From Multiple Chessboard Views</a> - MATLAB example of applying multiview auto-calibration to a series of chessboard images</li>
<li><a href="http://www.mathworks.com/help/vision/ref/detectcheckerboardpoints.html">MATLAB chessboard detection</a> - MATLAB function from the <a href="http://www.mathworks.com/products/computer-vision/">Computer Vision System Toolbox</a> for detecting chessboards in images</li>
<li><a href="http://docs.opencv.org/doc/tutorials/calib3d/camera_calibration_square_chess/camera_calibration_square_chess.html">OpenCV chessboard detection</a> - OpenCV function for detecting chessboards in images</li>
<li><a href="http://www.mathworks.com/help/images/ref/corner.html">MATLAB Harris corner detection</a> - MATLAB function for performing Harris corner detection</li>
<li><a href="http://docs.opencv.org/doc/tutorials/features2d/trackingmotion/harris_detector/harris_detector.html">OpenCV Harris corner detection</a> - OpenCV function for performing Harris corner detection</li>
<li><a href="http://www.mathworks.com/help/images/hough-transform.html">MATLAB Hough transform</a> - MATLAB function for computing the Hough transform</li>
<li><a href="http://docs.opencv.org/doc/tutorials/imgproc/imgtrans/hough_lines/hough_lines.html">OpenCV Hough transform</a> - OpenCV function for computing the Hough transform</li>
</ul>

<p>"</p>

<p><a href="Category:Feature_detection_(computer_vision)" title="wikilink">Category:Feature detection (computer vision)</a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1">D. Forsyth and J. Ponce. Computer Vision: A Modern Approach. Prentice Hall. (2002). <a href="http://www.amazon.com/Computer-Vision-Modern-Approach-Edition/dp/013608592X">ISBN 978-0262061582</a>.<a href="#fnref1">‚Ü©</a></li>
<li id="fn2">R. Szeliski. Computer Vision: Algorithms and Applications. Springer Science and Business Media. (2010). <a href="http://www.springer.com/computer/image+processing/book/978-1-84882-934-3">ISBN 978-1848829350</a>.<a href="#fnref2">‚Ü©</a></li>
<li id="fn3">O. Faugeras. Three-dimensional Computer Vision. MIT Press. (1993). <a href="http://www.amazon.com/Three-Dimensional-Computer-Vision-Artificial-Intelligence/dp/0262061589">ISBN 978-0262061582</a>.<a href="#fnref3">‚Ü©</a></li>
<li id="fn4"></li>
<li id="fn5">Z. Zhang. "A flexible new technique for camera calibration." IEEE Transactions on Pattern Analysis and Machine Intelligence. vol. 22(11), pp. 1330-1334 (2000).<a href="#fnref5">‚Ü©</a></li>
<li id="fn6">J. Bouguet, "Camera calibration toolbox for MATLAB". <a class="uri" href="http://www.vision.caltech.edu/bouguetj/calib_doc/">http://www.vision.caltech.edu/bouguetj/calib_doc/</a>. (2013).<a href="#fnref6">‚Ü©</a></li>
<li id="fn7"></li>
<li id="fn8">C. Harris and M. Stephens. "A combined corner and edge detector." Proceedings of the 4th Alvey Vision Conference. pp. 147-151 (1988).<a href="#fnref8">‚Ü©</a></li>
<li id="fn9">L. Shapiro and G. Stockman. Computer Vision. Prentice-Hall, Inc. (2001). <a href="http://www.amazon.com/Computer-Vision-Linda-G-Shapiro/dp/0130307963">ISBN 978-0130307965</a><a href="#fnref9">‚Ü©</a></li>
<li id="fn10">R. Duda and P. Hart. "Use of the Hough transformation to detect lines and curves in pictures," Comm. ACM, vol. 15, pp. 11-15 (1972).<a href="#fnref10">‚Ü©</a></li>
<li id="fn11">P. Hough. "Machine analysis of bubble chamber pictures." Proc. Int. Conf. High Energy Accelerators and Instrumentation. (1959).<a href="#fnref11">‚Ü©</a></li>
</ol>
</section>
</body>

