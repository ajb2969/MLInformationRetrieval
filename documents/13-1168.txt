   Rank factorization      Rank factorization   Given an    m  ×  n      m  n    m\times n    matrix    A   A   A   of rank    r   r   r   , a rank decomposition or rank factorization of   A   A   A   is a product    A  =   C  F       A    C  F     A=CF   , where   C   C   C   is an    m  ×  r      m  r    m\times r   matrix and   F   F   F   is an    r  ×  n      r  n    r\times n   matrix.  Every finite-dimensional matrix has a rank decomposition: Let   A   A   A   be an    m  ×  n      m  n    m\times n   matrix whose column rank is   r   r   r   . Therefore, there are   r   r   r    linearly independent columns in   A   A   A   ; equivalently, the dimension of the column space of   A   A   A   is   r   r   r   . Let     c  1   ,   c  2   ,  …  ,   c  r       subscript  c  1    subscript  c  2   normal-…   subscript  c  r     c_{1},c_{2},\ldots,c_{r}   be any basis for the column space of   A   A   A   and place them as column vectors to form the    m  ×  r      m  r    m\times r   matrix    C  =   [   c  1   :   c  2   :  …  :   c  r   ]      fragments  C    fragments  normal-[   subscript  c  1   normal-:   subscript  c  2   normal-:  normal-…  normal-:   subscript  c  r   normal-]     C=[c_{1}:c_{2}:\ldots:c_{r}]   . Therefore, every column vector of   A   A   A   is a linear combination of the columns of   C   C   C   . To be precise, if    A  =   [   a  1   :   a  2   :  …  :   a  n   ]      fragments  A    fragments  normal-[   subscript  a  1   normal-:   subscript  a  2   normal-:  normal-…  normal-:   subscript  a  n   normal-]     A=[a_{1}:a_{2}:\ldots:a_{n}]   is an    m  ×  n      m  n    m\times n   matrix with    a  j     subscript  a  j    a_{j}   as the   j   j   j   -th column, then        a  j   =     f   1  j     c  1    +    f   2  j     c  2    +  ⋯  +    f   r  j     c  r      ,       subscript  a  j        subscript  f    1  j     subscript  c  1       subscript  f    2  j     subscript  c  2    normal-⋯     subscript  f    r  j     subscript  c  r       a_{j}=f_{1j}c_{1}+f_{2j}c_{2}+\cdots+f_{rj}c_{r},   where    f   i  j      subscript  f    i  j     f_{ij}   's are the scalar coefficients of    a  j     subscript  a  j    a_{j}   in terms of the basis     c  1   ,   c  2   ,  …  ,   c  r       subscript  c  1    subscript  c  2   normal-…   subscript  c  r     c_{1},c_{2},\ldots,c_{r}   . This implies that    A  =   C  F       A    C  F     A=CF   , where    f   i  j      subscript  f    i  j     f_{ij}   is the    (  i  ,  j  )     i  j    (i,j)   -th element of   F   F   F   .  == rank(A) = rank(A T ) == An immediate consequence of rank factorization is that the rank of   A   A   A   is equal to the rank of its transpose    A  T     superscript  A  T    A^{\text{T}}   . Since the columns of   A   A   A   are the rows of    A  T     superscript  A  T    A^{\text{T}}   , the column rank of   A   A   A   equals its row rank .  Proof: To see why this is true, let us first define rank to mean column rank. Since    A  =   C  F       A    C  F     A=CF   , it follows that     A  T   =    F  T    C  T         superscript  A  T      superscript  F  T    superscript  C  T      A^{\text{T}}=F^{\text{T}}C^{\text{T}}   . From the definition of matrix multiplication , this means that each column of    A  T     superscript  A  T    A^{\text{T}}   is a linear combination of the columns of    F  T     superscript  F  T    F^{\text{T}}   . Therefore, the column space of    A  T     superscript  A  T    A^{\text{T}}   is contained within the column space of    F  T     superscript  F  T    F^{\text{T}}   and, hence, rank(    A  T     superscript  A  T    A^{\text{T}}   ) ≤ rank(    F  T     superscript  F  T    F^{\text{T}}   ). Now,    F  T     superscript  F  T    F^{\text{T}}   is   n   n   n   ×   r   r   r   , so there are   r   r   r   columns in    F  T     superscript  F  T    F^{\text{T}}   and, hence, rank(    A  T     superscript  A  T    A^{\text{T}}   ) ≤   r   r   r   = rank(   A   A   A   ). This proves that rank(     A  T   )     fragments   superscript  A  T   normal-)    A^{\text{T}})   ≤ rank(   A   A   A   ). Now apply the result to    A  T     superscript  A  T    A^{\text{T}}   to obtain the reverse inequality: since     (   A  T   )   T     superscript   superscript  A  T   T    (A^{\text{T}})^{\text{T}}   =   A   A   A   , we can write rank(   A   A   A   ) = rank(      (   A  T   )   T   )     fragments   superscript   fragments  normal-(   superscript  A  T   normal-)   T   normal-)    (A^{\text{T}})^{\text{T}})   ≤ rank(    A  T     superscript  A  T    A^{\text{T}}   ). This proves rank(    A  )     fragments  A  normal-)    A)   ≤ rank(    A  T     superscript  A  T    A^{\text{T}}   ). We have, therefore, proved rank(     A  T   )     fragments   superscript  A  T   normal-)    A^{\text{T}})   ≤ rank(   A   A   A   ) and rank(   A   A   A   ) ≤ rank(    A  T     superscript  A  T    A^{\text{T}}   ), so rank(   A   A   A   ) = rank(    A  T     superscript  A  T    A^{\text{T}}   ). (Also see the first proof of column rank = row rank under rank ).  Rank factorization from row echelon forms  In practice, we can construct one specific rank factorization as follows: we can compute   B   B   B   , the reduced row echelon form of   A   A   A   . Then   C   C   C   is obtained by removing from   A   A   A   all non- pivot columns , and   F   F   F   by eliminating all zero rows of   B   B   B   .  Example  Consider the matrix      A  =   [     1    3    1    4      2    7    3    9      1    5    3    1      1    2    0    8     ]   ∼   [     1    0     -  2     0      0    1    1    0      0    0    0    1      0    0    0    0     ]   =   B  .         A    1  3  1  4    2  7  3  9    1  5  3  1    1  2  0  8      similar-to      1  0    2   0    0  1  1  0    0  0  0  1    0  0  0  0           B  .      A=\begin{bmatrix}1&3&1&4\\
 2&7&3&9\\
 1&5&3&1\\
 1&2&0&8\end{bmatrix}\sim\begin{bmatrix}1&0&-2&0\\
 0&1&1&0\\
 0&0&0&1\\
 0&0&0&0\end{bmatrix}=B\text{.}      B   B   B   is in reduced echelon form. Then   C   C   C   is obtained by removing the third column of   A   A   A   , the only one which is not a pivot column, and   F   F   F   by getting rid of the last row of zeroes, so       C  =    [     1    3    4      2    7    9      1    5    1      1    2    8     ]   ,     F  =    [     1    0     -  2     0      0    1    1    0      0    0    0    1     ]   .       formulae-sequence    C      1  3  4    2  7  9    1  5  1    1  2  8    ,      F      1  0    2   0    0  1  1  0    0  0  0  1    .      C=\begin{bmatrix}1&3&4\\
 2&7&9\\
 1&5&1\\
 1&2&8\end{bmatrix}\text{,}\qquad F=\begin{bmatrix}1&0&-2&0\\
 0&1&1&0\\
 0&0&0&1\end{bmatrix}\text{.}   It is straightforward to check that      A  =   [     1    3    1    4      2    7    3    9      1    5    3    1      1    2    0    8     ]   =    [     1    3    4      2    7    9      1    5    1      1    2    8     ]    [     1    0     -  2     0      0    1    1    0      0    0    0    1     ]    =   C  F  .         A    1  3  1  4    2  7  3  9    1  5  3  1    1  2  0  8             1  3  4    2  7  9    1  5  1    1  2  8      1  0    2   0    0  1  1  0    0  0  0  1            C  F  .      A=\begin{bmatrix}1&3&1&4\\
 2&7&3&9\\
 1&5&3&1\\
 1&2&0&8\end{bmatrix}=\begin{bmatrix}1&3&4\\
 2&7&9\\
 1&5&1\\
 1&2&8\end{bmatrix}\begin{bmatrix}1&0&-2&0\\
 0&1&1&0\\
 0&0&0&1\end{bmatrix}=CF\text{.}     Proof  Let   P   P   P   be an    n  ×  n      n  n    n\times n   permutation matrix such that     A  P   =   (  C  ,  D  )         A  P    C  D     AP=(C,D)   in block partitioned form, where the columns of   C   C   C   are the   r   r   r   pivot columns of   A   A   A   . Every column of   D   D   D   is a linear combination of the columns of   C   C   C   , so there is a matrix   G   G   G   such that    D  =   C  G       D    C  G     D=CG   , where the columns of   G   G   G   contain the coefficients of each of those linear combinations. So     A  P   =   (  C  ,   C  G   )   =   C   (   I  r   ,  G  )            A  P    C    C  G           C    subscript  I  r   G       AP=(C,CG)=C(I_{r},G)   ,    I  r     subscript  I  r    I_{r}   being the    r  ×  r      r  r    r\times r   identity matrix. We will show now that     (   I  r   ,  G  )   =   F  P         subscript  I  r   G     F  P     (I_{r},G)=FP   .  Transforming    A  P      A  P    AP   into its reduced row echelon form amounts to left-multiplying by a matrix   E   E   E   which is a product of elementary matrices , so     E  A  P   =   B  P   =   E  C   (   I  r   ,  G  )            E  A  P     B  P          E  C    subscript  I  r   G       EAP=BP=EC(I_{r},G)   , where     E  C   =   (      I  r       0     )         E  C      subscript  I  r     0      EC=\begin{pmatrix}I_{r}\\
 0\end{pmatrix}   . We then can write     B  P   =   (      I  r     G      0    0     )         B  P      subscript  I  r   G    0  0      BP=\begin{pmatrix}I_{r}&G\\
 0&0\end{pmatrix}   , which allows us to identify     (   I  r   ,  G  )   =   F  P         subscript  I  r   G     F  P     (I_{r},G)=FP   , i.e. the nonzero   r   r   r   rows of the reduced echelon form, with the same permutation on the columns as we did for   A   A   A   . We thus have     A  P   =   C  F  P         A  P     C  F  P     AP=CFP   , and since   P   P   P   is invertible this implies    A  =   C  F       A    C  F     A=CF   , and the proof is complete.  References       "  Category:Matrix decompositions  Category:Linear algebra   