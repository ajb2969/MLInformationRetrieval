   Hodges' estimator      Hodges' estimator   In statistics , Hodges‚Äô estimator 1 (or the Hodges‚ÄìLe Cam estimator 2 ), named for Joseph Hodges , is a famous 3 counter example of an estimator which is "superefficient", i.e. it attains smaller asymptotic variance than regular efficient estimators . The existence of such a counterexample is the reason for the introduction of the notion of regular estimators .  Hodges‚Äô estimator improves upon a regular estimator at a single point. In general, any superefficient estimator may surpass a regular estimator at most on a set of Lebesgue measure zero. 4  Construction  Suppose     Œ∏  ^   n     subscript   normal-^  Œ∏   n    \scriptstyle\hat{\theta}_{n}   is a "common" estimator for some parameter Œ∏ : it is consistent , and converges to some asymptotic distribution  L Œ∏ (usually this is a normal distribution with mean zero and variance which may depend on Œ∏ ) at the :         n    (     Œ∏  ^   n   -  Œ∏   )      ‚Üí  ùëë      L  Œ∏     .      d  normal-‚Üí       n      subscript   normal-^  Œ∏   n   Œ∏     subscript  L  Œ∏     \sqrt{n}(\hat{\theta}_{n}-\theta)\ \xrightarrow{d}\ L_{\theta}\ .     Then the Hodges‚Äô estimator      Œ∏  ^   n  H     subscript   superscript   normal-^  Œ∏   H   n    \scriptstyle\hat{\theta}^{H}_{n}   is defined as 5        Œ∏  ^   n  H   =   {        Œ∏  ^   n   ,       if   |    Œ∏  ^   n   |    ‚â•    n   -   1  /  4     ,  and         0  ,        if   |    Œ∏  ^   n   |    <   n   -   1  /  4      .            superscript   subscript   normal-^  Œ∏   n   H    cases   subscript   normal-^  Œ∏   n       if     subscript   normal-^  Œ∏   n       superscript  n      1  4     and    0      if     subscript   normal-^  Œ∏   n      superscript  n      1  4         \hat{\theta}_{n}^{H}=\begin{cases}\hat{\theta}_{n},&\text{if }|\hat{\theta}_{n%
 }|\geq n^{-1/4},\text{ and}\\
 0,&\text{if }|\hat{\theta}_{n}|   This estimator is equal to     Œ∏  ^   n     subscript   normal-^  Œ∏   n    \scriptstyle\hat{\theta}_{n}   everywhere except on the small interval , where it is equal to zero. It is not difficult to see that this estimator is consistent for Œ∏ , and its asymptotic distribution is 6          n  Œ±    (     Œ∏  ^   n  H   -  Œ∏   )     ‚Üí  ùëë   0   ,    when  Œ∏   =  0    ,     formulae-sequence    d  normal-‚Üí      superscript  n  Œ±      superscript   subscript   normal-^  Œ∏   n   H   Œ∏    0       when  Œ∏   0     \displaystyle n^{\alpha}(\hat{\theta}_{n}^{H}-\theta)\ \xrightarrow{d}\ 0,%
 \qquad\text{when }\theta=0,   for any Œ± ‚àà R . Thus this estimator has the same asymptotic distribution as     Œ∏  ^   n     subscript   normal-^  Œ∏   n    \scriptstyle\hat{\theta}_{n}   for all , whereas for  the rate of convergence becomes arbitrarily fast. This estimator is superefficient , as it surpasses the asymptotic behavior of the efficient estimator     Œ∏  ^   n     subscript   normal-^  Œ∏   n    \scriptstyle\hat{\theta}_{n}   at least at one point . In general, superefficiency may only be attained on a subset of measure zero of the parameter space Œò.  Example  (Figure)  The mean square error (times n ) of Hodges‚Äô estimator. Blue curve corresponds to , purple to , and olive to . 7   Suppose x 1 , ‚Ä¶, x n is an iid sample from normal distribution  with unknown mean but known variance. Then the common estimator for the population mean Œ∏ is the arithmetic mean of all observations:    x  ¬Ø     normal-¬Ø  x    \scriptstyle\bar{x}   . The corresponding Hodges‚Äô estimator will be       Œ∏  ^   n  H    =   x  ¬Ø   ‚ãÖ  ùüè   {  |   x  ¬Ø   |  ‚â•   n   -   1  /  4     }      fragments   subscript   superscript   normal-^  Œ∏   H   n     normal-¬Ø  x   normal-‚ãÖ  1   fragments  normal-{  normal-|   normal-¬Ø  x   normal-|    superscript  n      1  4     normal-}     \scriptstyle\hat{\theta}^{H}_{n}\;=\;\bar{x}\cdot\mathbf{1}\{|\bar{x}|\,\geq\,%
 n^{-1/4}\}   , where 1 {‚Ä¶} denotes the indicator function .  The mean square error (scaled by n ) associated with the regular estimator x is constant and equal to 1 for all Œ∏ ‚Äôs. At the same time the mean square error of the Hodges‚Äô estimator     Œ∏  ^   n  H     superscript   subscript   normal-^  Œ∏   n   H    \scriptstyle\hat{\theta}_{n}^{H}   behaves erratically in the vicinity of zero, and even becomes unbounded as . This demonstrates that the Hodges‚Äô estimator is not regular , and its asymptotic properties are not adequately described by limits of the form ( Œ∏ fixed, ).  See also   James‚ÄìStein estimator   Notes  References        "  Category:Estimation theory     ‚Ü©  ‚Ü©  ‚Ü©  ‚Ü©  ‚Ü©  ‚Ü©  ‚Ü©     