


Equilibrium point




Equilibrium point

In mathematics, specifically in differential equations, an equilibrium point is a constant solution to a differential equation.
Formal definition
The point $\tilde{\mathbf{x}}\in \mathbb{R}^n$ is an equilibrium point for the differential equation
$$\frac{d\mathbf{x}}{dt} = \mathbf{f}(t,\mathbf{x})$$
if $\mathbf{f}(t,\tilde{\mathbf{x}})=0$ for all $t\,\!$.
Similarly, the point $\tilde{\mathbf{x}}\in \mathbb{R}^n$ is an equilibrium point (or fixed point) for the difference equation
$$\mathbf{x}_{k+1} = \mathbf{f}(k,\mathbf{x}_k)$$
if $\mathbf{f}(k,\tilde{\mathbf{x}})= \tilde{\mathbf{x}}$ for $k=0,1,2,\ldots$.
Classification
Equilibria can be classified by looking at the signs of the eigenvalues of the linearization of the equations about the equilibria. That is to say, by evaluating the Jacobian matrix at each of the equilibrium points of the system, and then finding the resulting eigenvalues, the equilibria can be categorized. Then the behavior of the system in the neighborhood of each equilibrium point can be qualitatively determined, (or even quantitatively determined, in some instances), by finding the eigenvector(s) associated with each eigenvalue.
An equilibrium point is hyperbolic if none of the eigenvalues have zero real part. If all eigenvalues have negative real part, the equilibrium is a stable equation. If at least one has a positive real part, the equilibrium is an unstable node. If at least one eigenvalue has negative real part and at least one has positive real part, the equilibrium is a saddle point.
See also

Autonomous equation
Equilibrium switching1

References



"
Category:Stability theory Category:Dynamical systems








