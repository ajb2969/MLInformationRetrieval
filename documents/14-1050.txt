   Zyablov bound      Zyablov bound   In coding theory, the Zyablov bound is a lower bound on the rate   R   R   R   and relative distance   Œ¥   Œ¥   \delta   of concatenated codes .  Statement of the bound  (Figure)  |   Let   R   R   R   be the rate of the outer code    C   o  u  t      subscript  C    o  u  t     C_{out}   and   Œ¥   Œ¥   \delta   be the relative distance, then the rate of the concatenated codes satisfies the following bound.      ‚Ñõ  ‚â•    (   max   0  ‚â§  r  ‚â§   (   1  -    H  q    (   Œ¥  +  Œµ   )     )     )   r   (   1  -   Œ¥     H  q   -  1     (   1  -  r   )    -  Œµ     )        ‚Ñõ     subscript       0  r         1     subscript  H  q     Œ¥  Œµ        r    1    Œ¥       superscript   subscript  H  q     1      1  r    Œµ        \mathcal{R}\geq(\max\limits_{0\leq r\leq(1-H_{q}(\delta+\varepsilon))})r(1-{%
 \delta\over{H_{q}^{-1}(1-r)-\varepsilon}})     where   r   r   r   is the rate of the inner code    C   i  n      subscript  C    i  n     C_{in}   .  Description  Let    C   o  u  t      subscript  C    o  u  t     C_{out}   be the outer code,    C   i  n      subscript  C    i  n     C_{in}   be the inner code.  Consider    C   o  u  t      subscript  C    o  u  t     C_{out}   meets the Singleton bound with rate of   R   R   R   , i.e.    C   o  u  t      subscript  C    o  u  t     C_{out}   has relative distance   Œ¥   Œ¥   \delta   >    1  -  R      1  R    {1-R}   . In order for     C   o  u  t    ‚àò   C   i  n         subscript  C    o  u  t     subscript  C    i  n      C_{out}\circ C_{in}   to be an asymptotically good code,    C   i  n      subscript  C    i  n     C_{in}   also needs to be an asymptotically good code which means,    C   i  n      subscript  C    i  n     C_{in}   needs to have rate   r   r   r   >   0   0    and relative distance    Œ¥   i  n      subscript  Œ¥    i  n     \delta_{in}   >   0   0    .  Suppose    C   i  n      subscript  C    i  n     C_{in}   meets the Gilbert-Varshamov bound with rate of   r   r   r   and thus with relative distance     Œ¥   i  n    ‚â•      H  q   -  1     (   1  -  r   )    -  Œµ   ,  Œµ        subscript  Œ¥    i  n          superscript   subscript  H  q     1      1  r    Œµ   Œµ     \delta_{in}\geq H_{q}^{-1}(1-r)-\varepsilon,\varepsilon   >   0   0    , then     C   o  u  t    ‚àò   C   i  n         subscript  C    o  u  t     subscript  C    i  n      C_{out}\circ C_{in}   has rate of    r  R      r  R    rR   and    Œ¥  =    (   1  -  R   )    (     H  q   -  1     (   1  -  r   )    -  Œµ   )        Œ¥      1  R        superscript   subscript  H  q     1      1  r    Œµ      \delta=(1-R)(H_{q}^{-1}(1-r)-\varepsilon)   .  Expressing   R   R   R   as a function of    Œ¥  ,  r     Œ¥  r    \delta,r   ,    R  =   (   1  -   Œ¥     H   -  1     (   1  -  r   )    -  Œµ     )       R    1    Œ¥       superscript  H    1      1  r    Œµ       R=(1-\frac{\delta}{H^{-1}(1-r)-\varepsilon})     Then optimizing over the choice of r, we get that rate of the Concatenated error correction code satisÔ¨Åes,      ‚Ñõ  ‚â•     max   0  ‚â§  r  ‚â§   1  -    H  q    (   Œ¥  +  Œµ   )       r    (   1  -   Œ¥     H  q   -  1     (   1  -  r   )    -  Œµ     )        ‚Ñõ      subscript       0  r         1     subscript  H  q     Œ¥  Œµ        r     1    Œ¥       superscript   subscript  H  q     1      1  r    Œµ        \mathcal{R}\geq{\max\limits_{0\leq r\leq{1-H_{q}(\delta+\varepsilon)}}}r\left(%
 1-{\delta\over{H_{q}^{-1}(1-r)-\varepsilon}}\right)     This lower bound is called Zyablov bound (the bound of   r   r   r   {1 - H_q}(\delta + \varepsilon) is necessary to ensure that   R   R   R   >   0   0    ). See Figure 2 for a plot of this bound.  Note that the Zyablov bound implies that for every   Œ¥   Œ¥   \delta   >   0   0    , there exists a (concatenated) code with rate   R   R   R   >   0   0    .  Remarks  We can construct a code that achieves the Zyablov bound in polynomial time. In particular, we can construct explicit asymptotically good code (over some alphabets) in polynomial time.  Linear Codes will help us complete the proof of the above statement since linear codes have polynomial representation. Let Cout be an     [  N  ,  K  ]   Q     subscript   N  K   Q    [N,K]_{Q}    Reed-Solomon error correction code where    N  =   Q  -  1       N    Q  1     N=Q-1   (evaluation points being    ùîΩ  Q  *     superscript   subscript  ùîΩ  Q      \mathbb{F}_{Q}^{*}   with    Q  =   q  k       Q   superscript  q  k     Q=q^{k}   , then    k  =   Œ∏   (   l  o  g  N   )        k    Œ∏    l  o  g  N      k=\theta(logN)   .  We need to construct the Inner code that lies on Gilbert-Varshamov bound . This can be done in two ways   To perform an exhaustive search on all generator matrices until the required property is satisfied for    C   i  n      subscript  C    i  n     C_{in}   . This is because Varshamovs bound states that there exists a linear code that lies on Gilbert-Varshamon bound which will take    q   O   (   k  n   )       superscript  q    O    k  n      q^{O(kn)}   time.Using    k  =   r  n       k    r  n     k=rn   we get     q   O   (   k  n   )     =   q   O   (   k  2   )     =   N   O   (   l  o  g  N   )            superscript  q    O    k  n      superscript  q    O   superscript  k  2           superscript  N    O    l  o  g  N        q^{O(kn)}=q^{O(k^{2})}=N^{O(logN)}   , which is upper bounded by    n   N   O   (   l  o  g  n  N   )         n   superscript  N    O    l  o  g  n  N       nN^{O(lognN)}   , a quasi-polynomial time bound.    To construct    C   i  n      subscript  C    i  n     C_{in}   in    q   O   (  n  )       superscript  q    O  n     q^{O(n)}   time and use     (   n  N   )    O   (  1  )       superscript    n  N     O  1     (nN)^{O(1)}   time overall. This can be achieved by using the method of conditional expectation on the proof that random linear code lies on the bound with high probability.   Thus we can construct a code that achieves the Zyablov bound in polynomial time.  See also   Singleton bound  Gilbert-Varshamov bound   References and External Links   MIT Lecture Notes on Essential Coding Theory ‚Äì Dr. Madhu Sudan  University at Buffalo Lecture Notes on Coding Theory ‚Äì Dr. Atri Rudra  University of Washington Lecture Notes on Coding Theory- Dr. Venkatesan Guruswami   "  Category:Error detection and correction  Category:Coding theory  Category:Finite fields  Category:Information theory   