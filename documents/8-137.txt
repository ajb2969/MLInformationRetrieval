


Slutsky's theorem




Slutsky's theorem

In probability theory, Slutsky’s theorem1 extends some properties of algebraic operations on convergent sequences of real numbers to sequences of random variables.
The theorem was named after Eugen Slutsky.2 Slutsky’s theorem is also attributed to Harald Cramér.3
Statement
Let {Xn}, {Yn} be sequences of scalar/vector/matrix random elements.
If Xn converges in distribution to a random element X;
and Yn converges in probability to a constant c, then









 
    provided that c is invertible,

where 
 
 
 
  denotes convergence in distribution.
Notes:

In the statement of the theorem, the condition “Yn converges in probability to a constant c” may be replaced with “Yn converges in distribution to a constant c” — these two requirements are equivalent according to this property.
The requirement that Yn converges to a constant is important — if it were to converge to a non-degenerate random variable, the theorem would be no longer valid.
The theorem remains valid if we replace all convergences in distribution with convergences in probability (due to this property).

Proof
This theorem follows from the fact that if Xn converges in distribution to X and Yn converges in probability to a constant c, then the joint vector (Xn, Yn) converges in distribution to (X, c) (see here).
Next we apply the continuous mapping theorem, recognizing the functions g(x,y)=x+y, g(x,y)=xy, and g(x,y)=x−1y as continuous (for the last function to be continuous, x has to be invertible).
References





"
Category:Probability theorems Category:Statistical theorems



↩
↩
Slutsky's theorem is also called Cramér’s theorem according to Remark 11.1 (page 249) of Allan Gut. A Graduate Course in Probability. Springer Verlag. 2005.↩




