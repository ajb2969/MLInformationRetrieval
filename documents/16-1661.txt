   Tempotron      Tempotron   The Tempotron is a supervised synaptic learning algorithm which is applied when the information is encoded in spatiotemporal  spiking patterns. This is an advancement of the perceptron which does not incorporate a spike timing framework.  It is general consensus that spike timing (STDP) plays a crucial role in the development of synaptic efficacy for many different kinds of neurons 1 Therefore a large variety of STDP-rules has been developed one of which is the tempotron.  Algorithm  Assuming a leaky integrate-and-fire-model the potential    V   (  t  )       V  t    V(t)   of the synapse can be described by        V   (  t  )    =     ∑  i     ω  i     ∑   t  i     K   (   t  -   t  i    )       +   V   r  e  s  t      ,        V  t       subscript   i      subscript  ω  i     subscript    subscript  t  i      K    t   subscript  t  i         subscript  V    r  e  s  t       V(t)=\sum_{i}\omega_{i}\sum_{t_{i}}K(t-t_{i})+V_{rest},     where    t  i     subscript  t  i    t_{i}   denotes the spike time of the i-th afferent synapse with synaptic efficacy    ω  i     subscript  ω  i    \omega_{i}   and    V   r  e  s  t      subscript  V    r  e  s  t     V_{rest}   the resting potential.    K   (   t  -   t  i    )       K    t   subscript  t  i      K(t-t_{i})   describes the postsynaptic potential (PSP) elicited by each incoming spike:       K   (   t  -   t  i    )    =   {       V  0    [    e  x  p   (   -    (   t  -   t  i    )   /  τ    )    -   e  x  p   (   -    (   t  -   t  i    )   /   τ  s     )     ]       t  ≥   t  i        0     t  <   t  i              K    t   subscript  t  i      cases     subscript  V  0    delimited-[]      e  x  p        t   subscript  t  i    τ       e  x  p        t   subscript  t  i     subscript  τ  s           t   subscript  t  i    0    t   subscript  t  i       K(t-t_{i})=\begin{cases}V_{0}[exp(-(t-t_{i})/\tau)-exp(-(t-t_{i})/\tau_{s})]&t%
 \geq t_{i}\\
 0&t     with parameters   τ   τ   \tau   and    τ  s     subscript  τ  s    \tau_{s}   denoting decay time constants of the membrane integration and synaptic currents. The factor    V  0     subscript  V  0    V_{0}   is used for the normalization of the PSP kernels. When the potential crosses the firing threshold    V   t  h      subscript  V    t  h     V_{th}   the potential is reset to its resting value by shunting all incoming spikes.  Next a binary classification of the input patterns is needed(   ∘     \circ   refers to a pattern which should elicit at least one post synaptic action potential and   ∙   normal-∙   \bullet   refers to a pattern which should have no response accordingly). In the beginning the neuron does not know which pattern belongs to which classification and has to learn it iteratively, similar to the perceptron . The tempotron learns its tasks by adapting the synaptic effifacy    ω  i     subscript  ω  i    \omega_{i}   . If a   ∘     \circ   pattern is presented and the postsynaptic neuron did not spike, all synaptic efficacies are increased by    Δ   ω  i       normal-Δ   subscript  ω  i     \Delta\omega_{i}   whereas a   ∙   normal-∙   \bullet   pattern followed by a postsynaptic response leads to a decrease of the synaptic efficacies by    -   Δ   ω  i          normal-Δ   subscript  ω  i      -\Delta\omega_{i}   with 2     V   (  t  )       V  t    V(t)   denotes the time at which the postsynaptic potential $V(t)$ reaches its maximal value.  Sources  "  Category:Neurology     Caporale, N., & Dan, Y. (2008). Spike timing-dependent plasticity: a Hebbian learning rule. Annu Rev Neurosci, 31, 25-46. ↩  Rober Gütig, Haim Sompolinsky (2006): The tempotron: a neuron that learns spike timing-based decisions , Nature Neuroscience vol. 9, no.3, 420-428 ↩     