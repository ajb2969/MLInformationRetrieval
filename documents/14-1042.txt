   Berlekamp–Welch algorithm      Berlekamp–Welch algorithm   The Berlekamp–Welch algorithm , also known as the Welch–Berlekamp algorithm , is named for Elwyn R. Berlekamp and Lloyd R. Welch . The algorithm efficiently corrects errors in BCH codes and Reed–Solomon codes (which are a subset of BCH codes). Unlike many other decoding algorithms, and in correspondence with the code-domain Berlekamp–Massey algorithm that uses syndrome decoding and the dual of the codes, the Berlekamp–Welch decoding algorithm provides a method for decoding Reed–Solomon codes using just the generator matrix and not syndromes.  History on decoding Reed–Solomon codes   In 1960, Peterson came up with an algorithm for decoding BCH codes . 1 2 His algorithm solves the important second stage of the generalized BCH decoding procedure and is used to calculate the error locator polynomial coefficients that in turn provide the error locator polynomial. This is crucial to the decoding of BCH codes.  In 1963, Gorenstein–Zierler saw that BCH codes and Reed–Solomon codes have a common generalization and that the decoding algorithm extends to more general situation.  In 1968 / 69, Elwyn Berlekamp invented an algorithm for decoding BCH codes. James Massey recognized its application to linear feedback shift registers and simplified the algorithm. 3 4 Massey termed the algorithm the LFSR Synthesis Algorithm (Berlekamp Iterative Algorithm) but it is now known as the Berlekamp–Massey algorithm .  In 1986, The Welch–Berlekamp algorithm was developed to solve the decoding equation of Reed–Solomon codes , using a fast method to solve a certain polynomial equation. The Berlekamp – Welch algorithm has a running time complexity of    𝒪   (   N  3   )       𝒪   superscript  N  3     \mathcal{O}(N^{3})   . We will in the following sections look at the Gemmel and Sudan’s exposition of the Berlekamp Welch Algorithm. 5   Error locator polynomial of Reed–Solomon codes  In the problem of decoding Reed–Solomon codes, the inputs are pair wise distinct evaluation points    α  i     subscript  α  i    \alpha_{i}   ’s ( i = 1, . . ., n ) where     α  i   ∈  𝔽       subscript  α  i   𝔽    \alpha_{i}\in\mathbb{F}   with dimension    K   K   K   and distance     D  =    N  -  K   +  1       D      N  K   1     D=N-K+1   and a codeword   y   y   y   =     (   y  1   ,  …  ,   y  n   )   ∈   𝔽  n         subscript  y  1   normal-…   subscript  y  n     subscript  𝔽  n     (y_{1},\ldots,y_{n})\in\mathbb{F}_{n}   . Our goal is to describe an algorithm that can correct    e  <     N  -  K   +  1   2       e        N  K   1   2     e<{N-K+1\over 2}   many errors in polynomial time. To do so we have to find a polynomial   P   P   P   over   𝔽   𝔽   \mathbb{F}   such that   P   P   P   has degree less than    k  -  1      k  1    k-1   and (the number of   i   i   i   ’s such that     P   (   α  i   )    ≠   y  i   ≤  e          P   subscript  α  i     subscript  y  i        e     P(\alpha_{i})\neq y_{i}\leq e   . We can assume that there exists a polynomial    P   (  X  )       P  X    P(X)   such that    Δ   (  y  ,    (   P   (   α  i   )    )    i  =  1   N   )       normal-Δ   y   subscript   superscript    P   subscript  α  i    N     i  1       \Delta(y,(P(\alpha_{i}))^{N}_{i=1})   ≤    e  ≤   D  2       e    D  2     e\leq{D\over 2}   or      N  -  K   +  1   2          N  K   1   2    {N-K+1\over 2}   .  Note that the coefficients of   P   P   P   are the encoded information. To solve this, we use an indicator for those   i   i   i   ’s where an error may have occurred. Thus we define    E   (  X  )       E  X    E(X)   , which is an error locator polynomial over   𝔽   𝔽   \mathbb{F}   such that     E   (   α  i   )    =  0        E   subscript  α  i    0    E(\alpha_{i})=0   if     y  i   ≠   P   (   α  i   )         subscript  y  i     P   subscript  α  i      y_{i}\neq P(\alpha_{i})   and the degree of   E   E   E   can be given by    E  ≤    n  -  k   2       E      n  k   2     E\leq{n-k\over 2}   .       E   (  X  )    =    ∏    α  i   ∈  S     (   X  -   α  i    )          E  X     subscript  product     subscript  α  i   S      X   subscript  α  i       E(X)=\prod_{\alpha_{i}\in S}(X-\alpha_{i})   where    S  =   {   α  i   |    P   (   α  i   )    ≠   y  i    }       S   conditional-set   subscript  α  i       P   subscript  α  i     subscript  y  i       S=\{\alpha_{i}|P(\alpha_{i})\neq y_{i}\}     We can also claim that for every    1  ≤  i  ≤  N        1  i       N     1\leq i\leq N   ,      y  i   E   (   α  i   )    =   P   (   α  i   )   E   (   α  i   )           subscript  y  i   E   subscript  α  i      P   subscript  α  i   E   subscript  α  i      y_{i}E(\alpha_{i})=P(\alpha_{i})E(\alpha_{i})   . This fact holds true because in the event of     y  i   ≠   P   (   α  i   )         subscript  y  i     P   subscript  α  i      y_{i}\neq P(\alpha_{i})   , both sides of the above equation become   0   0    because     E   (   α  i   )    =  0        E   subscript  α  i    0    E(\alpha_{i})=0   .  However since both    E   (  X  )       E  X    E(X)   and    P   (  X  )       P  X    P(X)   are unknown, the main task of the decoding algorithm would be to find    P   (  X  )       P  X    P(X)   . To do this we use a seemingly useless yet very powerful method and define another polynomial    Q   (  X  )       Q  X    Q(X)   as    Q   (  X  )       Q  X    Q(X)   =    P   (  X  )   E   (  X  )       P  X  E  X    P(X)E(X)   . This is because the   n   n   n   equations with    e  +  k      e  k    e+k   we need to solve are quadratic in nature. Thus by defining a product of two variables that gives rise to a quadratic term as one unknown variable, we increase the number of unknowns but make the equations linear in nature. This method is called linearization 6 and is a very powerful tool.  Thus    Q   (  X  )       Q  X    Q(X)   is a polynomial over   𝔽   𝔽   \mathbb{F}   having the properties:        deg   (  Q  )    ≤      n  -  k   2   +  k   -  1        degree  Q           n  k   2   k   1     \deg(Q)\leq{{n-k\over 2}+k-1}          ∀   Q   (   α  i   )     =   E   (   α  i   )    y  i         for-all    Q   subscript  α  i       E   subscript  α  i    subscript  y  i      \forall Q(\alpha_{i})=E(\alpha_{i})y_{i}      This helps because if we now manage to find    Q   (  X  )       Q  X    Q(X)   and    E   (  X  )       E  X    E(X)   , we can easily find    P   (  X  )       P  X    P(X)   using     P   (  X  )    =    Q   (  X  )     E   (  X  )           P  X       Q  X     E  X      P(X)={Q(X)\over E(X)}   . The main purpose of the Berlekamp Welch algorithm is to find out    P   (  X  )       P  X    P(X)   using degree bounded polynomials    Q   (  X  )       Q  X    Q(X)   and    E   (  X  )       E  X    E(X)   and the properties of   E   E   E   and   N   N   N   .  Computing    E   (  X  )       E  X    E(X)   is as hard as ﬁnding the end solution, polynomial    P   (  X  )       P  X    P(X)   . Once    E   (  X  )       E  X    E(X)   is computed, using erasure decoding for Reed–Solomon codes, we can easily recover    P   (  X  )       P  X    P(X)   . However in a few cases, even the polynomial    Q   (  X  )       Q  X    Q(X)   is as hard to ﬁnd as    E   (  X  )       E  X    E(X)   . As an example, given    Q   (  X  )       Q  X    Q(X)   and   y   y   y   (such that     y  i   ≠  0       subscript  y  i   0    y_{i}\neq 0   for    1  ≤  i  ≤  n        1  i       n     1\leq i\leq n   ), by checking positions where     Q   (  i  )    =  0        Q  i   0    Q(i)=0   , we can ﬁnd the error locations. Thus the algorithm works on the principle that while each of the polynomials    E   (  X  )       E  X    E(X)   and    Q   (  X  )       Q  X    Q(X)   are hard to ﬁnd individually; computing them together is much easier.  The Berlekamp–Welch decoder and algorithm  The Welch–Berlekamp decoder for Reed–Solomon codes consists of the Welch– Berlekamp algorithm augmented by some additional steps that prepare the received word for the algorithm and interpret the result of the algorithm.  The inputs given to the Berlekamp Welch decoder are the integers denoting Block Length   N   N   N   , the number of errors   e   e   e   such that   e   e   e   {N - K + 1 \over 2}, and the received word     (   y  i   ,   α  i   )    i  =  1   N     subscript   superscript    subscript  y  i    subscript  α  i    N     i  1     (y_{i},\alpha_{i})^{N}_{i=1}   satisfying the condition that there exists at most one    P   (  X  )       P  X    P(X)   with     d  e  g   (   P   (  X  )    )    ≤   k  -  1         d  e  g    P  X      k  1     deg(P(X))\leq{k-1}   with     Δ   (  y  ,   P    (   α  i   )   i    )    ≤  e        normal-Δ   y    P   subscript   subscript  α  i   i      e    \Delta(y,{P(\alpha_{i})_{i}})\leq e   .  The output of the decoder is either the polynomial    P   (  X  )       P  X    P(X)   , or in some cases, a failure. This decoder functions in two steps as follows:   This step is called the interpolation step in which the decoder computes a non zero polynomial    E   (  X  )       E  X    E(X)   of degree e (This implies that the coefficient of    X  e     superscript  X  e    X^{e}   must be 1 7 ) and another polynomial    Q   (  X  )       Q  X    Q(X)   with     deg   (   Q   (  X  )    )    ≤    e  +  K   -  1        degree    Q  X        e  K   1     \deg(Q(X))\leq{e+K-1}   . These polynomials are created such that the condition      y  i   E   (   α  i   )    =   Q   (   α  i   )           subscript  y  i   E   subscript  α  i      Q   subscript  α  i      y_{i}E(\alpha_{i})=Q(\alpha_{i})   for all    1  ≤  i  ≤  n        1  i       n     1\leq i\leq n   . In the case that polynomials satisfying the above condition cannot be computed, the output of the decoder would be a failure.  If    E   (  X  )       E  X    E(X)   divides    Q   (  X  )       Q  X    Q(X)   , then a   P   P   P   ’    (  X  )    X   (X)   is defined which equals     Q   (  X  )     E   (  X  )          Q  X     E  X     Q(X)\over E(X)   . If    Δ   (   (  y  ,   (  P        fragments  Δ   fragments  normal-(   fragments  normal-(  y  normal-,   fragments  normal-(  P       \Delta((y,(P   ’       (   α  i   )   i   )   ≤  e  )     fragments   fragments   subscript   fragments  normal-(   subscript  α  i   normal-)   i   normal-)    e  normal-)    (\alpha_{i})_{i})\leq e)   , then the decoder outputs   P   P   P   ’    (  X  )    X   (X)   . If the above condition is not satisfied, i.e. if    E   (  X  )       E  X    E(X)   does not divide    Q   (  X  )       Q  X    Q(X)   then a failure is returned by the decoder.   According to the algorithm, in the cases where it does not output a failure, it outputs a    P   (  X  )       P  X    P(X)   that is the correct and desired polynomial. To prove that, the algorithm always outputs the desired polynomial, we need to prove a few claims we have made while describing the algorithm. Let us go ahead and do so now.  Claim 1: There exist a pair of polynomials    E   (  X  )       E  X    E(X)   and    Q   (  X  )       Q  X    Q(X)   that satisfy Step 1 of the BW algorithm such that      Q   (  X  )     E   (  X  )     =   P   (  X  )            Q  X     E  X      P  X     {Q(X)\over E(X)}=P(X)   .  Let E ( x ) be the error-locating polynomial for    P   (  X  )       P  X    P(X)   such that     E   (  X  )    =    X   e  -   Δ   (  y  ,   P    (   α  i   )   i    )        ∏   1  ≤  i  ≤  n  |   y  i   ≠  P   (   α  i   )      (   X  -   α  i    )           E  X      superscript  X    e    normal-Δ   y    P   subscript   subscript  α  i   i          subscript  product   fragments  1   i   n  normal-|   subscript  y  i    P   fragments  normal-(   subscript  α  i   normal-)       X   subscript  α  i        E(X)=X^{e-\Delta(y,P(\alpha_{i})_{i})}\prod_{1\leq i\leq n|y_{i}\neq P(\alpha_%
 {i})}(X-\alpha_{i})   and let     Q   (  X  )    =   P   (  X  )   E   (  X  )          Q  X     P  X  E  X     Q(X)=P(X)E(X)   . Note that     d  e  g   (   Q   (  X  )    )    ≤    d  e  g   (   P   (  X  )    )    +   d  e  g   (   E   (  X  )    )     ≤    e  +  k   -  1           d  e  g    Q  X        d  e  g    P  X      d  e  g    E  X              e  k   1      deg(Q(X))\leq{deg(P(X))+deg(E(X))}\leq{e+k-1}   . We also stated that    E   (  X  )       E  X    E(X)   is a polynomial of degree exactly   e   e   e   . Note that    E   (  X  )       E  X    E(X)   is a polynomial following the property that     E   (   α  i   )    =  0        E   subscript  α  i    0    E(\alpha_{i})=0   if and only if     y  i   ≠   P   (   α  i   )         subscript  y  i     P   subscript  α  i      y_{i}\neq P(\alpha_{i})   .We can now state that    E   (  X  )       E  X    E(X)   and    Q   (  X  )       Q  X    Q(X)   satisfy the equation      y  i   E   (   α  i   )    =   Q   (   α  i   )           subscript  y  i   E   subscript  α  i      Q   subscript  α  i      y_{i}E(\alpha_{i})=Q(\alpha_{i})   from the first step of the BW algorithm. If     E   (   α  i   )    =  0        E   subscript  α  i    0    E(\alpha_{i})=0   , then     Q   (   α  i   )    =   P   (   α  i   )   E   (   α  i   )    =    y  i   E   (   α  i   )    =  0          Q   subscript  α  i      P   subscript  α  i   E   subscript  α  i            subscript  y  i   E   subscript  α  i         0     Q(\alpha_{i})=P(\alpha_{i})E(\alpha_{i})=y_{i}E(\alpha_{i})=0   . However whenever     E   (   α  i   )    ≠  0        E   subscript  α  i    0    E(\alpha_{i})\neq 0   , we can easily state that     P   (   α  i   )    =   y  i         P   subscript  α  i     subscript  y  i     P(\alpha_{i})=y_{i}   and therefore also state that     P   (   α  i   )   E   (   α  i   )    =    y  i   E   (   α  i   )          P   subscript  α  i   E   subscript  α  i       subscript  y  i   E   subscript  α  i      P(\alpha_{i})E(\alpha_{i})=y_{i}E(\alpha_{i})   just as we claimed.  This above claim however just reiterates and proves the fact that there exists a pair of polynomials    E   (  X  )       E  X    E(X)   and    Q   (  X  )       Q  X    Q(X)   such that    P   (  X  )       P  X    P(X)   =      Q   (  X  )    /  E    (  X  )           Q  X   E   X    Q(X)/E(X)   . It however does not necessarily guarantee the fact that the algorithm we discussed above would indeed output such a pair of polynomials. We therefore move on to look at another claim that helps establish this fact using the above claim and thereby proving the correctness of the algorithm.  Claim 2: For any two distinct solutions     (    E  1    (  X  )    ,    Q  1    (  X  )    )   ≠   (    E  2    (  X  )    ,    Q  2    (  X  )    )           subscript  E  1   X      subscript  Q  1   X        subscript  E  2   X      subscript  Q  2   X      (E_{1}(X),Q_{1}(X))\neq(E_{2}(X),Q_{2}(X))   that satisfy the first step of the Berlekamp Welch algorithm given above, they will also satisfy the equation       Q  1    (  X  )      E  1    (  X  )     =     Q  2    (  X  )      E  2    (  X  )              subscript  Q  1   X      subscript  E  1   X         subscript  Q  2   X      subscript  E  2   X      {Q_{1}(X)\over E_{1}(X)}={Q_{2}(X)\over E_{2}(X)}     The total degrees of the polynomials     Q  1    (  X  )    E  1    (  X  )        subscript  Q  1   X   subscript  E  1   X    Q_{1}(X)E_{1}(X)   and      Q  2    (  X  )    E  2    (  X  )    ≤     2  e   +  k   -  1          subscript  Q  2   X   subscript  E  2   X         2  e   k   1     Q_{2}(X)E_{2}(X)\leq{2e+k-1}   . We define another polynomial     R   (  X  )    =     Q  1    (  X  )    E  2    (  X  )    -    Q  2    (  X  )    E  1    (  X  )           R  X        subscript  Q  1   X   subscript  E  2   X      subscript  Q  2   X   subscript  E  1   X      R(X)=Q_{1}(X)E_{2}(X)-Q_{2}(X)E_{1}(X)   ....................................(i)  Note that    R   (  X  )       R  X    R(X)   such that     d  e  g   (   R   (  X  )    )    ≤     2  e   +  k   -  1         d  e  g    R  X          2  e   k   1     deg(R(X))\leq{2e+k-1}   . From step 1 of the Berlekamp Welch algorithm we also know that      y  i    E  1    (   α  i   )    =    Q  1    (   α  i   )           subscript  y  i    subscript  E  1    subscript  α  i       subscript  Q  1    subscript  α  i      y_{i}E_{1}(\alpha_{i})=Q_{1}(\alpha_{i})   and     y  i    E  2    (   α  i   )   =   Q  2    (   α  i       fragments   subscript  y  i    subscript  E  2    fragments  normal-(   subscript  α  i   normal-)     subscript  Q  2    fragments  normal-(   subscript  α  i      y_{i}E_{2}(\alpha_{i})=Q_{2}(\alpha_{i}   ) ........…..........(ii)  Now, substituting the values of    Q   (  X  )       Q  X    Q(X)   from equation (ii) into equation (i), we get:     R   (   α  i   )    =     y  i    E  1    (   α  i   )    E  2    (   α  i   )    -    y  i    E  2    (   α  i   )    E  1    (   α  i   )     =  0          R   subscript  α  i         subscript  y  i    subscript  E  1    subscript  α  i    subscript  E  2    subscript  α  i       subscript  y  i    subscript  E  2    subscript  α  i    subscript  E  1    subscript  α  i          0     R(\alpha_{i})=y_{i}E_{1}(\alpha_{i})E_{2}(\alpha_{i})-y_{i}E_{2}(\alpha_{i})E_%
 {1}(\alpha_{i})=0   for    1  ≤  i  ≤  n        1  i       n     1\leq i\leq n   .  Thus, the above polynomial    R   (  X  )       R  X    R(X)   has   n   n   n   roots and     d  e  g   (   R   (  X  )    )    ≤     2  e   +  k   -  1         d  e  g    R  X          2  e   k   1     deg(R(X))\leq{2e+k-1}   which implies that    d  e  g   (   R   (  X  )    )       d  e  g    R  X     deg(R(X))   n because of the upper bound on   e   e   e   . Since    d  e  g   (   R   (  X  )    )       d  e  g    R  X     deg(R(X))   n, we can come to the conclusion that the polynomials     Q  1    (  X  )    E  2    (  X  )        subscript  Q  1   X   subscript  E  2   X    Q_{1}(X)E_{2}(X)   and     Q  2    (  X  )    E  1    (  X  )        subscript  Q  2   X   subscript  E  1   X    Q_{2}(X)E_{1}(X)   agree on more points than their degree, and hence they are identical. Note that since      E  1    (  X  )    ≠  0         subscript  E  1   X   0    E_{1}(X)\neq 0   and      E  2    (  X  )    ≠  0         subscript  E  2   X   0    E_{2}(X)\neq 0   , it can be implied that       Q  1    (  X  )      E  1    (  X  )     =     Q  2    (  X  )      E  2    (  X  )              subscript  Q  1   X      subscript  E  1   X         subscript  Q  2   X      subscript  E  2   X      {Q_{1}(X)\over E_{1}(X)}={Q_{2}(X)\over E_{2}(X)}   as per our initial claim.  Thus based on the above claims, we can safely state that the output of the Berlekamp Welch algorithm, when outputting the polynomial    P   (  X  )       P  X    P(X)   is correct.  We can now claim that the algorithm can be implemented such that it has a running time of    O   (   n  3   )       O   superscript  n  3     O(n^{3})   . This can be proved as follows: In Step 1 of the algorithm, the polynomials    Q   (  X  )       Q  X    Q(X)   and    E   (  X  )       E  X    E(X)   have    e  +  k      e  k    e+k   and    e  +  1      e  1    e+1   unknown values respectively and the constraints      y  i   E   (   α  i   )    =   Q   (   α  i   )           subscript  y  i   E   subscript  α  i      Q   subscript  α  i      y_{i}E(\alpha_{i})=Q(\alpha_{i})   for all    1  ≤  i  ≤  n        1  i       n     1\leq i\leq n   acts as a linear equation with these unknowns. We therefore get a system of   n   n   n   linear equations in     2  e   +  k  +  1        2  e   k  1    2e+k+1   n + 2 unknowns. Using our first claim, this system of equations has a solution since the degree of polynomial    E   (  X  )       E  X    E(X)   is   e   e   e   . This can be solved in    O   (   n  3   )       O   superscript  n  3     O(n^{3})   time, by say Gaussian elimination. Finally, we can note that Step 2 of the algorithm can also be implemented in time    O   (   n  3   )       O   superscript  n  3     O(n^{3})   by "long division" method. Hence we can state that the Berlekamp Welch algorithm can be used to uniquely decode any     [  n  ,  k  ]   q     subscript   n  k   q    [n,k]_{q}   Reed–Solomon code in    O   (   n  3   )       O   superscript  n  3     O(n^{3})   time for a maximum of      n  -  k   +  1   2          n  k   1   2    {n-k+1}\over 2   errors.  Example  thumb|upright=1.5|The error locator polynomial serves to "neutralize" errors in P by making Q zero at those points, so that the system of linear equations is not affected by the inaccuracy in the input.  Consider a simple example where a redundant set of points are used to represent the line    y  =   5  -  x       y    5  x     y=5-x   , and one of the points is incorrect. The points that the algorithm gets as an input are     (  1  ,  4  )   ,   (  2  ,  3  )   ,   (  3  ,  4  )   ,   (  4  ,  1  )       1  4    2  3    3  4    4  1     (1,4),(2,3),(3,4),(4,1)   , where    (  3  ,  4  )     3  4    (3,4)   is the defective point. The algorithm must solve the following system of equations:      Q   (  1  )       Q  1    \displaystyle Q(1)    Given a solution   Q   Q   Q   and   E   E   E   to this system of equations, it is evident that at any of the points    x  =   1  ,  2  ,  3  ,  4       x   1  2  3  4     x=1,2,3,4   one of the following must be true: either     Q   (   x  i   )    =   E   (   x  i   )    =  0          Q   subscript  x  i      E   subscript  x  i         0     Q(x_{i})=E(x_{i})=0   , or     P   (   x  i   )    =    Q   (   x  i   )     E   (   x  i   )     =   y  i           P   subscript  x  i        Q   subscript  x  i      E   subscript  x  i           subscript  y  i      P(x_{i})={Q(x_{i})\over E(x_{i})}=y_{i}   . Since   E   E   E   is defined as only having a degree of one, the former can only be true in one point. Therefore,    P   (   x  i   )       P   subscript  x  i     P(x_{i})   must equal    y  i     subscript  y  i    y_{i}   at the three other points.  Letting     E   (  x  )    =   x  +   e  0          E  x     x   subscript  e  0      E(x)=x+e_{0}   and     Q   (  x  )    =    q  0   +    q  1   x   +    q  2    x  2           Q  x      subscript  q  0      subscript  q  1   x      subscript  q  2    superscript  x  2       Q(x)=q_{0}+q_{1}x+q_{2}x^{2}   and bringing    E   (  x  )       E  x    E(x)   to the left, we can rewrite the system thus:      q  0     subscript  q  0    \displaystyle q_{0}    This system can be solved through Gaussian elimination , and gives the values:        q  0   =   -  15    ,     q  1   =  8   ,     q  2   =   -  1    ,    e  0   =   -  3         formulae-sequence     subscript  q  0     15     formulae-sequence     subscript  q  1   8    formulae-sequence     subscript  q  2     1       subscript  e  0     3        q_{0}=-15,q_{1}=8,q_{2}=-1,e_{0}=-3    Thus,      Q   (  x  )    =     -   x  2    +   8  x    -  15    ,    E   (  x  )    =   x  -  3       formulae-sequence      Q  x          superscript  x  2      8  x    15        E  x     x  3      Q(x)=-x^{2}+8x-15,E(x)=x-3   . Dividing the two gives:        Q   (  x  )     E   (  x  )     =   P   (  x  )    =   5  -  x             Q  x     E  x      P  x          5  x      {Q(x)\over E(x)}=P(x)=5-x        5  -  x      5  x    5-x   fits three of the four points given, so it is the most likely to be the original polynomial.  See also   BCH code  Berlekamp–Massey algorithm  Reed–Solomon error correction   References  External links   MIT Lecture Notes on Essential Coding Theory – Dr. Madhu Sudan  University at Buffalo Lecture Notes on Coding Theory – Dr. Atri Rudra  Algebraic Codes on Lines, Planes and Curves, An Engineering Approach – Richard E. Blahut  Welch Berlekamp Decoding of Reed–Solomon Codes – L. R. Welch   – The patent by Lloyd R. Welch and Elewyn R. Berlekamp   "  Category:Finite fields  Category:Coding theory  Category:Information theory  Category:Error detection and correction     ↩  . Previous publisher McGraw–Hill, New York, NY. ↩  ↩  ↩  Highly resilient correctors for polynomials – Peter Gemmel and Madhu Sudan's Exposition. ↩  A provable example of the linearization method – Dick Lipton ↩  ↩     