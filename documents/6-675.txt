   Fuzzy clustering      Fuzzy clustering   Data clustering is the process of dividing data elements into classes or clusters so that items in the same class are as similar as possible, and items in different classes are as dissimilar as possible. Depending on the nature of the data and the purpose for which clustering is being used, different measures of similarity may be used to place items into classes, where the similarity measure controls how the clusters are formed. Some examples of measures that can be used as in clustering include distance, connectivity, and intensity.  In hard clustering , data is divided into distinct clusters, where each data element belongs to exactly one cluster. In fuzzy clustering (also referred to as soft clustering ), data elements can belong to more than one cluster, and associated with each element is a set of membership levels. These indicate the strength of the association between that data element and a particular cluster. Fuzzy clustering is a process of assigning these membership levels, and then using them to assign data elements to one or more clusters.  One of the most widely used fuzzy clustering algorithms is the Fuzzy C-Means (FCM) Algorithm (Bezdek 1981). The FCM algorithm attempts to partition a finite collection of   n   n   n   elements    X  =   {   ğ±  1   ,  â€¦  ,   ğ±  n   }       X    subscript  ğ±  1   normal-â€¦   subscript  ğ±  n      X=\{\mathbf{x}_{1},...,\mathbf{x}_{n}\}   into a collection of c fuzzy clusters with respect to some given criterion. Given a finite set of data, the algorithm returns a list of   c   c   c   cluster centres    C  =   {   ğœ  1   ,  â€¦  ,   ğœ  c   }       C    subscript  ğœ  1   normal-â€¦   subscript  ğœ  c      C=\{\mathbf{c}_{1},...,\mathbf{c}_{c}\}   and a partition matrix     W  =   w   i  ,  j    âˆˆ   [  0  ,  1  ]    ,    i  =   1  ,  â€¦  ,  n    ,   j  =   1  ,  â€¦  ,  c        formulae-sequence      W   subscript  w   i  j          0  1      formulae-sequence    i   1  normal-â€¦  n      j   1  normal-â€¦  c       W=w_{i,j}\in[0,1],\;i=1,...,n,\;j=1,...,c   , where each element    w   i  j      subscript  w    i  j     w_{ij}   tells the degree to which element    ğ±  i     subscript  ğ±  i    \mathbf{x}_{i}   belongs to cluster    ğœ  j     subscript  ğœ  j    \mathbf{c}_{j}   . Like the K-means clustering , the FCM aims to minimize an objective function:          arg   min   ğ¶     âˆ‘   i  =  1   n     âˆ‘   j  =  1   c     w   i  j   m     âˆ¥    ğ±  i   -   ğœ  j    âˆ¥   2       ,       C    arg  min      superscript   subscript     i  1    n     superscript   subscript     j  1    c      superscript   subscript  w    i  j    m    superscript   norm     subscript  ğ±  i    subscript  ğœ  j     2        \underset{C}{\operatorname{arg\,min}}\sum_{i=1}^{n}\sum_{j=1}^{c}w_{ij}^{m}%
 \left\|\mathbf{x}_{i}-\mathbf{c}_{j}\right\|^{2},     where:        w   i  j    =   1    âˆ‘   k  =  1   c     (    âˆ¥    ğ±  i   -   ğœ  j    âˆ¥    âˆ¥    ğ±  i   -   ğœ  k    âˆ¥    )    2   m  -  1        .       subscript  w    i  j      1    superscript   subscript     k  1    c    superscript     norm     subscript  ğ±  i    subscript  ğœ  j      norm     subscript  ğ±  i    subscript  ğœ  k        2    m  1         w_{ij}=\frac{1}{\sum_{k=1}^{c}\left(\frac{\left\|\mathbf{x}_{i}-\mathbf{c}_{j}%
 \right\|}{\left\|\mathbf{x}_{i}-\mathbf{c}_{k}\right\|}\right)^{\frac{2}{m-1}}}.     This differs from the k -means objective function by the addition of the membership values    w   i  j      subscript  w    i  j     w_{ij}   and the fuzzifier    m  âˆˆ  R      m  R    m\in R   , with    m  â‰¥  1      m  1    m\geq 1   . The fuzzifier   m   m   m   determines the level of cluster fuzziness. A large   m   m   m   results in smaller memberships    w   i  j      subscript  w    i  j     w_{ij}   and hence, fuzzier clusters. In the limit    m  =  1      m  1    m=1   , the memberships    w   i  j      subscript  w    i  j     w_{ij}   converge to 0 or 1, which implies a crisp partitioning. In the absence of experimentation or domain knowledge,   m   m   m   is commonly set to 2.  Fuzzy c-means clustering  In fuzzy clustering, every point has a degree of belonging to clusters, as in fuzzy logic , rather than belonging completely to just one cluster. Thus, points on the edge of a cluster, may be in the cluster to a lesser degree than points in the center of cluster. An overview and comparison of different fuzzy clustering algorithms is available. 1  Any point x has a set of coefficients giving the degree of being in the k th cluster w k ( x ). With fuzzy c -means, the centroid of a cluster is the mean of all points, weighted by their degree of belonging to the cluster:        c  k   =     âˆ‘  x     w  k     (  x  )   m   x      âˆ‘  x     w  k     (  x  )   m       .       subscript  c  k       subscript   x      subscript  w  k    superscript  x  m   x      subscript   x      subscript  w  k    superscript  x  m        c_{k}={{\sum_{x}{w_{k}(x)}^{m}x}\over{\sum_{x}{w_{k}(x)}^{m}}}.     The degree of belonging, w k ( x ), is related inversely to the distance from x to the cluster center as calculated on the previous pass. It also depends on a parameter m that controls how much weight is given to the closest center. The fuzzy c -means algorithm is very similar to the k -means algorithm : 2   Choose a number of clusters .  Assign randomly to each point coefficients for being in the clusters.  Repeat until the algorithm has converged (that is, the coefficients' change between two iterations is no more than   Îµ   Îµ   \varepsilon   , the given sensitivity threshold) :  Compute the centroid for each cluster, using the formula above.  For each point, compute its coefficients of being in the clusters, using the formula above.    The algorithm minimizes intra-cluster variance as well, but has the same problems as k -means; the minimum is a local minimum, and the results depend on the initial choice of weights.  Using a mixture of Gaussians along with the expectation-maximization algorithm is a more statistically formalized method which includes some of these ideas: partial membership in classes.  Another algorithm closely related to Fuzzy C-Means is Soft K-means .  Fuzzy c-means has been a very important tool for image processing in clustering objects in an image. In the 70's, mathematicians introduced the spatial term into the FCM algorithm to improve the accuracy of clustering under noise. 3  See also   FLAME Clustering  Cluster Analysis  Expectation-maximization algorithm (a similar, but more statistically formalized method)   References  External links   Fuzzy Clustering in Wolfram Research  Extended Fuzzy Clustering Algorithms by Kaymak, U. and Setnes, M.  ''Fuzzy Clustering in C++ and Boost by Antonio Gulli  Concise description with examples   "  Category:Data clustering algorithms     Nock, R. and Nielsen, F. (2006) "On Weighting Clustering" , IEEE Trans. on Pattern Analysis and Machine Intelligence, 28 (8), 1â€“13 â†©  â†©  . â†©     