   Conditional probability distribution      Conditional probability distribution   In probability theory and statistics , given two jointly distributed random variables  X and Y , the conditional probability distribution of Y given X is the probability distribution of Y when X is known to be a particular value; in some cases the conditional probabilities may be expressed as functions containing the unspecified value x of X as a parameter. In case that both "X" and "Y" are categorical variables , a conditional probability table is typically used to represent the conditional probability. The conditional distribution contrasts with the marginal distribution of a random variable, which is its distribution without reference to the value of the other variable.  If the conditional distribution of Y given X is a continuous distribution , then its probability density function is known as the conditional density function . The properties of a conditional distribution, such as the moments , are often referred to by corresponding names such as the conditional mean and conditional variance .  More generally, one can refer to the conditional distribution of a subset of a set of more than two variables; this conditional distribution is contingent on the values of all the remaining variables, and if more than one variable is included in the subset then this conditional distribution is the conditional joint distribution of the included variables.  Discrete distributions  For discrete random variables , the conditional probability mass function of Y given the occurrence of the value x of X can be written according to its definition as:       p  Y    (  y  ∣  X  =  x  )   =  P   (  Y  =  y  ∣  X  =  x  )   =    P   (  X  =   x   ∩  Y  =  y  )     P   (  X  =  x  )     .     fragments   subscript  p  Y    fragments  normal-(  y  normal-∣  X   x  normal-)    P   fragments  normal-(  Y   y  normal-∣  X   x  normal-)       fragments  P   fragments  normal-(  X   x   Y   y  normal-)     fragments  P   fragments  normal-(  X   x  normal-)     normal-.    p_{Y}(y\mid X=x)=P(Y=y\mid X=x)=\frac{P(X=x\ \cap Y=y)}{P(X=x)}.     Due to the occurrence of    P   (  X  =  x  )      fragments  P   fragments  normal-(  X   x  normal-)     P(X=x)   in a denominator, this is defined only for non-zero (hence strictly positive)    P   (  X  =  x  )   .     fragments  P   fragments  normal-(  X   x  normal-)   normal-.    P(X=x).     The relation with the probability distribution of X given Y is:      P   (  Y  =  y  ∣  X  =  x  )   P   (  X  =  x  )   =  P   (  X  =   x   ∩  Y  =  y  )   =  P   (  X  =  x  ∣  Y  =  y  )   P   (  Y  =  y  )   .     fragments  P   fragments  normal-(  Y   y  normal-∣  X   x  normal-)   P   fragments  normal-(  X   x  normal-)    P   fragments  normal-(  X   x   Y   y  normal-)    P   fragments  normal-(  X   x  normal-∣  Y   y  normal-)   P   fragments  normal-(  Y   y  normal-)   normal-.    P(Y=y\mid X=x)P(X=x)=P(X=x\ \cap Y=y)=P(X=x\mid Y=y)P(Y=y).     Continuous distributions  Similarly for continuous random variables , the conditional probability density function of Y given the occurrence of the value x of X can be written as       f  Y    (  y  ∣  X  =  x  )   =     f   X  ,  Y     (  x  ,  y  )      f  X    (  x  )     ,     fragments   subscript  f  Y    fragments  normal-(  y  normal-∣  X   x  normal-)         subscript  f   X  Y     x  y       subscript  f  X   x    normal-,    f_{Y}(y\mid X=x)=\frac{f_{X,Y}(x,y)}{f_{X}(x)},     where f X,Y ( x, y'') gives the joint density of X and Y , while f X (x'') gives the marginal density for X . Also in this case it is necessary that      f  X    (  x  )    >  0         subscript  f  X   x   0    f_{X}(x)>0   .  The relation with the probability distribution of X given Y is given by:       f  Y    (  y  ∣  X  =  x  )    f  X    (  x  )   =   f   X  ,  Y     (  x  ,  y  )   =   f  X    (  x  ∣  Y  =  y  )    f  Y    (  y  )   .     fragments   subscript  f  Y    fragments  normal-(  y  normal-∣  X   x  normal-)    subscript  f  X    fragments  normal-(  x  normal-)     subscript  f   X  Y     fragments  normal-(  x  normal-,  y  normal-)     subscript  f  X    fragments  normal-(  x  normal-∣  Y   y  normal-)    subscript  f  Y    fragments  normal-(  y  normal-)   normal-.    f_{Y}(y\mid X=x)f_{X}(x)=f_{X,Y}(x,y)=f_{X}(x\mid Y=y)f_{Y}(y).     The concept of the conditional distribution of a continuous random variable is not as intuitive as it might seem: Borel's paradox shows that conditional probability density functions need not be invariant under coordinate transformations.  Relation to independence  Random variables X , Y are independent if and only if the conditional distribution of Y given X is, for all possible realizations of X , equal to the unconditional distribution of Y . For discrete random variables this means P ( Y = y | X = x ) = P ( Y = y ) for all relevant x and y . For continuous random variables X and Y , having a joint density function , it means f Y ( y | X=x ) = f Y ( y ) for all relevant x and y.  Properties  Seen as a function of y for given x , P ( Y = y | X = x ) is a probability and so the sum over all y (or integral if it is a conditional probability density) is 1. Seen as a function of x for given y , it is a likelihood function , so that the sum over all x need not be 1.  Measure-Theoretic Formulation  Let    (  Ω  ,  ℱ  ,  P  )     normal-Ω  ℱ  P    (\Omega,\mathcal{F},P)   be a probability space,    𝒢  ⊆  ℱ      𝒢  ℱ    \mathcal{G}\subseteq\mathcal{F}   a   σ   σ   \sigma   -field in   ℱ   ℱ   \mathcal{F}   , and    X  :   Ω  →  ℝ      normal-:  X   normal-→  normal-Ω  ℝ     X:\Omega\to\mathbb{R}   a real-valued random variable (measurable with respect to the Borel   σ   σ   \sigma   -field    ℛ  1     superscript  ℛ  1    \mathcal{R}^{1}   on   ℝ   ℝ   \mathbb{R}   ). It can be shown that there exists 1 a function    μ  :     ℛ  1   ×  Ω   →  ℝ      normal-:  μ   normal-→     superscript  ℛ  1   normal-Ω   ℝ     \mu:\mathcal{R}^{1}\times\Omega\to\mathbb{R}   such that    μ   (  ⋅  ,  ω  )       μ   normal-⋅  ω     \mu(\cdot,\omega)   is a probability measure on    ℛ  1     superscript  ℛ  1    \mathcal{R}^{1}   for each    ω  ∈  Ω      ω  normal-Ω    \omega\in\Omega   (i.e., it is regular ) and    μ   (  H  ,  ⋅  )   =  P   (  X  ∈  H  |  𝒢  )      fragments  μ   fragments  normal-(  H  normal-,  normal-⋅  normal-)    P   fragments  normal-(  X   H  normal-|  G  normal-)     \mu(H,\cdot)=P(X\in H|\mathcal{G})   (almost surely) for every    H  ∈   ℛ  1       H   superscript  ℛ  1     H\in\mathcal{R}^{1}   . For any    ω  ∈  Ω      ω  normal-Ω    \omega\in\Omega   , the function     μ   (  ⋅  ,  ω  )    :    ℛ  1   →  ℝ      normal-:    μ   normal-⋅  ω     normal-→   superscript  ℛ  1   ℝ     \mu(\cdot,\omega):\mathcal{R}^{1}\to\mathbb{R}   is called a conditional probability distribution of   X   X   X   given   𝒢   𝒢   \mathcal{G}   . In this case,      E   [  X  |  𝒢  ]   =   ∫   -  ∞   ∞    x   μ   (  d  x  ,  ⋅  )      fragments  E   fragments  normal-[  X  normal-|  G  normal-]     superscript   subscript          x  μ   fragments  normal-(  d  x  normal-,  normal-⋅  normal-)     E[X|\mathcal{G}]=\int_{-\infty}^{\infty}x\,\mu(dx,\cdot)   almost surely.  Relation to conditional expectation  For any event    A  ∈  𝒜  ⊇  ℬ        A  𝒜    superset-of-or-equals    ℬ     A\in\mathcal{A}\supseteq\mathcal{B}   , define the indicator function :        𝟏  A    (  ω  )    =   {     1       if  ω   ∈  A   ,       0       if  ω   ∉  A   ,              subscript  1  A   ω    cases  1      if  ω   A   0      if  ω   A      \mathbf{1}_{A}(\omega)=\begin{cases}1&\text{if }\omega\in A,\\
 0&\text{if }\omega\notin A,\end{cases}     which is a random variable. Note that the expectation of this random variable is equal to the probability of A itself:        E   (   𝟏  A   )    =   P   (  A  )     .       normal-E   subscript  1  A     normal-P  A     \operatorname{E}(\mathbf{1}_{A})=\operatorname{P}(A).\;     Then the conditional probability given   ℬ   ℬ   \scriptstyle\mathcal{B}    is a function    P   (  ⋅  |  ℬ  )   :  𝒜  ×  Ω  →   (  0  ,  1  )      fragments  normal-P   fragments  normal-(  normal-⋅  normal-|  B  normal-)   normal-:  A   Ω  normal-→   fragments  normal-(  0  normal-,  1  normal-)     \scriptstyle\operatorname{P}(\cdot|\mathcal{B}):\mathcal{A}\times\Omega\to(0,1)   such that    P   (  A  |  ℬ  )      normal-P  A  ℬ    \scriptstyle\operatorname{P}(A|\mathcal{B})   is the conditional expectation of the indicator function for A :       P   (  A  |  ℬ  )    =   E   (   𝟏  A   |  ℬ  )         normal-P  A  ℬ    normal-E   subscript  1  A   ℬ     \operatorname{P}(A|\mathcal{B})=\operatorname{E}(\mathbf{1}_{A}|\mathcal{B})\;     In other words,    P   (  A  |  ℬ  )      normal-P  A  ℬ    \scriptstyle\operatorname{P}(A|\mathcal{B})   is a   ℬ   ℬ   \scriptstyle\mathcal{B}   -measurable function satisfying          ∫  B     P   (  A  |  ℬ  )     (  ω  )    d   P   (  ω  )       =    P   (   A  ∩  B   )    for all      A  ∈  𝒜   ,   B  ∈  ℬ     .     formulae-sequence      subscript   B      normal-P  A  ℬ   ω   normal-d   normal-P  ω        normal-P    A  B    for all     formulae-sequence    A  𝒜     B  ℬ      \int_{B}\operatorname{P}(A|\mathcal{B})(\omega)\,\operatorname{d}\operatorname%
 {P}(\omega)=\operatorname{P}(A\cap B)\qquad\text{for all}\quad A\in\mathcal{A}%
 ,B\in\mathcal{B}.     A conditional probability is regular if    P   (  ⋅  |  ℬ  )    (  ω  )      fragments  normal-P   fragments  normal-(  normal-⋅  normal-|  B  normal-)    fragments  normal-(  ω  normal-)     \scriptstyle\operatorname{P}(\cdot|\mathcal{B})(\omega)   is also a probability measure for all ω ∈ Ω . An expectation of a random variable with respect to a regular conditional probability is equal to its conditional expectation.   For the trivial sigma algebra    ℬ  =   {  ∅  ,  Ω  }       ℬ    normal-Ω     \mathcal{B}=\{\emptyset,\Omega\}   the conditional probability is a constant function,      P   (  A  |   {  ∅  ,  Ω  }   )    ≡   P   (  A  )     .       normal-P  A    normal-Ω     normal-P  A     \operatorname{P}\!\left(A|\{\emptyset,\Omega\}\right)\equiv\operatorname{P}(A).       For    A  ∈  ℬ      A  ℬ    A\in\mathcal{B}   , as outlined above,      P   (  A  |  ℬ  )    =   1  A    .       normal-P  A  ℬ    subscript  1  A     \operatorname{P}(A|\mathcal{B})=1_{A}.   .   See also   Conditioning (probability)  Conditional probability  Regular conditional probability  Bayes' theorem   Notes  References     "  Category:Probability theory  Category:Types of probability distributions     Billingsley (1995) , p. 439 ↩     