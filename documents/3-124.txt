   F-distribution      F-distribution   {(d_1\,x+d_2)^{d_1+d_2}}}} {x\,\mathrm{B}\!\left(\frac{d_1}{2},\frac{d_2}{2}\right)}\!|  cdf        =      I     d  1   x      d  1   x   +   d  2       (    d  1   2   ,    d  2   2   )        subscript  I       subscript  d  1   x        subscript  d  1   x    subscript  d  2          subscript  d  1   2      subscript  d  2   2      I_{\frac{d_{1}x}{d_{1}x+d_{2}}}\left(\tfrac{d_{1}}{2},\tfrac{d_{2}}{2}\right)    |  mean       =       d  2     d  2   -  2         subscript  d  2      subscript  d  2   2     \frac{d_{2}}{d_{2}-2}\!     for d 2 > 2|  median     =|  mode       =         d  1   -  2    d  1       d  2     d  2   +  2             subscript  d  1   2    subscript  d  1       subscript  d  2      subscript  d  2   2      \frac{d_{1}-2}{d_{1}}\;\frac{d_{2}}{d_{2}+2}     for d 1 > 2|  variance   =        2     d  2  2     (     d  1   +   d  2    -  2   )      d  1     (    d  2   -  2   )   2    (    d  2   -  4   )           2   superscript   subscript  d  2   2        subscript  d  1    subscript  d  2    2       subscript  d  1    superscript     subscript  d  2   2   2      subscript  d  2   4      \frac{2\,d_{2}^{2}\,(d_{1}+d_{2}-2)}{d_{1}(d_{2}-2)^{2}(d_{2}-4)}\!     for d 2 > 4|  skewness   =        (     2   d  1    +   d  2    -  2   )     8   (    d  2   -  4   )        (    d  2   -  6   )      d  1    (     d  1   +   d  2    -  2   )                   2   subscript  d  1     subscript  d  2    2       8     subscript  d  2   4           subscript  d  2   6        subscript  d  1        subscript  d  1    subscript  d  2    2        \frac{(2d_{1}+d_{2}-2)\sqrt{8(d_{2}-4)}}{(d_{2}-6)\sqrt{d_{1}(d_{1}+d_{2}-2)}}\!     for d 2 > 6|  kurtosis   = see  text |  entropy    =|  mgf        =''does not exist, raw moments defined in text and in 1 2 ''|  char       = see  text |}}  The F -distribution , also known as Snedecor's F distribution or the Fisher–Snedecor distribution (after Ronald Fisher and George W. Snedecor ) is, in probability theory and statistics , a continuous probability distribution . 3 4 5 6 The F -distribution arises frequently as the null distribution of a test statistic , most notably in the analysis of variance ; see F -test .  Definition  If a random variable  X has an F -distribution with parameters d 1 and d 2 , we write X ~ F( d 1 , d 2 ). Then the probability density function (pdf) for X is given by      f   (  x  ;   d  1   ,   d  2   )       f   x   subscript  d  1    subscript  d  2      \displaystyle f(x;d_{1},d_{2})     for real  x ≥ 0. Here   B   normal-B   \mathrm{B}   is the beta function . In many applications, the parameters d 1 and d 2 are positive integers , but the distribution is well-defined for positive real values of these parameters.  The cumulative distribution function is        F   (  x  ;   d  1   ,   d  2   )    =    I     d  1   x      d  1   x   +   d  2       (     d  1   2    ,     d  2   2    )     ,        F   x   subscript  d  1    subscript  d  2        subscript  I       subscript  d  1   x        subscript  d  1   x    subscript  d  2          subscript  d  1   2      subscript  d  2   2       F(x;d_{1},d_{2})=I_{\frac{d_{1}x}{d_{1}x+d_{2}}}\left(\tfrac{d_{1}}{2},\tfrac{%
 d_{2}}{2}\right),     where I is the regularized incomplete beta function .  The expectation, variance, and other details about the F( d 1 , d 2 ) are given in the sidebox; for d 2 > 8, the excess kurtosis is       γ  2   =   12      d  1    (    5   d  2    -  22   )    (     d  1   +   d  2    -  2   )    +    (    d  2   -  4   )     (    d  2   -  2   )   2       d  1    (    d  2   -  6   )    (    d  2   -  8   )    (     d  1   +   d  2    -  2   )           subscript  γ  2     12         subscript  d  1       5   subscript  d  2    22        subscript  d  1    subscript  d  2    2         subscript  d  2   4    superscript     subscript  d  2   2   2        subscript  d  1      subscript  d  2   6      subscript  d  2   8        subscript  d  1    subscript  d  2    2        \gamma_{2}=12\frac{d_{1}(5d_{2}-22)(d_{1}+d_{2}-2)+(d_{2}-4)(d_{2}-2)^{2}}{d_{%
 1}(d_{2}-6)(d_{2}-8)(d_{1}+d_{2}-2)}   .  The k -th moment of an F( d 1 , d 2 ) distribution exists and is finite only when 2 k 2 and it is equal to 7        μ  X    (  k  )    =     (    d  2    d  1    )   k     Γ   (     d  1   2   +  k   )     Γ   (    d  1   2   )       Γ   (     d  2   2   -  k   )     Γ   (    d  2   2   )             subscript  μ  X   k      superscript     subscript  d  2    subscript  d  1    k       normal-Γ       subscript  d  1   2   k      normal-Γ     subscript  d  1   2         normal-Γ       subscript  d  2   2   k      normal-Γ     subscript  d  2   2        \mu_{X}(k)=\left(\frac{d_{2}}{d_{1}}\right)^{k}\frac{\Gamma\left(\tfrac{d_{1}}%
 {2}+k\right)}{\Gamma\left(\tfrac{d_{1}}{2}\right)}\frac{\Gamma\left(\tfrac{d_{%
 2}}{2}-k\right)}{\Gamma\left(\tfrac{d_{2}}{2}\right)}     The F -distribution is a particular parametrization of the beta prime distribution , which is also called the beta distribution of the second kind.  The characteristic function is listed incorrectly in many standard references (e.g., 8 ). The correct expression 9 is        φ    d  1   ,   d  2    F    (  s  )    =     Γ   (     d  1   +   d  2    2   )     Γ   (    d  2   2   )      U    (    d  1   2   ,   1  -    d  2   2    ,   -     d  2    d  1    ı  s    )           subscript   superscript  φ  F     subscript  d  1    subscript  d  2     s         normal-Γ       subscript  d  1    subscript  d  2    2      normal-Γ     subscript  d  2   2     U      subscript  d  1   2     1     subscript  d  2   2           subscript  d  2    subscript  d  1    ı  s        \varphi^{F}_{d_{1},d_{2}}(s)=\frac{\Gamma(\frac{d_{1}+d_{2}}{2})}{\Gamma(%
 \tfrac{d_{2}}{2})}U\!\left(\frac{d_{1}}{2},1-\frac{d_{2}}{2},-\frac{d_{2}}{d_{%
 1}}\imath s\right)     where U ( a , b , z ) is the confluent hypergeometric function of the second kind.  Characterization  A random variate of the F -distribution with parameters d 1 and d 2 arises as the ratio of two appropriately scaled chi-squared variates: 10      X  =     U  1   /   d  1      U  2   /   d  2         X       subscript  U  1    subscript  d  1       subscript  U  2    subscript  d  2       X=\frac{U_{1}/d_{1}}{U_{2}/d_{2}}     where   U 1 and U 2 have chi-squared distributions with d 1 and d 2  degrees of freedom respectively, and  U 1 and U 2 are independent .   In instances where the F -distribution is used, for example in the analysis of variance , independence of U 1 and U 2 might be demonstrated by applying Cochran's theorem .  Equivalently, the random variable of the F -distribution may also be written      X  =      s  1  2    σ  1  2     /    s  2  2    σ  2  2         X       superscript   subscript  s  1   2    superscript   subscript  σ  1   2       superscript   subscript  s  2   2    superscript   subscript  σ  2   2       X=\frac{s_{1}^{2}}{\sigma_{1}^{2}}\;/\;\frac{s_{2}^{2}}{\sigma_{2}^{2}}     where s 1 2 and s 2 2 are the sums of squares S 1 2 and S 2 2 from two normal processes with variances σ 1 2 and σ 2 2 divided by the corresponding number of χ 2 degrees of freedom, d 1 and d 2 respectively.  In a frequentist context, a scaled F -distribution therefore gives the probability p ( s 1 2 / s 2 2 | σ 1 2 , σ 2 2 ), with the F -distribution itself, without any scaling, applying where σ 1 2 is being taken equal to σ 2 2 . This is the context in which the F -distribution most generally appears in F -tests : where the null hypothesis is that two independent normal variances are equal, and the observed sums of some appropriately selected squares are then examined to see whether their ratio is significantly incompatible with this null hypothesis.  The quantity X has the same distribution in Bayesian statistics, if an uninformative rescaling-invariant Jeffreys prior is taken for the prior probabilities of σ 1 2 and σ 2 2 . 11 In this context, a scaled F -distribution thus gives the posterior probability p (σ 2 2 /σ 1 2 | s 1 2 , s 2 2 ), where now the observed sums s 1 2 and s 2 2 are what are taken as known.  Differential equation  The probability density function of the F -distribution is a solution of the following differential equation :      {         2  x   (     d  1   x   +   d  2    )    f  ′    (  x  )    +    (      2   d  1   x   +    d  2    d  1   x    -    d  2    d  1     +   2   d  2     )   f   (  x  )     =  0   ,         f   (  1  )    =     d  1    d  1   2     d  2    d  2   2     (   d  1   +   d  2   )       1  2    (    -   d  1    -   d  2    )       B   (    d  1   2   ,    d  2   2   )         }             2  x       subscript  d  1   x    subscript  d  2     superscript  f  normal-′   x             2   subscript  d  1   x      subscript  d  2    subscript  d  1   x       subscript  d  2    subscript  d  1       2   subscript  d  2     f  x    0         f  1      fragments   superscript   subscript  d  1      subscript  d  1   2     superscript   subscript  d  2      subscript  d  2   2     fragments  normal-(   subscript  d  1     subscript  d  2   normal-)        1  2        subscript  d  1     subscript  d  2         B      subscript  d  1   2      subscript  d  2   2           \left\{\begin{array}[]{l}2x\left(d_{1}x+d_{2}\right)f^{\prime}(x)+\left(2d_{1}%
 x+d_{2}d_{1}x-d_{2}d_{1}+2d_{2}\right)f(x)=0,\\
 f(1)=\frac{d_{1}^{\frac{d_{1}}{2}}d_{2}^{\frac{d_{2}}{2}}\left(d_{1}+d_{2}%
 \right){}^{\frac{1}{2}\left(-d_{1}-d_{2}\right)}}{B\left(\frac{d_{1}}{2},\frac%
 {d_{2}}{2}\right)}\end{array}\right\}     Generalization  A generalization of the (central) F -distribution is the noncentral F -distribution .  Related distributions and properties   If    X  ∼   χ   d  1   2      similar-to  X   subscript   superscript  χ  2    subscript  d  1      X\sim\chi^{2}_{d_{1}}   and    Y  ∼   χ   d  2   2      similar-to  Y   subscript   superscript  χ  2    subscript  d  2      Y\sim\chi^{2}_{d_{2}}   are independent , then      X  /   d  1     Y  /   d  2     ∼   F   (   d  1   ,   d  2   )       similar-to      X   subscript  d  1      Y   subscript  d  2       normal-F    subscript  d  1    subscript  d  2       \frac{X/d_{1}}{Y/d_{2}}\sim\mathrm{F}(d_{1},d_{2})     If    X  ∼   Beta   (    d  1   /  2   ,    d  2   /  2   )       similar-to  X   Beta     subscript  d  1   2      subscript  d  2   2      X\sim\operatorname{Beta}(d_{1}/2,d_{2}/2)   ( Beta distribution ) then       d  2   X     d  1    (   1  -  X   )     ∼   F   (   d  1   ,   d  2   )       similar-to       subscript  d  2   X      subscript  d  1     1  X      normal-F   subscript  d  1    subscript  d  2      \frac{d_{2}X}{d_{1}(1-X)}\sim\operatorname{F}(d_{1},d_{2})     Equivalently, if X ~ F( d 1 , d 2 ), then        d  1   X   /   d  2     1  +     d  1   X   /   d  2      ∼   Beta   (    d  1   /  2   ,    d  2   /  2   )       similar-to         subscript  d  1   X    subscript  d  2      1       subscript  d  1   X    subscript  d  2       Beta     subscript  d  1   2      subscript  d  2   2      \frac{d_{1}X/d_{2}}{1+d_{1}X/d_{2}}\sim\operatorname{Beta}(d_{1}/2,d_{2}/2)   .  If X ~ F( d 1 , d 2 ) then    Y  =    lim    d  2   →  ∞      d  1   X        Y    subscript    normal-→   subscript  d  2         subscript  d  1   X      Y=\lim_{d_{2}\to\infty}d_{1}X   has the chi-squared distribution     χ   d  1   2     subscript   superscript  χ  2    subscript  d  1     \chi^{2}_{d_{1}}     F( d 1 , d 2 ) is equivalent to the scaled Hotelling's T-squared distribution       d  2     d  1    (     d  1   +   d  2    -  1   )       T  2    (   d  1   ,     d  1   +   d  2    -  1   )           subscript  d  2      subscript  d  1        subscript  d  1    subscript  d  2    1       superscript  normal-T  2    subscript  d  1        subscript  d  1    subscript  d  2    1      \frac{d_{2}}{d_{1}(d_{1}+d_{2}-1)}\operatorname{T}^{2}(d_{1},d_{1}+d_{2}-1)   .  If X ~ F( d 1 , d 2 ) then X −1 ~ F( d 2 , d 1 ).  If X ~ t( n ) then          X  2   ∼   F   (  1  ,  n  )       similar-to   superscript  X  2    normal-F  1  n     X^{2}\sim\operatorname{F}(1,n)          X   -  2    ∼   F   (  n  ,  1  )       similar-to   superscript  X    2     normal-F  n  1     X^{-2}\sim\operatorname{F}(n,1)         F -distribution is a special case of type 6 Pearson distribution    If X and Y are independent, with X , Y ~ Laplace(μ, b ) then           |   X  -  μ   |    |   Y  -  μ   |    ∼   F   (  2  ,  2  )       similar-to        X  μ        Y  μ      normal-F  2  2     \tfrac{|X-\mu|}{|Y-\mu|}\sim\operatorname{F}(2,2)         If X ~ F( n , m ) then      log  X   2   ∼   FisherZ   (  n  ,  m  )       similar-to      X   2    FisherZ  n  m     \tfrac{\log{X}}{2}\sim\operatorname{FisherZ}(n,m)   ( Fisher's z-distribution )  The noncentral F -distribution simplifies to the F -distribution if λ = 0.  The doubly noncentral F -distribution simplifies to the F -distribution if     λ  1   =   λ  2   =  0         subscript  λ  1    subscript  λ  2        0     \lambda_{1}=\lambda_{2}=0       If     Q  X    (  p  )       subscript  normal-Q  X   p    \operatorname{Q}_{X}(p)   is the quantile p for X ~ F( d 1 , d 2 ) and     Q  Y    (   1  -  p   )       subscript  normal-Q  Y     1  p     \operatorname{Q}_{Y}(1-p)   is the quantile 1− p for Y ~ F( d 2 , d 1 ), then           Q  X    (  p  )    =   1    Q  Y    (   1  -  p   )           subscript  normal-Q  X   p     1    subscript  normal-Q  Y     1  p       \operatorname{Q}_{X}(p)=\frac{1}{\operatorname{Q}_{Y}(1-p)}   .     See also   Chi-squared distribution  Chow test  Gamma distribution  Hotelling's T-squared distribution  Student's t-distribution  Wilks' lambda distribution  Wishart distribution   References  External links   Table of critical values of the F -distribution  Earliest Uses of Some of the Words of Mathematics: entry on F -distribution contains a brief history  Free calculator for F -testing   "  Category:Continuous distributions  Category:Analysis of variance  Category:Probability distributions       ↩  ↩  NIST (2006). Engineering Statistics Handbook – F Distribution ↩  ↩  ↩   Phillips, P. C. B. (1982) "The true characteristic function of the F distribution," Biometrika , 69: 261–264 ↩  M.H. DeGroot (1986), Probability and Statistics (2nd Ed), Addison-Wesley. ISBN 0-201-11366-X, p. 500 ↩  G.E.P. Box and G.C. Tiao (1973), Bayesian Inference in Statistical Analysis , Addison-Wesley. p.110 ↩     