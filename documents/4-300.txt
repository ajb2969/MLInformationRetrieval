   Mechanism design      Mechanism design   (Figure)  The Stanley Reiter diagram above illustrates a game of mechanism design. The upper-left space   Θ   normal-Θ   \Theta   depicts the type space and the upper-right space X the space of outcomes. The social choice function    f   (  θ  )       f  θ    f(\theta)   maps a type profile to an outcome. In games of mechanism design, agents send messages   M   M   M   in a game environment   g   g   g   . The equilibrium in the game    ξ   (  M  ,  g  ,  θ  )       ξ   M  g  θ     \xi(M,g,\theta)   can be designed to implement some social choice function    f   (  θ  )       f  θ    f(\theta)   .   Mechanism design (sometimes called reverse game theory ) is a field in game theory studying solution concepts for a class of private-information games. Leonid Hurwicz explains that 'in a design problem, the goal function is the main “given,” while the mechanism is the unknown. Therefore, the design problem is the “inverse” of traditional economic theory, which is typically devoted to the analysis of the performance of a given mechanism.' 1 So, two distinguishing features of these games are:   that a game "designer" chooses the game structure rather than inheriting one    that the designer is interested in the game's outcome   The 2007 Nobel Memorial Prize in Economic Sciences was awarded to Leonid Hurwicz , Eric Maskin , and Roger Myerson "for having laid the foundations of mechanism design theory". 2  Intuition  In an interesting class of Bayesian games , one player, called the “principal,” would like to condition his behavior on information privately known to other players. For example, the principal would like to know the true quality of a used car a salesman is pitching. He cannot learn anything simply by asking the salesman, because it is in his interest to distort the truth. Fortunately, in mechanism design the principal does have one advantage: He may design a game whose rules can influence others to act the way he would like.  Without mechanism design theory, the principal's problem would be difficult to solve. He would have to consider all the possible games and choose the one that best influences other players' tactics. In addition, the principal would have to draw conclusions from agents who may lie to him. Thanks to mechanism design, and particularly the revelation principle , the principal need only consider games in which agents truthfully report their private information.  Foundations  Mechanism  A game of mechanism design is a game of private information in which one of the agents, called the principal, chooses the payoff structure. Following Harsanyi (1967), the agents receive secret "messages" from nature containing information relevant to payoffs. For example, a message may contain information about their preferences or the quality of a good for sale. We call this information the agent's "type" (usually noted   θ   θ   \theta   and accordingly the space of types   Θ   normal-Θ   \Theta   ). Agents then report a type to the principal (usually noted with a hat    θ  ^     normal-^  θ    \hat{\theta}   ) that can be a strategic lie. After the report, the principal and the agents are paid according to the payoff structure the principal chose.  The timing of the game is:   The principal commits to a mechanism    y   (  )       y     y()   that grants an outcome   y   y   y   as a function of reported type  The agents report, possibly dishonestly, a type profile    θ  ^     normal-^  θ    \hat{\theta}     The mechanism is executed (agents receive outcome    y   (   θ  ^   )       y   normal-^  θ     y(\hat{\theta})   )   In order to understand who gets what, it is common to divide the outcome   y   y   y   into a goods allocation and a money transfer,      y   (  θ  )    =   {   x   (  θ  )    ,   t   (  θ  )    }    ,    x  ∈  X   ,   t  ∈  T       formulae-sequence      y  θ      x  θ     t  θ      formulae-sequence    x  X     t  T      y(\theta)=\{x(\theta),t(\theta)\},\ x\in X,t\in T   where   x   x   x   stands for an allocation of goods rendered or received as a function of type, and   t   t   t   stands for a monetary transfer as a function of type.  As a benchmark the designer often defines what would happen under full information. Define a social choice function     f   (  θ  )       f  θ    f(\theta)   mapping the (true) type profile directly to the allocation of goods received or rendered,       f   (  θ  )    :   Θ  →  X      normal-:    f  θ    normal-→  normal-Θ  X     f(\theta):\Theta\rightarrow X     In contrast a mechanism maps the reported type profile to an outcome (again, both a goods allocation   x   x   x   and a money transfer   t   t   t   )       y   (   θ  ^   )    :   Θ  →  Y      normal-:    y   normal-^  θ     normal-→  normal-Θ  Y     y(\hat{\theta}):\Theta\rightarrow Y     Revelation principle  A proposed mechanism constitutes a Bayesian game (a game of private information), and if it is well-behaved the game has a Bayesian Nash equilibrium . At equilibrium agents choose their reports strategically as a function of type       θ  ^    (  θ  )        normal-^  θ   θ    \hat{\theta}(\theta)     It is difficult to solve for Bayesian equilibria in such a setting because it involves solving for agents' best-response strategies and for the best inference from a possible strategic lie. Thanks to a sweeping result called the revelation principle, no matter the mechanism a designer can 3 confine attention to equilibria in which agents truthfully report type. The revelation principle states: "To every Bayesian Nash equilibrium there corresponds a Bayesian game with the same equilibrium outcome but in which players truthfully report type."  This is extremely useful. The principle allows one to solve for a Bayesian equilibrium by assuming all players truthfully report type (subject to an incentive compatibility constraint). In one blow it eliminates the need to consider either strategic behavior or lying.  Its proof is quite direct. Assume a Bayesian game in which the agent's strategy and payoff are functions of its type and what others do,     u  i    (    s  i    (   θ  i   )    ,    s   -  i     (   θ   -  i    )    ,   θ  i   )        subscript  u  i       subscript  s  i    subscript  θ  i       subscript  s    i     subscript  θ    i      subscript  θ  i      u_{i}\left(s_{i}(\theta_{i}),s_{-i}(\theta_{-i}),\theta_{i}\right)   . By definition agent i 's equilibrium strategy    s   (   θ  i   )       s   subscript  θ  i     s(\theta_{i})   is Nash in expected utility:       s  i    (   θ  i   )   ∈  arg   max    s  i  ′   ∈   S  i       ∑   θ   -  i      p   (   θ   -  i    ∣   θ  i   )    u  i    (   s  i  ′   ,   s   -  i     (   θ   -  i    )   ,   θ  i   )      fragments   subscript  s  i    fragments  normal-(   subscript  θ  i   normal-)      subscript      subscript   superscript  s  normal-′   i    subscript  S  i      subscript    subscript  θ    i     p   fragments  normal-(   subscript  θ    i    normal-∣   subscript  θ  i   normal-)    subscript  u  i    fragments  normal-(   subscript   superscript  s  normal-′   i   normal-,   subscript  s    i     fragments  normal-(   subscript  θ    i    normal-)   normal-,   subscript  θ  i   normal-)     s_{i}(\theta_{i})\in\arg\max_{s^{\prime}_{i}\in S_{i}}\sum_{\theta_{-i}}\ p(%
 \theta_{-i}\mid\theta_{i})\ u_{i}\left(s^{\prime}_{i},s_{-i}(\theta_{-i}),%
 \theta_{i}\right)     Simply define a mechanism that would induce agents to choose the same equilibrium. The easiest one to define is for the mechanism to commit to playing the agents' equilibrium strategies for them.       y   (   θ  ^   )    :   Θ  →   S   (  Θ  )    →  Y      normal-:    y   normal-^  θ       normal-→  normal-Θ    S  normal-Θ     normal-→    Y      y(\hat{\theta}):\Theta\rightarrow S(\Theta)\rightarrow Y     Under such a mechanism the agents of course find it optimal to reveal type since the mechanism plays the strategies they found optimal anyway. Formally, choose    y   (  θ  )       y  θ    y(\theta)   such that        θ  ^   i    (   θ  i   )   ∈  arg   max    θ  i  ′   ∈  Θ      ∑   θ   -  i      p   (   θ   -  i    ∣   θ  i   )    u  i    (  y   (   θ  i  ′   ,   θ   -  i    )   ,   θ  i   )      fragments   subscript   normal-^  θ   i    fragments  normal-(   subscript  θ  i   normal-)      subscript      subscript   superscript  θ  normal-′   i   normal-Θ     subscript    subscript  θ    i     p   fragments  normal-(   subscript  θ    i    normal-∣   subscript  θ  i   normal-)    subscript  u  i    fragments  normal-(  y   fragments  normal-(   subscript   superscript  θ  normal-′   i   normal-,   subscript  θ    i    normal-)   normal-,   subscript  θ  i   normal-)     \hat{\theta}_{i}(\theta_{i})\in\arg\max_{\theta^{\prime}_{i}\in\Theta}\sum_{%
 \theta_{-i}}\ p(\theta_{-i}\mid\theta_{i})\ u_{i}\left(y(\theta^{\prime}_{i},%
 \theta_{-i}),\theta_{i}\right)           =    ∑   θ   -  i      p   (   θ   -  i    ∣   θ  i   )    u  i    (   s  i    (  θ  )   ,   s   -  i     (   θ   -  i    )   ,   θ  i   )      fragments    subscript    subscript  θ    i     p   fragments  normal-(   subscript  θ    i    normal-∣   subscript  θ  i   normal-)    subscript  u  i    fragments  normal-(   subscript  s  i    fragments  normal-(  θ  normal-)   normal-,   subscript  s    i     fragments  normal-(   subscript  θ    i    normal-)   normal-,   subscript  θ  i   normal-)     =\sum_{\theta_{-i}}\ p(\theta_{-i}\mid\theta_{i})\ u_{i}\left(s_{i}(\theta),s_%
 {-i}(\theta_{-i}),\theta_{i}\right)        Implementability  The designer of a mechanism generally hopes either   to design a mechanism    y   (  )       y     y()   that "implements" a social choice function  to find the mechanism    y   (  )       y     y()   that maximizes some value criterion (e.g. profit)   To implement a social choice function    f   (  θ  )       f  θ    f(\theta)   is to find some    t   (  θ  )       t  θ    t(\theta)   transfer function that motivates agents to pick outcome    x   (  θ  )       x  θ    x(\theta)   . Formally, if the equilibrium strategy profile under the mechanism maps to the same goods allocation as a social choice function,       f   (  θ  )    =   x   (    θ  ^    (  θ  )    )          f  θ     x     normal-^  θ   θ      f(\theta)=x\left(\hat{\theta}(\theta)\right)   we say the mechanism implements the social choice function.  Thanks to the revelation principle, the designer can usually find a transfer function    t   (  θ  )       t  θ    t(\theta)   to implement a social choice by solving an associated truthtelling game. If agents find it optimal to truthfully report type,        θ  ^    (  θ  )    =  θ         normal-^  θ   θ   θ    \hat{\theta}(\theta)=\theta   we say such a mechanism is truthfully implementable (or just "implementable"). The task is then to solve for a truthfully implementable    t   (  θ  )       t  θ    t(\theta)   and impute this transfer function to the original game. An allocation    x   (  θ  )       x  θ    x(\theta)   is truthfully implementable if there exists a transfer function    t   (  θ  )       t  θ    t(\theta)   such that        u   (   x   (  θ  )    ,   t   (  θ  )    ,  θ  )    ≥   u   (   x   (   θ  ^   )    ,   t   (   θ  ^   )    ,  θ  )    ∀  θ     ,    θ  ^   ∈  Θ      formulae-sequence      u     x  θ     t  θ   θ      u     x   normal-^  θ      t   normal-^  θ    θ    for-all  θ        normal-^  θ   normal-Θ     u(x(\theta),t(\theta),\theta)\geq u(x(\hat{\theta}),t(\hat{\theta}),\theta)\ %
 \forall\theta,\hat{\theta}\in\Theta   which is also called the incentive compatibility (IC) constraint.  In applications, the IC condition is the key to describing the shape of    t   (  θ  )       t  θ    t(\theta)   in any useful way. Under certain conditions it can even isolate the transfer function analytically! Additionally, a participation ( individual rationality ) constraint is sometimes added if agents have the option of not playing.  Necessity  Consider a setting in which all agents have a type-contingent utility function    u   (  x  ,  t  ,  θ  )       u   x  t  θ     u(x,t,\theta)   . Consider also a goods allocation    x   (  θ  )       x  θ    x(\theta)   that is vector-valued and size   k   k   k   (which permits   k   k   k   number of goods) and assume it is piecewise continuous with respect to its arguments.  The function    x   (  θ  )       x  θ    x(\theta)   is implementable only if        ∑   k  =  1   n     ∂   ∂  θ     (     ∂  u   /   ∂   x  k      |    ∂  u   /   ∂  t    |    )     ∂  x    ∂  θ      ≥  0        subscript   superscript   n     k  1           θ          u      subscript  x  k           u     t          x     θ      0    \sum^{n}_{k=1}\frac{\partial}{\partial\theta}\left(\frac{\partial u/\partial x%
 _{k}}{\left|\partial u/\partial t\right|}\right)\frac{\partial x}{\partial%
 \theta}\geq 0   whenever    x  =   x   (  θ  )        x    x  θ     x=x(\theta)   and    t  =   t   (  θ  )        t    t  θ     t=t(\theta)   and x is continuous at   θ   θ   \theta   . This is a necessary condition and is derived from the first- and second-order conditions of the agent's optimization problem assuming truth-telling.  Its meaning can be understood in two pieces. The first piece says the agent's marginal rate of substitution increases as a function of the type,        ∂   ∂  θ     (     ∂  u   /   ∂   x  k      |    ∂  u   /   ∂  t    |    )    =    ∂   ∂  θ    M  R   S   x  ,  t                θ          u      subscript  x  k           u     t              θ    M  R   subscript  S   x  t       \frac{\partial}{\partial\theta}\left(\frac{\partial u/\partial x_{k}}{\left|%
 \partial u/\partial t\right|}\right)=\frac{\partial}{\partial\theta}MRS_{x,t}   In short, agents will not tell the truth if the mechanism does not offer higher agent types a better deal. Otherwise, higher types facing any mechanism that punishes high types for reporting will lie and declare they are lower types, violating the truthtelling IC constraint. The second piece is a monotonicity condition waiting to happen,       ∂  x    ∂  θ         x     θ     \frac{\partial x}{\partial\theta}   which, to be positive, means higher types must be given more of the good.  There is potential for the two pieces to interact. If for some type range the contract offered less quantity to higher types      ∂  x   /   ∂  θ    <  0          x     θ    0    \partial x/\partial\theta<0   , it is possible the mechanism could compensate by giving higher types a discount. But such a contract already exists for low-type agents, so this solution is pathological. Such a solution sometimes occurs in the process of solving for a mechanism. In these cases it must be " ironed ." In a multiple-good environment it is also possible for the designer to reward the agent with more of one good to substitute for less of another (e.g. butter for margarine ). Multiple-good mechanisms are an ongoing problem in mechanism design theory.  Sufficiency  Mechanism design papers usually make two assumptions to ensure implementability:        1.    ∂   ∂  θ       ∂  u   /   ∂   x  k      |    ∂  u   /   ∂  t    |     >    0    ∀  k          1.       θ          u      subscript  x  k           u     t         0   for-all  k      1.\ \frac{\partial}{\partial\theta}\frac{\partial u/\partial x_{k}}{\left|%
 \partial u/\partial t\right|}>0\ \forall k   This is known by several names: the single-crossing condition , the sorting condition and the Spence–Mirrlees condition. It means the utility function is of such a shape that the agent's MRS is increasing in type.         2.    ∃   K  0     ,    K  1   such that   |     ∂  u   /   ∂   x  k       ∂  u   /   ∂  t     |     ≤    K  0   +    K  1    |  t  |            2.     subscript  K  0        subscript  K  1   such that          u      subscript  x  k         u     t           subscript  K  0      subscript  K  1     t       2.\ \exists K_{0},K_{1}\text{ such that }\left|\frac{\partial u/\partial x_{k}%
 }{\partial u/\partial t}\right|\leq K_{0}+K_{1}|t|   This is a technical condition bounding the rate of growth of the MRS.  These assumptions are sufficient to provide that any monotonic    x   (  θ  )       x  θ    x(\theta)   is implementable (a    t   (  θ  )       t  θ    t(\theta)   exists that can implement it). In addition, in the single-good setting the single-crossing condition is sufficient to provide that only a monotonic    x   (  θ  )       x  θ    x(\theta)   is implementable, so the designer can confine his search to a monotonic    x   (  θ  )       x  θ    x(\theta)   .  Highlighted results  Revenue equivalence theorem  Vickrey (1961) gives a celebrated result that any member of a large class of auctions assures the seller of the same expected revenue and that the expected revenue is the best the seller can do. This is the case if   The buyers have identical valuation functions (which may be a function of type)  The buyers' types are independently distributed  The buyers types are drawn from a continuous distribution  The type distribution bears the monotone hazard rate property  The mechanism sells the good to the buyer with the highest valuation   The last condition is crucial to the theorem. An implication is that for the seller to achieve higher revenue he must take a chance on giving the item to an agent with a lower valuation. Usually this means he must risk not selling the item at all.  Vickrey–Clarke–Groves mechanisms  The Vickrey (1961) auction model was later expanded by Clarke (1971) and Groves (1973) to treat a public choice problem in which a public project's cost is borne by all agents, e.g. whether to build a municipal bridge. The resulting "Vickrey–Clarke–Groves" mechanism can motivate agents to choose the socially efficient allocation of the public good even if agents have privately known valuations. In other words, it can solve the " tragedy of the commons "—under certain conditions, in particular quasilinear utility or if budget balance is not required.  Consider a setting in which   I   I   I   number of agents have quasilinear utility with private valuations    v   (  x  ,  t  ,  θ  )       v   x  t  θ     v(x,t,\theta)   where the currency   t   t   t   is valued linearly. The VCG designer designs an incentive compatible (hence truthfully implementable) mechanism to obtain the true type profile, from which the designer implements the socially optimal allocation        x  I  *    (  θ  )    ∈    arg   max   x  ∈  X       ∑   i  ∈  I     v   (  x  ,   θ  i   )             subscript   superscript  x    I   θ        subscript     x  X       subscript     i  I      v   x   subscript  θ  i         x^{*}_{I}(\theta)\in\arg\max_{x\in X}\sum_{i\in I}v(x,\theta_{i})     The cleverness of the VCG mechanism is the way it motivates truthful revelation. It eliminates incentives to misreport by penalizing any agent by the cost of the distortion he causes. Among the reports the agent may make, the VCG mechanism permits a "null" report saying he is indifferent to the public good and cares only about the money transfer. This effectively removes the agent from the game. If an agent does choose to report a type, the VCG mechanism charges the agent a fee if his report is pivotal , that is if his report changes the optimal allocation x so as to harm other agents. The payment is calculated        t  i    (   θ  ^   )    =     ∑   j  ∈   I  -  i       v  j    (    x   I  -  i   *    (   θ   I  -  i    )    ,   θ  j   )     -    ∑   j  ∈   I  -  i       v  j    (    x  I  *    (    θ  ^   i   ,   θ  I   )    ,   θ  j   )             subscript  t  i    normal-^  θ        subscript     j    I  i        subscript  v  j       subscript   superscript  x      I  i     subscript  θ    I  i      subscript  θ  j        subscript     j    I  i        subscript  v  j       subscript   superscript  x    I     subscript   normal-^  θ   i    subscript  θ  I      subscript  θ  j         t_{i}(\hat{\theta})=\sum_{j\in I-i}v_{j}(x^{*}_{I-i}(\theta_{I-i}),\theta_{j})%
 -\sum_{j\in I-i}v_{j}(x^{*}_{I}(\hat{\theta}_{i},\theta_{I}),\theta_{j})   which sums the distortion in the utilities of the other agents (and not his own) caused by one agent reporting.  Gibbard–Satterthwaite theorem  Gibbard (1973) and Satterthwaite (1975) give an impossibility result similar in spirit to Arrow's impossibility theorem . For a very general class of games, only "dictatorial" social choice functions can be implemented.  A social choice function f () is dictatorial if one agent always receives his most-favored goods allocation,       for  f   (  Θ  )   ,   ∃  i    ∈   I  such that   u  i    (  x  ,   θ  i   )    ≥    u  i    (   x  ′   ,   θ  i   )    ∀   x  ′     ∈  X          for  f  normal-Θ  ,    i      I  such that   subscript  u  i    x   subscript  θ  i             subscript  u  i     superscript  x  normal-′    subscript  θ  i     for-all   superscript  x  normal-′          X     \text{for }f(\Theta)\text{, }\exists i\in I\text{ such that }u_{i}(x,\theta_{i%
 })\geq u_{i}(x^{\prime},\theta_{i})\ \forall x^{\prime}\in X     The theorem states that under general conditions any truthfully implementable social choice function must be dictatorial,   X finite and contains at least three elements  Preferences are rational       f   (  Θ  )    =  X        f  normal-Θ   X    f(\Theta)=X      Myerson–Satterthwaite theorem  Myerson and Satterthwaite (1983) show there is no efficient way for two parties to trade a good when they each have secret and probabilistically varying valuations for it, without the risk of forcing one party to trade at a loss. It is among the most remarkable negative results in economics—a kind of negative mirror to the fundamental theorems of welfare economics .  Examples  Price discrimination  Mirrlees (1971) introduces a setting in which the transfer function t () is easy to solve for. Due to its relevance and tractability it is a common setting in the literature. Consider a single-good, single-agent setting in which the agent has quasilinear utility with an unknown type parameter   θ   θ   \theta          u   (  x  ,  t  ,  θ  )    =    V   (  x  ,  θ  )    -  t         u   x  t  θ        V   x  θ    t     u(x,t,\theta)=V(x,\theta)-t   and in which the principal has a prior CDF over the agent's type    P   (  θ  )       P  θ    P(\theta)   . The principal can produce goods at a convex marginal cost c ( x ) and wants to maximize the expected profit from the transaction        max    x   (  θ  )    ,   t   (  θ  )       𝔼  θ     [    t   (  θ  )    -   c   (   x   (  θ  )    )     ]         subscript      x  θ     t  θ      subscript  𝔼  θ     delimited-[]      t  θ     c    x  θ        \max_{x(\theta),t(\theta)}\mathbb{E}_{\theta}\left[t(\theta)-c\left(x(\theta)%
 \right)\right]   subject to IC and IR conditions       u   (   x   (  θ  )    ,   t   (  θ  )    ,  θ  )    ≥    u   (   x   (   θ  ′   )    ,   t   (   θ  ′   )    ,  θ  )    ∀  θ    ,   θ  ′          u     x  θ     t  θ   θ       u     x   superscript  θ  normal-′      t   superscript  θ  normal-′    θ    for-all  θ     superscript  θ  normal-′      u(x(\theta),t(\theta),\theta)\geq u(x(\theta^{\prime}),t(\theta^{\prime}),%
 \theta)\ \forall\theta,\theta^{\prime}          u   (   x   (  θ  )    ,   t   (  θ  )    ,  θ  )    ≥    u  ¯    (  θ  )    ∀  θ          u     x  θ     t  θ   θ       normal-¯  u   θ   for-all  θ      u(x(\theta),t(\theta),\theta)\geq\underline{u}(\theta)\ \forall\theta   The principal here is a monopolist trying to set a profit-maximizing price scheme in which it cannot identify the type of the customer. A common example is an airline setting fares for business, leisure and student travelers. Due to the IR condition it has to give every type a good enough deal to induce participation. Due to the IC condition it has to give every type a good enough deal that the type prefers its deal to that of any other.  A trick given by Mirrlees (1971) is to use the envelope theorem to eliminate the transfer function from the expectation to be maximized,       let  U   (  θ  )    =     max   θ  ′    u    (   x   (   θ  ′   )    ,   t   (   θ  ′   )    ,  θ  )          let  U  θ       subscript    superscript  θ  normal-′    u      x   superscript  θ  normal-′      t   superscript  θ  normal-′    θ      \text{let }U(\theta)=\max_{\theta^{\prime}}u\left(x(\theta^{\prime}),t(\theta^%
 {\prime}),\theta\right)           d  U    d  θ    =    ∂  u    ∂  θ    =    ∂  V    ∂  θ              d  U     d  θ        u     θ             V     θ       \frac{dU}{d\theta}=\frac{\partial u}{\partial\theta}=\frac{\partial V}{%
 \partial\theta}   Integrating,       U   (  θ  )    =     u  ¯    (   θ  0   )    +    ∫   θ  0   θ      ∂  V    ∂   θ  ~     d   θ  ~            U  θ        normal-¯  u    subscript  θ  0      subscript   superscript   θ    subscript  θ  0          V      normal-~  θ     d   normal-~  θ        U(\theta)=\underline{u}(\theta_{0})+\int^{\theta}_{\theta_{0}}\frac{\partial V%
 }{\partial\tilde{\theta}}d\tilde{\theta}   where    θ  0     subscript  θ  0    \theta_{0}   is some index type. Replacing the incentive-compatible     t   (  θ  )    =    V   (   x   (  θ  )    ,  θ  )    -   U   (  θ  )           t  θ       V     x  θ   θ      U  θ      t(\theta)=V(x(\theta),\theta)-U(\theta)   in the maximand,       𝔼  θ    [    V   (   x   (  θ  )    ,  θ  )    -    u  ¯    (   θ  0   )    -    ∫   θ  0   θ      ∂  V    ∂   θ  ~     d   θ  ~     -   c   (   x   (  θ  )    )     ]        subscript  𝔼  θ    delimited-[]      V     x  θ   θ       normal-¯  u    subscript  θ  0      subscript   superscript   θ    subscript  θ  0          V      normal-~  θ     d   normal-~  θ       c    x  θ        \mathbb{E}_{\theta}\left[V(x(\theta),\theta)-\underline{u}(\theta_{0})-\int^{%
 \theta}_{\theta_{0}}\frac{\partial V}{\partial\tilde{\theta}}d\tilde{\theta}-c%
 \left(x(\theta)\right)\right]            =    𝔼  θ    [    V   (   x   (  θ  )    ,  θ  )    -    u  ¯    (   θ  0   )    -     1  -   P   (  θ  )      p   (  θ  )       ∂  V    ∂  θ     -   c   (   x   (  θ  )    )     ]        absent     subscript  𝔼  θ    delimited-[]      V     x  θ   θ       normal-¯  u    subscript  θ  0          1    P  θ      p  θ        V     θ       c    x  θ         =\mathbb{E}_{\theta}\left[V(x(\theta),\theta)-\underline{u}(\theta_{0})-\frac{%
 1-P(\theta)}{p(\theta)}\frac{\partial V}{\partial\theta}-c\left(x(\theta)%
 \right)\right]        after an integration by parts. This function can be maximized pointwise.  Because    U   (  θ  )       U  θ    U(\theta)   is incentive-compatible already the designer can drop the IC constraint. If the utility function satisfies the Spence–Mirrlees condition then a monotonic    x   (  θ  )       x  θ    x(\theta)   function exists. The IR constraint can be checked at equilibrium and the fee schedule raised or lowered accordingly. Additionally, note the presence of a hazard rate in the expression. If the type distribution bears the monotone hazard ratio property, the FOC is sufficient to solve for t (). If not, then it is necessary to check whether the monotonicity constraint (see sufficiency , above) is satisfied everywhere along the allocation and fee schedules. If not, then the designer must use Myerson ironing.  Myerson ironing  (Figure)  It is possible to solve for a goods or price schedule that satisfies the first-order conditions yet is not monotonic. If so it is necessary to "iron" the schedule by choosing some value at which to flatten the function.   In some applications the designer may solve the first-order conditions for the price and allocation schedules yet find they are not monotonic. For example, in the quasilinear setting this often happens when the hazard ratio is itself not monotone. By the Spence–Mirrlees condition the optimal price and allocation schedules must be monotonic, so the designer must eliminate any interval over which the schedule changes direction by flattening it.  Intuitively, what is going on is the designer finds it optimal to bunch certain types together and give them the same contract. Normally the designer motivates higher types to distinguish themselves by giving them a better deal. If there are insufficiently few higher types on the margin the designer does not find it worthwhile to grant lower types a concession (called their information rent ) in order to charge higher types a type-specific contract.  Consider a monopolist principal selling to agents with quasilinear utility, the example above. Suppose the allocation schedule    x   (  θ  )       x  θ    x(\theta)   satisfying the first-order conditions has a single interior peak at    θ  1     subscript  θ  1    \theta_{1}   and a single interior trough at     θ  2   >   θ  1        subscript  θ  2    subscript  θ  1     \theta_{2}>\theta_{1}   , illustrated at right.   Following Myerson (1981) flatten it by choosing   x   x   x   satisfying           ∫    ϕ  2    (  x  )      ϕ  1    (  x  )       (      ∂  V    ∂  x     (  x  ,  θ  )    -     1  -   P   (  θ  )      p   (  θ  )        ∂  2   V     ∂   θ     ∂  x      (  x  ,  θ  )    -     ∂  c    ∂  x     (  x  )     )   d  θ    =  0        subscript   superscript      subscript  ϕ  1   x       subscript  ϕ  2   x              V     x     x  θ          1    P  θ      p  θ        superscript   2   V       θ     x      x  θ          c     x    x    d  θ    0    \int^{\phi_{1}(x)}_{\phi_{2}(x)}\left(\frac{\partial V}{\partial x}(x,\theta)-%
 \frac{1-P(\theta)}{p(\theta)}\frac{\partial^{2}V}{\partial\theta\,\partial x}(%
 x,\theta)-\frac{\partial c}{\partial x}(x)\right)d\theta=0       where     ϕ  1    (  x  )        subscript  ϕ  1   x    \phi_{1}(x)   is the inverse function of x mapping to    θ  ≤   θ  1       θ   subscript  θ  1     \theta\leq\theta_{1}   and     ϕ  2    (  x  )        subscript  ϕ  2   x    \phi_{2}(x)   is the inverse function of x mapping to    θ  ≥   θ  2       θ   subscript  θ  2     \theta\geq\theta_{2}   . That is,    ϕ  1     subscript  ϕ  1    \phi_{1}   returns a   θ   θ   \theta   before the interior peak and    ϕ  2     subscript  ϕ  2    \phi_{2}   returns a   θ   θ   \theta   after the interior trough.    If the nonmonotonic region of    x   (  θ  )       x  θ    x(\theta)   borders the edge of the type space, simply set the appropriate    ϕ   (  x  )       ϕ  x    \phi(x)   function (or both) to the boundary type. If there are multiple regions, see a textbook for an iterative procedure; it may be that more than one troughs should be ironed together.   Proof  The proof uses the theory of optimal control. It considers the set of intervals    [   θ  ¯   ,   θ  ¯   ]      normal-¯  θ    normal-¯  θ     \left[\underline{\theta},\overline{\theta}\right]   in the nonmonotonic region of    x   (  θ  )       x  θ    x(\theta)   over which it might flatten the schedule. It then writes a Hamiltonian to obtain necessary conditions for a    x   (  θ  )       x  θ    x(\theta)   within the intervals   that does satisfy monotonicity  for which the monotonicity constraint is not binding on the boundaries of the interval   Condition two ensures that the    x   (  θ  )       x  θ    x(\theta)   satisfying the optimal control problem reconnects to the schedule in the original problem at the interval boundaries (no jumps). Any    x   (  θ  )       x  θ    x(\theta)   satisfying the necessary conditions must be flat because it must be monotonic and yet reconnect at the boundaries.  As before maximize the principal's expected payoff, but this time subject to the monotonicity constraint        ∂  x    ∂  θ    ≥  0          x     θ    0    \frac{\partial x}{\partial\theta}\geq 0   and use a Hamiltonian to do it, with shadow price    ν   (  θ  )       ν  θ    \nu(\theta)         H  =     (    V   (  x  ,  θ  )    -    u  ¯    (   θ  0   )    -     1  -   P   (  θ  )      p   (  θ  )       ∂  V    ∂  θ     (  x  ,  θ  )    -   c   (  x  )     )   p   (  θ  )    +   ν   (  θ  )     ∂  x    ∂  θ          H          V   x  θ       normal-¯  u    subscript  θ  0          1    P  θ      p  θ        V     θ     x  θ      c  x    p  θ     ν  θ      x     θ        H=\left(V(x,\theta)-\underline{u}(\theta_{0})-\frac{1-P(\theta)}{p(\theta)}%
 \frac{\partial V}{\partial\theta}(x,\theta)-c(x)\right)p(\theta)+\nu(\theta)%
 \frac{\partial x}{\partial\theta}   where   x   x   x   is a state variable and     ∂  x   /   ∂  θ         x     θ     \partial x/\partial\theta   the control. As usual in optimal control the costate evolution equation must satisfy        ∂  ν    ∂  θ    =   -    ∂  H    ∂  x     =   -    (      ∂  V    ∂  x     (  x  ,  θ  )    -     1  -   P   (  θ  )      p   (  θ  )        ∂  2   V     ∂   θ     ∂  x      (  x  ,  θ  )    -     ∂  c    ∂  x     (  x  )     )   p   (  θ  )               ν     θ          H     x                      V     x     x  θ          1    P  θ      p  θ        superscript   2   V       θ     x      x  θ          c     x    x    p  θ       \frac{\partial\nu}{\partial\theta}=-\frac{\partial H}{\partial x}=-\left(\frac%
 {\partial V}{\partial x}(x,\theta)-\frac{1-P(\theta)}{p(\theta)}\frac{\partial%
 ^{2}V}{\partial\theta\,\partial x}(x,\theta)-\frac{\partial c}{\partial x}(x)%
 \right)p(\theta)   Taking advantage of condition 2, note the monotonicity constraint is not binding at the boundaries of the   θ   θ   \theta   interval,       ν   (   θ  ¯   )    =   ν   (   θ  ¯   )    =  0          ν   normal-¯  θ      ν   normal-¯  θ         0     \nu(\underline{\theta})=\nu(\overline{\theta})=0   meaning the costate variable condition can be integrated and also equals 0        ∫   θ  ¯    θ  ¯      (      ∂  V    ∂  x     (  x  ,  θ  )    -     1  -   P   (  θ  )      p   (  θ  )        ∂  2   V     ∂   θ     ∂  x      (  x  ,  θ  )    -     ∂  c    ∂  x     (  x  )     )   p   (  θ  )   d  θ    =  0        subscript   superscript    normal-¯  θ     normal-¯  θ              V     x     x  θ          1    P  θ      p  θ        superscript   2   V       θ     x      x  θ          c     x    x    p  θ  d  θ    0    \int^{\overline{\theta}}_{\underline{\theta}}\left(\frac{\partial V}{\partial x%
 }(x,\theta)-\frac{1-P(\theta)}{p(\theta)}\frac{\partial^{2}V}{\partial\theta\,%
 \partial x}(x,\theta)-\frac{\partial c}{\partial x}(x)\right)p(\theta)d\theta=0   The average distortion of the principal's surplus must be 0. To flatten the schedule, find an   x   x   x   such that its inverse image maps to a   θ   θ   \theta   interval satisfying the condition above.  See also   Algorithmic mechanism design  Assignment problem  Contract theory  Implementation theory  Incentive compatibility  Revelation principle  Smart market  Metagame   Notes  References   Chapter 7 of . A standard text for graduate game theory.  Chapter 23 of . A standard text for graduate microeconomics.   . Applications of mechanism design principles in the context of auctions.  Noam Nisan . A Google tech talk on mechanism design.  Roger B. Myerson (2008). "mechanism design," ''The New Palgrave Dictionary of Economics Online, [ http://www.dictionaryofeconomics.com/article?id=pde2008_M000132&q; ;=Mechanism%20design&topicid;=&result;_number=2 Abstract.]   "  Category:Game theory  Category:Social choice theory  *     L. Hurwicz & S. Reiter (2006) Designing Economic Mechanisms , p. 30 ↩  ↩  In unusual circumstances some truth-telling games have more equilibria than the Bayesian game they mapped from. See Fudenburg-Tirole Ch. 7.2 for some references. ↩     