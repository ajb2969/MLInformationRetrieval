<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="1855">ID3 algorithm</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>ID3 algorithm</h1>
<hr/>

<p>In <a href="decision_tree_learning" title="wikilink">decision tree learning</a>, <strong>ID3</strong> (<strong>Iterative Dichotomiser 3</strong>) is an <a class="uri" href="algorithm" title="wikilink">algorithm</a> invented by <a href="Ross_Quinlan" title="wikilink">Ross Quinlan</a><a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a> used to generate a <a href="decision_tree_learning" title="wikilink">decision tree</a> from a dataset. ID3 is the precursor to the <a href="C4.5_algorithm" title="wikilink">C4.5 algorithm</a>, and is typically used in the <a href="machine_learning" title="wikilink">machine learning</a> and <a href="natural_language_processing" title="wikilink">natural language processing</a> domains.</p>
<h2 id="algorithm">Algorithm</h2>

<p>The ID3 algorithm begins with the original set 

<math display="inline" id="ID3_algorithm:0">
 <semantics>
  <mi>S</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>S</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   S
  </annotation>
 </semantics>
</math>

 as the root node. On each iteration of the algorithm, it iterates through every unused attribute of the set 

<math display="inline" id="ID3_algorithm:1">
 <semantics>
  <mi>S</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>S</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   S
  </annotation>
 </semantics>
</math>

 and calculates the <a href="Entropy_(information_theory)" title="wikilink">entropy</a> 

<math display="inline" id="ID3_algorithm:2">
 <semantics>
  <mrow>
   <mi>H</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <mi>S</mi>
    <mo stretchy="false">)</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <ci>H</ci>
    <ci>S</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   H(S)
  </annotation>
 </semantics>
</math>

 (or <a href="Information_gain_in_decision_trees" title="wikilink">information gain</a> 

<math display="inline" id="ID3_algorithm:3">
 <semantics>
  <mrow>
   <mi>I</mi>
   <mi>G</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <mi>A</mi>
    <mo stretchy="false">)</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <ci>I</ci>
    <ci>G</ci>
    <ci>A</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   IG(A)
  </annotation>
 </semantics>
</math>

) of that attribute. It then selects the attribute which has the smallest entropy (or largest information gain) value. The set 

<math display="inline" id="ID3_algorithm:4">
 <semantics>
  <mi>S</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>S</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   S
  </annotation>
 </semantics>
</math>

 is then split by the selected attribute (e.g. age = 100) to produce subsets of the data. The algorithm continues to recur on each subset, considering only attributes never selected before.<br/>
Recursion on a subset may stop in one of these cases:</p>
<ul>
<li>every element in the subset belongs to the same class (+ or -), then the node is turned into a leaf and labelled with the class of the examples</li>
<li>there are no more attributes to be selected, but the examples still do not belong to the same class (some are + and some are -), then the node is turned into a leaf and labelled with the most common class of the examples in the subset</li>
<li>there are no examples in the subset, this happens when no example in the parent set was found to be matching a specific value of the selected attribute, for example if there was no example with age &gt;= 100. Then a leaf is created, and labelled with the most common class of the examples in the parent set.</li>
</ul>

<p>Throughout the algorithm, the decision tree is constructed with each non-terminal node representing the selected attribute on which the data was split, and terminal nodes representing the class label of the final subset of this branch.</p>
<h3 id="summary">Summary</h3>
<ol>
<li>Calculate the entropy of every attribute using the data set 

<math display="inline" id="ID3_algorithm:5">
 <semantics>
  <mi>S</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>S</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   S
  </annotation>
 </semantics>
</math>

</li>
<li>Split the set 

<math display="inline" id="ID3_algorithm:6">
 <semantics>
  <mi>S</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>S</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   S
  </annotation>
 </semantics>
</math>

 into subsets using the attribute for which entropy is minimum (or, equivalently, information gain is maximum)</li>
<li>Make a decision tree node containing that attribute</li>
<li>Recur on subsets using remaining attributes.</li>
</ol>
<h3 id="properties">Properties</h3>

<p>ID3 does not guarantee an optimal solution; it can get stuck in local optimums. It uses a greedy approach by selecting the best attribute to split the dataset on each iteration. One improvement that can be made on the algorithm can be to use <a class="uri" href="backtracking" title="wikilink">backtracking</a> during the search for the optimal decision tree.</p>

<p>ID3 can <a href="Overfitting" title="wikilink">overfit</a> to the training data, to avoid overfitting, smaller decision trees should be preferred over larger ones. This algorithm usually produces small trees, but it does not always produce the smallest possible tree.</p>

<p>ID3 is harder to use on continuous data. If the values of any given attribute is continuous, then there are many more places to split the data on this attribute, and searching for the best value to split by can be time consuming.</p>
<h3 id="usage">Usage</h3>

<p>The ID3 algorithm is used by training on a dataset 

<math display="inline" id="ID3_algorithm:7">
 <semantics>
  <mi>S</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>S</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   S
  </annotation>
 </semantics>
</math>

 to produce a <a href="Decision_tree_learning" title="wikilink">decision tree</a> which is stored in memory. At runtime, this decision tree is used to classify new unseen test cases by working down the decision tree using the values of this test case to arrive at a terminal node that tells you what class this test case belongs to.</p>
<h2 id="the-id3-metrics">The ID3 metrics</h2>
<h3 id="entropy">Entropy</h3>

<p><a href="Entropy_(information_theory)" title="wikilink">Entropy</a> 

<math display="inline" id="ID3_algorithm:8">
 <semantics>
  <mrow>
   <mi>H</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <mi>S</mi>
    <mo stretchy="false">)</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <ci>H</ci>
    <ci>S</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   H(S)
  </annotation>
 </semantics>
</math>

 is a measure of the amount of uncertainty in the (data) set 

<math display="inline" id="ID3_algorithm:9">
 <semantics>
  <mi>S</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>S</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   S
  </annotation>
 </semantics>
</math>

 (i.e. entropy characterizes the (data) set 

<math display="inline" id="ID3_algorithm:10">
 <semantics>
  <mi>S</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>S</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   S
  </annotation>
 </semantics>
</math>

).</p>

<p>

<math display="block" id="ID3_algorithm:11">
 <semantics>
  <mrow>
   <mrow>
    <mi>H</mi>
    <mrow>
     <mo stretchy="false">(</mo>
     <mi>S</mi>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
   <mo>=</mo>
   <mrow>
    <mo>-</mo>
    <mrow>
     <munder>
      <mo largeop="true" movablelimits="false" symmetric="true">∑</mo>
      <mrow>
       <mi>x</mi>
       <mo>∈</mo>
       <mi>X</mi>
      </mrow>
     </munder>
     <mrow>
      <mi>p</mi>
      <mrow>
       <mo stretchy="false">(</mo>
       <mi>x</mi>
       <mo stretchy="false">)</mo>
      </mrow>
      <mrow>
       <msub>
        <mi>log</mi>
        <mn>2</mn>
       </msub>
       <mi>p</mi>
      </mrow>
      <mrow>
       <mo stretchy="false">(</mo>
       <mi>x</mi>
       <mo stretchy="false">)</mo>
      </mrow>
     </mrow>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <times></times>
     <ci>H</ci>
     <ci>S</ci>
    </apply>
    <apply>
     <minus></minus>
     <apply>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <sum></sum>
       <apply>
        <in></in>
        <ci>x</ci>
        <ci>X</ci>
       </apply>
      </apply>
      <apply>
       <times></times>
       <ci>p</ci>
       <ci>x</ci>
       <apply>
        <apply>
         <csymbol cd="ambiguous">subscript</csymbol>
         <log></log>
         <cn type="integer">2</cn>
        </apply>
        <ci>p</ci>
       </apply>
       <ci>x</ci>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   H(S)=-\sum_{x\in X}p(x)\log_{2}p(x)
  </annotation>
 </semantics>
</math>

</p>

<p>Where,</p>
<ul>
<li>

<math display="inline" id="ID3_algorithm:12">
 <semantics>
  <mi>S</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>S</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   S
  </annotation>
 </semantics>
</math>

 - The current (data) set for which entropy is being calculated (changes every iteration of the ID3 algorithm)</li>
<li>

<math display="inline" id="ID3_algorithm:13">
 <semantics>
  <mi>X</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>X</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   X
  </annotation>
 </semantics>
</math>

 - Set of classes in 

<math display="inline" id="ID3_algorithm:14">
 <semantics>
  <mi>S</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>S</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   S
  </annotation>
 </semantics>
</math>

</li>
<li>

<math display="inline" id="ID3_algorithm:15">
 <semantics>
  <mrow>
   <mi>p</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <mi>x</mi>
    <mo stretchy="false">)</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <ci>p</ci>
    <ci>x</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   p(x)
  </annotation>
 </semantics>
</math>

 - The proportion of the number of elements in class 

<math display="inline" id="ID3_algorithm:16">
 <semantics>
  <mi>x</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>x</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   x
  </annotation>
 </semantics>
</math>

 to the number of elements in set 

<math display="inline" id="ID3_algorithm:17">
 <semantics>
  <mi>S</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>S</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   S
  </annotation>
 </semantics>
</math>

</li>
</ul>

<p>When 

<math display="inline" id="ID3_algorithm:18">
 <semantics>
  <mrow>
   <mrow>
    <mi>H</mi>
    <mrow>
     <mo stretchy="false">(</mo>
     <mi>S</mi>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
   <mo>=</mo>
   <mn>0</mn>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <times></times>
     <ci>H</ci>
     <ci>S</ci>
    </apply>
    <cn type="integer">0</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   H(S)=0
  </annotation>
 </semantics>
</math>

, the set 

<math display="inline" id="ID3_algorithm:19">
 <semantics>
  <mi>S</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>S</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   S
  </annotation>
 </semantics>
</math>

 is perfectly classified (i.e. all elements in 

<math display="inline" id="ID3_algorithm:20">
 <semantics>
  <mi>S</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>S</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   S
  </annotation>
 </semantics>
</math>

 are of the same class).</p>

<p>In ID3, entropy is calculated for each remaining attribute. The attribute with the <strong>smallest</strong> entropy is used to split the set 

<math display="inline" id="ID3_algorithm:21">
 <semantics>
  <mi>S</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>S</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   S
  </annotation>
 </semantics>
</math>

 on this iteration. The higher the entropy, the higher the potential to improve the classification here.</p>
<h3 id="information-gain">Information Gain</h3>

<p><a href="Information_gain_in_decision_trees" title="wikilink">Information gain</a> 

<math display="inline" id="ID3_algorithm:22">
 <semantics>
  <mrow>
   <mi>I</mi>
   <mi>G</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <mi>A</mi>
    <mo stretchy="false">)</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <ci>I</ci>
    <ci>G</ci>
    <ci>A</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   IG(A)
  </annotation>
 </semantics>
</math>

 is the measure of the difference in entropy from before to after the set 

<math display="inline" id="ID3_algorithm:23">
 <semantics>
  <mi>S</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>S</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   S
  </annotation>
 </semantics>
</math>

 is split on an attribute 

<math display="inline" id="ID3_algorithm:24">
 <semantics>
  <mi>A</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>A</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   A
  </annotation>
 </semantics>
</math>

. In other words, how much uncertainty in 

<math display="inline" id="ID3_algorithm:25">
 <semantics>
  <mi>S</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>S</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   S
  </annotation>
 </semantics>
</math>

 was reduced after splitting set 

<math display="inline" id="ID3_algorithm:26">
 <semantics>
  <mi>S</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>S</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   S
  </annotation>
 </semantics>
</math>

 on attribute 

<math display="inline" id="ID3_algorithm:27">
 <semantics>
  <mi>A</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>A</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   A
  </annotation>
 </semantics>
</math>

.</p>

<p>

<math display="block" id="ID3_algorithm:28">
 <semantics>
  <mrow>
   <mrow>
    <mi>I</mi>
    <mi>G</mi>
    <mrow>
     <mo stretchy="false">(</mo>
     <mi>A</mi>
     <mo>,</mo>
     <mi>S</mi>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
   <mo>=</mo>
   <mrow>
    <mrow>
     <mi>H</mi>
     <mrow>
      <mo stretchy="false">(</mo>
      <mi>S</mi>
      <mo stretchy="false">)</mo>
     </mrow>
    </mrow>
    <mo>-</mo>
    <mrow>
     <munder>
      <mo largeop="true" movablelimits="false" symmetric="true">∑</mo>
      <mrow>
       <mi>t</mi>
       <mo>∈</mo>
       <mi>T</mi>
      </mrow>
     </munder>
     <mrow>
      <mi>p</mi>
      <mrow>
       <mo stretchy="false">(</mo>
       <mi>t</mi>
       <mo stretchy="false">)</mo>
      </mrow>
      <mi>H</mi>
      <mrow>
       <mo stretchy="false">(</mo>
       <mi>t</mi>
       <mo stretchy="false">)</mo>
      </mrow>
     </mrow>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <times></times>
     <ci>I</ci>
     <ci>G</ci>
     <interval closure="open">
      <ci>A</ci>
      <ci>S</ci>
     </interval>
    </apply>
    <apply>
     <minus></minus>
     <apply>
      <times></times>
      <ci>H</ci>
      <ci>S</ci>
     </apply>
     <apply>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <sum></sum>
       <apply>
        <in></in>
        <ci>t</ci>
        <ci>T</ci>
       </apply>
      </apply>
      <apply>
       <times></times>
       <ci>p</ci>
       <ci>t</ci>
       <ci>H</ci>
       <ci>t</ci>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   IG(A,S)=H(S)-\sum_{t\in T}p(t)H(t)
  </annotation>
 </semantics>
</math>

</p>

<p>Where,</p>
<ul>
<li>

<math display="inline" id="ID3_algorithm:29">
 <semantics>
  <mrow>
   <mi>H</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <mi>S</mi>
    <mo stretchy="false">)</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <ci>H</ci>
    <ci>S</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   H(S)
  </annotation>
 </semantics>
</math>

 - Entropy of set 

<math display="inline" id="ID3_algorithm:30">
 <semantics>
  <mi>S</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>S</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   S
  </annotation>
 </semantics>
</math>

</li>
<li>

<math display="inline" id="ID3_algorithm:31">
 <semantics>
  <mi>T</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>T</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   T
  </annotation>
 </semantics>
</math>

 - The subsets created from splitting set 

<math display="inline" id="ID3_algorithm:32">
 <semantics>
  <mi>S</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>S</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   S
  </annotation>
 </semantics>
</math>

 by attribute 

<math display="inline" id="ID3_algorithm:33">
 <semantics>
  <mi>A</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>A</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   A
  </annotation>
 </semantics>
</math>

 such that 

<math display="inline" id="ID3_algorithm:34">
 <semantics>
  <mrow>
   <mi>S</mi>
   <mo>=</mo>
   <mrow>
    <msub>
     <mo largeop="true" mathsize="160%" stretchy="false" symmetric="true">⋃</mo>
     <mrow>
      <mi>t</mi>
      <mo>∈</mo>
      <mi>T</mi>
     </mrow>
    </msub>
    <mi>t</mi>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <ci>S</ci>
    <apply>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <union></union>
      <apply>
       <in></in>
       <ci>t</ci>
       <ci>T</ci>
      </apply>
     </apply>
     <ci>t</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   S=\bigcup_{t\in T}t
  </annotation>
 </semantics>
</math>

</li>
<li>

<math display="inline" id="ID3_algorithm:35">
 <semantics>
  <mrow>
   <mi>p</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <mi>t</mi>
    <mo stretchy="false">)</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <ci>p</ci>
    <ci>t</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   p(t)
  </annotation>
 </semantics>
</math>

 - The proportion of the number of elements in 

<math display="inline" id="ID3_algorithm:36">
 <semantics>
  <mi>t</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>t</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   t
  </annotation>
 </semantics>
</math>

 to the number of elements in set 

<math display="inline" id="ID3_algorithm:37">
 <semantics>
  <mi>S</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>S</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   S
  </annotation>
 </semantics>
</math>

</li>
<li>

<math display="inline" id="ID3_algorithm:38">
 <semantics>
  <mrow>
   <mi>H</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <mi>t</mi>
    <mo stretchy="false">)</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <ci>H</ci>
    <ci>t</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   H(t)
  </annotation>
 </semantics>
</math>

 - Entropy of subset 

<math display="inline" id="ID3_algorithm:39">
 <semantics>
  <mi>t</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>t</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   t
  </annotation>
 </semantics>
</math>

</li>
</ul>

<p>In ID3, information gain can be calculated (instead of entropy) for each remaining attribute. The attribute with the <strong>largest</strong> information gain is used to split the set 

<math display="inline" id="ID3_algorithm:40">
 <semantics>
  <mi>S</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>S</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   S
  </annotation>
 </semantics>
</math>

 on this iteration.</p>
<h2 id="see-also">See also</h2>
<ul>
<li><a href="Classification_and_regression_tree" title="wikilink">CART</a></li>
<li><a href="C4.5_algorithm" title="wikilink">C4.5 algorithm</a></li>
</ul>
<h2 id="references">References</h2>
<references>
</references>
<ul>
<li>Mitchell, Tom M. <em>Machine Learning</em>. McGraw-Hill, 1997. pp. 55–58.</li>
<li>Grzymala-Busse, Jerzy W. "Selected Algorithms of Machine Learning from Examples." <em>Fundamenta Informaticae</em> 18, (1993): 193–207.</li>
</ul>
<h2 id="further-reading">Further Reading</h2>
<ul>
<li><a href="http://jeremykun.com/2012/10/08/decision-trees-and-political-party-classification/">Decision Trees and Political Party Classification</a></li>
</ul>
<h2 id="external-links">External links</h2>
<ul>
<li>Seminars - <a href="http://www2.cs.uregina.ca/~hamilton/courses/831/notes/ml/dtrees/4_dtrees1.html"></a><a class="uri" href="http://www2.cs.uregina.ca/">http://www2.cs.uregina.ca/</a></li>
<li>Description and examples - <a href="http://www.cise.ufl.edu/~ddd/cap6635/Fall-97/Short-papers/2.htm"></a><a class="uri" href="http://www.cise.ufl.edu/">http://www.cise.ufl.edu/</a></li>
<li>Description and examples - <a href="http://www.cis.temple.edu/~ingargio/cis587/readings/id3-c45.html"></a><a class="uri" href="http://www.cis.temple.edu/">http://www.cis.temple.edu/</a></li>
<li><a href="http://www.onlamp.com/pub/a/python/2006/02/09/ai_decision_trees.html">An implementation of ID3 in Python</a></li>
<li><a href="http://ai4r.org/machineLearning.html">An implementation of ID3 in Ruby</a></li>
<li><a href="http://www.pvv.ntnu.no/~oyvinht/static/OSS/cl-id3/">An implementation of ID3 in Common Lisp</a></li>
<li><a href="http://www.codeproject.com/cs/algorithms/id3.asp">An implementation of ID3 algorithm in C#</a></li>
<li>[<a class="uri" href="https://metacpan.org/module/AI">https://metacpan.org/module/AI</a>::DecisionTree An implementation of ID3 in Perl]</li>
<li><a href="http://ftp.cs.stanford.edu/cs/robotics/shoham/prolog.tar.Z">An implementation of ID3 in Prolog</a></li>
<li><a href="http://id3alg.altervista.org">An implementation of ID3 in C (This code is commented in Italian)</a></li>
<li><a href="http://ipub.ch/id3-with-data-tree">An implementation of ID3 in R</a></li>
</ul>

<p>"</p>

<p><a href="Category:Decision_trees" title="wikilink">Category:Decision trees</a> <a href="Category:Classification_algorithms" title="wikilink">Category:Classification algorithms</a> <a href="Category:Articles_with_example_pseudocode" title="wikilink">Category:Articles with example pseudocode</a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1">Quinlan, J. R. 1986. Induction of Decision Trees. Mach. Learn. 1, 1 (Mar. 1986), 81-106<a href="#fnref1">↩</a></li>
</ol>
</section>
</body>
</html>
