   Parallel Processing (DSP implementation)      Parallel Processing (DSP implementation)   Parallel Processing in digital signal processing (DSP) is a technique duplicating function units to operate different tasks (signals) simultaneously. 1 Accordingly, we can perform the same processing for different signals on the corresponding duplicated function units. Further, due to the features of parallel processing , the parallel DSP design often contains multiple outputs, resulting in higher throughput than not parallel.  Conceptual Example  Consider a function unit ( F 0 ) and three tasks ( T 0 , T 1 and T 2 ). The required time for the function unit F 0 to process those tasks is t 0 , t 1 and t 2 respectively. Then, if we operate these three tasks in a sequential order, the required time to complete them is t 0 + t 1 + t 2 .    However, if we duplicate the function unit to another two copies ( F ), the aggregate time is reduced to max( t 0 , t 1 , t 2 ), which is smaller than in a sequential order.    Parallel Processing Versus Pipelining  Mechanism:   Parallel: duplicated function units working in parallel  Each task is processed entirely by a different function unit.   Pipelining : different function units working in parallel  Each task is split into a sequence of sub-tasks, which are handled by specialized and different function units.    Objective:   Pipelining leads to a reduction in the critical path, which can increase the sample speed or reduce power consumption at the same speed.  Parallel processing techniques require multiple outputs, which are computed in parallel in a clock period. Therefore, the effective sample speed is increased by the level of parallelism.   Consider a condition that we are able to apply both parallel processing and pipelining techniques, it is better to choose parallel processing techniques with the following reasons   Pipelining usually causes I/O bottlenecks  Parallel processing is also utilized for reduction of power consumption while using slow clocks  The hybrid method of pipelining and parallel processing further increase the speed of the architecture   Parallel FIR Filters  Consider a 3-tap FIR filter: 2      y   (  n  )    =    a  x   (  n  )    +   b  x   (   n  -  1   )    +   c  x   (   n  -  2   )           y  n       a  x  n     b  x    n  1      c  x    n  2       y(n)=ax(n)+bx(n-1)+cx(n-2)     which is shown in the following figure.  Assume the calculation time for multiplication units is T m and T a for add units. The sample period is given by       T   s  a  m  p  l  e    ≥    T  m   +   2   T  a          subscript  T    s  a  m  p  l  e       subscript  T  m     2   subscript  T  a       {T_{sample}\geq T_{m}+2T_{a}}     By parallelizing it, the resultant architecture is shown as follows. The sample rate now becomes      T   s  a  m  p  l  e    ≥    T   c  l  o  c  k    N   =     T  m   +   2   T  a     3          subscript  T    s  a  m  p  l  e       subscript  T    c  l  o  c  k    N             subscript  T  m     2   subscript  T  a     3      {T_{sample}\geq\frac{T_{clock}}{N}=\frac{T_{m}+2T_{a}}{3}}     where N represents the number of copies.  Please note that, in a parallel system,     T   s  a  m  p  l  e    ≠   T   c  l  o  c  k         subscript  T    s  a  m  p  l  e     subscript  T    c  l  o  c  k      T_{sample}\neq T_{clock}   while     T   s  a  m  p  l  e    =   T   c  l  o  c  k         subscript  T    s  a  m  p  l  e     subscript  T    c  l  o  c  k      T_{sample}=T_{clock}   holds in a pipelined system.  Parallel 1st-order IIR Filters  Consider the transfer function of a 1st–order IIR filter formulated as      H   (  z  )    =    z   -  1     1  -   a  *   z   -  1             H  z      superscript  z    1      1    a   superscript  z    1         H(z)=\frac{z^{-1}}{1-a*z^{-1}}     where | a |≤1 for stability, and such filter has only one pole located at z = a ;  The corresponding recursive representation is      y   (   n  +  1   )    =    a  y   (  n  )    +   u   (  n  )           y    n  1        a  y  n     u  n      y(n+1)=ay(n)+u(n)     Consider the design of a 4-parallel architecture ( N =4). In such parallel system, each delay element means a block delay and the clock period is four times the sample period. Therefore, by iterating the recursion with n =4 k , we have      y   (   n  +  4   )    =     a  4   y   (  n  )    +    a  3   u   (  n  )    +    a  2   u   (   n  +  1   )    +   a  u   (   n  +  2   )    +   u   (   n  +  3   )           y    n  4         superscript  a  4   y  n      superscript  a  3   u  n      superscript  a  2   u    n  1      a  u    n  2      u    n  3       y(n+4)=a^{4}y(n)+a^{3}u(n)+a^{2}u(n+1)+au(n+2)+u(n+3)        →   y   (    4  k   +  4   )    =     a  4   y   (   4  k   )    +    a  3   u   (   4  k   )    +    a  2   u   (    4  k   +  1   )    +   a  u   (    4  k   +  2   )    +   u   (    4  k   +  3   )          normal-→  absent    y      4  k   4              superscript  a  4   y    4  k       superscript  a  3   u    4  k       superscript  a  2   u      4  k   1      a  u      4  k   2      u      4  k   3        \rightarrow y(4k+4)=a^{4}y(4k)+a^{3}u(4k)+a^{2}u(4k+1)+au(4k+2)+u(4k+3)     The corresponding architecture is shown as follows.  (Figure)  Parallel IIR.png   The resultant parallel design has the following properties.   The pole of the original filter is at z = a while the pole for the parallel system is at z = a 4 which is closer to the origin.  The pole movement improves the robustness of the system to the round-off noise.  Hardware complexity of this architecture: N * N multiply-add operations.   Please note that the square increase in hardware complexity can be reduced by exploiting the concurrency and the incremental computation to avoid repeated computing.  Parallel Processing for Low Power  Another advantage for the parallel processing techniques is that it can reduce the power consumption of a system by reducing the supply voltage. Consider the following power consumption in a normal CMOS circuit.      P   s  e  q    =    C   t  o  t  a  l    *   V  0  2   *  f        subscript  P    s  e  q       subscript  C    t  o  t  a  l     superscript   subscript  V  0   2   f     P_{seq}=C_{total}*V_{0}^{2}*f     where the C total represents the total capacitance of the CMOS circuit.  For a parallel version, the charging capacitance remains the same but the total capacitance increases by N times. In order to maintain the same sample rate, the clock period of the N -parallel circuit increases to N times the propagation delay of the original circuit. It makes the charging time prolongs N times. The supply voltage can be reduced to β V 0 .  Therefore, the power consumption of the N-parallel system can be formulated as      P   p  a  r  a    =    (   N   C   t  o  t  a  l     )   *   (   β   V  0  2    )   *   f  N    =    β  2   *   P   s  e  q            subscript  P    p  a  r  a        N   subscript  C    t  o  t  a  l       β   superscript   subscript  V  0   2      f  N            superscript  β  2    subscript  P    s  e  q        P_{para}=(NC_{total})*(\beta V_{0}^{2})*\frac{f}{N}=\beta^{2}*P_{seq}     where β can be computed by       N    (    β   V  0    -   V  t    )   2    =   β    (    V  0   -   V  t    )   2          N   superscript      β   subscript  V  0     subscript  V  t    2      β   superscript     subscript  V  0    subscript  V  t    2      N(\beta V_{0}-V_{t})^{2}=\beta(V_{0}-V_{t})^{2}     References    "  Category:Digital signal processing     K.K. Parhi, VLSI Digital Signal Processing Systems: Design and Implementation, John Wiley, 1999 ↩  Slides for VLSI Digital Signal Processing Systems: Design and Implementation John Wiley & Sons, 1999 (ISBN Number: 0-471-24186-5): http://www.ece.umn.edu/users/parhi/slides.html ↩     