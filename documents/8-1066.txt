   Kolmogorov extension theorem      Kolmogorov extension theorem   In mathematics , the Kolmogorov extension theorem (also known as Kolmogorov existence theorem or Kolmogorov consistency theorem ) is a theorem that guarantees that a suitably "consistent" collection of finite-dimensional distributions will define a stochastic process . It is credited to the Soviet  mathematician  Andrey Nikolaevich Kolmogorov . 1  Statement of the theorem  Let   T   T   T   denote some interval (thought of as " time "), and let    n  ∈  ℕ      n  ℕ    n\in\mathbb{N}   . For each    k  ∈  ℕ      k  ℕ    k\in\mathbb{N}   and finite sequence of times      t  1   ,  …  ,   t  k    ∈  T        subscript  t  1   normal-…   subscript  t  k    T    t_{1},\dots,t_{k}\in T   , let    ν    t  1   …   t  k       subscript  ν     subscript  t  1   normal-…   subscript  t  k      \nu_{t_{1}\dots t_{k}}   be a probability measure on     (   ℝ  n   )   k     superscript   superscript  ℝ  n   k    (\mathbb{R}^{n})^{k}   . Suppose that these measures satisfy two consistency conditions:  1. for all permutations    π   π   \pi   of    {  1  ,  …  ,  k  }     1  normal-…  k    \{1,\dots,k\}   and measurable sets     F  i   ⊆   ℝ  n        subscript  F  i    superscript  ℝ  n     F_{i}\subseteq\mathbb{R}^{n}   ,         ν    t   π   (  1  )     …   t   π   (  k  )        (    F   π   (  1  )     ×  …  ×   F   π   (  k  )      )    =    ν    t  1   …   t  k      (    F  1   ×  …  ×   F  k    )     ;         subscript  ν     subscript  t    π  1    normal-…   subscript  t    π  k         subscript  F    π  1    normal-…   subscript  F    π  k         subscript  ν     subscript  t  1   normal-…   subscript  t  k        subscript  F  1   normal-…   subscript  F  k       \nu_{t_{\pi(1)}\dots t_{\pi(k)}}\left(F_{\pi(1)}\times\dots\times F_{\pi(k)}%
 \right)=\nu_{t_{1}\dots t_{k}}\left(F_{1}\times\dots\times F_{k}\right);     2. for all measurable sets     F  i   ⊆   ℝ  n        subscript  F  i    superscript  ℝ  n     F_{i}\subseteq\mathbb{R}^{n}   ,    m  ∈  ℕ      m  ℕ    m\in\mathbb{N}            ν    t  1   …   t  k      (    F  1   ×  …  ×   F  k    )    =    ν     t  1   …   t  k    t   k  +  1     ,  …  ,   t   k  +  m       (    F  1   ×  …  ×   F  k   ×   ℝ  n   ×  …  ×   ℝ  n    )     .         subscript  ν     subscript  t  1   normal-…   subscript  t  k        subscript  F  1   normal-…   subscript  F  k        subscript  ν      subscript  t  1   normal-…   subscript  t  k    subscript  t    k  1     normal-…   subscript  t    k  m         subscript  F  1   normal-…   subscript  F  k    superscript  ℝ  n   normal-…   superscript  ℝ  n       \nu_{t_{1}\dots t_{k}}\left(F_{1}\times\dots\times F_{k}\right)=\nu_{t_{1}%
 \dots t_{k}t_{k+1},\dots,t_{k+m}}\left(F_{1}\times\dots\times F_{k}\times%
 \mathbb{R}^{n}\times\dots\times\mathbb{R}^{n}\right).   Then there exists a probability space     (  Ω  ,  ℱ  ,  ℙ  )     normal-Ω  ℱ  ℙ    (\Omega,\mathcal{F},\mathbb{P})   and a stochastic process    X  :    T  ×  Ω   →   ℝ  n       normal-:  X   normal-→    T  normal-Ω    superscript  ℝ  n      X:T\times\Omega\to\mathbb{R}^{n}   such that       ν    t  1   …   t  k      (   F  1   ×  …  ×   F  k   )   =  ℙ   (   X   t  1    ∈   F  1   ,  …  ,   X   t  k    ∈   F  k   )      fragments   subscript  ν     subscript  t  1   normal-…   subscript  t  k      fragments  normal-(   subscript  F  1    normal-…    subscript  F  k   normal-)    P   fragments  normal-(   subscript  X   subscript  t  1      subscript  F  1   normal-,  normal-…  normal-,   subscript  X   subscript  t  k      subscript  F  k   normal-)     \nu_{t_{1}\dots t_{k}}\left(F_{1}\times\dots\times F_{k}\right)=\mathbb{P}%
 \left(X_{t_{1}}\in F_{1},\dots,X_{t_{k}}\in F_{k}\right)   for all     t  i   ∈  T       subscript  t  i   T    t_{i}\in T   ,    k  ∈  ℕ      k  ℕ    k\in\mathbb{N}   and measurable sets     F  i   ⊆   ℝ  n        subscript  F  i    superscript  ℝ  n     F_{i}\subseteq\mathbb{R}^{n}   , i.e.   X   X   X   has    ν    t  1   …   t  k       subscript  ν     subscript  t  1   normal-…   subscript  t  k      \nu_{t_{1}\dots t_{k}}   as its finite-dimensional distributions relative to times     t  1   …   t  k        subscript  t  1   normal-…   subscript  t  k     t_{1}\dots t_{k}   .  In fact, it is always possible to take as the underlying probability space    Ω  =    (   ℝ  n   )   T       normal-Ω   superscript   superscript  ℝ  n   T     \Omega=(\mathbb{R}^{n})^{T}   and to take for   X   X   X   the canonical process    X  :    (  t  ,  Y  )   ↦   Y  t       normal-:  X   maps-to   t  Y    subscript  Y  t      X\colon(t,Y)\mapsto Y_{t}   . Therefore, an alternative way of stating Kolomogorov's extension theorem is that, provided that the above consistency conditions hold, there exists a (unique) measure   ν   ν   \nu   on     (   ℝ  n   )   T     superscript   superscript  ℝ  n   T    (\mathbb{R}^{n})^{T}   with marginals    ν    t  1   …   t  k       subscript  ν     subscript  t  1   normal-…   subscript  t  k      \nu_{t_{1}\dots t_{k}}   for any finite collection of times     t  1   …   t  k        subscript  t  1   normal-…   subscript  t  k     t_{1}\dots t_{k}   . Kolmogorov's extension theorem applies when   T   T   T   is uncountable, but the price to pay for this level of generality is that the measure   ν   ν   \nu   is only defined on the product σ-algebra of     (   ℝ  n   )   T     superscript   superscript  ℝ  n   T    (\mathbb{R}^{n})^{T}   , which is not very rich.  Explanation of the conditions  The two conditions required by the theorem are trivially satisfied by any stochastic process. For example, consider a real-valued discrete-time stochastic process   X   X   X   . Then the probability    ℙ   (   X  1   >  0  ,   X  2   <  0  )      fragments  P   fragments  normal-(   subscript  X  1    0  normal-,   subscript  X  2    0  normal-)     \mathbb{P}(X_{1}>0,X_{2}<0)   can be computed either as     ν   1  ,  2     (    ℝ  +   ×   ℝ  -    )        subscript  ν   1  2       subscript  ℝ     subscript  ℝ       \nu_{1,2}(\mathbb{R}_{+}\times\mathbb{R}_{-})   or as     ν   2  ,  1     (    ℝ  -   ×   ℝ  +    )        subscript  ν   2  1       subscript  ℝ     subscript  ℝ       \nu_{2,1}(\mathbb{R}_{-}\times\mathbb{R}_{+})   . Hence, for the finite-dimensional distributions to be consistent, it must hold that      ν   1  ,  2     (    ℝ  +   ×   ℝ  -    )    =    ν   2  ,  1     (    ℝ  -   ×   ℝ  +    )           subscript  ν   1  2       subscript  ℝ     subscript  ℝ         subscript  ν   2  1       subscript  ℝ     subscript  ℝ        \nu_{1,2}(\mathbb{R}_{+}\times\mathbb{R}_{-})=\nu_{2,1}(\mathbb{R}_{-}\times%
 \mathbb{R}_{+})   . The first condition generalises this obvious statement to hold for any number of time points    t  i     subscript  t  i    t_{i}   , and any control sets    F  i     subscript  F  i    F_{i}   .  Continuing the example, the second condition implies that    ℙ   (   X  1   >  0  )   =  ℙ   (   X  1   >  0  ,   X  2   ∈  ℝ  )      fragments  P   fragments  normal-(   subscript  X  1    0  normal-)    P   fragments  normal-(   subscript  X  1    0  normal-,   subscript  X  2    R  normal-)     \mathbb{P}(X_{1}>0)=\mathbb{P}(X_{1}>0,X_{2}\in\mathbb{R})   . Also this is a trivial condition that will be satisfied by any consistent family of finite-dimensional distributions.  Implications of the theorem  Since the two conditions are trivially satisfied for any stochastic process, the power of the theorem is that no other conditions are required: For any reasonable (i.e., consistent) family of finite-dimensional distributions, there exists a stochastic process with these distributions.  The measure-theoretic approach to stochastic processes starts with a probability space and defines a stochastic process as a family of functions on this probability space. However, in many applications the starting point is really the finite-dimensional distributions of the stochastic process. The theorem says that provided the finite-dimensional distributions satisfy the obvious consistency requirements, one can always identify a probability space to match the purpose. In many situations, this means that one does not have to be explicit about what the probability space is. Many texts on stochastic processes do, indeed, assume a probability space but never state explicitly what it is.  The theorem is used in one of the standard proofs of existence of a Brownian motion , by specifying the finite dimensional distributions to be Gaussian random variables, satisfying the consistency conditions above. As in most of the definitions of Brownian motion it is required that the sample paths are continuous almost surely, one then uses kolmogorov continuity theorem to construct a continuous modification of the process constructed by Kolmogorov extension theorem.  A more general form of the theorem  The Kolmogorov extension theorem gives us conditions for a collection of measures on Euclidean spaces to be the finite-dimensional distributions of some    ℝ  n     superscript  ℝ  n    \mathbb{R}^{n}   -valued stochastic process, but the assumption that the state space be    ℝ  n     superscript  ℝ  n    \mathbb{R}^{n}   is unnecessary. In fact, any collection of measurable spaces together with a collection of inner regular measures defined on the finite products of these spaces would suffice, provided that these measures satisfy a certain compatibility relation. The formal statement of the general theorem is as follows. 2  Let   T   T   T   be any set. Let     {   (   Ω  t   ,   ℱ  t   )   }    t  ∈  T      subscript     subscript  normal-Ω  t    subscript  ℱ  t       t  T     \{(\Omega_{t},\mathcal{F}_{t})\}_{t\in T}   be some collection of measurable spaces, and for each    t  ∈  T      t  T    t\in T   , let    τ  t     subscript  τ  t    \tau_{t}   be a Hausdorff topology on    Ω  t     subscript  normal-Ω  t    \Omega_{t}   . For each subset    J  ⊂  T      J  T    J\subset T   , define       Ω  J   :=    ∏   t  ∈  J     Ω  t       assign   subscript  normal-Ω  J     subscript  product    t  J     subscript  normal-Ω  t      \Omega_{J}:=\prod_{t\in J}\Omega_{t}   .  For subsets    I  ⊂  J  ⊂  T        I  J       T     I\subset J\subset T   , let     π   I  ←  J    :    Ω  J   →   Ω  I       normal-:   subscript  π   normal-←  I  J     normal-→   subscript  normal-Ω  J    subscript  normal-Ω  I      \pi_{I\leftarrow J}:\Omega_{J}\to\Omega_{I}   denote the canonical projection map    ω  ↦    ω  |   I      maps-to  ω   evaluated-at  ω  I     \omega\mapsto\omega|_{I}   .  For each finite subset    F  ⊂  T      F  T    F\subset T   , suppose we have a probability measure    μ  F     subscript  μ  F    \mu_{F}   on    Ω  F     subscript  normal-Ω  F    \Omega_{F}   which is inner regular with respect to the product topology (induced by the    τ  t     subscript  τ  t    \tau_{t}   ) on    Ω  F     subscript  normal-Ω  F    \Omega_{F}   . Suppose also that this collection    {   μ  F   }      subscript  μ  F     \{\mu_{F}\}   of measures satisfies the following compatibility relation: for finite subsets    F  ⊂  G  ⊂  T        F  G       T     F\subset G\subset T   , we have that       μ  F   =     (   π   F  ←  G    )   *    μ  G         subscript  μ  F      subscript   subscript  π   normal-←  F  G       subscript  μ  G      \mu_{F}=(\pi_{F\leftarrow G})_{*}\mu_{G}     where      (   π   F  ←  G    )   *    μ  G        subscript   subscript  π   normal-←  F  G       subscript  μ  G     (\pi_{F\leftarrow G})_{*}\mu_{G}   denotes the pushforward measure of    μ  G     subscript  μ  G    \mu_{G}   induced by the canonical projection map    π   F  ←  G      subscript  π   normal-←  F  G     \pi_{F\leftarrow G}   .  Then there exists a unique probability measure   μ   μ   \mu   on    Ω  T     subscript  normal-Ω  T    \Omega_{T}   such that     μ  F   =     (   π   F  ←  T    )   *   μ        subscript  μ  F      subscript   subscript  π   normal-←  F  T      μ     \mu_{F}=(\pi_{F\leftarrow T})_{*}\mu   for every finite subset    F  ⊂  T      F  T    F\subset T   .  As a remark, all of the measures     μ  F   ,  μ      subscript  μ  F   μ    \mu_{F},\mu   are defined on the product sigma algebra on their respective spaces, which (as mentioned before) is rather coarse. The measure   μ   μ   \mu   may sometimes be extended appropriately to a larger sigma algebra, if there is additional structure involved.  Note that the original statement of the theorem is just a special case of this theorem with     Ω  t   =   ℝ  n        subscript  normal-Ω  t    superscript  ℝ  n     \Omega_{t}=\mathbb{R}^{n}   for all    t  ∈  T      t  T    t\in T   , and     μ   {   t  1   ,  …  ,   t  k   }    =   ν    t  1   …   t  k          subscript  μ    subscript  t  1   normal-…   subscript  t  k      subscript  ν     subscript  t  1   normal-…   subscript  t  k       \mu_{\{t_{1},...,t_{k}\}}=\nu_{t_{1}\dots t_{k}}   for      t  1   ,  …  ,   t  k    ∈  T        subscript  t  1   normal-…   subscript  t  k    T    t_{1},...,t_{k}\in T   . The stochastic process would simply be the canonical process     (   π  t   )    t  ∈  T      subscript   subscript  π  t     t  T     (\pi_{t})_{t\in T}   , defined on    Ω  =    (   ℝ  n   )   T       normal-Ω   superscript   superscript  ℝ  n   T     \Omega=(\mathbb{R}^{n})^{T}   with probability measure    P  =  μ      P  μ    P=\mu   . The reason that the original statement of the theorem does not mention inner regularity of the measures    ν    t  1   …   t  k       subscript  ν     subscript  t  1   normal-…   subscript  t  k      \nu_{t_{1}\dots t_{k}}   is that this would automatically follow, since Borel probability measures on Polish spaces are automatically Radon .  This theorem has many far-reaching consequences; for example it can be used to prove the existence of the following, among others:   Brownian motion, i.e., the Wiener process ,  a Markov chain taking values in a given state space with a given transition matrix,  the random-cluster model on infinite lattices with given parameters    p  ,  q     p  q    p,q   ,  infinite products of (inner-regular) probability spaces.   History  According to John Aldrich, the theorem was independently discovered by British mathematician Percy John Daniell in the slightly different setting of integration theory. 3  References  External links  Aldrich, J. (2007) "But you have to remember P.J.Daniell of Sheffield"  Electronic Journ@l for History of Probability and Statistics December 2007.  "  Category:Stochastic processes  Category:Probability theorems     ↩  T. Tao, An Introduction to Measure Theory , Graduate Studies in Mathematics, Vol. 126, 2011, p. 195 ↩  J. Aldrich, But you have to remember PJ Daniell of Sheffield, Electronic Journal for History of Probability and Statistics, Vol. 3, number 2, 2007 ↩     