


Basel problem




Basel problem

The Basel problem is a problem in mathematical analysis with relevance to number theory, first posed by Pietro Mengoli in 1644 and solved by Leonhard Euler in 17341 and read on 5 December 1735 in The Saint Petersburg Academy of Sciences ().2 Since the problem had withstood the attacks of the leading mathematicians of the day, Euler's solution brought him immediate fame when he was twenty-eight. Euler generalised the problem considerably, and his ideas were taken up years later by Bernhard Riemann in his seminal 1859 paper On the Number of Primes Less Than a Given Magnitude, in which he defined his zeta function and proved its basic properties. The problem is named after Basel, hometown of Euler as well as of the Bernoulli family who unsuccessfully attacked the problem.
The Basel problem asks for the precise summation of the reciprocals of the squares of the natural numbers, i.e. the precise sum of the infinite series:



The series is approximately equal to 1.644934 . The Basel problem asks for the exact sum of this series (in closed form), as well as a proof that this sum is correct. Euler found the exact sum to be 
 
 
 
  and announced this discovery in 1735. His arguments were based on manipulations that were not justified at the time, and it was not until 1741 that he was able to produce a truly rigorous proof.
Euler's approach
Euler's original derivation of the value π2/6 essentially extended observations about finite polynomials and assumed that these same properties hold true for infinite series.
Of course, Euler's original reasoning requires justification (100 years later, Weierstrass proved that Euler's representation of the sine function as an infinite product is correct, see: Weierstrass factorization theorem), but even without justification, by simply obtaining the correct value, he was able to verify it numerically against partial sums of the series. The agreement he observed gave him sufficient confidence to announce his result to the mathematical community.
To follow Euler's argument, recall the Taylor series expansion of the sine function



Dividing through by x, we have



Using the Weierstrass factorization theorem, it can also be shown that the left-hand side is the product of linear factors given by its roots, just as we do for finite polynomials (which Euler assumed, but is not always true):



If we formally multiply out this product and collect all the x2 terms (we are allowed to do so because of Newton's identities), we see that the x2 coefficient of sin(x)/x is



But from the original infinite series expansion of sin(x)/x, the coefficient of x2 is −1/(3!) = −1/6. These two coefficients must be equal; thus,



Multiplying through both sides of this equation by 
 
 
 
  gives the sum of the reciprocals of the positive square integers.



The Riemann zeta function
The Riemann zeta function

 
  is one of the most important functions in mathematics, because of its relationship to the distribution of the prime numbers. The function is defined for any complex number s with real part > 1 by the following formula:



Taking s = 2, we see that 
 
 
 
  is equal to the sum of the reciprocals of the squares of the positive integers:



Convergence can be proven with the following inequality:



This gives us the upper bound 
 
 
 
 , and because the infinite sum has only positive terms, it must converge. It can be shown that 
 
 
 
  has a nice expression in terms of the Bernoulli numbers whenever s is a positive even integer. With 
 
 
 
 :



A rigorous proof using Fourier series
Let 
 
 
 
  over the interval x ∈ (–
 
 
 
 ,
 
 
 
 ). The Fourier series for this function (worked out in that article) is



Then, using Parseval's identity (with 
 
 
 
 ) we have that


 
 ,
where



for n ≠ 0, and a0 = 0. Thus,



for n ≠ 0 and



Therefore,



as required.
A rigorous elementary proof
This is by far the most elementary well-known proof; while most proofs use results from advanced mathematics, such as Fourier analysis, complex analysis, and multivariable calculus, the following does not even require single-variable calculus (although a single limit is taken at the end).
For a proof using the residue theorem, see the linked article.
History of this proof
The proof goes back to Augustin Louis Cauchy (Cours d'Analyse, 1821, Note VIII). In 1954, this proof appeared in the book of Akiva and Isaak Yaglom "Nonelementary Problems in an Elementary Exposition". Later, in 1982, it appeared in the journal Eureka, attributed to John Scholes, but Scholes claims he learned the proof from Peter Swinnerton-Dyer, and in any case he maintains the proof was "common knowledge at Cambridge in the late 1960s".
The proof
The main idea behind the proof is to bound the partial sums



between two expressions, each of which will tend to 
 
 
2/6 as m approaches infinity. The two expressions are derived from identities involving the cotangent and cosecant functions. These identities are in turn derived from de Moivre's formula, and we now turn to establishing these identities.
Let 
 
 
 
  be a real number with 
 
 

From the binomial theorem, we have



Combining the two equations and equating imaginary parts gives the identity



We take this identity, fix a positive integer 
 
 
 
 , set 
 
 
 
  and consider 
 
 
 
  for 
 
 
 
 . Then 
 
 
 
  is a multiple of 
 
 
 
  and therefore a zero of the sine function, and so



for every 
 
 
 
 . The values 
 
 
 
  are distinct numbers in the interval (0, 
 
 
 
 /2). Since the function 
 
 
 
  is one-to-one on this interval, the numbers 
 
 
 
  are distinct for r = 1, 2, …, m. By the above equation, these m numbers are the roots of the mth degree polynomial



By Viète's formulas we can calculate the sum of the roots directly by examining the first two coefficients of the polynomial, and this comparison shows that



Substituting the identity 
 
 
 
 , we have



Now consider the inequality 
 
 
 
 . If we add up all these inequalities for each of the numbers 
 
 
 
 , and if we use the two identities above, we get



Multiplying through by (
 
 
 
 /(2m + 1))2, this becomes



As m approaches infinity, the left and right hand expressions each approach 
 
 
 
 , so by the squeeze theorem,



and this completes the proof.
Packing squares with side 1/n
The solution to the Basel problem is related to packing squares with side length of 
 
 
 
 . The question that is asked is "What is the smallest rectangle that can contain the squares as n approaches infinity?"3 One bound to the answer is dependent on one rectangle side, 
 
 
 
 , to be the sum of the largest two squares sides summed together,


 
 .
The other rectangle side, 
 
 
 
 , depends on the order of remaining squares. However, we know that total area, A, of the squares (minus the square with n=1) is:


 
 .
Dividing the square's total area by the one known rectangle side leaves the ideal rectangle side length,
$$S_2 = \frac{A}{S_1} = \frac{\frac{\pi ^2}{6} - 1}{\frac{5}{6}} = \frac{\pi ^2 - 6}{5} = 0.77392088021 \cdots$$ .
The current packing record holder is Marc Paulhus, who developed a packing algorithm.4
See also

Riemann zeta function

References


.

.

.


.

Notes
External links

An infinite series of surprises by C. J. Sangwin

, English translation with notes of Euler’s paper by Lucas Willis and Thomas J. Osler



, Fourteen proofs compiled by Robin Chapman

"
Category:Number theory Category:Articles containing proofs Category:Zeta and L-functions Category:Mathematical problems



↩
E41 -- De summis serierum reciprocarum↩
↩
↩




