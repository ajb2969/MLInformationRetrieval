   Sum of normally distributed random variables      Sum of normally distributed random variables   In probability theory , calculation of the sum of normally distributed random variables is an instance of the arithmetic of random variables , which can be quite complex based on the probability distributions of the random variables involved and their relationships.  Independent random variables  If X and Y are independent  random variables that are normally distributed (and therefore also jointly so), then their sum is also normally distributed. i.e., if      X  ∼   N   (   μ  X   ,   σ  X  2   )       similar-to  X    N    subscript  μ  X    superscript   subscript  σ  X   2       X\sim N(\mu_{X},\sigma_{X}^{2})         Y  ∼   N   (   μ  Y   ,   σ  Y  2   )       similar-to  Y    N    subscript  μ  Y    superscript   subscript  σ  Y   2       Y\sim N(\mu_{Y},\sigma_{Y}^{2})          Z  =   X  +  Y    ,      Z    X  Y     Z=X+Y,     then       Z  ∼   N   (    μ  X   +   μ  Y    ,    σ  X  2   +   σ  Y  2    )     .     similar-to  Z    N      subscript  μ  X    subscript  μ  Y       superscript   subscript  σ  X   2    superscript   subscript  σ  Y   2        Z\sim N(\mu_{X}+\mu_{Y},\sigma_{X}^{2}+\sigma_{Y}^{2}).     This means that the sum of two independent normally distributed random variables is normal, with its mean being the sum of the two means, and its variance being the sum of the two variances (i.e., the square of the standard deviation is the sum of the squares of the standard deviations).  Note that the result that the sum is normally distributed requires the assumption of independence, not just uncorrelatedness ; two separately (not jointly) normally distributed random variables can be uncorrelated without being independent, in which case their sum can be non-normally distributed (see Normally distributed and uncorrelated does not imply independent#A symmetric example ). The result about the mean holds in all cases, while the result for the variance requires uncorrelatedness, but not independence.  Proofs  Proof using characteristic functions  The characteristic function        φ   X  +  Y     (  t  )    =   E   (   e   i  t   (   X  +  Y   )     )           subscript  φ    X  Y    t    normal-E   superscript  e    i  t    X  Y        \varphi_{X+Y}(t)=\operatorname{E}\left(e^{it(X+Y)}\right)     of the sum of two independent random variables X and Y is just the product of the two separate characteristic functions:         φ  X    (  t  )    =   E   (   e   i  t  X    )     ,     φ  Y    (  t  )    =   E   (   e   i  t  Y    )        formulae-sequence       subscript  φ  X   t    normal-E   superscript  e    i  t  X           subscript  φ  Y   t    normal-E   superscript  e    i  t  Y        \varphi_{X}(t)=\operatorname{E}\left(e^{itX}\right),\qquad\varphi_{Y}(t)=%
 \operatorname{E}\left(e^{itY}\right)     of X and Y .  The characteristic function of the normal distribution with expected value μ and variance σ 2 is        φ   (  t  )    =   exp   (    i  t  μ   -     σ  2    t  2    2    )     .        φ  t         i  t  μ        superscript  σ  2    superscript  t  2    2       \varphi(t)=\exp\left(it\mu-{\sigma^{2}t^{2}\over 2}\right).     So         φ   X  +  Y     (  t  )    =    φ  X    (  t  )    φ  Y    (  t  )    =    exp   (    i  t   μ  X    -     σ  X  2    t  2    2    )     exp   (    i  t   μ  Y    -     σ  Y  2    t  2    2    )     =   exp   (    i  t   (    μ  X   +   μ  Y    )    -     (    σ  X  2   +   σ  Y  2    )    t  2    2    )     .           subscript  φ    X  Y    t      subscript  φ  X   t   subscript  φ  Y   t                i  t   subscript  μ  X         superscript   subscript  σ  X   2    superscript  t  2    2           i  t   subscript  μ  Y         superscript   subscript  σ  Y   2    superscript  t  2    2                 i  t     subscript  μ  X    subscript  μ  Y            superscript   subscript  σ  X   2    superscript   subscript  σ  Y   2     superscript  t  2    2        \varphi_{X+Y}(t)=\varphi_{X}(t)\varphi_{Y}(t)=\exp\left(it\mu_{X}-{\sigma_{X}^%
 {2}t^{2}\over 2}\right)\exp\left(it\mu_{Y}-{\sigma_{Y}^{2}t^{2}\over 2}\right)%
 =\exp\left(it(\mu_{X}+\mu_{Y})-{(\sigma_{X}^{2}+\sigma_{Y}^{2})t^{2}\over 2}%
 \right).     This is the characteristic function of the normal distribution with expected value     μ  X   +   μ  Y        subscript  μ  X    subscript  μ  Y     \mu_{X}+\mu_{Y}   and variance     σ  X  2   +   σ  Y  2        superscript   subscript  σ  X   2    superscript   subscript  σ  Y   2     \sigma_{X}^{2}+\sigma_{Y}^{2}     Finally, recall that no two distinct distributions can both have the same characteristic function, so the distribution of X + Y must be just this normal distribution.  Proof using convolutions  For independent random variables X and Y , the distribution f Z of Z = X + Y equals the convolution of f X and f Y :        f  Z    (  z  )    =    ∫   -  ∞   ∞     f  Y    (   z  -  x   )    f  X    (  x  )   d  x           subscript  f  Z   z     superscript   subscript             subscript  f  Y     z  x    subscript  f  X   x  d  x      f_{Z}(z)=\int_{-\infty}^{\infty}f_{Y}(z-x)f_{X}(x)dx     Given that f X and f Y are normal densities,        f  X    (  x  )    =    1     2  π     σ  X      e   -     (   x  -   μ  X    )   2    2   σ  X  2               subscript  f  X   x       1        2  π     subscript  σ  X      superscript  e       superscript    x   subscript  μ  X    2     2   superscript   subscript  σ  X   2          f_{X}(x)=\frac{1}{\sqrt{2\pi}\sigma_{X}}e^{-{(x-\mu_{X})^{2}\over 2\sigma_{X}^%
 {2}}}           f  Y    (  y  )    =    1     2  π     σ  Y      e   -     (   y  -   μ  Y    )   2    2   σ  Y  2               subscript  f  Y   y       1        2  π     subscript  σ  Y      superscript  e       superscript    y   subscript  μ  Y    2     2   superscript   subscript  σ  Y   2          f_{Y}(y)=\frac{1}{\sqrt{2\pi}\sigma_{Y}}e^{-{(y-\mu_{Y})^{2}\over 2\sigma_{Y}^%
 {2}}}     Substituting into the convolution:        f  Z    (  z  )    =    ∫   -  ∞   ∞     1     2  π     σ  Y      e   -     (   z  -  x  -   μ  Y    )   2    2   σ  Y  2        1     2  π     σ  X      e   -     (   x  -   μ  X    )   2    2   σ  X  2       d  x           subscript  f  Z   z     superscript   subscript              1        2  π     subscript  σ  Y      superscript  e       superscript    z  x   subscript  μ  Y    2     2   superscript   subscript  σ  Y   2         1        2  π     subscript  σ  X      superscript  e       superscript    x   subscript  μ  X    2     2   superscript   subscript  σ  X   2       d  x      f_{Z}(z)=\int_{-\infty}^{\infty}\frac{1}{\sqrt{2\pi}\sigma_{Y}}e^{-{(z-x-\mu_{%
 Y})^{2}\over 2\sigma_{Y}^{2}}}\frac{1}{\sqrt{2\pi}\sigma_{X}}e^{-{(x-\mu_{X})^%
 {2}\over 2\sigma_{X}^{2}}}dx          =    ∫   -  ∞   ∞     1     2  π       σ  X  2   +   σ  Y  2        exp   [   -     (   z  -   (    μ  X   +   μ  Y    )    )   2    2   (    σ  X  2   +   σ  Y  2    )      ]     1     2  π       σ  X    σ  Y       σ  X  2   +   σ  Y  2         exp   [   -     (   x  -      σ  X  2    (   z  -   μ  Y    )    +    σ  Y  2    μ  X       σ  X  2   +   σ  Y  2      )   2    2    (     σ  X    σ  Y       σ  X  2   +   σ  Y  2      )   2      ]    d  x        absent    superscript   subscript              1        2  π         superscript   subscript  σ  X   2    superscript   subscript  σ  Y   2              superscript    z     subscript  μ  X    subscript  μ  Y     2     2     superscript   subscript  σ  X   2    superscript   subscript  σ  Y   2          1        2  π         subscript  σ  X    subscript  σ  Y         superscript   subscript  σ  X   2    superscript   subscript  σ  Y   2               superscript    x         superscript   subscript  σ  X   2     z   subscript  μ  Y        superscript   subscript  σ  Y   2    subscript  μ  X        superscript   subscript  σ  X   2    superscript   subscript  σ  Y   2      2     2   superscript       subscript  σ  X    subscript  σ  Y         superscript   subscript  σ  X   2    superscript   subscript  σ  Y   2      2       d  x      =\int_{-\infty}^{\infty}\frac{1}{\sqrt{2\pi}\sqrt{\sigma_{X}^{2}+\sigma_{Y}^{2%
 }}}\exp\left[-{(z-(\mu_{X}+\mu_{Y}))^{2}\over 2(\sigma_{X}^{2}+\sigma_{Y}^{2})%
 }\right]\frac{1}{\sqrt{2\pi}\frac{\sigma_{X}\sigma_{Y}}{\sqrt{\sigma_{X}^{2}+%
 \sigma_{Y}^{2}}}}\exp\left[-\frac{\left(x-\frac{\sigma_{X}^{2}(z-\mu_{Y})+%
 \sigma_{Y}^{2}\mu_{X}}{\sigma_{X}^{2}+\sigma_{Y}^{2}}\right)^{2}}{2\left(\frac%
 {\sigma_{X}\sigma_{Y}}{\sqrt{\sigma_{X}^{2}+\sigma_{Y}^{2}}}\right)^{2}}\right%
 ]dx          =    1    2  π   (    σ  X  2   +   σ  Y  2    )       exp   [   -     (   z  -   (    μ  X   +   μ  Y    )    )   2    2   (    σ  X  2   +   σ  Y  2    )      ]      ∫   -  ∞   ∞     1     2  π       σ  X    σ  Y       σ  X  2   +   σ  Y  2         exp   [   -     (   x  -      σ  X  2    (   z  -   μ  Y    )    +    σ  Y  2    μ  X       σ  X  2   +   σ  Y  2      )   2    2    (     σ  X    σ  Y       σ  X  2   +   σ  Y  2      )   2      ]    d  x         absent      1      2  π     superscript   subscript  σ  X   2    superscript   subscript  σ  Y   2              superscript    z     subscript  μ  X    subscript  μ  Y     2     2     superscript   subscript  σ  X   2    superscript   subscript  σ  Y   2          superscript   subscript              1        2  π         subscript  σ  X    subscript  σ  Y         superscript   subscript  σ  X   2    superscript   subscript  σ  Y   2               superscript    x         superscript   subscript  σ  X   2     z   subscript  μ  Y        superscript   subscript  σ  Y   2    subscript  μ  X        superscript   subscript  σ  X   2    superscript   subscript  σ  Y   2      2     2   superscript       subscript  σ  X    subscript  σ  Y         superscript   subscript  σ  X   2    superscript   subscript  σ  Y   2      2       d  x       =\frac{1}{\sqrt{2\pi(\sigma_{X}^{2}+\sigma_{Y}^{2})}}\exp\left[-{(z-(\mu_{X}+%
 \mu_{Y}))^{2}\over 2(\sigma_{X}^{2}+\sigma_{Y}^{2})}\right]\int_{-\infty}^{%
 \infty}\frac{1}{\sqrt{2\pi}\frac{\sigma_{X}\sigma_{Y}}{\sqrt{\sigma_{X}^{2}+%
 \sigma_{Y}^{2}}}}\exp\left[-\frac{\left(x-\frac{\sigma_{X}^{2}(z-\mu_{Y})+%
 \sigma_{Y}^{2}\mu_{X}}{\sigma_{X}^{2}+\sigma_{Y}^{2}}\right)^{2}}{2\left(\frac%
 {\sigma_{X}\sigma_{Y}}{\sqrt{\sigma_{X}^{2}+\sigma_{Y}^{2}}}\right)^{2}}\right%
 ]dx     The expression in the integral is a normal density distribution on x , and so the integral evaluates to 1. The desired result follows:        f  Z    (  z  )    =    1    2  π   (    σ  X  2   +   σ  Y  2    )       exp   [   -     (   z  -   (    μ  X   +   μ  Y    )    )   2    2   (    σ  X  2   +   σ  Y  2    )      ]            subscript  f  Z   z       1      2  π     superscript   subscript  σ  X   2    superscript   subscript  σ  Y   2              superscript    z     subscript  μ  X    subscript  μ  Y     2     2     superscript   subscript  σ  X   2    superscript   subscript  σ  Y   2           f_{Z}(z)=\frac{1}{\sqrt{2\pi(\sigma_{X}^{2}+\sigma_{Y}^{2})}}\exp\left[-{(z-(%
 \mu_{X}+\mu_{Y}))^{2}\over 2(\sigma_{X}^{2}+\sigma_{Y}^{2})}\right]     Geometric proof  First consider the normalized case when X , Y ~ N (0, 1), so that their PDFs are       f   (  x  )    =      1  /  2    π      e   -    x  2   /  2            f  x           1  2   π     superscript  e       superscript  x  2   2        f(x)=\sqrt{1/2\pi\,}e^{-x^{2}/2}   and        g   (  y  )    =      1  /  2    π      e   -    y  2   /  2       .        g  y           1  2   π     superscript  e       superscript  y  2   2        g(y)=\sqrt{1/2\pi\,}e^{-y^{2}/2}.   Let Z = X + Y . Then the CDF for Z will be       z  ↦    ∫    x  +  y   ≤  z     f   (  x  )   g   (  y  )   d   x   d  y     .     maps-to  z    subscript       x  y   z      f  x  g  y  d  x  d  y      z\mapsto\int_{x+y\leq z}f(x)g(y)\,dx\,dy.   This integral is over the half-plane which lies under the line x + y = z .  The key observation is that the function       f   (  x  )   g   (  y  )    =    (    1  /  2   π   )     e   -    (    x  2   +   y  2    )   /  2             f  x  g  y         1  2   π    superscript  e         superscript  x  2    superscript  y  2    2        f(x)g(y)=(1/2\pi)e^{-(x^{2}+y^{2})/2}\,     is radially symmetric. So we rotate the coordinate plane about the origin, choosing new coordinates     x  ′   ,   y  ′       superscript  x  normal-′    superscript  y  normal-′     x^{\prime},y^{\prime}   such that the line x + y = z is described by the equation     x  ′   =  c       superscript  x  normal-′   c    x^{\prime}=c   where    c  =   c   (  z  )        c    c  z     c=c(z)   is determined geometrically. Because of the radial symmetry, we have     f   (  x  )   g   (  y  )    =   f   (   x  ′   )   g   (   y  ′   )          f  x  g  y     f   superscript  x  normal-′   g   superscript  y  normal-′      f(x)g(y)=f(x^{\prime})g(y^{\prime})   , and the CDF for Z is        ∫     x  ′   ≤  c   ,    y  ′   ∈   \reals       f   (   x  ′   )   g   (   y  ′   )   d    x  ′    d   y  ′     .      subscript    formulae-sequence     superscript  x  normal-′   c      superscript  y  normal-′   \reals       f   superscript  x  normal-′   g   superscript  y  normal-′   d   superscript  x  normal-′   d   superscript  y  normal-′      \int_{x^{\prime}\leq c,y^{\prime}\in\reals}f(x^{\prime})g(y^{\prime})\,dx^{%
 \prime}\,dy^{\prime}.     This is easy to integrate; we find that the CDF for Z is         ∫   -  ∞    c   (  z  )      f   (   x  ′   )   d   x  ′     =   Φ   (   c   (  z  )    )     .        superscript   subscript          c  z      f   superscript  x  normal-′   d   superscript  x  normal-′       normal-Φ    c  z      \int_{-\infty}^{c(z)}f(x^{\prime})\,dx^{\prime}=\Phi(c(z)).     To determine the value    c   (  z  )       c  z    c(z)   , note that we rotated the plane so that the line x + y = z now runs vertically with x -intercept equal to c . So c is just the distance from the origin to the line x + y = z along the perpendicular bisector, which meets the line at its nearest point to the origin, in this case    (   z  /  2   ,   z  /  2   )       z  2     z  2     (z/2,z/2)\,   . So the distance is    c  =      (   z  /  2   )   2   +    (   z  /  2   )   2     =   z  /    2           c       superscript    z  2   2    superscript    z  2   2            z    2       c=\sqrt{(z/2)^{2}+(z/2)^{2}}=z/\sqrt{2}\,   , and the CDF for Z is    Φ   (   z  /   2    )       normal-Φ    z    2      \Phi(z/\sqrt{2})   , i.e.,     Z  =   X  +  Y   ∼   N   (  0  ,  2  )     .        Z    X  Y     similar-to      N   0  2       Z=X+Y\sim N(0,2).     Now, if a , b are any real constants (not both zero!) then the probability that      a  X   +   b  Y    ≤  z          a  X     b  Y    z    aX+bY\leq z   is found by the same integral as above, but with the bounding line      a  x   +   b  y    =  z          a  x     b  y    z    ax+by=z   . The same rotation method works, and in this more general case we find that the closest point on the line to the origin is located a (signed) distance      z     a  2   +   b  2         z       superscript  a  2    superscript  b  2       \frac{z}{\sqrt{a^{2}+b^{2}}}   away, so that         a  X   +   b  Y    ∼   N   (  0  ,    a  2   +   b  2    )     .     similar-to      a  X     b  Y      N   0     superscript  a  2    superscript  b  2        aX+bY\sim N(0,a^{2}+b^{2}).   The same argument in higher dimensions shows that if         X  i   ∼   N   (  0  ,   σ  i  2   )     ,   i  =   1  ,  …  ,  n     ,     formulae-sequence   similar-to   subscript  X  i     N   0   superscript   subscript  σ  i   2        i   1  normal-…  n      X_{i}\sim N(0,\sigma_{i}^{2}),\qquad i=1,\dots,n,   then         X  1   +  ⋯  +   X  n    ∼   N   (  0  ,    σ  1  2   +  ⋯  +   σ  n  2    )     .     similar-to     subscript  X  1   normal-⋯   subscript  X  n      N   0     superscript   subscript  σ  1   2   normal-⋯   superscript   subscript  σ  n   2        X_{1}+\cdots+X_{n}\sim N(0,\sigma_{1}^{2}+\cdots+\sigma_{n}^{2}).     Now we are essentially done, because        X  ∼   N   (  μ  ,   σ  2   )     ⇔     1  σ    (   X  -  μ   )    ∼   N   (  0  ,  1  )      .     normal-⇔   similar-to  X    N   μ   superscript  σ  2       similar-to      1  σ     X  μ      N   0  1       X\sim N(\mu,\sigma^{2})\Leftrightarrow\frac{1}{\sigma}(X-\mu)\sim N(0,1).   So in general, if         X  i   ∼   N   (   μ  i   ,   σ  i  2   )     ,   i  =   1  ,  …  ,  n     ,     formulae-sequence   similar-to   subscript  X  i     N    subscript  μ  i    superscript   subscript  σ  i   2        i   1  normal-…  n      X_{i}\sim N(\mu_{i},\sigma_{i}^{2}),\qquad i=1,\dots,n,   then         ∑   i  =  1   n     a  i    X  i     ∼   N   (    ∑   i  =  1   n     a  i    μ  i     ,    ∑   i  =  1   n     (    a  i    σ  i    )   2    )     .     similar-to    superscript   subscript     i  1    n      subscript  a  i    subscript  X  i       N     superscript   subscript     i  1    n      subscript  a  i    subscript  μ  i       superscript   subscript     i  1    n    superscript     subscript  a  i    subscript  σ  i    2        \sum_{i=1}^{n}a_{i}X_{i}\sim N\left(\sum_{i=1}^{n}a_{i}\mu_{i},\sum_{i=1}^{n}(%
 a_{i}\sigma_{i})^{2}\right).     Correlated random variables  In the event that the variables X and Y are jointly normally distributed random variables, then X + Y is still normally distributed (see Multivariate normal distribution ) and the mean is the sum of the means. However, the variances are not additive due to the correlation. Indeed,        σ   X  +  Y    =     σ  X  2   +   σ  Y  2   +   2  ρ   σ  X    σ  Y       ,       subscript  σ    X  Y         superscript   subscript  σ  X   2    superscript   subscript  σ  Y   2     2  ρ   subscript  σ  X    subscript  σ  Y        \sigma_{X+Y}=\sqrt{\sigma_{X}^{2}+\sigma_{Y}^{2}+2\rho\sigma_{X}\sigma_{Y}},     where ρ is the correlation . In particular, whenever ρ \frac{1}{2 \pi \sigma_x \sigma_y \sqrt{1-\rho^2}} \iint_{x\,y} \exp \left[ -\frac{1}{2(1-\rho^2)} \left(\frac{x^2}{\sigma_x^2} + \frac{y^2}{\sigma_y^2} - \frac{2 \rho x y}{\sigma_x\sigma_y}\right)\right] \delta(z - (x+y))\, \operatorname{d}x\,\operatorname{d}y.  As above, one makes the substitution    y  →   z  -  x      normal-→  y    z  x     y\rightarrow z-x     This integral is more complicated to simplify analytically, but can be done easily using a symbolic mathematics program. The probability distribution f Z ( z ) is given in this case by        f  Z    (  z  )    =    1     2  π     σ  +      exp   (   -    z  2    2   σ  +  2      )            subscript  f  Z   z       1        2  π     subscript  σ             superscript  z  2     2   superscript   subscript  σ    2          f_{Z}(z)=\frac{1}{\sqrt{2\pi}\sigma_{+}}\exp\left(-\frac{z^{2}}{2\sigma_{+}^{2%
 }}\right)   where        σ  +   =     σ  x  2   +   σ  y  2   +   2  ρ   σ  x    σ  y       .       subscript  σ         superscript   subscript  σ  x   2    superscript   subscript  σ  y   2     2  ρ   subscript  σ  x    subscript  σ  y        \sigma_{+}=\sqrt{\sigma_{x}^{2}+\sigma_{y}^{2}+2\rho\sigma_{x}\sigma_{y}}.     If one considers instead Z = X − Y , then one obtains        f  Z    (  z  )    =    1    2  π   (     σ  x  2   +   σ  y  2    -   2  ρ   σ  x    σ  y     )       exp   (   -    z  2    2   (     σ  x  2   +   σ  y  2    -   2  ρ   σ  x    σ  y     )      )            subscript  f  Z   z       1      2  π       superscript   subscript  σ  x   2    superscript   subscript  σ  y   2      2  ρ   subscript  σ  x    subscript  σ  y               superscript  z  2     2       superscript   subscript  σ  x   2    superscript   subscript  σ  y   2      2  ρ   subscript  σ  x    subscript  σ  y            f_{Z}(z)=\frac{1}{\sqrt{2\pi(\sigma_{x}^{2}+\sigma_{y}^{2}-2\rho\sigma_{x}%
 \sigma_{y})}}\exp\left(-\frac{z^{2}}{2(\sigma_{x}^{2}+\sigma_{y}^{2}-2\rho%
 \sigma_{x}\sigma_{y})}\right)   which also can be rewritten with        σ  -   =      σ  x  2   +   σ  y  2    -   2  ρ   σ  x    σ  y       .       subscript  σ           superscript   subscript  σ  x   2    superscript   subscript  σ  y   2      2  ρ   subscript  σ  x    subscript  σ  y        \sigma_{-}=\sqrt{\sigma_{x}^{2}+\sigma_{y}^{2}-2\rho\sigma_{x}\sigma_{y}}.     The standard deviations of each distribution are obvious by comparison with the standard normal distribution.  See also   Algebra of random variables  Stable distribution  Standard error (statistics)  Ratio distribution  Product distribution  Slash distribution  List of convolutions of probability distributions  Not to be confused with: Mixture distribution   "  Normal  Category:Normal distribution   