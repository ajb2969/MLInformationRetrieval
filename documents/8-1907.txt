   Adaptive quadrature      Adaptive quadrature   In applied mathematics , adaptive quadrature is a process in which the integral of a function     f   (  x  )       f  x    f(x)   is approximated using static quadrature rules on adaptively refined subintervals of the integration domain . Generally, adaptive algorithms are just as efficient and effective as traditional algorithms for "well behaved" integrands, but are also effective for "badly behaved" integrands for which traditional algorithms fail.  General scheme  Adaptive quadrature follows the general scheme  1. procedure integrate ( f, a, b, tau )  2.     Q  ≈    ∫  a  b    f   (  x  )   d  x        Q    superscript   subscript   a   b     f  x  d  x      Q\approx\int_{a}^{b}f(x)\,\mbox{d}x     3.     ε  ≈   |   Q  -    ∫  a  b    f   (  x  )   d  x     |       ε      Q    superscript   subscript   a   b     f  x  d  x        \varepsilon\approx\left|Q-\int_{a}^{b}f(x)\,\mbox{d}x\right|     4. if      ε  >  τ      ε  τ    \varepsilon>\tau     then  5.       m = (a + b) / 2  6.       Q = integrate(f,a,m,tau/2) + integrate(f,m,b,tau/2)  7. endif  8. return Q  An approximation   Q   Q   Q   to the integral of    f   (  x  )       f  x    f(x)   over the interval    [  a  ,  b  ]     a  b    [a,b]   is computed (line 2), as well as an error estimate   ε   ε   \varepsilon   (line 3). If the estimated error is larger than the required tolerance   τ   τ   \tau   (line 4), the interval is subdivided (line 5) and the quadrature is applied on both halves separately (line 6). Either the initial estimate or the sum of the recursively computed halves is returned (line 7).  The important components are the quadrature rule itself       Q  ≈    ∫  a  b    f   (  x  )   d  x     ,      Q    superscript   subscript   a   b     f  x  d  x      Q\approx\int_{a}^{b}f(x)\,\mbox{d}x,     the error estimator       ε  ≈   |   Q  -    ∫  a  b    f   (  x  )   d  x     |    ,      ε      Q    superscript   subscript   a   b     f  x  d  x        \varepsilon\approx\left|Q-\int_{a}^{b}f(x)\,\mbox{d}x\right|,     and the logic for deciding which interval to subdivide, and when to terminate.  There are several variants of this scheme. The most common will be discussed later.  Basic rules  The quadrature rules generally have the form       Q  n   =    ∑   i  =  0   n     w  i   f   (   x  i   )     ≈    ∫  a  b    f   (  x  )   d  x        subscript  Q  n      superscript   subscript     i  0    n      subscript  w  i   f   subscript  x  i        superscript   subscript   a   b     f  x  d  x      Q_{n}\quad=\quad\sum_{i=0}^{n}w_{i}f(x_{i})\quad\approx\quad\int_{a}^{b}f(x)\,%
 \mbox{d}x     where the nodes    x  i     subscript  x  i    x_{i}   and weights    w  i     subscript  w  i    w_{i}   are generally precomputed.  In the simplest case, Newton–Cotes formulas of even degree are used, where the nodes    x  i     subscript  x  i    x_{i}   are evenly spaced in the interval:       x  i   =   a  +    i  n    (   b  -  a   )          subscript  x  i     a      i  n     b  a       x_{i}=a+\frac{i}{n}(b-a)   .  When such rules are used, the points at which    f   (  x  )       f  x    f(x)   has been evaluated can be re-used upon recursion:      A similar strategy is used with Clenshaw–Curtis quadrature , where the nodes are chosen as       x  i   =   cos   (     2  i   n   π   )         subscript  x  i           2  i   n   π      x_{i}=\cos\left(\frac{2i}{n}\pi\right)   .  Or, when Fejér quadrature is used,       x  i   =   cos   (     2   (   i  +  0.5   )     n  +  1    π   )         subscript  x  i           2    i  0.5      n  1    π      x_{i}=\cos\left(\frac{2(i+0.5)}{n+1}\pi\right)   .  Other quadrature rules, such as Gaussian quadrature or Gauss-Kronrod quadrature , may also be used.  An algorithm may elect to use different quadrature methods on different subintervals, for example using a high-order method only where the integrand is smooth.  Error estimation  Some quadrature algorithms generate a sequence of results which should approach the correct value. Otherwise one can use a "null rule" which has the form of the above quadrature rule, but whose value would be zero for a simple integrand (for example, if the integrand were a polynomial of the appropriate degree).  See:   Richardson extrapolation (see also Romberg's method )  Null rules  Epsilon algorithm   Subdivision logic  "Local" adaptive quadrature makes the acceptable error for a given interval proportional to the length of that interval. This criterion can be difficult to satisfy if the integrands are badly behaved at only a few points, for example with a few step discontinuities. Alternatively, one could require only that the sum of the errors on each of the subintervals be less than the user's requirement. This would be "global" adaptive quadrature. Global adaptive quadrature can be more efficient (using fewer evaluations of the integrand) but is generally more complex to program and may require more working space to record information on the current set of intervals.  See also   Adaptive Simpson's method for an example of adaptive quadrature  QUADPACK , a FORTRAN library that uses global adaptive quadrature   Notes  References   [ http://portal.acm.org/citation.cfm?id=369102&dl; ;=GUIDE&coll;=GUIDE&CFID;=26917988&CFTOKEN;=19121185 William M. McKeeman: Algorithm 145: Adaptive numerical integration by Simpson's rule. Commun. ACM 5(12): 604 (1962).]  [ http://portal.acm.org/citation.cfm?id=321870&dl; ;=GUIDE&coll;=GUIDE&CFID;=26917988&CFTOKEN;=19121185 John R. Rice. A Metalgorithm for Adaptive Quadrature. Journal of the ACM 22(1) pp 61-82 (January 1975).]    "  Category:Numerical integration (quadrature)   