   Affinity propagation      Affinity propagation   In statistics and data mining , affinity propagation (AP) is a clustering algorithm based on the concept of "message passing" between data points. 1 Unlike clustering algorithms such as    k   k   k   -means or    k   k   k   -medoids , AP does not require the number of clusters to be determined or estimated before running the algorithm. Like   k   k   k   -medoids, AP finds "exemplars", members of the input set that are representative of clusters. 2  Algorithm  Let through be a set of data points, with no assumptions made about their internal structure, and let   s   s   s   be a function that quantifies the similarity between any two points, such that  iff  is more similar to than to .  The algorithm proceeds by alternating two message passing steps, to update two matrices: 3   The "responsibility" matrix   𝐑   𝐑   \mathbf{R}   has values    r   (  i  ,  k  )       r   i  k     r(i,k)   that quantify how well-suited is to serve as the exemplar for , relative to other candidate exemplars for .  The "availability" matrix   𝐀   𝐀   \mathbf{A}   contains values    a   (  i  ,  k  )       a   i  k     a(i,k)   represents how "appropriate" it would be for to pick as its exemplar, taking into account other points' preference for as an exemplar.   Both matrices are initialized to all zeroes, and can be viewed as log-probability tables. The algorithm then performs the following updates iteratively:   First, responsibility updates are sent around     r   (  i  ,  k  )    ←    s   (  i  ,  k  )    -    max    k  ′   ≠  k     {    a   (  i  ,   k  ′   )    +   s   (  i  ,   k  ′   )     }        normal-←    r   i  k        s   i  k      subscript      superscript  k  normal-′   k        a   i   superscript  k  normal-′       s   i   superscript  k  normal-′          r(i,k)\leftarrow s(i,k)-\max_{k^{\prime}\neq k}\left\{a(i,k^{\prime})+s(i,k^{%
 \prime})\right\}     Then, availability is updated per          a   (  i  ,  k  )    ←   min   (  0  ,    r   (  k  ,  k  )    +    ∑    i  ′   ∉   {  i  ,  k  }      max   (  0  ,   r   (   i  ′   ,  k  )    )      )       normal-←    a   i  k      0      r   k  k      subscript      superscript  i  normal-′    i  k       0    r    superscript  i  normal-′   k          a(i,k)\leftarrow\min\left(0,r(k,k)+\sum_{i^{\prime}\not\in\{i,k\}}\max(0,r(i^{%
 \prime},k))\right)   for    i  ≠  k      i  k    i\neq k   and       a   (  k  ,  k  )    ←    ∑    i  ′   ≠  k     max   (  0  ,   r   (   i  ′   ,  k  )    )        normal-←    a   k  k      subscript      superscript  i  normal-′   k      0    r    superscript  i  normal-′   k        a(k,k)\leftarrow\sum_{i^{\prime}\neq k}\max(0,r(i^{\prime},k))   .     Applications  The inventors of affinity propagation showed it is better for certain computer vision and computational biology tasks, e.g. clustering of pictures of human faces and identifying regulated transcripts, than   k   k   k   -means, 4 even when   k   k   k   -means was allowed many random restarts and initialized using PCA . 5 A study comparing AP and Markov clustering on protein interaction graph partitioning found Markov clustering to work better for that problem. 6 A semi-supervised variant has been proposed for text mining applications. 7  Software   A Java implementation is included in the ELKI data mining framework.  Java  Apro library implements parallelized Affinity Propagation and Hierarchical AP.  A Julia implementation of affinity propagation is contained in Julia Statistics's Clustering.jl package. 8  A Python version is part of the scikit-learn library. 9  An R implementation is available in the "apcluster" package. 10   References  "  Category:Data clustering algorithms     ↩     ↩  ↩  ↩  Clustering.jl www.github.com ↩  ↩  apcluster cran.r-project.org> ↩     