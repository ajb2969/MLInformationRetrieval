   Matrix splitting      Matrix splitting   In the mathematical discipline of numerical linear algebra , a matrix splitting is an expression which represents a given matrix as a sum or difference of matrices. Many iterative methods (e.g., for systems of differential equations ) depend upon the direct solution of matrix equations involving matrices more general than tridiagonal matrices . These matrix equations can often be solved directly and efficiently when written as a matrix splitting. The technique was devised by Richard S. Varga in 1960. 1  Regular splittings  We seek to solve the matrix equation       ğ”¸  ğ•©   =   ğ•œ  ,   (  1  )          ğ”¸  ğ•©    ğ•œ  1     \mathbb{A}\mathbb{x}=\mathbb{k},\quad(1)     where A is a given n Ã— n  non-singular matrix, and k is a given column vector with n components. We split the matrix A into      ğ”¸  =    ğ”¹  -  â„‚   ,   (  2  )        ğ”¸     ğ”¹  â„‚   2     \mathbb{A}=\mathbb{B}-\mathbb{C},\quad(2)     where B and C are n Ã— n matrices. If, for an arbitrary n Ã— n matrix M , M has nonnegative entries, we write M â‰¥ 0 . If M has only positive entries, we write M > 0 . Similarly, if the matrix M 1 âˆ’ M 2 has nonnegative entries, we write M 1 â‰¥ M 2 .  Definition: A = B âˆ’ C is a regular splitting of A if and only if B âˆ’1 â‰¥ 0 and C â‰¥ 0 .  We assume that matrix equations of the form       ğ”¹  ğ•©   =   ğ•˜  ,   (  3  )          ğ”¹  ğ•©    ğ•˜  3     \mathbb{B}\mathbb{x}=\mathbb{g},\quad(3)     where g is a given column vector, can be solved directly for the vector x . If (2) represents a regular splitting of A , then the iterative method        ğ”¹   ğ•©   (   m  +  1   )     =    â„‚   ğ•©   (  m  )     +  ğ•œ    ,   m  =   0  ,  1  ,  2  ,  â€¦  ,   (  4  )        formulae-sequence      ğ”¹   superscript  ğ•©    m  1         â„‚   superscript  ğ•©  m    ğ•œ      m   0  1  2  normal-â€¦  4      \mathbb{B}\mathbb{x}^{(m+1)}=\mathbb{C}\mathbb{x}^{(m)}+\mathbb{k},\quad m=0,1%
 ,2,\ldots,\quad(4)     where x (0) is an arbitrary vector, can be carried out. Equivalently, we write (4) in the form        ğ•©   (   m  +  1   )    =     ğ”¹   -  1    â„‚   ğ•©   (  m  )     +    ğ”¹   -  1    ğ•œ     ,   m  =   0  ,  1  ,  2  ,  â€¦   (  5  )        formulae-sequence     superscript  ğ•©    m  1         superscript  ğ”¹    1    â„‚   superscript  ğ•©  m       superscript  ğ”¹    1    ğ•œ       m   0  1  2  normal-â€¦  5      \mathbb{x}^{(m+1)}=\mathbb{B}^{-1}\mathbb{C}\mathbb{x}^{(m)}+\mathbb{B}^{-1}%
 \mathbb{k},\quad m=0,1,2,\ldots\quad(5)     The matrix D = B âˆ’1 C has nonnegative entries if (2) represents a regular splitting of A . 2  It can be shown that if A âˆ’1 > 0 , then    Ï   (  ğ”»  )       Ï  ğ”»    \rho(\mathbb{D})   \rho (\bold D) represents the spectral radius of D , and thus D is a convergent matrix . As a consequence, the iterative method (5) is necessarily convergent . 3 4  If, in addition, the splitting (2) is chosen so that the matrix B is a diagonal matrix (with the diagonal entries all non-zero, since B must be invertible ), then B can be inverted in linear time (see Time complexity ).  Matrix iterative methods  Many iterative methods can be described as a matrix splitting. If the diagonal entries of the matrix A are all nonzero, and we express the matrix A as the matrix sum      ğ”¸  =    ğ”»  -  ğ•Œ  -  ğ•ƒ   ,   (  6  )        ğ”¸     ğ”»  ğ•Œ  ğ•ƒ   6     \mathbb{A}=\mathbb{D}-\mathbb{U}-\mathbb{L},\quad(6)     where D is the diagonal part of A , and U and L are respectively strictly upper and lower triangular  n Ã— n matrices, then we have the following.  The Jacobi method can be represented in matrix form as a splitting       ğ•©   (   m  +  1   )    =   ğ”»   -  1     (  ğ•Œ  +  ğ•ƒ  )    ğ•©   (  m  )    +   ğ”»   -  1    ğ•œ  .   (  7  )      fragments   superscript  ğ•©    m  1      superscript  ğ”»    1     fragments  normal-(  U   L  normal-)    superscript  ğ•©  m     superscript  ğ”»    1    k  normal-.    fragments  normal-(  7  normal-)     \mathbb{x}^{(m+1)}=\mathbb{D}^{-1}(\mathbb{U}+\mathbb{L})\mathbb{x}^{(m)}+%
 \mathbb{D}^{-1}\mathbb{k}.\quad(7)    5 6  The Gauss-Seidel method can be represented in matrix form as a splitting       ğ•©   (   m  +  1   )    =    (  ğ”»  -  ğ•ƒ  )    -  1    ğ•Œ   ğ•©   (  m  )    +    (  ğ”»  -  ğ•ƒ  )    -  1    ğ•œ  .   (  8  )      fragments   superscript  ğ•©    m  1      superscript   fragments  normal-(  D   L  normal-)     1    U   superscript  ğ•©  m     superscript   fragments  normal-(  D   L  normal-)     1    k  normal-.    fragments  normal-(  8  normal-)     \mathbb{x}^{(m+1)}=(\mathbb{D}-\mathbb{L})^{-1}\mathbb{U}\mathbb{x}^{(m)}+(%
 \mathbb{D}-\mathbb{L})^{-1}\mathbb{k}.\quad(8)    7 8  The method of successive over-relaxation can be represented in matrix form as a splitting       ğ•©   (   m  +  1   )    =    (  ğ”»  -  Ï‰  ğ•ƒ  )    -  1     [   (  1  -  Ï‰  )   ğ”»  +  Ï‰  ğ•Œ  ]    ğ•©   (  m  )    +  Ï‰    (  ğ”»  -  Ï‰  ğ•ƒ  )    -  1    ğ•œ  .   (  9  )      fragments   superscript  ğ•©    m  1      superscript   fragments  normal-(  D   Ï‰  L  normal-)     1     fragments  normal-[   fragments  normal-(  1   Ï‰  normal-)   D   Ï‰  U  normal-]    superscript  ğ•©  m    Ï‰   superscript   fragments  normal-(  D   Ï‰  L  normal-)     1    k  normal-.    fragments  normal-(  9  normal-)     \mathbb{x}^{(m+1)}=(\mathbb{D}-\omega\mathbb{L})^{-1}[(1-\omega)\mathbb{D}+%
 \omega\mathbb{U}]\mathbb{x}^{(m)}+\omega(\mathbb{D}-\omega\mathbb{L})^{-1}%
 \mathbb{k}.\quad(9)    9 10  Example  Regular splitting  In equation (1), let      ğ€  =   (     6     -  2      -  3        -  1     4     -  2        -  3      -  1     5     )   ,  ğ¤  =   (     5       -  12       10     )   .   (  10  )      fragments  A     6    2     3       1   4    2       3     1   5    normal-,  k     5      12     10    normal-.    fragments  normal-(  10  normal-)     \displaystyle\mathbf{A}=\begin{pmatrix}6&-2&-3\\
 -1&4&-2\\
 -3&-1&5\end{pmatrix},\quad\mathbf{k}=\begin{pmatrix}5\\
 -12\\
 10\end{pmatrix}.\quad(10)   Let us apply the splitting (7) which is used in the Jacobi method: we split A in such a way that B consists of all of the diagonal elements of A , and C consists of all of the off-diagonal elements of A , negated. (Of course this is not the only useful way to split a matrix into two matrices.) We have       ğ  =   (     6    0    0      0    4    0      0    0    5     )    ,   ğ‚  =    (     0    2    3      1    0    2      3    1    0     )   ,   (  11  )        formulae-sequence    ğ    6  0  0    0  4  0    0  0  5       ğ‚     0  2  3    1  0  2    3  1  0    11      \displaystyle\mathbf{B}=\begin{pmatrix}6&0&0\\
 0&4&0\\
 0&0&5\end{pmatrix},\quad\mathbf{C}=\begin{pmatrix}0&2&3\\
 1&0&2\\
 3&1&0\end{pmatrix},\quad(11)            ğ€   -  ğŸ    =     1  47     (     18    13    16      11    21    15      13    12    22     )     ,    ğ   -  ğŸ    =   (      1  6     0    0      0     1  4     0      0    0     1  5      )     ,     formulae-sequence     superscript  ğ€    1        1  47     18  13  16    11  21  15    13  12  22         superscript  ğ    1        1  6   0  0    0    1  4   0    0  0    1  5        \displaystyle\mathbf{A^{-1}}=\frac{1}{47}\begin{pmatrix}18&13&16\\
 11&21&15\\
 13&12&22\end{pmatrix},\quad\mathbf{B^{-1}}=\begin{pmatrix}\frac{1}{6}&0&0\\
 0&\frac{1}{4}&0\\
 0&0&\frac{1}{5}\end{pmatrix},           ğƒ  =    ğ   -  ğŸ    ğ‚   =   (     0     1  3      1  2        1  4     0     1  2        3  5      1  5     0     )    ,     ğ   -  ğŸ    ğ¤   =   (      5  6        -  3       2     )     .     formulae-sequence      ğƒ     superscript  ğ    1    ğ‚          0    1  3     1  2       1  4   0    1  2       3  5     1  5   0           superscript  ğ    1    ğ¤       5  6       3     2       \displaystyle\mathbf{D}=\mathbf{B^{-1}C}=\begin{pmatrix}0&\frac{1}{3}&\frac{1}%
 {2}\\
 \frac{1}{4}&0&\frac{1}{2}\\
 \frac{3}{5}&\frac{1}{5}&0\end{pmatrix},\quad\mathbf{B^{-1}k}=\begin{pmatrix}%
 \frac{5}{6}\\
 -3\\
 2\end{pmatrix}.   Since B âˆ’1 â‰¥ 0 and C â‰¥ 0 , the splitting (11) is a regular splitting. Since A âˆ’1 > 0 , the spectral radius    Ï   (  ğ”»  )       Ï  ğ”»    \rho(\mathbb{D})   \lambda_i â‰ˆ â€“0.4599820, â€“0.3397859, 0.7997679.) Hence, the matrix D is convergent and the method (5) necessarily converges for the problem (10). Note that the diagonal elements of A are all greater than zero, the off-diagonal elements of A are all less than zero and A is strictly diagonally dominant . 11  The method (5) applied to the problem (10) then takes the form        ğ•©   (   m  +  1   )    =        (     0      1  3        1  2          1  4      0      1  2          3  5        1  5      0     )    ğ•©   (  m  )     +   (       5  6         -  3       2     )        ,   m  =   0  ,  1  ,  2  ,  â€¦   (  12  )        formulae-sequence     superscript  ğ•©    m  1            0    1  3     1  2       1  4   0    1  2       3  5     1  5   0     superscript  ğ•©  m        5  6       3     2          m   0  1  2  normal-â€¦  12      \mathbb{x}^{(m+1)}=\begin{aligned}\displaystyle\begin{pmatrix}0&\frac{1}{3}&%
 \frac{1}{2}\\
 \frac{1}{4}&0&\frac{1}{2}\\
 \frac{3}{5}&\frac{1}{5}&0\end{pmatrix}\mathbb{x}^{(m)}+\begin{pmatrix}\frac{5}%
 {6}\\
 -3\\
 2\end{pmatrix}\end{aligned},\quad m=0,1,2,\ldots\quad(12)     The exact solution to equation (12) is      ğ±  =   (     2       -  1       3     )   .   (  13  )      fragments  x     2      1     3    normal-.    fragments  normal-(  13  normal-)     \displaystyle\mathbf{x}=\begin{pmatrix}2\\
 -1\\
 3\end{pmatrix}.\quad(13)   The first few iterates for equation (12) are listed in the table below, beginning with x (0) = (0.0, 0.0, 0.0) T . From the table one can see that the method is evidently converging to the solution (13), albeit rather slowly.          x  1   (  m  )      subscript   superscript  x  m   1    x^{(m)}_{1}          x  2   (  m  )      subscript   superscript  x  m   2    x^{(m)}_{2}          x  3   (  m  )      subscript   superscript  x  m   3    x^{(m)}_{3}             0.0   0.0   0.0         0.0   0.0   0.0         0.0   0.0   0.0           0.83333   0.83333   0.83333          -  3.0000      3.0000    -3.0000         2.0000   2.0000   2.0000           0.83333   0.83333   0.83333          -  1.7917      1.7917    -1.7917         1.9000   1.9000   1.9000           1.1861   1.1861   1.1861          -  1.8417      1.8417    -1.8417         2.1417   2.1417   2.1417           1.2903   1.2903   1.2903          -  1.6326      1.6326    -1.6326         2.3433   2.3433   2.3433           1.4608   1.4608   1.4608          -  1.5058      1.5058    -1.5058         2.4477   2.4477   2.4477           1.5553   1.5553   1.5553          -  1.4110      1.4110    -1.4110         2.5753   2.5753   2.5753           1.6507   1.6507   1.6507          -  1.3235      1.3235    -1.3235         2.6510   2.6510   2.6510           1.7177   1.7177   1.7177          -  1.2618      1.2618    -1.2618         2.7257   2.7257   2.7257           1.7756   1.7756   1.7756          -  1.2077      1.2077    -1.2077         2.7783   2.7783   2.7783           1.8199   1.8199   1.8199          -  1.1670      1.1670    -1.1670         2.8238   2.8238   2.8238        Jacobi method  As stated above, the Jacobi method (7) is the same as the specific regular splitting (11) demonstrated above.  Gauss-Seidel method  Since the diagonal entries of the matrix A in problem (10) are all nonzero, we can express the matrix A as the splitting (6), where      ğƒ  =   (     6    0    0      0    4    0      0    0    5     )   ,  ğ”  =   (     0    2    3      0    0    2      0    0    0     )   ,  ğ‹  =   (     0    0    0      1    0    0      3    1    0     )   .   (  14  )      fragments  D     6  0  0    0  4  0    0  0  5    normal-,  U     0  2  3    0  0  2    0  0  0    normal-,  L     0  0  0    1  0  0    3  1  0    normal-.    fragments  normal-(  14  normal-)     \displaystyle\mathbf{D}=\begin{pmatrix}6&0&0\\
 0&4&0\\
 0&0&5\end{pmatrix},\quad\mathbf{U}=\begin{pmatrix}0&2&3\\
 0&0&2\\
 0&0&0\end{pmatrix},\quad\mathbf{L}=\begin{pmatrix}0&0&0\\
 1&0&0\\
 3&1&0\end{pmatrix}.\quad(14)     We then have         (   ğƒ  -  ğ‹   )    -  ğŸ    =     1  120     (     20    0    0      5    30    0      13    6    24     )     ,       superscript    ğƒ  ğ‹     1        1  120     20  0  0    5  30  0    13  6  24       \displaystyle\mathbf{(D-L)^{-1}}=\frac{1}{120}\begin{pmatrix}20&0&0\\
 5&30&0\\
 13&6&24\end{pmatrix},              (   ğƒ  -  ğ‹   )    -  ğŸ    ğ”   =     1  120     (     0    40    60      0    10    75      0    26    51     )     ,      (   ğƒ  -  ğ‹   )    -  ğŸ    ğ¤   =     1  120     (     100       -  335       233     )      .     formulae-sequence       superscript    ğƒ  ğ‹     1    ğ”       1  120     0  40  60    0  10  75    0  26  51           superscript    ğƒ  ğ‹     1    ğ¤       1  120     100      335     233        \displaystyle\mathbf{(D-L)^{-1}U}=\frac{1}{120}\begin{pmatrix}0&40&60\\
 0&10&75\\
 0&26&51\end{pmatrix},\quad\mathbf{(D-L)^{-1}k}=\frac{1}{120}\begin{pmatrix}100%
 \\
 -335\\
 233\end{pmatrix}.     The Gauss-Seidel method (8) applied to the problem (10) takes the form        ğ•©   (   m  +  1   )    =          1  120    (     0    40    60      0    10    75      0    26    51     )    ğ•©   (  m  )     +    1  120    (     100       -  335       233     )     ,        m  =   0  ,  1  ,  2  ,  â€¦   (  15  )        formulae-sequence     superscript  ğ•©    m  1       missing-subexpression         1  120     0  40  60    0  10  75    0  26  51     superscript  ğ•©  m        1  120     100      335     233           m   0  1  2  normal-â€¦  15      \mathbb{x}^{(m+1)}=\begin{aligned}&\displaystyle\frac{1}{120}\begin{pmatrix}0&%
 40&60\\
 0&10&75\\
 0&26&51\end{pmatrix}\mathbb{x}^{(m)}+\frac{1}{120}\begin{pmatrix}100\\
 -335\\
 233\end{pmatrix},\end{aligned}\quad m=0,1,2,\ldots\quad(15)     The first few iterates for equation (15) are listed in the table below, beginning with x (0) = (0.0, 0.0, 0.0) T . From the table one can see that the method is evidently converging to the solution (13), somewhat faster than the Jacobi method described above.          x  1   (  m  )      subscript   superscript  x  m   1    x^{(m)}_{1}          x  2   (  m  )      subscript   superscript  x  m   2    x^{(m)}_{2}          x  3   (  m  )      subscript   superscript  x  m   3    x^{(m)}_{3}             0.0   0.0   0.0         0.0   0.0   0.0         0.0   0.0   0.0           0.8333   0.8333   0.8333          -  2.7917      2.7917    -2.7917         1.9417   1.9417   1.9417           0.8736   0.8736   0.8736          -  1.8107      1.8107    -1.8107         2.1620   2.1620   2.1620           1.3108   1.3108   1.3108          -  1.5913      1.5913    -1.5913         2.4682   2.4682   2.4682           1.5370   1.5370   1.5370          -  1.3817      1.3817    -1.3817         2.6459   2.6459   2.6459           1.6957   1.6957   1.6957          -  1.2531      1.2531    -1.2531         2.7668   2.7668   2.7668           1.7990   1.7990   1.7990          -  1.1668      1.1668    -1.1668         2.8461   2.8461   2.8461           1.8675   1.8675   1.8675          -  1.1101      1.1101    -1.1101         2.8985   2.8985   2.8985           1.9126   1.9126   1.9126          -  1.0726      1.0726    -1.0726         2.9330   2.9330   2.9330           1.9423   1.9423   1.9423          -  1.0479      1.0479    -1.0479         2.9558   2.9558   2.9558           1.9619   1.9619   1.9619          -  1.0316      1.0316    -1.0316         2.9708   2.9708   2.9708        Successive over-relaxation method  Let Ï‰ = 1.1. Using the splitting (14) of the matrix A in problem (10) for the successive over-relaxation method, we have         (   ğƒ  -   Ï‰  ğ‹    )    -  ğŸ    =     1  12     (     2    0    0      0.55    3    0      1.441    0.66    2.4     )     ,       superscript    ğƒ    Ï‰  ğ‹      1        1  12     2  0  0    0.55  3  0    1.441  0.66  2.4       \displaystyle\mathbf{(D-\omega L)^{-1}}=\frac{1}{12}\begin{pmatrix}2&0&0\\
 0.55&3&0\\
 1.441&0.66&2.4\end{pmatrix},             (   ğƒ  -   Ï‰  ğ‹    )    -  ğŸ     [     (   ğŸ  -  Ï‰   )   ğƒ   +   Ï‰  ğ”    ]    =     1  12     (      -  1.2     4.4    6.6       -  0.33     0.01    8.415       -  0.8646     2.9062    5.0073     )     ,         superscript    ğƒ    Ï‰  ğ‹      1     delimited-[]        1  Ï‰   ğƒ     Ï‰  ğ”          1  12       1.2   4.4  6.6      0.33   0.01  8.415      0.8646   2.9062  5.0073       \displaystyle\mathbf{(D-\omega L)^{-1}[(1-\omega)D+\omega U]}=\frac{1}{12}%
 \begin{pmatrix}-1.2&4.4&6.6\\
 -0.33&0.01&8.415\\
 -0.8646&2.9062&5.0073\end{pmatrix},           Ï‰    (   ğƒ  -   Ï‰  ğ‹    )    -  ğŸ    ğ¤   =     1  12     (     11       -  36.575       25.6135     )     .        Ï‰   superscript    ğƒ    Ï‰  ğ‹      1    ğ¤       1  12     11      36.575     25.6135       \displaystyle\mathbf{\omega(D-\omega L)^{-1}k}=\frac{1}{12}\begin{pmatrix}11\\
 -36.575\\
 25.6135\end{pmatrix}.     The successive over-relaxation method (9) applied to the problem (10) takes the form        ğ•©   (   m  +  1   )    =          1  12    (      -  1.2     4.4    6.6       -  0.33     0.01    8.415       -  0.8646     2.9062    5.0073     )    ğ•©   (  m  )     +    1  12    (     11       -  36.575       25.6135     )     ,        m  =   0  ,  1  ,  2  ,  â€¦   (  16  )        formulae-sequence     superscript  ğ•©    m  1       missing-subexpression         1  12       1.2   4.4  6.6      0.33   0.01  8.415      0.8646   2.9062  5.0073     superscript  ğ•©  m        1  12     11      36.575     25.6135           m   0  1  2  normal-â€¦  16      \mathbb{x}^{(m+1)}=\begin{aligned}&\displaystyle\frac{1}{12}\begin{pmatrix}-1.%
 2&4.4&6.6\\
 -0.33&0.01&8.415\\
 -0.8646&2.9062&5.0073\end{pmatrix}\mathbb{x}^{(m)}+\frac{1}{12}\begin{pmatrix}%
 11\\
 -36.575\\
 25.6135\end{pmatrix},\end{aligned}\quad m=0,1,2,\ldots\quad(16)     The first few iterates for equation (16) are listed in the table below, beginning with x (0) = (0.0, 0.0, 0.0) T . From the table one can see that the method is evidently converging to the solution (13), slightly faster than the Gauss-Seidel method described above.          x  1   (  m  )      subscript   superscript  x  m   1    x^{(m)}_{1}          x  2   (  m  )      subscript   superscript  x  m   2    x^{(m)}_{2}          x  3   (  m  )      subscript   superscript  x  m   3    x^{(m)}_{3}             0.0   0.0   0.0         0.0   0.0   0.0         0.0   0.0   0.0           0.9167   0.9167   0.9167          -  3.0479      3.0479    -3.0479         2.1345   2.1345   2.1345           0.8814   0.8814   0.8814          -  1.5788      1.5788    -1.5788         2.2209   2.2209   2.2209           1.4711   1.4711   1.4711          -  1.5161      1.5161    -1.5161         2.6153   2.6153   2.6153           1.6521   1.6521   1.6521          -  1.2557      1.2557    -1.2557         2.7526   2.7526   2.7526           1.8050   1.8050   1.8050          -  1.1641      1.1641    -1.1641         2.8599   2.8599   2.8599           1.8823   1.8823   1.8823          -  1.0930      1.0930    -1.0930         2.9158   2.9158   2.9158           1.9314   1.9314   1.9314          -  1.0559      1.0559    -1.0559         2.9508   2.9508   2.9508           1.9593   1.9593   1.9593          -  1.0327      1.0327    -1.0327         2.9709   2.9709   2.9709           1.9761   1.9761   1.9761          -  1.0185      1.0185    -1.0185         2.9829   2.9829   2.9829           1.9862   1.9862   1.9862          -  1.0113      1.0113    -1.0113         2.9901   2.9901   2.9901        See also   Matrix decomposition  M-matrix  Stieltjes matrix   Notes  References    .        .   "  Category:Matrices  Category:Numerical linear algebra  Category:Relaxation (iterative methods)     â†©  â†©  â†©  â†©  â†©  â†©  â†©  â†©  â†©  â†©  â†©     