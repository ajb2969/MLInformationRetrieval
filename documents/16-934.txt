


Hsu–Robbins–Erdős theorem




Hsu–Robbins–Erdős theorem

In the mathematical theory of probability, the Hsu–Robbins–Erdős theorem states that if 
 
 
 
  is a sequence of i.i.d. random variables with zero mean and finite variance and



then



for every 
 
 
 
 .
The result was proved by Pao-Lu Hsu and Herbert Robbins in 1947.
This is an interesting strengthening of the classical strong law of large numbers in the direction of the Borel–Cantelli lemma. The idea of such a result is probably due to Robbins, but the method of proof is vintage Hsu.1 Hsu and Robbins further conjectured in 2 that the condition of finiteness of the variance of 
 
 
 
  is also a necessary condition for 
 
 
 
  to hold. Two years later, the famed mathematician Paul Erdős proved the conjecture.3
Since then, many authors extended this result in several directions.4
References
"
Category:Theorems in measure theory Category:Probabilistic inequalities



Chung, K. L. (1979). Hsu's work in probability. The Annals of Statistics, 479–483.
Hsu, P. L., & Robbins, H. (1947). Complete convergence and the law of large numbers. Proceedings of the National Academy of Sciences of the United States of America, 33(2), 25.
Erdos, P. (1949). On a theorem of Hsu and Robbins. The Annals of Mathematical Statistics, 286–291.
Hsu-Robbins theorem for the correlated sequences




