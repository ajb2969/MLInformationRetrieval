   General linear model      General linear model   The general linear model is a statistical linear model . It may be written as 1       ğ˜  =   ğ—ğ  +  ğ”    ,      ğ˜    ğ—ğ  ğ”     \mathbf{Y}=\mathbf{X}\mathbf{B}+\mathbf{U},     where Y is a matrix with series of multivariate measurements, X is a matrix that might be a design matrix , B is a matrix containing parameters that are usually to be estimated and U is a matrix containing errors or noise . The errors are usually assumed to be uncorrelated across measurements, and follow a multivariate normal distribution . If the errors do not follow a multivariate normal distribution, generalized linear models may be used to relax assumptions about Y and U .  The general linear model incorporates a number of different statistical models: ANOVA , ANCOVA , MANOVA , MANCOVA , ordinary linear regression , t-test and F-test . The general linear model is a generalization of multiple linear regression model to the case of more than one dependent variable. If Y , B , and U were column vectors , the matrix equation above would represent multiple linear regression.  Hypothesis tests with the general linear model can be made in two ways: multivariate or as several independent univariate tests. In multivariate tests the columns of Y are tested together, whereas in univariate tests the columns of Y are tested independently, i.e., as multiple univariate tests with the same design matrix.  Multiple linear regression  Multiple linear regression is a generalization of linear regression by considering more than one independent variable, and a specific case of general linear models formed by restricting the number of dependent variables to one. The basic model for linear regression is        Y  i   =    Î²  0   +    Î²  1    X   i  1     +    Î²  2    X   i  2     +  â€¦  +    Î²  p    X   i  p     +   Ïµ  i     .       subscript  Y  i      subscript  Î²  0      subscript  Î²  1    subscript  X    i  1        subscript  Î²  2    subscript  X    i  2     normal-â€¦     subscript  Î²  p    subscript  X    i  p      subscript  Ïµ  i      Y_{i}=\beta_{0}+\beta_{1}X_{i1}+\beta_{2}X_{i2}+\ldots+\beta_{p}X_{ip}+%
 \epsilon_{i}.     In the formula above we consider n observations of one dependent variable and p independent variables. Thus, Y i is the i th observation of the dependent variable, X ij is i th observation of the j th independent variable, j = 1, 2, ..., p . The values Î² j represent parameters to be estimated, and Îµ i is the i th independent identically distributed normal error.  Applications  An application of the general linear model appears in the analysis of multiple brain scans in scientific experiments where Y contains data from brain scanners, X contains experimental design variables and confounds. It is usually tested in a univariate way (usually referred to a mass-univariate in this setting) and is often referred to as statistical parametric mapping . 2  See also   Comparison of general and generalized linear models  Bayesian multivariate linear regression   Notes  References       "  Category:Multivariate statistics  Category:Regression analysis     â†©  â†©     