   Forcing (mathematics)      Forcing (mathematics)   In the mathematical discipline of set theory , forcing is a technique discovered by Paul Cohen for proving consistency and independence results. It was first used, in 1963, to prove the independence of the axiom of choice and the continuum hypothesis from Zermelo–Fraenkel set theory . Forcing was considerably reworked and simplified in the following years, and has since served as a powerful technique both in set theory and in areas of mathematical logic such as recursion theory .  Descriptive set theory uses the notion of forcing from both recursion theory and set theory. Forcing has also been used in model theory but it is common in model theory to define genericity directly without mention of forcing.  Intuitions  Forcing is equivalent to the method of Boolean-valued models , which some feel is conceptually more natural and intuitive, but usually much more difficult to apply.  Intuitively, forcing consists of expanding the set theoretical universe  V to a larger universe V *. In this bigger universe, for example, one might have lots of new subsets of ω =    0  ,  1  ,  2  ,  …     0  1  2  normal-…    {0,1,2,…}   that were not there in the old universe, and thereby violate the continuum hypothesis . While impossible on the face of it, this is just another version of Cantor's paradox about infinity. In principle, one could consider        V  *   =   V  ×   {  0  ,  1  }     ,       superscript  V      V   0  1      V^{*}=V\times\{0,1\},\,     identify    x  ∈  V      x  V    x\in V   with    (  x  ,  0  )     x  0    (x,0)   , and then introduce an expanded membership relation involving the "new" sets of the form    (  x  ,  1  )     x  1    (x,1)   . Forcing is a more elaborate version of this idea, reducing the expansion to the existence of one new set, and allowing for fine control over the properties of the expanded universe.  Cohen's original technique, now called ramified forcing , is slightly different from the unramified forcing expounded here.  Forcing posets  A forcing poset is an ordered triple,    (  P  ,  ≤  ,  1  )     P  normal-≤  1    (P,≤,1)   , where   ≤   normal-≤   ≤   is a preorder on   P   P   P   that satisfies following splitting condition:   For all    p  ∈  P      p  normal-∈  P    p∈P   , there are    q  ,   r  ∈  P      q    r  normal-∈  P     q,r∈P   such that    q  ,   r  ≤  p      q    r  normal-≤  p     q,r≤p   with no    s  ∈  P      s  normal-∈  P    s∈P   such that     s  ≤  q   ,  r       s  normal-≤  q   r    s≤q,r      The largest element of   P   P   P   is   1   1   1   , that is,    p  ≤  1      p  normal-≤  1    p≤1   for all    p  ∈  P      p  normal-∈  P    p∈P   . Members of   P   P   P   are called forcing conditions or just conditions . One reads    p  ≤  q      p  normal-≤  q    p≤q   as   p   p   p   is stronger than   q   q   q   . Intuitively, the "smaller" condition provides "more" information, just as the smaller interval [3.1415926,3.1415927] provides more information about the number π than the interval [3.1,3.2] does.  There are various conventions in use. Some authors require   ≤   normal-≤   ≤   to also be antisymmetric , so that the relation is a partial order . Some use the term partial order anyway, conflicting with standard terminology, while some use the term preorder . The largest element can be dispensed with. The reverse ordering is also used, most notably by Saharon Shelah and his co-authors.  P-names  Associated with a forcing poset   P   P   P   is the class of   P   P   P   - names .   P   P   P   -names are sets of the form       (   (  u  ,  p  )   :  u     fragments  normal-(   fragments  normal-(  u  normal-,  p  normal-)   normal-:  u    {{(}}(u,p):u   is a   P   P   P   -name and    p  ∈  P      p  normal-∈  P    p∈P   and (some criterion involving   u   u   u   and   p   p   p   )   )   normal-)   {{)}}      Using transfinite recursion , one defines        N  a  m  e   (  0  )    =         N  a  m  e  0   absent    Name(0)={}   ,      N  a  m  e   (   α  +  1   )       N  a  m  e    α  1     Name(α+1)   = the power set of    (   N  a  m  e   (  α  )   ×  P   )      N  a  m  e  α  normal-×  P    (Name(α)×P)   ,     λ   λ   λ      and then the class of   )   normal-)   {{)}}   -names is defined by   ∪{{(}}Name(α) : α}} is an ordinal   P   P   P   .   The    x  ∈  V      x  normal-∈  V    x∈V   -names are, in fact, an expansion of the universe . Given    x  ˇ      x  normal-ˇ    xˇ   , one defines   P   P   P   to be the      x  ˇ   =   (   y  ˇ   ,  1  )    :   y  ∈  x      normal-:      x  normal-ˇ      y  normal-ˇ   1      y  normal-∈  x     xˇ={(yˇ,1):y∈x}   -name      G   G   G   .   Again, this is really a definition by transfinite recursion.  Interpretation  Given any subset   P   P   P   of   P   P   P   , one next defines the interpretation or valuation map from      v  a  l   (  u  ,  G  )    =   v  a  l   (  v  ,  G  )     :    ∃  p  ∈  G   ,    (  v  ,  p  )   ∈  u       normal-:      v  a  l   u  G      v  a  l   v  G        normal-∃  p  normal-∈  G      v  p   normal-∈  u      val(u,G)={val(v,G):∃p∈G,(v,p)∈u}   -names by      1   1   1   .   (Again a definition by transfinite recursion.) Note that if   G   G   G   is in     v  a  l   (   x  ˇ   ,  G  )    =  x        v  a  l     x  normal-ˇ   G    x    val(xˇ,G)=x   , then       (   B  o  r   (  𝐈  )    ,  ⊆  ,  𝐈  )       B  o  r  𝐈   normal-⊆  𝐈    (Bor(\mathbf{I}),⊆,\mathbf{I})   .   One defines   }} ,   so that   G}} .   Example  A good example of a forcing poset is    I  =   0  ,  11       I   0  11     I=0,11   where    B  o  r   (  I  )       B  o  r  I    Bor(I)   and   I   I   I   are the Borel subsets of    B  o  r   (  I  )       B  o  r  I    Bor(I)   having non-zero Lebesgue measure . In this case, one can talk about the conditions as being probabilities, and a    ⊩   M  ,  P      subscript  forces   M  P     \Vdash_{M,P}   -name assigns membership in a probabilistic sense. Because of the ready intuition this example can provide, probabilistic language is sometimes used with other forcing posets.  Countable transitive models and generic filters  The key step in forcing is, given a ZFC universe V , to find appropriate G not in V . The resulting class of all interpretations of P -names will turn out to be a model of ZFC, properly extending the original V (since G ∉ V ).  Instead of working with V , one considers a countable transitive model  M with ( P ,≤,1) ∈ M . By model, we mean a model of set theory, either of all of ZFC, or a model of a large but finite subset of the ZFC axioms, or some variant thereof. Transitivity means that if x ∈ y ∈ M , then x ∈ M . The Mostowski collapsing theorem says this can be assumed if the membership relation is well-founded . The effect of transitivity is that membership and other elementary notions can be handled intuitively. Countability of the model relies on the Löwenheim–Skolem theorem .  Since M is a set, there are sets not in M – this follows from Russell's paradox . The appropriate set G to pick, and adjoin to M , is a generic filter on P . The filter condition means that G ⊆ P and  :*1 ∈ G ;  :*if p ≥ q ∈ G , then p ∈ G ;  :*if p , q ∈ G , then ∃ r ∈ G , r ≤ p and r ≤ q ; For G to be generic means  :*if D ∈ M is a dense subset of P (that is, p ∈ P implies ∃ q ∈ D , q ≤ p ) then G ∩ D ≠ 0 .  The existence of a generic filter G follows from the Rasiowa–Sikorski lemma . In fact, slightly more is true: given a condition p ∈ P , one can find a generic filter G such that p ∈ G . Due to the splitting condition, if G is filter, then P \ G is dense. If G is in M then P \ G is in M because M is model of set theory. By this reason, a generic filter is never in M .  Forcing  Given a generic filter G ⊆ P , one proceeds as follows. The subclass of P -names in M is denoted M ( P ) . Let M [ G ]= . To reduce the study of the set theory of M [ G ] to that of M , one works with the forcing language , which is built up like ordinary first-order logic , with membership as binary relation and all the names as constants.  Define p     ⊩   M  ,  P      subscript  forces   M  P     \Vdash_{M,P}   φ( u 1 ,…, u n ) (read " p forces φ in model M with poset P") where p is a condition, φ is a formula in the forcing language, and the u i are names, to mean that if G is a generic filter containing p , then M [ G ] ⊨ φ(val( u 1 , G ),…,val( u n , G )). The special case 1    ⊩   M  ,  P      subscript  forces   M  P     \Vdash_{M,P}   φ is often written P     ⊩   M  ,  P      subscript  forces   M  P     \Vdash_{M,P}   φ or    ⊩   M  ,  P      subscript  forces   M  P     \Vdash_{M,P}   φ. Such statements are true in M [ G ] no matter what G is.  What is important is that this "external" definition of the forcing relation p     ⊩   M  ,  P      subscript  forces   M  P     \Vdash_{M,P}   φ is equivalent to an "internal" definition, defined by transfinite induction over the names on instances of u ∈ v and u = v , and then by ordinary induction over the complexity of formulas. This has the effect that all the properties of M [ G ] are really properties of M , and the verification of ZFC in M [ G ] becomes straightforward. This is usually summarized as three key properties:   Truth : M [ G ] ⊨ φ(val( u 1 , G ),…,val( u n , G )) if and only if it is forced by G , that is, for some condition p ∈ G , p     ⊩   M  ,  P      subscript  forces   M  P     \Vdash_{M,P}   φ( u 1 ,…, u n ).  Definability : The statement " p     ⊩   M  ,  P      subscript  forces   M  P     \Vdash_{M,P}   φ( u 1 ,…, u n )" is definable in M .  Coherence : If p     ⊩   M  ,  P      subscript  forces   M  P     \Vdash_{M,P}   φ( u 1 ,…, u n ) and q ≤ p , then q    V   V   V   φ( u 1 ,…, u n ).   We define the forcing relation in    p   ⊩  P   a  ∈  b        subscript  forces  P   p  a       b     p\Vdash_{P}a\in b   by induction on complexity, in which we simultaneously define forcing of atomic formulas by ∈-induction and then we define it by induction on formula complexity.  1.     (  ∀  q  ≤  p  )    (  ∃  r  ≤  q  )    (  ∃  s  ,  c  )    (   (  s  ,  c  )   ∈  b  ∧  r  ≤  s  ∧  r   ⊩  P   a  =  c  )      fragments   fragments  normal-(  for-all  q   p  normal-)    fragments  normal-(   r   q  normal-)    fragments  normal-(   s  normal-,  c  normal-)    fragments  normal-(   fragments  normal-(  s  normal-,  c  normal-)    b   r   s   r   subscript  forces  P   a   c  normal-)     (\forall q\leq p)(\exists r\leq q)(\exists s,c)((s,c)\in b\land r\leq s\land r%
 \Vdash_{P}a=c)   if    p   ⊩  P   a  =  b        subscript  forces  P   p  a       b     p\Vdash_{P}a=b   .  2.     (  ∀  q  ≤  p  )    (  ∀  c  ∈   V  P   )    (  q   ⊩  P   c  ∈   a   ⇔  q   ⊩  P   c  ∈  b  )      fragments   fragments  normal-(  for-all  q   p  normal-)    fragments  normal-(  for-all  c    superscript  V  P   normal-)    fragments  normal-(  q   subscript  forces  P   c   a  normal-⇔  q   subscript  forces  P   c   b  normal-)     (\forall q\leq p)(\forall c\in V^{P})(q\Vdash_{P}c\in a\,\Leftrightarrow q%
 \Vdash_{P}c\in b)   if    p   ⊩  P    ¬  f       subscript  forces  P   p     f     p\Vdash_{P}\lnot f   .  3.      ¬   (    ∃  q   ≤  p   )    q    ⊩  P   f      subscript  forces  P           q   p    q   f    \lnot(\exists q\leq p)q\Vdash_{P}f   if    p   ⊩  P    (   f  ∧  g   )       subscript  forces  P   p    f  g     p\Vdash_{P}(f\land g)   .  4.    (   p   ⊩  P     f   ∧  p    ⊩  P   g   )        subscript  forces  P   p    f  p      subscript  forces  P     g     (p\Vdash_{P}f\,\land\,p\Vdash_{P}g)   if    p   ⊩  P     (   ∀  x   )   f       subscript  forces  P   p     for-all  x   f     p\Vdash_{P}(\forall x)f   .  5.     (  ∀  x  ∈   V  P   )   p   ⊩  P   f     fragments   fragments  normal-(  for-all  x    superscript  V  P   normal-)   p   subscript  forces  P   f    (\forall x\in V^{P})p\Vdash_{P}f   if   p   p   p   .  In 1–5   a   a   a   is an arbitrary condition. In 1 and 2   a   a   a   and   f   f   f   are arbitrary names and in 3–5   g   g   g   and    f   (   x  1   ,  …  ,   x  n   )       f    subscript  x  1   normal-…   subscript  x  n      f(x_{1},\dots,x_{n})   are arbitrary formulas where all free occurrences of variables referring names. This definition is syntax transform of formulas. This means that for any given formula    p   ⊨  P    f   (   x  1   ,  …  ,   x  n   )        subscript  normal-⊨  P   p    f    subscript  x  1   normal-…   subscript  x  n       p\vDash_{P}f(x_{1},\dots,x_{n})   the formula    p  ,  P  ,   x  1   ,  …  ,   x  n      p  P   subscript  x  1   normal-…   subscript  x  n     p,P,x_{1},\dots,x_{n}   with free variables    f   (   x  1   ,  …  ,   x  n   )       f    subscript  x  1   normal-…   subscript  x  n      f(x_{1},\dots,x_{n})   is well defined. In fact this syntax transform has following properties: any equivalence given by 1-5 is theorem (single theorem per formula) and for any formula     (  ∀  p  ,  P  ,   x  1   ,  …  ,   x  n   )    (  p   ⊩  P   f   (   x  1   ,  …  ,   x  n   )   ⇒   (  p  o   (  P  )   ∧  p  ∈  d  o  m   (  P  )   ∧   x  1   ,  …  ,   x  n   ∈   V  P   )       fragments   fragments  normal-(  for-all  p  normal-,  P  normal-,   subscript  x  1   normal-,  normal-…  normal-,   subscript  x  n   normal-)    fragments  normal-(  p   subscript  forces  P   f   fragments  normal-(   subscript  x  1   normal-,  normal-…  normal-,   subscript  x  n   normal-)   normal-⇒   fragments  normal-(  p  o   fragments  normal-(  P  normal-)    p   d  o  m   fragments  normal-(  P  normal-)     subscript  x  1   normal-,  normal-…  normal-,   subscript  x  n     superscript  V  P   normal-)      (\forall p,P,x_{1},\dots,x_{n})(p\Vdash_{P}f(x_{1},\dots,x_{n})\Rightarrow(po(%
 P)\land p\in dom(P)\land x_{1},\dots,x_{n}\in V^{P})   following formula    p  o   (  P  )       p  o  P    po(P)   is theorem where   P   P   P   means that   V   V   V   is partial order with splitting condition. The bit of definition is existence of syntax transform with these properties.  This definition provides the possibility of working in   M   M   M   without any countable transitive model     (  ∀  M  ,  P  ,   x  1   ,  …  ,   x  n   )    (  c  t  m   (  M  )   ∧  p  o   (  P  )   ∧  P  ∈  M  ∧  p  ∈  d  o  m   (  P  )   ∧   x  1   ,  …  ,   x  n   ∈   M  P   ⇒   (  p   ⊩   M  ,  P    f   (   x  1   ,  …  ,   x  n   )   ⇔  M  ⊧  p   ⊩  P   f   (   x  1   ,  …  ,   x  n   )   )   )      fragments   fragments  normal-(  for-all  M  normal-,  P  normal-,   subscript  x  1   normal-,  normal-…  normal-,   subscript  x  n   normal-)    fragments  normal-(  c  t  m   fragments  normal-(  M  normal-)    p  o   fragments  normal-(  P  normal-)    P   M   p   d  o  m   fragments  normal-(  P  normal-)     subscript  x  1   normal-,  normal-…  normal-,   subscript  x  n     superscript  M  P   normal-⇒   fragments  normal-(  p   subscript  forces   M  P    f   fragments  normal-(   subscript  x  1   normal-,  normal-…  normal-,   subscript  x  n   normal-)   normal-⇔  M  models  p   subscript  forces  P   f   fragments  normal-(   subscript  x  1   normal-,  normal-…  normal-,   subscript  x  n   normal-)   normal-)   normal-)     (\forall M,P,x_{1},\dots,x_{n})(ctm(M)\land po(P)\land P\in M\land p\in dom(P)%
 \land x_{1},\dots,x_{n}\in M^{P}\Rightarrow(p\Vdash_{M,P}f(x_{1},\dots,x_{n})%
 \,\Leftrightarrow\,M\models p\Vdash_{P}f(x_{1},\dots,x_{n})))   . The following statement gives announced definability:      c  t  m   (  M  )       c  t  m  M    ctm(M)     where   M   M   M   means that    Z  F      Z  F    ZF   is countable transitive model satisfying some finite part of   f   f   f   axioms depending on formula   ⊩   forces   \Vdash   .  (Where no confusion is possible we simply write    0  ,  1     0  1    {0,1}   .)  Consistency  The above can be summarized by saying the fundamental consistency result is that given a forcing poset P , we may assume that there exists a generic filter G , not in the universe V , such that V [ G ] is again a set theoretic universe, modelling ZFC. Furthermore, all truths in V [ G ] can be reduced to truths in V regarding the forcing relation.  Both styles, adjoining G to a countable transitive model M or to the whole universe V , are commonly used. Less commonly seen is the approach using the "internal" definition of forcing, and no mention of set or class models is made. This was Cohen's original method, and in one elaboration, it becomes the method of Boolean-valued analysis.  Cohen forcing  The simplest nontrivial forcing poset is ( Fin(ω,2), ⊇, 0 ), the finite partial functions from ω to 2=    p  :   p   (  n  )   i  s  d  e  f  i  n  e  d      normal-:  p    p  n  i  s  d  e  f  i  n  e  d     {p:p(n)isdefined}   under reverse inclusion. That is, a condition p is essentially two disjoint finite subsets p −1 [1] and p −1 [0] of ω, to be thought of as the "yes" and "no" parts of p , with no information provided on values outside the domain of p . q is stronger than p means that q ⊇ p , in other words, the "yes" and "no" parts of q are supersets of the "yes" and "no" parts of p , and in that sense, provide more information.  Let G be a generic filter for this poset. If p and q are both in G , then p ∪ q is a condition, because G is a filter. This means that g =⋃ G is a well-defined partial function from ω to 2, because any two conditions in G agree on their common domain.  g is in fact a total function. Given n ∈ ω, let D n =     (   n  ˇ   ,  p  )   :    p   (  n  )    =  1      normal-:     n  normal-ˇ   p       p  n   1     {(nˇ,p):p(n)=1}   , then D n is dense. (Given any p , if n is not in p ’s domain, adjoin a value for n , the result is in D n .) A condition p ∈ G ∩ D n has n in its domain, and since p ⊆ g , g ( n ) is defined.  Let X = g −1 [1], the set of all "yes" members of the generic conditions. It is possible to give a name for X directly. Let X =    p  :     ∃  n   ,   n  ∈  d  o  m   (  p  )   a  n  d  p   (  n  )     =   1  i  f  a  n  d  o  n  l  y  i  f  n  ∉  A       normal-:  p       normal-∃  n     n  normal-∈  d  o  m  p  a  n  d  p  n      1  i  f  a  n  d  o  n  l  y  i  f  n  normal-∉  A      {p:∃n,n∈dom(p)andp(n)=1ifandonlyifn∉A}   , then val( X , G ) = X . Now suppose A ⊆ω in V . We claim that X ≠ A . Let D A =    p  :    ∃  n   ,   p   (  n  ,  α  )   ≠  p   (  n  ,  β  )        normal-:  p     normal-∃  n     p   n  α   normal-≠  p   n  β       {p:∃n,p(n,α)≠p(n,β)}   . D A is dense. (Given any p , if n is not in p ’s domain, adjoin a value for n contrary to the status of " n ∈ A ".) Then any p ∈ G ∩ D A witnesses X ≠ A . To summarize, X is a new subset of ω, necessarily infinite.  Replacing ω with ω×ω 2 , that is, consider instead finite partial functions whose inputs are of the form ( n ,α), with n <ω and α2, and whose outputs are 0 or 1, one gets ω 2 new subsets of ω. They are all distinct, by a density argument: given α2, let D α,β =    p  :    p  ≤  q   ,   s  o  m  e  q  ∈  A       normal-:  p     p  normal-≤  q     s  o  m  e  q  normal-∈  A      {p:p≤q,someq∈A}   , then each D α,β is dense, and a generic condition in it proves that the αth new set disagrees somewhere with the βth new set.  This is not yet the falsification of the continuum hypothesis. One must prove that no new maps have been introduced which map ω onto ω 1 or ω 1 onto ω 2 . For example, if one considers instead Fin(ω,ω 1 ), finite partial functions from ω to ω 1 , the first uncountable ordinal , one gets in V [ G ] a bijection from ω to ω 1 . In other words, ω 1 has collapsed , and in the forcing extension, is a countable ordinal.  The last step in showing the independence of the continuum hypothesis, then, is to show that Cohen forcing does not collapse cardinals. For this, a sufficient combinatorial property is that all of the antichains of this poset are countable.  The countable chain condition  An antichain A of P is a subset such that if p and q are in A , then p and q are incompatible (written p ⊥ q ), meaning there is no r in P such that r ≤ p and r ≤ q . In the Borel sets example, incompatibility means p ∩ q has measure zero. In the finite partial functions example, incompatibility means that p ∪ q is not a function, in other words, p and q assign different values to some domain input.  P satisfies the countable chain condition (c.c.c.) if every antichain in P is countable. (The name, which is obviously inappropriate, is a holdover from older terminology. Some mathematicians write "c.a.c." for "countable antichain condition".)  It is easy to see that Bor( I ) satisfies the c.c.c., because the measures add up to at most 1. Fin( E ,2) is also c.c.c., but the proof is more difficult.  Given an uncountable subfamily W ⊆ Fin( E ,2), shrink W to an uncountable subfamily W 0 of sets of size n , for some n <ω. If p( e 1 )= b 1 for uncountably many p ∈ W 0 , shrink to this uncountable subfamily W 1 , and repeat, getting a finite set , and an uncountable family W k of incompatible conditions of size n − k such that every e is in at most countably many dom( p ) for p ∈ W k . Now pick an arbitrary p ∈ W k , and pick from W k any q that is not one of the countably many members that have a domain member in common with p . Then p ∪ and q ∪ are compatible, so W is not an antichain. In other words, Fin( E ,2) antichains are countable.  The importance of antichains in forcing is that for most purposes, dense sets and maximal antichains are equivalent. A maximal antichain A is one that cannot be extended and still be an antichain. This means every element of p ∈ P is compatible with some member of A . Their existence follows from Zorn's lemma . Given a maximal antichain A , let D =    b  :     ∃  q  ≤  p   ,   q  f  o  r  c  e  s  u   (   a  ˇ   )     =   b  ˇ       normal-:  b       normal-∃  q  normal-≤  p     q  f  o  r  c  e  s  u    a  normal-ˇ       b  normal-ˇ      {b:∃q≤p,qforcesu(aˇ)=bˇ}   . D is dense, and G ∩ D ≠0 if and only if G ∩ A ≠0. Conversely, given a dense set D , Zorn's lemma shows there exists a maximal antichain A ⊆ D , and then G ∩ D ≠0 if and only if G ∩ A ≠0.  Assume P is c.c.c. Given x , y ∈ V , with f : x → y in V [ G ], one can approximate f inside V as follows. Let u be a name for f (by the definition of V [ G ]) and let p be a condition which forces u to be a function from x to y . Define a function F whose domain is x by F ( a ) =     B   (   i  n  V   )    :    r  ∈  B   *   (   i  n  V  G  G   )       normal-:    B    i  n  V        r  normal-∈  B     i  n  V  G  G      {B(inV):r∈B*(inVGG)}   . By definability of forcing, this definition makes sense within V . By coherence of forcing, different b ’s come from incompatible p ’s. By c.c.c., F ( a ) is countable.  In summary, f is unknown in V , since it depends on G , but it is not wildly unknown for a c.c.c. forcing. One can identify a countable set of guesses for what the value of f is at any input, independent of G .  This has the following very important consequence. If in V [ G ], f :α→β is a surjection from one infinite ordinal to another, then there is a surjection g :ω×α→β in V and consequently a surjection h :α→β in V . In particular, cardinals cannot collapse. The conclusion is that 2 ℵ₀ ≥ ℵ 2 in V [ G ].  Easton forcing  The exact value of the continuum in the above Cohen model, and variants like Fin(ω × κ , 2) for cardinals κ in general, was worked out by Robert M. Solovay , who also worked out how to violate GCH (the generalized continuum hypothesis ), for regular cardinals only, a finite number of times. For example, in the above Cohen model, if CH holds in V , then 2 ℵ₀ = ℵ 2 holds in V [ G ].  W. B. Easton worked out the infinite and proper class version of violating the GCH for regular cardinals, basically showing the known restrictions (monotonicity, Cantor's theorem , and König's theorem ) were the only ZFC provable restrictions. See Easton's theorem .  Easton's work was notable in that it involved forcing with a proper class of conditions. In general, the method of forcing with a proper class of conditions will fail to give a model of ZFC. For example, Fin ( ω × On , 2 ), where "On" is the proper class of all ordinals, will make the continuum a proper class. Fin ( ω, On ) will introduce a countable enumeration of the ordinals. In both cases, the resulting V [ G ] is visibly not a model of ZFC.  At one time, it was thought that more sophisticated forcing would also allow arbitrary variation in the powers of singular cardinals . But this has turned out to be a difficult, subtle and even surprising problem, with several more restrictions provable in ZFC, and with the forcing models depending on the consistency of various large cardinal properties. Many open problems remain.  Random reals  In the Borel sets ( Bor( I ), ⊆, I ) example, the generic filter converges to a real number r , called a random real. A name for the decimal expansion of r (in the sense of the canonical set of decimal intervals that converge to r ) can be given by letting r = [ k ⋅10 − n , ( k + 1)⋅10 − n ], 0 ≤ k  n }} . This is, in some sense, just a subname of G .  To recover G from r , one takes those Borel subsets of I that "contain" r . Since the forcing poset is in V , but r is not in V , this containment is actually impossible. But there is a natural sense in which the interval [0.5, 0.6] in V "contains" a random real whose decimal expansion begins 0.5. This is formalized by the notion of "Borel code".  Every Borel set can, nonuniquely, be built up, starting from intervals with rational endpoints and applying the operations of complement and countable unions, a countable number of times. The record of such a construction is called a Borel code . Given a Borel set B in V , one recovers a Borel code, and then applies the same construction sequence in V [ G ], getting a Borel set B *. One can prove that one gets the same set independent of the construction of B , and that basic properties are preserved. For example, if B ⊆ C , then B *⊆ C *. If B has measure zero, then B * has measure zero.  So given r , a random real, one can show that G =      Z  F  C   ⊢    Con   (   Z  F  C   )    →   Con   (    Z  F  C   +  H   )      .     proves    Z  F  C    normal-→   Con    Z  F  C     Con      Z  F  C   H       ZFC\vdash\operatorname{Con}(ZFC)\rightarrow\operatorname{Con}(ZFC+H).   . Because of the mutual interdefinability between r and G , one generally writes V [ r ] for V [ G ].  A different interpretation of reals in V [ G ] was provided by Dana Scott . Rational numbers in V [ G ] have names that correspond to countably many distinct rational values assigned to a maximal antichain of Borel sets, in other words, a certain rational-valued function on I = [0,1]. Real numbers in V [ G ] then correspond to Dedekind cuts of such functions, that is, measurable functions .  Boolean-valued models   Main article: Boolean-valued model    Perhaps more clearly, the method can be explained in terms of Boolean-valued models. In these, any statement is assigned a truth value from some complete atomless Boolean algebra , rather than just a true/false value. Then an ultrafilter is picked in this Boolean algebra, which assigns values true/false to statements of our theory. The point is that the resulting theory has a model which contains this ultrafilter, which can be understood as a new model obtained by extending the old one with this ultrafilter. By picking a Boolean-valued model in an appropriate way, we can get a model that has the desired property. In it, only statements which must be true (are "forced" to be true) will be true, in a sense (since it has this extension/minimality property).  Meta-mathematical explanation  In forcing we usually seek to show some sentence is consistent with ZFC (or optionally some extension of ZFC). One way to interpret the argument is that we assume ZFC is consistent and use it to prove ZFC combined with our new sentence is also consistent.  Each "condition" is a finite piece of information – the idea is that only finite pieces are relevant for consistency, since by the compactness theorem a theory is satisfiable if and only if every finite subset of its axioms is satisfiable. Then, we can pick an infinite set of consistent conditions to extend our model. Thus, assuming consistency of set theory, we prove consistency of the theory extended with this infinite set.  Logical explanation  By Gödel's incompleteness theorem one cannot prove the consistency of any sufficiently strong formal theory, such as ZFC, using only the axioms of the theory itself, unless the theory itself is inconsistent. Consequently mathematicians do not attempt to prove the consistency of ZFC using only the axioms of ZFC, or to prove ZFC+H is consistent for any hypothesis H using only ZFC+H. For this reason the aim of a consistency proof is to prove the consistency of ZFC + H relative to consistency of ZFC. Such problems are known as problems of relative consistency. In fact one proves  (*)    Z  F  C  +  ¬  Con   (  Z  F  C  +  H  )   ⊢  ∃  T   (  Fin   (  T  )   ∧  T  ⊂  Z  F  C  ∧   (  T  ⊢  ¬  H  )   )   .     fragments  Z  F  C    Con   fragments  normal-(  Z  F  C   H  normal-)   proves   T   fragments  normal-(  Fin   fragments  normal-(  T  normal-)    T   Z  F  C    fragments  normal-(  T  proves   H  normal-)   normal-)   normal-.    ZFC+\lnot\operatorname{Con}(ZFC+H)\vdash\exists T(\operatorname{Fin}(T)\land T%
 \subset ZFC\land(T\vdash\lnot H)).     We will give the general schema of relative consistency proofs. Because any proof is finite it uses finite number of axioms.      Z  F  C  ⊢  ∀  T   (   (  T  ⊢  ¬  H  )   →   (  Z  F  C  ⊢   (  T  ⊢  ¬  H  )   )   )   .     fragments  Z  F  C  proves  for-all  T   fragments  normal-(   fragments  normal-(  T  proves   H  normal-)   normal-→   fragments  normal-(  Z  F  C  proves   fragments  normal-(  T  proves   H  normal-)   normal-)   normal-)   normal-.    ZFC\vdash\forall T((T\vdash\lnot H)\rightarrow(ZFC\vdash(T\vdash\lnot H))).     For any given proof ZFC can verify validity of this proof. This is provable by induction by the length of the proof.      Z  F  C  +  ¬  Con   (  Z  F  C  +  H  )   ⊢  ∃  T   (  Fin   (  T  )   ∧  T  ⊂  Z  F  C  ∧   (  Z  F  C  ⊢   (  T  ⊢  ¬  H  )   )   )   .     fragments  Z  F  C    Con   fragments  normal-(  Z  F  C   H  normal-)   proves   T   fragments  normal-(  Fin   fragments  normal-(  T  normal-)    T   Z  F  C    fragments  normal-(  Z  F  C  proves   fragments  normal-(  T  proves   H  normal-)   normal-)   normal-)   normal-.    ZFC+\lnot\operatorname{Con}(ZFC+H)\vdash\exists T(\operatorname{Fin}(T)\land T%
 \subset ZFC\land(ZFC\vdash(T\vdash\lnot H))).     Now we obtain      Z  F  C  ⊢  ∀  T   (  Fin   (  T  )   ∧  T  ⊂  Z  F  C  →   (  Z  F  C  ⊢  Con   (  T  +  H  )   )   )      fragments  Z  F  C  proves  for-all  T   fragments  normal-(  Fin   fragments  normal-(  T  normal-)    T   Z  F  C  normal-→   fragments  normal-(  Z  F  C  proves  Con   fragments  normal-(  T   H  normal-)   normal-)   normal-)     ZFC\vdash\forall T(\operatorname{Fin}(T)\land T\subset ZFC\rightarrow(ZFC%
 \vdash\operatorname{Con}(T+H)))     If we prove the following  (**)    Z  F  C  +  ¬  Con   (  Z  F  C  +  H  )   ⊢  ∃  T   (  Fin   (  T  )   ∧  T  ⊂  Z  F  C  ∧   (  Z  F  C  ⊢   (  T  ⊢  ¬  H  )   )   ∧   (  Z  F  C  ⊢  Con   (  T  +  H  )   )   )      fragments  Z  F  C    Con   fragments  normal-(  Z  F  C   H  normal-)   proves   T   fragments  normal-(  Fin   fragments  normal-(  T  normal-)    T   Z  F  C    fragments  normal-(  Z  F  C  proves   fragments  normal-(  T  proves   H  normal-)   normal-)     fragments  normal-(  Z  F  C  proves  Con   fragments  normal-(  T   H  normal-)   normal-)   normal-)     ZFC+\lnot\operatorname{Con}(ZFC+H)\vdash\exists T(\operatorname{Fin}(T)\land T%
 \subset ZFC\land(ZFC\vdash(T\vdash\lnot H))\land(ZFC\vdash\operatorname{Con}(T%
 +H)))     we can conclude that        Z  F  C   +   ¬   Con   (    Z  F  C   +  H   )      ⊢   ¬   Con   (   Z  F  C   )        proves      Z  F  C       Con      Z  F  C   H          Con    Z  F  C       ZFC+\lnot\operatorname{Con}(ZFC+H)\vdash\lnot\operatorname{Con}(ZFC)     which is equivalent to       Z  F  C   ⊢   Con   (   Z  F  C   )    ↔   Con   (   Z  F  L   )         proves    Z  F  C    Con    Z  F  C      normal-↔     Con    Z  F  L       ZFC\vdash\operatorname{Con}(ZFC)\leftrightarrow\operatorname{Con}(ZFL)     which gives (*). The core of the relative consistency proof is proving (**). One has to construct a ZFC proof of Con( T + H ) for any given finite set T of ZFC axioms (by ZFC instruments of course). (No universal proof of Con( T + H ) of course.)  In ZFC it is provable that for any condition p the set of formulas (evaluated by names) forced by p is deductively closed. Also, for any ZFC axiom, ZFC proves that this axiom is forced by 1. Then it suffices to prove that there is at least one condition which forces H.  In the case of Boolean valued forcing, the procedure is similar – one has to prove that the Boolean value of H is not 0.  Another approach uses the reflection theorem. For any given finite set of ZFC axioms there is ZFC proof that this set of axioms has a countable transitive model. For any given finite set T of ZFC axioms there is finite set T' of ZFC axioms such that ZFC proves that if a countable transitive model M satisfies T' then M [ G ] satisfies T . One has to prove that there is finite set T" of ZFC axioms such that if a countable transitive model M satisfies T" then M [ G ] satisfies the hypothesis H . Then, for any given finite set T of ZFC axioms, ZFC proves Con( T + H ).  Sometimes in (**) some stronger theory S than ZFC is used for proving Con( T + H ). Then we have proof of consistency of ZFC + H relative to the consistency of S . Note that $ZFC\vdash \operatorname{Con}(ZFC)\leftrightarrow \operatorname{Con}(ZFL)$ , where ZFL is ZF + V = L (axiom of constructibility).  See also   List of forcing notions  Nice name   References   Bell, J. L. (1985) Boolean-Valued Models and Independence Proofs in Set Theory , Oxford. ISBN 0-19-853241-5      External links   Nik Weaver's book Forcing for Mathematicians was written for mathematicians who want to learn the basic machinery of forcing. No background in logic is assumed, beyond the facility with formal syntax which should be second nature to any well-trained mathematician.  Tim Chow's article A Beginner's Guide to Forcing is a good introduction to the concepts of forcing that avoids a lot of technical detail. This paper grew out of Chow's newsgroup article Forcing for dummies . In addition to improved exposition, the Beginner's Guide includes a section on Boolean Valued Models.  See also Kenny Easwaran's article A Cheerful Introduction to Forcing and the Continuum Hypothesis , which is also aimed at the beginner but includes more technical details than Chow's article.  The Independence of the Continuum Hypothesis Paul J. Cohen, Proceedings of the National Academy of Sciences of the United States of America, Vol. 50, No. 6. (Dec. 15, 1963), pp. 1143–1148.  The Independence of the Continuum Hypothesis, II Paul J. Cohen Proceedings of the National Academy of Sciences of the United States of America, Vol. 51, No. 1. (Jan. 15, 1964), pp. 105–110.  Paul Cohen gave a historical lecture [ http://projecteuclid.org/DPubS?service=UI&version; ;=1.0&verb;=Display&handle;=euclid.rmjm/1181070010 The Discovery of Forcing] (Rocky Mountain J. Math. Volume 32, Number 4 (2002), 1071–1100) about how he developed his independence proof. The linked page has a download link for an open access PDF but your browser must send a referer header from the linked page to retrieve it.    "     