


Jacobian matrix and determinant




Jacobian matrix and determinant

In vector calculus, the Jacobian matrix (, ) is the matrix of all first-order partial derivatives of a vector-valued function. Specifically, suppose  is a function which takes as input the vector  and produces as output the vector . Then the Jacobian matrix 
 
 
 
  of 
 
 
 
  is an 
 
 
 
  matrix, usually defined and arranged as follows:



or, component-wise:



This matrix, whose entries are functions of 
 
 
 
 , is also denoted by 
 
 
 
 , , and . (Note that some literature defines the Jacobian as the transpose of the matrix given above.)
The Jacobian matrix is important because if the function 
 
 
 
 
  is differentiable at a point 
 
 
 
  (this is a slightly stronger condition than merely requiring that all partial derivatives exist there), then the Jacobian matrix defines a linear map , which is the best linear approximation of the function 
 
 
 
  near the point 
 
 
 
 . This linear map is thus the generalization of the usual notion of derivative, and is called the derivative or the differential of 
 
 
 
  at 
 
 
 
 
 .
If 
 
 
 
  = 
 
 
 
 , the Jacobian matrix is a square matrix, and its determinant, a function of , is the Jacobian determinant of 
 
 
 
 . It carries important information about the local behavior of 
 
 
 
 . In particular, the function 
 
 
 
 
  has locally in the neighborhood of a point 
 
 
 
  an inverse function that is differentiable if and only if the Jacobian determinant is nonzero at 
 
 
 
  (see Jacobian conjecture). The Jacobian determinant occurs also when changing the variables in multi-variable integrals (see substitution rule for multiple variables).
If 
 
 
 
  = 1, 
 
 
 
  is a scalar field and the Jacobian matrix is reduced to a row vector of partial derivatives of 
 
 
 
 
 —i.e. the gradient of 
 
 
 
 .
These concepts are named after the mathematician Carl Gustav Jacob Jacobi (1804–1851).
Jacobian matrix
The Jacobian generalizes the gradient of a scalar-valued function of multiple variables, which itself generalizes the derivative of a scalar-valued function of a single variable. In other words, the Jacobian for a scalar-valued multivariable function is the gradient and that of a scalar-valued function of single variable is simply its derivative. The Jacobian can also be thought of as describing the amount of "stretching", "rotating" or "transforming" that a transformation imposes locally. For example, if 
 
 
 
  is used to transform an image, the Jacobian , describes how the image in the neighborhood of 
 
 
 
  is transformed.
If a function is differentiable at a point, its derivative is given in coordinates by the Jacobian, but a function doesn't need to be differentiable for the Jacobian to be defined, since only the partial derivatives are required to exist.
If 
 
 
 
  is a point in  and 
 
 
 
 
  is differentiable at 
 
 
 
 , then its derivative is given by . In this case, the linear map described by  is the best linear approximation of 
 
 
 
  near the point 
 
 
 
 , in the sense that



for 
 
 
 
 
  close to 
 
 
 
  and where 
 
 
 
  is the little o-notation (for 
 
 
 
 ) and 
 
 
 
  is the distance between 
 
 
 
 
  and 
 
 
 
 .
Compare this to a Taylor series for a scalar function of a scalar argument, truncated to first order:



In a sense, both the gradient and Jacobian are "first derivatives"—the former the first derivative of a scalar function of several variables, the latter the first derivative of a vector function of several variables.
The Jacobian of the gradient of a scalar function of several variables has a special name: the Hessian matrix, which in a sense is the "second derivative" of the function in question.
Jacobian determinant
(Figure)
A nonlinear map f : R2 → R2 sends a small square to a distorted parallelepiped close to the image of the square under the best linear approximation of f near the point.

If 
 
 
 
 =
 
 
 
 , then 
 
 
 
 
  is a function from  to itself and the Jacobian matrix is a square matrix. We can then form its determinant, known as the Jacobian determinant. The Jacobian determinant is occasionally referred to as "the Jacobian".
The Jacobian determinant at a given point gives important information about the behavior of 
 
 
 
  near that point. For instance, the continuously differentiable function

 
  is invertible near a point  if the Jacobian determinant at 
 
 
 
  is non-zero. This is the inverse function theorem. Furthermore, if the Jacobian determinant at 
 
 
 
  is positive, then 
 
 
 
 
  preserves orientation near 
 
 
 
 ; if it is negative, 
 
 
 
  reverses orientation. The absolute value of the Jacobian determinant at 
 
 
 
  gives us the factor by which the function 
 
 
 
  expands or shrinks volumes near 
 
 
 
 
 ; this is why it occurs in the general substitution rule.
The Jacobian determinant is used when making a change of variables when evaluating a multiple integral of a function over a region within its domain. To accommodate for the change of coordinates the magnitude of the Jacobian determinant arises as a multiplicative factor within the integral. This is because the 
 
 
 
 -dimensional 
 
 
 
  element is in general a parallelepiped in the new coordinate system, and the 
 
 
 
 -volume of a parallelepiped is the determinant of its edge vectors.
The Jacobian can also be used to solve systems of differential equations at an equilibrium point or approximate solutions near an equilibrium point.
Inverse
According to the inverse function theorem, the matrix inverse of the Jacobian matrix of an invertible function is the Jacobian matrix of the inverse function. That is, if the Jacobian of the function  is continuous and nonsingular at the point 
 
 
 
  in , then 
 
 
 
 
  is invertible when restricted to some neighborhood of 
 
 
 
  and



Conversely, if the Jacobian determinant is not zero at a point, then the function is locally invertible near this point, that is there is neighbourhood of this point, in which the function is invertible.
The (unproved) Jacobian conjecture is related to global invertibility in the case of a polynomial functions, that is a function defined by n polynomials in n variables. It asserts that, if the Jacobian determinant is a non-zero constant (or, equivalently, that it does not have any complex zero), then the function is invertible and its inverse is a polynomial function.
Critical points
If  is a differentiable function, a critical point of 
 
 
 
  is a point where the rank of the Jacobian matrix is not maximal. This means that the rank at the critical point is lower than the rank at some neighbour point. In other words, let 
 
 
 
  be the maximal dimension of the open balls contained in the image of 
 
 
 
 
 ; then a point is critical if all minors of rank 
 
 
 
  of 
 
 
 
  are zero.
In the case where 1 = 
 
 
 
  = 
 
 
 
  = 
 
 
 
 
 , a point is critical if the Jacobian determinant is zero.
Examples
Example 1
Consider the function  given by


 
  Then we have


 
  and


 
  and the Jacobian matrix of 
 
 
 
  is


 
  and the Jacobian determinant is



Example 2: polar-Cartesian transformation
The transformation from polar coordinates

 
  to Cartesian coordinates (x, y), is given by the function  with components:






The Jacobian determinant is equal to 
 
 
 
 . This can be used to transform integrals between the two coordinate systems:



Example 3: spherical-Cartesian transformation
The transformation from spherical coordinates

 
 
  to Cartesian coordinates (x, y, z), is given by the function  with components:



The Jacobian matrix for this coordinate change is



The determinant is . As an example, since  dx1 dx2 dx3}} this determinant implies that the differential volume element  r2 sin θ dr dθ dφ}}. Nevertheless this determinant varies with coordinates.
Example 4
The Jacobian matrix of the function  with components



is



This example shows that the Jacobian need not be a square matrix.
Example 5
The Jacobian determinant of the function  with components



is



From this we see that 
 
 
 
  reverses orientation near those points where  and  have the same sign; the function is locally invertible everywhere except near points where  0}} or  0}}. Intuitively, if one starts with a tiny object around the point 
 
 
 
  and apply 
 
 
 
  to that object, one will get a resulting object with approximately 
 
 
 
  times the volume of the original one.
Other uses
The Jacobian serves as a linearized design matrix in statistical regression and curve fitting; see non-linear least squares.
Dynamical systems
Consider a dynamical system of the form 
 
 
 
 , where 
 
 
 
  is the (component-wise) time derivative of 
 
 
 
 , and  is differentiable. If  0}}, then  is a stationary point (also called a critical point; this is not to be confused with fixed points). The behavior of the system near a stationary point is related to the eigenvalues of , the Jacobian of 
 
 
 
  at the stationary point.1 Specifically, if the eigenvalues all have real parts that are negative, then the system is stable near the stationary point, if any eigenvalue has a real part that is positive, then the point is unstable. If the largest real part of the eigenvalues is zero, the Jacobian matrix does not allow for an evaluation of the stability.
Newton's method
A system of coupled nonlinear equations can be solved iteratively by Newton's method. This method uses the Jacobian matrix of the system of equations.
See also

Hessian matrix
Pushforward (differential)

References
Further reading



External links


Mathworld A more technical explanation of Jacobians

"
Category:Multivariable calculus Category:Differential calculus Category:Generalizations of the derivative Category:Determinants Category:Matrices



↩




