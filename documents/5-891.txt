   Matrix norm      Matrix norm   In mathematics , a matrix norm is a natural extension of the notion of a vector norm to matrices .  Definition  In what follows,   K   K   K   will denote the field of real or complex numbers . Let    K   m  ×  n      superscript  K    m  n     K^{m\times n}   denote the vector space containing all matrices with   m   m   m   rows and   n   n   n   columns with entries in   K   K   K   . Throughout the article    A  *     superscript  A     A^{*}   denotes the conjugate transpose of matrix   A   A   A   .  A matrix norm is a vector norm on    K   m  ×  n      superscript  K    m  n     K^{m\times n}   . That is, if    ∥  A  ∥     norm  A    \|A\|   denotes the norm of the matrix   A   A   A   , then,        ∥  A  ∥   ≥  0       norm  A   0    \|A\|\geq 0          ∥  A  ∥   =  0       norm  A   0    \|A\|=0    iff     A  =  0      A  0    A=0          ∥   α  A   ∥   =    |  α  |    ∥  A  ∥         norm    α  A        α    norm  A      \|\alpha A\|=|\alpha|\|A\|   for all   α   α   \alpha   in   K   K   K   and all matrices   A   A   A   in    K   m  ×  n      superscript  K    m  n     K^{m\times n}          ∥   A  +  B   ∥   ≤    ∥  A  ∥   +   ∥  B  ∥         norm    A  B       norm  A    norm  B      \|A+B\|\leq\|A\|+\|B\|   for all matrices   A   A   A   and   B   B   B   in     K   m  ×  n    .     superscript  K    m  n     K^{m\times n}.      Additionally, in the case of square matrices (thus, m = n ), some (but not all) matrix norms satisfy the following condition, which is related to the fact that matrices are more than just vectors:        ∥   A  B   ∥   ≤    ∥  A  ∥    ∥  B  ∥         norm    A  B       norm  A    norm  B      \|AB\|\leq\|A\|\|B\|   for all matrices   A   A   A   and   B   B   B   in     K   n  ×  n    .     superscript  K    n  n     K^{n\times n}.      A matrix norm that satisfies this additional property is called a sub-multiplicative norm (in some books, the terminology matrix norm is used only for those norms which are sub-multiplicative). The set of all n -by- n matrices, together with such a sub-multiplicative norm, is an example of a Banach algebra .  Induced norm  If vector norms on K m and K n are given ( K is the field of real or complex numbers ), then one defines the corresponding induced norm or operator norm on the space of m -by- n matrices as the following maxima:      ∥  A  ∥     norm  A    \displaystyle\|A\|     The operator norm corresponding to the p -norm for vectors is:         ∥  A  ∥   p   =    sup   x  ≠  0       ∥   A  x   ∥   p     ∥  x  ∥   p      .       subscript   norm  A   p     subscript  supremum    x  0       subscript   norm    A  x    p    subscript   norm  x   p       \left\|A\right\|_{p}=\sup\limits_{x\neq 0}\frac{\left\|Ax\right\|_{p}}{\left\|%
 x\right\|_{p}}.     These are different from the entrywise p -norms and the Schatten p -norms for matrices treated below, which are also usually denoted by      ∥  A  ∥   p   .     subscript   norm  A   p    \left\|A\right\|_{p}.     In the case of    p  =  1      p  1    p=1   and    p  =  ∞      p     p=\infty   , the norms can be computed as:         ∥  A  ∥   1   =    max   1  ≤  j  ≤  n      ∑   i  =  1   m    |   a   i  j    |      ,       subscript   norm  A   1      subscript       1  j       n       superscript   subscript     i  1    m      subscript  a    i  j         \left\|A\right\|_{1}=\max\limits_{1\leq j\leq n}\sum_{i=1}^{m}|a_{ij}|,   which is simply the maximum absolute column sum of the matrix.         ∥  A  ∥   ∞   =    max   1  ≤  i  ≤  m      ∑   j  =  1   n    |   a   i  j    |      ,       subscript   norm  A        subscript       1  i       m       superscript   subscript     j  1    n      subscript  a    i  j         \left\|A\right\|_{\infty}=\max\limits_{1\leq i\leq m}\sum_{j=1}^{n}|a_{ij}|,   which is simply the maximum absolute row sum of the matrix  For example, if the matrix A is defined by       A  =   [      -  3     5    7      2    6    4      0    2    8     ]    ,      A      3   5  7    2  6  4    0  2  8      A=\begin{bmatrix}-3&5&7\\
 2&6&4\\
 0&2&8\\
 \end{bmatrix},   then we have || A || 1 = max(|-3|+2+0, 5+6+2, 7+4+8) = max(5,13,19) = 19. and || A || ∞ = max(|-3|+5+7, 2+6+4,0+2+8) = max(15,12,10) = 15.  In the special case of p = 2 (the Euclidean norm ), the induced matrix norm is the spectral norm . The spectral norm of a matrix A is the largest singular value of A i.e. the square root of the largest eigenvalue of the positive-semidefinite matrix  A * A :        ∥  A  ∥   2   =     λ  max    (    A    *    A   )     =    σ  max    (  A  )           subscript   norm  A   2        subscript  λ  max      superscript  A      A             subscript  σ  max   A      \left\|A\right\|_{2}=\sqrt{\lambda_{\text{max}}(A^{{}^{*}}A)}=\sigma_{\text{%
 max}}(A)    1 where A * denotes the conjugate transpose of A .  More generally, one can define the subordinate matrix norm on    K   m  ×  n      superscript  K    m  n     K^{m\times n}   induced by    ∥  ⋅   ∥  α      fragments  parallel-to  normal-⋅   subscript  parallel-to  α     \|\cdot\|_{\alpha}   on    K  n     superscript  K  n    K^{n}   , and    ∥  ⋅   ∥  β      fragments  parallel-to  normal-⋅   subscript  parallel-to  β     \|\cdot\|_{\beta}   on    K  m     superscript  K  m    K^{m}   as:         ∥  A  ∥    α  ,  β    =    max   x  ≠  0       ∥   A  x   ∥   β     ∥  x  ∥   α      .       subscript   norm  A    α  β      subscript     x  0       subscript   norm    A  x    β    subscript   norm  x   α       \left\|A\right\|_{\alpha,\beta}=\max\limits_{x\neq 0}\frac{\left\|Ax\right\|_{%
 \beta}}{\left\|x\right\|_{\alpha}}.     Subordinate norms are consistent with the norms that induce them, giving         ∥   A  x   ∥   β   ≤     ∥  A  ∥    α  ,  β      ∥  x  ∥   α     .       subscript   norm    A  x    β      subscript   norm  A    α  β     subscript   norm  x   α      \|Ax\|_{\beta}\leq\|A\|_{\alpha,\beta}\|x\|_{\alpha}.     For    α  =  β      α  β    \alpha=\beta   , any induced operator norm is a sub-multiplicative matrix norm since     ∥   A  B  x   ∥   ≤    ∥  A  ∥    ∥   B  x   ∥    ≤    ∥  A  ∥    ∥  B  ∥    ∥  x  ∥           norm    A  B  x       norm  A    norm    B  x             norm  A    norm  B    norm  x       \|ABx\|\leq\|A\|\|Bx\|\leq\|A\|\|B\|\|x\|   and       max    ∥  x  ∥   =  1     ∥   A  B  x   ∥    =   ∥   A  B   ∥    .        subscript      norm  x   1     norm    A  B  x      norm    A  B      \max\limits_{\|x\|=1}\|ABx\|=\|AB\|.   .  Any induced norm satisfies the inequality         ∥   A  r   ∥    1  /  r    ≥   ρ   (  A  )     ,       superscript   norm   superscript  A  r      1  r      ρ  A     \left\|A^{r}\right\|^{1/r}\geq\rho(A),   where ρ( A ) is the spectral radius of A . For a symmetric or hermitian matrix   A   A   A   , we have equality for the 2-norm, since in this case the 2-norm is the spectral radius of   A   A   A   . For an arbitrary matrix, we may not have equality for any norm. Take       A  =   [     0    1      0    0     ]    ,      A    0  1    0  0      A=\begin{bmatrix}0&1\\
 0&0\\
 \end{bmatrix},   the spectral radius of   A   A   A   is 0, but   A   A   A   is not the zero matrix, and so none of the induced norms are equal to the spectral radius of   A   A   A   .  Furthermore, for square matrices we have the spectral radius formula :         lim   r  →  ∞      ∥   A  r   ∥    1  /  r     =   ρ   (  A  )     .        subscript    normal-→  r      superscript   norm   superscript  A  r      1  r       ρ  A     \lim_{r\rightarrow\infty}\|A^{r}\|^{1/r}=\rho(A).     "Entrywise" norms  These vector norms treat an    m  ×  n      m  n    m\times n   matrix as a vector of size    m  n      m  n    mn   , and use one of the familiar vector norms.  For example, using the p -norm for vectors, we get:        ∥  A  ∥   p   =    ∥   vec   (  A  )    ∥   p   =    (    ∑   i  =  1   m     ∑   j  =  1   n     |   a   i  j    |   p     )    1  /  p           subscript   norm  A   p    subscript   norm    vec  A    p         superscript    superscript   subscript     i  1    m     superscript   subscript     j  1    n    superscript     subscript  a    i  j     p       1  p       \|A\|_{p}=\|\mathrm{vec}(A)\|_{p}=\left(\sum_{i=1}^{m}\sum_{j=1}^{n}|a_{ij}|^{%
 p}\right)^{1/p}     This is a different norm from the induced p -norm (see above) and the Schatten p -norm (see below), but the notation is the same.  The special case p = 2 is the Frobenius norm, and p = ∞ yields the maximum norm.  L2,1 norm  Let    (   a  1   ,  ⋯  ,   a  n   )      subscript  a  1   normal-⋯   subscript  a  n     (a_{1},\cdots,a_{n})   be the columns of matrix   A   A   A   . The    L   2  ,  1      subscript  L   2  1     L_{2,1}   norm 2 is the sum of the Euclidean norm of the columns of the matrix:        ∥  A  ∥    2  ,  1    =    ∑   j  =  1   n     ∥   a  j   ∥   2    =    ∑   j  =  1   n     (    ∑   i  =  1   m     |   a   i  j    |   2    )    1  /  2            subscript   norm  A    2  1      superscript   subscript     j  1    n    subscript   norm   subscript  a  j    2           superscript   subscript     j  1    n    superscript    superscript   subscript     i  1    m    superscript     subscript  a    i  j     2      1  2        \|A\|_{2,1}=\sum_{j=1}^{n}\|a_{j}\|_{2}=\sum_{j=1}^{n}\left(\sum_{i=1}^{m}|a_{%
 ij}|^{2}\right)^{1/2}     In this norm, the two indices   i   i   i   and   j   j   j   of    A   i  ,  j      subscript  A   i  j     A_{i,j}   are treated differently; all matrix norms introduced prior to the    L   2  ,  1      subscript  L   2  1     L_{2,1}   norm treat the two indicees symmetrically. The    L   2  ,  1      subscript  L   2  1     L_{2,1}   norm is used in robust data analysis and sparse coding for feature selection .  The    L   2  ,  1      subscript  L   2  1     L_{2,1}   norm can be generalized to the    L   p  ,  q      subscript  L   p  q     L_{p,q}   norm, defined by        ∥  A  ∥    p  ,  q    =    [    ∑   j  =  1   n     (    ∑   i  =  1   m     |   a   i  j    |   p    )    q  /  p     ]    1  /  q         subscript   norm  A    p  q     superscript   delimited-[]    superscript   subscript     j  1    n    superscript    superscript   subscript     i  1    m    superscript     subscript  a    i  j     p      q  p        1  q      \|A\|_{p,q}=\left[\sum_{j=1}^{n}\left(\sum_{i=1}^{m}|a_{ij}|^{p}\right)^{q/p}%
 \right]^{1/q}     Frobenius norm  For p = q = 2, this is called the Frobenius norm or the Hilbert–Schmidt norm , though the latter term is often reserved for operators on Hilbert space . This norm can be defined in various ways:        ∥  A  ∥   F   =     ∑   i  =  1   m     ∑   j  =  1   n     |   a   i  j    |   2      =    trace   (    A    *    A   )     =     ∑   i  =  1    min   {  m  ,  n  }      σ  i  2            subscript   norm  A   F       superscript   subscript     i  1    m     superscript   subscript     j  1    n    superscript     subscript  a    i  j     2              trace     superscript  A      A              superscript   subscript     i  1      m  n     superscript   subscript  σ  i   2        \|A\|_{F}=\sqrt{\sum_{i=1}^{m}\sum_{j=1}^{n}|a_{ij}|^{2}}=\sqrt{\operatorname{%
 trace}(A^{{}^{*}}A)}=\sqrt{\sum_{i=1}^{\min\{m,\,n\}}\sigma_{i}^{2}}     where A * denotes the conjugate transpose of A , σ i are the singular values of A , and the trace function is used. The Frobenius norm is similar to the Euclidean norm on K n and comes from the Frobenius inner product on the space of all matrices.  The Frobenius norm is sub-multiplicative and is very useful for numerical linear algebra . This norm is often easier to compute than induced norms and has the useful property of being invariant under rotations , that is,      ∥  A  ∥   F  2   =    ∥   A  R   ∥   F  2   =    ∥   R  A   ∥   F  2          superscript   subscript   norm  A   F   2    superscript   subscript   norm    A  R    F   2         superscript   subscript   norm    R  A    F   2      \|A\|_{F}^{2}=\|AR\|_{F}^{2}=\|RA\|_{F}^{2}   for any rotation matrix   R   R   R   . This property follows from the trace definition restricted to real matrices,        ∥   A  R   ∥   F  2   =   trace   (    R  T    A  T   A  R   )    =   trace   (   R   R  T    A  T   A   )    =   trace   (    A  T   A   )    =    ∥  A  ∥   F  2          superscript   subscript   norm    A  R    F   2    trace     superscript  R  normal-T    superscript  A  normal-T   A  R          trace    R   superscript  R  normal-T    superscript  A  normal-T   A          trace     superscript  A  normal-T   A          superscript   subscript   norm  A   F   2      \|AR\|_{F}^{2}=\operatorname{trace}\left(R^{\rm T}A^{\rm T}AR\right)=%
 \operatorname{trace}\left(RR^{\rm T}A^{\rm T}A\right)=\operatorname{trace}%
 \left(A^{\rm T}A\right)=\|A\|_{F}^{2}     and        ∥   R  A   ∥   F  2   =   trace   (    A  T    R  T   R  A   )    =   trace   (    A  T   A   )    =    ∥  A  ∥   F  2          superscript   subscript   norm    R  A    F   2    trace     superscript  A  normal-T    superscript  R  normal-T   R  A          trace     superscript  A  normal-T   A          superscript   subscript   norm  A   F   2      \|RA\|_{F}^{2}=\operatorname{trace}\left(A^{\rm T}R^{\rm T}RA\right)=%
 \operatorname{trace}\left(A^{\rm T}A\right)=\|A\|_{F}^{2}   where we have used the orthogonal nature of   R   R   R   , that is,      R  T   R   =   R   R  T    =  𝐈           superscript  R  normal-T   R     R   superscript  R  normal-T         𝐈     R^{\rm T}R=RR^{\rm T}=\mathbf{I}   , and the cyclic nature of the trace,     trace   (   X  Y  Z   )    =   trace   (   Z  X  Y   )         trace    X  Y  Z     trace    Z  X  Y      \operatorname{trace}(XYZ)=\operatorname{trace}(ZXY)   . More generally the norm is invariant under a unitary transformation for complex matrices.  Max norm  The max norm is the elementwise norm with p = ∞:         ∥  A  ∥   max   =   max   {   |   a   i  j    |   }     .       subscript   norm  A   max        subscript  a    i  j        \|A\|_{\text{max}}=\max\{|a_{ij}|\}.   This norm is not sub-multiplicative.  Schatten norms  The Schatten p -norms arise when applying the p -norm to the vector of singular values of a matrix. If the singular values are denoted by σ i , then the Schatten p -norm is defined by         ∥  A  ∥   p   =    (    ∑   i  =  1    min   {  m  ,  n  }      σ  i  p    )    1  /  p     .       subscript   norm  A   p    superscript    superscript   subscript     i  1      m  n     superscript   subscript  σ  i   p      1  p      \|A\|_{p}=\left(\sum_{i=1}^{\min\{m,\,n\}}\sigma_{i}^{p}\right)^{1/p}.\,   These norms again share the notation with the induced and entrywise p -norms, but they are different.  All Schatten norms are sub-multiplicative. They are also unitarily invariant, which means that || A || = || UAV || for all matrices A and all unitary matrices  U and V .  The most familiar cases are p = 1, 2, ∞. The case p = 2 yields the Frobenius norm, introduced before. The case p = ∞ yields the spectral norm, which is the matrix norm induced by the vector 2-norm (see above). Finally, p = 1 yields the nuclear norm (also known as the trace norm , or the Ky Fan 'n'-norm), defined as         ∥  A  ∥   *   =   trace   (     A  *   A    )    =    ∑   i  =  1    min   {  m  ,  n  }      σ  i     .         subscript   norm  A      trace       superscript  A    A            superscript   subscript     i  1      m  n     subscript  σ  i       \|A\|_{*}=\operatorname{trace}\left(\sqrt{A^{*}A}\right)=\sum_{i=1}^{\min\{m,%
 \,n\}}\sigma_{i}.     (Here      A  *   A          superscript  A    A     \sqrt{A^{*}A}   denotes a positive semidefinite matrix   B   B   B   such that     B  B   =    A  *   A         B  B      superscript  A    A     BB=A^{*}A   . More precisely, since     A  *   A       superscript  A    A    A^{*}A   is a positive semidefinite matrix , its square root is well-defined.)  Consistent norms  A matrix norm    ∥  ⋅   ∥   a  b       fragments  parallel-to  normal-⋅   subscript  parallel-to    a  b      \|\cdot\|_{ab}   on    K   m  ×  n      superscript  K    m  n     K^{m\times n}   is called consistent with a vector norm    ∥  ⋅   ∥  a      fragments  parallel-to  normal-⋅   subscript  parallel-to  a     \|\cdot\|_{a}   on    K  n     superscript  K  n    K^{n}   and a vector norm    ∥  ⋅   ∥  b      fragments  parallel-to  normal-⋅   subscript  parallel-to  b     \|\cdot\|_{b}   on    K  m     superscript  K  m    K^{m}   if:        ∥   A  x   ∥   b   ≤     ∥  A  ∥    a  b      ∥  x  ∥   a         subscript   norm    A  x    b      subscript   norm  A     a  b     subscript   norm  x   a      \|Ax\|_{b}\leq\|A\|_{ab}\|x\|_{a}   for all     A  ∈   K   m  ×  n     ,   x  ∈   K  n       formulae-sequence    A   superscript  K    m  n       x   superscript  K  n      A\in K^{m\times n},x\in K^{n}   . All induced norms are consistent by definition.  Compatible norms  A matrix norm    ∥  ⋅   ∥  b      fragments  parallel-to  normal-⋅   subscript  parallel-to  b     \|\cdot\|_{b}   on    K   n  ×  n      superscript  K    n  n     K^{n\times n}   is called compatible with a vector norm    ∥  ⋅   ∥  a      fragments  parallel-to  normal-⋅   subscript  parallel-to  a     \|\cdot\|_{a}   on    K  n     superscript  K  n    K^{n}   if:        ∥   A  x   ∥   a   ≤     ∥  A  ∥   b     ∥  x  ∥   a         subscript   norm    A  x    a      subscript   norm  A   b    subscript   norm  x   a      \|Ax\|_{a}\leq\|A\|_{b}\|x\|_{a}   for all     A  ∈   K   n  ×  n     ,   x  ∈   K  n       formulae-sequence    A   superscript  K    n  n       x   superscript  K  n      A\in K^{n\times n},x\in K^{n}   . Induced norms are compatible by definition.  Equivalence of norms  For any two vector norms    ∥  ⋅   ∥  α      fragments  parallel-to  normal-⋅   subscript  parallel-to  α     \|\cdot\|_{\alpha}   and    ∥  ⋅   ∥  β      fragments  parallel-to  normal-⋅   subscript  parallel-to  β     \|\cdot\|_{\beta}   , we have       r    ∥  A  ∥   α    ≤    ∥  A  ∥   β   ≤   s    ∥  A  ∥   α            r   subscript   norm  A   α     subscript   norm  A   β          s   subscript   norm  A   α       r\left\|A\right\|_{\alpha}\leq\left\|A\right\|_{\beta}\leq s\left\|A\right\|_{\alpha}     for some positive numbers r and s , for all matrices A in    K   m  ×  n      superscript  K    m  n     K^{m\times n}   . In other words, all norms on    K   m  ×  n      superscript  K    m  n     K^{m\times n}   are equivalent ; they induce the same topology on    K   m  ×  n      superscript  K    m  n     K^{m\times n}   . This is true because the vector space    K   m  ×  n      superscript  K    m  n     K^{m\times n}   has the finite dimension     m  ×  n      m  n    m\times n   .  Moreover, for every vector norm    ∥  ⋅  ∥     fragments  parallel-to  normal-⋅  parallel-to    \|\cdot\|   on    ℝ   n  ×  n      superscript  ℝ    n  n     \mathbb{R}^{n\times n}   , there exists a unique positive real number   k   k   k   such that    l  ∥  ⋅  ∥     fragments  l  parallel-to  normal-⋅  parallel-to    l\|\cdot\|   is a sub-multiplicative matrix norm for every    l  ≥  k      l  k    l\geq k   .  A sub-multiplicative matrix norm    ∥  ⋅   ∥  α      fragments  parallel-to  normal-⋅   subscript  parallel-to  α     \|\cdot\|_{\alpha}   is said to be minimal if there exists no other sub-multiplicative matrix norm    ∥  ⋅   ∥  β      fragments  parallel-to  normal-⋅   subscript  parallel-to  β     \|\cdot\|_{\beta}   satisfying    ∥  ⋅   ∥  β   <  ∥  ⋅   ∥  α      fragments  parallel-to  normal-⋅   subscript  parallel-to  β    parallel-to  normal-⋅   subscript  parallel-to  α     \|\cdot\|_{\beta}<\|\cdot\|_{\alpha}   .  Examples of norm equivalence  For matrix    A  ∈   ℝ   m  ×  n        A   superscript  ℝ    m  n      A\in\mathbb{R}^{m\times n}   of rank    r   r   r   , the following inequalities hold: 3 4         ∥  A  ∥   2   ≤    ∥  A  ∥   F   ≤    r     ∥  A  ∥   2           subscript   norm  A   2    subscript   norm  A   F            r    subscript   norm  A   2       \|A\|_{2}\leq\|A\|_{F}\leq\sqrt{r}\|A\|_{2}           ∥  A  ∥   F   ≤    ∥  A  ∥   *   ≤    r     ∥  A  ∥   F           subscript   norm  A   F    subscript   norm  A              r    subscript   norm  A   F       \|A\|_{F}\leq\|A\|_{*}\leq\sqrt{r}\|A\|_{F}           ∥  A  ∥   max   ≤    ∥  A  ∥   2   ≤     m  n      ∥  A  ∥   max           subscript   norm  A   max    subscript   norm  A   2              m  n     subscript   norm  A   max       \|A\|_{\text{max}}\leq\|A\|_{2}\leq\sqrt{mn}\|A\|_{\text{max}}           1   n      ∥  A  ∥   ∞    ≤    ∥  A  ∥   2   ≤    m     ∥  A  ∥   ∞              1    n     subscript   norm  A       subscript   norm  A   2            m    subscript   norm  A         \frac{1}{\sqrt{n}}\|A\|_{\infty}\leq\|A\|_{2}\leq\sqrt{m}\|A\|_{\infty}            1   m      ∥  A  ∥   1    ≤    ∥  A  ∥   2   ≤    n     ∥  A  ∥   1     .            1    m     subscript   norm  A   1     subscript   norm  A   2            n    subscript   norm  A   1       \frac{1}{\sqrt{m}}\|A\|_{1}\leq\|A\|_{2}\leq\sqrt{n}\|A\|_{1}.      Here,     ∥  A  ∥   p     subscript   norm  A   p    \|A\|_{p}   refers to the matrix norm induced by the vector p -norm.  Another useful inequality between matrix norms is         ∥  A  ∥   2   ≤      ∥  A  ∥   1     ∥  A  ∥   ∞      ,       subscript   norm  A   2        subscript   norm  A   1    subscript   norm  A         \|A\|_{2}\leq\sqrt{\|A\|_{1}\|A\|_{\infty}},   which is a special case of Hölder's inequality.  Notes  References   James W. Demmel , Applied Numerical Linear Algebra, section 1.7, published by SIAM, 1997.  Carl D. Meyer, Matrix Analysis and Applied Linear Algebra, published by SIAM, 2000. 1  John Watrous , Theory of Quantum Information, 2.3 Norms of operators , lecture notes, University of Waterloo, 2011.  Kendall Atkinson , An Introduction to Numerical Analysis, published by John Wiley & Sons, Inc 1989    "  Category:Norms (mathematics)  Category:Linear algebra     Carl D. Meyer, Matrix Analysis and Applied Linear Algebra,section 5.2,p281, Society for Industrial & Applied Mathematics,June 2000. ↩  ↩  Golub, Gene ; Charles F. Van Loan (1996). Matrix Computations - Third Edition. Baltimore: The Johns Hopkins University Press, 56-57. ISBN 0-8018-5413-X. ↩  Roger Horn and Charles Johnson. Matrix Analysis, Chapter 5, Cambridge University Press, 1985. ISBN 0-521-38632-2. ↩     