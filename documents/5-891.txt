   Matrix norm      Matrix norm   In mathematics , a matrix norm is a natural extension of the notion of a vector norm to matrices .  Definition  In what follows,   K   K   K   will denote the field of real or complex numbers . Let    K   m  √ó  n      superscript  K    m  n     K^{m\times n}   denote the vector space containing all matrices with   m   m   m   rows and   n   n   n   columns with entries in   K   K   K   . Throughout the article    A  *     superscript  A     A^{*}   denotes the conjugate transpose of matrix   A   A   A   .  A matrix norm is a vector norm on    K   m  √ó  n      superscript  K    m  n     K^{m\times n}   . That is, if    ‚à•  A  ‚à•     norm  A    \|A\|   denotes the norm of the matrix   A   A   A   , then,        ‚à•  A  ‚à•   ‚â•  0       norm  A   0    \|A\|\geq 0          ‚à•  A  ‚à•   =  0       norm  A   0    \|A\|=0    iff     A  =  0      A  0    A=0          ‚à•   Œ±  A   ‚à•   =    |  Œ±  |    ‚à•  A  ‚à•         norm    Œ±  A        Œ±    norm  A      \|\alpha A\|=|\alpha|\|A\|   for all   Œ±   Œ±   \alpha   in   K   K   K   and all matrices   A   A   A   in    K   m  √ó  n      superscript  K    m  n     K^{m\times n}          ‚à•   A  +  B   ‚à•   ‚â§    ‚à•  A  ‚à•   +   ‚à•  B  ‚à•         norm    A  B       norm  A    norm  B      \|A+B\|\leq\|A\|+\|B\|   for all matrices   A   A   A   and   B   B   B   in     K   m  √ó  n    .     superscript  K    m  n     K^{m\times n}.      Additionally, in the case of square matrices (thus, m = n ), some (but not all) matrix norms satisfy the following condition, which is related to the fact that matrices are more than just vectors:        ‚à•   A  B   ‚à•   ‚â§    ‚à•  A  ‚à•    ‚à•  B  ‚à•         norm    A  B       norm  A    norm  B      \|AB\|\leq\|A\|\|B\|   for all matrices   A   A   A   and   B   B   B   in     K   n  √ó  n    .     superscript  K    n  n     K^{n\times n}.      A matrix norm that satisfies this additional property is called a sub-multiplicative norm (in some books, the terminology matrix norm is used only for those norms which are sub-multiplicative). The set of all n -by- n matrices, together with such a sub-multiplicative norm, is an example of a Banach algebra .  Induced norm  If vector norms on K m and K n are given ( K is the field of real or complex numbers ), then one defines the corresponding induced norm or operator norm on the space of m -by- n matrices as the following maxima:      ‚à•  A  ‚à•     norm  A    \displaystyle\|A\|     The operator norm corresponding to the p -norm for vectors is:         ‚à•  A  ‚à•   p   =    sup   x  ‚â†  0       ‚à•   A  x   ‚à•   p     ‚à•  x  ‚à•   p      .       subscript   norm  A   p     subscript  supremum    x  0       subscript   norm    A  x    p    subscript   norm  x   p       \left\|A\right\|_{p}=\sup\limits_{x\neq 0}\frac{\left\|Ax\right\|_{p}}{\left\|%
 x\right\|_{p}}.     These are different from the entrywise p -norms and the Schatten p -norms for matrices treated below, which are also usually denoted by      ‚à•  A  ‚à•   p   .     subscript   norm  A   p    \left\|A\right\|_{p}.     In the case of    p  =  1      p  1    p=1   and    p  =  ‚àû      p     p=\infty   , the norms can be computed as:         ‚à•  A  ‚à•   1   =    max   1  ‚â§  j  ‚â§  n      ‚àë   i  =  1   m    |   a   i  j    |      ,       subscript   norm  A   1      subscript       1  j       n       superscript   subscript     i  1    m      subscript  a    i  j         \left\|A\right\|_{1}=\max\limits_{1\leq j\leq n}\sum_{i=1}^{m}|a_{ij}|,   which is simply the maximum absolute column sum of the matrix.         ‚à•  A  ‚à•   ‚àû   =    max   1  ‚â§  i  ‚â§  m      ‚àë   j  =  1   n    |   a   i  j    |      ,       subscript   norm  A        subscript       1  i       m       superscript   subscript     j  1    n      subscript  a    i  j         \left\|A\right\|_{\infty}=\max\limits_{1\leq i\leq m}\sum_{j=1}^{n}|a_{ij}|,   which is simply the maximum absolute row sum of the matrix  For example, if the matrix A is defined by       A  =   [      -  3     5    7      2    6    4      0    2    8     ]    ,      A      3   5  7    2  6  4    0  2  8      A=\begin{bmatrix}-3&5&7\\
 2&6&4\\
 0&2&8\\
 \end{bmatrix},   then we have || A || 1 = max(|-3|+2+0, 5+6+2, 7+4+8) = max(5,13,19) = 19. and || A || ‚àû = max(|-3|+5+7, 2+6+4,0+2+8) = max(15,12,10) = 15.  In the special case of p = 2 (the Euclidean norm ), the induced matrix norm is the spectral norm . The spectral norm of a matrix A is the largest singular value of A i.e. the square root of the largest eigenvalue of the positive-semidefinite matrix  A * A :        ‚à•  A  ‚à•   2   =     Œª  max    (    A    *    A   )     =    œÉ  max    (  A  )           subscript   norm  A   2        subscript  Œª  max      superscript  A      A             subscript  œÉ  max   A      \left\|A\right\|_{2}=\sqrt{\lambda_{\text{max}}(A^{{}^{*}}A)}=\sigma_{\text{%
 max}}(A)    1 where A * denotes the conjugate transpose of A .  More generally, one can define the subordinate matrix norm on    K   m  √ó  n      superscript  K    m  n     K^{m\times n}   induced by    ‚à•  ‚ãÖ   ‚à•  Œ±      fragments  parallel-to  normal-‚ãÖ   subscript  parallel-to  Œ±     \|\cdot\|_{\alpha}   on    K  n     superscript  K  n    K^{n}   , and    ‚à•  ‚ãÖ   ‚à•  Œ≤      fragments  parallel-to  normal-‚ãÖ   subscript  parallel-to  Œ≤     \|\cdot\|_{\beta}   on    K  m     superscript  K  m    K^{m}   as:         ‚à•  A  ‚à•    Œ±  ,  Œ≤    =    max   x  ‚â†  0       ‚à•   A  x   ‚à•   Œ≤     ‚à•  x  ‚à•   Œ±      .       subscript   norm  A    Œ±  Œ≤      subscript     x  0       subscript   norm    A  x    Œ≤    subscript   norm  x   Œ±       \left\|A\right\|_{\alpha,\beta}=\max\limits_{x\neq 0}\frac{\left\|Ax\right\|_{%
 \beta}}{\left\|x\right\|_{\alpha}}.     Subordinate norms are consistent with the norms that induce them, giving         ‚à•   A  x   ‚à•   Œ≤   ‚â§     ‚à•  A  ‚à•    Œ±  ,  Œ≤      ‚à•  x  ‚à•   Œ±     .       subscript   norm    A  x    Œ≤      subscript   norm  A    Œ±  Œ≤     subscript   norm  x   Œ±      \|Ax\|_{\beta}\leq\|A\|_{\alpha,\beta}\|x\|_{\alpha}.     For    Œ±  =  Œ≤      Œ±  Œ≤    \alpha=\beta   , any induced operator norm is a sub-multiplicative matrix norm since     ‚à•   A  B  x   ‚à•   ‚â§    ‚à•  A  ‚à•    ‚à•   B  x   ‚à•    ‚â§    ‚à•  A  ‚à•    ‚à•  B  ‚à•    ‚à•  x  ‚à•           norm    A  B  x       norm  A    norm    B  x             norm  A    norm  B    norm  x       \|ABx\|\leq\|A\|\|Bx\|\leq\|A\|\|B\|\|x\|   and       max    ‚à•  x  ‚à•   =  1     ‚à•   A  B  x   ‚à•    =   ‚à•   A  B   ‚à•    .        subscript      norm  x   1     norm    A  B  x      norm    A  B      \max\limits_{\|x\|=1}\|ABx\|=\|AB\|.   .  Any induced norm satisfies the inequality         ‚à•   A  r   ‚à•    1  /  r    ‚â•   œÅ   (  A  )     ,       superscript   norm   superscript  A  r      1  r      œÅ  A     \left\|A^{r}\right\|^{1/r}\geq\rho(A),   where œÅ( A ) is the spectral radius of A . For a symmetric or hermitian matrix   A   A   A   , we have equality for the 2-norm, since in this case the 2-norm is the spectral radius of   A   A   A   . For an arbitrary matrix, we may not have equality for any norm. Take       A  =   [     0    1      0    0     ]    ,      A    0  1    0  0      A=\begin{bmatrix}0&1\\
 0&0\\
 \end{bmatrix},   the spectral radius of   A   A   A   is 0, but   A   A   A   is not the zero matrix, and so none of the induced norms are equal to the spectral radius of   A   A   A   .  Furthermore, for square matrices we have the spectral radius formula :         lim   r  ‚Üí  ‚àû      ‚à•   A  r   ‚à•    1  /  r     =   œÅ   (  A  )     .        subscript    normal-‚Üí  r      superscript   norm   superscript  A  r      1  r       œÅ  A     \lim_{r\rightarrow\infty}\|A^{r}\|^{1/r}=\rho(A).     "Entrywise" norms  These vector norms treat an    m  √ó  n      m  n    m\times n   matrix as a vector of size    m  n      m  n    mn   , and use one of the familiar vector norms.  For example, using the p -norm for vectors, we get:        ‚à•  A  ‚à•   p   =    ‚à•   vec   (  A  )    ‚à•   p   =    (    ‚àë   i  =  1   m     ‚àë   j  =  1   n     |   a   i  j    |   p     )    1  /  p           subscript   norm  A   p    subscript   norm    vec  A    p         superscript    superscript   subscript     i  1    m     superscript   subscript     j  1    n    superscript     subscript  a    i  j     p       1  p       \|A\|_{p}=\|\mathrm{vec}(A)\|_{p}=\left(\sum_{i=1}^{m}\sum_{j=1}^{n}|a_{ij}|^{%
 p}\right)^{1/p}     This is a different norm from the induced p -norm (see above) and the Schatten p -norm (see below), but the notation is the same.  The special case p = 2 is the Frobenius norm, and p = ‚àû yields the maximum norm.  L2,1 norm  Let    (   a  1   ,  ‚ãØ  ,   a  n   )      subscript  a  1   normal-‚ãØ   subscript  a  n     (a_{1},\cdots,a_{n})   be the columns of matrix   A   A   A   . The    L   2  ,  1      subscript  L   2  1     L_{2,1}   norm 2 is the sum of the Euclidean norm of the columns of the matrix:        ‚à•  A  ‚à•    2  ,  1    =    ‚àë   j  =  1   n     ‚à•   a  j   ‚à•   2    =    ‚àë   j  =  1   n     (    ‚àë   i  =  1   m     |   a   i  j    |   2    )    1  /  2            subscript   norm  A    2  1      superscript   subscript     j  1    n    subscript   norm   subscript  a  j    2           superscript   subscript     j  1    n    superscript    superscript   subscript     i  1    m    superscript     subscript  a    i  j     2      1  2        \|A\|_{2,1}=\sum_{j=1}^{n}\|a_{j}\|_{2}=\sum_{j=1}^{n}\left(\sum_{i=1}^{m}|a_{%
 ij}|^{2}\right)^{1/2}     In this norm, the two indices   i   i   i   and   j   j   j   of    A   i  ,  j      subscript  A   i  j     A_{i,j}   are treated differently; all matrix norms introduced prior to the    L   2  ,  1      subscript  L   2  1     L_{2,1}   norm treat the two indicees symmetrically. The    L   2  ,  1      subscript  L   2  1     L_{2,1}   norm is used in robust data analysis and sparse coding for feature selection .  The    L   2  ,  1      subscript  L   2  1     L_{2,1}   norm can be generalized to the    L   p  ,  q      subscript  L   p  q     L_{p,q}   norm, defined by        ‚à•  A  ‚à•    p  ,  q    =    [    ‚àë   j  =  1   n     (    ‚àë   i  =  1   m     |   a   i  j    |   p    )    q  /  p     ]    1  /  q         subscript   norm  A    p  q     superscript   delimited-[]    superscript   subscript     j  1    n    superscript    superscript   subscript     i  1    m    superscript     subscript  a    i  j     p      q  p        1  q      \|A\|_{p,q}=\left[\sum_{j=1}^{n}\left(\sum_{i=1}^{m}|a_{ij}|^{p}\right)^{q/p}%
 \right]^{1/q}     Frobenius norm  For p = q = 2, this is called the Frobenius norm or the Hilbert‚ÄìSchmidt norm , though the latter term is often reserved for operators on Hilbert space . This norm can be defined in various ways:        ‚à•  A  ‚à•   F   =     ‚àë   i  =  1   m     ‚àë   j  =  1   n     |   a   i  j    |   2      =    trace   (    A    *    A   )     =     ‚àë   i  =  1    min   {  m  ,  n  }      œÉ  i  2            subscript   norm  A   F       superscript   subscript     i  1    m     superscript   subscript     j  1    n    superscript     subscript  a    i  j     2              trace     superscript  A      A              superscript   subscript     i  1      m  n     superscript   subscript  œÉ  i   2        \|A\|_{F}=\sqrt{\sum_{i=1}^{m}\sum_{j=1}^{n}|a_{ij}|^{2}}=\sqrt{\operatorname{%
 trace}(A^{{}^{*}}A)}=\sqrt{\sum_{i=1}^{\min\{m,\,n\}}\sigma_{i}^{2}}     where A * denotes the conjugate transpose of A , œÉ i are the singular values of A , and the trace function is used. The Frobenius norm is similar to the Euclidean norm on K n and comes from the Frobenius inner product on the space of all matrices.  The Frobenius norm is sub-multiplicative and is very useful for numerical linear algebra . This norm is often easier to compute than induced norms and has the useful property of being invariant under rotations , that is,      ‚à•  A  ‚à•   F  2   =    ‚à•   A  R   ‚à•   F  2   =    ‚à•   R  A   ‚à•   F  2          superscript   subscript   norm  A   F   2    superscript   subscript   norm    A  R    F   2         superscript   subscript   norm    R  A    F   2      \|A\|_{F}^{2}=\|AR\|_{F}^{2}=\|RA\|_{F}^{2}   for any rotation matrix   R   R   R   . This property follows from the trace definition restricted to real matrices,        ‚à•   A  R   ‚à•   F  2   =   trace   (    R  T    A  T   A  R   )    =   trace   (   R   R  T    A  T   A   )    =   trace   (    A  T   A   )    =    ‚à•  A  ‚à•   F  2          superscript   subscript   norm    A  R    F   2    trace     superscript  R  normal-T    superscript  A  normal-T   A  R          trace    R   superscript  R  normal-T    superscript  A  normal-T   A          trace     superscript  A  normal-T   A          superscript   subscript   norm  A   F   2      \|AR\|_{F}^{2}=\operatorname{trace}\left(R^{\rm T}A^{\rm T}AR\right)=%
 \operatorname{trace}\left(RR^{\rm T}A^{\rm T}A\right)=\operatorname{trace}%
 \left(A^{\rm T}A\right)=\|A\|_{F}^{2}     and        ‚à•   R  A   ‚à•   F  2   =   trace   (    A  T    R  T   R  A   )    =   trace   (    A  T   A   )    =    ‚à•  A  ‚à•   F  2          superscript   subscript   norm    R  A    F   2    trace     superscript  A  normal-T    superscript  R  normal-T   R  A          trace     superscript  A  normal-T   A          superscript   subscript   norm  A   F   2      \|RA\|_{F}^{2}=\operatorname{trace}\left(A^{\rm T}R^{\rm T}RA\right)=%
 \operatorname{trace}\left(A^{\rm T}A\right)=\|A\|_{F}^{2}   where we have used the orthogonal nature of   R   R   R   , that is,      R  T   R   =   R   R  T    =  ùêà           superscript  R  normal-T   R     R   superscript  R  normal-T         ùêà     R^{\rm T}R=RR^{\rm T}=\mathbf{I}   , and the cyclic nature of the trace,     trace   (   X  Y  Z   )    =   trace   (   Z  X  Y   )         trace    X  Y  Z     trace    Z  X  Y      \operatorname{trace}(XYZ)=\operatorname{trace}(ZXY)   . More generally the norm is invariant under a unitary transformation for complex matrices.  Max norm  The max norm is the elementwise norm with p = ‚àû:         ‚à•  A  ‚à•   max   =   max   {   |   a   i  j    |   }     .       subscript   norm  A   max        subscript  a    i  j        \|A\|_{\text{max}}=\max\{|a_{ij}|\}.   This norm is not sub-multiplicative.  Schatten norms  The Schatten p -norms arise when applying the p -norm to the vector of singular values of a matrix. If the singular values are denoted by œÉ i , then the Schatten p -norm is defined by         ‚à•  A  ‚à•   p   =    (    ‚àë   i  =  1    min   {  m  ,  n  }      œÉ  i  p    )    1  /  p     .       subscript   norm  A   p    superscript    superscript   subscript     i  1      m  n     superscript   subscript  œÉ  i   p      1  p      \|A\|_{p}=\left(\sum_{i=1}^{\min\{m,\,n\}}\sigma_{i}^{p}\right)^{1/p}.\,   These norms again share the notation with the induced and entrywise p -norms, but they are different.  All Schatten norms are sub-multiplicative. They are also unitarily invariant, which means that || A || = || UAV || for all matrices A and all unitary matrices  U and V .  The most familiar cases are p = 1, 2, ‚àû. The case p = 2 yields the Frobenius norm, introduced before. The case p = ‚àû yields the spectral norm, which is the matrix norm induced by the vector 2-norm (see above). Finally, p = 1 yields the nuclear norm (also known as the trace norm , or the Ky Fan 'n'-norm), defined as         ‚à•  A  ‚à•   *   =   trace   (     A  *   A    )    =    ‚àë   i  =  1    min   {  m  ,  n  }      œÉ  i     .         subscript   norm  A      trace       superscript  A    A            superscript   subscript     i  1      m  n     subscript  œÉ  i       \|A\|_{*}=\operatorname{trace}\left(\sqrt{A^{*}A}\right)=\sum_{i=1}^{\min\{m,%
 \,n\}}\sigma_{i}.     (Here      A  *   A          superscript  A    A     \sqrt{A^{*}A}   denotes a positive semidefinite matrix   B   B   B   such that     B  B   =    A  *   A         B  B      superscript  A    A     BB=A^{*}A   . More precisely, since     A  *   A       superscript  A    A    A^{*}A   is a positive semidefinite matrix , its square root is well-defined.)  Consistent norms  A matrix norm    ‚à•  ‚ãÖ   ‚à•   a  b       fragments  parallel-to  normal-‚ãÖ   subscript  parallel-to    a  b      \|\cdot\|_{ab}   on    K   m  √ó  n      superscript  K    m  n     K^{m\times n}   is called consistent with a vector norm    ‚à•  ‚ãÖ   ‚à•  a      fragments  parallel-to  normal-‚ãÖ   subscript  parallel-to  a     \|\cdot\|_{a}   on    K  n     superscript  K  n    K^{n}   and a vector norm    ‚à•  ‚ãÖ   ‚à•  b      fragments  parallel-to  normal-‚ãÖ   subscript  parallel-to  b     \|\cdot\|_{b}   on    K  m     superscript  K  m    K^{m}   if:        ‚à•   A  x   ‚à•   b   ‚â§     ‚à•  A  ‚à•    a  b      ‚à•  x  ‚à•   a         subscript   norm    A  x    b      subscript   norm  A     a  b     subscript   norm  x   a      \|Ax\|_{b}\leq\|A\|_{ab}\|x\|_{a}   for all     A  ‚àà   K   m  √ó  n     ,   x  ‚àà   K  n       formulae-sequence    A   superscript  K    m  n       x   superscript  K  n      A\in K^{m\times n},x\in K^{n}   . All induced norms are consistent by definition.  Compatible norms  A matrix norm    ‚à•  ‚ãÖ   ‚à•  b      fragments  parallel-to  normal-‚ãÖ   subscript  parallel-to  b     \|\cdot\|_{b}   on    K   n  √ó  n      superscript  K    n  n     K^{n\times n}   is called compatible with a vector norm    ‚à•  ‚ãÖ   ‚à•  a      fragments  parallel-to  normal-‚ãÖ   subscript  parallel-to  a     \|\cdot\|_{a}   on    K  n     superscript  K  n    K^{n}   if:        ‚à•   A  x   ‚à•   a   ‚â§     ‚à•  A  ‚à•   b     ‚à•  x  ‚à•   a         subscript   norm    A  x    a      subscript   norm  A   b    subscript   norm  x   a      \|Ax\|_{a}\leq\|A\|_{b}\|x\|_{a}   for all     A  ‚àà   K   n  √ó  n     ,   x  ‚àà   K  n       formulae-sequence    A   superscript  K    n  n       x   superscript  K  n      A\in K^{n\times n},x\in K^{n}   . Induced norms are compatible by definition.  Equivalence of norms  For any two vector norms    ‚à•  ‚ãÖ   ‚à•  Œ±      fragments  parallel-to  normal-‚ãÖ   subscript  parallel-to  Œ±     \|\cdot\|_{\alpha}   and    ‚à•  ‚ãÖ   ‚à•  Œ≤      fragments  parallel-to  normal-‚ãÖ   subscript  parallel-to  Œ≤     \|\cdot\|_{\beta}   , we have       r    ‚à•  A  ‚à•   Œ±    ‚â§    ‚à•  A  ‚à•   Œ≤   ‚â§   s    ‚à•  A  ‚à•   Œ±            r   subscript   norm  A   Œ±     subscript   norm  A   Œ≤          s   subscript   norm  A   Œ±       r\left\|A\right\|_{\alpha}\leq\left\|A\right\|_{\beta}\leq s\left\|A\right\|_{\alpha}     for some positive numbers r and s , for all matrices A in    K   m  √ó  n      superscript  K    m  n     K^{m\times n}   . In other words, all norms on    K   m  √ó  n      superscript  K    m  n     K^{m\times n}   are equivalent ; they induce the same topology on    K   m  √ó  n      superscript  K    m  n     K^{m\times n}   . This is true because the vector space    K   m  √ó  n      superscript  K    m  n     K^{m\times n}   has the finite dimension     m  √ó  n      m  n    m\times n   .  Moreover, for every vector norm    ‚à•  ‚ãÖ  ‚à•     fragments  parallel-to  normal-‚ãÖ  parallel-to    \|\cdot\|   on    ‚Ñù   n  √ó  n      superscript  ‚Ñù    n  n     \mathbb{R}^{n\times n}   , there exists a unique positive real number   k   k   k   such that    l  ‚à•  ‚ãÖ  ‚à•     fragments  l  parallel-to  normal-‚ãÖ  parallel-to    l\|\cdot\|   is a sub-multiplicative matrix norm for every    l  ‚â•  k      l  k    l\geq k   .  A sub-multiplicative matrix norm    ‚à•  ‚ãÖ   ‚à•  Œ±      fragments  parallel-to  normal-‚ãÖ   subscript  parallel-to  Œ±     \|\cdot\|_{\alpha}   is said to be minimal if there exists no other sub-multiplicative matrix norm    ‚à•  ‚ãÖ   ‚à•  Œ≤      fragments  parallel-to  normal-‚ãÖ   subscript  parallel-to  Œ≤     \|\cdot\|_{\beta}   satisfying    ‚à•  ‚ãÖ   ‚à•  Œ≤   <  ‚à•  ‚ãÖ   ‚à•  Œ±      fragments  parallel-to  normal-‚ãÖ   subscript  parallel-to  Œ≤    parallel-to  normal-‚ãÖ   subscript  parallel-to  Œ±     \|\cdot\|_{\beta}<\|\cdot\|_{\alpha}   .  Examples of norm equivalence  For matrix    A  ‚àà   ‚Ñù   m  √ó  n        A   superscript  ‚Ñù    m  n      A\in\mathbb{R}^{m\times n}   of rank    r   r   r   , the following inequalities hold: 3 4         ‚à•  A  ‚à•   2   ‚â§    ‚à•  A  ‚à•   F   ‚â§    r     ‚à•  A  ‚à•   2           subscript   norm  A   2    subscript   norm  A   F            r    subscript   norm  A   2       \|A\|_{2}\leq\|A\|_{F}\leq\sqrt{r}\|A\|_{2}           ‚à•  A  ‚à•   F   ‚â§    ‚à•  A  ‚à•   *   ‚â§    r     ‚à•  A  ‚à•   F           subscript   norm  A   F    subscript   norm  A              r    subscript   norm  A   F       \|A\|_{F}\leq\|A\|_{*}\leq\sqrt{r}\|A\|_{F}           ‚à•  A  ‚à•   max   ‚â§    ‚à•  A  ‚à•   2   ‚â§     m  n      ‚à•  A  ‚à•   max           subscript   norm  A   max    subscript   norm  A   2              m  n     subscript   norm  A   max       \|A\|_{\text{max}}\leq\|A\|_{2}\leq\sqrt{mn}\|A\|_{\text{max}}           1   n      ‚à•  A  ‚à•   ‚àû    ‚â§    ‚à•  A  ‚à•   2   ‚â§    m     ‚à•  A  ‚à•   ‚àû              1    n     subscript   norm  A       subscript   norm  A   2            m    subscript   norm  A         \frac{1}{\sqrt{n}}\|A\|_{\infty}\leq\|A\|_{2}\leq\sqrt{m}\|A\|_{\infty}            1   m      ‚à•  A  ‚à•   1    ‚â§    ‚à•  A  ‚à•   2   ‚â§    n     ‚à•  A  ‚à•   1     .            1    m     subscript   norm  A   1     subscript   norm  A   2            n    subscript   norm  A   1       \frac{1}{\sqrt{m}}\|A\|_{1}\leq\|A\|_{2}\leq\sqrt{n}\|A\|_{1}.      Here,     ‚à•  A  ‚à•   p     subscript   norm  A   p    \|A\|_{p}   refers to the matrix norm induced by the vector p -norm.  Another useful inequality between matrix norms is         ‚à•  A  ‚à•   2   ‚â§      ‚à•  A  ‚à•   1     ‚à•  A  ‚à•   ‚àû      ,       subscript   norm  A   2        subscript   norm  A   1    subscript   norm  A         \|A\|_{2}\leq\sqrt{\|A\|_{1}\|A\|_{\infty}},   which is a special case of H√∂lder's inequality.  Notes  References   James W. Demmel , Applied Numerical Linear Algebra, section 1.7, published by SIAM, 1997.  Carl D. Meyer, Matrix Analysis and Applied Linear Algebra, published by SIAM, 2000. 1  John Watrous , Theory of Quantum Information, 2.3 Norms of operators , lecture notes, University of Waterloo, 2011.  Kendall Atkinson , An Introduction to Numerical Analysis, published by John Wiley & Sons, Inc 1989    "  Category:Norms (mathematics)  Category:Linear algebra     Carl D. Meyer, Matrix Analysis and Applied Linear Algebra,section 5.2,p281, Society for Industrial & Applied Mathematics,June 2000. ‚Ü©  ‚Ü©  Golub, Gene ; Charles F. Van Loan (1996). Matrix Computations - Third Edition. Baltimore: The Johns Hopkins University Press, 56-57. ISBN 0-8018-5413-X. ‚Ü©  Roger Horn and Charles Johnson. Matrix Analysis, Chapter 5, Cambridge University Press, 1985. ISBN 0-521-38632-2. ‚Ü©     