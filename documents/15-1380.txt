   Kemeny's constant      Kemeny's constant   In probability theory , Kemeny’s constant is the expected number of time steps required for a Markov chain to transition from a starting state i to a random destination state sampled from the Markov chain's stationary distribution. Surprisingly, this quantity does not depend on which starting state i is chosen. 1 It is in that sense a constant, although it is different for different Markov chains. When first published by John Kemeny in 1960 a prize was offered for an intuitive explanation as to why quantity was constant. 2 3  Definition  For a finite ergodic Markov chain 4 with transition matrix  P and invariant distribution π , write m ij for the mean first passage time from state i to state j (denoting the mean recurrence time for the case i = j ). Then      K  =    ∑  j     π  j    m   i  j          K    subscript   j      subscript  π  j    subscript  m    i  j        K=\sum_{j}\pi_{j}m_{ij}   is a constant and not dependent on i . 5  Prize  Kemeny wrote, (for i the starting state of the Markov chain) “A prize is offered for the first person to give an intuitively plausible reason for the above sum to be independent of i .” 6 Grinstead and Snell offer an explanation by Peter Doyle as an exercise, with solution “he got it!” 7 8   In the course of a walk with Snell along Minnehaha Avenue in Minneapolis in the fall of 1983, Peter Doyle suggested the following explanation for the constancy of Kemeny's constant. Choose a target state according to the fixed vector w . Start from state i and wait until the time T that the target state occurs for the first time. Let K i be the expected value of T . Observe that        K  i   +     w  i   ⋅  1   /   w  i     =     ∑  j     P   i  j     K  j     +  1          subscript  K  i      normal-⋅   subscript  w  i   1    subscript  w  i         subscript   j      subscript  P    i  j     subscript  K  j     1     K_{i}+w_{i}\cdot 1/w_{i}=\sum_{j}P_{ij}K_{j}+1   and hence        K  i   =    ∑  j     P   i  j     K  j      .       subscript  K  i     subscript   j      subscript  P    i  j     subscript  K  j       K_{i}=\sum_{j}P_{ij}K_{j}.   By the maximum principle , K i is a constant. Should Peter have been given the prize?   References  "  Category:Stochastic processes     ↩  (Corollary 4.3.6) ↩  ↩  ↩  ↩   ↩  ↩     