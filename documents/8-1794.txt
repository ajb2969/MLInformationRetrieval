   Quantum finite automata      Quantum finite automata   In quantum computing , quantum finite automata or QFA or quantum state machines are a quantum analog of probabilistic automata or a Markov decision process . They are related to quantum computers in a similar fashion as finite automata are related to Turing machines . Several types of automata may be defined, including measure-once and measure-many automata. Quantum finite automata can also be understood as the quantization of subshifts of finite type , or as a quantization of Markov chains . QFA's are, in turn, special cases of geometric finite automata or topological finite automata .  The automata work by accepting a finite-length string     Ïƒ  =   (   Ïƒ  0   ,   Ïƒ  1   ,  â‹¯  ,   Ïƒ  k   )       Ïƒ    subscript  Ïƒ  0    subscript  Ïƒ  1   normal-â‹¯   subscript  Ïƒ  k      \sigma=(\sigma_{0},\sigma_{1},\cdots,\sigma_{k})   of letters    Ïƒ  i     subscript  Ïƒ  i    \sigma_{i}   from a finite alphabet    Î£   normal-Î£   \Sigma   , and assigning to each such string a probability     Pr   (  Ïƒ  )      Pr  Ïƒ    \operatorname{Pr}(\sigma)   indicating the probability of the automaton being in an accept state ; that is, indicating whether the automaton accepted or rejected the string.  The languages accepted by QFA's are not the regular languages of deterministic finite automata , nor are they the stochastic languages of probabilistic finite automata . Study of these quantum languages remains an active area of research.  Informal description  There is a simple, intuitive way of understanding quantum finite automata. One begins with a graph-theoretic interpretation of deterministic finite automata (DFA). A DFA can be represented as a directed graph, with states as nodes in the graph, and arrows representing state transitions. Each arrow is labelled with a possible input symbol, so that, given a specific state and an input symbol, the arrow points at the next state. One way of representing such a graph is by means of a set of adjacency matrices , with one matrix for each input symbol. In this case, the list of possible DFA states is written as a column vector. For a given input symbol, the adjacency matrix indicates how any given state (row in the state vector) will transition to the next state; a state transition is given by matrix multiplication .  One needs a distinct adjacency matrix for each possible input symbol, since each input symbol can result in a different transition. The entries in the adjacency matrix must be zero's and one's. For any given column in the matrix, only one entry can be non-zero: this is the entry that indicates the next (unique) state transition. Similarly, the state of the system is a column vector, in which only one entry is non-zero: this entry corresponds to the current state of the system. Let    Î£  =   {  Î±  }       normal-Î£   Î±     \Sigma=\{\alpha\}   denote the set of input symbols. For a given input symbol    Î±  âˆˆ  Î£      Î±  normal-Î£    \alpha\in\Sigma   , write    U  Î±     subscript  U  Î±    U_{\alpha}   as the adjacency matrix that describes the evolution of the DFA to its next state. The set    {   U  Î±   |   Î±  âˆˆ  Î£   }     conditional-set   subscript  U  Î±     Î±  normal-Î£     \{U_{\alpha}|\alpha\in\Sigma\}   then completely describes the state transition function of the DFA. Let Q represent the set of possible states of the DFA. If there are N states in Q , then each matrix    U  Î±     subscript  U  Î±    U_{\alpha}   is N by N -dimensional. The initial state     q  0   âˆˆ  Q       subscript  q  0   Q    q_{0}\in Q   corresponds to a column vector with a one in the q 0 'th row. A general state q is then a column vector with a one in the q 'th row. By abuse of notation , let q 0 and q also denote these two vectors. Then, after reading input symbols    Î±  Î²  Î³  â‹¯      Î±  Î²  Î³  normal-â‹¯    \alpha\beta\gamma\cdots   from the input tape, the state of the DFA will be given by     q  =   â‹¯   U  Î³    U  Î²    U  Î±    q  0     .      q    normal-â‹¯   subscript  U  Î³    subscript  U  Î²    subscript  U  Î±    subscript  q  0      q=\cdots U_{\gamma}U_{\beta}U_{\alpha}q_{0}.   The state transitions are given by ordinary matrix multiplication (that is, multiply q 0 by    U  Î±     subscript  U  Î±    U_{\alpha}   , etc. ); the order of application is 'reversed' only because we follow the standard application order in linear algebra.  The above description of a DFA, in terms of linear operators and vectors, almost begs for generalization, by replacing the state-vector q by some general vector, and the matrices    {   U  Î±   }      subscript  U  Î±     \{U_{\alpha}\}   by some general operators. This is essentially what a QFA does: it replaces q by a probability amplitude , and the    {   U  Î±   }      subscript  U  Î±     \{U_{\alpha}\}   by unitary matrices . Other, similar generalizations also become obvious: the vector q can be some distribution on a manifold ; the set of transition matrices become automorphisms of the manifold; this defines a topological finite automaton. Similarly, the matrices could be taken as automorphisms of a homogeneous space ; this defines a geometric finite automaton.  Before moving on to the formal description of a QFA, there are two noteworthy generalizations that should be mentioned and understood. The first is the non-deterministic finite automaton (NFA). In this case, the vector q is replaced by a vector which can have more than one entry that is non-zero. Such a vector then represents an element of the power set of Q ; its just an indicator function on Q . Likewise, the state transition matrices    {   U  Î±   }      subscript  U  Î±     \{U_{\alpha}\}   are defined in such a way that a given column can have several non-zero entries in it. After each application of    {   U  Î±   }      subscript  U  Î±     \{U_{\alpha}\}   , though, the column vector q must be renormalized so that it only contains zeros and ones. Equivalently, the multiply-add operations performed during component-wise matrix multiplication should be replaced by Boolean and-or operations, that is, so that one is working with a ring of characteristic 2 .  A well-known theorem states that, for each DFA, there is an equivalent NFA, and vice versa. This implies that the set of languages that can be recognized by DFA's and NFA's are the same; these are the regular languages . In the generalization to QFA's, the set of recognized languages will be different. Describing that set is one of the outstanding research problems in QFA theory.  Another generalization that should be immediately apparent is to use a stochastic matrix for the transition matrices, and a probability vector for the state; this gives a probabilistic finite automaton . The entries in the state vector must be real numbers, positive, and sum to one, in order for the state vector to be interpreted as a probability. The transition matrices must preserve this property: this is why they must be stochastic. Each state vector should be imagined as specifying a point in a simplex ; thus, this is a topological automaton, with the simplex being the manifold, and the stochastic matrices being linear automorphisms of the simplex onto itself. Since each transition is (essentially) independent of the previous (if we disregard the distinction between accepted and rejected languages), the PFA essentially becomes a kind of Markov chain .  By contrast, in a QFA, the manifold is complex projective space     â„‚   P  N       â„‚   superscript  P  N     \mathbb{C}P^{N}   , and the transition matrices are unitary matrices. Each point in    â„‚   P  N       â„‚   superscript  P  N     \mathbb{C}P^{N}   corresponds to a quantum-mechanical probability amplitude or pure state ; the unitary matrices can be thought of as governing the time evolution of the system (viz in the SchrÃ¶dinger picture ). The generalization from pure states to mixed states should be straightforward: A mixed state is simply a measure-theoretic  probability distribution on    â„‚   P  N       â„‚   superscript  P  N     \mathbb{C}P^{N}   .  A worthy point to contemplate is the distributions that result on the manifold during the input of a language. In order for an automaton to be 'efficient' in recognizing a language, that distribution should be 'as uniform as possible'. This need for uniformity is the underlying principle behind maximum entropy methods : these simply guarantee crisp, compact operation of the automaton. Put in other words, the machine learning methods used to train hidden Markov models generalize to QFA's as well: the Viterbi algorithm and the forward-backward algorithm generalize readily to the QFA.  Measure-once automata  Measure-once automata were introduced by Cris Moore and James P. Crutchfield . 1 They may be defined formally as follows.  As with an ordinary finite automaton , the quantum automaton is considered to have   N   N   N   possible internal states, represented in this case by an   N   N   N   -state qubit     |  Ïˆ  âŸ©     ket  Ïˆ    |\psi\rangle   . More precisely, the   N   N   N   -state qubit     |  Ïˆ  âŸ©   âˆˆ   â„‚   P  N         ket  Ïˆ     â„‚   superscript  P  N      |\psi\rangle\in\mathbb{C}P^{N}   is an element of   N   N   N   -dimensional complex projective space , carrying an inner product     âˆ¥  â‹…  âˆ¥     fragments  parallel-to  normal-â‹…  parallel-to    \|\cdot\|   that is the Fubiniâ€“Study metric .  The state transitions , transition matrixes or de Bruijn graphs are represented by a collection of    N  Ã—  N      N  N    N\times N    unitary matrixes     U  Î±     subscript  U  Î±    U_{\alpha}   , with one unitary matrix for each letter    Î±  âˆˆ  Î£      Î±  normal-Î£    \alpha\in\Sigma   . That is, given an input letter   Î±   Î±   \alpha   , the unitary matrix describes the transition of the automaton from its current state    |  Ïˆ  âŸ©     ket  Ïˆ    |\psi\rangle   to its next state    |   Ïˆ  â€²   âŸ©     ket   superscript  Ïˆ  normal-â€²     |\psi^{\prime}\rangle   :       |   Ïˆ  â€²   âŸ©   =    U  Î±    |  Ïˆ  âŸ©         ket   superscript  Ïˆ  normal-â€²       subscript  U  Î±    ket  Ïˆ      |\psi^{\prime}\rangle=U_{\alpha}|\psi\rangle     Thus, the triple    (   â„‚   P  N    ,  Î£  ,   {   U  Î±   |   Î±  âˆˆ  Î£   }   )       â„‚   superscript  P  N    normal-Î£   conditional-set   subscript  U  Î±     Î±  normal-Î£      (\mathbb{C}P^{N},\Sigma,\{U_{\alpha}|\alpha\in\Sigma\})   form a quantum semiautomaton .  The accept state of the automaton is given by an    N  Ã—  N      N  N    N\times N    projection matrix    P   P   P   , so that, given a   N   N   N   -dimensional quantum state    |  Ïˆ  âŸ©     ket  Ïˆ    |\psi\rangle   , the probability of    |  Ïˆ  âŸ©     ket  Ïˆ    |\psi\rangle   being in the accept state is       âŸ¨  Ïˆ  |  P  |  Ïˆ  âŸ©   =    âˆ¥   P   |  Ïˆ  âŸ©    âˆ¥   2        quantum-operator-product  Ïˆ  P  Ïˆ    superscript   norm    P   ket  Ïˆ     2     \langle\psi|P|\psi\rangle=\|P|\psi\rangle\|^{2}     The probability of the state machine accepting a given finite input string    Ïƒ  =   (   Ïƒ  0   ,   Ïƒ  1   ,  â‹¯  ,   Ïƒ  k   )       Ïƒ    subscript  Ïƒ  0    subscript  Ïƒ  1   normal-â‹¯   subscript  Ïƒ  k      \sigma=(\sigma_{0},\sigma_{1},\cdots,\sigma_{k})   is given by       Pr   (  Ïƒ  )    =    âˆ¥   P   U   Ïƒ  k    â‹¯   U   Ïƒ  1     U   Ïƒ  0     |  Ïˆ  âŸ©    âˆ¥   2        Pr  Ïƒ    superscript   norm    P   subscript  U   subscript  Ïƒ  k    normal-â‹¯   subscript  U   subscript  Ïƒ  1     subscript  U   subscript  Ïƒ  0     ket  Ïˆ     2     \operatorname{Pr}(\sigma)=\|PU_{\sigma_{k}}\cdots U_{\sigma_{1}}U_{\sigma_{0}}%
 |\psi\rangle\|^{2}     Here, the vector    |  Ïˆ  âŸ©     ket  Ïˆ    |\psi\rangle   is understood to represent the initial state of the automaton, that is, the state the automaton was in before it started accepting the string input. The empty string   âˆ…     \varnothing   is understood to be just the unit matrix, so that       Pr   (  âˆ…  )    =    âˆ¥   P   |  Ïˆ  âŸ©    âˆ¥   2        Pr     superscript   norm    P   ket  Ïˆ     2     \operatorname{Pr}(\varnothing)=\|P|\psi\rangle\|^{2}     is just the probability of the initial state being an accepted state.  Because the left-action of    U  Î±     subscript  U  Î±    U_{\alpha}   on    |  Ïˆ  âŸ©     ket  Ïˆ    |\psi\rangle   reverses the order of the letters in the string   Ïƒ   Ïƒ   \sigma   , it is not uncommon for QFA's to be defined using a right action on the Hermitian transpose states, simply in order to keep the order of the letters the same.  A regular language is accepted with probability   p   p   p   by a quantum finite automaton, if, for all sentences   Ïƒ   Ïƒ   \sigma   in the language, (and a given, fixed initial state    |  Ïˆ  âŸ©     ket  Ïˆ    |\psi\rangle   ), one has    p  <   Pr   (  Ïƒ  )        p   Pr  Ïƒ     p<\operatorname{Pr}(\sigma)   .  Example  Consider the classical deterministic finite automaton given by the state transition table         State Transition Table   Input State   align="center" 1   align="center" 0     S 1   S 1   S 2     S 2   S 2   S 1         State Diagram      The quantum state is a vector, in braâ€“ket notation       |  Ïˆ  âŸ©   =     a  1    |   S  1   âŸ©    +    a  2    |   S  2   âŸ©     =   [      a  1        a  2      ]          ket  Ïˆ        subscript  a  1    ket   subscript  S  1        subscript  a  2    ket   subscript  S  2              subscript  a  1      subscript  a  2        |\psi\rangle=a_{1}|S_{1}\rangle+a_{2}|S_{2}\rangle=\begin{bmatrix}a_{1}\\
 a_{2}\end{bmatrix}     with the complex numbers      a  1   ,   a  2       subscript  a  1    subscript  a  2     a_{1},a_{2}   normalized so that        [        a  1  *     a  2  *       ]    [      a  1        a  2      ]    =     a  1  *    a  1    +    a  2  *    a  2     =  1               subscript   superscript  a    1    subscript   superscript  a    2         subscript  a  1      subscript  a  2           superscript   subscript  a  1      subscript  a  1       superscript   subscript  a  2      subscript  a  2          1     \begin{bmatrix}a^{*}_{1}\;\;a^{*}_{2}\end{bmatrix}\begin{bmatrix}a_{1}\\
 a_{2}\end{bmatrix}=a_{1}^{*}a_{1}+a_{2}^{*}a_{2}=1     The unitary transition matrices are       U  0   =   [     0    1      1    0     ]        subscript  U  0     0  1    1  0      U_{0}=\begin{bmatrix}0&1\\
 1&0\end{bmatrix}     and       U  1   =   [     1    0      0    1     ]        subscript  U  1     1  0    0  1      U_{1}=\begin{bmatrix}1&0\\
 0&1\end{bmatrix}     Taking    S  1     subscript  S  1    S_{1}   to be the accept state, the projection matrix is      P  =   [     1    0      0    0     ]       P    1  0    0  0      P=\begin{bmatrix}1&0\\
 0&0\end{bmatrix}     As should be readily apparent, if the initial state is the pure state    |   S  1   âŸ©     ket   subscript  S  1     |S_{1}\rangle   or    |   S  2   âŸ©     ket   subscript  S  2     |S_{2}\rangle   , then the result of running the machine will be exactly identical to the classical deterministic finite state machine. In particular, there is a language accepted by this automaton with probability one, for these initial states, and it is identical to the regular language for the classical DFA, and is given by the regular expression :       (    1  *     (    01  *   0   )   *    )   *     superscript     superscript  1     superscript     superscript  01    0         (1^{*}(01^{*}0)^{*})^{*}\,\!     The non-classical behaviour occurs if both    a  1     subscript  a  1    a_{1}   and    a  2     subscript  a  2    a_{2}   are non-zero. More subtle behaviour occurs when the matrices    U  0     subscript  U  0    U_{0}   and    U  1     subscript  U  1    U_{1}   are not so simple; see, for example, the de Rham curve as an example of a quantum finite state machine acting on the set of all possible finite binary strings.  Measure-many automata  Measure-many automata were introduced by Kondacs and Watrous in 1997. 2 The general framework resembles that of the measure-once automaton, except that instead of there being one projection, at the end, there is a projection, or quantum measurement , performed after each letter is read. A formal definition follows.  The Hilbert space     â„‹  Q     subscript  â„‹  Q    \mathcal{H}_{Q}   is decomposed into three orthogonal subspaces       â„‹  Q   =    â„‹  accept   âŠ•   â„‹  reject   âŠ•   â„‹  non-halting         subscript  â„‹  Q    direct-sum   subscript  â„‹  accept    subscript  â„‹  reject    subscript  â„‹  non-halting      \mathcal{H}_{Q}=\mathcal{H}_{\mbox{accept}}\oplus\mathcal{H}_{\mbox{reject}}%
 \oplus\mathcal{H}_{\mbox{non-halting}}     In the literature, these orthogonal subspaces are usually formulated in terms of the set   Q   Q   Q   of orthogonal basis vectors for the Hilbert space    â„‹  Q     subscript  â„‹  Q    \mathcal{H}_{Q}   . This set of basis vectors is divided up into subsets     Q  acc   âŠ‚  Q       subscript  Q  acc   Q    Q_{\mbox{acc}}\subset Q   and     Q  rej   âŠ‚  Q       subscript  Q  rej   Q    Q_{\mbox{rej}}\subset Q   , such that       â„‹  accept   =   span   {    |  q  âŸ©   :    |  q  âŸ©   âˆˆ   Q  acc     }         subscript  â„‹  accept    span   normal-:   ket  q      ket  q    subscript  Q  acc        \mathcal{H}_{\mbox{accept}}=\operatorname{span}\{|q\rangle:|q\rangle\in Q_{%
 \mbox{acc}}\}     is the linear span of the basis vectors in the accept set. The reject space is defined analogously, and the remaining space is designated the non-halting subspace. There are three projection matrices,    P  acc     subscript  P  acc    P_{\mbox{acc}}   ,    P  rej     subscript  P  rej    P_{\mbox{rej}}   and    P  non     subscript  P  non    P_{\mbox{non}}   , each projecting to the respective subspace:       P  acc   :    â„‹  Q   â†’   â„‹  accept       normal-:    P  acc    normal-â†’   subscript  â„‹  Q    subscript  â„‹  accept      P\mbox{acc}:\mathcal{H}_{Q}\to\mathcal{H}_{\mbox{accept}}     and so on. The parsing of the input string proceeds as follows. Consider the automaton to be in a state    |  Ïˆ  âŸ©     ket  Ïˆ    |\psi\rangle   . After reading an input letter   Î±   Î±   \alpha   , the automaton will be in the state       |   Ïˆ  â€²   âŸ©   =    U  Î±    |  Ïˆ  âŸ©         ket   superscript  Ïˆ  normal-â€²       subscript  U  Î±    ket  Ïˆ      |\psi^{\prime}\rangle=U_{\alpha}|\psi\rangle     At this point, a measurement is performed on the state    |   Ïˆ  â€²   âŸ©     ket   superscript  Ïˆ  normal-â€²     |\psi^{\prime}\rangle   , using the projection operators   P   P   P   , at which time its wave-function collapses into one of the three subspaces    â„‹  accept     subscript  â„‹  accept    \mathcal{H}_{\mbox{accept}}   or    â„‹  reject     subscript  â„‹  reject    \mathcal{H}_{\mbox{reject}}   or    â„‹  non-halting     subscript  â„‹  non-halting    \mathcal{H}_{\mbox{non-halting}}   . The probability of collapse is given by        Pr  acc    (  Ïƒ  )    =    âˆ¥    P  acc    |   Ïˆ  â€²   âŸ©    âˆ¥   2         subscript  Pr  acc   Ïƒ    superscript   norm     subscript  P  acc    ket   superscript  Ïˆ  normal-â€²      2     \operatorname{Pr}_{\mbox{acc}}(\sigma)=\|P_{\mbox{acc}}|\psi^{\prime}\rangle\|%
 ^{2}     for the "accept" subspace, and analogously for the other two spaces.  If the wave function has collapsed to either the "accept" or "reject" subspaces, then further processing halts. Otherwise, processing continues, with the next letter read from the input, and applied to what must be an eigenstate of    P  non     subscript  P  non    P_{\mbox{non}}   . Processing continues until the whole string is read, or the machine halts. Often, additional symbols   Îº   Îº   \kappa   and $ are adjoined to the alphabet, to act as the left and right end-markers for the string.  In the literature, the meaure-many automaton is often denoted by the tuple    (  Q  ;  Î£  ;  Î´  ;   q  0   ;   Q  acc   ;   Q  rej   )     Q  normal-Î£  Î´   subscript  q  0    subscript  Q  acc    subscript  Q  rej     (Q;\Sigma;\delta;q_{0};Q_{\mbox{acc}};Q_{\mbox{rej}})   . Here,   Q   Q   Q   ,   Î£   normal-Î£   \Sigma   ,    Q  acc      Q  acc    Q\mbox{acc}   and    Q  rej      Q  rej    Q\mbox{rej}   are as defined above. The initial state is denoted by     |  Ïˆ  âŸ©   =   |   q  0   âŸ©        ket  Ïˆ    ket   subscript  q  0      |\psi\rangle=|q_{0}\rangle   . The unitary transformations are denoted by the map   Î´   Î´   \delta   ,      Î´  :    Q  Ã—  Î£  Ã—  Q   â†’  â„‚      normal-:  Î´   normal-â†’    Q  normal-Î£  Q   â„‚     \delta:Q\times\Sigma\times Q\to\mathbb{C}     so that        U  Î±    |   q  1   âŸ©    =    âˆ‘    q  2   âˆˆ  Q     Î´   (   q  1   ,  Î±  ,   q  2   )    |   q  2   âŸ©            subscript  U  Î±    ket   subscript  q  1       subscript      subscript  q  2   Q      Î´    subscript  q  1   Î±   subscript  q  2     ket   subscript  q  2        U_{\alpha}|q_{1}\rangle=\sum_{q_{2}\in Q}\delta(q_{1},\alpha,q_{2})|q_{2}\rangle     Geometric generalizations  The above constructions indicate how the concept of a quantum finite automaton can be generalized to arbitrary topological spaces . For example, one may take some ( N -dimensional) Riemann symmetric space to take the place of    â„‚   P  N       â„‚   superscript  P  N     \mathbb{C}P^{N}   . In place of the unitary matrices, one uses the isometries of the Riemannian manifold, or, more generally, some set of open functions appropriate for the given topological space. The initial state may be taken to be a point in the space. The set of accept states can be taken to be some arbitrary subset of the topological space. One then says that a formal language is accepted by this topological automaton if the point, after iteration by the homeomorphisms, intersects the accept set. But, of course, this is nothing more than the standard definition of an M-automaton . The behaviour of topological automata is studied in the field of topological dynamics .  The quantum automaton differs from the topological automaton in that, instead of having a binary result (is the iterated point in, or not in, the final set?), one has a probability. The quantum probability is the (square of) the initial state projected onto some final state P ; that is     â„™  ð•£   =    |   âŸ¨  P  |  Ïˆ  âŸ©   |   2         â„™  ð•£    superscript     inner-product  P  Ïˆ    2     \mathbb{Pr}=|\langle P|\psi\rangle|^{2}   . But this probability amplitude is just a very simple function of the distance between the point    |  P  âŸ©     ket  P    |P\rangle   and the point    |  Ïˆ  âŸ©     ket  Ïˆ    |\psi\rangle   in    â„‚   P  N       â„‚   superscript  P  N     \mathbb{C}P^{N}   , under the distance metric given by the Fubiniâ€“Study metric . To recap, the quantum probability of a language being accepted can be interpreted as a metric, with the probability of accept being unity, if the metric distance between the initial and final states is zero, and otherwise the probability of accept is less than one, if the metric distance is non-zero. Thus, it follows that the quantum finite automaton is just a special case of a geometric automaton or a metric automaton , where    â„‚   P  N       â„‚   superscript  P  N     \mathbb{C}P^{N}   is generalized to some metric space , and the probability measure is replaced by a simple function of the metric on that space.  See also   Quantum Markov chain   References      (Provides an intro to quantum Markov chains.)  Alex Brodsky, Nicholas Pippenger, "Characterization of 1-way Quantum Finite Automata" , SIAM Journal on Computing  31 (2002) pp 1456â€“1478.  Vincent D. Blondel, Emmanual Jeandel, Pascal Koiran and Natacha Portier, "Decidable and Undecidable Problems about Quantum Automata", SIAM Journal on Computing  34 (2005) pp 1464â€“1473.   "  Category:Quantum information theory  Category:Automata theory     C. Moore, J. Crutchfield, "Quantum automata and quantum grammars", Theoretical Computer Science , 237 (2000) pp 275-306. â†©  â†©     