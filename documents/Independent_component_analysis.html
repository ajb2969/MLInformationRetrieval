<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="1841">Independent component analysis</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>Independent component analysis</h1>
<hr/>

<p>In <a href="signal_processing" title="wikilink">signal processing</a>, <strong>independent component analysis</strong> (<strong>ICA</strong>) is a computational method for separating a <a href="multivariate_statistics" title="wikilink">multivariate</a> signal into additive subcomponents. This is done by assuming that the subcomponents are non-Gaussian signals and that they are <a href="Statistical_independence" title="wikilink">statistically independent</a> from each other. ICA is a special case of <a href="blind_source_separation" title="wikilink">blind source separation</a>. A common example application is the "<a href="cocktail_party_problem" title="wikilink">cocktail party problem</a>" of listening in on one person's speech in a noisy room.</p>
<h2 id="introduction">Introduction</h2>

<p>Independent Component Analysis attempts to decompose a multivariate signal into independent non-gaussian signals. As an example, sound is usually a signal that is composed of the numerical addition, at each time t, of signals from several sources. The question then is whether it is possible to separate these contributing sources from the observed total signal. When the statistical independence assumption is correct, blind ICA separation of a mixed signal gives very good results. It is also used for signals that are not supposed to be generated by a mixing for analysis purposes. A simple application of ICA is the "<a href="cocktail_party_problem" title="wikilink">cocktail party problem</a>", where the underlying speech signals are separated from a sample data consisting of people talking simultaneously in a room. Usually the problem is simplified by assuming no time delays or echoes. An important note to consider is that if <em>N</em> sources are present, at least <em>N</em> observations (e.g. microphones) are needed to recover the original signals. This constitutes the square case (<em>J</em> = <em>D</em>, where <em>D</em> is the input dimension of the data and <em>J</em> is the dimension of the model). Other cases of underdetermined (<em>J</em> &gt; <em>D</em>) and overdetermined (<em>J</em> <a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a></p>
<h2 id="defining-component-independence">Defining component independence</h2>

<p>ICA finds the independent components (also called factors, latent variables or sources) by maximizing the statistical independence of the estimated components. We may choose one of many ways to define independence, and this choice governs the form of the ICA algorithm. The two broadest definitions of independence for ICA are</p>
<ol>
<li>Minimization of mutual information</li>
<li>Maximization of non-Gaussianity</li>
</ol>

<p>The Minimization-of-<a href="Mutual_information" title="wikilink">Mutual information</a> (MMI) family of ICA algorithms uses measures like <a href="Kullback–Leibler_divergence" title="wikilink">Kullback-Leibler Divergence</a> and <a href="Principle_of_maximum_entropy" title="wikilink">maximum entropy</a>. The non-Gaussianity family of ICA algorithms, motivated by the <a href="central_limit_theorem" title="wikilink">central limit theorem</a>, uses <a class="uri" href="kurtosis" title="wikilink">kurtosis</a> and <a class="uri" href="negentropy" title="wikilink">negentropy</a>.</p>

<p>Typical algorithms for ICA use centering (subtract the mean to create a zero mean signal), <a href="Whitening_transformation" title="wikilink">whitening</a> (usually with the <a href="eigenvalue_decomposition" title="wikilink">eigenvalue decomposition</a>), and <a href="dimensionality_reduction" title="wikilink">dimensionality reduction</a> as preprocessing steps in order to simplify and reduce the complexity of the problem for the actual iterative algorithm. Whitening and <a href="dimension_reduction" title="wikilink">dimension reduction</a> can be achieved with <a href="principal_component_analysis" title="wikilink">principal component analysis</a> or <a href="singular_value_decomposition" title="wikilink">singular value decomposition</a>. Whitening ensures that all dimensions are treated equally <em>a priori</em> before the algorithm is run. Well-known algorithms for ICA include <a class="uri" href="infomax" title="wikilink">infomax</a>, <a class="uri" href="FastICA" title="wikilink">FastICA</a>, and JADE, but there are many others.</p>

<p>In general, ICA cannot identify the actual number of source signals, a uniquely correct ordering of the source signals, nor the proper scaling (including sign) of the source signals.</p>

<p>ICA is important to <a href="blind_signal_separation" title="wikilink">blind signal separation</a> and has many practical applications. It is closely related to (or even a special case of) the search for a <a href="factorial_code" title="wikilink">factorial code</a> of the data, i.e., a new vector-valued representation of each data vector such that it gets uniquely encoded by the resulting code vector (loss-free coding), but the code components are statistically independent.</p>
<h2 id="mathematical-definitions">Mathematical definitions</h2>

<p>Linear independent component analysis can be divided into noiseless and noisy cases, where noiseless ICA is a special case of noisy ICA. Nonlinear ICA should be considered as a separate case.</p>
<h3 id="general-definition">General definition</h3>

<p>The data are represented by the <a href="random_vector" title="wikilink">random vector</a>
<math display="inline" id="Independent_component_analysis:0">
<semantics>
<mrow>
<mi>x</mi>
<mo>=</mo>
<msup>
<mrow>
<mo stretchy="false">(</mo>
<msub>
<mi>x</mi>
<mn>1</mn>
</msub>
<mo>,</mo>
<mi mathvariant="normal">…</mi>
<mo>,</mo>
<msub>
<mi>x</mi>
<mi>m</mi>
</msub>
<mo stretchy="false">)</mo>
</mrow>
<mi>T</mi>
</msup>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<eq></eq>
<ci>x</ci>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<vector>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>x</ci>
<cn type="integer">1</cn>
</apply>
<ci>normal-…</ci>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>x</ci>
<ci>m</ci>
</apply>
</vector>
<ci>T</ci>
</apply>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   x=(x_{1},\ldots,x_{m})^{T}
  </annotation>
</semantics>
</math>

 and the components as the random vector 

<math display="inline" id="Independent_component_analysis:1">
<semantics>
<mrow>
<mrow>
<mi>s</mi>
<mo>=</mo>
<msup>
<mrow>
<mo stretchy="false">(</mo>
<msub>
<mi>s</mi>
<mn>1</mn>
</msub>
<mo>,</mo>
<mi mathvariant="normal">…</mi>
<mo>,</mo>
<msub>
<mi>s</mi>
<mi>n</mi>
</msub>
<mo stretchy="false">)</mo>
</mrow>
<mi>T</mi>
</msup>
</mrow>
<mo>.</mo>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<eq></eq>
<ci>s</ci>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<vector>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>s</ci>
<cn type="integer">1</cn>
</apply>
<ci>normal-…</ci>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>s</ci>
<ci>n</ci>
</apply>
</vector>
<ci>T</ci>
</apply>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   s=(s_{1},\ldots,s_{n})^{T}.
  </annotation>
</semantics>
</math>

 The task is to transform the observed data 

<math display="inline" id="Independent_component_analysis:2">
<semantics>
<mrow>
<mi>x</mi>
<mo>,</mo>
</mrow>
<annotation-xml encoding="MathML-Content">
<ci>x</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   x,
  </annotation>
</semantics>
</math>

 using a linear static transformation <em>W</em> as 

<math display="inline" id="Independent_component_analysis:3">
<semantics>
<mrow>
<mi>s</mi>
<mo>=</mo>
<mrow>
<mi>W</mi>
<mpadded width="+1.7pt">
<mi>x</mi>
</mpadded>
</mrow>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<eq></eq>
<ci>s</ci>
<apply>
<times></times>
<ci>W</ci>
<ci>x</ci>
</apply>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   s=Wx\,
  </annotation>
</semantics>
</math>

 into maximally independent components 

<math display="inline" id="Independent_component_analysis:4">
<semantics>
<mi>s</mi>
<annotation-xml encoding="MathML-Content">
<ci>s</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   s
  </annotation>
</semantics>
</math>

 measured by some function 

<math display="inline" id="Independent_component_analysis:5">
<semantics>
<mrow>
<mi>F</mi>
<mrow>
<mo stretchy="false">(</mo>
<msub>
<mi>s</mi>
<mn>1</mn>
</msub>
<mo>,</mo>
<mi mathvariant="normal">…</mi>
<mo>,</mo>
<msub>
<mi>s</mi>
<mi>n</mi>
</msub>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<times></times>
<ci>F</ci>
<vector>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>s</ci>
<cn type="integer">1</cn>
</apply>
<ci>normal-…</ci>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>s</ci>
<ci>n</ci>
</apply>
</vector>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   F(s_{1},\ldots,s_{n})
  </annotation>
</semantics>
</math>

 of independence.</p>
<h3 id="generative-model">Generative model</h3>
<h4 id="linear-noiseless-ica">Linear noiseless ICA</h4>

<p>The components 

<math display="inline" id="Independent_component_analysis:6">
<semantics>
<msub>
<mi>x</mi>
<mi>i</mi>
</msub>
<annotation-xml encoding="MathML-Content">
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>x</ci>
<ci>i</ci>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   x_{i}
  </annotation>
</semantics>
</math>

 of the observed random vector 

<math display="inline" id="Independent_component_analysis:7">
<semantics>
<mrow>
<mi>x</mi>
<mo>=</mo>
<msup>
<mrow>
<mo stretchy="false">(</mo>
<msub>
<mi>x</mi>
<mn>1</mn>
</msub>
<mo>,</mo>
<mi mathvariant="normal">…</mi>
<mo>,</mo>
<msub>
<mi>x</mi>
<mi>m</mi>
</msub>
<mo stretchy="false">)</mo>
</mrow>
<mi>T</mi>
</msup>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<eq></eq>
<ci>x</ci>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<vector>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>x</ci>
<cn type="integer">1</cn>
</apply>
<ci>normal-…</ci>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>x</ci>
<ci>m</ci>
</apply>
</vector>
<ci>T</ci>
</apply>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   x=(x_{1},\ldots,x_{m})^{T}
  </annotation>
</semantics>
</math>

 are generated as a sum of the independent components 

<math display="inline" id="Independent_component_analysis:8">
<semantics>
<msub>
<mi>s</mi>
<mi>k</mi>
</msub>
<annotation-xml encoding="MathML-Content">
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>s</ci>
<ci>k</ci>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   s_{k}
  </annotation>
</semantics>
</math>

, 

<math display="inline" id="Independent_component_analysis:9">
<semantics>
<mrow>
<mi>k</mi>
<mo>=</mo>
<mrow>
<mn>1</mn>
<mo>,</mo>
<mi mathvariant="normal">…</mi>
<mo>,</mo>
<mi>n</mi>
</mrow>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<eq></eq>
<ci>k</ci>
<list>
<cn type="integer">1</cn>
<ci>normal-…</ci>
<ci>n</ci>
</list>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   k=1,\ldots,n
  </annotation>
</semantics>
</math>

:</p>

<p>
<math display="inline" id="Independent_component_analysis:10">
<semantics>
<mrow>
<msub>
<mi>x</mi>
<mi>i</mi>
</msub>
<mo>=</mo>
<mrow>
<mrow>
<msub>
<mi>a</mi>
<mrow>
<mi>i</mi>
<mo>,</mo>
<mn>1</mn>
</mrow>
</msub>
<msub>
<mi>s</mi>
<mn>1</mn>
</msub>
</mrow>
<mo>+</mo>
<mi mathvariant="normal">⋯</mi>
<mo>+</mo>
<mrow>
<msub>
<mi>a</mi>
<mrow>
<mi>i</mi>
<mo>,</mo>
<mi>k</mi>
</mrow>
</msub>
<msub>
<mi>s</mi>
<mi>k</mi>
</msub>
</mrow>
<mo>+</mo>
<mi mathvariant="normal">⋯</mi>
<mo>+</mo>
<mrow>
<msub>
<mi>a</mi>
<mrow>
<mi>i</mi>
<mo>,</mo>
<mi>n</mi>
</mrow>
</msub>
<msub>
<mi>s</mi>
<mi>n</mi>
</msub>
</mrow>
</mrow>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<eq></eq>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>x</ci>
<ci>i</ci>
</apply>
<apply>
<plus></plus>
<apply>
<times></times>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>a</ci>
<list>
<ci>i</ci>
<cn type="integer">1</cn>
</list>
</apply>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>s</ci>
<cn type="integer">1</cn>
</apply>
</apply>
<ci>normal-⋯</ci>
<apply>
<times></times>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>a</ci>
<list>
<ci>i</ci>
<ci>k</ci>
</list>
</apply>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>s</ci>
<ci>k</ci>
</apply>
</apply>
<ci>normal-⋯</ci>
<apply>
<times></times>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>a</ci>
<list>
<ci>i</ci>
<ci>n</ci>
</list>
</apply>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>s</ci>
<ci>n</ci>
</apply>
</apply>
</apply>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   x_{i}=a_{i,1}s_{1}+\cdots+a_{i,k}s_{k}+\cdots+a_{i,n}s_{n}
  </annotation>
</semantics>
</math>
</p>

<p>weighted by the mixing weights 

<math display="inline" id="Independent_component_analysis:11">
<semantics>
<msub>
<mi>a</mi>
<mrow>
<mi>i</mi>
<mo>,</mo>
<mi>k</mi>
</mrow>
</msub>
<annotation-xml encoding="MathML-Content">
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>a</ci>
<list>
<ci>i</ci>
<ci>k</ci>
</list>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   a_{i,k}
  </annotation>
</semantics>
</math>

.</p>

<p>The same generative model can be written in vectorial form as 

<math display="inline" id="Independent_component_analysis:12">
<semantics>
<mrow>
<mi>x</mi>
<mo>=</mo>
<mrow>
<msubsup>
<mo largeop="true" symmetric="true">∑</mo>
<mrow>
<mi>k</mi>
<mo>=</mo>
<mn>1</mn>
</mrow>
<mi>n</mi>
</msubsup>
<mrow>
<msub>
<mi>s</mi>
<mi>k</mi>
</msub>
<msub>
<mi>a</mi>
<mi>k</mi>
</msub>
</mrow>
</mrow>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<eq></eq>
<ci>x</ci>
<apply>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<sum></sum>
<apply>
<eq></eq>
<ci>k</ci>
<cn type="integer">1</cn>
</apply>
</apply>
<ci>n</ci>
</apply>
<apply>
<times></times>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>s</ci>
<ci>k</ci>
</apply>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>a</ci>
<ci>k</ci>
</apply>
</apply>
</apply>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   x=\sum_{k=1}^{n}s_{k}a_{k}
  </annotation>
</semantics>
</math>

, where the observed random vector 

<math display="inline" id="Independent_component_analysis:13">
<semantics>
<mi>x</mi>
<annotation-xml encoding="MathML-Content">
<ci>x</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   x
  </annotation>
</semantics>
</math>

 is represented by the basis vectors 

<math display="inline" id="Independent_component_analysis:14">
<semantics>
<mrow>
<msub>
<mi>a</mi>
<mi>k</mi>
</msub>
<mo>=</mo>
<msup>
<mrow>
<mo stretchy="false">(</mo>
<msub>
<mi>a</mi>
<mrow>
<mn>1</mn>
<mo>,</mo>
<mi>k</mi>
</mrow>
</msub>
<mo>,</mo>
<mi mathvariant="normal">…</mi>
<mo>,</mo>
<msub>
<mi>a</mi>
<mrow>
<mi>m</mi>
<mo>,</mo>
<mi>k</mi>
</mrow>
</msub>
<mo stretchy="false">)</mo>
</mrow>
<mi>T</mi>
</msup>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<eq></eq>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>a</ci>
<ci>k</ci>
</apply>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<vector>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>a</ci>
<list>
<cn type="integer">1</cn>
<ci>k</ci>
</list>
</apply>
<ci>normal-…</ci>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>a</ci>
<list>
<ci>m</ci>
<ci>k</ci>
</list>
</apply>
</vector>
<ci>T</ci>
</apply>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   a_{k}=(a_{1,k},\ldots,a_{m,k})^{T}
  </annotation>
</semantics>
</math>

. The basis vectors 

<math display="inline" id="Independent_component_analysis:15">
<semantics>
<msub>
<mi>a</mi>
<mi>k</mi>
</msub>
<annotation-xml encoding="MathML-Content">
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>a</ci>
<ci>k</ci>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   a_{k}
  </annotation>
</semantics>
</math>

 form the columns of the mixing matrix 

<math display="inline" id="Independent_component_analysis:16">
<semantics>
<mrow>
<mi>A</mi>
<mo>=</mo>
<mrow>
<mo stretchy="false">(</mo>
<msub>
<mi>a</mi>
<mn>1</mn>
</msub>
<mo>,</mo>
<mi mathvariant="normal">…</mi>
<mo>,</mo>
<msub>
<mi>a</mi>
<mi>n</mi>
</msub>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<eq></eq>
<ci>A</ci>
<vector>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>a</ci>
<cn type="integer">1</cn>
</apply>
<ci>normal-…</ci>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>a</ci>
<ci>n</ci>
</apply>
</vector>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   A=(a_{1},\ldots,a_{n})
  </annotation>
</semantics>
</math>

 and the generative formula can be written as 

<math display="inline" id="Independent_component_analysis:17">
<semantics>
<mrow>
<mi>x</mi>
<mo>=</mo>
<mrow>
<mi>A</mi>
<mi>s</mi>
</mrow>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<eq></eq>
<ci>x</ci>
<apply>
<times></times>
<ci>A</ci>
<ci>s</ci>
</apply>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   x=As
  </annotation>
</semantics>
</math>

, where 

<math display="inline" id="Independent_component_analysis:18">
<semantics>
<mrow>
<mi>s</mi>
<mo>=</mo>
<msup>
<mrow>
<mo stretchy="false">(</mo>
<msub>
<mi>s</mi>
<mn>1</mn>
</msub>
<mo>,</mo>
<mi mathvariant="normal">…</mi>
<mo>,</mo>
<msub>
<mi>s</mi>
<mi>n</mi>
</msub>
<mo stretchy="false">)</mo>
</mrow>
<mi>T</mi>
</msup>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<eq></eq>
<ci>s</ci>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<vector>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>s</ci>
<cn type="integer">1</cn>
</apply>
<ci>normal-…</ci>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>s</ci>
<ci>n</ci>
</apply>
</vector>
<ci>T</ci>
</apply>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   s=(s_{1},\ldots,s_{n})^{T}
  </annotation>
</semantics>
</math>

.</p>

<p>Given the model and realizations (samples) 

<math display="inline" id="Independent_component_analysis:19">
<semantics>
<mrow>
<msub>
<mi>x</mi>
<mn>1</mn>
</msub>
<mo>,</mo>
<mi mathvariant="normal">…</mi>
<mo>,</mo>
<msub>
<mi>x</mi>
<mi>N</mi>
</msub>
</mrow>
<annotation-xml encoding="MathML-Content">
<list>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>x</ci>
<cn type="integer">1</cn>
</apply>
<ci>normal-…</ci>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>x</ci>
<ci>N</ci>
</apply>
</list>
</annotation-xml>
<annotation encoding="application/x-tex">
   x_{1},\ldots,x_{N}
  </annotation>
</semantics>
</math>

 of the random vector 

<math display="inline" id="Independent_component_analysis:20">
<semantics>
<mi>x</mi>
<annotation-xml encoding="MathML-Content">
<ci>x</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   x
  </annotation>
</semantics>
</math>

, the task is to estimate both the mixing matrix 

<math display="inline" id="Independent_component_analysis:21">
<semantics>
<mi>A</mi>
<annotation-xml encoding="MathML-Content">
<ci>A</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   A
  </annotation>
</semantics>
</math>

 and the sources 

<math display="inline" id="Independent_component_analysis:22">
<semantics>
<mi>s</mi>
<annotation-xml encoding="MathML-Content">
<ci>s</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   s
  </annotation>
</semantics>
</math>

. This is done by adaptively calculating the 

<math display="inline" id="Independent_component_analysis:23">
<semantics>
<mi>w</mi>
<annotation-xml encoding="MathML-Content">
<ci>w</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   w
  </annotation>
</semantics>
</math>

 vectors and setting up a cost function which either maximizes the nongaussianity of the calculated 

<math display="inline" id="Independent_component_analysis:24">
<semantics>
<mrow>
<msub>
<mi>s</mi>
<mi>k</mi>
</msub>
<mo>=</mo>
<mrow>
<mo stretchy="false">(</mo>
<mrow>
<msup>
<mi>w</mi>
<mi>T</mi>
</msup>
<mo>*</mo>
<mi>x</mi>
</mrow>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<eq></eq>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>s</ci>
<ci>k</ci>
</apply>
<apply>
<times></times>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<ci>w</ci>
<ci>T</ci>
</apply>
<ci>x</ci>
</apply>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   s_{k}=(w^{T}*x)
  </annotation>
</semantics>
</math>

 or minimizes the mutual information. In some cases, a priori knowledge of the probability distributions of the sources can be used in the cost function.</p>

<p>The original sources 

<math display="inline" id="Independent_component_analysis:25">
<semantics>
<mi>s</mi>
<annotation-xml encoding="MathML-Content">
<ci>s</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   s
  </annotation>
</semantics>
</math>

 can be recovered by multiplying the observed signals 

<math display="inline" id="Independent_component_analysis:26">
<semantics>
<mi>x</mi>
<annotation-xml encoding="MathML-Content">
<ci>x</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   x
  </annotation>
</semantics>
</math>

 with the inverse of the mixing matrix 

<math display="inline" id="Independent_component_analysis:27">
<semantics>
<mrow>
<mi>W</mi>
<mo>=</mo>
<msup>
<mi>A</mi>
<mrow>
<mo>-</mo>
<mn>1</mn>
</mrow>
</msup>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<eq></eq>
<ci>W</ci>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<ci>A</ci>
<apply>
<minus></minus>
<cn type="integer">1</cn>
</apply>
</apply>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   W=A^{-1}
  </annotation>
</semantics>
</math>

, also known as the unmixing matrix. Here it is assumed that the mixing matrix is square (

<math display="inline" id="Independent_component_analysis:28">
<semantics>
<mrow>
<mi>n</mi>
<mo>=</mo>
<mi>m</mi>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<eq></eq>
<ci>n</ci>
<ci>m</ci>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   n=m
  </annotation>
</semantics>
</math>

). If the number of basis vectors is greater than the dimensionality of the observed vectors, 

<math display="inline" id="Independent_component_analysis:29">
<semantics>
<mrow>
<mi>n</mi>
<mo>&gt;</mo>
<mi>m</mi>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<gt></gt>
<ci>n</ci>
<ci>m</ci>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   n&gt;m
  </annotation>
</semantics>
</math>

, the task is overcomplete but is still solvable with the <a href="pseudo_inverse" title="wikilink">pseudo inverse</a>.</p>
<h4 id="linear-noisy-ica">Linear noisy ICA</h4>

<p>With the added assumption of zero-mean and uncorrelated Gaussian noise 

<math display="inline" id="Independent_component_analysis:30">
<semantics>
<mrow>
<mi>n</mi>
<mo>∼</mo>
<mrow>
<mi>N</mi>
<mrow>
<mo stretchy="false">(</mo>
<mn>0</mn>
<mo>,</mo>
<mrow>
<mo>diag</mo>
<mrow>
<mo stretchy="false">(</mo>
<mi mathvariant="normal">Σ</mi>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<csymbol cd="latexml">similar-to</csymbol>
<ci>n</ci>
<apply>
<times></times>
<ci>N</ci>
<interval closure="open">
<cn type="integer">0</cn>
<apply>
<ci>diag</ci>
<ci>normal-Σ</ci>
</apply>
</interval>
</apply>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   n\sim N(0,\operatorname{diag}(\Sigma))
  </annotation>
</semantics>
</math>

, the ICA model takes the form 

<math display="inline" id="Independent_component_analysis:31">
<semantics>
<mrow>
<mi>x</mi>
<mo>=</mo>
<mrow>
<mrow>
<mi>A</mi>
<mi>s</mi>
</mrow>
<mo>+</mo>
<mi>n</mi>
</mrow>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<eq></eq>
<ci>x</ci>
<apply>
<plus></plus>
<apply>
<times></times>
<ci>A</ci>
<ci>s</ci>
</apply>
<ci>n</ci>
</apply>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   x=As+n
  </annotation>
</semantics>
</math>

.</p>
<h4 id="nonlinear-ica">Nonlinear ICA</h4>

<p>The mixing of the sources does not need to be linear. Using a nonlinear mixing function 

<math display="inline" id="Independent_component_analysis:32">
<semantics>
<mrow>
<mi>f</mi>
<mrow>
<mo stretchy="false">(</mo>
<mo>⋅</mo>
<mo stretchy="false">|</mo>
<mi>θ</mi>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
<annotation-xml encoding="MathML-Content">
<cerror>
<csymbol cd="ambiguous">fragments</csymbol>
<csymbol cd="unknown">f</csymbol>
<cerror>
<csymbol cd="ambiguous">fragments</csymbol>
<ci>normal-(</ci>
<ci>normal-⋅</ci>
<ci>normal-|</ci>
<csymbol cd="unknown">θ</csymbol>
<ci>normal-)</ci>
</cerror>
</cerror>
</annotation-xml>
<annotation encoding="application/x-tex">
   f(\cdot|\theta)
  </annotation>
</semantics>
</math>

 with parameters 

<math display="inline" id="Independent_component_analysis:33">
<semantics>
<mi>θ</mi>
<annotation-xml encoding="MathML-Content">
<ci>θ</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   \theta
  </annotation>
</semantics>
</math>

 the <a href="nonlinear_ICA" title="wikilink">nonlinear ICA</a> model is 

<math display="inline" id="Independent_component_analysis:34">
<semantics>
<mrow>
<mi>x</mi>
<mo>=</mo>
<mi>f</mi>
<mrow>
<mo stretchy="false">(</mo>
<mi>s</mi>
<mo stretchy="false">|</mo>
<mi>θ</mi>
<mo stretchy="false">)</mo>
</mrow>
<mo>+</mo>
<mi>n</mi>
</mrow>
<annotation-xml encoding="MathML-Content">
<cerror>
<csymbol cd="ambiguous">fragments</csymbol>
<csymbol cd="unknown">x</csymbol>
<eq></eq>
<csymbol cd="unknown">f</csymbol>
<cerror>
<csymbol cd="ambiguous">fragments</csymbol>
<ci>normal-(</ci>
<csymbol cd="unknown">s</csymbol>
<ci>normal-|</ci>
<csymbol cd="unknown">θ</csymbol>
<ci>normal-)</ci>
</cerror>
<plus></plus>
<csymbol cd="unknown">n</csymbol>
</cerror>
</annotation-xml>
<annotation encoding="application/x-tex">
   x=f(s|\theta)+n
  </annotation>
</semantics>
</math>

.</p>
<h3 id="identifiability">Identifiability</h3>

<p>The independent components are identifiable up to a permutation and scaling of the sources. This identifiability requires that:</p>
<ul>
<li>At most one of the sources 

<math display="inline" id="Independent_component_analysis:35">
<semantics>
<msub>
<mi>s</mi>
<mi>k</mi>
</msub>
<annotation-xml encoding="MathML-Content">
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>s</ci>
<ci>k</ci>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   s_{k}
  </annotation>
</semantics>
</math>

 is Gaussian,</li>
<li>The number of observed mixtures, 

<math display="inline" id="Independent_component_analysis:36">
<semantics>
<mi>m</mi>
<annotation-xml encoding="MathML-Content">
<ci>m</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   m
  </annotation>
</semantics>
</math>

, must be at least as large as the number of estimated components 

<math display="inline" id="Independent_component_analysis:37">
<semantics>
<mi>n</mi>
<annotation-xml encoding="MathML-Content">
<ci>n</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   n
  </annotation>
</semantics>
</math>
<math display="block" id="Independent_component_analysis:38">
<semantics>
<mrow>
<mi>m</mi>
<mo>≥</mo>
<mi>n</mi>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<geq></geq>
<ci>m</ci>
<ci>n</ci>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   m\geq n
  </annotation>
</semantics>
</math>

. It is equivalent to say that the mixing matrix 

<math display="inline" id="Independent_component_analysis:39">
<semantics>
<mi>A</mi>
<annotation-xml encoding="MathML-Content">
<ci>A</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   A
  </annotation>
</semantics>
</math>

 must be of full <a href="rank_(linear_algebra)" title="wikilink">rank</a> for its inverse to exist.</li>
</ul>
<h2 id="binary-independent-component-analysis">Binary independent component analysis</h2>

<p>A special variant of ICA is <strong>Binary ICA</strong> in which both signal sources and monitors are in binary form and observations from monitors are disjunctive mixtures of binary independent sources. The problem was shown to have applications in many domains including <a href="medical_diagnosis" title="wikilink">medical diagnosis</a>, <a href="multi-cluster_assignment" title="wikilink">multi-cluster assignment</a>, <a href="network_tomography" title="wikilink">network tomography</a> and <a href="internet_resource_management" title="wikilink">internet resource management</a>.</p>

<p>Let 

<math display="inline" id="Independent_component_analysis:40">
<semantics>
<mrow>
<msub>
<mi>x</mi>
<mn>1</mn>
</msub>
<mo>,</mo>
<msub>
<mi>x</mi>
<mn>2</mn>
</msub>
<mo>,</mo>
<mi mathvariant="normal">…</mi>
<mo>,</mo>
<msub>
<mi>x</mi>
<mi>m</mi>
</msub>
</mrow>
<annotation-xml encoding="MathML-Content">
<list>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>x</ci>
<cn type="integer">1</cn>
</apply>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>x</ci>
<cn type="integer">2</cn>
</apply>
<ci>normal-…</ci>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>x</ci>
<ci>m</ci>
</apply>
</list>
</annotation-xml>
<annotation encoding="application/x-tex">
   {x_{1},x_{2},\ldots,x_{m}}
  </annotation>
</semantics>
</math>

 be the set of binary variables from 

<math display="inline" id="Independent_component_analysis:41">
<semantics>
<mi>m</mi>
<annotation-xml encoding="MathML-Content">
<ci>m</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   m
  </annotation>
</semantics>
</math>

 monitors and 

<math display="inline" id="Independent_component_analysis:42">
<semantics>
<mrow>
<msub>
<mi>y</mi>
<mn>1</mn>
</msub>
<mo>,</mo>
<msub>
<mi>y</mi>
<mn>2</mn>
</msub>
<mo>,</mo>
<mi mathvariant="normal">…</mi>
<mo>,</mo>
<msub>
<mi>y</mi>
<mi>n</mi>
</msub>
</mrow>
<annotation-xml encoding="MathML-Content">
<list>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>y</ci>
<cn type="integer">1</cn>
</apply>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>y</ci>
<cn type="integer">2</cn>
</apply>
<ci>normal-…</ci>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>y</ci>
<ci>n</ci>
</apply>
</list>
</annotation-xml>
<annotation encoding="application/x-tex">
   {y_{1},y_{2},\ldots,y_{n}}
  </annotation>
</semantics>
</math>

 be the set of binary variables from 

<math display="inline" id="Independent_component_analysis:43">
<semantics>
<mi>n</mi>
<annotation-xml encoding="MathML-Content">
<ci>n</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   n
  </annotation>
</semantics>
</math>

 sources. Source-monitor connections are represented by the (unknown) mixing matrix 

<math display="inline" id="Independent_component_analysis:44">
<semantics>
<mi>G</mi>
<annotation-xml encoding="MathML-Content">
<ci>G</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   G
  </annotation>
</semantics>
</math>

, where 

<math display="inline" id="Independent_component_analysis:45">
<semantics>
<mrow>
<msub>
<mi>g</mi>
<mrow>
<mi>i</mi>
<mi>j</mi>
</mrow>
</msub>
<mo>=</mo>
<mn>1</mn>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<eq></eq>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>g</ci>
<apply>
<times></times>
<ci>i</ci>
<ci>j</ci>
</apply>
</apply>
<cn type="integer">1</cn>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   g_{ij}=1
  </annotation>
</semantics>
</math>

 indicates that signal from the <em>i</em>-th source can be observed by the <em>j</em>-th monitor. The system works as follows: at any time, if a source 

<math display="inline" id="Independent_component_analysis:46">
<semantics>
<mi>i</mi>
<annotation-xml encoding="MathML-Content">
<ci>i</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   i
  </annotation>
</semantics>
</math>

 is active (

<math display="inline" id="Independent_component_analysis:47">
<semantics>
<mrow>
<msub>
<mi>y</mi>
<mi>i</mi>
</msub>
<mo>=</mo>
<mn>1</mn>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<eq></eq>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>y</ci>
<ci>i</ci>
</apply>
<cn type="integer">1</cn>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   y_{i}=1
  </annotation>
</semantics>
</math>

) and it is connected to the monitor 

<math display="inline" id="Independent_component_analysis:48">
<semantics>
<mi>j</mi>
<annotation-xml encoding="MathML-Content">
<ci>j</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   j
  </annotation>
</semantics>
</math>

 (

<math display="inline" id="Independent_component_analysis:49">
<semantics>
<mrow>
<msub>
<mi>g</mi>
<mrow>
<mi>i</mi>
<mi>j</mi>
</mrow>
</msub>
<mo>=</mo>
<mn>1</mn>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<eq></eq>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>g</ci>
<apply>
<times></times>
<ci>i</ci>
<ci>j</ci>
</apply>
</apply>
<cn type="integer">1</cn>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   g_{ij}=1
  </annotation>
</semantics>
</math>

) then the monitor 

<math display="inline" id="Independent_component_analysis:50">
<semantics>
<mi>j</mi>
<annotation-xml encoding="MathML-Content">
<ci>j</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   j
  </annotation>
</semantics>
</math>

 will observe some activity (

<math display="inline" id="Independent_component_analysis:51">
<semantics>
<mrow>
<msub>
<mi>x</mi>
<mi>j</mi>
</msub>
<mo>=</mo>
<mn>1</mn>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<eq></eq>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>x</ci>
<ci>j</ci>
</apply>
<cn type="integer">1</cn>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   x_{j}=1
  </annotation>
</semantics>
</math>

). Formally we have:</p>

<p>
<math display="block" id="Independent_component_analysis:52">
<semantics>
<mrow>
<mrow>
<mrow>
<msub>
<mi>x</mi>
<mi>i</mi>
</msub>
<mo>=</mo>
<mrow>
<munderover>
<mo largeop="true" mathsize="160%" movablelimits="false" stretchy="false" symmetric="true">⋁</mo>
<mrow>
<mi>j</mi>
<mo>=</mo>
<mn>1</mn>
</mrow>
<mi>n</mi>
</munderover>
<mrow>
<mo stretchy="false">(</mo>
<mrow>
<msub>
<mi>g</mi>
<mrow>
<mi>i</mi>
<mi>j</mi>
</mrow>
</msub>
<mo>∧</mo>
<msub>
<mi>y</mi>
<mi>j</mi>
</msub>
</mrow>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
</mrow>
<mo>,</mo>
<mrow>
<mi>i</mi>
<mo>=</mo>
<mrow>
<mn>1</mn>
<mo>,</mo>
<mn>2</mn>
<mo>,</mo>
<mi mathvariant="normal">…</mi>
<mo>,</mo>
<mi>m</mi>
</mrow>
</mrow>
</mrow>
<mo>,</mo>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<csymbol cd="ambiguous">formulae-sequence</csymbol>
<apply>
<eq></eq>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>x</ci>
<ci>i</ci>
</apply>
<apply>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<or></or>
<apply>
<eq></eq>
<ci>j</ci>
<cn type="integer">1</cn>
</apply>
</apply>
<ci>n</ci>
</apply>
<apply>
<and></and>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>g</ci>
<apply>
<times></times>
<ci>i</ci>
<ci>j</ci>
</apply>
</apply>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>y</ci>
<ci>j</ci>
</apply>
</apply>
</apply>
</apply>
<apply>
<eq></eq>
<ci>i</ci>
<list>
<cn type="integer">1</cn>
<cn type="integer">2</cn>
<ci>normal-…</ci>
<ci>m</ci>
</list>
</apply>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   x_{i}=\bigvee_{j=1}^{n}(g_{ij}\wedge y_{j}),i=1,2,\ldots,m,
  </annotation>
</semantics>
</math>
</p>

<p>where 

<math display="inline" id="Independent_component_analysis:53">
<semantics>
<mo>∧</mo>
<annotation-xml encoding="MathML-Content">
<and></and>
</annotation-xml>
<annotation encoding="application/x-tex">
   \wedge
  </annotation>
</semantics>
</math>

 is Boolean AND and 

<math display="inline" id="Independent_component_analysis:54">
<semantics>
<mo>∨</mo>
<annotation-xml encoding="MathML-Content">
<or></or>
</annotation-xml>
<annotation encoding="application/x-tex">
   \vee
  </annotation>
</semantics>
</math>

 is Boolean OR. Note that noise is not explicitly modeled, rather, can be treated as independent sources.</p>

<p>The above problem can be heuristically solved <a class="footnoteRef" href="#fn2" id="fnref2"><sup>2</sup></a> by assuming variables are continuous and running <a class="uri" href="FastICA" title="wikilink">FastICA</a> on binary observation data to get the mixing matrix 

<math display="inline" id="Independent_component_analysis:55">
<semantics>
<mi>G</mi>
<annotation-xml encoding="MathML-Content">
<ci>G</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   G
  </annotation>
</semantics>
</math>

 (real values), then apply <a href="round_number" title="wikilink">round number</a> techniques on 

<math display="inline" id="Independent_component_analysis:56">
<semantics>
<mi>G</mi>
<annotation-xml encoding="MathML-Content">
<ci>G</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   G
  </annotation>
</semantics>
</math>

 to obtain the binary values. This approach has been shown to produce a highly inaccurate result.</p>

<p>Another method is to use dynamic programming: recursively breaking the observation matrix 

<math display="inline" id="Independent_component_analysis:57">
<semantics>
<mi>X</mi>
<annotation-xml encoding="MathML-Content">
<ci>X</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   X
  </annotation>
</semantics>
</math>

 into its sub-matrices and run the inference algorithm on these sub-matrices. The key observation which leads to this algorithm is the sub-matrix 

<math display="inline" id="Independent_component_analysis:58">
<semantics>
<msup>
<mi>X</mi>
<mn>0</mn>
</msup>
<annotation-xml encoding="MathML-Content">
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<ci>X</ci>
<cn type="integer">0</cn>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   X^{0}
  </annotation>
</semantics>
</math>

 of 

<math display="inline" id="Independent_component_analysis:59">
<semantics>
<mi>X</mi>
<annotation-xml encoding="MathML-Content">
<ci>X</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   X
  </annotation>
</semantics>
</math>

 where 

<math display="inline" id="Independent_component_analysis:60">
<semantics>
<mrow>
<msub>
<mi>x</mi>
<mrow>
<mi>i</mi>
<mi>j</mi>
</mrow>
</msub>
<mo>=</mo>
<mrow>
<mn>0</mn>
<mo>,</mo>
<mrow>
<mo>∀</mo>
<mi>j</mi>
</mrow>
</mrow>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<eq></eq>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>x</ci>
<apply>
<times></times>
<ci>i</ci>
<ci>j</ci>
</apply>
</apply>
<list>
<cn type="integer">0</cn>
<apply>
<csymbol cd="latexml">for-all</csymbol>
<ci>j</ci>
</apply>
</list>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   x_{ij}=0,\forall j
  </annotation>
</semantics>
</math>

 corresponds to the unbiased observation matrix of hidden components that do not have connection to the 

<math display="inline" id="Independent_component_analysis:61">
<semantics>
<mi>i</mi>
<annotation-xml encoding="MathML-Content">
<ci>i</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   i
  </annotation>
</semantics>
</math>

-th monitor. Experimental results from <a class="footnoteRef" href="#fn3" id="fnref3"><sup>3</sup></a> show that this approach is accurate under moderate noise levels.</p>

<p>The Generalized Binary ICA framework <a class="footnoteRef" href="#fn4" id="fnref4"><sup>4</sup></a> introduces a broader problem formulation which does not necessitate any knowledge on the generative model. In other words, this method attempts to decompose a source into its independent components (as much as possible, and without losing any information) with no prior assumption on the way it was generated. Although this problem appears quite complex, it can be accurately solved with a branch and bound search tree algorithm or tightly upper bounded with a single multiplication of a matrix with a vector.</p>
<h2 id="methods-for-blind-source-separation">Methods for Blind Source Separation <a class="footnoteRef" href="#fn5" id="fnref5"><sup>5</sup></a></h2>
<h3 id="projection-pursuit">Projection Pursuit <a class="footnoteRef" href="#fn6" id="fnref6"><sup>6</sup></a></h3>

<p>Signal mixtures tend to have Gaussian probability density functions, and source signals tend to have non-Gaussian probability density functions. Each source signal can be extracted from a set of signal mixtures by taking the inner product of a weight vector and those signal mixtures where this inner product provides an orthogonal projection of the signal mixtures. The remaining challenge is finding such a weight vector. One type of method for doing so is <a href="projection_pursuit" title="wikilink">projection pursuit</a>.<a class="footnoteRef" href="#fn7" id="fnref7"><sup>7</sup></a></p>

<p>Projection pursuit seek one projection at a time such that the extracted signal is as non-Gaussian as possible. This contrasts with ICA, which typically extracts <em>M</em> signals simultaneously from <em>M</em> signal mixtures, which requires estimating a <em>M</em> × <em>M</em> unmixing matrix. One practical advantage of projection pursuit over ICA is that fewer than <em>M</em> signals can be extracted if required, where each source signal is extracted from <em>M</em> signal mixtures using an <em>M</em>-element weight vector.</p>

<p>We can use <a class="uri" href="kurtosis" title="wikilink">kurtosis</a> to recover the multiple source signal by finding the correct weight vectors with the use of projection pursuit.</p>

<p>The <a class="uri" href="kurtosis" title="wikilink">kurtosis</a> of the probability density function of a signal, for a finite sample, is computed as</p>

<p>
<math display="block" id="Independent_component_analysis:62">
<semantics>
<mrow>
<mi>K</mi>
<mo>=</mo>
<mrow>
<mfrac>
<mrow>
<mo>E</mo>
<mrow>
<mo stretchy="false">[</mo>
<msup>
<mrow>
<mo stretchy="false">(</mo>
<mrow>
<mi>𝐲</mi>
<mo>-</mo>
<mover accent="true">
<mi>𝐲</mi>
<mo>¯</mo>
</mover>
</mrow>
<mo stretchy="false">)</mo>
</mrow>
<mn>4</mn>
</msup>
<mo stretchy="false">]</mo>
</mrow>
</mrow>
<msup>
<mrow>
<mo stretchy="false">(</mo>
<mrow>
<mo>E</mo>
<mrow>
<mo stretchy="false">[</mo>
<msup>
<mrow>
<mo stretchy="false">(</mo>
<mrow>
<mi>𝐲</mi>
<mo>-</mo>
<mover accent="true">
<mi>𝐲</mi>
<mo>¯</mo>
</mover>
</mrow>
<mo stretchy="false">)</mo>
</mrow>
<mn>2</mn>
</msup>
<mo stretchy="false">]</mo>
</mrow>
</mrow>
<mo stretchy="false">)</mo>
</mrow>
<mn>2</mn>
</msup>
</mfrac>
<mo>-</mo>
<mn>3</mn>
</mrow>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<eq></eq>
<ci>K</ci>
<apply>
<minus></minus>
<apply>
<divide></divide>
<apply>
<ci>normal-E</ci>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<apply>
<minus></minus>
<ci>𝐲</ci>
<apply>
<ci>normal-¯</ci>
<ci>𝐲</ci>
</apply>
</apply>
<cn type="integer">4</cn>
</apply>
</apply>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<apply>
<ci>normal-E</ci>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<apply>
<minus></minus>
<ci>𝐲</ci>
<apply>
<ci>normal-¯</ci>
<ci>𝐲</ci>
</apply>
</apply>
<cn type="integer">2</cn>
</apply>
</apply>
<cn type="integer">2</cn>
</apply>
</apply>
<cn type="integer">3</cn>
</apply>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   K=\frac{\operatorname{E}[(\mathbf{y}-\mathbf{\overline{y}})^{4}]}{(%
\operatorname{E}[(\mathbf{y}-\mathbf{\overline{y}})^{2}])^{2}}-3
  </annotation>
</semantics>
</math>
</p>

<p>where 

<math display="inline" id="Independent_component_analysis:63">
<semantics>
<mover accent="true">
<mi>𝐲</mi>
<mo>¯</mo>
</mover>
<annotation-xml encoding="MathML-Content">
<apply>
<ci>normal-¯</ci>
<ci>𝐲</ci>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   \mathbf{\overline{y}}
  </annotation>
</semantics>
</math>

 is the <a href="sample_mean" title="wikilink">sample mean</a> of 

<math display="inline" id="Independent_component_analysis:64">
<semantics>
<mi>𝐲</mi>
<annotation-xml encoding="MathML-Content">
<ci>𝐲</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   \mathbf{y}
  </annotation>
</semantics>
</math>

, the extracted signals. The constant 3 ensures that Gaussian signals have zero kurtosis, Super-Gaussian signals have positive kurtosis, and Sub-Gaussian signals have negative kurtosis. The denominator is the <a class="uri" href="variance" title="wikilink">variance</a> of 

<math display="inline" id="Independent_component_analysis:65">
<semantics>
<mi>𝐲</mi>
<annotation-xml encoding="MathML-Content">
<ci>𝐲</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   \mathbf{y}
  </annotation>
</semantics>
</math>

, and ensures that the measured kurtosis takes account of signal variance. The goal of projection pursuit is to maximize the kurtosis, and make the extracted signal as non-normal as possible.</p>

<p>Using kurtosis as a measure of non-normality, we can now examine how the kurtosis of a signal 

<math display="inline" id="Independent_component_analysis:66">
<semantics>
<mrow>
<mi>𝐲</mi>
<mo>=</mo>
<mrow>
<msup>
<mi>𝐰</mi>
<mi>T</mi>
</msup>
<mi>𝐱</mi>
</mrow>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<eq></eq>
<ci>𝐲</ci>
<apply>
<times></times>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<ci>𝐰</ci>
<ci>T</ci>
</apply>
<ci>𝐱</ci>
</apply>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   \mathbf{y}=\mathbf{w}^{T}\mathbf{x}
  </annotation>
</semantics>
</math>

 extracted from a set of <em>M</em> mixtures 

<math display="inline" id="Independent_component_analysis:67">
<semantics>
<mrow>
<mi>𝐱</mi>
<mo>=</mo>
<msup>
<mrow>
<mo stretchy="false">(</mo>
<msub>
<mi>x</mi>
<mn>1</mn>
</msub>
<mo>,</mo>
<msub>
<mi>x</mi>
<mn>2</mn>
</msub>
<mo>,</mo>
<mi mathvariant="normal">…</mi>
<mo>,</mo>
<msub>
<mi>x</mi>
<mi>M</mi>
</msub>
<mo stretchy="false">)</mo>
</mrow>
<mi>T</mi>
</msup>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<eq></eq>
<ci>𝐱</ci>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<vector>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>x</ci>
<cn type="integer">1</cn>
</apply>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>x</ci>
<cn type="integer">2</cn>
</apply>
<ci>normal-…</ci>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>x</ci>
<ci>M</ci>
</apply>
</vector>
<ci>T</ci>
</apply>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   \mathbf{x}=(x_{1},x_{2},\ldots,x_{M})^{T}
  </annotation>
</semantics>
</math>

 varies as the weight vector 

<math display="inline" id="Independent_component_analysis:68">
<semantics>
<mi>𝐰</mi>
<annotation-xml encoding="MathML-Content">
<ci>𝐰</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   \mathbf{w}
  </annotation>
</semantics>
</math>

 is rotated around the origin. Given our assumption that each source signal 

<math display="inline" id="Independent_component_analysis:69">
<semantics>
<mi>𝐬</mi>
<annotation-xml encoding="MathML-Content">
<ci>𝐬</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   \mathbf{s}
  </annotation>
</semantics>
</math>

 is super-gaussian we would expect:</p>
<ol>
<li>the kurtosis of the extracted signal 

<math display="inline" id="Independent_component_analysis:70">
<semantics>
<mi>𝐲</mi>
<annotation-xml encoding="MathML-Content">
<ci>𝐲</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   \mathbf{y}
  </annotation>
</semantics>
</math>

 to be maximal precisely when 

<math display="inline" id="Independent_component_analysis:71">
<semantics>
<mrow>
<mi>𝐲</mi>
<mo>=</mo>
<mi>𝐬</mi>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<eq></eq>
<ci>𝐲</ci>
<ci>𝐬</ci>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   \mathbf{y}=\mathbf{s}
  </annotation>
</semantics>
</math>

.</li>
<li>the kurtosis of the extracted signal 

<math display="inline" id="Independent_component_analysis:72">
<semantics>
<mi>𝐲</mi>
<annotation-xml encoding="MathML-Content">
<ci>𝐲</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   \mathbf{y}
  </annotation>
</semantics>
</math>

 to be maximal when 

<math display="inline" id="Independent_component_analysis:73">
<semantics>
<mi>𝐰</mi>
<annotation-xml encoding="MathML-Content">
<ci>𝐰</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   \mathbf{w}
  </annotation>
</semantics>
</math>

 is orthogonal to the projected axes 

<math display="inline" id="Independent_component_analysis:74">
<semantics>
<msub>
<mi>S</mi>
<mn>1</mn>
</msub>
<annotation-xml encoding="MathML-Content">
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>S</ci>
<cn type="integer">1</cn>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   S_{1}
  </annotation>
</semantics>
</math>

 or 

<math display="inline" id="Independent_component_analysis:75">
<semantics>
<msub>
<mi>S</mi>
<mn>2</mn>
</msub>
<annotation-xml encoding="MathML-Content">
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>S</ci>
<cn type="integer">2</cn>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   S_{2}
  </annotation>
</semantics>
</math>

, because we know the optimal weight vector should be orthogonal to a transformed axis 

<math display="inline" id="Independent_component_analysis:76">
<semantics>
<msub>
<mi>S</mi>
<mn>1</mn>
</msub>
<annotation-xml encoding="MathML-Content">
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>S</ci>
<cn type="integer">1</cn>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   S_{1}
  </annotation>
</semantics>
</math>

 or 

<math display="inline" id="Independent_component_analysis:77">
<semantics>
<msub>
<mi>S</mi>
<mn>2</mn>
</msub>
<annotation-xml encoding="MathML-Content">
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>S</ci>
<cn type="integer">2</cn>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   S_{2}
  </annotation>
</semantics>
</math>

.</li>
</ol>

<p>For multiple source mixture signals, we can use kurtosis and <a class="uri" href="Gram-Schmidt" title="wikilink">Gram-Schmidt</a> Orthogonalizaton (GSO) to recover the signals. Given <em>M</em> signal mixtures in an <em>M</em>-dimensional space, GSO project these data points onto an (<em>M-1</em>)-dimensional space by using the weight vector. We can guarantee the independence of the extracted signals with the use of GSO.</p>

<p>In order to find the correct value of 

<math display="inline" id="Independent_component_analysis:78">
<semantics>
<mi>𝐰</mi>
<annotation-xml encoding="MathML-Content">
<ci>𝐰</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   \mathbf{w}
  </annotation>
</semantics>
</math>

, we can use <a href="gradient_descent" title="wikilink">gradient descent</a> method. We first of all whiten the data, and transform 

<math display="inline" id="Independent_component_analysis:79">
<semantics>
<mi>𝐱</mi>
<annotation-xml encoding="MathML-Content">
<ci>𝐱</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   \mathbf{x}
  </annotation>
</semantics>
</math>

 into a new mixture 

<math display="inline" id="Independent_component_analysis:80">
<semantics>
<mi>𝐳</mi>
<annotation-xml encoding="MathML-Content">
<ci>𝐳</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   \mathbf{z}
  </annotation>
</semantics>
</math>

, which has unit variance, and 

<math display="inline" id="Independent_component_analysis:81">
<semantics>
<mrow>
<mi>𝐳</mi>
<mo>=</mo>
<msup>
<mrow>
<mo stretchy="false">(</mo>
<msub>
<mi>z</mi>
<mn>1</mn>
</msub>
<mo>,</mo>
<msub>
<mi>z</mi>
<mn>2</mn>
</msub>
<mo>,</mo>
<mi mathvariant="normal">…</mi>
<mo>,</mo>
<msub>
<mi>z</mi>
<mi>M</mi>
</msub>
<mo stretchy="false">)</mo>
</mrow>
<mi>T</mi>
</msup>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<eq></eq>
<ci>𝐳</ci>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<vector>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>z</ci>
<cn type="integer">1</cn>
</apply>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>z</ci>
<cn type="integer">2</cn>
</apply>
<ci>normal-…</ci>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>z</ci>
<ci>M</ci>
</apply>
</vector>
<ci>T</ci>
</apply>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   \mathbf{z}=(z_{1},z_{2},\ldots,z_{M})^{T}
  </annotation>
</semantics>
</math>

. This process can be achieved by applying <a href="Singular_value_decomposition" title="wikilink">Singular value decomposition</a> to 

<math display="inline" id="Independent_component_analysis:82">
<semantics>
<mi>𝐱</mi>
<annotation-xml encoding="MathML-Content">
<ci>𝐱</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   \mathbf{x}
  </annotation>
</semantics>
</math>

,</p>

<p>
<math display="block" id="Independent_component_analysis:83">
<semantics>
<mrow>
<mi>𝐱</mi>
<mo>=</mo>
<msup>
<mi>𝐔𝐃𝐕</mi>
<mi>T</mi>
</msup>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<eq></eq>
<ci>𝐱</ci>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<ci>𝐔𝐃𝐕</ci>
<ci>T</ci>
</apply>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   \mathbf{x}=\mathbf{U}\mathbf{D}\mathbf{V}^{T}
  </annotation>
</semantics>
</math>
</p>

<p>Rescaling each vector 

<math display="inline" id="Independent_component_analysis:84">
<semantics>
<mrow>
<msub>
<mi>U</mi>
<mi>i</mi>
</msub>
<mo>=</mo>
<mrow>
<msub>
<mi>U</mi>
<mi>i</mi>
</msub>
<mo>/</mo>
<mrow>
<mo>E</mo>
<mrow>
<mo stretchy="false">(</mo>
<msubsup>
<mi>U</mi>
<mi>i</mi>
<mn>2</mn>
</msubsup>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
</mrow>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<eq></eq>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>U</ci>
<ci>i</ci>
</apply>
<apply>
<divide></divide>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>U</ci>
<ci>i</ci>
</apply>
<apply>
<ci>normal-E</ci>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>U</ci>
<ci>i</ci>
</apply>
<cn type="integer">2</cn>
</apply>
</apply>
</apply>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   U_{i}=U_{i}/\operatorname{E}(U_{i}^{2})
  </annotation>
</semantics>
</math>

, and let 

<math display="inline" id="Independent_component_analysis:85">
<semantics>
<mrow>
<mi>𝐳</mi>
<mo>=</mo>
<mi>𝐔</mi>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<eq></eq>
<ci>𝐳</ci>
<ci>𝐔</ci>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   \mathbf{z}=\mathbf{U}
  </annotation>
</semantics>
</math>

. The signal extracted by a weighted vector 

<math display="inline" id="Independent_component_analysis:86">
<semantics>
<mi>𝐰</mi>
<annotation-xml encoding="MathML-Content">
<ci>𝐰</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   \mathbf{w}
  </annotation>
</semantics>
</math>

 is 

<math display="inline" id="Independent_component_analysis:87">
<semantics>
<mrow>
<mi>𝐲</mi>
<mo>=</mo>
<mrow>
<msup>
<mi>𝐰</mi>
<mi>T</mi>
</msup>
<mi>𝐳</mi>
</mrow>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<eq></eq>
<ci>𝐲</ci>
<apply>
<times></times>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<ci>𝐰</ci>
<ci>T</ci>
</apply>
<ci>𝐳</ci>
</apply>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   \mathbf{y}=\mathbf{w}^{T}\mathbf{z}
  </annotation>
</semantics>
</math>

. If the weight vector <strong>w</strong> has unit length, that is 

<math display="inline" id="Independent_component_analysis:88">
<semantics>
<mrow>
<mrow>
<mo>E</mo>
<mrow>
<mo stretchy="false">[</mo>
<msup>
<mrow>
<mo stretchy="false">(</mo>
<mrow>
<msup>
<mi>𝐰</mi>
<mi>T</mi>
</msup>
<mi>𝐳</mi>
</mrow>
<mo stretchy="false">)</mo>
</mrow>
<mn>2</mn>
</msup>
<mo stretchy="false">]</mo>
</mrow>
</mrow>
<mo>=</mo>
<mn>1</mn>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<eq></eq>
<apply>
<ci>normal-E</ci>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<apply>
<times></times>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<ci>𝐰</ci>
<ci>T</ci>
</apply>
<ci>𝐳</ci>
</apply>
<cn type="integer">2</cn>
</apply>
</apply>
<cn type="integer">1</cn>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   \operatorname{E}[(\mathbf{w}^{T}\mathbf{z})^{2}]=1
  </annotation>
</semantics>
</math>

, then the kurtosis can be written as:</p>

<p>
<math display="block" id="Independent_component_analysis:89">
<semantics>
<mrow>
<mi>K</mi>
<mo>=</mo>
<mrow>
<mfrac>
<mrow>
<mo>E</mo>
<mrow>
<mo stretchy="false">[</mo>
<msup>
<mi>𝐲</mi>
<mn>4</mn>
</msup>
<mo stretchy="false">]</mo>
</mrow>
</mrow>
<msup>
<mrow>
<mo stretchy="false">(</mo>
<mrow>
<mo>E</mo>
<mrow>
<mo stretchy="false">[</mo>
<msup>
<mi>𝐲</mi>
<mn>2</mn>
</msup>
<mo stretchy="false">]</mo>
</mrow>
</mrow>
<mo stretchy="false">)</mo>
</mrow>
<mn>2</mn>
</msup>
</mfrac>
<mo>-</mo>
<mn>3</mn>
</mrow>
<mo>=</mo>
<mrow>
<mrow>
<mo>E</mo>
<mrow>
<mo stretchy="false">[</mo>
<msup>
<mrow>
<mo stretchy="false">(</mo>
<mrow>
<msup>
<mi>𝐰</mi>
<mi>T</mi>
</msup>
<mi>𝐳</mi>
</mrow>
<mo stretchy="false">)</mo>
</mrow>
<mn>4</mn>
</msup>
<mo stretchy="false">]</mo>
</mrow>
</mrow>
<mo>-</mo>
<mn>3.</mn>
</mrow>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<and></and>
<apply>
<eq></eq>
<ci>K</ci>
<apply>
<minus></minus>
<apply>
<divide></divide>
<apply>
<ci>normal-E</ci>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<ci>𝐲</ci>
<cn type="integer">4</cn>
</apply>
</apply>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<apply>
<ci>normal-E</ci>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<ci>𝐲</ci>
<cn type="integer">2</cn>
</apply>
</apply>
<cn type="integer">2</cn>
</apply>
</apply>
<cn type="integer">3</cn>
</apply>
</apply>
<apply>
<eq></eq>
<share href="#.cmml">
</share>
<apply>
<minus></minus>
<apply>
<ci>normal-E</ci>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<apply>
<times></times>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<ci>𝐰</ci>
<ci>T</ci>
</apply>
<ci>𝐳</ci>
</apply>
<cn type="integer">4</cn>
</apply>
</apply>
<cn type="float">3.</cn>
</apply>
</apply>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   K=\frac{\operatorname{E}[\mathbf{y}^{4}]}{(\operatorname{E}[\mathbf{y}^{2}])^{%
2}}-3=\operatorname{E}[(\mathbf{w}^{T}\mathbf{z})^{4}]-3.
  </annotation>
</semantics>
</math>
</p>

<p>The updating process for 

<math display="inline" id="Independent_component_analysis:90">
<semantics>
<mi>𝐰</mi>
<annotation-xml encoding="MathML-Content">
<ci>𝐰</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   \mathbf{w}
  </annotation>
</semantics>
</math>

 is:</p>

<p>
<math display="block" id="Independent_component_analysis:91">
<semantics>
<mrow>
<mrow>
<msub>
<mi>𝐰</mi>
<mrow>
<mi>n</mi>
<mi>e</mi>
<mi>w</mi>
</mrow>
</msub>
<mo>=</mo>
<mrow>
<msub>
<mi>𝐰</mi>
<mrow>
<mi>o</mi>
<mi>l</mi>
<mi>d</mi>
</mrow>
</msub>
<mo>-</mo>
<mrow>
<mi>η</mi>
<mrow>
<mo>E</mo>
<mrow>
<mo stretchy="false">[</mo>
<mrow>
<mi>𝐳</mi>
<msup>
<mrow>
<mo stretchy="false">(</mo>
<mrow>
<msubsup>
<mi>𝐰</mi>
<mrow>
<mi>o</mi>
<mi>l</mi>
<mi>d</mi>
</mrow>
<mi>T</mi>
</msubsup>
<mi>𝐳</mi>
</mrow>
<mo stretchy="false">)</mo>
</mrow>
<mn>3</mn>
</msup>
</mrow>
<mo stretchy="false">]</mo>
</mrow>
</mrow>
</mrow>
</mrow>
</mrow>
<mo>.</mo>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<eq></eq>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>𝐰</ci>
<apply>
<times></times>
<ci>n</ci>
<ci>e</ci>
<ci>w</ci>
</apply>
</apply>
<apply>
<minus></minus>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>𝐰</ci>
<apply>
<times></times>
<ci>o</ci>
<ci>l</ci>
<ci>d</ci>
</apply>
</apply>
<apply>
<times></times>
<ci>η</ci>
<apply>
<ci>normal-E</ci>
<apply>
<times></times>
<ci>𝐳</ci>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<apply>
<times></times>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>𝐰</ci>
<apply>
<times></times>
<ci>o</ci>
<ci>l</ci>
<ci>d</ci>
</apply>
</apply>
<ci>T</ci>
</apply>
<ci>𝐳</ci>
</apply>
<cn type="integer">3</cn>
</apply>
</apply>
</apply>
</apply>
</apply>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   \mathbf{w}_{new}=\mathbf{w}_{old}-\eta\operatorname{E}[\mathbf{z}(\mathbf{w}_{%
old}^{T}\mathbf{z})^{3}].
  </annotation>
</semantics>
</math>

 where 

<math display="inline" id="Independent_component_analysis:92">
<semantics>
<mi>η</mi>
<annotation-xml encoding="MathML-Content">
<ci>η</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   \eta
  </annotation>
</semantics>
</math>

 is a small constant to guarantee that 

<math display="inline" id="Independent_component_analysis:93">
<semantics>
<mi>𝐰</mi>
<annotation-xml encoding="MathML-Content">
<ci>𝐰</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   \mathbf{w}
  </annotation>
</semantics>
</math>

 converge to the optimal solution. After each update, we normalized 

<math display="inline" id="Independent_component_analysis:94">
<semantics>
<mrow>
<msub>
<mi>𝐰</mi>
<mrow>
<mi>n</mi>
<mi>e</mi>
<mi>w</mi>
</mrow>
</msub>
<mo>=</mo>
<mfrac>
<msub>
<mi>𝐰</mi>
<mrow>
<mi>n</mi>
<mi>e</mi>
<mi>w</mi>
</mrow>
</msub>
<mrow>
<mo stretchy="false">|</mo>
<msub>
<mi>𝐰</mi>
<mrow>
<mi>n</mi>
<mi>e</mi>
<mi>w</mi>
</mrow>
</msub>
<mo stretchy="false">|</mo>
</mrow>
</mfrac>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<eq></eq>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>𝐰</ci>
<apply>
<times></times>
<ci>n</ci>
<ci>e</ci>
<ci>w</ci>
</apply>
</apply>
<apply>
<divide></divide>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>𝐰</ci>
<apply>
<times></times>
<ci>n</ci>
<ci>e</ci>
<ci>w</ci>
</apply>
</apply>
<apply>
<abs></abs>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>𝐰</ci>
<apply>
<times></times>
<ci>n</ci>
<ci>e</ci>
<ci>w</ci>
</apply>
</apply>
</apply>
</apply>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   \mathbf{w}_{new}=\frac{\mathbf{w}_{new}}{|\mathbf{w}_{new}|}
  </annotation>
</semantics>
</math>

, and set 

<math display="inline" id="Independent_component_analysis:95">
<semantics>
<mrow>
<msub>
<mi>𝐰</mi>
<mrow>
<mi>o</mi>
<mi>l</mi>
<mi>d</mi>
</mrow>
</msub>
<mo>=</mo>
<msub>
<mi>𝐰</mi>
<mrow>
<mi>n</mi>
<mi>e</mi>
<mi>w</mi>
</mrow>
</msub>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<eq></eq>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>𝐰</ci>
<apply>
<times></times>
<ci>o</ci>
<ci>l</ci>
<ci>d</ci>
</apply>
</apply>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>𝐰</ci>
<apply>
<times></times>
<ci>n</ci>
<ci>e</ci>
<ci>w</ci>
</apply>
</apply>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   \mathbf{w}_{old}=\mathbf{w}_{new}
  </annotation>
</semantics>
</math>

, and repeat the updating process till it converges. We can also use another algorithm to update the weight vector 

<math display="inline" id="Independent_component_analysis:96">
<semantics>
<mi>𝐰</mi>
<annotation-xml encoding="MathML-Content">
<ci>𝐰</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   \mathbf{w}
  </annotation>
</semantics>
</math>

.</p>

<p>Another approach is using <a class="uri" href="Negentropy" title="wikilink">Negentropy</a><a class="footnoteRef" href="#fn8" id="fnref8"><sup>8</sup></a> instead of kurtosis. Negentropy is a robust method for kurtosis, as kurtosis is very sensitive to outliers. The negentropy method are based on an important property of gaussian distribution : a gaussian variable has the largest entropy among all random variables of equal variance. This is also the reason why we want to find the most nongaussian variables. A simple proof can be found in wiki page <a href="Differential_entropy" title="wikilink">Differential entropy</a>.</p>

<p>
<math display="block" id="Independent_component_analysis:97">
<semantics>
<mrow>
<mrow>
<mi>J</mi>
<mrow>
<mo stretchy="false">(</mo>
<mi>x</mi>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
<mo>=</mo>
<mrow>
<mrow>
<mi>S</mi>
<mrow>
<mo stretchy="false">(</mo>
<mi>y</mi>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
<mo>-</mo>
<mrow>
<mi>S</mi>
<mrow>
<mo stretchy="false">(</mo>
<mi>x</mi>
<mo rspace="4.2pt" stretchy="false">)</mo>
</mrow>
</mrow>
</mrow>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<eq></eq>
<apply>
<times></times>
<ci>J</ci>
<ci>x</ci>
</apply>
<apply>
<minus></minus>
<apply>
<times></times>
<ci>S</ci>
<ci>y</ci>
</apply>
<apply>
<times></times>
<ci>S</ci>
<ci>x</ci>
</apply>
</apply>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   J(x)=S(y)-S(x)\,
  </annotation>
</semantics>
</math>
</p>

<p>y is a Gaussian random variable of the same covariance matrix as x</p>

<p>
<math display="block" id="Independent_component_analysis:98">
<semantics>
<mrow>
<mrow>
<mi>S</mi>
<mrow>
<mo stretchy="false">(</mo>
<mi>x</mi>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
<mo>=</mo>
<mrow>
<mo>-</mo>
<mrow>
<mo largeop="true" symmetric="true">∫</mo>
<mrow>
<msub>
<mi>p</mi>
<mi>x</mi>
</msub>
<mrow>
<mo stretchy="false">(</mo>
<mi>u</mi>
<mo stretchy="false">)</mo>
</mrow>
<mrow>
<mi>log</mi>
<msub>
<mi>p</mi>
<mi>x</mi>
</msub>
</mrow>
<mrow>
<mo stretchy="false">(</mo>
<mi>u</mi>
<mo stretchy="false">)</mo>
</mrow>
<mi>d</mi>
<mi>u</mi>
</mrow>
</mrow>
</mrow>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<eq></eq>
<apply>
<times></times>
<ci>S</ci>
<ci>x</ci>
</apply>
<apply>
<minus></minus>
<apply>
<int></int>
<apply>
<times></times>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>p</ci>
<ci>x</ci>
</apply>
<ci>u</ci>
<apply>
<log></log>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>p</ci>
<ci>x</ci>
</apply>
</apply>
<ci>u</ci>
<ci>d</ci>
<ci>u</ci>
</apply>
</apply>
</apply>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   S(x)=-\int p_{x}(u)\log p_{x}(u)du
  </annotation>
</semantics>
</math>
</p>

<p>An approximation for negentropy is</p>

<p>
<math display="block" id="Independent_component_analysis:99">
<semantics>
<mrow>
<mrow>
<mi>J</mi>
<mrow>
<mo stretchy="false">(</mo>
<mi>x</mi>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
<mo>=</mo>
<mrow>
<mrow>
<mfrac>
<mn>1</mn>
<mn>12</mn>
</mfrac>
<msup>
<mrow>
<mo stretchy="false">(</mo>
<mrow>
<mi>E</mi>
<mrow>
<mo stretchy="false">(</mo>
<msup>
<mi>x</mi>
<mn>3</mn>
</msup>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
<mo stretchy="false">)</mo>
</mrow>
<mn>2</mn>
</msup>
</mrow>
<mo>+</mo>
<mrow>
<mfrac>
<mn>1</mn>
<mn>48</mn>
</mfrac>
<msup>
<mrow>
<mo stretchy="false">(</mo>
<mrow>
<mi>k</mi>
<mi>u</mi>
<mi>r</mi>
<mi>t</mi>
<mrow>
<mo stretchy="false">(</mo>
<mi>x</mi>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
<mo stretchy="false">)</mo>
</mrow>
<mn>2</mn>
</msup>
</mrow>
</mrow>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<eq></eq>
<apply>
<times></times>
<ci>J</ci>
<ci>x</ci>
</apply>
<apply>
<plus></plus>
<apply>
<times></times>
<apply>
<divide></divide>
<cn type="integer">1</cn>
<cn type="integer">12</cn>
</apply>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<apply>
<times></times>
<ci>E</ci>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<ci>x</ci>
<cn type="integer">3</cn>
</apply>
</apply>
<cn type="integer">2</cn>
</apply>
</apply>
<apply>
<times></times>
<apply>
<divide></divide>
<cn type="integer">1</cn>
<cn type="integer">48</cn>
</apply>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<apply>
<times></times>
<ci>k</ci>
<ci>u</ci>
<ci>r</ci>
<ci>t</ci>
<ci>x</ci>
</apply>
<cn type="integer">2</cn>
</apply>
</apply>
</apply>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   J(x)=\frac{1}{12}(E(x^{3}))^{2}+\frac{1}{48}(kurt(x))^{2}
  </annotation>
</semantics>
</math>

 A proof can be found on page 131 in the book Independent Component Analysis written by Aapo Hyvärinen, Juha Karhunen, and Erkki Oja (They contribute great works to ICA)<a class="footnoteRef" href="#fn9" id="fnref9"><sup>9</sup></a> This approximation also suffers the same problem as kurtosis (sensitive to outliers). Other approaches were developed.<a class="footnoteRef" href="#fn10" id="fnref10"><sup>10</sup></a></p>

<p>
<math display="block" id="Independent_component_analysis:100">
<semantics>
<mrow>
<mi>J</mi>
<mrow>
<mo stretchy="false">(</mo>
<mi>y</mi>
<mo stretchy="false">)</mo>
</mrow>
<mo>=</mo>
<msub>
<mi>k</mi>
<mn>1</mn>
</msub>
<msup>
<mrow>
<mo stretchy="false">(</mo>
<mi>E</mi>
<mrow>
<mo stretchy="false">(</mo>
<msub>
<mi>G</mi>
<mn>1</mn>
</msub>
<mrow>
<mo stretchy="false">(</mo>
<mi>y</mi>
<mo stretchy="false">)</mo>
</mrow>
<mo stretchy="false">)</mo>
</mrow>
<mo stretchy="false">)</mo>
</mrow>
<mn>2</mn>
</msup>
<mo>+</mo>
<msub>
<mi>k</mi>
<mn>2</mn>
</msub>
<mrow>
<mo stretchy="false">(</mo>
<mi>E</mi>
<mrow>
<mo stretchy="false">(</mo>
<msub>
<mi>G</mi>
<mn>2</mn>
</msub>
<mrow>
<mo stretchy="false">(</mo>
<mi>y</mi>
<mo stretchy="false">)</mo>
</mrow>
<mo stretchy="false">)</mo>
</mrow>
<mo>-</mo>
<mi>E</mi>
<msup>
<mrow>
<mo stretchy="false">(</mo>
<msub>
<mi>G</mi>
<mn>2</mn>
</msub>
<mrow>
<mo stretchy="false">(</mo>
<mi>v</mi>
<mo stretchy="false">)</mo>
</mrow>
<mo stretchy="false">)</mo>
</mrow>
<mn>2</mn>
</msup>
</mrow>
</mrow>
<annotation-xml encoding="MathML-Content">
<cerror>
<csymbol cd="ambiguous">fragments</csymbol>
<csymbol cd="unknown">J</csymbol>
<cerror>
<csymbol cd="ambiguous">fragments</csymbol>
<ci>normal-(</ci>
<csymbol cd="unknown">y</csymbol>
<ci>normal-)</ci>
</cerror>
<eq></eq>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>k</ci>
<cn type="integer">1</cn>
</apply>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<cerror>
<csymbol cd="ambiguous">fragments</csymbol>
<ci>normal-(</ci>
<csymbol cd="unknown">E</csymbol>
<cerror>
<csymbol cd="ambiguous">fragments</csymbol>
<ci>normal-(</ci>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>G</ci>
<cn type="integer">1</cn>
</apply>
<cerror>
<csymbol cd="ambiguous">fragments</csymbol>
<ci>normal-(</ci>
<csymbol cd="unknown">y</csymbol>
<ci>normal-)</ci>
</cerror>
<ci>normal-)</ci>
</cerror>
<ci>normal-)</ci>
</cerror>
<cn type="integer">2</cn>
</apply>
<plus></plus>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>k</ci>
<cn type="integer">2</cn>
</apply>
<cerror>
<csymbol cd="ambiguous">fragments</csymbol>
<ci>normal-(</ci>
<csymbol cd="unknown">E</csymbol>
<cerror>
<csymbol cd="ambiguous">fragments</csymbol>
<ci>normal-(</ci>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>G</ci>
<cn type="integer">2</cn>
</apply>
<cerror>
<csymbol cd="ambiguous">fragments</csymbol>
<ci>normal-(</ci>
<csymbol cd="unknown">y</csymbol>
<ci>normal-)</ci>
</cerror>
<ci>normal-)</ci>
</cerror>
<minus></minus>
<csymbol cd="unknown">E</csymbol>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<cerror>
<csymbol cd="ambiguous">fragments</csymbol>
<ci>normal-(</ci>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>G</ci>
<cn type="integer">2</cn>
</apply>
<cerror>
<csymbol cd="ambiguous">fragments</csymbol>
<ci>normal-(</ci>
<csymbol cd="unknown">v</csymbol>
<ci>normal-)</ci>
</cerror>
<ci>normal-)</ci>
</cerror>
<cn type="integer">2</cn>
</apply>
</cerror>
</cerror>
</annotation-xml>
<annotation encoding="application/x-tex">
   J(y)=k_{1}(E(G_{1}(y)))^{2}+k_{2}(E(G_{2}(y))-E(G_{2}(v))^{2}
  </annotation>
</semantics>
</math>

 A choice of 

<math display="inline" id="Independent_component_analysis:101">
<semantics>
<msub>
<mi>G</mi>
<mn>1</mn>
</msub>
<annotation-xml encoding="MathML-Content">
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>G</ci>
<cn type="integer">1</cn>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   G_{1}
  </annotation>
</semantics>
</math>

 and 

<math display="inline" id="Independent_component_analysis:102">
<semantics>
<msub>
<mi>G</mi>
<mn>2</mn>
</msub>
<annotation-xml encoding="MathML-Content">
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>G</ci>
<cn type="integer">2</cn>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   G_{2}
  </annotation>
</semantics>
</math>

 are</p>

<p>
<math display="block" id="Independent_component_analysis:103">
<semantics>
<mrow>
<msub>
<mi>G</mi>
<mn>1</mn>
</msub>
<mo>=</mo>
<mrow>
<mfrac>
<mn>1</mn>
<msub>
<mi>a</mi>
<mn>1</mn>
</msub>
</mfrac>
<mrow>
<mi>log</mi>
<mrow>
<mo stretchy="false">(</mo>
<mrow>
<mi>cosh</mi>
<mrow>
<mo stretchy="false">(</mo>
<mrow>
<msub>
<mi>a</mi>
<mn>1</mn>
</msub>
<mi>u</mi>
</mrow>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
</mrow>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<eq></eq>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>G</ci>
<cn type="integer">1</cn>
</apply>
<apply>
<times></times>
<apply>
<divide></divide>
<cn type="integer">1</cn>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>a</ci>
<cn type="integer">1</cn>
</apply>
</apply>
<apply>
<log></log>
<apply>
<cosh></cosh>
<apply>
<times></times>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>a</ci>
<cn type="integer">1</cn>
</apply>
<ci>u</ci>
</apply>
</apply>
</apply>
</apply>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   G_{1}=\frac{1}{a_{1}}\log(\cosh(a_{1}u))
  </annotation>
</semantics>
</math>

 and 

<math display="inline" id="Independent_component_analysis:104">
<semantics>
<mrow>
<msub>
<mi>G</mi>
<mn>2</mn>
</msub>
<mo>=</mo>
<mrow>
<mo>-</mo>
<mrow>
<mi>exp</mi>
<mrow>
<mo stretchy="false">(</mo>
<mrow>
<mo>-</mo>
<mfrac>
<msup>
<mi>u</mi>
<mn>2</mn>
</msup>
<mn>2</mn>
</mfrac>
</mrow>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
</mrow>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<eq></eq>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>G</ci>
<cn type="integer">2</cn>
</apply>
<apply>
<minus></minus>
<apply>
<exp></exp>
<apply>
<minus></minus>
<apply>
<divide></divide>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<ci>u</ci>
<cn type="integer">2</cn>
</apply>
<cn type="integer">2</cn>
</apply>
</apply>
</apply>
</apply>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   G_{2}=-\exp(-\frac{u^{2}}{2})
  </annotation>
</semantics>
</math>
</p>
<h3 id="independent-component-analysis-based-on-infomax">Independent Component Analysis based on Infomax <a class="footnoteRef" href="#fn11" id="fnref11"><sup>11</sup></a></h3>

<p>ICA is essentially a multivariate, parallel version of projection pursuit. Whereas projection pursuit extracts a series of signals one at a time from a set of <em>M</em> signal mixtures, ICA extracts <em>M</em> signals in parallel. This tends to make ICA more robust than projection pursuit.</p>

<p>The projection pursuit method use <a class="uri" href="Gram-Schmidt" title="wikilink">Gram-Schmidt</a> Orthogonalizaton to ensure the independence of the extracted signal, while ICA use <a class="uri" href="infomax" title="wikilink">infomax</a> and <a href="maximum_likelihood" title="wikilink">maximum likelihood</a> estimate to ensure the independence of the extracted signal. The Non-Normality of the extracted signal is achieved by assigning an appropriate model, or prior, for the signal.</p>

<p>The process of ICA based on <a class="uri" href="infomax" title="wikilink">infomax</a> in short is: given a set of signal mixtures 

<math display="inline" id="Independent_component_analysis:105">
<semantics>
<mi>𝐱</mi>
<annotation-xml encoding="MathML-Content">
<ci>𝐱</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   \mathbf{x}
  </annotation>
</semantics>
</math>

 and a set of identical independent model <a href="cumulative_distribution_functions" title="wikilink">cumulative distribution functions</a>(cdfs) 

<math display="inline" id="Independent_component_analysis:106">
<semantics>
<mi>g</mi>
<annotation-xml encoding="MathML-Content">
<ci>g</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   g
  </annotation>
</semantics>
</math>

, we seek the unmixing matrix 

<math display="inline" id="Independent_component_analysis:107">
<semantics>
<mi>𝐖</mi>
<annotation-xml encoding="MathML-Content">
<ci>𝐖</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   \mathbf{W}
  </annotation>
</semantics>
</math>

 which maximizes the joint <a class="uri" href="entropy" title="wikilink">entropy</a> of the signals 

<math display="inline" id="Independent_component_analysis:108">
<semantics>
<mrow>
<mi>𝐘</mi>
<mo>=</mo>
<mrow>
<mi>g</mi>
<mrow>
<mo stretchy="false">(</mo>
<mi>𝐲</mi>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<eq></eq>
<ci>𝐘</ci>
<apply>
<times></times>
<ci>g</ci>
<ci>𝐲</ci>
</apply>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   \mathbf{Y}=g(\mathbf{y})
  </annotation>
</semantics>
</math>

, where 

<math display="inline" id="Independent_component_analysis:109">
<semantics>
<mrow>
<mi>𝐲</mi>
<mo>=</mo>
<mi>𝐖𝐱</mi>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<eq></eq>
<ci>𝐲</ci>
<ci>𝐖𝐱</ci>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   \mathbf{y}=\mathbf{Wx}
  </annotation>
</semantics>
</math>

 are the signals extracted by 

<math display="inline" id="Independent_component_analysis:110">
<semantics>
<mi>𝐖</mi>
<annotation-xml encoding="MathML-Content">
<ci>𝐖</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   \mathbf{W}
  </annotation>
</semantics>
</math>

. Given the optimal 

<math display="inline" id="Independent_component_analysis:111">
<semantics>
<mi>𝐖</mi>
<annotation-xml encoding="MathML-Content">
<ci>𝐖</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   \mathbf{W}
  </annotation>
</semantics>
</math>

, the signals 

<math display="inline" id="Independent_component_analysis:112">
<semantics>
<mi>𝐘</mi>
<annotation-xml encoding="MathML-Content">
<ci>𝐘</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   \mathbf{Y}
  </annotation>
</semantics>
</math>

 have maximum entropy and are therefore independent, which ensures that the extracted signals 

<math display="inline" id="Independent_component_analysis:113">
<semantics>
<mrow>
<mi>𝐲</mi>
<mo>=</mo>
<mrow>
<msup>
<mi>g</mi>
<mrow>
<mo>-</mo>
<mn>1</mn>
</mrow>
</msup>
<mrow>
<mo stretchy="false">(</mo>
<mi>𝐘</mi>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<eq></eq>
<ci>𝐲</ci>
<apply>
<times></times>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<ci>g</ci>
<apply>
<minus></minus>
<cn type="integer">1</cn>
</apply>
</apply>
<ci>𝐘</ci>
</apply>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   \mathbf{y}=g^{-1}(\mathbf{Y})
  </annotation>
</semantics>
</math>

 are also independent. 

<math display="inline" id="Independent_component_analysis:114">
<semantics>
<mi>g</mi>
<annotation-xml encoding="MathML-Content">
<ci>g</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   g
  </annotation>
</semantics>
</math>

 is an invertible function, and is the signal model. Note that if the source signal model <a href="probability_density_function" title="wikilink">probability density function</a>
<math display="inline" id="Independent_component_analysis:115">
<semantics>
<msub>
<mi>p</mi>
<mi>s</mi>
</msub>
<annotation-xml encoding="MathML-Content">
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>p</ci>
<ci>s</ci>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   p_{s}
  </annotation>
</semantics>
</math>

 matches the <a href="probability_density_function" title="wikilink">probability density function</a> of the extracted signal 

<math display="inline" id="Independent_component_analysis:116">
<semantics>
<msub>
<mi>p</mi>
<mi>𝐲</mi>
</msub>
<annotation-xml encoding="MathML-Content">
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>p</ci>
<ci>𝐲</ci>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   p_{\mathbf{y}}
  </annotation>
</semantics>
</math>

, then maximizing the joint entropy of 

<math display="inline" id="Independent_component_analysis:117">
<semantics>
<mi>Y</mi>
<annotation-xml encoding="MathML-Content">
<ci>Y</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   Y
  </annotation>
</semantics>
</math>

 also maximizes the amount of <a href="mutual_information" title="wikilink">mutual information</a> between 

<math display="inline" id="Independent_component_analysis:118">
<semantics>
<mi>𝐱</mi>
<annotation-xml encoding="MathML-Content">
<ci>𝐱</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   \mathbf{x}
  </annotation>
</semantics>
</math>

 and 

<math display="inline" id="Independent_component_analysis:119">
<semantics>
<mi>𝐘</mi>
<annotation-xml encoding="MathML-Content">
<ci>𝐘</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   \mathbf{Y}
  </annotation>
</semantics>
</math>

. For this reason, using entropy to extract independent signals is known as <a class="uri" href="infomax" title="wikilink">infomax</a>.</p>

<p>Consider the entropy of the vector variable 

<math display="inline" id="Independent_component_analysis:120">
<semantics>
<mrow>
<mi>𝐘</mi>
<mo>=</mo>
<mrow>
<mi>g</mi>
<mrow>
<mo stretchy="false">(</mo>
<mi>𝐲</mi>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<eq></eq>
<ci>𝐘</ci>
<apply>
<times></times>
<ci>g</ci>
<ci>𝐲</ci>
</apply>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   \mathbf{Y}=g(\mathbf{y})
  </annotation>
</semantics>
</math>

, where 

<math display="inline" id="Independent_component_analysis:121">
<semantics>
<mrow>
<mi>𝐲</mi>
<mo>=</mo>
<mi>𝐖𝐱</mi>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<eq></eq>
<ci>𝐲</ci>
<ci>𝐖𝐱</ci>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   \mathbf{y}=\mathbf{Wx}
  </annotation>
</semantics>
</math>

 is the set of signals extracted by the unmixing matrix 

<math display="inline" id="Independent_component_analysis:122">
<semantics>
<mi>𝐖</mi>
<annotation-xml encoding="MathML-Content">
<ci>𝐖</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   \mathbf{W}
  </annotation>
</semantics>
</math>

. For a finite set of values sampled from a distribution with pdf 

<math display="inline" id="Independent_component_analysis:123">
<semantics>
<msub>
<mi>p</mi>
<mi>𝐲</mi>
</msub>
<annotation-xml encoding="MathML-Content">
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>p</ci>
<ci>𝐲</ci>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   p_{\mathbf{y}}
  </annotation>
</semantics>
</math>

, the entropy of 

<math display="inline" id="Independent_component_analysis:124">
<semantics>
<mi>𝐘</mi>
<annotation-xml encoding="MathML-Content">
<ci>𝐘</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   \mathbf{Y}
  </annotation>
</semantics>
</math>

 can be estimated as:</p>

<p>
<math display="block" id="Independent_component_analysis:125">
<semantics>
<mrow>
<mrow>
<mi>H</mi>
<mrow>
<mo stretchy="false">(</mo>
<mi>𝐘</mi>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
<mo>=</mo>
<mrow>
<mo>-</mo>
<mrow>
<mfrac>
<mn>1</mn>
<mi>N</mi>
</mfrac>
<mrow>
<munderover>
<mo largeop="true" movablelimits="false" symmetric="true">∑</mo>
<mrow>
<mi>t</mi>
<mo>=</mo>
<mn>1</mn>
</mrow>
<mi>N</mi>
</munderover>
<mrow>
<mrow>
<mi>ln</mi>
<msub>
<mi>p</mi>
<mi>𝐘</mi>
</msub>
</mrow>
<mrow>
<mo stretchy="false">(</mo>
<msup>
<mi>𝐘</mi>
<mi>t</mi>
</msup>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
</mrow>
</mrow>
</mrow>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<eq></eq>
<apply>
<times></times>
<ci>H</ci>
<ci>𝐘</ci>
</apply>
<apply>
<minus></minus>
<apply>
<times></times>
<apply>
<divide></divide>
<cn type="integer">1</cn>
<ci>N</ci>
</apply>
<apply>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<sum></sum>
<apply>
<eq></eq>
<ci>t</ci>
<cn type="integer">1</cn>
</apply>
</apply>
<ci>N</ci>
</apply>
<apply>
<times></times>
<apply>
<ln></ln>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>p</ci>
<ci>𝐘</ci>
</apply>
</apply>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<ci>𝐘</ci>
<ci>t</ci>
</apply>
</apply>
</apply>
</apply>
</apply>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   H(\mathbf{Y})=-\frac{1}{N}\sum_{t=1}^{N}\ln p_{\mathbf{Y}}(\mathbf{Y}^{t})
  </annotation>
</semantics>
</math>

 The joint pdf 

<math display="inline" id="Independent_component_analysis:126">
<semantics>
<msub>
<mi>p</mi>
<mi>𝐘</mi>
</msub>
<annotation-xml encoding="MathML-Content">
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>p</ci>
<ci>𝐘</ci>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   p_{\mathbf{Y}}
  </annotation>
</semantics>
</math>

 can be shown to be related to the joint pdf 

<math display="inline" id="Independent_component_analysis:127">
<semantics>
<msub>
<mi>p</mi>
<mi>𝐲</mi>
</msub>
<annotation-xml encoding="MathML-Content">
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>p</ci>
<ci>𝐲</ci>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   p_{\mathbf{y}}
  </annotation>
</semantics>
</math>

 of the extracted signals by the multivariate form:</p>

<p>
<math display="block" id="Independent_component_analysis:128">
<semantics>
<mrow>
<mrow>
<msub>
<mi>p</mi>
<mi>𝐘</mi>
</msub>
<mrow>
<mo stretchy="false">(</mo>
<mi>Y</mi>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
<mo>=</mo>
<mfrac>
<mrow>
<msub>
<mi>p</mi>
<mi>𝐲</mi>
</msub>
<mrow>
<mo stretchy="false">(</mo>
<mi>𝐲</mi>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
<mrow>
<mo stretchy="false">|</mo>
<mfrac>
<mrow>
<mo>∂</mo>
<mi>𝐘</mi>
</mrow>
<mrow>
<mo>∂</mo>
<mi>𝐲</mi>
</mrow>
</mfrac>
<mo stretchy="false">|</mo>
</mrow>
</mfrac>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<eq></eq>
<apply>
<times></times>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>p</ci>
<ci>𝐘</ci>
</apply>
<ci>Y</ci>
</apply>
<apply>
<divide></divide>
<apply>
<times></times>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>p</ci>
<ci>𝐲</ci>
</apply>
<ci>𝐲</ci>
</apply>
<apply>
<abs></abs>
<apply>
<divide></divide>
<apply>
<partialdiff></partialdiff>
<ci>𝐘</ci>
</apply>
<apply>
<partialdiff></partialdiff>
<ci>𝐲</ci>
</apply>
</apply>
</apply>
</apply>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   p_{\mathbf{Y}}(Y)=\frac{p_{\mathbf{y}}(\mathbf{y})}{|\frac{\partial\mathbf{Y}}%
{\partial\mathbf{y}}|}
  </annotation>
</semantics>
</math>
</p>

<p>where 

<math display="inline" id="Independent_component_analysis:129">
<semantics>
<mrow>
<mi>𝐉</mi>
<mo>=</mo>
<mfrac>
<mrow>
<mo>∂</mo>
<mi>𝐘</mi>
</mrow>
<mrow>
<mo>∂</mo>
<mi>𝐲</mi>
</mrow>
</mfrac>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<eq></eq>
<ci>𝐉</ci>
<apply>
<divide></divide>
<apply>
<partialdiff></partialdiff>
<ci>𝐘</ci>
</apply>
<apply>
<partialdiff></partialdiff>
<ci>𝐲</ci>
</apply>
</apply>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   \mathbf{J}=\frac{\partial\mathbf{Y}}{\partial\mathbf{y}}
  </annotation>
</semantics>
</math>

 is the <a href="Jacobian_matrix" title="wikilink">Jacobian matrix</a>. We have 

<math display="inline" id="Independent_component_analysis:130">
<semantics>
<mrow>
<mrow>
<mo stretchy="false">|</mo>
<mi>𝐉</mi>
<mo stretchy="false">|</mo>
</mrow>
<mo>=</mo>
<mrow>
<msup>
<mi>g</mi>
<mo>′</mo>
</msup>
<mrow>
<mo stretchy="false">(</mo>
<mi>𝐲</mi>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<eq></eq>
<apply>
<abs></abs>
<ci>𝐉</ci>
</apply>
<apply>
<times></times>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<ci>g</ci>
<ci>normal-′</ci>
</apply>
<ci>𝐲</ci>
</apply>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   |\mathbf{J}|=g^{\prime}(\mathbf{y})
  </annotation>
</semantics>
</math>

, and 

<math display="inline" id="Independent_component_analysis:131">
<semantics>
<msup>
<mi>g</mi>
<mo>′</mo>
</msup>
<annotation-xml encoding="MathML-Content">
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<ci>g</ci>
<ci>normal-′</ci>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   g^{\prime}
  </annotation>
</semantics>
</math>

 is the pdf assumed for source signals 

<math display="inline" id="Independent_component_analysis:132">
<semantics>
<mrow>
<msup>
<mi>g</mi>
<mo>′</mo>
</msup>
<mo>=</mo>
<msub>
<mi>p</mi>
<mi>s</mi>
</msub>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<eq></eq>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<ci>g</ci>
<ci>normal-′</ci>
</apply>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>p</ci>
<ci>s</ci>
</apply>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   g^{\prime}=p_{s}
  </annotation>
</semantics>
</math>

, therefore,</p>

<p>
<math display="block" id="Independent_component_analysis:133">
<semantics>
<mrow>
<mrow>
<msub>
<mi>p</mi>
<mi>𝐘</mi>
</msub>
<mrow>
<mo stretchy="false">(</mo>
<mi>Y</mi>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
<mo>=</mo>
<mfrac>
<mrow>
<msub>
<mi>p</mi>
<mi>𝐲</mi>
</msub>
<mrow>
<mo stretchy="false">(</mo>
<mi>𝐲</mi>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
<mrow>
<mo stretchy="false">|</mo>
<mfrac>
<mrow>
<mo>∂</mo>
<mi>𝐘</mi>
</mrow>
<mrow>
<mo>∂</mo>
<mi>𝐲</mi>
</mrow>
</mfrac>
<mo stretchy="false">|</mo>
</mrow>
</mfrac>
<mo>=</mo>
<mfrac>
<mrow>
<msub>
<mi>p</mi>
<mi>𝐲</mi>
</msub>
<mrow>
<mo stretchy="false">(</mo>
<mi>𝐲</mi>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
<mrow>
<msub>
<mi>p</mi>
<mi>𝐬</mi>
</msub>
<mrow>
<mo stretchy="false">(</mo>
<mi>𝐲</mi>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
</mfrac>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<and></and>
<apply>
<eq></eq>
<apply>
<times></times>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>p</ci>
<ci>𝐘</ci>
</apply>
<ci>Y</ci>
</apply>
<apply>
<divide></divide>
<apply>
<times></times>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>p</ci>
<ci>𝐲</ci>
</apply>
<ci>𝐲</ci>
</apply>
<apply>
<abs></abs>
<apply>
<divide></divide>
<apply>
<partialdiff></partialdiff>
<ci>𝐘</ci>
</apply>
<apply>
<partialdiff></partialdiff>
<ci>𝐲</ci>
</apply>
</apply>
</apply>
</apply>
</apply>
<apply>
<eq></eq>
<share href="#.cmml">
</share>
<apply>
<divide></divide>
<apply>
<times></times>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>p</ci>
<ci>𝐲</ci>
</apply>
<ci>𝐲</ci>
</apply>
<apply>
<times></times>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>p</ci>
<ci>𝐬</ci>
</apply>
<ci>𝐲</ci>
</apply>
</apply>
</apply>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   p_{\mathbf{Y}}(Y)=\frac{p_{\mathbf{y}}(\mathbf{y})}{|\frac{\partial\mathbf{Y}}%
{\partial\mathbf{y}}|}=\frac{p_{\mathbf{y}}(\mathbf{y})}{p_{\mathbf{s}}(%
\mathbf{y})}
  </annotation>
</semantics>
</math>

 therefore,</p>

<p>
<math display="block" id="Independent_component_analysis:134">
<semantics>
<mrow>
<mrow>
<mi>H</mi>
<mrow>
<mo stretchy="false">(</mo>
<mi>𝐘</mi>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
<mo>=</mo>
<mrow>
<mo>-</mo>
<mrow>
<mfrac>
<mn>1</mn>
<mi>N</mi>
</mfrac>
<mrow>
<munderover>
<mo largeop="true" movablelimits="false" symmetric="true">∑</mo>
<mrow>
<mi>t</mi>
<mo>=</mo>
<mn>1</mn>
</mrow>
<mi>N</mi>
</munderover>
<mrow>
<mi>ln</mi>
<mfrac>
<mrow>
<msub>
<mi>p</mi>
<mi>𝐲</mi>
</msub>
<mrow>
<mo stretchy="false">(</mo>
<mi>𝐲</mi>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
<mrow>
<msub>
<mi>p</mi>
<mi>𝐬</mi>
</msub>
<mrow>
<mo stretchy="false">(</mo>
<mi>𝐲</mi>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
</mfrac>
</mrow>
</mrow>
</mrow>
</mrow>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<eq></eq>
<apply>
<times></times>
<ci>H</ci>
<ci>𝐘</ci>
</apply>
<apply>
<minus></minus>
<apply>
<times></times>
<apply>
<divide></divide>
<cn type="integer">1</cn>
<ci>N</ci>
</apply>
<apply>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<sum></sum>
<apply>
<eq></eq>
<ci>t</ci>
<cn type="integer">1</cn>
</apply>
</apply>
<ci>N</ci>
</apply>
<apply>
<ln></ln>
<apply>
<divide></divide>
<apply>
<times></times>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>p</ci>
<ci>𝐲</ci>
</apply>
<ci>𝐲</ci>
</apply>
<apply>
<times></times>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>p</ci>
<ci>𝐬</ci>
</apply>
<ci>𝐲</ci>
</apply>
</apply>
</apply>
</apply>
</apply>
</apply>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   H(\mathbf{Y})=-\frac{1}{N}\sum_{t=1}^{N}\ln\frac{p_{\mathbf{y}}(\mathbf{y})}{p%
_{\mathbf{s}}(\mathbf{y})}
  </annotation>
</semantics>
</math>
</p>

<p>We know that when 

<math display="inline" id="Independent_component_analysis:135">
<semantics>
<mrow>
<msub>
<mi>p</mi>
<mi>𝐲</mi>
</msub>
<mo>=</mo>
<msub>
<mi>p</mi>
<mi>s</mi>
</msub>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<eq></eq>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>p</ci>
<ci>𝐲</ci>
</apply>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>p</ci>
<ci>s</ci>
</apply>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   p_{\mathbf{y}}=p_{s}
  </annotation>
</semantics>
</math>

, 

<math display="inline" id="Independent_component_analysis:136">
<semantics>
<msub>
<mi>p</mi>
<mi>𝐘</mi>
</msub>
<annotation-xml encoding="MathML-Content">
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>p</ci>
<ci>𝐘</ci>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   p_{\mathbf{Y}}
  </annotation>
</semantics>
</math>

 is of uniform distribution, and 

<math display="inline" id="Independent_component_analysis:137">
<semantics>
<mrow>
<mi>H</mi>
<mrow>
<mo stretchy="false">(</mo>
<mi>𝐘</mi>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<times></times>
<ci>H</ci>
<ci>𝐘</ci>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   H({\mathbf{Y}})
  </annotation>
</semantics>
</math>

 is maximized. Since</p>

<p>
<math display="block" id="Independent_component_analysis:138">
<semantics>
<mrow>
<mrow>
<msub>
<mi>p</mi>
<mi>𝐲</mi>
</msub>
<mrow>
<mo stretchy="false">(</mo>
<mi>𝐲</mi>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
<mo>=</mo>
<mfrac>
<mrow>
<msub>
<mi>p</mi>
<mi>𝐱</mi>
</msub>
<mrow>
<mo stretchy="false">(</mo>
<mi>𝐱</mi>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
<mrow>
<mo stretchy="false">|</mo>
<mfrac>
<mrow>
<mo>∂</mo>
<mi>𝐲</mi>
</mrow>
<mrow>
<mo>∂</mo>
<mi>𝐱</mi>
</mrow>
</mfrac>
<mo stretchy="false">|</mo>
</mrow>
</mfrac>
<mo>=</mo>
<mfrac>
<mrow>
<msub>
<mi>p</mi>
<mi>𝐱</mi>
</msub>
<mrow>
<mo stretchy="false">(</mo>
<mi>𝐱</mi>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
<mrow>
<mo stretchy="false">|</mo>
<mi>𝐖</mi>
<mo stretchy="false">|</mo>
</mrow>
</mfrac>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<and></and>
<apply>
<eq></eq>
<apply>
<times></times>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>p</ci>
<ci>𝐲</ci>
</apply>
<ci>𝐲</ci>
</apply>
<apply>
<divide></divide>
<apply>
<times></times>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>p</ci>
<ci>𝐱</ci>
</apply>
<ci>𝐱</ci>
</apply>
<apply>
<abs></abs>
<apply>
<divide></divide>
<apply>
<partialdiff></partialdiff>
<ci>𝐲</ci>
</apply>
<apply>
<partialdiff></partialdiff>
<ci>𝐱</ci>
</apply>
</apply>
</apply>
</apply>
</apply>
<apply>
<eq></eq>
<share href="#.cmml">
</share>
<apply>
<divide></divide>
<apply>
<times></times>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>p</ci>
<ci>𝐱</ci>
</apply>
<ci>𝐱</ci>
</apply>
<apply>
<abs></abs>
<ci>𝐖</ci>
</apply>
</apply>
</apply>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   p_{\mathbf{y}}(\mathbf{y})=\frac{p_{\mathbf{x}}(\mathbf{x})}{|\frac{\partial%
\mathbf{y}}{\partial\mathbf{x}}|}=\frac{p_{\mathbf{x}}(\mathbf{x})}{|\mathbf{W%
}|}
  </annotation>
</semantics>
</math>

 where 

<math display="inline" id="Independent_component_analysis:139">
<semantics>
<mrow>
<mo stretchy="false">|</mo>
<mi>𝐖</mi>
<mo stretchy="false">|</mo>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<abs></abs>
<ci>𝐖</ci>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   |\mathbf{W}|
  </annotation>
</semantics>
</math>

 is the absolute value of the determinant of the unmixing matix 

<math display="inline" id="Independent_component_analysis:140">
<semantics>
<mi>𝐖</mi>
<annotation-xml encoding="MathML-Content">
<ci>𝐖</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   \mathbf{W}
  </annotation>
</semantics>
</math>

. Therefore,</p>

<p>
<math display="block" id="Independent_component_analysis:141">
<semantics>
<mrow>
<mrow>
<mi>H</mi>
<mrow>
<mo stretchy="false">(</mo>
<mi>𝐘</mi>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
<mo>=</mo>
<mrow>
<mo>-</mo>
<mrow>
<mfrac>
<mn>1</mn>
<mi>N</mi>
</mfrac>
<mrow>
<munderover>
<mo largeop="true" movablelimits="false" symmetric="true">∑</mo>
<mrow>
<mi>t</mi>
<mo>=</mo>
<mn>1</mn>
</mrow>
<mi>N</mi>
</munderover>
<mrow>
<mi>ln</mi>
<mfrac>
<mrow>
<msub>
<mi>p</mi>
<mi>𝐱</mi>
</msub>
<mrow>
<mo stretchy="false">(</mo>
<msup>
<mi>𝐱</mi>
<mi>t</mi>
</msup>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
<mrow>
<mrow>
<mo stretchy="false">|</mo>
<mi>𝐖</mi>
<mo stretchy="false">|</mo>
</mrow>
<msub>
<mi>p</mi>
<mi>𝐬</mi>
</msub>
<mrow>
<mo stretchy="false">(</mo>
<msup>
<mi>𝐲</mi>
<mi>t</mi>
</msup>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
</mfrac>
</mrow>
</mrow>
</mrow>
</mrow>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<eq></eq>
<apply>
<times></times>
<ci>H</ci>
<ci>𝐘</ci>
</apply>
<apply>
<minus></minus>
<apply>
<times></times>
<apply>
<divide></divide>
<cn type="integer">1</cn>
<ci>N</ci>
</apply>
<apply>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<sum></sum>
<apply>
<eq></eq>
<ci>t</ci>
<cn type="integer">1</cn>
</apply>
</apply>
<ci>N</ci>
</apply>
<apply>
<ln></ln>
<apply>
<divide></divide>
<apply>
<times></times>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>p</ci>
<ci>𝐱</ci>
</apply>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<ci>𝐱</ci>
<ci>t</ci>
</apply>
</apply>
<apply>
<times></times>
<apply>
<abs></abs>
<ci>𝐖</ci>
</apply>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>p</ci>
<ci>𝐬</ci>
</apply>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<ci>𝐲</ci>
<ci>t</ci>
</apply>
</apply>
</apply>
</apply>
</apply>
</apply>
</apply>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   H(\mathbf{Y})=-\frac{1}{N}\sum_{t=1}^{N}\ln\frac{p_{\mathbf{x}}(\mathbf{x}^{t}%
)}{|\mathbf{W}|p_{\mathbf{s}}(\mathbf{y}^{t})}
  </annotation>
</semantics>
</math>

 so,</p>

<p>
<math display="block" id="Independent_component_analysis:142">
<semantics>
<mrow>
<mrow>
<mi>H</mi>
<mrow>
<mo stretchy="false">(</mo>
<mi>𝐘</mi>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
<mo>=</mo>
<mrow>
<mrow>
<mfrac>
<mn>1</mn>
<mi>N</mi>
</mfrac>
<mrow>
<munderover>
<mo largeop="true" movablelimits="false" symmetric="true">∑</mo>
<mrow>
<mi>t</mi>
<mo>=</mo>
<mn>1</mn>
</mrow>
<mi>N</mi>
</munderover>
<mrow>
<mrow>
<mi>ln</mi>
<msub>
<mi>p</mi>
<mi>𝐬</mi>
</msub>
</mrow>
<mrow>
<mo stretchy="false">(</mo>
<msup>
<mi>𝐲</mi>
<mi>t</mi>
</msup>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
</mrow>
</mrow>
<mo>+</mo>
<mrow>
<mi>ln</mi>
<mrow>
<mo stretchy="false">|</mo>
<mi>𝐖</mi>
<mo stretchy="false">|</mo>
</mrow>
</mrow>
<mo>+</mo>
<mrow>
<mi>H</mi>
<mrow>
<mo stretchy="false">(</mo>
<mi>𝐱</mi>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
</mrow>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<eq></eq>
<apply>
<times></times>
<ci>H</ci>
<ci>𝐘</ci>
</apply>
<apply>
<plus></plus>
<apply>
<times></times>
<apply>
<divide></divide>
<cn type="integer">1</cn>
<ci>N</ci>
</apply>
<apply>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<sum></sum>
<apply>
<eq></eq>
<ci>t</ci>
<cn type="integer">1</cn>
</apply>
</apply>
<ci>N</ci>
</apply>
<apply>
<times></times>
<apply>
<ln></ln>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>p</ci>
<ci>𝐬</ci>
</apply>
</apply>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<ci>𝐲</ci>
<ci>t</ci>
</apply>
</apply>
</apply>
</apply>
<apply>
<ln></ln>
<apply>
<abs></abs>
<ci>𝐖</ci>
</apply>
</apply>
<apply>
<times></times>
<ci>H</ci>
<ci>𝐱</ci>
</apply>
</apply>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   H(\mathbf{Y})=\frac{1}{N}\sum_{t=1}^{N}\ln p_{\mathbf{s}}(\mathbf{y}^{t})+\ln|%
\mathbf{W}|+H(\mathbf{x})
  </annotation>
</semantics>
</math>

 since 

<math display="inline" id="Independent_component_analysis:143">
<semantics>
<mrow>
<mrow>
<mi>H</mi>
<mrow>
<mo stretchy="false">(</mo>
<mi>𝐱</mi>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
<mo>=</mo>
<mrow>
<mo>-</mo>
<mrow>
<mfrac>
<mn>1</mn>
<mi>N</mi>
</mfrac>
<mrow>
<msubsup>
<mo largeop="true" symmetric="true">∑</mo>
<mrow>
<mi>t</mi>
<mo>=</mo>
<mn>1</mn>
</mrow>
<mi>N</mi>
</msubsup>
<mrow>
<mrow>
<mi>ln</mi>
<msub>
<mi>p</mi>
<mi>𝐱</mi>
</msub>
</mrow>
<mrow>
<mo stretchy="false">(</mo>
<msup>
<mi>𝐱</mi>
<mi>t</mi>
</msup>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
</mrow>
</mrow>
</mrow>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<eq></eq>
<apply>
<times></times>
<ci>H</ci>
<ci>𝐱</ci>
</apply>
<apply>
<minus></minus>
<apply>
<times></times>
<apply>
<divide></divide>
<cn type="integer">1</cn>
<ci>N</ci>
</apply>
<apply>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<sum></sum>
<apply>
<eq></eq>
<ci>t</ci>
<cn type="integer">1</cn>
</apply>
</apply>
<ci>N</ci>
</apply>
<apply>
<times></times>
<apply>
<ln></ln>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>p</ci>
<ci>𝐱</ci>
</apply>
</apply>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<ci>𝐱</ci>
<ci>t</ci>
</apply>
</apply>
</apply>
</apply>
</apply>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   H(\mathbf{x})=-\frac{1}{N}\sum_{t=1}^{N}\ln p_{\mathbf{x}}(\mathbf{x}^{t})
  </annotation>
</semantics>
</math>

, and maximizing 

<math display="inline" id="Independent_component_analysis:144">
<semantics>
<mi>𝐖</mi>
<annotation-xml encoding="MathML-Content">
<ci>𝐖</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   \mathbf{W}
  </annotation>
</semantics>
</math>

 does not affect 

<math display="inline" id="Independent_component_analysis:145">
<semantics>
<msub>
<mi>H</mi>
<mi>𝐱</mi>
</msub>
<annotation-xml encoding="MathML-Content">
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>H</ci>
<ci>𝐱</ci>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   H_{\mathbf{x}}
  </annotation>
</semantics>
</math>

, so we can maximize the function</p>

<p>
<math display="block" id="Independent_component_analysis:146">
<semantics>
<mrow>
<mrow>
<mi>h</mi>
<mrow>
<mo stretchy="false">(</mo>
<mi>𝐘</mi>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
<mo>=</mo>
<mrow>
<mrow>
<mfrac>
<mn>1</mn>
<mi>N</mi>
</mfrac>
<mrow>
<munderover>
<mo largeop="true" movablelimits="false" symmetric="true">∑</mo>
<mrow>
<mi>t</mi>
<mo>=</mo>
<mn>1</mn>
</mrow>
<mi>N</mi>
</munderover>
<mrow>
<mrow>
<mi>ln</mi>
<msub>
<mi>p</mi>
<mi>𝐬</mi>
</msub>
</mrow>
<mrow>
<mo stretchy="false">(</mo>
<msup>
<mi>𝐲</mi>
<mi>t</mi>
</msup>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
</mrow>
</mrow>
<mo>+</mo>
<mrow>
<mi>ln</mi>
<mrow>
<mo stretchy="false">|</mo>
<mi>𝐖</mi>
<mo stretchy="false">|</mo>
</mrow>
</mrow>
</mrow>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<eq></eq>
<apply>
<times></times>
<ci>h</ci>
<ci>𝐘</ci>
</apply>
<apply>
<plus></plus>
<apply>
<times></times>
<apply>
<divide></divide>
<cn type="integer">1</cn>
<ci>N</ci>
</apply>
<apply>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<sum></sum>
<apply>
<eq></eq>
<ci>t</ci>
<cn type="integer">1</cn>
</apply>
</apply>
<ci>N</ci>
</apply>
<apply>
<times></times>
<apply>
<ln></ln>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>p</ci>
<ci>𝐬</ci>
</apply>
</apply>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<ci>𝐲</ci>
<ci>t</ci>
</apply>
</apply>
</apply>
</apply>
<apply>
<ln></ln>
<apply>
<abs></abs>
<ci>𝐖</ci>
</apply>
</apply>
</apply>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   h(\mathbf{Y})=\frac{1}{N}\sum_{t=1}^{N}\ln p_{\mathbf{s}}(\mathbf{y}^{t})+\ln|%
\mathbf{W}|
  </annotation>
</semantics>
</math>

 to achieve the independence of extracted signal.</p>

<p>If there are <em>M</em> marginal pdfs of the model joint pdf 

<math display="inline" id="Independent_component_analysis:147">
<semantics>
<msub>
<mi>p</mi>
<mi>𝐬</mi>
</msub>
<annotation-xml encoding="MathML-Content">
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>p</ci>
<ci>𝐬</ci>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   p_{\mathbf{s}}
  </annotation>
</semantics>
</math>

 are independent and use the commonly super-gaussian model pdf for the source signals 

<math display="inline" id="Independent_component_analysis:148">
<semantics>
<mrow>
<msub>
<mi>p</mi>
<mi>𝐬</mi>
</msub>
<mo>=</mo>
<mrow>
<mo stretchy="false">(</mo>
<mn>1</mn>
<mo>-</mo>
<mi>tanh</mi>
<msup>
<mrow>
<mo stretchy="false">(</mo>
<mi>𝐬</mi>
<mo stretchy="false">)</mo>
</mrow>
<mn>2</mn>
</msup>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
<annotation-xml encoding="MathML-Content">
<cerror>
<csymbol cd="ambiguous">fragments</csymbol>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>p</ci>
<ci>𝐬</ci>
</apply>
<eq></eq>
<cerror>
<csymbol cd="ambiguous">fragments</csymbol>
<ci>normal-(</ci>
<cn type="integer">1</cn>
<minus></minus>
<tanh></tanh>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<cerror>
<csymbol cd="ambiguous">fragments</csymbol>
<ci>normal-(</ci>
<csymbol cd="unknown">s</csymbol>
<ci>normal-)</ci>
</cerror>
<cn type="integer">2</cn>
</apply>
<ci>normal-)</ci>
</cerror>
</cerror>
</annotation-xml>
<annotation encoding="application/x-tex">
   p_{\mathbf{s}}=(1-\tanh(\mathbf{s})^{2})
  </annotation>
</semantics>
</math>

, then we have</p>

<p>
<math display="block" id="Independent_component_analysis:149">
<semantics>
<mrow>
<mi>h</mi>
<mrow>
<mo stretchy="false">(</mo>
<mi>𝐘</mi>
<mo stretchy="false">)</mo>
</mrow>
<mo>=</mo>
<mfrac>
<mn>1</mn>
<mi>N</mi>
</mfrac>
<munderover>
<mo largeop="true" movablelimits="false" symmetric="true">∑</mo>
<mrow>
<mi>i</mi>
<mo>=</mo>
<mn>1</mn>
</mrow>
<mi>M</mi>
</munderover>
<munderover>
<mo largeop="true" movablelimits="false" symmetric="true">∑</mo>
<mrow>
<mi>t</mi>
<mo>=</mo>
<mn>1</mn>
</mrow>
<mi>N</mi>
</munderover>
<mi>ln</mi>
<mrow>
<mo stretchy="false">(</mo>
<mn>1</mn>
<mo>-</mo>
<mi>tanh</mi>
<msup>
<mrow>
<mo stretchy="false">(</mo>
<msubsup>
<mi>𝐰</mi>
<mi>𝐢</mi>
<mi>𝐓</mi>
</msubsup>
<msup>
<mi>𝐱</mi>
<mi>𝐭</mi>
</msup>
<mo stretchy="false">)</mo>
</mrow>
<mn>2</mn>
</msup>
<mo stretchy="false">)</mo>
</mrow>
<mo>+</mo>
<mi>ln</mi>
<mo stretchy="false">|</mo>
<mi>𝐖</mi>
<mo stretchy="false">|</mo>
</mrow>
<annotation-xml encoding="MathML-Content">
<cerror>
<csymbol cd="ambiguous">fragments</csymbol>
<csymbol cd="unknown">h</csymbol>
<cerror>
<csymbol cd="ambiguous">fragments</csymbol>
<ci>normal-(</ci>
<csymbol cd="unknown">Y</csymbol>
<ci>normal-)</ci>
</cerror>
<eq></eq>
<apply>
<divide></divide>
<cn type="integer">1</cn>
<ci>N</ci>
</apply>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<sum></sum>
<apply>
<eq></eq>
<ci>i</ci>
<cn type="integer">1</cn>
</apply>
</apply>
<ci>M</ci>
</apply>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<sum></sum>
<apply>
<eq></eq>
<ci>t</ci>
<cn type="integer">1</cn>
</apply>
</apply>
<ci>N</ci>
</apply>
<ln></ln>
<cerror>
<csymbol cd="ambiguous">fragments</csymbol>
<ci>normal-(</ci>
<cn type="integer">1</cn>
<minus></minus>
<tanh></tanh>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<cerror>
<csymbol cd="ambiguous">fragments</csymbol>
<ci>normal-(</ci>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>𝐰</ci>
<ci>𝐢</ci>
</apply>
<ci>𝐓</ci>
</apply>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<ci>𝐱</ci>
<ci>𝐭</ci>
</apply>
<ci>normal-)</ci>
</cerror>
<cn type="integer">2</cn>
</apply>
<ci>normal-)</ci>
</cerror>
<plus></plus>
<ln></ln>
<ci>normal-|</ci>
<csymbol cd="unknown">W</csymbol>
<ci>normal-|</ci>
</cerror>
</annotation-xml>
<annotation encoding="application/x-tex">
   h(\mathbf{Y})=\frac{1}{N}\sum_{i=1}^{M}\sum_{t=1}^{N}\ln(1-\tanh(\mathbf{w_{i}%
^{T}x^{t}})^{2})+\ln|\mathbf{W}|
  </annotation>
</semantics>
</math>
</p>

<p>In the sum, given an observed signal mixture 

<math display="inline" id="Independent_component_analysis:150">
<semantics>
<mi>𝐱</mi>
<annotation-xml encoding="MathML-Content">
<ci>𝐱</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   \mathbf{x}
  </annotation>
</semantics>
</math>

, the corresponding set of extracted signals 

<math display="inline" id="Independent_component_analysis:151">
<semantics>
<mi>𝐲</mi>
<annotation-xml encoding="MathML-Content">
<ci>𝐲</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   \mathbf{y}
  </annotation>
</semantics>
</math>

 and source signal model 

<math display="inline" id="Independent_component_analysis:152">
<semantics>
<mrow>
<msub>
<mi>p</mi>
<mi>𝐬</mi>
</msub>
<mo>=</mo>
<msup>
<mi>g</mi>
<mo>′</mo>
</msup>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<eq></eq>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>p</ci>
<ci>𝐬</ci>
</apply>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<ci>g</ci>
<ci>normal-′</ci>
</apply>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   p_{\mathbf{s}}=g^{\prime}
  </annotation>
</semantics>
</math>

, we can find the optimal unmixing matrix 

<math display="inline" id="Independent_component_analysis:153">
<semantics>
<mi>𝐖</mi>
<annotation-xml encoding="MathML-Content">
<ci>𝐖</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   \mathbf{W}
  </annotation>
</semantics>
</math>

, and make the extracted signals independent and non-gaussian. Like the projection pursuit situation, we can use gradient descent method to find the optimal solution of the unmixing matrix.</p>
<h3 id="independent-component-analysis-based-on-maximum-likelihood-estimation">Independent Component Analysis based on <a href="Maximum_Likelihood" title="wikilink">Maximum Likelihood</a> Estimation <a class="footnoteRef" href="#fn12" id="fnref12"><sup>12</sup></a></h3>

<p><strong><a href="Maximum_likelihood" title="wikilink">Maximum likelihood</a> estimation (MLE)</strong> is a standard statistical tool for finding parameter values (e.g. the unmixing matrix 

<math display="inline" id="Independent_component_analysis:154">
<semantics>
<mi>𝐖</mi>
<annotation-xml encoding="MathML-Content">
<ci>𝐖</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   \mathbf{W}
  </annotation>
</semantics>
</math>

) that provide the best fit of some data (e.g., the extracted signals 

<math display="inline" id="Independent_component_analysis:155">
<semantics>
<mi>y</mi>
<annotation-xml encoding="MathML-Content">
<ci>y</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   y
  </annotation>
</semantics>
</math>

) to a given a model (e.g., the assumed joint probability density function (pdf) 

<math display="inline" id="Independent_component_analysis:156">
<semantics>
<msub>
<mi>p</mi>
<mi>s</mi>
</msub>
<annotation-xml encoding="MathML-Content">
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>p</ci>
<ci>s</ci>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   p_{s}
  </annotation>
</semantics>
</math>

 of source signals).</p>

<p>The <strong>ML</strong> “model” includes a specification of a pdf, which in this case is the pdf 

<math display="inline" id="Independent_component_analysis:157">
<semantics>
<msub>
<mi>p</mi>
<mi>s</mi>
</msub>
<annotation-xml encoding="MathML-Content">
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>p</ci>
<ci>s</ci>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   p_{s}
  </annotation>
</semantics>
</math>

 of the unknown source signals 

<math display="inline" id="Independent_component_analysis:158">
<semantics>
<mi>s</mi>
<annotation-xml encoding="MathML-Content">
<ci>s</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   s
  </annotation>
</semantics>
</math>

. Using <strong>ML ICA</strong>, the objective is to find an unmixing matrix that yields extracted signals 

<math display="inline" id="Independent_component_analysis:159">
<semantics>
<mrow>
<mi>y</mi>
<mo>=</mo>
<mrow>
<mi>𝐖</mi>
<mi>x</mi>
</mrow>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<eq></eq>
<ci>y</ci>
<apply>
<times></times>
<ci>𝐖</ci>
<ci>x</ci>
</apply>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   y=\mathbf{W}x
  </annotation>
</semantics>
</math>

 with a joint pdf as similar as possible to the joint pdf 

<math display="inline" id="Independent_component_analysis:160">
<semantics>
<msub>
<mi>p</mi>
<mi>s</mi>
</msub>
<annotation-xml encoding="MathML-Content">
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>p</ci>
<ci>s</ci>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   p_{s}
  </annotation>
</semantics>
</math>

 of the unknown source signals 

<math display="inline" id="Independent_component_analysis:161">
<semantics>
<mi>s</mi>
<annotation-xml encoding="MathML-Content">
<ci>s</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   s
  </annotation>
</semantics>
</math>

.</p>

<p><strong>MLE</strong> is thus based on the assumption that if the model pdf 

<math display="inline" id="Independent_component_analysis:162">
<semantics>
<msub>
<mi>p</mi>
<mi>s</mi>
</msub>
<annotation-xml encoding="MathML-Content">
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>p</ci>
<ci>s</ci>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   p_{s}
  </annotation>
</semantics>
</math>

 and the model parameters 

<math display="inline" id="Independent_component_analysis:163">
<semantics>
<mi>𝐀</mi>
<annotation-xml encoding="MathML-Content">
<ci>𝐀</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   \mathbf{A}
  </annotation>
</semantics>
</math>

 are correct then a high probability should be obtained for the data 

<math display="inline" id="Independent_component_analysis:164">
<semantics>
<mi>x</mi>
<annotation-xml encoding="MathML-Content">
<ci>x</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   x
  </annotation>
</semantics>
</math>

 that were actually observed. Conversely, if 

<math display="inline" id="Independent_component_analysis:165">
<semantics>
<mi>𝐀</mi>
<annotation-xml encoding="MathML-Content">
<ci>𝐀</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   \mathbf{A}
  </annotation>
</semantics>
</math>

 is far from the correct parameter values then a low probability of the observed data would be expected.</p>

<p>Using <strong>MLE</strong>, we call the probability of the observed data for a given set of model parameter values (e.g., a pdf 

<math display="inline" id="Independent_component_analysis:166">
<semantics>
<msub>
<mi>p</mi>
<mi>s</mi>
</msub>
<annotation-xml encoding="MathML-Content">
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>p</ci>
<ci>s</ci>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   p_{s}
  </annotation>
</semantics>
</math>

 and a matrix 

<math display="inline" id="Independent_component_analysis:167">
<semantics>
<mi>𝐀</mi>
<annotation-xml encoding="MathML-Content">
<ci>𝐀</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   \mathbf{A}
  </annotation>
</semantics>
</math>

) the <em>likelihood</em> of the model parameter values given the observed data.</p>

<p>We define a <em>likelihood</em> function 

<math display="inline" id="Independent_component_analysis:168">
<semantics>
<mrow>
<mi>𝐋</mi>
<mrow>
<mo stretchy="false">(</mo>
<mi>𝐖</mi>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<times></times>
<ci>𝐋</ci>
<ci>𝐖</ci>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   \mathbf{L(W)}
  </annotation>
</semantics>
</math>

 of 

<math display="inline" id="Independent_component_analysis:169">
<semantics>
<mi>𝐖</mi>
<annotation-xml encoding="MathML-Content">
<ci>𝐖</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   \mathbf{W}
  </annotation>
</semantics>
</math>

:</p>

<p>
<math display="inline" id="Independent_component_analysis:170">
<semantics>
<mrow>
<mrow>
<mrow>
<mi>𝐋</mi>
<mrow>
<mo stretchy="false">(</mo>
<mi>𝐖</mi>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
<mo>=</mo>
<mrow>
<msub>
<mi>p</mi>
<mi>s</mi>
</msub>
<mrow>
<mo stretchy="false">(</mo>
<mrow>
<mi>𝐖</mi>
<mi>x</mi>
</mrow>
<mo stretchy="false">)</mo>
</mrow>
<mrow>
<mo stretchy="false">|</mo>
<mi>𝐖</mi>
<mo stretchy="false">|</mo>
</mrow>
</mrow>
</mrow>
<mo>.</mo>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<eq></eq>
<apply>
<times></times>
<ci>𝐋</ci>
<ci>𝐖</ci>
</apply>
<apply>
<times></times>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>p</ci>
<ci>s</ci>
</apply>
<apply>
<times></times>
<ci>𝐖</ci>
<ci>x</ci>
</apply>
<apply>
<abs></abs>
<ci>𝐖</ci>
</apply>
</apply>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   \mathbf{L(W)}=p_{s}(\mathbf{W}x)|\mathbf{W}|.
  </annotation>
</semantics>
</math>
</p>

<p>Thus, if we wish to find a 

<math display="inline" id="Independent_component_analysis:171">
<semantics>
<mi>𝐖</mi>
<annotation-xml encoding="MathML-Content">
<ci>𝐖</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   \mathbf{W}
  </annotation>
</semantics>
</math>

 that is most likely to have generated the observed mixtures 

<math display="inline" id="Independent_component_analysis:172">
<semantics>
<mi>x</mi>
<annotation-xml encoding="MathML-Content">
<ci>x</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   x
  </annotation>
</semantics>
</math>

 from the unknown source signals 

<math display="inline" id="Independent_component_analysis:173">
<semantics>
<mi>s</mi>
<annotation-xml encoding="MathML-Content">
<ci>s</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   s
  </annotation>
</semantics>
</math>

 with pdf 

<math display="inline" id="Independent_component_analysis:174">
<semantics>
<msub>
<mi>p</mi>
<mi>s</mi>
</msub>
<annotation-xml encoding="MathML-Content">
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>p</ci>
<ci>s</ci>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   p_{s}
  </annotation>
</semantics>
</math>

 then we need only find that 

<math display="inline" id="Independent_component_analysis:175">
<semantics>
<mi>𝐖</mi>
<annotation-xml encoding="MathML-Content">
<ci>𝐖</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   \mathbf{W}
  </annotation>
</semantics>
</math>

 which maximizes the <em>likelihood</em>
<math display="inline" id="Independent_component_analysis:176">
<semantics>
<mrow>
<mi>𝐋</mi>
<mrow>
<mo stretchy="false">(</mo>
<mi>𝐖</mi>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<times></times>
<ci>𝐋</ci>
<ci>𝐖</ci>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   \mathbf{L(W)}
  </annotation>
</semantics>
</math>

. The unmixing matrix that maximizes equation is known as the <strong>MLE</strong> of the optimal unmixing matrix.</p>

<p>It is common practice to use the log <em>likelihood</em>, because this is easier to evaluate. As the logarithm is a monotonic function, the 

<math display="inline" id="Independent_component_analysis:177">
<semantics>
<mi>𝐖</mi>
<annotation-xml encoding="MathML-Content">
<ci>𝐖</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   \mathbf{W}
  </annotation>
</semantics>
</math>

 that maximizes the function 

<math display="inline" id="Independent_component_analysis:178">
<semantics>
<mrow>
<mi>𝐋</mi>
<mrow>
<mo stretchy="false">(</mo>
<mi>𝐖</mi>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<times></times>
<ci>𝐋</ci>
<ci>𝐖</ci>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   \mathbf{L(W)}
  </annotation>
</semantics>
</math>

 also maximizes its logarithm 

<math display="inline" id="Independent_component_analysis:179">
<semantics>
<mrow>
<mrow>
<mi>ln</mi>
<mi>𝐋</mi>
</mrow>
<mrow>
<mo stretchy="false">(</mo>
<mi>𝐖</mi>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<times></times>
<apply>
<ln></ln>
<ci>𝐋</ci>
</apply>
<ci>𝐖</ci>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   \ln\mathbf{L(W)}
  </annotation>
</semantics>
</math>

. This allows us to take the logarithm of equation above, which yields the log <em>likelihood</em> function</p>

<p>
<math display="inline" id="Independent_component_analysis:180">
<semantics>
<mrow>
<mrow>
<mrow>
<mi>ln</mi>
<mi>𝐋</mi>
</mrow>
<mrow>
<mo stretchy="false">(</mo>
<mi>𝐖</mi>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
<mo>=</mo>
<mrow>
<mrow>
<msub>
<mo largeop="true" symmetric="true">∑</mo>
<mi>i</mi>
</msub>
<mrow>
<msub>
<mo largeop="true" symmetric="true">∑</mo>
<mi>t</mi>
</msub>
<mrow>
<mrow>
<mi>ln</mi>
<msub>
<mi>p</mi>
<mi>s</mi>
</msub>
</mrow>
<mrow>
<mo stretchy="false">(</mo>
<mrow>
<msubsup>
<mi>w</mi>
<mi>i</mi>
<mi>T</mi>
</msubsup>
<msub>
<mi>x</mi>
<mi>t</mi>
</msub>
</mrow>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
</mrow>
</mrow>
<mo>+</mo>
<mrow>
<mi>N</mi>
<mrow>
<mi>ln</mi>
<mrow>
<mo stretchy="false">|</mo>
<mi>𝐖</mi>
<mo stretchy="false">|</mo>
</mrow>
</mrow>
</mrow>
</mrow>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<eq></eq>
<apply>
<times></times>
<apply>
<ln></ln>
<ci>𝐋</ci>
</apply>
<ci>𝐖</ci>
</apply>
<apply>
<plus></plus>
<apply>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<sum></sum>
<ci>i</ci>
</apply>
<apply>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<sum></sum>
<ci>t</ci>
</apply>
<apply>
<times></times>
<apply>
<ln></ln>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>p</ci>
<ci>s</ci>
</apply>
</apply>
<apply>
<times></times>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<ci>w</ci>
<ci>T</ci>
</apply>
<ci>i</ci>
</apply>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>x</ci>
<ci>t</ci>
</apply>
</apply>
</apply>
</apply>
</apply>
<apply>
<times></times>
<ci>N</ci>
<apply>
<ln></ln>
<apply>
<abs></abs>
<ci>𝐖</ci>
</apply>
</apply>
</apply>
</apply>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   \ln\mathbf{L(W)}=\sum_{i}\sum_{t}\ln p_{s}(w^{T}_{i}x_{t})+N\ln|\mathbf{W}|
  </annotation>
</semantics>
</math>
</p>

<p>If we substitute a commonly used high-<a class="uri" href="Kurtosis" title="wikilink">Kurtosis</a> model pdf for the source signals 

<math display="inline" id="Independent_component_analysis:181">
<semantics>
<mrow>
<msub>
<mi>p</mi>
<mi>s</mi>
</msub>
<mo>=</mo>
<mrow>
<mo stretchy="false">(</mo>
<mn>1</mn>
<mo>-</mo>
<mi>tanh</mi>
<msup>
<mrow>
<mo stretchy="false">(</mo>
<mi>s</mi>
<mo stretchy="false">)</mo>
</mrow>
<mn>2</mn>
</msup>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
<annotation-xml encoding="MathML-Content">
<cerror>
<csymbol cd="ambiguous">fragments</csymbol>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>p</ci>
<ci>s</ci>
</apply>
<eq></eq>
<cerror>
<csymbol cd="ambiguous">fragments</csymbol>
<ci>normal-(</ci>
<cn type="integer">1</cn>
<minus></minus>
<tanh></tanh>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<cerror>
<csymbol cd="ambiguous">fragments</csymbol>
<ci>normal-(</ci>
<csymbol cd="unknown">s</csymbol>
<ci>normal-)</ci>
</cerror>
<cn type="integer">2</cn>
</apply>
<ci>normal-)</ci>
</cerror>
</cerror>
</annotation-xml>
<annotation encoding="application/x-tex">
   p_{s}=(1-\tanh(s)^{2})
  </annotation>
</semantics>
</math>

 then we have</p>

<p>
<math display="inline" id="Independent_component_analysis:182">
<semantics>
<mrow>
<mi>ln</mi>
<mi>𝐋</mi>
<mrow>
<mo stretchy="false">(</mo>
<mi>𝐖</mi>
<mo stretchy="false">)</mo>
</mrow>
<mo>=</mo>
<mfrac>
<mn>1</mn>
<mi>N</mi>
</mfrac>
<msubsup>
<mo largeop="true" symmetric="true">∑</mo>
<mi>i</mi>
<mi>M</mi>
</msubsup>
<msubsup>
<mo largeop="true" symmetric="true">∑</mo>
<mi>t</mi>
<mi>N</mi>
</msubsup>
<mi>ln</mi>
<mrow>
<mo stretchy="false">(</mo>
<mn>1</mn>
<mo>-</mo>
<mi>tanh</mi>
<msup>
<mrow>
<mo stretchy="false">(</mo>
<msubsup>
<mi>w</mi>
<mi>i</mi>
<mi>T</mi>
</msubsup>
<msub>
<mi>x</mi>
<mi>t</mi>
</msub>
<mo stretchy="false">)</mo>
</mrow>
<mn>2</mn>
</msup>
<mo stretchy="false">)</mo>
</mrow>
<mo>+</mo>
<mi>ln</mi>
<mo stretchy="false">|</mo>
<mi>𝐖</mi>
<mo stretchy="false">|</mo>
</mrow>
<annotation-xml encoding="MathML-Content">
<cerror>
<csymbol cd="ambiguous">fragments</csymbol>
<ln></ln>
<csymbol cd="unknown">L</csymbol>
<cerror>
<csymbol cd="ambiguous">fragments</csymbol>
<ci>normal-(</ci>
<csymbol cd="unknown">W</csymbol>
<ci>normal-)</ci>
</cerror>
<eq></eq>
<apply>
<divide></divide>
<cn type="integer">1</cn>
<ci>N</ci>
</apply>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<sum></sum>
<ci>i</ci>
</apply>
<ci>M</ci>
</apply>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<sum></sum>
<ci>t</ci>
</apply>
<ci>N</ci>
</apply>
<ln></ln>
<cerror>
<csymbol cd="ambiguous">fragments</csymbol>
<ci>normal-(</ci>
<cn type="integer">1</cn>
<minus></minus>
<tanh></tanh>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<cerror>
<csymbol cd="ambiguous">fragments</csymbol>
<ci>normal-(</ci>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<ci>w</ci>
<ci>T</ci>
</apply>
<ci>i</ci>
</apply>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>x</ci>
<ci>t</ci>
</apply>
<ci>normal-)</ci>
</cerror>
<cn type="integer">2</cn>
</apply>
<ci>normal-)</ci>
</cerror>
<plus></plus>
<ln></ln>
<ci>normal-|</ci>
<csymbol cd="unknown">W</csymbol>
<ci>normal-|</ci>
</cerror>
</annotation-xml>
<annotation encoding="application/x-tex">
   \ln\mathbf{L(W)}={1\over N}\sum_{i}^{M}\sum_{t}^{N}\ln(1-\tanh(w^{T}_{i}x_{t})%
^{2})+\ln|\mathbf{W}|
  </annotation>
</semantics>
</math>
</p>

<p>This matrix 

<math display="inline" id="Independent_component_analysis:183">
<semantics>
<mi>𝐖</mi>
<annotation-xml encoding="MathML-Content">
<ci>𝐖</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   \mathbf{W}
  </annotation>
</semantics>
</math>

 that maximizes this function is the <strong><em><a href="maximum_likelihood" title="wikilink">maximum likelihood</a> estimation</em></strong>.</p>
<h2 id="history-and-background">History and background</h2>

<p>The general framework for independent component analysis was introduced by Jeanny Herault and Christian Jutten in 1986 and was most clearly stated by Pierre Comon in 1994. In 1995, Tony Bell and <a href="Terry_Sejnowski" title="wikilink">Terry Sejnowski</a> introduced a fast and efficient ICA algorithm based on <a class="uri" href="infomax" title="wikilink">infomax</a>, a principle introduced by Ralph Linsker in 1987.</p>

<p>There are many algorithms available in the literature which do ICA. A largely used one, including in industrial applications, is the FastICA algorithm, developed by Aapo Hyvärinen and Erkki Oja, which uses the <a class="uri" href="kurtosis" title="wikilink">kurtosis</a> as cost function. Other examples are rather related to <a href="blind_source_separation" title="wikilink">blind source separation</a> where a more general approach is used. For example, one can drop the independence assumption and separate mutually correlated signals, thus, statistically "dependent" signals. Sepp Hochreiter and <a href="Jürgen_Schmidhuber" title="wikilink">Jürgen Schmidhuber</a> showed how to obtain non-linear ICA or <a href="source_separation" title="wikilink">source separation</a> as a by-product of <a href="regularization_(mathematics)" title="wikilink">regularization</a> (1999). Their method does not require a priori knowledge about the number of independent sources..</p>
<h2 id="applications">Applications</h2>

<p>ICA can be extended to analyze non-physical signals. For instance, ICA has been applied to discover discussion topics on a bag of news list archives.</p>

<p>Some ICA applications are listed below:<a class="footnoteRef" href="#fn13" id="fnref13"><sup>13</sup></a> </p>
<ul>
<li>optical Imaging of neurons<a class="footnoteRef" href="#fn14" id="fnref14"><sup>14</sup></a></li>
<li>neuronal spike sorting<a class="footnoteRef" href="#fn15" id="fnref15"><sup>15</sup></a></li>
<li>face recognition<a class="footnoteRef" href="#fn16" id="fnref16"><sup>16</sup></a></li>
<li>modeling receptive fields of primary visual neurons<a class="footnoteRef" href="#fn17" id="fnref17"><sup>17</sup></a></li>
<li>predicting stock market prices<a class="footnoteRef" href="#fn18" id="fnref18"><sup>18</sup></a></li>
<li>mobile phone communications <a class="footnoteRef" href="#fn19" id="fnref19"><sup>19</sup></a></li>
<li>color based detection of the ripeness of tomatoes<a class="footnoteRef" href="#fn20" id="fnref20"><sup>20</sup></a></li>
<li>removing artifacts, such as eye blinks, from <a class="uri" href="EEG" title="wikilink">EEG</a> data.<a class="footnoteRef" href="#fn21" id="fnref21"><sup>21</sup></a></li>
</ul>
<h2 id="see-also">See also</h2>
<ul>
<li><a href="Blind_deconvolution" title="wikilink">Blind deconvolution</a></li>
<li><a href="Factor_analysis" title="wikilink">Factor analysis</a></li>
<li><a href="Hilbert_spectrum" title="wikilink">Hilbert spectrum</a></li>
<li><a href="Image_processing" title="wikilink">Image processing</a></li>
<li><a href="Multilinear_principal_component_analysis" title="wikilink">Multilinear PCA</a></li>
<li><a href="Multilinear_subspace_learning" title="wikilink">Multilinear subspace learning</a></li>
<li><a href="Non-negative_matrix_factorization" title="wikilink">Non-negative matrix factorization (NMF)</a></li>
<li><a href="Nonlinear_dimensionality_reduction" title="wikilink">Nonlinear dimensionality reduction</a></li>
<li><a href="Projection_pursuit" title="wikilink">Projection pursuit</a></li>
<li><a href="Varimax_rotation" title="wikilink">Varimax rotation</a></li>
</ul>
<h2 id="notes">Notes</h2>
<h2 id="references">References</h2>
<ul>
<li>Comon, Pierre (1994): <a href="http://mlsp.cs.cmu.edu/courses/fall2012/lectures/ICA.pdf">"Independent Component Analysis: a new concept?"</a>, <em>Signal Processing</em>, 36(3):287–314 (The original paper describing the concept of ICA)</li>
<li>Hyvärinen, A.; Karhunen, J.; Oja, E. (2001): <em><a href="http://www.cis.hut.fi/projects/ica/book/">Independent Component Analysis</a></em>, New York: Wiley, ISBN 978-0-471-40540-5 ( <a href="http://www.cis.hut.fi/projects/ica/book/intro.pdf">Introductory chapter</a> )</li>
<li>Hyvärinen, A.; Oja, E. (2000): <a href="http://www.cs.helsinki.fi/u/ahyvarin/papers/NN00new.pdf">"Independent Component Analysis: Algorithms and Application"</a>, <em>Neural Networks</em>, 13(4-5):411-430. (Technical but pedagogical introduction).</li>
<li>Comon, P.; Jutten C., (2010): Handbook of Blind Source Separation, Independent Component Analysis and Applications. Academic Press, Oxford UK. ISBN 978-0-12-374726-6</li>
<li>Lee, T.-W. (1998): <em>Independent component analysis: Theory and applications</em>, Boston, Mass: Kluwer Academic Publishers, ISBN 0-7923-8261-7</li>
<li>Acharyya, Ranjan (2008): <em>A New Approach for Blind Source Separation of Convolutive Sources - Wavelet Based Separation Using Shrinkage Function</em> ISBN 3-639-07797-0 ISBN 978-3639077971 (this book focuses on unsupervised learning with Blind Source Separation)</li>
</ul>
<h2 id="external-links">External links</h2>
<ul>
<li><a href="http://www.cs.helsinki.fi/u/ahyvarin/whatisica.shtml">What is independent component analysis?</a> by Aapo Hyvärinen</li>
<li><a href="http://www.cis.hut.fi/aapo/papers/IJCNN99_tutorialweb/IJCNN99_tutorial3.html">Independent Component Analysis: A Tutorial</a> by Aapo Hyvärinen</li>
<li><a href="http://arxiv.org/abs/1404.2986">A Tutorial on Independent Component Analysis</a></li>
<li><a href="http://www.cis.hut.fi/projects/ica/fastica/">FastICA as a package for Matlab, in R language, C++</a></li>
<li><a href="http://www.bsp.brain.riken.go.jp/ICALAB/">ICALAB Toolboxes</a> for Matlab, developed at <a class="uri" href="RIKEN" title="wikilink">RIKEN</a></li>
<li><a href="http://nic.uoregon.edu/projects/hipersat/index.php">High Performance Signal Analysis Toolkit</a> provides C++ implementations of FastICA and Infomax</li>
<li><a href="http://isp.imm.dtu.dk/toolbox/">ICA toolbox</a> Matlab tools for ICA with Bell-Sejnowski, Molgedey-Schuster and mean field ICA. Developed at DTU.</li>
<li><a href="http://www.cis.hut.fi/projects/ica/cocktail/cocktail_en.cgi">Demonstration of the cocktail party problem</a></li>
<li><a href="http://sccn.ucsd.edu/eeglab/">EEGLAB Toolbox</a> ICA of <a href="electroencephalogram" title="wikilink">EEG</a> for Matlab, developed at UCSD.</li>
<li><a href="http://sccn.ucsd.edu/fmrlab/">FMRLAB Toolbox</a> ICA of <a class="uri" href="fMRI" title="wikilink">fMRI</a> for Matlab, developed at UCSD</li>
<li><a href="http://brandon-merkl.blogspot.com/2005/12/independent-component-analysis.html">Discussion of ICA used in a biomedical shape-representation context</a></li>
<li><a href="http://mdp-toolkit.sourceforge.net/">FastICA, CuBICA, JADE and TDSEP algorithm for Python and more...</a></li>
<li><a href="http://icatb.sourceforge.net/">Group ICA Toolbox and Fusion ICA Toolbox</a></li>
<li><a href="http://www.nbtwiki.net/doku.php?id=tutorial:compute_independent_component_analysis">Tutorial: Using ICA for cleaning EEG signals</a></li>
</ul>

<p>"</p>

<p><a href="Category:Signal_processing" title="wikilink">Category:Signal processing</a> <a href="Category:Data_analysis" title="wikilink">Category:Data analysis</a> <a href="Category:Time_series_analysis" title="wikilink">Category:Time series analysis</a> <a href="Category:Statistical_models" title="wikilink">Category:Statistical models</a> <a href="Category:Multivariate_statistics" title="wikilink">Category:Multivariate statistics</a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1"><a href="#fnref1">↩</a></li>
<li id="fn2">Johan Himbergand Aapo Hyvärinen, <em><a href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.11.8895">Independent Component Analysis For Binary Data: An Experimental Study</a></em>, Proc. Int. Workshop on Independent Component Analysis and Blind Signal Separation (ICA2001), San Diego, California, 2001.<a href="#fnref2">↩</a></li>
<li id="fn3">Huy Nguyen and Rong Zheng, <em><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5753957">Binary Independent Component Analysis With or Mixtures</a></em>, IEEE Transactions on Signal Processing, Vol. 59, Issue 7. (July 2011), pp. 3168–3181.<a href="#fnref3">↩</a></li>
<li id="fn4"><a href="#fnref4">↩</a></li>
<li id="fn5">James V. Stone(2004); "Independent Component Analysis: A Tutorial Introduction", The MIT Press Cambridge, Massachusetts, London, England; ISBN 0-262-69315-1<a href="#fnref5">↩</a></li>
<li id="fn6"></li>
<li id="fn7">Kruskal, JB. 1969; "Toward a practical method which helps uncover the structure of a set of observations by finding the line transformation which optimizes a new "index of condensation", Pages 427–440 of: Milton, RC, &amp; Nelder, JA (eds), Statistical computation; New York, Academic Press<a href="#fnref7">↩</a></li>
<li id="fn8"><a href="#fnref8">↩</a></li>
<li id="fn9"><a href="#fnref9">↩</a></li>
<li id="fn10"><a href="#fnref10">↩</a></li>
<li id="fn11">James V. Stone(2004); "Independent Component Analysis: A Tutorial Introduction", The MIT Press Cambridge, Massachusetts, London, England; ISBN 0-262-69315-1<a href="#fnref11">↩</a></li>
<li id="fn12"></li>
<li id="fn13"></li>
<li id="fn14"><a href="#fnref14">↩</a></li>
<li id="fn15"><a href="#fnref15">↩</a></li>
<li id="fn16"><a href="#fnref16">↩</a></li>
<li id="fn17"><a href="#fnref17">↩</a></li>
<li id="fn18"><a href="#fnref18">↩</a></li>
<li id="fn19"><a href="#fnref19">↩</a></li>
<li id="fn20"><a href="#fnref20">↩</a></li>
<li id="fn21"><a href="#fnref21">↩</a></li>
</ol>
</section>
</body>
</html>
