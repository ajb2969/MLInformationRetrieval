


Coskewness




Coskewness

In probability theory and statistics, coskewness is a measure of how much two random variables change together. Coskewness is the third standardized cross central moment, related to skewness as covariance is related to variance. In 1976, Krauss and Litzenberger used it to examine risk in stock market investments.1 The application to risk was extended by Harvey and Siddique in 2000.2
If two random variables exhibit positive coskewness they will tend to undergo extreme positive deviations at the same time. Similarly, if two random variables exhibit negative coskewness they will tend to undergo extreme negative deviations at the same time.
Definition
For two random variables X and Y there are two non-trivial coskewness statistics: 3



and



where E[X] is the expected value of X, also known as the mean of X, and 
 
 
 
  is the standard deviation of X.
Properties
Skewness is a special case of the coskewness when the two random variables are identical:



For two random variables, X and Y, the skewness of the sum, X + Y, is



where SX is the skewness of X and 
 
 
 
  is the standard deviation of X. It follows that the sum of two random variables can be asymmetric (SX+Y ≠ 0) even if both random variables are symmetric in isolation SX = 0 and SY = 0).
The coskewness between variables X and Y does not depend on the scale on which the variables are expressed. If we are analyzing the relationship between X and Y, the coskewness between X and Y will be the same as the coskewness between a + bX and c + dY, where a, b, c, and d are constants.
See also

Moment (mathematics)

References
Further reading




"
Category:Algebra of random variables Category:Theory of probability distributions



↩
↩
↩




