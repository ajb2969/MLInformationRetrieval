<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="708">Neural gas</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>Neural gas</h1>
<hr/>

<p><strong>Neural gas</strong> is an <a href="artificial_neural_network" title="wikilink">artificial neural network</a>, inspired by the <a href="self-organizing_map" title="wikilink">self-organizing map</a> and introduced in 1991 by <a href="Thomas_Martinetz" title="wikilink">Thomas Martinetz</a> and <a href="Klaus_Schulten" title="wikilink">Klaus Schulten</a>.<a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a> The neural gas is a simple algorithm for finding optimal data representations based on <a href="feature_vector" title="wikilink">feature vectors</a>. The algorithm was coined "neural gas" because of the dynamics of the feature vectors during the adaptation process, which distribute themselves like a gas within the data space. It is applied where <a href="data_compression" title="wikilink">data compression</a> or <a href="vector_quantization" title="wikilink">vector quantization</a> is an issue, for example <a href="speech_recognition" title="wikilink">speech recognition</a>,<a class="footnoteRef" href="#fn2" id="fnref2"><sup>2</sup></a> <a href="image_processing" title="wikilink">image processing</a><a class="footnoteRef" href="#fn3" id="fnref3"><sup>3</sup></a> or <a href="pattern_recognition" title="wikilink">pattern recognition</a>. As a robustly converging alternative to the <a href="k-means_clustering" title="wikilink">k-means clustering</a> it is also used for <a href="cluster_analysis" title="wikilink">cluster analysis</a>.<a class="footnoteRef" href="#fn4" id="fnref4"><sup>4</sup></a></p>
<h2 id="algorithm">Algorithm</h2>

<p>Given a <a href="probability_distribution" title="wikilink">probability distribution</a> <em>P(x)</em> of data vectors <em>x</em> and a finite number of <a href="feature_vector" title="wikilink">feature vectors</a> <em>w<sub>i</sub>, i=1,...,N</em>.</p>

<p>With each time step <em>t</em> a data vector randomly chosen from <em>P</em> is presented. Subsequently, the distance order of the feature vectors to the given data vector <em>x</em> is determined. <em>i<sub>0</sub></em> denotes the index of the closest feature vector, <em>i<sub>1</sub></em> the index of the second closest feature vector etc. and <em>i<sub>N-1</sub></em> the index of the feature vector most distant to <em>x</em>. Then each feature vector (<em>k=0,...,N-1</em>) is adapted according to</p>
<center>

<p>

<math display="inline" id="Neural_gas:0">
 <semantics>
  <mrow>
   <msubsup>
    <mi>w</mi>
    <msub>
     <mi>i</mi>
     <mi>k</mi>
    </msub>
    <mrow>
     <mi>t</mi>
     <mo>+</mo>
     <mn>1</mn>
    </mrow>
   </msubsup>
   <mo>=</mo>
   <mrow>
    <msubsup>
     <mi>w</mi>
     <msub>
      <mi>i</mi>
      <mi>k</mi>
     </msub>
     <mi>t</mi>
    </msubsup>
    <mo>+</mo>
    <mrow>
     <mi>ε</mi>
     <mo>⋅</mo>
     <msup>
      <mi>e</mi>
      <mrow>
       <mo>-</mo>
       <mrow>
        <mi>k</mi>
        <mo>/</mo>
        <mi>λ</mi>
       </mrow>
      </mrow>
     </msup>
     <mo>⋅</mo>
     <mrow>
      <mo stretchy="false">(</mo>
      <mrow>
       <mi>x</mi>
       <mo>-</mo>
       <msubsup>
        <mi>w</mi>
        <msub>
         <mi>i</mi>
         <mi>k</mi>
        </msub>
        <mi>t</mi>
       </msubsup>
      </mrow>
      <mo stretchy="false">)</mo>
     </mrow>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <csymbol cd="ambiguous">superscript</csymbol>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>w</ci>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>i</ci>
       <ci>k</ci>
      </apply>
     </apply>
     <apply>
      <plus></plus>
      <ci>t</ci>
      <cn type="integer">1</cn>
     </apply>
    </apply>
    <apply>
     <plus></plus>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>w</ci>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <ci>i</ci>
        <ci>k</ci>
       </apply>
      </apply>
      <ci>t</ci>
     </apply>
     <apply>
      <ci>normal-⋅</ci>
      <ci>ε</ci>
      <apply>
       <csymbol cd="ambiguous">superscript</csymbol>
       <ci>e</ci>
       <apply>
        <minus></minus>
        <apply>
         <divide></divide>
         <ci>k</ci>
         <ci>λ</ci>
        </apply>
       </apply>
      </apply>
      <apply>
       <minus></minus>
       <ci>x</ci>
       <apply>
        <csymbol cd="ambiguous">superscript</csymbol>
        <apply>
         <csymbol cd="ambiguous">subscript</csymbol>
         <ci>w</ci>
         <apply>
          <csymbol cd="ambiguous">subscript</csymbol>
          <ci>i</ci>
          <ci>k</ci>
         </apply>
        </apply>
        <ci>t</ci>
       </apply>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   w_{i_{k}}^{t+1}=w_{i_{k}}^{t}+\varepsilon\cdot e^{-k/\lambda}\cdot(x-w_{i_{k}}%
^{t})
  </annotation>
 </semantics>
</math>

</p>
</center>

<p>with ε as the adaptation step size and λ as the so-called neighborhood range. ε and λ are reduced with increasing <em>t</em>. After sufficiently many adaptation steps the feature vectors cover the data space with minimum representation error.<a class="footnoteRef" href="#fn5" id="fnref5"><sup>5</sup></a></p>

<p>The adaptation step of the neural gas can be interpreted as <a href="gradient_descent" title="wikilink">gradient descent</a> on a <a href="Loss_function" title="wikilink">cost function</a>. By adapting not only the closest feature vector but all of them with a step size decreasing with increasing distance order, compared to (online) <a href="k-means_clustering" title="wikilink">k-means clustering</a> a much more robust convergence of the algorithm can be achieved. The neural gas model does not delete a node and also does not create new nodes.</p>
<h2 id="further-reading">Further reading</h2>
<ul>
<li>T. Martinetz, S. Berkovich, and K. Schulten. "Neural-gas" Network for Vector Quantization and its Application to Time-Series Prediction. IEEE-Transactions on Neural Networks, 4(4):558-569, 1993.</li>
<li>T. Martinetz and K. Schulten. Topology representing networks. Neural Networks, 7(3):507-522, 1994.</li>
</ul>
<h2 id="references">References</h2>
<h2 id="external-links">External links</h2>
<ul>
<li><a href="http://www.demogng.de">DemoGNG</a> Java applet which demonstrates neural gas, growing neural gas, self-organizing maps and other methods related to competitive learning.</li>
<li><a href="http://homepages.feis.herts.ac.uk/~nngroup/software.php">Java Competitive Learning Applications</a> Unsupervised Neural Networks (including Self-organizing map) in Java with source codes.</li>
<li><a href="http://wwwold.ini.rub.de/VDM/research/gsn/JavaPaper/node16.html">Neural gas algorithm</a></li>
</ul>

<p>"</p>

<p><a href="Category:Artificial_neural_networks" title="wikilink">Category:Artificial neural networks</a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1"><a href="#fnref1">↩</a></li>
<li id="fn2"><a href="#fnref2">↩</a></li>
<li id="fn3"><a href="#fnref3">↩</a></li>
<li id="fn4"><a href="#fnref4">↩</a></li>
<li id="fn5"><a class="uri" href="http://wwwold.ini.rub.de/VDM/research/gsn/JavaPaper/img187.gif">http://wwwold.ini.rub.de/VDM/research/gsn/JavaPaper/img187.gif</a><a href="#fnref5">↩</a></li>
</ol>
</section>
</body>
</html>
