   Le Cam's theorem      Le Cam's theorem   In probability theory , Le Cam's theorem , named after Lucien le Cam (1924 – 2000), states the following.  Suppose:   X 1 , ..., X n are independent  random variables , each with a Bernoulli distribution (i.e., equal to either 0 or 1), not necessarily identically distributed.    Pr( X i = 1) = p i for i = 1, 2, 3, ...          λ  n   =    p  1   +  ⋯  +   p  n     .       subscript  λ  n      subscript  p  1   normal-⋯   subscript  p  n      \lambda_{n}=p_{1}+\cdots+p_{n}.\,             S  n   =    X  1   +  ⋯  +   X  n     .       subscript  S  n      subscript  X  1   normal-⋯   subscript  X  n      S_{n}=X_{1}+\cdots+X_{n}.\,   (i.e.    S  n     subscript  S  n    S_{n}   follows a Poisson binomial distribution )   Then         ∑   k  =  0   ∞    |    Pr   (    S  n   =  k   )    -     λ  n  k    e   -   λ  n       k  !     |    <   2    ∑   i  =  1   n    p  i  2      .        superscript   subscript     k  0           Pr     subscript  S  n   k         superscript   subscript  λ  n   k    superscript  e     subscript  λ  n        k         2    superscript   subscript     i  1    n    superscript   subscript  p  i   2       \sum_{k=0}^{\infty}\left|\Pr(S_{n}=k)-{\lambda_{n}^{k}e^{-\lambda_{n}}\over k!%
 }\right|<2\sum_{i=1}^{n}p_{i}^{2}.     In other words, the sum has approximately a Poisson distribution and the above inequality bounds the approximation error in terms of the total variation distance .  By setting p i = λ n / n , we see that this generalizes the usual Poisson limit theorem .  References       External links     "  Category:Probability theorems  Category:Probabilistic inequalities  Category:Statistical inequalities  Category:Statistical theorems   