   Lindley's paradox      Lindley's paradox   Lindley's paradox is a counterintuitive situation in statistics in which the Bayesian and frequentist approaches to a hypothesis testing problem give different results for certain choices of the prior distribution . The problem of the disagreement between the two approaches was discussed in Harold Jeffreys ' 1939 textbook; 1 it became known as Lindley's paradox after Dennis Lindley called the disagreement a paradox in a 1957 paper. 2  Although referred to as a paradox , the differing results from the Bayesian and frequentist approaches can be explained as using them to answer fundamentally different questions, rather than actual disagreement between the two methods.  Description of the paradox  Consider the result   x   x   \textstyle x   of some experiment, with two possible explanations, hypotheses    H  0     subscript  H  0    \textstyle H_{0}   and    H  1     subscript  H  1    \textstyle H_{1}   , and some prior distribution   π   π   \textstyle\pi   representing uncertainty as to which hypothesis is more accurate before taking into account   x   x   \textstyle x   .  Lindley's paradox occurs when   The result   x   x   \textstyle x   is "significant" by a frequentist test of    H  0     subscript  H  0    \textstyle H_{0}   , indicating sufficient evidence to reject    H  0     subscript  H  0    \textstyle H_{0}   , say, at the 5% level, and  The posterior probability of    H  0     subscript  H  0    \textstyle H_{0}   given   x   x   \textstyle x   is high, indicating strong evidence that    H  0     subscript  H  0    \textstyle H_{0}   is in better agreement with   x   x   \textstyle x   than    H  1     subscript  H  1    \textstyle H_{1}   .   These results can occur at the same time when    H  0     subscript  H  0    \textstyle H_{0}   is very specific,    H  1     subscript  H  1    \textstyle H_{1}   more diffuse, and the prior distribution does not strongly favor one or the other, as seen below.  Numerical example  We can illustrate Lindley's paradox with a numerical example. Imagine a certain city where 49,581 boys and 48,870 girls have been born over a certain time period. The observed proportion   x   x   \textstyle x   of male births is thus 49,581/98,451 ≈ 0.5036. We assume the number of male births is a binomial variable with parameter   θ   θ   \textstyle\theta   . We are interested in testing whether   θ   θ   \textstyle\theta   is 0.5 or some other value. That is, our null hypothesis is     H  0   :   θ  =  0.5      normal-:   subscript  H  0     θ  0.5     \textstyle H_{0}:\theta=0.5   and the alternative is     H  1   :   θ  ≠  0.5      normal-:   subscript  H  1     θ  0.5     \textstyle H_{1}:\theta\neq 0.5   .  Frequentist approach  The frequentist approach to testing    H  0     subscript  H  0    \textstyle H_{0}   is to compute a p-value , the probability of observing a fraction of boys at least as large as   x   x   \textstyle x   assuming    H  0     subscript  H  0    \textstyle H_{0}   is true. Because the number of births is very large, we can use a normal approximation for the fraction of male births    X  ∼   N   (  μ  ,   σ  2   )       similar-to  X    N   μ   superscript  σ  2       \textstyle X\sim N(\mu,\sigma^{2})   , with     μ  =   n  p   =   n  θ   =  98   ,    451  ×  0.5   =   49  ,  225.5       formulae-sequence      μ    n  p          n  θ        98        451  0.5    49  225.5      \textstyle\mu=np=n\theta=98,451\times 0.5=49,225.5   and      σ  2   =   n  θ   (   1  -  θ   )    =  98   ,    451  ×  0.5  ×  0.5   =   24  ,  612.75       formulae-sequence       superscript  σ  2     n  θ    1  θ         98        451  0.5  0.5    24  612.75      \textstyle\sigma^{2}=n\theta(1-\theta)=98,451\times 0.5\times 0.5=24,612.75   , to compute      P   (  X  ≥  x  ∣  μ  =  49222.5  )   =    ∫   x  =  49581   98451      1    2  π   σ  2        e   -     (    u  -  μ   σ   )   2   /  2     d  u     fragments  P   fragments  normal-(  X   x  normal-∣  μ   49222.5  normal-)     superscript   subscript     x  49581    98451     1      2  π   superscript  σ  2       superscript  e       superscript      u  μ   σ   2   2     d  u    \displaystyle P(X\geq x\mid\mu=49222.5)=\int_{x=49581}^{98451}\frac{1}{\sqrt{2%
 \pi\sigma^{2}}}e^{-(\frac{u-\mu}{\sigma})^{2}/2}du     We would have been equally surprised if we had seen 49,581 female births, i.e.    x  ≈  0.4964      x  0.4964    \textstyle x\approx 0.4964   , so a frequentist would usually perform a two-sided test, for which the p-value would be    p  ≈   2  ×  0.0117   =  0.0235        p    2  0.0117        0.0235     \textstyle p\approx 2\times 0.0117=0.0235   . In both cases, the p-value is lower than the significance level of 5%, so the frequentist approach rejects    H  0     subscript  H  0    \textstyle H_{0}   as it disagrees with the observed data.  Bayesian approach  Assuming no reason to favor one hypothesis over the other, the Bayesian approach would be to assign prior probabilities     π   (   H  0   )    =   π   (   H  1   )    =  0.5          π   subscript  H  0      π   subscript  H  1         0.5     \textstyle\pi(H_{0})=\pi(H_{1})=0.5   and a uniform distribution to   θ   θ   \textstyle\theta   under    H  1     subscript  H  1    H_{1}   , and then to compute the posterior probability of    H  0     subscript  H  0    \textstyle H_{0}   using Bayes' theorem ,      P   (   H  0   ∣  k  )   =    P   (  k  ∣   H  0   )   π   (   H  0   )     P   (  k  ∣   H  0   )   π   (   H  0   )   +  P   (  k  ∣   H  1   )   π   (   H  1   )     .     fragments  P   fragments  normal-(   subscript  H  0   normal-∣  k  normal-)       fragments  P   fragments  normal-(  k  normal-∣   subscript  H  0   normal-)   π   fragments  normal-(   subscript  H  0   normal-)     fragments  P   fragments  normal-(  k  normal-∣   subscript  H  0   normal-)   π   fragments  normal-(   subscript  H  0   normal-)    P   fragments  normal-(  k  normal-∣   subscript  H  1   normal-)   π   fragments  normal-(   subscript  H  1   normal-)     normal-.    P(H_{0}\mid k)=\frac{P(k\mid H_{0})\pi(H_{0})}{P(k\mid H_{0})\pi(H_{0})+P(k%
 \mid H_{1})\pi(H_{1})}.     After observing    k  =   49  ,  581       k   49  581     \textstyle k=49,581   boys out of    n  =   98  ,  451       n   98  451     \textstyle n=98,451   births, we can compute the posterior probability of each hypothesis using the probability mass function for a binomial variable,      P   (  k  ∣   H  0   )      fragments  P   fragments  normal-(  k  normal-∣   subscript  H  0   normal-)     \displaystyle P(k\mid H_{0})   where     \Beta    (  a  ,  b  )       \Beta   a  b     \textstyle\mathrm{\Beta}(a,b)   is the Beta function .  From these values, we find the posterior probability of    P   (   H  0   ∣  k  )   ≈  0.95     fragments  P   fragments  normal-(   subscript  H  0   normal-∣  k  normal-)    0.95    P(\textstyle H_{0}\mid k)\approx 0.95   , which strongly favors    H  0     subscript  H  0    \textstyle H_{0}   over    H  1     subscript  H  1    \textstyle H_{1}   .  The two approaches—the Bayesian and the frequentist—appear to be in conflict, and this is the "paradox".  The lack of an actual paradox  The apparent disagreement between the two approaches is caused by a combination of factors. First, the frequentist approach above tests    H  0     subscript  H  0    \textstyle H_{0}   without reference to    H  1     subscript  H  1    \textstyle H_{1}   . The Bayesian approach evaluates    H  0     subscript  H  0    \textstyle H_{0}   as an alternative to    H  1     subscript  H  1    \textstyle H_{1}   , and finds the first to be in better agreement with the observations. This is because the latter hypothesis is much more diffuse, as   θ   θ   \textstyle\theta   can be anywhere in    [  0  ,  1  ]     0  1    \textstyle[0,1]   , which results in it having a very low posterior probability. To understand why, it is helpful to consider the two hypotheses as generators of the observations:   Under    H  0     subscript  H  0    \textstyle H_{0}   , we choose    θ  ≈  0.500      θ  0.500    \textstyle\theta\approx 0.500   , and ask how likely it is to see 49,581 boys in 98,451 births.  Under    H  1     subscript  H  1    \textstyle H_{1}   , we choose   θ   θ   \textstyle\theta   randomly from anywhere within 0 to 1, and ask the same question.   Most of the possible values for   θ   θ   \textstyle\theta   under    H  1     subscript  H  1    \textstyle H_{1}   are very poorly supported by the observations. In essence, the apparent disagreement between the methods is not a disagreement at all, but rather two different statements about how the hypotheses relate to the data:   The frequentist finds that    H  0     subscript  H  0    \textstyle H_{0}   is a poor explanation for the observation.  The Bayesian finds that    H  0     subscript  H  0    \textstyle H_{0}   is a far better explanation for the observation than    H  1     subscript  H  1    \textstyle H_{1}   .   The ratio of the sex of newborns is improbably 50/50 male/female, according the frequentist test. Yet 50/50 is a better approximation than most, but not all , other ratios. The hypothesis    θ  ≈  0.504      θ  0.504    \textstyle\theta\approx 0.504   would have fit the observation much better than almost all other ratios, including    θ  ≈  0.500      θ  0.500    \textstyle\theta\approx 0.500   .  For example, this choice of hypotheses and prior probabilities implies the statement: "if   θ   θ   \textstyle\theta   > 0.49 and   θ   θ   \textstyle\theta   \theta being exactly 0.5 is 0.50/0.51   ≈     \approx   98%." Given such a strong preference for    θ  =  0.5      θ  0.5    \theta=0.5   , it is easy to see why the Bayesian approach favors    H  0     subscript  H  0    H_{0}   in the face of    x  ≈  0.5036      x  0.5036    x\approx 0.5036   , even though the observed value of   x   x   x   lies    2.28  σ      2.28  σ    2.28\sigma   away from 0.5. The deviation of over 2 sigma from    H  0     subscript  H  0    H_{0}   is considered significant in the frequentist approach, but its significance is overruled by the prior in the Bayesian approach.  Looking at it another way, we can see that the prior distribution is essentially flat with a delta function at    θ  =  0.5      θ  0.5    \textstyle\theta=0.5   . Clearly this is dubious. In fact if you were to picture real numbers as being continuous, then it would be more logical to assume that it would impossible for any given number to be exactly the parameter value, i.e., we should assume P(theta = 0.5) = 0.  A more realistic distribution for   θ   θ   \textstyle\theta   in the alternative hypothesis produces a less surprising result for the posterior of    H  0     subscript  H  0    \textstyle H_{0}   . For example, if we replace    H  1     subscript  H  1    \textstyle H_{1}   with     H  2   :   θ  =  x      normal-:   subscript  H  2     θ  x     \textstyle H_{2}:\theta=x   , i.e., the maximum likelihood estimate for   θ   θ   \textstyle\theta   , the posterior probability of    H  0     subscript  H  0    \textstyle H_{0}   would be only 0.07 compared to 0.93 for    H  2     subscript  H  2    \textstyle H_{2}   (Of course, one cannot actually use the MLE as part of a prior distribution).  Reconciling the Bayesian and frequentist approaches  If one uses an uninformative prior and tests a hypothesis more similar to that in the frequentist approach, the paradox disappears.  For example, if we calculate the posterior distribution    P   (  θ  ∣  x  ,  n  )      fragments  P   fragments  normal-(  θ  normal-∣  x  normal-,  n  normal-)     \textstyle P(\theta\mid x,n)   , using a uniform prior distribution on   θ   θ   \textstyle\theta   (i.e.,    π   (  θ  ∈   [  0  ,  1  ]   )   =  1     fragments  π   fragments  normal-(  θ    fragments  normal-[  0  normal-,  1  normal-]   normal-)    1    \textstyle\pi(\theta\in[0,1])=1   ), we find      P   (  θ  ∣  k  ,  n  )   =   \Beta    (  k  +  1  ,  n  -  k  +  1  )   .     fragments  P   fragments  normal-(  θ  normal-∣  k  normal-,  n  normal-)    \Beta   fragments  normal-(  k   1  normal-,  n   k   1  normal-)   normal-.    P(\theta\mid k,n)=\mathrm{\Beta}(k+1,n-k+1).     If we use this to check the probability that a newborn is more likely to be a boy than a girl, i.e.,    P   (  θ  >  0.5  ∣  k  ,  n  )      fragments  P   fragments  normal-(  θ   0.5  normal-∣  k  normal-,  n  normal-)     P(\theta>0.5\mid k,n)   , we find            ∫  0.5  1     \Beta    (  49582  ,  48871  )     ≈  0.983.        superscript   subscript   0.5   1     \Beta   49582  48871     0.983.    \int_{0.5}^{1}\mathrm{\Beta}(49582,48871)\approx 0.983.     In other words, it is very likely that the proportion of male births is above 0.5.  Neither analysis gives an estimate of the effect size , directly, but both could be used to determine, for instance, if the fraction of boy births is likely to be above some particular threshold.  Recent discussion  The paradox continues to be a source of active discussion. 3  See also   Bayes factor   Notes  References     "  Category:Hypothesis testing  Category:Statistical paradoxes  Category:Statistical inference     ↩  ↩   ↩     