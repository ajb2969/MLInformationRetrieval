<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="1972">Influence diagram</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>Influence diagram</h1>
<hr/>

<p>An <strong>influence diagram (ID)</strong> (also called a <strong>relevance diagram</strong>, <strong>decision diagram</strong> or a <strong>decision network</strong>) is a compact graphical and mathematical representation of a decision situation. It is a generalization of a <a href="Bayesian_network" title="wikilink">Bayesian network</a>, in which not only <a href="bayesian_inference" title="wikilink">probabilistic inference</a> problems but also <a href="decision_making" title="wikilink">decision making</a> problems (following <a href="expected_utility" title="wikilink">maximum expected utility</a> criterion) can be modeled and solved.</p>

<p>ID was first developed in mid-1970s within the <a href="decision_analysis" title="wikilink">decision analysis</a> community with an intuitive semantic that is easy to understand. It is now adopted widely and becoming an alternative to <a href="decision_tree" title="wikilink">decision tree</a> which typically suffers from <a href="exponential_growth" title="wikilink">exponential growth</a> in number of branches with each variable modeled. ID is directly applicable in <a href="team_theory" title="wikilink">team decision analysis</a>, since it allows incomplete sharing of information among team members to be modeled and solved explicitly. Extension of ID also find its use in <a href="game_theory" title="wikilink">game theory</a> as an alternative representation of <a href="game_tree" title="wikilink">game tree</a>.</p>
<h2 id="semantics">Semantics</h2>

<p>An ID is a <a href="directed_acyclic_graph" title="wikilink">directed acyclic graph</a> with three types (plus one subtype) of <a href="graph_node" title="wikilink">node</a> and three types of <a href="graph_arc" title="wikilink">arc</a> (or arrow) between nodes.</p>

<p>Nodes;</p>

<p>:*<em><a href="Decision_making" title="wikilink">Decision</a> node</em> (corresponding to each decision to be made) is drawn as a rectangle.</p>

<p>:*<em><a class="uri" href="Uncertainty" title="wikilink">Uncertainty</a> node</em> (corresponding to each uncertainty to be modeled) is drawn as an oval.</p>

<p>::*<em>Deterministic node</em> (corresponding to special kind of uncertainty that its outcome is deterministically known whenever the outcome of some other uncertainties are also known) is drawn as a double oval.</p>

<p>:*<em>Value node</em> (corresponding to each component of additively separable <a href="Von_Neumann-Morgenstern_utility" title="wikilink">Von Neumann-Morgenstern utility</a> function) is drawn as an octagon (or diamond).</p>

<p>Arcs;</p>

<p>:*<em>Functional arcs</em> (ending in value node) indicate that one of the components of additively separable utility function is a function of all the nodes at their tails.</p>

<p>:*<em>Conditional arcs</em> (ending in uncertainty node) indicate that the uncertainty at their heads is <a href="conditional_probability" title="wikilink">probabilistically conditioned</a> on all the nodes at their tails.</p>

<p>::*<em>Conditional arcs</em> (ending in deterministic node) indicate that the uncertainty at their heads is deterministically conditioned on all the nodes at their tails.</p>

<p>:*<em>Informational arcs</em> (ending in decision node) indicate that the decision at their heads is made with the outcome of all the nodes at their tails known beforehand.</p>

<p>Given a properly structured ID;</p>

<p>:*Decision nodes and incoming information arcs collectively state the <em>alternatives</em> (what can be done when the outcome of certain decisions and/or uncertainties are known beforehand)</p>

<p>:*Uncertainty/deterministic nodes and incoming conditional arcs collectively model the <em>information</em> (what are known and their probabilistic/deterministic relationships)</p>

<p>:*Value nodes and incoming functional arcs collectively quantify the <em>preference</em> (how things are preferred over one another).</p>

<p><em>Alternative, information, and preference</em> are termed <em>decision basis</em> in decision analysis, they represent three required components of any valid decision situation.</p>

<p>Formally, the semantic of influence diagram is based on sequential construction of nodes and arcs, which implies a specification of all conditional independencies in the diagram. The specification is defined by the 

<math display="inline" id="Influence_diagram:0">
 <semantics>
  <mi>d</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>d</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   d
  </annotation>
 </semantics>
</math>

-separation criterion of Bayesian network. According to this semantic, every node is probabilistically independent on its non-successor nodes given the outcome of its immediate predecessor nodes. Likewise, a missing arc between non-value node 

<math display="inline" id="Influence_diagram:1">
 <semantics>
  <mi>X</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>X</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   X
  </annotation>
 </semantics>
</math>

 and non-value node 

<math display="inline" id="Influence_diagram:2">
 <semantics>
  <mi>Y</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>Y</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   Y
  </annotation>
 </semantics>
</math>

 implies that there exists a set of non-value nodes 

<math display="inline" id="Influence_diagram:3">
 <semantics>
  <mi>Z</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>Z</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   Z
  </annotation>
 </semantics>
</math>

, e.g., the parents of 

<math display="inline" id="Influence_diagram:4">
 <semantics>
  <mi>Y</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>Y</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   Y
  </annotation>
 </semantics>
</math>

, that renders 

<math display="inline" id="Influence_diagram:5">
 <semantics>
  <mi>Y</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>Y</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   Y
  </annotation>
 </semantics>
</math>

 independent of 

<math display="inline" id="Influence_diagram:6">
 <semantics>
  <mi>X</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>X</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   X
  </annotation>
 </semantics>
</math>

 given the outcome of the nodes in 

<math display="inline" id="Influence_diagram:7">
 <semantics>
  <mi>Z</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>Z</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   Z
  </annotation>
 </semantics>
</math>

.</p>
<h2 id="example">Example</h2>
<figure><b>(Figure)</b>
<figcaption>Simple influence diagram for making decision about vacation activity</figcaption>
</figure>

<p>Consider the simple influence diagram representing a situation where a decision-maker is planning her vacation.</p>

<p>:*There is 1 decision node (<em>Vacation Activity</em>), 2 uncertainty nodes (<em>Weather Condition, Weather Forecast</em>), and 1 value node (<em>Satisfaction</em>).</p>

<p>:*There are 2 functional arcs (ending in <em>Satisfaction</em>), 1 conditional arc (ending in <em>Weather Forecast</em>), and 1 informational arc (ending in <em>Vacation Activity</em>).</p>

<p>:*Functional arcs ending in <em>Satisfaction</em> indicate that <em>Satisfaction</em> is a utility function of <em>Weather Condition</em> and <em>Vacation Activity</em>. In other words, her satisfaction can be quantified if she knows what the weather is like and what her choice of activity is. (Note that she does not value <em>Weather Forecast</em> directly)</p>

<p>:*Conditional arc ending in <em>Weather Forecast</em> indicates her belief that <em>Weather Forecast</em> and <em>Weather Condition</em> can be dependent.</p>

<p>:*Informational arc ending in <em>Vacation Activity</em> indicates that she will only know <em>Weather Forecast</em>, not <em>Weather Condition</em>, when making her choice. In other words, actual weather will be known after she makes her choice, and only forecast is what she can count on at this stage.</p>

<p>:*It also follows semantically, for example, that <em>Vacation Activity</em> is independent on (irrelevant to) <em>Weather Condition</em> given <em>Weather Forecast</em> is known.</p>
<h2 id="applicability-in-value-of-information">Applicability in value of information</h2>

<p>The above example highlights the power of influence diagram in representing an extremely important concept in decision analysis known as <a href="value_of_information" title="wikilink">value of information</a>. Consider the following three scenarios;</p>

<p>:*Scenario 1: The decision-maker could make her <em>Vacation Activity</em> decision while knowing what <em>Weather Condition</em> will be like. This corresponds to adding extra informational arc from <em>Weather Condition</em> to <em>Vacation Activity</em> in the above influence diagram.</p>

<p>:*Scenario 2: The original influence diagram as shown above.</p>

<p>:*Scenario 3: The decision-maker makes her decision without even knowing the <em>Weather Forecast</em>. This corresponds to removing informational arc from <em>Weather Forecast</em> to <em>Vacation Activity</em> in the above influence diagram.</p>

<p>Scenario 1 is the best possible scenario for this decision situation since there is no longer any uncertainty on what she cares about (<em>Weather Condition</em>) when making her decision. Scenario 3, however, is the worst possible scenario for this decision situation since she needs to make her decision without any hint (<em>Weather Forecast</em>) on what she cares about (<em>Weather Condition</em>) will turn out to be.</p>

<p>The decision-maker is usually better off (definitely no worse off) to move from scenario 3 to scenario 2 through the acquisition of new information. The most she should be willing to pay for such move is called <a href="value_of_information" title="wikilink">value of information</a> on <em>Weather Forecast</em>, which is essentially <a href="value_of_imperfect_information" title="wikilink">value of imperfect information</a> on <em>Weather Condition</em>.</p>

<p>Likewise, it is the best for the decision-maker to move from scenario 3 to scenario 1. The most she should be willing to pay for such move is called <a href="value_of_perfect_information" title="wikilink">value of perfect information</a> on <em>Weather Condition</em>.</p>

<p>The applicability of this simple ID and the value of information concept is tremendous, especially in <a href="Decision-making" title="wikilink">medical decision making</a> when most decisions have to be made with imperfect information about patients, diseases, etc.</p>
<h2 id="notes">Notes</h2>

<p>Influence diagrams are hierarchical and can be defined either in terms of their structure or in greater detail in terms of the functional and numerical relation between diagram elements. An ID that is consistently defined at all levels—structure, function, and number—is a well-defined mathematical representation and is referred to as a <em>well-formed influence diagram</em> (WFID). WFIDs can be evaluated using <a href="Node_reversal" title="wikilink">reversal</a> and <a href="Node_removal" title="wikilink">removal</a> operations to yield answers to a large class of probabilistic, inferential, and decision questions. More recent techniques have been developed by <a href="artificial_intelligence" title="wikilink">artificial intelligence</a> community with their works around <a href="Bayesian_inference" title="wikilink">Bayesian network inference</a> (<a href="Belief_propagation" title="wikilink">Belief propagation</a>).</p>

<p>Influence diagram having only uncertainty nodes (i.e., Bayesian network) is also called <strong>relevance diagram</strong>. This is perhaps a better use of language than <em>influence diagram</em>. An arc connecting node <em>A</em> to <em>B</em> implies not only that "<em>A</em> is relevant to <em>B</em>", but also that "<em>B</em> is relevant to <em>A</em>" (i.e., <a class="uri" href="relevance" title="wikilink">relevance</a> is a <a class="uri" href="symmetric" title="wikilink">symmetric</a> relationship). The word <em>influence</em> implies more of a one-way relationship, which is reinforced by the arc having a defined direction. Since some arcs are easily reversed, this "one-way" thinking that somehow "<em>A</em> influences <em>B</em>" is incorrect (the causality could be the other way around). However, the term <em>relevance diagram</em> is never adopted in larger community, and the world continues to refer to <em>influence diagram</em>.</p>
<h2 id="bibliography">Bibliography</h2>
<ul>
<li></li>
<li></li>
<li></li>
<li>Howard, R.A. and J.E. Matheson, "Influence diagrams" (1981), in <em>Readings on the Principles and Applications of Decision Analysis</em>, eds. R.A. Howard and J.E. Matheson, Vol. II (1984), Menlo Park CA: Strategic Decisions Group.</li>
<li></li>
<li></li>
<li></li>
<li></li>
<li></li>
<li></li>
</ul>
<h2 id="see-also">See also</h2>
<ul>
<li><a href="Bayesian_network" title="wikilink">Bayesian network</a></li>
<li><a href="Decision_making_software" title="wikilink">Decision making software</a></li>
<li><a href="Decision_tree" title="wikilink">Decision tree</a></li>
<li><a href="Morphological_analysis_(problem-solving)" title="wikilink">Morphological analysis</a></li>
<li><a href="Node_removal" title="wikilink">Node removal</a></li>
<li><a href="Node_reversal" title="wikilink">Node reversal</a></li>
</ul>
<h2 id="external-links">External links</h2>
<ul>
<li><a href="http://www.lumina.com/technology/influence-diagrams/">What are influence diagrams?</a></li>
<li></li>
</ul>

<p>"</p>

<p><a href="Category:Decision_theory" title="wikilink">Category:Decision theory</a> <a class="uri" href="Category:Diagrams" title="wikilink">Category:Diagrams</a> <a href="Category:Bayesian_networks" title="wikilink">Category:Bayesian networks</a></p>
</body>
</html>
