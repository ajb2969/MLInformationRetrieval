


Steffensen's method




Steffensen's method

 table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
   margin: 0; padding: 0; vertical-align: baseline; border: none; }
 <style>
 table.sourceCode { width: 100%; line-height: 100%; }
 td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
 td.sourceCode { padding-left: 5px; }
 code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
 code > span.dt { color: #902000; } /* DataType */
 code > span.dv { color: #40a070; } /* DecVal */
 code > span.bn { color: #40a070; } /* BaseN */
 code > span.fl { color: #40a070; } /* Float */
 code > span.ch { color: #4070a0; } /* Char */
 code > span.st { color: #4070a0; } /* String */
 code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
 code > span.ot { color: #007020; } /* Other */
 code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
 code > span.fu { color: #06287e; } /* Function */
 code > span.er { color: #ff0000; font-weight: bold; } /* Error */
 code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
 code > span.cn { color: #880000; } /* Constant */
 code > span.sc { color: #4070a0; } /* SpecialChar */
 code > span.vs { color: #4070a0; } /* VerbatimString */
 code > span.ss { color: #bb6688; } /* SpecialString */
 code > span.im { } /* Import */
 code > span.va { color: #19177c; } /* Variable */
 code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
 code > span.op { color: #666666; } /* Operator */
 code > span.bu { } /* BuiltIn */
 code > span.ex { } /* Extension */
 code > span.pp { color: #bc7a00; } /* Preprocessor */
 code > span.at { color: #7d9029; } /* Attribute */
 code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
 code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
 code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
 code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
   



In numerical analysis, Steffensen's method is a root-finding method, similar to Newton's method, named after Johan Frederik Steffensen. Steffensen's method also achieves quadratic convergence, but without using derivatives as Newton's method does.
Simple description
The simplest form of the formula for Steffensen's method occurs when it is used to find the zeros, or roots, of a function 
 
 
 
  ; that is: to find the value 
 
 
 
  that satisfies 
 
 
 
  . Near the solution 
 
 
 
 
  , the function 
 
 
 
  is supposed to approximately satisfy 
 
 
 
  ; this condition makes the function 
 
 
 
  adequate as a correction for finding its own solution, although it is not required to work efficiently. For some functions, Steffensen's method can work even if this condition is not met, but in such a case, the starting value 
 
 
 
  must be very close to the actual solution 
 
 
 
 
  , and convergence to the solution may be slow.
Given an adequate starting value 
 
 
 
  , a sequence of values 
 
 
 
  can be generated using the formula below. When it works, each value in the sequence is much closer to the solution 
 
 
 
  than the prior value. The value 
 
 
 
  from the current step generates the value 
 
 
 
 
  for the next step, via this formula:1



for n = 0, 1, 2, 3, ... , where the slope function 
 
 
 
  is a composite of the original function 
 
 
 
  given by the following formula:



The function 
 
 
 
 
  is the average value for the slope of the function 
 
 
 
  between the last sequence point 
 
 
 
  and the auxiliary point 
 
 
 
  , with the step 
 
 
 
  . It is also called the first-order divided difference of 
 
 
 
 
  between those two points.
It is only for the purpose of finding 
 
 
 
  for this auxiliary point that the value of the function 
 
 
 
  must be an adequate correction to get closer to its own solution, and for that reason fulfill the requirement that 
 
 
 
  . For all other parts of the calculation, Steffensen's method only requires the function 
 
 
 
  to be continuous and to actually have a nearby solution. Several modest modifications of the step 
 
 
 
 
  in the slope calculation 
 
 
 
  exist to accommodate functions 
 
 
 
  that do not quite meet the requirement.
Advantages and drawbacks
The main advantage of Steffensen's method is that it has quadratic convergence like Newton's method – that is, both methods find roots to an equation 
 
 
 
  just as ‘quickly’. In this case quickly means that for both methods, the number of correct digits in the answer doubles with each step. But the formula for Newton's method requires a separate function for the derivative; Steffensen's method does not. So Steffensen's method can be programmed for a generic function, as long as that function meets the constraints mentioned above.
The price for the quick convergence is the double function evaluation: both 
 
 
 
  and 
 
 
 
 
  must be calculated, which might be time-consuming if 
 
 
 
  is a complicated function. For comparison, the secant method needs only one function evaluation per step, so with two function evaluations the secant method can do two steps, and two steps of the secant method increase the number of correct digits by a factor of 1.6 . The equally time-consuming single step of Steffensen's (or Newton's) method increases the correct digits by a factor of 2 – which is only slightly less.
Similar to Newton's method and most other quadratically convergent algorithms, the crucial weakness in Steffensen's method is the choice of the starting value 
 
 
 
  . If the value of 
 
 
 
  is not close ‘enough’ to the actual solution 
 
 
 
  , the method may fail and the sequence of values 
 
 
 
 
  may either flip flop between two extremes, or diverge to infinity (possibly both!).
Derivation using Aitken's delta-squared process
The version of Steffensen's method implemented in the MATLAB code shown below can be found using the Aitken's delta-squared process for accelerating convergence of a sequence. To compare the following formulae to the formulae in the section above, notice that 
 
 
 
  . This method assumes starting with a linearly convergent sequence and increases the rate of convergence of that sequence. If the signs of 
 
 
 
  agree and 
 
 
 
  is sufficiently close to the desired limit of the sequence 
 
 
 
 , we can assume the following:


 
  then


 
  so


 
  and hence


 
  .
 Solving for the desired limit of the sequence 
 
 
 
  gives:








 which results in the more rapidly convergent sequence:




Implementation in Matlab
Here is the source for an implementation of Steffensen's Method in MATLAB.
function Steffensen(f,p0,tol)
 % This function takes as inputs: a fixed point iteration function, f, 
 % and initial guess to the fixed point, p0, and a tolerance, tol.
 % The fixed point iteration function is assumed to be input as an
 % inline function. 
 % This function will calculate and return the fixed point, p, 
 % that makes the expression f(x) = p true to within the desired 
 % tolerance, tol. 
 
 format compact % This shortens the output.
 format long    % This prints more decimal places. 
 
 for i=1:1000   % get ready to do a large, but finite, number of iterations.
                % This is so that if the method fails to converge, we won't
                % be stuck in an infinite loop.
     p1=f(p0);  % calculate the next two guesses for the fixed point.
     p2=f(p1);
     p=p0-(p1-p0)^2/(p2-2*p1+p0) % use Aitken's delta squared method to
                                 % find a better approximation to p0.
     if abs(p-p0)%="" abs(p-p0)="" answer.="" are="" are,="" break="" end="" for="" have="" if="" iteration.="" iterations,="" next="" our="" p0="" see="" stop="" test="" the="" to="" tolerance.="" update="" we="" within="">tol       % If we fail to meet the tolerance, we output a
% message of failure.
'failed to converge in 1000 iterations.'
 end
 
 Generalization
Steffensen's method can also be used to find an input 
 
 
 
 
  for a different kind of function 
 
 
 
  that produces output the same as its input
 
 
 
  for the special value 
 
 
 
  . Solutions like 
 
 
 
  are called fixed points. Many such functions can be used to find their own solutions by repeatedly recycling the result back as input, but the rate of convergence can be slow, or the function can fail to converge at all, depending on the individual function. Steffensen's method accelerates this convergence, to make it quadratic.
This method for finding fixed points of a real-valued function has been generalised for functions 
 
 
 
 
  on a Banach space

 
  . The generalised method assumes that a family of bounded linear operators

 
  associated with 
 
 
 
  and 
 
 
 
  can be found to satisfy the condition2



In the simple form given in the section above, the function 
 
 
 
  simply takes in and produces real numbers. There, the function 
 
 
 
  is a divided difference. In the generalized form here, the operator 
 
 
 
  is the analogue of a divided difference for use in the Banach space. The operator 
 
 
 
  is equivalent to a matrix whose entries are all functions of vector arguments

 
 
  and 
 
 
 
 .
Steffensen's method is then very similar to the Newton's method, except that it uses the divided difference
 
 
 
  instead of the derivative 
 
 
 
  . It is thus defined by



for 
 
 
 
 
  , and where 
 
 
 
  is the identity operator.
If the operator 
 
 
 
  satisfies



for some constant 
 
 
 
  , then the method converges quadratically to a fixed point of 
 
 
 
 
  if the initial approximation 
 
 
 
  is "sufficiently close" to the desired solution 
 
 
 
  , that satisfies 
 
 
 
  .
References


"
Category:Root-finding algorithms



Germund Dahlquist, Åke Björck, tr. Ned Anderson. (1974). Numerical Methods, pp. 230–231. Englewood Cliffs, NJ: Prentice Hall.↩
Johnson, L. W. & Scholz, D. R. (1968). On Steffensen's Method. SIAM Journal on Numerical Analysis, 5 (2), 296–302, (June 1968). Stable URL: 1↩


