   Inverse Gaussian distribution      Inverse Gaussian distribution  table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
   margin: 0; padding: 0; vertical-align: baseline; border: none; }
 <style>
 table.sourceCode { width: 100%; line-height: 100%; }
 td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
 td.sourceCode { padding-left: 5px; }
 code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
 code > span.dt { color: #902000; } /* DataType */
 code > span.dv { color: #40a070; } /* DecVal */
 code > span.bn { color: #40a070; } /* BaseN */
 code > span.fl { color: #40a070; } /* Float */
 code > span.ch { color: #4070a0; } /* Char */
 code > span.st { color: #4070a0; } /* String */
 code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
 code > span.ot { color: #007020; } /* Other */
 code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
 code > span.fu { color: #06287e; } /* Function */
 code > span.er { color: #ff0000; font-weight: bold; } /* Error */
 code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
 code > span.cn { color: #880000; } /* Constant */
 code > span.sc { color: #4070a0; } /* SpecialChar */
 code > span.vs { color: #4070a0; } /* VerbatimString */
 code > span.ss { color: #bb6688; } /* SpecialString */
 code > span.im { } /* Import */
 code > span.va { color: #19177c; } /* Variable */
 code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
 code > span.op { color: #666666; } /* Operator */
 code > span.bu { } /* BuiltIn */
 code > span.ex { } /* Extension */
 code > span.pp { color: #bc7a00; } /* Preprocessor */
 code > span.at { color: #7d9029; } /* Attribute */
 code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
 code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
 code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
 code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */     |  cdf        =     Φ   (     λ  x     (    x  μ   -  1   )    )       normal-Φ        λ  x        x  μ   1      \Phi\left(\sqrt{\frac{\lambda}{x}}\left(\frac{x}{\mu}-1\right)\right)         +    exp   (    2  λ   μ   )    Φ   (   -     λ  x     (    x  μ   +  1   )     )                2  λ   μ    normal-Φ          λ  x        x  μ   1        +\exp\left(\frac{2\lambda}{\mu}\right)\Phi\left(-\sqrt{\frac{\lambda}{x}}\left%
 (\frac{x}{\mu}+1\right)\right)      where    Φ   (  )       normal-Φ     \Phi\left(\right)   is the standard normal (standard Gaussian) distribution c.d.f. |  mean       =      𝐄   [  X  ]    =  μ        𝐄   delimited-[]  X    μ    \scriptstyle\mathbf{E}[X]=\mu         𝐄   [    1  X    ]    =     1  μ    +    1  λ           𝐄   delimited-[]    1  X         1  μ     1  λ      \scriptstyle\mathbf{E}[\frac{1}{X}]=\frac{1}{\mu}+\frac{1}{\lambda}    |  median     =|  mode       =     μ   [     (   1  +    9   μ  2     4   λ  2      )    1  2    -    3  μ    2  λ     ]       μ   delimited-[]     superscript    1      9   superscript  μ  2      4   superscript  λ  2        1  2        3  μ     2  λ        \mu\left[\left(1+\frac{9\mu^{2}}{4\lambda^{2}}\right)^{\frac{1}{2}}-\frac{3\mu%
 }{2\lambda}\right]    |  variance   =      𝐕𝐚𝐫   [  X  ]    =     μ  3   λ          𝐕𝐚𝐫   delimited-[]  X       superscript  μ  3   λ     \scriptstyle\mathbf{Var}[X]=\frac{\mu^{3}}{\lambda}         𝐕𝐚𝐫   [    1  X    ]    =     1   μ  λ     +    2   λ  2            𝐕𝐚𝐫   delimited-[]    1  X         1    μ  λ      2   superscript  λ  2       \scriptstyle\mathbf{Var}[\frac{1}{X}]=\frac{1}{\mu\lambda}+\frac{2}{\lambda^{2}}    |  skewness   =     3    (   μ  λ   )    1  /  2        3   superscript    μ  λ     1  2      3\left(\frac{\mu}{\lambda}\right)^{1/2}    |  kurtosis   =      15  μ   λ        15  μ   λ    \frac{15\mu}{\lambda}    |  entropy    =|  mgf        =     e    (   λ  μ   )    [   1  -    1  -    2   μ  2   t   λ      ]       superscript  e      λ  μ    delimited-[]    1      1      2   superscript  μ  2   t   λ          e^{\left(\frac{\lambda}{\mu}\right)\left[1-\sqrt{1-\frac{2\mu^{2}t}{\lambda}}%
 \right]}    |  char       =     e    (   λ  μ   )    [   1  -    1  -    2   μ  2   i  t   λ      ]       superscript  e      λ  μ    delimited-[]    1      1      2   superscript  μ  2   normal-i  t   λ          e^{\left(\frac{\lambda}{\mu}\right)\left[1-\sqrt{1-\frac{2\mu^{2}\mathrm{i}t}{%
 \lambda}}\right]}    |  }}  In probability theory , the inverse Gaussian distribution (also known as the Wald distribution ) is a two-parameter family of continuous probability distributions with support on (0,∞).  Its probability density function is given by       f   (  x  ;  μ  ,  λ  )    =     [   λ   2  π   x  3     ]    1  /  2     exp    -   λ    (   x  -  μ   )   2      2   μ  2   x            f   x  μ  λ       superscript   delimited-[]    λ    2  π   superscript  x  3        1  2            λ   superscript    x  μ   2       2   superscript  μ  2   x        f(x;\mu,\lambda)=\left[\frac{\lambda}{2\pi x^{3}}\right]^{1/2}\exp{\frac{-%
 \lambda(x-\mu)^{2}}{2\mu^{2}x}}     for x > 0, where    μ  >  0      μ  0    \mu>0   is the mean and    λ  >  0      λ  0    \lambda>0   is the shape parameter.  As λ tends to infinity, the inverse Gaussian distribution becomes more like a normal (Gaussian) distribution . The inverse Gaussian distribution has several properties analogous to a Gaussian distribution. The name can be misleading: it is an "inverse" only in that, while the Gaussian describes a Brownian Motion's level at a fixed time, the inverse Gaussian describes the distribution of the time a Brownian Motion with positive drift takes to reach a fixed positive level.  Its cumulant generating function (logarithm of the characteristic function) is the inverse of the cumulant generating function of a Gaussian random variable.  To indicate that a random variable  X is inverse Gaussian-distributed with mean μ and shape parameter λ we write       X  ∼   I  G   (  μ  ,  λ  )     .     similar-to  X    I  G   μ  λ      X\sim IG(\mu,\lambda).\,\!     Properties  Summation  If X i has a IG( μ 0 w i , λ 0 w i 2 ) distribution for i = 1, 2, ..., n and all X i are independent , then       S  =    ∑   i  =  1   n    X  i    ∼   I  G   (    μ  0    ∑   w  i     ,    λ  0     (   ∑   w  i    )   2    )     .        S    superscript   subscript     i  1    n    subscript  X  i      similar-to      I  G      subscript  μ  0      subscript  w  i        subscript  λ  0    superscript     subscript  w  i    2         S=\sum_{i=1}^{n}X_{i}\sim IG\left(\mu_{0}\sum w_{i},\lambda_{0}\left(\sum w_{i%
 }\right)^{2}\right).     Note that        Var   (   X  i   )     E   (   X  i   )     =     μ  0  2    w  i  2      λ  0    w  i  2     =    μ  0  2    λ  0              Var   subscript  X  i      E   subscript  X  i          superscript   subscript  μ  0   2    superscript   subscript  w  i   2       subscript  λ  0    superscript   subscript  w  i   2             superscript   subscript  μ  0   2    subscript  λ  0       \frac{\textrm{Var}(X_{i})}{\textrm{E}(X_{i})}=\frac{\mu_{0}^{2}w_{i}^{2}}{%
 \lambda_{0}w_{i}^{2}}=\frac{\mu_{0}^{2}}{\lambda_{0}}     is constant for all i . This is a necessary condition for the summation. Otherwise S would not be inverse Gaussian.  Scaling  For any t > 0 it holds that        X  ∼    I  G   (  μ  ,  λ  )    ⇒      t  X   ∼   I  G   (   t  μ   ,   t  λ   )      .     formulae-sequence   similar-to  X     I  G   μ  λ    normal-⇒     similar-to    t  X     I  G     t  μ     t  λ        X\sim IG(\mu,\lambda)\,\,\,\,\,\,\Rightarrow\,\,\,\,\,\,tX\sim IG(t\mu,t%
 \lambda).     Exponential family  The inverse Gaussian distribution is a two-parameter exponential family with natural parameters -λ/(2μ²) and -λ/2, and natural statistics  X and 1/X .  Differential equation      {      2   μ  2    x  2    f  ′    (  x  )    +   f   (  x  )    (    -   λ   μ  2     +   λ   x  2    +   3   μ  2   x    )     =  0   ,    f   (  1  )    =     λ    e   -    λ    (   1  -  μ   )   2     2   μ  2          2  π       }      formulae-sequence        2   superscript  μ  2    superscript  x  2    superscript  f  normal-′   x     f  x        λ   superscript  μ  2       λ   superscript  x  2      3   superscript  μ  2   x      0       f  1         λ    superscript  e        λ   superscript    1  μ   2      2   superscript  μ  2            2  π         \left\{2\mu^{2}x^{2}f^{\prime}(x)+f(x)\left(-\lambda\mu^{2}+\lambda x^{2}+3\mu%
 ^{2}x\right)=0,f(1)=\frac{\sqrt{\lambda}e^{-\frac{\lambda(1-\mu)^{2}}{2\mu^{2}%
 }}}{\sqrt{2\pi}}\right\}     Relationship with Brownian motion  The stochastic process  X t given by        X  0   =  0        subscript  X  0   0    X_{0}=0\quad           X  t   =    ν  t   +   σ   W  t           subscript  X  t       ν  t     σ   subscript  W  t       X_{t}=\nu t+\sigma W_{t}\quad\quad\quad\quad     (where W t is a standard Brownian motion and    ν  >  0      ν  0    \nu>0   ) is a Brownian motion with drift ν .  Then, the first passage time for a fixed level    α  >  0      α  0    \alpha>0   by X t is distributed according to an inverse-gaussian:        T  α   =   inf   {   0  <  t   ∣    X  t   =  α   }    ∼   I  G   (    α  ν    ,     α  2    σ  2     )     .         subscript  T  α    infimum   conditional-set    0  t      subscript  X  t   α       similar-to      I  G     α  ν      superscript  α  2    superscript  σ  2         T_{\alpha}=\inf\{0     When drift is zero  A common special case of the above arises when the Brownian motion has no drift. In that case, parameter μ tends to infinity, and the first passage time for fixed level α has probability density function        f   (  x  ;  0  ,    (   α  σ   )   2   )    =    α   σ    2  π   x  3        exp   (   -    α  2    2  x   σ  2      )      .        f   x  0   superscript    α  σ   2         α    σ      2  π   superscript  x  3              superscript  α  2     2  x   superscript  σ  2          f\left(x;0,\left(\frac{\alpha}{\sigma}\right)^{2}\right)=\frac{\alpha}{\sigma%
 \sqrt{2\pi x^{3}}}\exp\left(-\frac{\alpha^{2}}{2x\sigma^{2}}\right).     This is a Lévy distribution with parameters    c  =    α  2    σ  2        c     superscript  α  2    superscript  σ  2      c=\frac{\alpha^{2}}{\sigma^{2}}   and    μ  =  0      μ  0    \mu=0   .  Maximum likelihood  The model where        X  i   ∼   I  G   (  μ  ,   λ   w  i    )     ,   i  =   1  ,  2  ,  …  ,  n       formulae-sequence   similar-to   subscript  X  i     I  G   μ    λ   subscript  w  i         i   1  2  normal-…  n      X_{i}\sim IG(\mu,\lambda w_{i}),\,\,\,\,\,\,i=1,2,\ldots,n     with all w i known, ( μ , λ ) unknown and all X i  independent has the following likelihood function        L   (  μ  ,  λ  )    =     (   λ   2  π    )    n  2      (    ∏   i  =  1   n     w  i    X  i  3     )    1  2     exp   (     λ  μ     ∑   i  =  1   n    w  i     -    λ   2   μ  2       ∑   i  =  1   n     w  i    X  i      -    λ  2     ∑   i  =  1   n     w  i    1   X  i        )      .        L   μ  λ       superscript    λ    2  π      n  2     superscript    subscript   superscript  product  n     i  1       subscript  w  i    superscript   subscript  X  i   3       1  2            λ  μ     superscript   subscript     i  1    n    subscript  w  i         λ    2   superscript  μ  2       superscript   subscript     i  1    n      subscript  w  i    subscript  X  i          λ  2     superscript   subscript     i  1    n      subscript  w  i     1   subscript  X  i            L(\mu,\lambda)=\left(\frac{\lambda}{2\pi}\right)^{\frac{n}{2}}\left(\prod^{n}_%
 {i=1}\frac{w_{i}}{X_{i}^{3}}\right)^{\frac{1}{2}}\exp\left(\frac{\lambda}{\mu}%
 \sum_{i=1}^{n}w_{i}-\frac{\lambda}{2\mu^{2}}\sum_{i=1}^{n}w_{i}X_{i}-\frac{%
 \lambda}{2}\sum_{i=1}^{n}w_{i}\frac{1}{X_{i}}\right).     Solving the likelihood equation yields the following maximum likelihood estimates         μ  ^   =     ∑   i  =  1   n     w  i    X  i       ∑   i  =  1   n    w  i      ,    1   λ  ^    =    1  n     ∑   i  =  1   n     w  i    (    1   X  i    -   1   μ  ^     )        .     formulae-sequence     normal-^  μ       superscript   subscript     i  1    n      subscript  w  i    subscript  X  i       superscript   subscript     i  1    n    subscript  w  i          1   normal-^  λ        1  n     superscript   subscript     i  1    n      subscript  w  i       1   subscript  X  i      1   normal-^  μ           \hat{\mu}=\frac{\sum_{i=1}^{n}w_{i}X_{i}}{\sum_{i=1}^{n}w_{i}},\,\,\,\,\,\,\,%
 \,\frac{1}{\hat{\lambda}}=\frac{1}{n}\sum_{i=1}^{n}w_{i}\left(\frac{1}{X_{i}}-%
 \frac{1}{\hat{\mu}}\right).       μ  ^     normal-^  μ    \hat{\mu}   and    λ  ^     normal-^  λ    \hat{\lambda}   are independent and         μ  ^   ∼   I  G   (  μ  ,   λ    ∑   i  =  1   n    w  i     )       n   λ  ^    ∼    1  λ    χ   n  -  1   2      .     formulae-sequence   similar-to   normal-^  μ     I  G   μ    λ    superscript   subscript     i  1    n    subscript  w  i         similar-to    n   normal-^  λ        1  λ    subscript   superscript  χ  2     n  1        \hat{\mu}\sim IG\left(\mu,\lambda\sum_{i=1}^{n}w_{i}\right)\,\,\,\,\,\,\,\,%
 \frac{n}{\hat{\lambda}}\sim\frac{1}{\lambda}\chi^{2}_{n-1}.     Generating random variates from an inverse-Gaussian distribution  The following algorithm may be used. 1  Generate a random variate from a normal distribution with a mean of 0 and 1 standard deviation       ν  =   N   (  0  ,  1  )     .      ν    N   0  1      \displaystyle\nu=N(0,1).     Square the value      y  =   ν  2       y   superscript  ν  2     \displaystyle y=\nu^{2}     and use this relation       x  =    μ  +     μ  2   y    2  λ     -    μ   2  λ       4  μ  λ  y   +    μ  2    y  2         .      x      μ       superscript  μ  2   y     2  λ         μ    2  λ          4  μ  λ  y      superscript  μ  2    superscript  y  2          x=\mu+\frac{\mu^{2}y}{2\lambda}-\frac{\mu}{2\lambda}\sqrt{4\mu\lambda y+\mu^{2%
 }y^{2}}.     Generate another random variate, this time sampled from a uniform distribution between 0 and 1       z  =   U   (  0  ,  1  )     .      z    U   0  1      \displaystyle z=U(0,1).     If      z  ≤   μ   μ  +  x        z    μ    μ  x      z\leq\frac{\mu}{\mu+x}     then return     x   x   \displaystyle x   else return        μ  2   x   .       superscript  μ  2   x    \frac{\mu^{2}}{x}.     Sample code in Java :  1
 2
 3
 4
 5
 6
 7
 8
 9
 10
 11 public  double  inverseGaussian ( double mu, double lambda) {
        Random rand = new Random(); double v = rand. nextGaussian (); // sample from a normal distribution with a mean of 0 and 1 standard deviation  double y = v*v; double x = mu + (mu*mu*y)/( 2 *lambda) - (mu/( 2 *lambda)) * Math. sqrt ( 4 *mu*lambda*y + mu*mu*y*y); double test = rand. nextDouble (); // sample from a uniform distribution between 0 and 1  if (test <= (mu)/(mu + x)) return x; else  return (mu*mu)/x;
 }  And to plot Wald distribution in Python using matplotlib and NumPy :  1
 2
 3
 4
 5
 6 import matplotlib.pyplot as plt import numpy as np
 
 h = plt.hist(np.random.wald( 3 , 2 , 100000 ), bins = 200 , normed = True )
 
 plt.show()  Related distributions   If    X  ∼   IG   (  μ  ,  λ  )       similar-to  X    IG   μ  λ      X\sim\textrm{IG}(\mu,\lambda)\,   then     k  X   ∼   IG   (   k  μ   ,   k  λ   )       similar-to    k  X     IG     k  μ     k  λ       kX\sim\textrm{IG}(k\mu,k\lambda)\,     If     X  i   ∼   IG   (  μ  ,  λ  )       similar-to   subscript  X  i     IG   μ  λ      X_{i}\sim\textrm{IG}(\mu,\lambda)\,   then      ∑   i  =  1   n    X  i    ∼   IG   (   n  μ   ,    n  2   λ   )       similar-to    superscript   subscript     i  1    n    subscript  X  i      IG     n  μ      superscript  n  2   λ       \sum_{i=1}^{n}X_{i}\sim\textrm{IG}(n\mu,n^{2}\lambda)\,     If     X  i   ∼   IG   (  μ  ,  λ  )       similar-to   subscript  X  i     IG   μ  λ      X_{i}\sim\textrm{IG}(\mu,\lambda)\,   for    i  =   1  ,  …  ,   n        i   1  normal-…  n     i=1,\ldots,n\,   then     X  ¯   ∼   IG   (  μ  ,   n  λ   )       similar-to   normal-¯  X     IG   μ    n  λ       \bar{X}\sim\textrm{IG}(\mu,n\lambda)\,     If     X  i   ∼   IG   (   μ  i   ,   2   μ  i  2    )       similar-to   subscript  X  i     IG    subscript  μ  i     2   subscript   superscript  μ  2   i        X_{i}\sim\textrm{IG}(\mu_{i},2\mu^{2}_{i})\,   then      ∑   i  =  1   n    X  i    ∼   IG   (    ∑   i  =  1   n    μ  i    ,   2    (    ∑   i  =  1   n    μ  i    )   2    )       similar-to    superscript   subscript     i  1    n    subscript  X  i      IG     superscript   subscript     i  1    n    subscript  μ  i      2   superscript    superscript   subscript     i  1    n    subscript  μ  i    2        \sum_{i=1}^{n}X_{i}\sim\textrm{IG}\left(\sum_{i=1}^{n}\mu_{i},2{\left(\sum_{i=%
 1}^{n}\mu_{i}\right)}^{2}\right)\,      The convolution of a inverse Gaussian distribution (a Wald distribution) and an exponential (an ex-Wald distribution) is used as a model for response times in psychology, 2 with visual search as one example. 3  History  This distribution appears to have been first derived by Schrödinger in 1915 as the time to first passage of a Brownian motion. 4 The name inverse Gaussian was proposed by Tweedie in 1945. 5 Wald re-derived this distribution in 1947 as the limiting form of a sample in a sequential probability ratio test. Tweedie investigated this distribution in 1957 and established some of its statistical properties.  Software  The R programming language has software for this distribution. 6 The inverse Gaussian distribution can be called using the statmod package.  See also   Generalized inverse Gaussian distribution  Tweedie distributions —The inverse Gaussian distribution is a member of the family of Tweedie exponential dispersion models  Stopping time   Notes  References   The inverse gaussian distribution: theory, methodology, and applications by Raj Chhikara and Leroy Folks, 1989 ISBN 0-8247-7997-5  System Reliability Theory by Marvin Rausand and Arnljot Høyland  The Inverse Gaussian Distribution by Dr. V. Seshadri, Oxford Univ Press, 1993   External links   Inverse Gaussian Distribution in Wolfram website.   "  Category:Continuous distributions  Category:Exponential family distributions  Category:Probability distributions     ↩  ↩  ↩  Schrodinger E (1915) Zur Theorie der Fall—und Steigversuche an Teilchenn mit Brownscher Bewegung. Physikalische Zeitschrift 16, 289-295 ↩  ↩  ↩    