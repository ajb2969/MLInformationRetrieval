   Inverse Gaussian distribution      Inverse Gaussian distribution  table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
   margin: 0; padding: 0; vertical-align: baseline; border: none; }
 <style>
 table.sourceCode { width: 100%; line-height: 100%; }
 td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
 td.sourceCode { padding-left: 5px; }
 code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
 code > span.dt { color: #902000; } /* DataType */
 code > span.dv { color: #40a070; } /* DecVal */
 code > span.bn { color: #40a070; } /* BaseN */
 code > span.fl { color: #40a070; } /* Float */
 code > span.ch { color: #4070a0; } /* Char */
 code > span.st { color: #4070a0; } /* String */
 code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
 code > span.ot { color: #007020; } /* Other */
 code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
 code > span.fu { color: #06287e; } /* Function */
 code > span.er { color: #ff0000; font-weight: bold; } /* Error */
 code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
 code > span.cn { color: #880000; } /* Constant */
 code > span.sc { color: #4070a0; } /* SpecialChar */
 code > span.vs { color: #4070a0; } /* VerbatimString */
 code > span.ss { color: #bb6688; } /* SpecialString */
 code > span.im { } /* Import */
 code > span.va { color: #19177c; } /* Variable */
 code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
 code > span.op { color: #666666; } /* Operator */
 code > span.bu { } /* BuiltIn */
 code > span.ex { } /* Extension */
 code > span.pp { color: #bc7a00; } /* Preprocessor */
 code > span.at { color: #7d9029; } /* Attribute */
 code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
 code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
 code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
 code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */     |  cdfÂ Â Â Â Â Â Â Â =     Î¦   (     Î»  x     (    x  Î¼   -  1   )    )       normal-Î¦        Î»  x        x  Î¼   1      \Phi\left(\sqrt{\frac{\lambda}{x}}\left(\frac{x}{\mu}-1\right)\right)         +    exp   (    2  Î»   Î¼   )    Î¦   (   -     Î»  x     (    x  Î¼   +  1   )     )                2  Î»   Î¼    normal-Î¦          Î»  x        x  Î¼   1        +\exp\left(\frac{2\lambda}{\mu}\right)\Phi\left(-\sqrt{\frac{\lambda}{x}}\left%
 (\frac{x}{\mu}+1\right)\right)      where    Î¦   (  )       normal-Î¦     \Phi\left(\right)   is the standard normal (standard Gaussian) distribution c.d.f. |  meanÂ Â Â Â Â Â Â =      ð„   [  X  ]    =  Î¼        ð„   delimited-[]  X    Î¼    \scriptstyle\mathbf{E}[X]=\mu         ð„   [    1  X    ]    =     1  Î¼    +    1  Î»           ð„   delimited-[]    1  X         1  Î¼     1  Î»      \scriptstyle\mathbf{E}[\frac{1}{X}]=\frac{1}{\mu}+\frac{1}{\lambda}    |  medianÂ Â Â Â Â =|  modeÂ Â Â Â Â Â Â =     Î¼   [     (   1  +    9   Î¼  2     4   Î»  2      )    1  2    -    3  Î¼    2  Î»     ]       Î¼   delimited-[]     superscript    1      9   superscript  Î¼  2      4   superscript  Î»  2        1  2        3  Î¼     2  Î»        \mu\left[\left(1+\frac{9\mu^{2}}{4\lambda^{2}}\right)^{\frac{1}{2}}-\frac{3\mu%
 }{2\lambda}\right]    |  varianceÂ Â Â =      ð•ðšð«   [  X  ]    =     Î¼  3   Î»          ð•ðšð«   delimited-[]  X       superscript  Î¼  3   Î»     \scriptstyle\mathbf{Var}[X]=\frac{\mu^{3}}{\lambda}         ð•ðšð«   [    1  X    ]    =     1   Î¼  Î»     +    2   Î»  2            ð•ðšð«   delimited-[]    1  X         1    Î¼  Î»      2   superscript  Î»  2       \scriptstyle\mathbf{Var}[\frac{1}{X}]=\frac{1}{\mu\lambda}+\frac{2}{\lambda^{2}}    |  skewnessÂ Â Â =     3    (   Î¼  Î»   )    1  /  2        3   superscript    Î¼  Î»     1  2      3\left(\frac{\mu}{\lambda}\right)^{1/2}    |  kurtosisÂ Â Â =      15  Î¼   Î»        15  Î¼   Î»    \frac{15\mu}{\lambda}    |  entropyÂ Â Â Â =|  mgfÂ Â Â Â Â Â Â Â =     e    (   Î»  Î¼   )    [   1  -    1  -    2   Î¼  2   t   Î»      ]       superscript  e      Î»  Î¼    delimited-[]    1      1      2   superscript  Î¼  2   t   Î»          e^{\left(\frac{\lambda}{\mu}\right)\left[1-\sqrt{1-\frac{2\mu^{2}t}{\lambda}}%
 \right]}    |  charÂ Â Â Â Â Â Â =     e    (   Î»  Î¼   )    [   1  -    1  -    2   Î¼  2   i  t   Î»      ]       superscript  e      Î»  Î¼    delimited-[]    1      1      2   superscript  Î¼  2   normal-i  t   Î»          e^{\left(\frac{\lambda}{\mu}\right)\left[1-\sqrt{1-\frac{2\mu^{2}\mathrm{i}t}{%
 \lambda}}\right]}    |  }}  In probability theory , the inverse Gaussian distribution (also known as the Wald distribution ) is a two-parameter family of continuous probability distributions with support on (0,âˆž).  Its probability density function is given by       f   (  x  ;  Î¼  ,  Î»  )    =     [   Î»   2  Ï€   x  3     ]    1  /  2     exp    -   Î»    (   x  -  Î¼   )   2      2   Î¼  2   x            f   x  Î¼  Î»       superscript   delimited-[]    Î»    2  Ï€   superscript  x  3        1  2            Î»   superscript    x  Î¼   2       2   superscript  Î¼  2   x        f(x;\mu,\lambda)=\left[\frac{\lambda}{2\pi x^{3}}\right]^{1/2}\exp{\frac{-%
 \lambda(x-\mu)^{2}}{2\mu^{2}x}}     for x > 0, where    Î¼  >  0      Î¼  0    \mu>0   is the mean and    Î»  >  0      Î»  0    \lambda>0   is the shape parameter.  As Î» tends to infinity, the inverse Gaussian distribution becomes more like a normal (Gaussian) distribution . The inverse Gaussian distribution has several properties analogous to a Gaussian distribution. The name can be misleading: it is an "inverse" only in that, while the Gaussian describes a Brownian Motion's level at a fixed time, the inverse Gaussian describes the distribution of the time a Brownian Motion with positive drift takes to reach a fixed positive level.  Its cumulant generating function (logarithm of the characteristic function) is the inverse of the cumulant generating function of a Gaussian random variable.  To indicate that a random variable  X is inverse Gaussian-distributed with mean Î¼ and shape parameter Î» we write       X  âˆ¼   I  G   (  Î¼  ,  Î»  )     .     similar-to  X    I  G   Î¼  Î»      X\sim IG(\mu,\lambda).\,\!     Properties  Summation  If X i has a IG( Î¼ 0 w i , Î» 0 w i 2 ) distribution for i =Â 1,Â 2,Â ..., n and all X i are independent , then       S  =    âˆ‘   i  =  1   n    X  i    âˆ¼   I  G   (    Î¼  0    âˆ‘   w  i     ,    Î»  0     (   âˆ‘   w  i    )   2    )     .        S    superscript   subscript     i  1    n    subscript  X  i      similar-to      I  G      subscript  Î¼  0      subscript  w  i        subscript  Î»  0    superscript     subscript  w  i    2         S=\sum_{i=1}^{n}X_{i}\sim IG\left(\mu_{0}\sum w_{i},\lambda_{0}\left(\sum w_{i%
 }\right)^{2}\right).     Note that        Var   (   X  i   )     E   (   X  i   )     =     Î¼  0  2    w  i  2      Î»  0    w  i  2     =    Î¼  0  2    Î»  0              Var   subscript  X  i      E   subscript  X  i          superscript   subscript  Î¼  0   2    superscript   subscript  w  i   2       subscript  Î»  0    superscript   subscript  w  i   2             superscript   subscript  Î¼  0   2    subscript  Î»  0       \frac{\textrm{Var}(X_{i})}{\textrm{E}(X_{i})}=\frac{\mu_{0}^{2}w_{i}^{2}}{%
 \lambda_{0}w_{i}^{2}}=\frac{\mu_{0}^{2}}{\lambda_{0}}     is constant for all i . This is a necessary condition for the summation. Otherwise S would not be inverse Gaussian.  Scaling  For any t > 0 it holds that        X  âˆ¼    I  G   (  Î¼  ,  Î»  )    â‡’      t  X   âˆ¼   I  G   (   t  Î¼   ,   t  Î»   )      .     formulae-sequence   similar-to  X     I  G   Î¼  Î»    normal-â‡’     similar-to    t  X     I  G     t  Î¼     t  Î»        X\sim IG(\mu,\lambda)\,\,\,\,\,\,\Rightarrow\,\,\,\,\,\,tX\sim IG(t\mu,t%
 \lambda).     Exponential family  The inverse Gaussian distribution is a two-parameter exponential family with natural parameters -Î»/(2Î¼Â²) and -Î»/2, and natural statistics  X and 1/X .  Differential equation      {      2   Î¼  2    x  2    f  â€²    (  x  )    +   f   (  x  )    (    -   Î»   Î¼  2     +   Î»   x  2    +   3   Î¼  2   x    )     =  0   ,    f   (  1  )    =     Î»    e   -    Î»    (   1  -  Î¼   )   2     2   Î¼  2          2  Ï€       }      formulae-sequence        2   superscript  Î¼  2    superscript  x  2    superscript  f  normal-â€²   x     f  x        Î»   superscript  Î¼  2       Î»   superscript  x  2      3   superscript  Î¼  2   x      0       f  1         Î»    superscript  e        Î»   superscript    1  Î¼   2      2   superscript  Î¼  2            2  Ï€         \left\{2\mu^{2}x^{2}f^{\prime}(x)+f(x)\left(-\lambda\mu^{2}+\lambda x^{2}+3\mu%
 ^{2}x\right)=0,f(1)=\frac{\sqrt{\lambda}e^{-\frac{\lambda(1-\mu)^{2}}{2\mu^{2}%
 }}}{\sqrt{2\pi}}\right\}     Relationship with Brownian motion  The stochastic process  X t given by        X  0   =  0        subscript  X  0   0    X_{0}=0\quad           X  t   =    Î½  t   +   Ïƒ   W  t           subscript  X  t       Î½  t     Ïƒ   subscript  W  t       X_{t}=\nu t+\sigma W_{t}\quad\quad\quad\quad     (where W t is a standard Brownian motion and    Î½  >  0      Î½  0    \nu>0   ) is a Brownian motion with drift Î½ .  Then, the first passage time for a fixed level    Î±  >  0      Î±  0    \alpha>0   by X t is distributed according to an inverse-gaussian:        T  Î±   =   inf   {   0  <  t   âˆ£    X  t   =  Î±   }    âˆ¼   I  G   (    Î±  Î½    ,     Î±  2    Ïƒ  2     )     .         subscript  T  Î±    infimum   conditional-set    0  t      subscript  X  t   Î±       similar-to      I  G     Î±  Î½      superscript  Î±  2    superscript  Ïƒ  2         T_{\alpha}=\inf\{0     When drift is zero  A common special case of the above arises when the Brownian motion has no drift. In that case, parameter Î¼ tends to infinity, and the first passage time for fixed level Î± has probability density function        f   (  x  ;  0  ,    (   Î±  Ïƒ   )   2   )    =    Î±   Ïƒ    2  Ï€   x  3        exp   (   -    Î±  2    2  x   Ïƒ  2      )      .        f   x  0   superscript    Î±  Ïƒ   2         Î±    Ïƒ      2  Ï€   superscript  x  3              superscript  Î±  2     2  x   superscript  Ïƒ  2          f\left(x;0,\left(\frac{\alpha}{\sigma}\right)^{2}\right)=\frac{\alpha}{\sigma%
 \sqrt{2\pi x^{3}}}\exp\left(-\frac{\alpha^{2}}{2x\sigma^{2}}\right).     This is a LÃ©vy distribution with parameters    c  =    Î±  2    Ïƒ  2        c     superscript  Î±  2    superscript  Ïƒ  2      c=\frac{\alpha^{2}}{\sigma^{2}}   and    Î¼  =  0      Î¼  0    \mu=0   .  Maximum likelihood  The model where        X  i   âˆ¼   I  G   (  Î¼  ,   Î»   w  i    )     ,   i  =   1  ,  2  ,  â€¦  ,  n       formulae-sequence   similar-to   subscript  X  i     I  G   Î¼    Î»   subscript  w  i         i   1  2  normal-â€¦  n      X_{i}\sim IG(\mu,\lambda w_{i}),\,\,\,\,\,\,i=1,2,\ldots,n     with all w i known, ( Î¼ , Î» ) unknown and all X i  independent has the following likelihood function        L   (  Î¼  ,  Î»  )    =     (   Î»   2  Ï€    )    n  2      (    âˆ   i  =  1   n     w  i    X  i  3     )    1  2     exp   (     Î»  Î¼     âˆ‘   i  =  1   n    w  i     -    Î»   2   Î¼  2       âˆ‘   i  =  1   n     w  i    X  i      -    Î»  2     âˆ‘   i  =  1   n     w  i    1   X  i        )      .        L   Î¼  Î»       superscript    Î»    2  Ï€      n  2     superscript    subscript   superscript  product  n     i  1       subscript  w  i    superscript   subscript  X  i   3       1  2            Î»  Î¼     superscript   subscript     i  1    n    subscript  w  i         Î»    2   superscript  Î¼  2       superscript   subscript     i  1    n      subscript  w  i    subscript  X  i          Î»  2     superscript   subscript     i  1    n      subscript  w  i     1   subscript  X  i            L(\mu,\lambda)=\left(\frac{\lambda}{2\pi}\right)^{\frac{n}{2}}\left(\prod^{n}_%
 {i=1}\frac{w_{i}}{X_{i}^{3}}\right)^{\frac{1}{2}}\exp\left(\frac{\lambda}{\mu}%
 \sum_{i=1}^{n}w_{i}-\frac{\lambda}{2\mu^{2}}\sum_{i=1}^{n}w_{i}X_{i}-\frac{%
 \lambda}{2}\sum_{i=1}^{n}w_{i}\frac{1}{X_{i}}\right).     Solving the likelihood equation yields the following maximum likelihood estimates         Î¼  ^   =     âˆ‘   i  =  1   n     w  i    X  i       âˆ‘   i  =  1   n    w  i      ,    1   Î»  ^    =    1  n     âˆ‘   i  =  1   n     w  i    (    1   X  i    -   1   Î¼  ^     )        .     formulae-sequence     normal-^  Î¼       superscript   subscript     i  1    n      subscript  w  i    subscript  X  i       superscript   subscript     i  1    n    subscript  w  i          1   normal-^  Î»        1  n     superscript   subscript     i  1    n      subscript  w  i       1   subscript  X  i      1   normal-^  Î¼           \hat{\mu}=\frac{\sum_{i=1}^{n}w_{i}X_{i}}{\sum_{i=1}^{n}w_{i}},\,\,\,\,\,\,\,%
 \,\frac{1}{\hat{\lambda}}=\frac{1}{n}\sum_{i=1}^{n}w_{i}\left(\frac{1}{X_{i}}-%
 \frac{1}{\hat{\mu}}\right).       Î¼  ^     normal-^  Î¼    \hat{\mu}   and    Î»  ^     normal-^  Î»    \hat{\lambda}   are independent and         Î¼  ^   âˆ¼   I  G   (  Î¼  ,   Î»    âˆ‘   i  =  1   n    w  i     )       n   Î»  ^    âˆ¼    1  Î»    Ï‡   n  -  1   2      .     formulae-sequence   similar-to   normal-^  Î¼     I  G   Î¼    Î»    superscript   subscript     i  1    n    subscript  w  i         similar-to    n   normal-^  Î»        1  Î»    subscript   superscript  Ï‡  2     n  1        \hat{\mu}\sim IG\left(\mu,\lambda\sum_{i=1}^{n}w_{i}\right)\,\,\,\,\,\,\,\,%
 \frac{n}{\hat{\lambda}}\sim\frac{1}{\lambda}\chi^{2}_{n-1}.     Generating random variates from an inverse-Gaussian distribution  The following algorithm may be used. 1  Generate a random variate from a normal distribution with a mean of 0 and 1 standard deviation       Î½  =   N   (  0  ,  1  )     .      Î½    N   0  1      \displaystyle\nu=N(0,1).     Square the value      y  =   Î½  2       y   superscript  Î½  2     \displaystyle y=\nu^{2}     and use this relation       x  =    Î¼  +     Î¼  2   y    2  Î»     -    Î¼   2  Î»       4  Î¼  Î»  y   +    Î¼  2    y  2         .      x      Î¼       superscript  Î¼  2   y     2  Î»         Î¼    2  Î»          4  Î¼  Î»  y      superscript  Î¼  2    superscript  y  2          x=\mu+\frac{\mu^{2}y}{2\lambda}-\frac{\mu}{2\lambda}\sqrt{4\mu\lambda y+\mu^{2%
 }y^{2}}.     Generate another random variate, this time sampled from a uniform distribution between 0 and 1       z  =   U   (  0  ,  1  )     .      z    U   0  1      \displaystyle z=U(0,1).     If      z  â‰¤   Î¼   Î¼  +  x        z    Î¼    Î¼  x      z\leq\frac{\mu}{\mu+x}     then return     x   x   \displaystyle x   else return        Î¼  2   x   .       superscript  Î¼  2   x    \frac{\mu^{2}}{x}.     Sample code in Java :  1
 2
 3
 4
 5
 6
 7
 8
 9
 10
 11 public  double  inverseGaussian ( double mu, double lambda) {
        Random rand = new Random(); double v = rand. nextGaussian (); // sample from a normal distribution with a mean of 0 and 1 standard deviation  double y = v*v; double x = mu + (mu*mu*y)/( 2 *lambda) - (mu/( 2 *lambda)) * Math. sqrt ( 4 *mu*lambda*y + mu*mu*y*y); double test = rand. nextDouble (); // sample from a uniform distribution between 0 and 1  if (test <= (mu)/(mu + x)) return x; else  return (mu*mu)/x;
 }  And to plot Wald distribution in Python using matplotlib and NumPy :  1
 2
 3
 4
 5
 6 import matplotlib.pyplot as plt import numpy as np
 
 h = plt.hist(np.random.wald( 3 , 2 , 100000 ), bins = 200 , normed = True )
 
 plt.show()  Related distributions   If    X  âˆ¼   IG   (  Î¼  ,  Î»  )       similar-to  X    IG   Î¼  Î»      X\sim\textrm{IG}(\mu,\lambda)\,   then     k  X   âˆ¼   IG   (   k  Î¼   ,   k  Î»   )       similar-to    k  X     IG     k  Î¼     k  Î»       kX\sim\textrm{IG}(k\mu,k\lambda)\,     If     X  i   âˆ¼   IG   (  Î¼  ,  Î»  )       similar-to   subscript  X  i     IG   Î¼  Î»      X_{i}\sim\textrm{IG}(\mu,\lambda)\,   then      âˆ‘   i  =  1   n    X  i    âˆ¼   IG   (   n  Î¼   ,    n  2   Î»   )       similar-to    superscript   subscript     i  1    n    subscript  X  i      IG     n  Î¼      superscript  n  2   Î»       \sum_{i=1}^{n}X_{i}\sim\textrm{IG}(n\mu,n^{2}\lambda)\,     If     X  i   âˆ¼   IG   (  Î¼  ,  Î»  )       similar-to   subscript  X  i     IG   Î¼  Î»      X_{i}\sim\textrm{IG}(\mu,\lambda)\,   for    i  =   1  ,  â€¦  ,   n        i   1  normal-â€¦  n     i=1,\ldots,n\,   then     X  Â¯   âˆ¼   IG   (  Î¼  ,   n  Î»   )       similar-to   normal-Â¯  X     IG   Î¼    n  Î»       \bar{X}\sim\textrm{IG}(\mu,n\lambda)\,     If     X  i   âˆ¼   IG   (   Î¼  i   ,   2   Î¼  i  2    )       similar-to   subscript  X  i     IG    subscript  Î¼  i     2   subscript   superscript  Î¼  2   i        X_{i}\sim\textrm{IG}(\mu_{i},2\mu^{2}_{i})\,   then      âˆ‘   i  =  1   n    X  i    âˆ¼   IG   (    âˆ‘   i  =  1   n    Î¼  i    ,   2    (    âˆ‘   i  =  1   n    Î¼  i    )   2    )       similar-to    superscript   subscript     i  1    n    subscript  X  i      IG     superscript   subscript     i  1    n    subscript  Î¼  i      2   superscript    superscript   subscript     i  1    n    subscript  Î¼  i    2        \sum_{i=1}^{n}X_{i}\sim\textrm{IG}\left(\sum_{i=1}^{n}\mu_{i},2{\left(\sum_{i=%
 1}^{n}\mu_{i}\right)}^{2}\right)\,      The convolution of a inverse Gaussian distribution (a Wald distribution) and an exponential (an ex-Wald distribution) is used as a model for response times in psychology, 2 with visual search as one example. 3  History  This distribution appears to have been first derived by SchrÃ¶dinger in 1915 as the time to first passage of a Brownian motion. 4 The name inverse Gaussian was proposed by Tweedie in 1945. 5 Wald re-derived this distribution in 1947 as the limiting form of a sample in a sequential probability ratio test. Tweedie investigated this distribution in 1957 and established some of its statistical properties.  Software  The R programming language has software for this distribution. 6 The inverse Gaussian distribution can be called using the statmod package.  See also   Generalized inverse Gaussian distribution  Tweedie distributions â€”The inverse Gaussian distribution is a member of the family of Tweedie exponential dispersion models  Stopping time   Notes  References   The inverse gaussian distribution: theory, methodology, and applications by Raj Chhikara and Leroy Folks, 1989 ISBN 0-8247-7997-5  System Reliability Theory by Marvin Rausand and Arnljot HÃ¸yland  The Inverse Gaussian Distribution by Dr. V. Seshadri, Oxford Univ Press, 1993   External links   Inverse Gaussian Distribution in Wolfram website.   "  Category:Continuous distributions  Category:Exponential family distributions  Category:Probability distributions     â†©  â†©  â†©  Schrodinger E (1915) Zur Theorie der Fallâ€”und Steigversuche an Teilchenn mit Brownscher Bewegung. Physikalische Zeitschrift 16, 289-295 â†©  â†©  â†©    