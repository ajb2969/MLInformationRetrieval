   Typical set      Typical set   In information theory , the typical set is a set of sequences whose probability is close to two raised to the negative power of the entropy of their source distribution. That this set has total probability close to one is a consequence of the asymptotic equipartition property (AEP) which is a kind of law of large numbers . The notion of typicality is only concerned with the probability of a sequence and not the actual sequence itself.  This has great use in compression theory as it provides a theoretical means for compressing data, allowing us to represent any sequence X n using nH ( X ) bits on average, and, hence, justifying the use of entropy as a measure of information from a source.  The AEP can also be proven for a large class of stationary ergodic processes , allowing typical set to be defined in more general cases.  (Weakly) typical sequences (weak typicality, entropy typicality)  If a sequence x 1 ,¬†..., x n is drawn from an i.i.d. distribution  X defined over a finite alphabet   ùí≥   ùí≥   \mathcal{X}   , then the typical set, A Œµ ( n )      ‚àà  ùí≥      absent  ùí≥    \in\mathcal{X}    ( n ) is defined as those sequences which satisfy:       2   -   n   [    H   (  X  )    +  Œµ   ]      ‚©Ω   p   (   x  1   ,   x  2   ,  ‚Ä¶  ,   x  n   )    ‚©Ω   2   -   n   [    H   (  X  )    -  Œµ   ]             superscript  2      n   delimited-[]      H  X   Œµ         p    subscript  x  1    subscript  x  2   normal-‚Ä¶   subscript  x  n           superscript  2      n   delimited-[]      H  X   Œµ          2^{-n[H(X)+\varepsilon]}\leqslant p(x_{1},x_{2},\dots,x_{n})\leqslant 2^{-n[H(%
 X)-\varepsilon]}     Where       H   (  X  )    =   -    ‚àë   y   \isin   ùí≥     p   (  y  )     log  2   p    (  y  )            H  X       subscript     y  \isin  ùí≥      p  y    subscript   2   p   y       H(X)=-\sum_{y\isin\mathcal{X}}p(y)\log_{2}p(y)     is the information entropy of X . The probability above need only be within a factor of 2 n Œµ'' .  It has the following properties if n is sufficiently large,    œµ  >  0      œµ  0    \epsilon>0   can be chosen arbitrarily small so that:   The probability of a sequence from X being drawn from A Œµ ( n ) is greater than 1¬†‚àí Œµ , i.e.    P  r   [   x   (  n  )    ‚àà   A  œµ   (  n  )    ]   ‚â•  1  -  œµ     fragments  P  r   fragments  normal-[   superscript  x  n     superscript   subscript  A  œµ   n   normal-]    1   œµ    Pr[x^{(n)}\in A_{\epsilon}^{(n)}]\geq 1-\epsilon          |   A  Œµ     (  n  )    |   ‚©Ω   2   n   (    H   (  X  )    +  Œµ   )            superscript   subscript  A  Œµ   n     superscript  2    n      H  X   Œµ       \left|{A_{\varepsilon}}^{(n)}\right|\leqslant 2^{n(H(X)+\varepsilon)}          |   A  Œµ     (  n  )    |   ‚©æ    (   1  -  Œµ   )    2   n   (    H   (  X  )    -  Œµ   )             superscript   subscript  A  Œµ   n        1  Œµ    superscript  2    n      H  X   Œµ        \left|{A_{\varepsilon}}^{(n)}\right|\geqslant(1-\varepsilon)2^{n(H(X)-%
 \varepsilon)}     Most sequences are not typical. If the distribution over   ùí≥   ùí≥   \mathcal{X}   is not uniform, then the fraction of sequences that are typical is           |   A  œµ   (  n  )    |    |   ùí≥   (  n  )    |    ‚â°    2   n  H   (  X  )      2   n   log   |  ùí≥  |       =   2   -   n   (    log   |  ùí≥  |    -   H   (  X  )     )      ‚Üí  0             superscript   subscript  A  œµ   n       superscript  ùí≥  n        superscript  2    n  H  X     superscript  2    n      ùí≥             superscript  2      n        ùí≥      H  X         normal-‚Üí    0     \frac{|A_{\epsilon}^{(n)}|}{|\mathcal{X}^{(n)}|}\equiv\frac{2^{nH(X)}}{2^{n%
 \log|\mathcal{X}|}}=2^{-n(\log|\mathcal{X}|-H(X))}\rightarrow 0          as n becomes very large, since      H   (  X  )    <   log   |  ùí≥  |     .        H  X       ùí≥      H(X)<\log|\mathcal{X}|.        For a general stochastic process { X ( t )} with AEP, the (weakly) typical set can be defined similarly with p ( x 1 , x 2 ,¬†..., x n ) replaced by p ( x 0 œÑ ) (i.e. the probability of the sample limited to the time interval [0, œÑ ]), n being the degree of freedom of the process in the time interval and H ( X ) being the entropy rate . If the process is continuous-valued, differential entropy is used instead.  Counter-intuitively, most likely sequence is often not a member of the typical set. For example, suppose that X is an i.i.d Bernoulli random variable with p (0)=0.1 and p (1)=0.9. In n independent trials, since p (1)> p (0), the most likely sequence of outcome is the sequence of all 1's, (1,1,...,1). Here the entropy of X is H ( X )=0.469, while    -   1  n   log  p   (   x   (  n  )    =   (  1  ,  1  ,  ‚Ä¶  ,  1  )   )   =  -   1  n   log   (   0.9  n   )   =  0.152     fragments     1  n    p   fragments  normal-(   superscript  x  n     fragments  normal-(  1  normal-,  1  normal-,  normal-‚Ä¶  normal-,  1  normal-)   normal-)       1  n     fragments  normal-(   superscript  0.9  n   normal-)    0.152    -\frac{1}{n}\log p(x^{(n)}=(1,1,\ldots,1))=-\frac{1}{n}\log(0.9^{n})=0.152     So this sequence is not in the typical set because its average logarithmic probability cannot come arbitrarily close to the entropy of the random variable X no matter how large we take the value of n . For Bernoulli random variables, the typical set consists of sequences with average numbers of 0s and 1s in n independent trials. For this example, if n =10, then the typical set consist of all sequences that has a single 0 in the entire sequence. In case p (0)= p (1)=0.5, then every possible binary sequences belong to the typical set.  Strongly typical sequences (strong typicality, letter typicality)  If a sequence x 1 , ..., x n is drawn from some specified joint distribution defined over a finite or an infinite alphabet   ùí≥   ùí≥   \mathcal{X}   , then the strongly typical set, A Œµ,strong ( n )      ‚àà  ùí≥      absent  ùí≥    \in\mathcal{X}   is defined as the set of sequences which satisfy        |     N   (   x  i   )    n   -   p   (   x  i   )     |   <   Œµ   ‚à•  ùí≥  ‚à•     .              N   subscript  x  i    n     p   subscript  x  i        Œµ   norm  ùí≥      \left|\frac{N(x_{i})}{n}-p(x_{i})\right|<\frac{\varepsilon}{\|\mathcal{X}\|}.     where    N   (   x  i   )       N   subscript  x  i     {N(x_{i})}   is the number of occurrences of a specific symbol in the sequence.  It can be shown that strongly typical sequences are also weakly typical (with a different constant Œµ), and hence the name. The two forms, however, are not equivalent. Strong typicality is often easier to work with in proving theorems for memoryless channels. However, as is apparent from the definition, this form of typicality is only defined for random variables having finite support.  Jointly typical sequences  Two sequences    x  n     superscript  x  n    x^{n}   and    y  n     superscript  y  n    y^{n}   are jointly Œµ-typical if the pair    (   x  n   ,   y  n   )      superscript  x  n    superscript  y  n     (x^{n},y^{n})   is Œµ-typical with respect to the joint distribution     p   (   x  n   ,   y  n   )    =    ‚àè   i  =  1   n    p   (   x  i   ,   y  i   )           p    superscript  x  n    superscript  y  n       superscript   subscript  product    i  1    n     p    subscript  x  i    subscript  y  i        p(x^{n},y^{n})=\prod_{i=1}^{n}p(x_{i},y_{i})   and both    x  n     superscript  x  n    x^{n}   and    y  n     superscript  y  n    y^{n}   are Œµ-typical with respect to their marginal distributions    p   (   x  n   )       p   superscript  x  n     p(x^{n})   and    p   (   y  n   )       p   superscript  y  n     p(y^{n})   . The set of all such pairs of sequences    (   x  n   ,   y  n   )      superscript  x  n    superscript  y  n     (x^{n},y^{n})   is denoted by     A  Œµ  n    (  X  ,  Y  )        superscript   subscript  A  Œµ   n    X  Y     A_{\varepsilon}^{n}(X,Y)   . Jointly Œµ-typical n -tuple sequences are defined similarly.  Let     X  ~   n     superscript   normal-~  X   n    \tilde{X}^{n}   and     Y  ~   n     superscript   normal-~  Y   n    \tilde{Y}^{n}   be two independent sequences of random variables with the same marginal distributions    p   (   x  n   )       p   superscript  x  n     p(x^{n})   and    p   (   y  n   )       p   superscript  y  n     p(y^{n})   . Then for any Œµ>0, for sufficiently large n , jointly typical sequences satisfy the following properties:       P   [   (   X  n   ,   Y  n   )   ‚àà   A  Œµ  n    (  X  ,  Y  )   ]   ‚©æ  1  -  œµ     fragments  P   fragments  normal-[   fragments  normal-(   superscript  X  n   normal-,   superscript  Y  n   normal-)     superscript   subscript  A  Œµ   n    fragments  normal-(  X  normal-,  Y  normal-)   normal-]    1   œµ    P\left[(X^{n},Y^{n})\in A_{\varepsilon}^{n}(X,Y)\right]\geqslant 1-\epsilon          |    A  Œµ  n    (  X  ,  Y  )    |   ‚©Ω   2   n   (    H   (  X  ,  Y  )    +  œµ   )              superscript   subscript  A  Œµ   n    X  Y      superscript  2    n      H   X  Y    œµ       \left|A_{\varepsilon}^{n}(X,Y)\right|\leqslant 2^{n(H(X,Y)+\epsilon)}          |    A  Œµ  n    (  X  ,  Y  )    |   ‚©æ    (   1  -  œµ   )    2   n   (    H   (  X  ,  Y  )    -  œµ   )               superscript   subscript  A  Œµ   n    X  Y         1  œµ    superscript  2    n      H   X  Y    œµ        \left|A_{\varepsilon}^{n}(X,Y)\right|\geqslant(1-\epsilon)2^{n(H(X,Y)-\epsilon)}         P   [   (    X  ~   n   ,    Y  ~   n   )   ‚àà   A  Œµ  n    (  X  ,  Y  )   ]   ‚©Ω   2   -   n   (    I   (  X  ;  Y  )    -   3  œµ    )         fragments  P   fragments  normal-[   fragments  normal-(   superscript   normal-~  X   n   normal-,   superscript   normal-~  Y   n   normal-)     superscript   subscript  A  Œµ   n    fragments  normal-(  X  normal-,  Y  normal-)   normal-]     superscript  2      n      I   X  Y      3  œµ         P\left[(\tilde{X}^{n},\tilde{Y}^{n})\in A_{\varepsilon}^{n}(X,Y)\right]%
 \leqslant 2^{-n(I(X;Y)-3\epsilon)}         P   [   (    X  ~   n   ,    Y  ~   n   )   ‚àà   A  Œµ  n    (  X  ,  Y  )   ]   ‚©æ   (  1  -  œµ  )    2   -   n   (    I   (  X  ;  Y  )    +   3  œµ    )         fragments  P   fragments  normal-[   fragments  normal-(   superscript   normal-~  X   n   normal-,   superscript   normal-~  Y   n   normal-)     superscript   subscript  A  Œµ   n    fragments  normal-(  X  normal-,  Y  normal-)   normal-]     fragments  normal-(  1   œµ  normal-)    superscript  2      n      I   X  Y      3  œµ         P\left[(\tilde{X}^{n},\tilde{Y}^{n})\in A_{\varepsilon}^{n}(X,Y)\right]%
 \geqslant(1-\epsilon)2^{-n(I(X;Y)+3\epsilon)}      Applications of typicality  Typical set encoding  In information theory , typical set encoding encodes only the typical set of a stochastic source with fixed length block codes. Asymptotically, it is, by the AEP, lossless and achieves the minimum rate equal to the entropy rate of the source.  Typical set decoding  In information theory , typical set decoding is used in conjunction with random coding to estimate the transmitted message as the one with a codeword that is jointly Œµ-typical with the observation. i.e.       w  ^   =  w  ‚áî   (  ‚àÉ  w  )    (   (   x  1  n    (  w  )   ,   y  1  n   )   ‚àà   A  Œµ  n    (  X  ,  Y  )   )      fragments   normal-^  w    w  iff   fragments  normal-(   w  normal-)    fragments  normal-(   fragments  normal-(   superscript   subscript  x  1   n    fragments  normal-(  w  normal-)   normal-,   superscript   subscript  y  1   n   normal-)     superscript   subscript  A  Œµ   n    fragments  normal-(  X  normal-,  Y  normal-)   normal-)     \hat{w}=w\iff(\exists w)((x_{1}^{n}(w),y_{1}^{n})\in A_{\varepsilon}^{n}(X,Y))   where     w  ^   ,    x  1  n    (  w  )    ,   y  1  n       normal-^  w      superscript   subscript  x  1   n   w    superscript   subscript  y  1   n     \hat{w},x_{1}^{n}(w),y_{1}^{n}   are the message estimate, codeword of message   w   w   w   and the observation respectively.     A  Œµ  n    (  X  ,  Y  )        superscript   subscript  A  Œµ   n    X  Y     A_{\varepsilon}^{n}(X,Y)   is defined with respect to the joint distribution    p   (   x  1  n   )   p   (   y  1  n   |   x  1  n   )      fragments  p   fragments  normal-(   superscript   subscript  x  1   n   normal-)   p   fragments  normal-(   superscript   subscript  y  1   n   normal-|   superscript   subscript  x  1   n   normal-)     p(x_{1}^{n})p(y_{1}^{n}|x_{1}^{n})   where    p   (   y  1  n   |   x  1  n   )      fragments  p   fragments  normal-(   superscript   subscript  y  1   n   normal-|   superscript   subscript  x  1   n   normal-)     p(y_{1}^{n}|x_{1}^{n})   is the transition probability that characterizes the channel statistics, and    p   (   x  1  n   )       p   superscript   subscript  x  1   n     p(x_{1}^{n})   is some input distribution used to generate the codewords in the random codebook.  Universal null-hypothesis testing  Universal channel code  See also   Asymptotic equipartition property  Source coding theorem  Noisy-channel coding theorem   References   C. E. Shannon , " A Mathematical Theory of Communication ", Bell System Technical Journal , vol. 27, pp.¬†379‚Äì423, 623-656, July, October, 1948   David J. C. MacKay . Information Theory, Inference, and Learning Algorithms Cambridge: Cambridge University Press, 2003. ISBN 0-521-64298-1   "  Category:Information theory  Category:Probability theory   