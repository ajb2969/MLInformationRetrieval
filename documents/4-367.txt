   Correlation ratio      Correlation ratio   In statistics , the correlation ratio is a measure of the relationship between the statistical dispersion within individual categories and the dispersion across the whole population or sample. The measure is defined as the ratio of two standard deviations representing these types of variation. The context here is the same as that of the intraclass correlation coefficient , whose value is the square of the correlation ratio.  Definition  Suppose each observation is y xi where x indicates the category that observation is in and i is the label of the particular observation. Let n x be the number of observations in category x and        y  ¯   x   =     ∑  i    y   x  i      n  x         subscript   normal-¯  y   x       subscript   i    subscript  y    x  i      subscript  n  x      \overline{y}_{x}=\frac{\sum_{i}y_{xi}}{n_{x}}   and      y  ¯   =      ∑  x      n  x     y  ¯   x        ∑  x     n  x      ,       normal-¯  y       subscript   x      subscript  n  x    subscript   normal-¯  y   x       subscript   x    subscript  n  x       \overline{y}=\frac{\sum_{x}n_{x}\overline{y}_{x}}{\sum_{x}n_{x}},     where     y  ¯   x     subscript   normal-¯  y   x    \overline{y}_{x}   is the mean of the category x and    y  ¯     normal-¯  y    \overline{y}   is the mean of the whole population. The correlation ratio η ( eta ) is defined as to satisfy       η  2   =     ∑  x     n  x     (     y  ¯   x   -   y  ¯    )   2       ∑   x  ,  i      (    y   x  i    -   y  ¯    )   2          superscript  η  2       subscript   x      subscript  n  x    superscript     subscript   normal-¯  y   x    normal-¯  y    2       subscript    x  i     superscript     subscript  y    x  i     normal-¯  y    2       \eta^{2}=\frac{\sum_{x}n_{x}(\overline{y}_{x}-\overline{y})^{2}}{\sum_{x,i}(y_%
 {xi}-\overline{y})^{2}}     which can be written as         η  2   =    σ   y  ¯     2    σ  y    2     ,    where   σ   y  ¯     2    =      ∑  x     n  x     (     y  ¯   x   -   y  ¯    )   2       ∑  x    n  x     and   σ  y    2    =     ∑   x  ,  i      (    y   x  i    -   y  ¯    )   2    n     ,     formulae-sequence     superscript  η  2      superscript   subscript  σ   normal-¯  y    2    superscript   subscript  σ  y   2           where   superscript   subscript  σ   normal-¯  y    2          subscript   x      subscript  n  x    superscript     subscript   normal-¯  y   x    normal-¯  y    2       subscript   x    subscript  n  x     and   superscript   subscript  σ  y   2             subscript    x  i     superscript     subscript  y    x  i     normal-¯  y    2    n       \eta^{2}=\frac{{\sigma_{\overline{y}}}^{2}}{{\sigma_{y}}^{2}},\text{ where }{%
 \sigma_{\overline{y}}}^{2}=\frac{\sum_{x}n_{x}(\overline{y}_{x}-\overline{y})^%
 {2}}{\sum_{x}n_{x}}\text{ and }{\sigma_{y}}^{2}=\frac{\sum_{x,i}(y_{xi}-%
 \overline{y})^{2}}{n},   i.e. the weighted variance of the category means divided by the variance of all samples.  It is worth noting that if the relationship between values of    x    x   x\;   and values of     y  ¯   x     subscript   normal-¯  y   x    \overline{y}_{x}   is linear (which is certainly true when there are only two possibilities for x ) this will give the same result as the square of Pearson's correlation coefficient , otherwise the correlation ratio will be larger in magnitude. It can therefore be used for judging non-linear relationships.  Range  The correlation ratio   η   η   \eta   takes values between 0 and 1. The limit    η  =  0      η  0    \eta=0   represents the special case of no dispersion among the means of the different categories, while    η  =  1      η  1    \eta=1   refers to no dispersion within the respective categories. Note further, that   η   η   \eta   is undefined when all data points of the complete population take the same value.  Example  Suppose there is a distribution of test scores in three topics (categories):   Algebra: 45, 70, 29, 15 and 21 (5 scores)  Geometry: 40, 20, 30 and 42 (4 scores)  Statistics: 65, 95, 80, 70, 85 and 73 (6 scores).   Then the subject averages are 36, 33 and 78, with an overall average of 52.  The sums of squares of the differences from the subject averages are 1952 for Algebra, 308 for Geometry and 600 for Statistics, adding to 2860. The overall sum of squares of the differences from the overall average is 9640. The difference of 6780 between these is also the weighted sum of the square of the differences between the subject averages and the overall average:        5    (   36  -  52   )   2    +   4    (   33  -  52   )   2    +   6    (   78  -  52   )   2     =  6780          5   superscript    36  52   2      4   superscript    33  52   2      6   superscript    78  52   2     6780    5(36-52)^{2}+4(33-52)^{2}+6(78-52)^{2}=6780   This gives       η  2   =   6780  9640   =   0.7033  …          superscript  η  2     6780  9640          0.7033  normal-…      \eta^{2}=\frac{6780}{9640}=0.7033\ldots   suggesting that most of the overall dispersion is a result of differences between topics, rather than within topics. Taking the square root      η  =    6780  9640    =   0.8386  …         η      6780  9640           0.8386  normal-…      \eta=\sqrt{\frac{6780}{9640}}=0.8386\ldots   Observe that for    η  =  1      η  1    \eta=1   the overall sample dispersion is purely due to dispersion among the categories and not at all due to dispersion within the individual categories. For a quick comprehension simply imagine all Algebra, Geometry, and Statistics scores being the same respectively, e.g. 5 times 36, 4 times 33, 6 times 78.  The limit    η  =  0      η  0    \eta=0   refers to the case without dispersion in the categories contributing to the overall dispersion. The trivial requirement for this extreme is that all category means are the same.  Pearson v. Fisher  The correlation ratio was introduced by Karl Pearson as part of analysis of variance . Ronald Fisher commented:   As a descriptive statistic the utility of the correlation ratio is extremely limited. It will be noticed that the number of degrees of freedom in the numerator of    η  2     superscript  η  2    \eta^{2}   depends on the number of the arrays 1   to which Egon Pearson (Karl's son) responded by saying   Again, a long-established method such as the use of the correlation ratio [§45 The "Correlation Ratio" η] is passed over in a few words without adequate description, which is perhaps hardly fair to the student who is given no opportunity of judging its scope for himself. 2   References    "  Category:Covariance and correlation  Category:Statistical ratios     Ronald Fisher (1926) Statistical Methods for Research Workers , ISBN 0-05-002170-2 (excerpt) ↩  Pearson E.S. (1926) "Review of Statistical Methods for Research Workers (R. A. Fisher)", Science Progress , 20, 733-734. (excerpt) ↩     