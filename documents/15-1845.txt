   Compressed sensing in speech signals      Compressed sensing in speech signals   Compressed Sensing (CS) can be used to reconstruct sparse vector from less number of measurements, provided the signal can be represented in sparse domain. Sparse domain is a domain in which only a few measurements have non-zero values. Suppose a signal    x  ∈   R  N       x   superscript  R  N     {x\in R^{N}}   can be represented in a domain where only   M   M   {\it M}   coefficients out of   N   N   {\it N}   (where    M  ≪  N     much-less-than  M  N    {M\ll N}   ) are non zero, then the signal is said to be sparse in that domain. This reconstructed sparse vector can be used to construct back the original signal if the sparse domain of signal is known. CS can be applied to speech signal only if sparse domain of speech signal is known.  Consider a speech signal   x   x   {x}   , which can be represented in a domain   Ψ   normal-Ψ   {\Psi}   such that    x  =   Ψ  𝜶       x    normal-Ψ  𝜶     {x}={\Psi\boldsymbol{\alpha}}   , where speech signal    x  ∈   R  N       x   superscript  R  N     {x\in R^{\it N}}   , dictionary matrix    Ψ  ∈   R   N  ×  N        normal-Ψ   superscript  R    N  N      {\Psi\in R^{\it{N\times N}}}   and the sparse coefficient vector    𝜶  ∈   R  N       𝜶   superscript  R  N     {\boldsymbol{\alpha}\in R^{\it N}}   . This speech signal is said to be sparse in domain   Ψ   normal-Ψ   {\Psi}   , if number of significant (non zero) coefficients in sparse vector   𝜶   𝜶   {\boldsymbol{\alpha}}   are   K   K   {\it{K}}   , where    K  ≪  N     much-less-than  K  N    {\it{K\ll N}}   .  The observed signal   x   x   {x}   is of dimension    N  ×  1      N  1    {\it{N\times 1}}   . To reduce the complexity for solving   𝜶   𝜶   {\boldsymbol{\alpha}}   using CS speech signal is observed using a measurement matrix   Φ   normal-Φ   {\Phi}   such that  where    y  ∈   R  M       y   superscript  R  M     {y\in R^{\it M}}   , and measurement matrix    Φ  ∈   R   M  ×  N        normal-Φ   superscript  R    M  N      {\Phi\in R^{\it M\times N}}   such that    M  ≪  N     much-less-than  M  N    {\it{M\ll N}}   .  Sparse decomposition problem for eq. 1 can be solved as standard    l  1     subscript  l  1    {l_{1}}   minimization 1 as  }=\mbox{minimize}\;\Vert \mathbf{\boldsymbol\alpha} \Vert_1 \;\;\;\;\mbox{s.t.}\;\;\;\; \mathbf{y}=\mathbf{\Phi x}=\mathbf{\Phi \Psi} \mathbf{\boldsymbol\alpha} = \mathbf{A \boldsymbol\alpha}, \;\mbox{where} \;\;\mathbf{A}=\mathbf{\Phi \Psi}}| 2 }}  If measurement matrix   Φ   normal-Φ   {\Phi}   satisfies the restricted isometric property (RIP) and is incoherent with dictionary matrix   Ψ   normal-Ψ   {\Psi}   . 2 then the reconstructed signal is much closer to the original speech signal.  Different types of measurement matrices like random matrices can be used for speech signals. 3 4 Estimating the sparsity of speech signal is a problem since speech signal highly varies over time and thus sparsity of speech signal also varies highly over time. If sparsity of speech signal can be calculated over time without much complexity that will be best. If this is not possible then worst-case scenario for sparsity can be considered for a given speech signal.  Sparse vector (    𝜶  ^     normal-^  𝜶    {\hat{\boldsymbol{\alpha}}}   ) for a given speech signals is reconstructed from less number of measurements (   y   y   {y}   ) using    l  1     subscript  l  1    {l_{1}}   minimization. 5 Then original speech signal is reconstructed form the calculated sparse vector    𝜶  ^     normal-^  𝜶    {\hat{\boldsymbol{\alpha}}}   using the fixed dictionary matrix as   Ψ   normal-Ψ   {\Psi}   as    x  ^     normal-^  x    {\hat{x}}   =   Ψ   normal-Ψ   {\Psi}       𝜶  ^     normal-^  𝜶    {\hat{\boldsymbol{\alpha}}}   . 6  Estimation of both the dictionary matrix and sparse vector from just random measurements only has been done iteratively in. 7 The speech signal reconstructed from estimated sparse vector and dictionary matrix is much closer to the original signal. Some more iterative approaches to calculate both dictionary matrix and speech signal from just random measurements of speech signal are shown in. 8 Th application of structured sparsity for joint speech localization-separation in reverberant acoustics has been investigated for multiparty speech recognition. 9 Further applications of the concept of sparsity are yet to be studied in the field of speech processing. The idea behind CS for speech signals is that can we come up with some algorithms or methods where we only use those random measurements (    y  )     fragments  y  normal-)    {y})   ) to do some application-based processing like speaker recognition, speech enhancement, 10 etc.  References  '  Category:Speech processing     ↩  ↩  ↩  ↩   ↩  ↩  ↩  ↩  ↩     