<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title offset="674">Schur product theorem</title>
   <script type="text/javascript"
      src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js">
    </script>
</head>
<body>
<h1>Schur product theorem</h1>
<hr/>
<p>In <a class="uri" href="mathematics" title="wikilink">mathematics</a>, particularly in <a href="linear_algebra" title="wikilink">linear algebra</a>, the <strong>Schur product theorem</strong> states that the <a href="Hadamard_product_(matrices)" title="wikilink">Hadamard product</a> of two <a href="positive_definite_matrices" title="wikilink">positive definite matrices</a> is also a positive definite matrix. The result is named after <a href="Issai_Schur" title="wikilink">Issai Schur</a><a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a> (Schur 1911, p. 14, Theorem VII) (note that Schur signed as J. Schur in <em>Journal für die reine und angewandte Mathematik</em>.<a class="footnoteRef" href="#fn2" id="fnref2"><sup>2</sup></a><a class="footnoteRef" href="#fn3" id="fnref3"><sup>3</sup></a>)</p>
<h2 id="proof">Proof</h2>
<h3 id="proof-using-the-trace-formula">Proof using the trace formula</h3>
<p>It is easy to show that for matrices <span class="LaTeX">$M$</span> and <span class="LaTeX">$N$</span>, the Hadamard product <span class="LaTeX">$M \circ N$</span> considered as a bilinear form acts on vectors <span class="LaTeX">$a, b$</span> as</p>
<p><span class="LaTeX">$$a^T (M \circ N) b = \operatorname{Tr}(M \operatorname{diag}(a) N \operatorname{diag}(b))$$</span> where <span class="LaTeX">$\operatorname{Tr}$</span> is the matrix <a href="Trace_(linear_algebra)" title="wikilink">trace</a> and <span class="LaTeX">$\operatorname{diag}(a)$</span> is the <a href="diagonal_matrix" title="wikilink">diagonal matrix</a> having as diagonal entries the elements of <span class="LaTeX">$a$</span>.</p>
<p>Since <span class="LaTeX">$M$</span> and <span class="LaTeX">$N$</span> are positive definite, we can consider their square-roots <span class="LaTeX">$M^{1/2}$</span> and <span class="LaTeX">$N^{1/2}$</span> and write</p>
<p><span class="LaTeX">$$\operatorname{Tr}(M \operatorname{diag}(a) N \operatorname{diag}(b)) = \operatorname{Tr}(M^{1/2} M^{1/2} \operatorname{diag}(a) N^{1/2} N^{1/2} \operatorname{diag}(b)) = \operatorname{Tr}(M^{1/2} \operatorname{diag}(a) N^{1/2} N^{1/2} \operatorname{diag}(b) M^{1/2})$$</span> Then, for <span class="LaTeX">$a=b$</span>, this is written as <span class="LaTeX">$\operatorname{Tr}(A^T A)$</span> for <span class="LaTeX">$A = N^{1/2} \operatorname{diag}(a) M^{1/2}$</span> and thus is positive. This shows that <span class="LaTeX">$(M \circ N)$</span> is a positive definite matrix.</p>
<h3 id="proof-using-gaussian-integration">Proof using Gaussian integration</h3>
<p>==== Case of <em>M</em> = <em>N</em> ====</p>
<p>Let <span class="LaTeX">$X$</span> be an <span class="LaTeX">$n$</span>-dimensional centered <a href="Gaussian_random_variable" title="wikilink">Gaussian random variable</a> with <a class="uri" href="covariance" title="wikilink">covariance</a> <span class="LaTeX">$\langle X_i X_j \rangle = M_{ij}$</span>. Then the covariance matrix of <span class="LaTeX">$X_i^2$</span> and <span class="LaTeX">$X_j^2$</span> is</p>
<p><span class="LaTeX">$$\operatorname{Cov}(X_i^2, X_j^2) = \langle X_i^2 X_j^2 \rangle - \langle X_i^2 \rangle \langle X_j^2 \rangle$$</span></p>
<p>Using <a href="Wick's_theorem" title="wikilink">Wick's theorem</a> to develop <span class="LaTeX">$\langle X_i^2 X_j^2 \rangle = 2 \langle X_i X_j \rangle^2 + \langle X_i^2 \rangle \langle X_j^2 \rangle$</span> we have</p>
<p><span class="LaTeX">$$\operatorname{Cov}(X_i^2, X_j^2) = 2 \langle X_i X_j \rangle^2 = 2 M_{ij}^2$$</span></p>
<p>Since a covariance matrix is positive definite, this proves that the matrix with elements <span class="LaTeX">$M_{ij}^2$</span> is a positive definite matrix.</p>
<h4 id="general-case">General case</h4>
<p>Let <span class="LaTeX">$X$</span> and <span class="LaTeX">$Y$</span> be <span class="LaTeX">$n$</span>-dimensional centered <a href="Gaussian_random_variable" title="wikilink">Gaussian random variables</a> with <a href="covariance" title="wikilink">covariances</a> <span class="LaTeX">$\langle X_i X_j \rangle = M_{ij}$</span>, <span class="LaTeX">$\langle Y_i Y_j \rangle = N_{ij}$</span> and independt from each other so that we have</p>
<p><span class="LaTeX">$$\langle X_i Y_j \rangle = 0$$</span> for any <span class="LaTeX">$i, j$</span> Then the covariance matrix of <span class="LaTeX">$X_i Y_i$</span> and <span class="LaTeX">$X_j Y_j$</span> is</p>
<p><span class="LaTeX">$$\operatorname{Cov}(X_i Y_i, X_j Y_j) = \langle X_i Y_i X_j Y_j \rangle - \langle X_i Y_i \rangle \langle X_j Y_j \rangle$$</span> Using <a href="Wick's_theorem" title="wikilink">Wick's theorem</a> to develop</p>
<p><span class="LaTeX">$$\langle X_i Y_i X_j Y_j \rangle = \langle X_i X_j \rangle \langle Y_i Y_j \rangle +  \langle X_i Y_i \rangle \langle X_j Y_j \rangle + \langle X_i Y_j \rangle \langle X_j Y_i \rangle$$</span> and also using the independence of <span class="LaTeX">$X$</span> and <span class="LaTeX">$Y$</span>, we have</p>
<p><span class="LaTeX">$$\operatorname{Cov}(X_i Y_i, X_j Y_j) = \langle X_i X_j \rangle \langle Y_i Y_j \rangle = M_{ij} N_{ij}$$</span> Since a covariance matrix is positive definite, this proves that the matrix with elements <span class="LaTeX">$M_{ij} N_{ij}$</span> is a positive definite matrix.</p>
<h3 id="proof-using-eigendecomposition">Proof using eigendecomposition</h3>
<h4 id="proof-of-positive-semidefiniteness">Proof of positive semidefiniteness</h4>
<p>Let <span class="LaTeX">$M = \sum \mu_i m_i m_i^T$</span> and <span class="LaTeX">$N = \sum \nu_i n_i n_i^T$</span>. Then</p>
<p><span class="LaTeX">$$M \circ N = \sum_{ij} \mu_i \nu_j (m_i m_i^T) \circ (n_j n_j^T) = \sum_{ij} \mu_i \nu_j (m_i \circ n_j) (m_i \circ n_j)^T$$</span> Each <span class="LaTeX">$(m_i \circ n_j) (m_i \circ n_j)^T$</span> is positive semidefinite (but, except in the 1-dimensional case, not positive definite, since they are <a href="Rank_(linear_algebra)" title="wikilink">rank</a> 1 matrices). Also, <span class="LaTeX">$\mu_i \nu_j > 0$</span> thus the sum <span class="LaTeX">$M \circ N$</span> is also positive semidefinite.</p>
<h4 id="proof-of-definiteness">Proof of definiteness</h4>
<p>To show that the result is positive definite requires further proof. We shall show that for any vector <span class="LaTeX">$a \neq 0$</span>, we have <span class="LaTeX">$a^T (M \circ N) a > 0$</span>. Continuing as above, each <span class="LaTeX">$a^T (m_i \circ n_j) (m_i \circ n_j)^T a \ge 0$</span>, so it remains to show that there exist <span class="LaTeX">$i$</span> and <span class="LaTeX">$j$</span> for which the inequality is strict. For this we observe that</p>
<p><span class="LaTeX">$$a^T (m_i \circ n_j) (m_i \circ n_j)^T a = \left(\sum_k m_{i,k} n_{j,k} a_k\right)^2$$</span></p>
<p>Since <span class="LaTeX">$N$</span> is positive definite, there is a <span class="LaTeX">$j$</span> for which <span class="LaTeX">$n_{j,k} a_k$</span> is not 0 for all <span class="LaTeX">$k$</span>, and then, since <span class="LaTeX">$M$</span> is positive definite, there is an <span class="LaTeX">$i$</span> for which <span class="LaTeX">$m_{i,k} n_{j,k} a_k$</span> is not 0 for all <span class="LaTeX">$k$</span>. Then for this <span class="LaTeX">$i$</span> and <span class="LaTeX">$j$</span> we have <span class="LaTeX">$\left(\sum_k m_{i,k} n_{j,k} a_k\right)^2 > 0$</span>. This completes the proof.</p>
<h2 id="references">References</h2>
<h2 id="external-links">External links</h2>
<ul>
<li><a href="https://eudml.org/doc/149352">Bemerkungen zur Theorie der beschränkten Bilinearformen mit unendlich vielen Veränderlichen</a> at <a href="https://eudml.org">EUDML</a></li>
</ul>
<p>"</p>
<p><a href="Category:Linear_algebra" title="wikilink">Category:Linear algebra</a> <a href="Category:Matrix_theory" title="wikilink">Category:Matrix theory</a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1"><a href="#fnref1">↩</a></li>
<li id="fn2">, page 9, Ch. 0.6 <em>Publication under J. Schur</em><a href="#fnref2">↩</a></li>
<li id="fn3"><a href="#fnref3">↩</a></li>
</ol>
</section>
</body>
</html>
