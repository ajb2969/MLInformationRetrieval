   TOPSIS      TOPSIS  The '''Technique for Order of Preference by Similarity to Ideal Solution''' ('''TOPSI S''') is a multi-criteria decision analysis method, which was originally developed by Hwang and Yoon in 1981 1 with further developments by Yoon in 1987, 2 and Hwang, Lai and Liu in 1993. 3 TOPSIS is based on the concept that the chosen alternative should have the shortest geometric distance from the positive ideal solution and the longest geometric distance from the negative ideal solution. It is a method of compensatory aggregation that compares a set of alternatives by identifying weights for each criterion, normalising scores for each criterion and calculating the geometric distance between each alternative and the ideal alternative, which is the best score in each criterion. An assumption of TOPSIS is that the criteria are monotonically increasing or decreasing. Normalisation is usually required as the parameters or criteria are often of incongruous dimensions in multi-criteria problems. 4 5 Compensatory methods such as TOPSIS allow trade-offs between criteria, where a poor result in one criterion can be negated by a good result in another criterion. This provides a more realistic form of modelling than non-compensatory methods, which include or exclude alternative solutions based on hard cut-offs. 6  TOPSIS method  The TOPSIS process is carried out as follows:   Step 1: Create an evaluation matrix consisting of m alternatives and n criteria, with the intersection of each alternative and criteria given as    x   i  j      subscript  x    i  j     x_{ij}   , we therefore have a matrix     (   x   i  j    )    m  ×  n      subscript   subscript  x    i  j      m  n     (x_{ij})_{m\times n}   .    Step 2: The matrix     (   x   i  j    )    m  ×  n      subscript   subscript  x    i  j      m  n     (x_{ij})_{m\times n}   is then normalised to form the matrix       R  =    (   r   i  j    )    m  ×  n        R   subscript   subscript  r    i  j      m  n      R=(r_{ij})_{m\times n}   , using the normalisation method      r   i  j    =    x   i  j        ∑   i  =  1   m     x   i  j   2       ,    i  =   1  ,  2  ,  …  ,  m    ,   j  =   1  ,  2  ,  …  ,  n        formulae-sequence     subscript  r    i  j       subscript  x    i  j        superscript   subscript     i  1    m    superscript   subscript  x    i  j    2        formulae-sequence    i   1  2  normal-…  m      j   1  2  normal-…  n       r_{ij}=\frac{x_{ij}}{\sqrt{\sum_{i=1}^{m}x_{ij}^{2}}},i=1,2,...,m,j=1,2,...,n      Step 3: Calculate the weighted normalised decision matrix        T  =    (   t   i  j    )    m  ×  n    =    (    w  j    r   i  j     )    m  ×  n     ,   i  =   1  ,  2  ,  …  ,  m       formulae-sequence      T   subscript   subscript  t    i  j      m  n          subscript     subscript  w  j    subscript  r    i  j       m  n        i   1  2  normal-…  m      T=(t_{ij})_{m\times n}=(w_{j}r_{ij})_{m\times n},i=1,2,...,m      Where      w  j   =    W  j   /    ∑   j  =  1   n    W  j      ,   j  =   1  ,  2  ,  …  ,  n       formulae-sequence     subscript  w  j      subscript  W  j     superscript   subscript     j  1    n    subscript  W  j        j   1  2  normal-…  n      w_{j}=W_{j}/\sum_{j=1}^{n}W_{j},j=1,2,...,n   so that      ∑   j  =  1   n    w  j    =  1        superscript   subscript     j  1    n    subscript  w  j    1    \sum_{j=1}^{n}w_{j}=1   , and    W  j     subscript  W  j    W_{j}   is the original weight given to the indicator        v  j   ,  j   =  1   ,   2  ,  …  ,  n    .     formulae-sequence      subscript  v  j   j   1    2  normal-…  n     v_{j},j=1,2,...,n.       Step 4: Determine the worst alternative    (   A  w   )     subscript  A  w    (A_{w})   and the best alternative    (   A  b   )     subscript  A  b    (A_{b})   :        A  w   =   {   ⟨  m  a  x   (   t   i  j    |  i  =  1  ,  2  ,  …  ,  m  )   |  j  ∈   J  -   ⟩   ,   ⟨  m  i  n   (   t   i  j    |  i  =  1  ,  2  ,  …  ,  m  )   |  j  ∈   J  +   ⟩   }   ≡   {   t   w  j    |  j  =  1  ,  2  ,  …  ,  n  }   ,     fragments   subscript  A  w     fragments  normal-{   fragments  normal-⟨  m  a  x   fragments  normal-(   subscript  t    i  j    normal-|  i   1  normal-,  2  normal-,  normal-…  normal-,  m  normal-)   normal-|  j    subscript  J    normal-⟩   normal-,   fragments  normal-⟨  m  i  n   fragments  normal-(   subscript  t    i  j    normal-|  i   1  normal-,  2  normal-,  normal-…  normal-,  m  normal-)   normal-|  j    subscript  J    normal-⟩   normal-}     fragments  normal-{   subscript  t    w  j    normal-|  j   1  normal-,  2  normal-,  normal-…  normal-,  n  normal-}   normal-,    A_{w}=\{\langle max(t_{ij}|i=1,2,...,m)|j\in J_{-}\rangle,\langle min(t_{ij}|i%
 =1,2,...,m)|j\in J_{+}\rangle\}\equiv\{t_{wj}|j=1,2,...,n\},        A  b   =   {   ⟨  m  i  n   (   t   i  j    |  i  =  1  ,  2  ,  …  ,  m  )   |  j  ∈   J  -   ⟩   ,   ⟨  m  a  x   (   t   i  j    |  i  =  1  ,  2  ,  …  ,  m  )   |  j  ∈   J  +   ⟩   }   ≡   {   t   b  j    |  j  =  1  ,  2  ,  …  ,  n  }   ,     fragments   subscript  A  b     fragments  normal-{   fragments  normal-⟨  m  i  n   fragments  normal-(   subscript  t    i  j    normal-|  i   1  normal-,  2  normal-,  normal-…  normal-,  m  normal-)   normal-|  j    subscript  J    normal-⟩   normal-,   fragments  normal-⟨  m  a  x   fragments  normal-(   subscript  t    i  j    normal-|  i   1  normal-,  2  normal-,  normal-…  normal-,  m  normal-)   normal-|  j    subscript  J    normal-⟩   normal-}     fragments  normal-{   subscript  t    b  j    normal-|  j   1  normal-,  2  normal-,  normal-…  normal-,  n  normal-}   normal-,    A_{b}=\{\langle min(t_{ij}|i=1,2,...,m)|j\in J_{-}\rangle,\langle max(t_{ij}|i%
 =1,2,...,m)|j\in J_{+}\rangle\}\equiv\{t_{bj}|j=1,2,...,n\},      where,        J  +   =   {  j  =  1  ,  2  ,  …  ,  n  |  j      fragments   subscript  J      fragments  normal-{  j   1  normal-,  2  normal-,  normal-…  normal-,  n  normal-|  j     J_{+}=\{j=1,2,...,n|j   associated with the criteria having a positive impact, and       J  -   =   {  j  =  1  ,  2  ,  …  ,  n  |  j      fragments   subscript  J      fragments  normal-{  j   1  normal-,  2  normal-,  normal-…  normal-,  n  normal-|  j     J_{-}=\{j=1,2,...,n|j   associated with the criteria having a negative impact.   Step 5: Calculate the L2-distance between the target alternative   i   i   i   and the worst condition    A  w     subscript  A  w    A_{w}            d   i  w    =     ∑   j  =  1   n     (    t   i  j    -   t   w  j     )   2      ,   i  =   1  ,  2  ,  …  ,  m       formulae-sequence     subscript  d    i  w        superscript   subscript     j  1    n    superscript     subscript  t    i  j     subscript  t    w  j     2        i   1  2  normal-…  m      d_{iw}=\sqrt{\sum_{j=1}^{n}(t_{ij}-t_{wj})^{2}},i=1,2,...,m   ,  and the distance between the alternative   i   i   i   and the best condition    A  b     subscript  A  b    A_{b}           d   i  b    =     ∑   j  =  1   n     (    t   i  j    -   t   b  j     )   2      ,   i  =   1  ,  2  ,  …  ,  m       formulae-sequence     subscript  d    i  b        superscript   subscript     j  1    n    superscript     subscript  t    i  j     subscript  t    b  j     2        i   1  2  normal-…  m      d_{ib}=\sqrt{\sum_{j=1}^{n}(t_{ij}-t_{bj})^{2}},i=1,2,...,m      where    d   i  w      subscript  d    i  w     d_{iw}   and    d   i  b      subscript  d    i  b     d_{ib}   are L2-norm distances from the target alternative   i   i   i   to the worst and best conditions, respectively.    Step 6: Calculate the similarity to the worst condition:          s   i  w    =    d   i  w    /   (    d   i  w    +   d   i  b     )     ,   0  ≤   s   i  w    ≤  1    ,   i  =   1  ,  2  ,  …  ,  m       formulae-sequence   formulae-sequence     subscript  s    i  w       subscript  d    i  w       subscript  d    i  w     subscript  d    i  b           0   subscript  s    i  w         1       i   1  2  normal-…  m      s_{iw}=d_{iw}/(d_{iw}+d_{ib}),0\leq s_{iw}\leq 1,i=1,2,...,m   .       s   i  w    =  1       subscript  s    i  w    1    s_{iw}=1   if and only if the alternative solution has the best condition; and       s   i  w    =  0       subscript  s    i  w    0    s_{iw}=0   if and only if the alternative solution has the worst condition.   Step 7: Rank the alternatives according to     s   i  w     (  i  =  1  ,  2  ,  …  ,  m  )      fragments   subscript  s    i  w     fragments  normal-(  i   1  normal-,  2  normal-,  normal-…  normal-,  m  normal-)     s_{iw}(i=1,2,...,m)   .   Normalisation  Two methods of normalisation that have been used to deal with incongruous criteria dimensions are linear normalisation and vector normalisation.  Linear normalisation can be calculated as in Step 2 of the TOPSIS process above. Vector normalisation was incorporated with the original development of the TOPSIS method, 7 and is calculated using the following formula:        r   i  j    =    x   i  j        ∑   i  =  1   m     x   i  j   2       ,    i  =   1  ,  2  ,  …  ,  m    ,   j  =   1  ,  2  ,  …  ,  n        formulae-sequence     subscript  r    i  j       subscript  x    i  j        superscript   subscript     i  1    m    superscript   subscript  x    i  j    2        formulae-sequence    i   1  2  normal-…  m      j   1  2  normal-…  n       r_{ij}=\frac{x_{ij}}{\sqrt{\sum_{i=1}^{m}x_{ij}^{2}}},i=1,2,...,m,j=1,2,...,n     In using vector normalisation, the non-linear distances between single dimension scores and ratios should produce smoother trade-offs. 8  Assumptions   1. The value and suitability of each criterion should be linearly decreasing or increasing. 2. The criteria should be independent.   Advantages   1. Easy decision making using both negative and positive criteria. 2. Number of criteria can be applied during the decision process. 3. Simple and faster than AHP, FDAHP,SAW.   References  8. I. Beg and T. Rashid: Multi-criteria trapezoidal valued intuitionistic fuzzy decision making with Choquet integral based TOPSIS, OPSEARCH, 51(1) (2014), 98-129.  "  Category:Decision theory     ↩  ↩  ↩  ↩  ↩  ↩   ↩     