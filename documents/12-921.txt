


Lattice problem




Lattice problem

In computer science, lattice problems are a class of optimization problems on lattices. The conjectured intractability of such problems is central to construction of secure lattice-based cryptosystems. For applications in such cryptosystems, lattices over vector spaces (often 
 
 
 
 ) or free modules (often 
 
 
 
 ) are generally considered.
For all the problems below, assume that we are given (in addition to other more specific inputs) a basis for the vector space V and a norm N. The norms usually considered are L2. However, other norms (such as Lp) are also considered and show up in a variety of results.1 Let 
 
 
 
  denote the length of the shortest non-zero vector in the lattice L, that is,


 
 .
Shortest vector problem (SVP)
In SVP, a basis of a vector space V and a norm N (often L2) are given for a lattice L and one must find the shortest non-zero vector in V, as measured by N, in L. In other words, the algorithm should output a non-zero vector v such that 
 
 
 
 .
In the 
 
 
 
 -approximation version 
 
 
 
 , one must find a non-zero lattice vector of length at most 
 
 
 
 .
Known results
The exact version of the problem is only known to be NP-hard for randomized reductions.23
By contrast, the equivalent problem with respect to the uniform norm is known to be NP-hard 4
Approach techniques: Lenstra–Lenstra–Lovász lattice basis reduction algorithm produces a "relatively short vector" in polynomial time, but does not solve the problem. Kannan's HKZ basis reduction algorithm solves the problem in 
 
 
 
  time where n is the dimension. Lastly, Schnorr presented a technique that interpolates between LLL and HKZ called Block Reduction. Block reduction works with HKZ bases and if the number of blocks is chosen to be larger than the dimension, the resulting algorithm Kannan's full HKZ basis reduction.
GapSVP
The problem 
 
 
 
  consists of differentiating between the instances of SVP in which the answer is at most 1 or larger than 
 
 
 
 , where 
 
 
 
  can be a fixed function of 
 
 
 
 , the number of vectors. Given a basis for the lattice, the algorithm must decide whether 
 
 
 
  or 
 
 
 
 . Like other promise problems, the algorithm is allowed to err on all other cases.
Yet another version of the problem is 
 
 
 
  for some functions 
 
 
 
 . The input to the algorithm is a basis 
 
 
 
  and a number 
 
 
 
 . It is assured that all the vectors in the Gram–Schmidt orthogonalization are of length at least 1, and that 
 
 
 
  and that 
 
 
 
  where 
 
 
 
  is the dimension. The algorithm must accept if 
 
 
 
 , and reject if 
 
 
 
 . For large 
 
 
 
  (
 
 
 
 ), the problem is equivalent to 
 
 
 
  because5 a preprocessing done using the LLL algorithm makes the second condition (and hence, 
 
 
 
 ) redundant.
Closest vector problem (CVP)
Image:Svp09.png|The SVP by example Image:Cvp3.png|The CVP by example
In CVP, a basis of a vector space V and a metric M (often L2) are given for a lattice L, as well as a vector v in V but not necessarily in L. It is desired to find the vector in L closest to v (as measured by M). In the 
 
 
 
 -approximation version 
 
 
 
 , one must find a lattice vector at distance at most 
 
 
 
 .
Relationship with SVP
The closest vector problem is a generalization of the shortest vector problem. It is easy to show that given an oracle for 
 
 
 
  (defined below), one can solve 
 
 
 
  by making some queries to the oracle.6 The naive method to find the shortest vector by calling the 
 
 
 
  oracle to find the closest vector to 0 does not work because 0 is itself a lattice vector and the algorithm could potentially output 0.
The reduction from 
 
 
 
  to 
 
 
 
  is as follows: Suppose that the input to the 
 
 
 
  problem is the basis for lattice 
 
 
 
 . Consider the basis 
 
 
 
  and let 
 
 
 
  be the vector returned by 
 
 
 
 . The claim is that the shortest vector in the set 
 
 
 
  is the shortest vector in the given lattice.
Known results
Goldreich et al. showed that any hardness of SVP implies the same hardness for CVP.7 Using PCP tools, Arora et al. showed that CVP is hard to approximate within factor 
 
 
 
  unless 
 
 
 
 .8 Dinur et al. strengthened this by giving a NP-hardness result with 
 
 
 
  for 
 
 
 
 .9
Sphere decoding
The algorithm for CVP, especially the Fincke and Pohst variant,10 have been used for data detection in multiple-input multiple-output (MIMO) wireless communication systems (for coded and uncoded signals).1112 In this context it is called sphere decoding due to the radius used internal to many CVP solutions.13
It has been applied in the field of the integer ambiguity resolution of carrier-phase GNSS (GPS).14 It is called LAMBDA method in that field.
GapCVP
This problem is similar to the GapSVP problem. For 
 
 
 
 , the input consists of a lattice basis and a vector 
 
 
 
  and the algorithm must answer whether

there is a lattice vector such that the distance between it and 
 
 
 
  is at most 1.
every lattice vector is at a distance greater than 
 
 
 
  away from 
 
 
 
 .

Known results
The problem is trivially contained in NP for any approximation factor.
Schnorr, in 1987, showed that deterministic polynomial time algorithms can solve the problem for 
 
 
 
 .15 Ajtai et al. showed that probabilistic algorithms can achieve a slightly better approximation factor of 
 
 
 
 .16
In 1993, Banaszczyk showed that 
 
 
 
  is in 
 
 
 
 .17 In 2000, Goldreich and Goldwasser showed that 
 
 
 
  puts the problem in both NP and coAM.18 In 2005, Aharonov and Regev showed that for some constant 
 
 
 
 , the problem with 
 
 
 
  is in 
 
 
 
 .19
For lower bounds, Dinur et al. showed in 1998 that the problem is NP-hard for 
 
 
 
 .20
Shortest independent vectors problem (SIVP)
Given a lattice L of dimension n, the algorithm must output n linearly independent

 
  so that 
 
 
 
  where the right hand side considers all basis 
 
 
 
  of the lattice.
In the 
 
 
 
 -approximate version, given a lattice L with dimension n, find n linearly independent vectors 
 
 
 
  of length max ||
 
 
 
 || ≤ 
 
 
 
 , where 
 
 
 
  is the 
 
 
 
 'th successive minimum of 
 
 
 
 .
Bounded distance decoding
This problem is similar to CVP. Given a vector such that its distance from the lattice is at most 
 
 
 
 , the algorithm must output the closest lattice vector to it.
Covering radius problem
Given a basis for the lattice, the algorithm must find the largest distance (or in some versions, its approximation) from any vector to the lattice.
Shortest basis problem
Many problems become easier if the input basis consists of short vectors. An algorithm that solves the Shortest Basis Problem (SBP) must, given a lattice basis
 
 
 
 , output an equivalent basis 
 
 
 
  such that the length of the longest vector in 
 
 
 
  is as short as possible.
The approximation version 
 
 
 
  problem consist of finding a basis whose longest vector is at most 
 
 
 
  times longer than the longest vector in the shortest basis.
Use in cryptography
Average case hardness of problems forms a basis for proofs-of-security for most cryptographic schemes. However, experimental evidence suggests that most NP-hard problems lack this property: they are probably only worst case hard. Many lattice problems have been conjectured or proven to be average-case hard, making them an attractive class of problems to base cryptographic schemes on. Moreover, worst-case hardness of some lattice problems have been used to create secure cryptographic schemes. The use of worst-case hardness in such schemes makes them among the very few schemes that are very likely secure even against quantum computers.
The above lattice problems are easy to solve if the algorithm is provided with a "good" basis. Lattice reduction algorithms aim, given a basis for a lattice, to output a new basis consisting of relatively short, nearly orthogonal vectors. The Lenstra–Lenstra–Lovász lattice basis reduction algorithm (LLL) was an early efficient algorithm for this problem which could output an almost reduced lattice basis in polynomial time.21 This algorithm and its further refinements were used to break several cryptographic schemes, establishing its status as a very important tool in cryptanalysis. The success of LLL on experimental data led to a belief that lattice reduction might be an easy problem in practice. However, this belief was challenged when in the late 1990s, several new results on the hardness of lattice problems were obtained, starting with the result of Ajtai.22
In his seminal papers, Ajtai showed that the SVP problem was NP-hard and discovered some connections between the worst-case complexity and average-case complexity of some lattice problems.2324 Building on these results, Ajtai and Dwork created a public-key cryptosystem whose security could be proven using only the worst case hardness of a certain version of SVP,25 thus making it the first result to have used worst-case hardness to create secure systems.26
See also

Learning with errors

References
Further reading





"
Category:Computational hardness assumptions Category:Lattice-based cryptography Category:Mathematical problems



↩

↩
↩
↩
↩
↩
↩
↩
↩
↩
↩
↩
↩
↩
↩
↩
↩
↩
↩
↩
↩

↩
↩
↩




