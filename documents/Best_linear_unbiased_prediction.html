<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="44">Best linear unbiased prediction</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>Best linear unbiased prediction</h1>
<hr/>

<p>In <a class="uri" href="statistics" title="wikilink">statistics</a>, <strong>best linear unbiased prediction</strong> (<strong>BLUP</strong>) is used in linear <a href="mixed_model" title="wikilink">mixed models</a> for the estimation of <a href="random_effects_model" title="wikilink">random effects</a>. BLUP was derived by <a href="Charles_Roy_Henderson" title="wikilink">Charles Roy Henderson</a> in 1950 but the term "best linear unbiased predictor" (or "prediction") seems not to have been used until 1962.<a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a> "Best linear unbiased predictions" (BLUPs) of random effects are similar to best linear unbiased estimates (BLUEs) (see <a href="Gauss–Markov_theorem" title="wikilink">Gauss–Markov theorem</a>) of fixed effects. The distinction arises because it is conventional to talk about <em>estimating</em> fixed effects but <em>predicting</em> random effects, but the two terms are otherwise equivalent. (This is a bit strange since the random effects have already been "realized" − they already exist. The use of the term "prediction" may be because in the field of animal breeding in which Henderson worked, the random effects were usually genetic merit, which could be used to predict the quality of offspring (Robinson<a class="footnoteRef" href="#fn2" id="fnref2"><sup>2</sup></a> page 28)). However, the equations for the "fixed" effects and for the random effects are different.</p>

<p>In practice, it is often the case that the parameters associated with the random effect(s) term(s) are unknown; these parameters are the variances of the random effects and residuals. Typically the parameters are estimated and plugged into the predictor, leading to the <a href="Empirical_Best_Linear_Unbiased_Predictor" title="wikilink">Empirical Best Linear Unbiased Predictor</a> (EBLUP). Notice that by simply plugging in the estimated parameter into the predictor, additional variability is unaccounted for, leading to overly optimistic prediction variances for the EBLUP.</p>

<p>Best linear unbiased predictions are similar to <a href="empirical_Bayes" title="wikilink">empirical Bayes</a> estimates of random effects in linear mixed models, except that in the latter case, where weights depend on unknown values of components of variance, these unknown variances are replaced by sample-based estimates.</p>
<h2 id="example">Example</h2>

<p>Suppose that the model for observations {<em>Y</em><sub><em>j</em></sub>; <em>j</em> = 1, ..., <em>n</em>} is written as</p>

<p>

<math display="block" id="Best_linear_unbiased_prediction:0">
 <semantics>
  <mrow>
   <mrow>
    <msub>
     <mi>Y</mi>
     <mi>j</mi>
    </msub>
    <mo>=</mo>
    <mrow>
     <mi>μ</mi>
     <mo>+</mo>
     <mrow>
      <msubsup>
       <mi>x</mi>
       <mi>j</mi>
       <mi>T</mi>
      </msubsup>
      <mi>β</mi>
     </mrow>
     <mo>+</mo>
     <msub>
      <mi>ξ</mi>
      <mi>j</mi>
     </msub>
     <mo>+</mo>
     <msub>
      <mi>ε</mi>
      <mi>j</mi>
     </msub>
    </mrow>
   </mrow>
   <mo>,</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>Y</ci>
     <ci>j</ci>
    </apply>
    <apply>
     <plus></plus>
     <ci>μ</ci>
     <apply>
      <times></times>
      <apply>
       <csymbol cd="ambiguous">superscript</csymbol>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <ci>x</ci>
        <ci>j</ci>
       </apply>
       <ci>T</ci>
      </apply>
      <ci>β</ci>
     </apply>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>ξ</ci>
      <ci>j</ci>
     </apply>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>ε</ci>
      <ci>j</ci>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   Y_{j}=\mu+x_{j}^{T}\beta+\xi_{j}+\varepsilon_{j},\,
  </annotation>
 </semantics>
</math>

</p>

<p>where <em>ξ<sub>j</sub></em> and <em>ε<sub>j</sub></em> represent the random effect and observation error for observation <em>j</em>, and suppose they are uncorrelated and have known variances <em>σ<sub>ξ</sub></em><sup>2</sup> and <em>σ<sub>ε</sub></em><sup>2</sup>, respectively. Further, <em>x<sub>j</sub></em> is a vector of <a href="dependent_and_independent_variables" title="wikilink">independent variables</a> for the <em>j</em>th observation and <em>β</em> is a vector of regression parameters. The BLUP problem of providing an estimate of the observation-error-free value for the <em>k</em>th observation,</p>

<p>

<math display="block" id="Best_linear_unbiased_prediction:1">
 <semantics>
  <mrow>
   <mrow>
    <mover accent="true">
     <msub>
      <mi>Y</mi>
      <mi>k</mi>
     </msub>
     <mo stretchy="false">~</mo>
    </mover>
    <mo>=</mo>
    <mrow>
     <mi>μ</mi>
     <mo>+</mo>
     <mrow>
      <msubsup>
       <mi>x</mi>
       <mi>k</mi>
       <mi>T</mi>
      </msubsup>
      <mi>β</mi>
     </mrow>
     <mo>+</mo>
     <msub>
      <mi>ξ</mi>
      <mi>k</mi>
     </msub>
    </mrow>
   </mrow>
   <mo>,</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <ci>normal-~</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>Y</ci>
      <ci>k</ci>
     </apply>
    </apply>
    <apply>
     <plus></plus>
     <ci>μ</ci>
     <apply>
      <times></times>
      <apply>
       <csymbol cd="ambiguous">superscript</csymbol>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <ci>x</ci>
        <ci>k</ci>
       </apply>
       <ci>T</ci>
      </apply>
      <ci>β</ci>
     </apply>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>ξ</ci>
      <ci>k</ci>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \tilde{Y_{k}}=\mu+x_{k}^{T}\beta+\xi_{k},
  </annotation>
 </semantics>
</math>

</p>

<p>can be formulated as requiring that the coefficients of a linear predictor, defined as</p>

<p>

<math display="block" id="Best_linear_unbiased_prediction:2">
 <semantics>
  <mrow>
   <mrow>
    <mover accent="true">
     <msub>
      <mi>Y</mi>
      <mi>k</mi>
     </msub>
     <mo>^</mo>
    </mover>
    <mo>=</mo>
    <mrow>
     <munderover>
      <mo largeop="true" movablelimits="false" symmetric="true">∑</mo>
      <mrow>
       <mi>j</mi>
       <mo>=</mo>
       <mn>1</mn>
      </mrow>
      <mi>n</mi>
     </munderover>
     <mrow>
      <msub>
       <mi>c</mi>
       <mrow>
        <mi>j</mi>
        <mo>,</mo>
        <mi>k</mi>
       </mrow>
      </msub>
      <msub>
       <mi>Y</mi>
       <mi>j</mi>
      </msub>
     </mrow>
    </mrow>
   </mrow>
   <mo>,</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <ci>normal-^</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>Y</ci>
      <ci>k</ci>
     </apply>
    </apply>
    <apply>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <sum></sum>
       <apply>
        <eq></eq>
        <ci>j</ci>
        <cn type="integer">1</cn>
       </apply>
      </apply>
      <ci>n</ci>
     </apply>
     <apply>
      <times></times>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>c</ci>
       <list>
        <ci>j</ci>
        <ci>k</ci>
       </list>
      </apply>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>Y</ci>
       <ci>j</ci>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \widehat{Y_{k}}=\sum_{j=1}^{n}c_{j,k}Y_{j},
  </annotation>
 </semantics>
</math>

</p>

<p>should be chosen so as to minimise the variance of the prediction error,</p>

<p>

<math display="block" id="Best_linear_unbiased_prediction:3">
 <semantics>
  <mrow>
   <mrow>
    <mi>V</mi>
    <mo>=</mo>
    <mrow>
     <mo>Var</mo>
     <mrow>
      <mo stretchy="false">(</mo>
      <mrow>
       <mover accent="true">
        <msub>
         <mi>Y</mi>
         <mi>k</mi>
        </msub>
        <mo stretchy="false">~</mo>
       </mover>
       <mo>-</mo>
       <mover accent="true">
        <msub>
         <mi>Y</mi>
         <mi>k</mi>
        </msub>
        <mo>^</mo>
       </mover>
      </mrow>
      <mo stretchy="false">)</mo>
     </mrow>
    </mrow>
   </mrow>
   <mo>,</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <ci>V</ci>
    <apply>
     <ci>Var</ci>
     <apply>
      <minus></minus>
      <apply>
       <ci>normal-~</ci>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <ci>Y</ci>
        <ci>k</ci>
       </apply>
      </apply>
      <apply>
       <ci>normal-^</ci>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <ci>Y</ci>
        <ci>k</ci>
       </apply>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   V=\operatorname{Var}(\tilde{Y_{k}}-\widehat{Y_{k}}),
  </annotation>
 </semantics>
</math>

</p>

<p>subject to the condition that the predictor is unbiased,</p>

<p>

<math display="block" id="Best_linear_unbiased_prediction:4">
 <semantics>
  <mrow>
   <mrow>
    <mo>E</mo>
    <mrow>
     <mo stretchy="false">(</mo>
     <mrow>
      <mover accent="true">
       <msub>
        <mi>Y</mi>
        <mi>k</mi>
       </msub>
       <mo stretchy="false">~</mo>
      </mover>
      <mo>-</mo>
      <mover accent="true">
       <msub>
        <mi>Y</mi>
        <mi>k</mi>
       </msub>
       <mo>^</mo>
      </mover>
     </mrow>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
   <mo>=</mo>
   <mn>0.</mn>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <ci>normal-E</ci>
     <apply>
      <minus></minus>
      <apply>
       <ci>normal-~</ci>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <ci>Y</ci>
        <ci>k</ci>
       </apply>
      </apply>
      <apply>
       <ci>normal-^</ci>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <ci>Y</ci>
        <ci>k</ci>
       </apply>
      </apply>
     </apply>
    </apply>
    <cn type="float">0.</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \operatorname{E}(\tilde{Y_{k}}-\widehat{Y_{k}})=0.
  </annotation>
 </semantics>
</math>

</p>
<h2 id="blup-vs-blue">BLUP vs BLUE</h2>

<p>In contrast to the case of <a href="Best_linear_unbiased_estimator" title="wikilink">best linear unbiased estimation</a>, the "quantity to be estimated", 

<math display="inline" id="Best_linear_unbiased_prediction:5">
 <semantics>
  <mover accent="true">
   <msub>
    <mi>Y</mi>
    <mi>k</mi>
   </msub>
   <mo stretchy="false">~</mo>
  </mover>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <ci>normal-~</ci>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>Y</ci>
     <ci>k</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \tilde{Y_{k}}
  </annotation>
 </semantics>
</math>

, not only has a contribution from a random element but one of the observed quantities, specifically 

<math display="inline" id="Best_linear_unbiased_prediction:6">
 <semantics>
  <msub>
   <mi>Y</mi>
   <mi>k</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>Y</ci>
    <ci>k</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   Y_{k}
  </annotation>
 </semantics>
</math>

 which contributes to 

<math display="inline" id="Best_linear_unbiased_prediction:7">
 <semantics>
  <mover accent="true">
   <msub>
    <mi>Y</mi>
    <mi>k</mi>
   </msub>
   <mo>^</mo>
  </mover>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <ci>normal-^</ci>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>Y</ci>
     <ci>k</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \widehat{Y_{k}}
  </annotation>
 </semantics>
</math>

, also has a contribution from this same random element.</p>

<p>In contrast to BLUE, BLUP takes into account known or estimated variances.<a class="footnoteRef" href="#fn3" id="fnref3"><sup>3</sup></a></p>
<h2 id="see-also">See also</h2>
<ul>
<li><a href="Minimum_mean_square_error" title="wikilink">Minimum mean square error</a></li>
</ul>
<h2 id="tutorials">Tutorials</h2>
<ul>
<li><a href="http://www.extension.org/pages/61006/the-solcap-tomato-phenotypic-data:-estimating-heritability-and-blups-for-traits#.Ui4zjWRgYXc">Estimating BLUPs and Heritability Using R</a></li>
<li><a href="http://www.extension.org/pages/68019/genomic-relationships-and-gblup">Genomic Relationships and GBLUP</a></li>
<li><a href="http://www.extension.org/pages/66590/rrblup-package-in-r-for-genomewide-selection">Ridge Regression, rrBLUP for Genome-Wide Selection</a></li>
</ul>
<h2 id="notes">Notes</h2>
<references>
</references>
<h2 id="references">References</h2>
<ul>
<li></li>
<li>Xu-Qing Liu, Jian-Ying Rong, Xiu-Ying Liu (2008), "Best linear unbiased prediction for linear combinations in general mixed linear models", <em><a href="Journal_of_Multivariate_Analysis" title="wikilink">Journal of Multivariate Analysis</a></em>, 99 (8),1503–1517. .</li>
</ul>

<p>"</p>

<p><a href="Category:Statistical_methods" title="wikilink">Category:Statistical methods</a> <a href="Category:Estimation_theory" title="wikilink">Category:Estimation theory</a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1"><a href="#fnref1">↩</a></li>
<li id="fn2"></li>
<li id="fn3"><a href="#fnref3">↩</a></li>
</ol>
</section>
</body>
</html>
