<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="72">Big M method</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>Big M method</h1>
<hr/>

<p>In <a href="operations_research" title="wikilink">operations research</a>, the <strong>Big M method</strong> is a method of solving <a href="linear_programming" title="wikilink">linear programming</a> problems using the <a href="simplex_algorithm" title="wikilink">simplex algorithm</a>. The Big M method extends the power of the simplex algorithm to problems that contain "greater-than" constraints. It does so by associating the constraints with large negative constants which would not be part of any optimal solution, if it exists.</p>
<h2 id="algorithm">Algorithm</h2>

<p>The simplex algorithm is the original and still one of the most widely used methods for solving linear maximization problems. However, to apply it, the origin (all variables equal to 0) must be a feasible point. This condition is satisfied only when all the constraints (except non-negativity) are less-than constraints with a positive constant on the right-hand side. The Big M method introduces surplus and artificial variables to convert all inequalities into that form. The "Big M" refers to a large number associated with the artificial variables, represented by the letter M.</p>

<p>The steps in the algorithm are as follows:</p>
<ol>
<li>Multiply the inequality constraints to ensure that the right hand side is positive.</li>
<li>If the problem is of minimization, transform to maximization by multiplying the objective by -1</li>
<li>For any greater-than constraints, introduce surplus and artificial variables (as shown below)</li>
<li>Choose a large positive M and introduce a term in the objective of the form -M multiplying the artificial variables</li>
<li>For less-than or equal constraints, introduce slack variables so that all constraints are equalities</li>
<li>Solve the problem using the usual simplex method.</li>
</ol>

<p>For example <em>x</em> + <em>y</em> ≤  100 becomes <em>x</em> + <em>y</em> + <em>s</em><sub>1</sub> = 100, whilst <em>x</em> + <em>y</em> ≥ 100 becomes <em>x</em> + <em>y</em> − <em>a</em><sub>1</sub> = 100. The artificial variables must be shown to be 0. The function to be maximised is rewritten to include the sum of all the artificial variables. Then <a href="row_reductions" title="wikilink">row reductions</a> are applied to gain a final solution.</p>

<p>The value of M must be chosen sufficiently large so that the artificial variable would not be part of any feasible solution.</p>

<p>For a sufficiently large M, the optimal solution contains any artificial variables in the basis (i.e. positive values) if and only if the problem is not feasible.</p>
<h2 id="other-usage">Other usage</h2>

<p>The Big M method sometimes refers to any formulation of a linear optimization problem in which violations of a constraint are associated with a large positive penalty constant, M.</p>

<p>Another usage refers to using a large positive constant, M, to ensure that the constraint is not tight. For example, suppose x and y are ≥ 0. Then for a sufficiently large M and z binary variable (0 or 1), the following constraint ensures that when z=1, x=y: 

<math display="inline" id="Big_M_method:0">
 <semantics>
  <mrow>
   <mrow>
    <mi>x</mi>
    <mo>-</mo>
    <mi>y</mi>
   </mrow>
   <mo>≤</mo>
   <mrow>
    <mi>M</mi>
    <mrow>
     <mo stretchy="false">(</mo>
     <mrow>
      <mn>1</mn>
      <mo>-</mo>
      <mi>z</mi>
     </mrow>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <leq></leq>
    <apply>
     <minus></minus>
     <ci>x</ci>
     <ci>y</ci>
    </apply>
    <apply>
     <times></times>
     <ci>M</ci>
     <apply>
      <minus></minus>
      <cn type="integer">1</cn>
      <ci>z</ci>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   x-y\leq M(1-z)
  </annotation>
 </semantics>
</math>

</p>
<h2 id="see-also">See also</h2>
<ul>
<li><a href="Two_phase_method_(linear_programming)" title="wikilink">Two phase method (linear programming)</a> another approach for solving problems with &gt;= constraints</li>
<li><a href="Karush–Kuhn–Tucker_conditions" title="wikilink">Karush–Kuhn–Tucker conditions</a>, which apply to <a href="Non-Linear_Optimization" title="wikilink">Non-Linear Optimization</a> problems with inequality constraints.</li>
</ul>
<h2 id="references-and-external-links">References and external links</h2>

<p><strong>Bibliography</strong></p>
<ul>
<li></li>
</ul>

<p><strong>Discussion</strong></p>
<ul>
<li><a href="http://www.computing.dcu.ie/~lkillen/teach/CA427Simplexbigmexample.pdf">Simplex – Big M Method</a>, Lynn Killen, <a href="Dublin_City_University" title="wikilink">Dublin City University</a>.</li>
<li><a href="http://businessmanagementcourses.org/Lesson09TheBigMMethod.pdf">The Big M Method</a>, businessmanagementcourses.org</li>
<li><a href="http://hutchies.iconbar.com/bigm.html">The Big M Method</a>, Mark Hutchinson</li>
</ul>

<p>"</p>

<p><a href="Category:Optimization_algorithms_and_methods" title="wikilink">Category:Optimization algorithms and methods</a> <a href="Category:Operations_research" title="wikilink">Category:Operations research</a> <a href="Category:Linear_algebra" title="wikilink">Category:Linear algebra</a></p>
</body>
</html>
