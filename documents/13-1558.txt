   Tukey's test of additivity      Tukey's test of additivity   In statistics , Tukey's test of additivity , 1 named for John Tukey , is an approach used in two-way ANOVA ( regression analysis involving two qualitative factors) to assess whether the factor variables are additively related to the expected value of the response variable. It can be applied when there are no replicated values in the data set, a situation in which it is impossible to directly estimate a fully general non-additive regression structure and still have information left to estimate the error variance. The test statistic proposed by Tukey has one degree of freedom under the null hypothesis, hence this is often called "Tukey's one-degree-of-freedom test."  Introduction  The most common setting for Tukey's test of additivity is a two-way factorial Analysis of Variance (ANOVA) with one observation per cell. The response variable Y ij is observed in a table of cells with the rows indexed by i = 1,..., m and the columns indexed by j = 1,..., n . The rows and columns typically correspond to various types and levels of treatment that are applied in combination.  The additive model states that the expected response can be expressed EY ij = μ + α i + β j , where the α i and β j are unknown constant values. The unknown model parameters are usually estimated as       μ  ^   =    Y  ¯     ⋅  ⋅         normal-^  μ    subscript   normal-¯  Y    normal-⋅  absent  normal-⋅      \hat{\mu}=\bar{Y}_{\cdot\cdot}           α  ^   i   =     Y  ¯    i  ⋅    -    Y  ¯     ⋅  ⋅          subscript   normal-^  α   i      subscript   normal-¯  Y    i  normal-⋅     subscript   normal-¯  Y    normal-⋅  absent  normal-⋅       \hat{\alpha}_{i}=\bar{Y}_{i\cdot}-\bar{Y}_{\cdot\cdot}            β  ^   j   =     Y  ¯     ⋅  j    -    Y  ¯     ⋅  ⋅      .       subscript   normal-^  β   j      subscript   normal-¯  Y    normal-⋅  absent  j     subscript   normal-¯  Y    normal-⋅  absent  normal-⋅       \hat{\beta}_{j}=\bar{Y}_{\cdot j}-\bar{Y}_{\cdot\cdot}.     where Y i • is the mean of the i th row of the data table, Y • j is the mean of the j th column of the data table, and Y •• is the overall mean of the data table.  The additive model can be generalized to allow for arbitrary interaction effects by setting EY ij = μ + α i + β j + γ ij . However after fitting the natural estimator of γ'' ij ,         γ  ^    i  j    =    Y   i  j    -   (    μ  ^   +    α  ^   i   +    β  ^   j    )     ,       subscript   normal-^  γ     i  j       subscript  Y    i  j       normal-^  μ    subscript   normal-^  α   i    subscript   normal-^  β   j       \hat{\gamma}_{ij}=Y_{ij}-(\hat{\mu}+\hat{\alpha}_{i}+\hat{\beta}_{j}),     the fitted values        Y  ^    i  j    =    μ  ^   +    α  ^   i   +    β  ^   j   +    γ  ^    i  j     ≡   Y   i  j           subscript   normal-^  Y     i  j       normal-^  μ    subscript   normal-^  α   i    subscript   normal-^  β   j    subscript   normal-^  γ     i  j           subscript  Y    i  j       \hat{Y}_{ij}=\hat{\mu}+\hat{\alpha}_{i}+\hat{\beta}_{j}+\hat{\gamma}_{ij}%
 \equiv Y_{ij}     fit the data exactly. Thus there are no remaining degrees of freedom to estimate the variance σ 2 , and no hypothesis tests about the γ ij can performed.  Tukey therefore proposed a more constrained interaction model of the form       E   Y   i  j     =   μ  +   α  i   +   β  j   +   λ   α  i    β  j           E   subscript  Y    i  j       μ   subscript  α  i    subscript  β  j     λ   subscript  α  i    subscript  β  j       EY_{ij}=\mu+\alpha_{i}+\beta_{j}+\lambda\alpha_{i}\beta_{j}     By testing the null hypothesis that λ = 0, we are able to detect some departures from additivity based only on the single parameter λ.  Method  To carry out Tukey's test, set       S   S  A    ≡   n    ∑  i     (     Y  ¯    i  ⋅    -    Y  ¯     ⋅  ⋅     )   2           S   subscript  S  A      n    subscript   i    superscript     subscript   normal-¯  Y    i  normal-⋅     subscript   normal-¯  Y    normal-⋅  absent  normal-⋅     2       SS_{A}\equiv n\sum_{i}(\bar{Y}_{i\cdot}-\bar{Y}_{\cdot\cdot})^{2}          S   S  B    ≡   m    ∑  j     (     Y  ¯     ⋅  j    -    Y  ¯     ⋅  ⋅     )   2           S   subscript  S  B      m    subscript   j    superscript     subscript   normal-¯  Y    normal-⋅  absent  j     subscript   normal-¯  Y    normal-⋅  absent  normal-⋅     2       SS_{B}\equiv m\sum_{j}(\bar{Y}_{\cdot j}-\bar{Y}_{\cdot\cdot})^{2}          S   S   A  B     ≡     (    ∑   i  j      Y   i  j     (     Y  ¯    i  ⋅    -    Y  ¯     ⋅  ⋅     )    (     Y  ¯     ⋅  j    -    Y  ¯     ⋅  ⋅     )     )   2     ∑  i      (     Y  ¯    i  ⋅    -    Y  ¯     ⋅  ⋅     )   2     ∑  j     (     Y  ¯     ⋅  j    -    Y  ¯     ⋅  ⋅     )   2             S   subscript  S    A  B        superscript    subscript     i  j       subscript  Y    i  j       subscript   normal-¯  Y    i  normal-⋅     subscript   normal-¯  Y    normal-⋅  absent  normal-⋅        subscript   normal-¯  Y    normal-⋅  absent  j     subscript   normal-¯  Y    normal-⋅  absent  normal-⋅       2     subscript   i      superscript     subscript   normal-¯  Y    i  normal-⋅     subscript   normal-¯  Y    normal-⋅  absent  normal-⋅     2     subscript   j    superscript     subscript   normal-¯  Y    normal-⋅  absent  j     subscript   normal-¯  Y    normal-⋅  absent  normal-⋅     2         SS_{AB}\equiv\frac{(\sum_{ij}Y_{ij}(\bar{Y}_{i\cdot}-\bar{Y}_{\cdot\cdot})(%
 \bar{Y}_{\cdot j}-\bar{Y}_{\cdot\cdot}))^{2}}{\sum_{i}(\bar{Y}_{i\cdot}-\bar{Y%
 }_{\cdot\cdot})^{2}\sum_{j}(\bar{Y}_{\cdot j}-\bar{Y}_{\cdot\cdot})^{2}}          S   S  T    ≡    ∑   i  j      (    Y   i  j    -    Y  ¯     ⋅  ⋅     )   2          S   subscript  S  T      subscript     i  j     superscript     subscript  Y    i  j     subscript   normal-¯  Y    normal-⋅  absent  normal-⋅     2      SS_{T}\equiv\sum_{ij}(Y_{ij}-\bar{Y}_{\cdot\cdot})^{2}          S   S  E    ≡    S   S  T    -   S   S  A    -   S   S  B    -   S   S   A  B            S   subscript  S  E        S   subscript  S  T      S   subscript  S  A      S   subscript  S  B      S   subscript  S    A  B        SS_{E}\equiv SS_{T}-SS_{A}-SS_{B}-SS_{AB}    Then use the following test statistic 2         S   S   A  B     /  1    M   S  E     .          S   subscript  S    A  B     1     M   subscript  S  E      \frac{SS_{AB}/1}{MS_{E}}.    Under the null hypothesis, the test statistic has an F distribution with 1, q degrees of freedom, where q = mn − ( m + n ) is the degrees of freedom for estimating the error variance.  See also  :* Tukey's range test for multiple comparisons  References    "  Category:Analysis of variance  Category:Statistical tests     ↩  Alin, A. and Kurt, S. (2006). “Testing non-additivity (interaction) in two-way ANOVA tables with no replication”. Statistical Methods in Medical Research  15 , 63–85. ↩     