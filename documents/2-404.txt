   Wiener process      Wiener process     In mathematics , the Wiener process is a continuous-time stochastic process named in honor of Norbert Wiener . It is often called standard Brownian motion , after Robert Brown . It is one of the best known Lévy processes ( càdlàg stochastic processes with stationary  independent increments) and occurs frequently in pure and applied mathematics, economics , quantitative finance, and physics .  The Wiener process plays an important role both in pure and applied mathematics. In pure mathematics, the Wiener process gave rise to the study of continuous time martingales . It is a key process in terms of which more complicated stochastic processes can be described. As such, it plays a vital role in stochastic calculus , diffusion processes and even potential theory . It is the driving process of Schramm–Loewner evolution . In applied mathematics , the Wiener process is used to represent the integral of a white noise  Gaussian process , and so is useful as a model of noise in electronics engineering , instrument errors in filtering theory and unknown forces in control theory .  The Wiener process has applications throughout the mathematical sciences. In physics it is used to study Brownian motion , the diffusion of minute particles suspended in fluid, and other types of diffusion via the Fokker–Planck and Langevin equations . It also forms the basis for the rigorous path integral formulation of quantum mechanics (by the Feynman–Kac formula , a solution to the Schrödinger equation can be represented in terms of the Wiener process) and the study of eternal inflation in physical cosmology . It is also prominent in the mathematical theory of finance , in particular the Black–Scholes option pricing model.  Characterisations of the Wiener process  The Wiener process W t is characterised by three properties: 1   W 0 = 0  The function t → W t is almost surely everywhere continuous  W t has independent increments with W t − W s ~ N (0, t − s ) (for 0 ≤ s 2) denotes the normal distribution with expected value μ and variance σ 2 .   The last condition means that if 0 ≤ s 1 1 ≤ s 2 2 then W t 1 − W s 1 and W t 2 − W s 2 are independent random variables, and the similar condition holds for n increments.  An alternative characterisation of the Wiener process is the so-called Lévy characterisation that says that the Wiener process is an almost surely continuous martingale with W 0 = 0 and quadratic variation [ W t , W t ] = t (which means that W t 2 − t is also a martingale).  A third characterisation is that the Wiener process has a spectral representation as a sine series whose coefficients are independent N (0, 1) random variables. This representation can be obtained using the Karhunen–Loève theorem .  Another characterisation of a Wiener process is the Definite integral (from zero to time t) of a zero mean, unit variance, delta correlated ("white") Gaussian process .  The Wiener process can be constructed as the scaling limit of a random walk , or other discrete-time stochastic processes with stationary independent increments. This is known as Donsker's theorem . Like the random walk, the Wiener process is recurrent in one or two dimensions (meaning that it returns almost surely to any fixed neighborhood of the origin infinitely often) whereas it is not recurrent in dimensions three and higher. Unlike the random walk, it is scale invariant , meaning that       α   -  1     W    α  2   t         superscript  α    1     subscript  W     superscript  α  2   t      \alpha^{-1}W_{\alpha^{2}t}     is a Wiener process for any nonzero constant α. The Wiener measure is the probability law on the space of continuous functions  g , with g (0) = 0, induced by the Wiener process. An integral based on Wiener measure may be called a Wiener integral .  Properties of a one-dimensional Wiener process  Basic properties  The unconditional probability density function , which follows Normal Distribution with mean = 0 and variance = t, at a fixed time t :         f   W  t     (  x  )    =    1    2  π  t      e   -    x  2    2  t        .         subscript  f   subscript  W  t    x       1      2  π  t      superscript  e       superscript  x  2     2  t         f_{W_{t}}(x)=\frac{1}{\sqrt{2\pi t}}e^{-\frac{x^{2}}{2t}}.     The expectation is zero:       E   [   W  t   ]    =  0.        E   delimited-[]   subscript  W  t     0.    E[W_{t}]=0.     The variance , using the computational formula , is t :        Var   (   W  t   )    =    E   [   W  t  2   ]    -    E  2    [   W  t   ]     =    E   [   W  t  2   ]    -  0   =   E   [   W  t  2   ]    =  t   .         Var   subscript  W  t        E   delimited-[]   subscript   superscript  W  2   t        superscript  E  2    delimited-[]   subscript  W  t               E   delimited-[]   subscript   superscript  W  2   t     0          E   delimited-[]   subscript   superscript  W  2   t          t     \operatorname{Var}(W_{t})=E\left[W^{2}_{t}\right]-E^{2}[W_{t}]=E\left[W^{2}_{t%
 }\right]-0=E\left[W^{2}_{t}\right]=t.     The covariance and correlation :        cov   (   W  s   ,   W  t   )    =   min   (  s  ,  t  )     ,       cov   subscript  W  s    subscript  W  t      s  t     \operatorname{cov}(W_{s},W_{t})=\min(s,t),           corr   (   W  s   ,   W  t   )    =    cov   (   W  s   ,   W  t   )      σ   W  s     σ   W  t      =    min   (  s  ,  t  )      s  t     =     min   (  s  ,  t  )     max   (  s  ,  t  )       .         corr   subscript  W  s    subscript  W  t        cov    subscript  W  s    subscript  W  t        subscript  σ   subscript  W  s     subscript  σ   subscript  W  t               s  t       s  t                s  t     s  t        \operatorname{corr}(W_{s},W_{t})=\frac{\mathrm{cov}(W_{s},W_{t})}{\sigma_{W_{s%
 }}\sigma_{W_{t}}}=\frac{\min(s,t)}{\sqrt{st}}=\sqrt{\frac{\min(s,t)}{\max(s,t)%
 }}.     The results for the expectation and variance follow immediately from the definition that increments have a normal distribution , centered at zero. Thus        W  t   =    W  t   -   W  0    ∼   N   (  0  ,  t  )     .         subscript  W  t      subscript  W  t    subscript  W  0      similar-to      N   0  t       W_{t}=W_{t}-W_{0}\sim N(0,t).     The results for the covariance and correlation follow from the definition that non-overlapping increments are independent, of which only the property that they are uncorrelated is used. Suppose that t 1 2.        cov   (   W   t  1    ,   W   t  2    )    =   E   [    (    W   t  1    -   E   [   W   t  1    ]     )   ⋅   (    W   t  2    -   E   [   W   t  2    ]     )    ]    =   E   [    W   t  1    ⋅   W   t  2     ]     .         cov   subscript  W   subscript  t  1     subscript  W   subscript  t  2       E   delimited-[]   normal-⋅     subscript  W   subscript  t  1      E   delimited-[]   subscript  W   subscript  t  1          subscript  W   subscript  t  2      E   delimited-[]   subscript  W   subscript  t  2                 E   delimited-[]   normal-⋅   subscript  W   subscript  t  1     subscript  W   subscript  t  2          \operatorname{cov}(W_{t_{1}},W_{t_{2}})=E\left[(W_{t_{1}}-E[W_{t_{1}}])\cdot(W%
 _{t_{2}}-E[W_{t_{2}}])\right]=E\left[W_{t_{1}}\cdot W_{t_{2}}\right].     Substituting       W   t  2    =    (    W   t  2    -   W   t  1     )   +   W   t  1          subscript  W   subscript  t  2         subscript  W   subscript  t  2     subscript  W   subscript  t  1      subscript  W   subscript  t  1       W_{t_{2}}=(W_{t_{2}}-W_{t_{1}})+W_{t_{1}}     we arrive at:        E   [    W   t  1    ⋅   W   t  2     ]    =   E   [    W   t  1    ⋅   (    (    W   t  2    -   W   t  1     )   +   W   t  1     )    ]    =    E   [    W   t  1    ⋅   (    W   t  2    -   W   t  1     )    ]    +   E   [   W   t  1   2   ]      .          E   delimited-[]   normal-⋅   subscript  W   subscript  t  1     subscript  W   subscript  t  2         E   delimited-[]   normal-⋅   subscript  W   subscript  t  1         subscript  W   subscript  t  2     subscript  W   subscript  t  1      subscript  W   subscript  t  1                 E   delimited-[]   normal-⋅   subscript  W   subscript  t  1       subscript  W   subscript  t  2     subscript  W   subscript  t  1          E   delimited-[]   superscript   subscript  W   subscript  t  1    2         E[W_{t_{1}}\cdot W_{t_{2}}]=E\left[W_{t_{1}}\cdot((W_{t_{2}}-W_{t_{1}})+W_{t_{%
 1}})\right]=E\left[W_{t_{1}}\cdot(W_{t_{2}}-W_{t_{1}})\right]+E\left[W_{t_{1}}%
 ^{2}\right].     Since W ( t 1 ) = W ( t 1 )− W ( t 0 ) and W ( t 2 )− W ( t 1 ), are independent,       E   [    W   t  1    ⋅   (    W   t  2    -   W   t  1     )    ]    =     E   [   W   t  1    ]    ⋅  E    [    W   t  2    -   W   t  1     ]    =  0.          E   delimited-[]   normal-⋅   subscript  W   subscript  t  1       subscript  W   subscript  t  2     subscript  W   subscript  t  1           normal-⋅    E   delimited-[]   subscript  W   subscript  t  1      E    delimited-[]     subscript  W   subscript  t  2     subscript  W   subscript  t  1            0.     E\left[W_{t_{1}}\cdot(W_{t_{2}}-W_{t_{1}})\right]=E[W_{t_{1}}]\cdot E[W_{t_{2}%
 }-W_{t_{1}}]=0.     Thus        cov   (   W   t  1    ,   W   t  2    )    =   E   [   W   t  1   2   ]    =   t  1    .         cov   subscript  W   subscript  t  1     subscript  W   subscript  t  2       E   delimited-[]   superscript   subscript  W   subscript  t  1    2           subscript  t  1      \operatorname{cov}(W_{t_{1}},W_{t_{2}})=E\left[W_{t_{1}}^{2}\right]=t_{1}.     Wiener representation  Wiener (1923) also gave a representation of a Brownian path in terms of a random Fourier series . If    ξ  n     subscript  ξ  n    \xi_{n}   are independent Gaussian variables with mean zero and variance one, then       W  t   =     ξ  0   t   +    2     ∑   n  =  1   ∞     ξ  n     sin   π  n  t     π  n             subscript  W  t        subscript  ξ  0   t       2     superscript   subscript     n  1         subscript  ξ  n         π  n  t      π  n          W_{t}=\xi_{0}t+\sqrt{2}\sum_{n=1}^{\infty}\xi_{n}\frac{\sin\pi nt}{\pi n}   and       W  t   =    2     ∑   n  =  1   ∞     ξ  n     sin   (    (   n  -   1  2    )   π  t   )      (   n  -   1  2    )   π            subscript  W  t       2     superscript   subscript     n  1         subscript  ξ  n           n    1  2    π  t        n    1  2    π         W_{t}=\sqrt{2}\sum_{n=1}^{\infty}\xi_{n}\frac{\sin\left(\left(n-\frac{1}{2}%
 \right)\pi t\right)}{\left(n-\frac{1}{2}\right)\pi}   represent a Brownian motion on    [  0  ,  1  ]     0  1    [0,1]   . The scaled process        c    W   (   t  c   )         c   W    t  c     \sqrt{c}\,W\left(\frac{t}{c}\right)   is a Brownian motion on    [  0  ,  c  ]     0  c    [0,c]   (cf. Karhunen–Loève theorem ).  Running maximum  The joint distribution of the running maximum       M  t   =    max   0  ≤  s  ≤  t     W  s         subscript  M  t     subscript       0  s       t      subscript  W  s      M_{t}=\max_{0\leq s\leq t}W_{s}     and W t is          f    M  t   ,   W  t      (  m  ,  w  )    =     2   (    2  m   -  w   )     t    2  π  t       e   -     (    2  m   -  w   )   2    2  t        ,    m  ≥  0   ,   w  ≤  m     .     formulae-sequence       subscript  f    subscript  M  t    subscript  W  t      m  w          2      2  m   w      t      2  π  t       superscript  e       superscript      2  m   w   2     2  t         formulae-sequence    m  0     w  m      f_{M_{t},W_{t}}(m,w)=\frac{2(2m-w)}{t\sqrt{2\pi t}}e^{-\frac{(2m-w)^{2}}{2t}},%
 \qquad m\geq 0,w\leq m.     To get the unconditional distribution of    f   M  t      subscript  f   subscript  M  t     f_{M_{t}}   , integrate over −∞  f_{M_t}(m) = \int_{-\infty}^{m} f_{M_t,W_t}(m,w)\,dw = \int_{-\infty}^{m} \frac{2(2m - w)}{t\sqrt{2 \pi t}} e^{-\frac{(2m-w)^2}{2t}}\,dw = \sqrt{\frac{2}{\pi t}}e^{-\frac{m^2}{2t}}, \qquad m \ge 0.  And the expectation 2       E   [   M  t   ]    =    ∫  0  ∞    m   f   M  t     (  m  )   d  m    =    ∫  0  ∞    m    2   π  t       e   -    m  2    2  t       d  m    =     2  t   π            E   delimited-[]   subscript  M  t       superscript   subscript   0       m   subscript  f   subscript  M  t    m  d  m           superscript   subscript   0       m      2    π  t      superscript  e       superscript  m  2     2  t      d  m               2  t   π       E[M_{t}]=\int_{0}^{\infty}mf_{M_{t}}(m)\,dm=\int_{0}^{\infty}m\sqrt{\frac{2}{%
 \pi t}}e^{-\frac{m^{2}}{2t}}\,dm=\sqrt{\frac{2t}{\pi}}     Self-similarity  (Figure)  A demonstration of Brownian scaling, showing     V  t   =    (   1  /   c    )    W   c  t          subscript  V  t       1    c     subscript  W    c  t       V_{t}=(1/\sqrt{c})W_{ct}   for decreasing c . Note that the average features of the function do not change while zooming in, and note that it zooms in quadratically faster horizontally than vertically.   Brownian scaling  For every c > 0 the process     V  t   =    (   1  /   c    )    W   c  t          subscript  V  t       1    c     subscript  W    c  t       V_{t}=(1/\sqrt{c})W_{ct}   is another Wiener process.  Time reversal  The process     V  t   =    W  1   -   W   1  -  t          subscript  V  t      subscript  W  1    subscript  W    1  t       V_{t}=W_{1}-W_{1-t}   for 0 ≤ t ≤ 1 is distributed like W t for 0 ≤ t ≤ 1.  Time inversion  The process     V  t   =   t   W   1  /  t          subscript  V  t     t   subscript  W    1  t       V_{t}=tW_{1/t}   is another Wiener process.  A class of Brownian martingales  If a polynomial  p ( x , t ) satisfies the PDE        (    ∂   ∂  t    +    1  2     ∂  2    ∂   x  2       )   p   (  x  ,  t  )    =  0               t        1  2      superscript   2      superscript  x  2       p   x  t    0    \left(\frac{\partial}{\partial t}+\frac{1}{2}\frac{\partial^{2}}{\partial x^{2%
 }}\right)p(x,t)=0     then the stochastic process       M  t   =   p   (   W  t   ,  t  )         subscript  M  t     p    subscript  W  t   t      M_{t}=p(W_{t},t)     is a martingale .  Example:      W  t  2   -  t       superscript   subscript  W  t   2   t    W_{t}^{2}-t   is a martingale, which shows that the quadratic variation of W on [0, t ] is equal to t . It follows that the expected time of first exit of W from (− c , c ) is equal to c 2 .  More generally, for every polynomial p ( x , t ) the following stochastic process is a martingale:        M  t   =    p   (   W  t   ,  t  )    -    ∫  0  t    a   (   W  s   ,  s  )   d  s      ,       subscript  M  t       p    subscript  W  t   t      superscript   subscript   0   t     a    subscript  W  s   s   normal-d  s       M_{t}=p(W_{t},t)-\int_{0}^{t}a(W_{s},s)\,\mathrm{d}s,   where a is the polynomial        a   (  x  ,  t  )    =    (    ∂   ∂  t    +    1  2     ∂  2    ∂   x  2       )   p   (  x  ,  t  )     .        a   x  t             t        1  2      superscript   2      superscript  x  2       p   x  t      a(x,t)=\left(\frac{\partial}{\partial t}+\frac{1}{2}\frac{\partial^{2}}{%
 \partial x^{2}}\right)p(x,t).     Example:       p   (  x  ,  t  )    =    (    x  2   -  t   )   2    ,        p   x  t     superscript     superscript  x  2   t   2     p(x,t)=(x^{2}-t)^{2},         a   (  x  ,  t  )    =   4   x  2     ;        a   x  t      4   superscript  x  2      a(x,t)=4x^{2};   the process        (    W  t  2   -  t   )   2   -   4    ∫  0  t      W  s  2    d  s          superscript     superscript   subscript  W  t   2   t   2     4    superscript   subscript   0   t      superscript   subscript  W  s   2   normal-d  s       (W_{t}^{2}-t)^{2}-4\int_{0}^{t}W_{s}^{2}\,\mathrm{d}s   is a martingale, which shows that the quadratic variation of the martingale     W  t  2   -  t       superscript   subscript  W  t   2   t    W_{t}^{2}-t   on [0, t ] is equal to       4    ∫  0  t      W  s  2    d  s     .      4    superscript   subscript   0   t      superscript   subscript  W  s   2   normal-d  s      4\int_{0}^{t}W_{s}^{2}\,\mathrm{d}s.     About functions p ( xa , t ) more general than polynomials, see local martingales .  Some properties of sample paths  The set of all functions w with these properties is of full Wiener measure. That is, a path (sample function) of the Wiener process has all these properties almost surely.  Qualitative properties   For every ε > 0, the function w takes both (strictly) positive and (strictly) negative values on (0, ε).  The function w is continuous everywhere but differentiable nowhere (like the Weierstrass function ).  Points of local maximum of the function w are a dense countable set; the maximum values are pairwise different; each local maximum is sharp in the following sense: if w has a local maximum at t then            lim   s  →  t      |    w   (  s  )    -   w   (  t  )     |    |   s  -  t   |     →  ∞   .     normal-→    subscript    normal-→  s  t            w  s     w  t         s  t         \lim_{s\to t}\frac{|w(s)-w(t)|}{|s-t|}\to\infty.       The same holds for local minima.    The function w has no points of local increase, that is, no t > 0 satisfies the following for some ε in (0, t ): first, w ( s ) ≤ w ( t ) for all s in ( t − ε, t ), and second, w ( s ) ≥ w ( t ) for all s in ( t , t + ε). (Local increase is a weaker condition than that w is increasing on ( t − ε, t + ε).) The same holds for local decrease.  The function w is of unbounded variation on every interval.  Zeros of the function w are a nowhere dense  perfect set of Lebesgue measure 0 and Hausdorff dimension 1/2 (therefore, uncountable).   Quantitative properties  Law of the iterated logarithm         lim sup   t  →   +  ∞       |   w   (  t  )    |     2  t   log   log  t        =   1  ,  almost surely    .        subscript  limit-supremum   normal-→  t              w  t        2  t      t         1  almost surely     \limsup_{t\to+\infty}\frac{|w(t)|}{\sqrt{2t\log\log t}}=1,\quad\text{almost %
 surely}.     Modulus of continuity  Local modulus of continuity:         lim sup   ε  →   0  +       |   w   (  ε  )    |     2  ε   log   log   (   1  /  ε   )         =   1  ,  almost surely    .        subscript  limit-supremum   normal-→  ε   limit-from  0            w  ε        2  ε        1  ε          1  almost surely     \limsup_{\varepsilon\to 0+}\frac{|w(\varepsilon)|}{\sqrt{2\varepsilon\log\log(%
 1/\varepsilon)}}=1,\qquad\text{almost surely}.     Global modulus of continuity (Lévy):       X  t   =    μ  t   +   σ   W  t          subscript  X  t       μ  t     σ   subscript  W  t       X_{t}=\mu t+\sigma W_{t}     for a wide class of functions f (namely: all continuous functions; all locally integrable functions; all non-negative measurable functions). The density L t is (more exactly, can and will be chosen to be) continuous. The number L t ( x ) is called the local time at x of w on [0, t ]. It is strictly positive for all x of the interval ( a , b ) where a and b are the least and the greatest value of w on [0, t ], respectively. (For x outside this interval the local time evidently vanishes.) Treated as a function of two variables x and t , the local time is still continuous. Treated as a function of t (while x is fixed), the local time is a singular function corresponding to a nonatomic measure on the set of zeros of w .  These continuity properties are fairly non-trivial. Consider that the local time can also be defined (as the density of the pushforward measure) for a smooth function. Then, however, the density is discontinuous, unless the given function is monotone. In other words, there is a conflict between good behavior of a function and good behavior of its local time. In this sense, the continuity of the local time of the Wiener process is another manifestation of non-smoothness of the trajectory.  Related processes  (Figure)  The generator of a Brownian motion is ½ times the Laplace–Beltrami operator . The image above is of the Brownian motion on a special manifold: the surface of a sphere.   The stochastic process defined by       e     μ  t   -     σ  2   t   2    +   σ   W  t      .     superscript  e        μ  t        superscript  σ  2   t   2      σ   subscript  W  t       e^{\mu t-\frac{\sigma^{2}t}{2}+\sigma W_{t}}.     is called a Wiener process with drift μ and infinitesimal variance σ 2 . These processes exhaust continuous Lévy processes .  Two random processes on the time interval [0, 1] appear, roughly speaking, when conditioning the Wiener process to vanish on both ends of [0,1]. With no further conditioning, the process takes both positive and negative values on [0, 1] and is called Brownian bridge . Conditioned also to stay positive on (0, 1), the process is called Brownian excursion . 3 In both cases a rigorous treatment involves a limiting procedure, since the formula P ( A | B ) = P ( A ∩ B )/ P ( B ) does not apply when P ( B ) = 0.  A geometric Brownian motion can be written       X  t   =    e   -  t     W   e   2  t           subscript  X  t      superscript  e    t     subscript  W   superscript  e    2  t        X_{t}=e^{-t}W_{e^{2t}}     It is a stochastic process which is used to model processes that can never take on negative values, such as the value of stocks.  The stochastic process        L  x    (  t  )    =    ∫  0  t    δ   (   x  -   B  t    )   d  s           superscript  L  x   t     superscript   subscript   0   t     δ    x   subscript  B  t    d  s      L^{x}(t)=\int_{0}^{t}\delta(x-B_{t})\,ds     is distributed like the Ornstein–Uhlenbeck process .  The time of hitting a single point x > 0 by the Wiener process is a random variable with the Lévy distribution . The family of these random variables (indexed by all positive numbers x ) is a left-continuous modification of a Lévy process . The right-continuous  modification of this process is given by times of first exit from closed intervals [0, x ].  The local time  L = ( L x t ) x ∈ R , t ≥ 0 of a Brownian motion describes the time that the process spends at the point x . Formally        W   (   -  1   )     (  t  )    :=    ∫  0  t    W   (  s  )   d  s       assign     superscript  W    1    t     superscript   subscript   0   t     W  s  d  s      W^{(-1)}(t):=\int_{0}^{t}W(s)ds   where δ is the Dirac delta function . The behaviour of the local time is characterised by Ray–Knight theorems .  Brownian martingales  Let A be an event related to the Wiener process (more formally: a set, measurable with respect to the Wiener measure, in the space of functions), and X t the conditional probability of A given the Wiener process on the time interval [0, t ] (more formally: the Wiener measure of the set of trajectories whose concatenation with the given partial trajectory on [0, t ] belongs to A ). Then the process X t is a continuous martingale. Its martingale property follows immediately from the definitions, but its continuity is a very special fact – a special case of a general theorem stating that all Brownian martingales are continuous. A Brownian martingale is, by definition, a martingale adapted to the Brownian filtration; and the Brownian filtration is, by definition, the filtration generated by the Wiener process.  Integrated Brownian motion  The time-integral of the Wiener process      t  ∧  s      t  s    t\wedge s   is called integrated Brownian motion or integrated Wiener process . It arises in many applications and can be shown to have the distribution N (0, t 3 /3), calculus lead using the fact that the covariation of the Wiener process is      W  t  2   -  t   =   V   A   (  t  )            superscript   subscript  W  t   2   t    subscript  V    A  t      W_{t}^{2}-t=V_{A(t)}   . 4  Time change  Every continuous martingale (starting at the origin) is a time changed Wiener process.  Example: 2 W t = V (4 t ) where V is another Wiener process (different from W but distributed like W ).  Example.      A   (  t  )    =   4    ∫  0  t      W  s  2    d  s           A  t     4    superscript   subscript   0   t      superscript   subscript  W  s   2   normal-d  s       A(t)=4\int_{0}^{t}W_{s}^{2}\,\mathrm{d}s   where      M  t   -   M  0    =   V   A   (  t  )            subscript  M  t    subscript  M  0     subscript  V    A  t      M_{t}-M_{0}=V_{A(t)}   and V is another Wiener process.  In general, if M is a continuous martingale then      M  ∞  -   =    lim inf   t  →  ∞     M  t     ,       subscript   superscript  M        subscript  limit-infimum   normal-→  t      subscript  M  t      M^{-}_{\infty}=\liminf_{t\to\infty}M_{t},   where A ( t ) is the quadratic variation of M on [0, t ], and V is a Wiener process.  Corollary. (See also Doob's martingale convergence theorems ) Let M t be a continuous martingale, and        M  ∞  +   =    lim sup   t  →  ∞     M  t     .       subscript   superscript  M        subscript  limit-supremum   normal-→  t      subscript  M  t      M^{+}_{\infty}=\limsup_{t\to\infty}M_{t}.           -  ∞   <   M  ∞  -   =   M  ∞  +   <   +  ∞    ,             subscript   superscript  M            subscript   superscript  M                  -\infty     Then only the following two cases are possible:        -  ∞   =   M  ∞  -   <   M  ∞  +   =   +  ∞    ;             subscript   superscript  M            subscript   superscript  M                  -\infty=M^{-}_{\infty}           M  ∞  -   =   M  ∞  +   =   +  ∞    ,         subscript   superscript  M       subscript   superscript  M                  M^{-}_{\infty}=M^{+}_{\infty}=+\infty,     other cases (such as     M  ∞  -   <   M  ∞  +   <   +  ∞          subscript   superscript  M       subscript   superscript  M                  M^{-}_{\infty}        f   (   Z  t   )    -   f   (  0  )          f   subscript  Z  t      f  0     f(Z_{t})-f(0)   etc.) are of probability 0.  Especially, a nonnegative continuous martingale has a finite limit (as t → ∞) almost surely.  All stated (in this subsection) for martingales holds also for local martingales .  Change of measure  A wide class of continuous semimartingales (especially, of diffusion processes ) is related to the Wiener process via a combination of time change and change of measure .  Using this fact, the qualitative properties stated above for the Wiener process can be generalized to a wide class of continuous semimartingales. 5 6  Complex-valued Wiener process  The complex-valued Wiener process may be defined as a complex-valued random process of the form Z t = X t + iY t where X t , Y t are independent Wiener processes (real-valued). 7  Self-similarity  Brownian scaling, time reversal, time inversion: the same as in the real-valued case.  Rotation invariance: for every complex number c such that | c | = 1 the process cZ t is another complex-valued Wiener process.  Time change  If f is an entire function then the process     Z  t  2   =    (    X  t  2   -   Y  t  2    )   +   2   X  t    Y  t   i    =   U   A   (  t  )            superscript   subscript  Z  t   2        superscript   subscript  X  t   2    superscript   subscript  Y  t   2      2   subscript  X  t    subscript  Y  t   i          subscript  U    A  t       Z_{t}^{2}=(X_{t}^{2}-Y_{t}^{2})+2X_{t}Y_{t}i=U_{A(t)}   is a time-changed complex-valued Wiener process.  Example:      A   (  t  )    =   4    ∫  0  t       |   Z  s   |   2    d  s           A  t     4    superscript   subscript   0   t      superscript     subscript  Z  s    2   normal-d  s       A(t)=4\int_{0}^{t}|Z_{s}|^{2}\,\mathrm{d}s   where  $$A(t) = 4 \int_0^t |Z_s|^2 \, \mathrm{d} s$$ and U is another complex-valued Wiener process.  In contrast to the real-valued case, a complex-valued martingale is generally not a time-changed complex-valued Wiener process. For example, the martingale 2 X t + iY t is not (here X t , Y t are independent Wiener processes, as before).  See also  Generalities:   Abstract Wiener space  Classical Wiener space  Chernoff's distribution  Fractal   Numerical path sampling:   Euler–Maruyama method  Walk-on-spheres method   Notes  References    (also available online: PDF-files )''      External links   Brownian motion java simulation  Article for the school-going child  Brownian Motion, "Diverse and Undulating"  Discusses history, botany and physics of Brown's original observations, with videos  "Einstein's prediction finally witnessed one century later" : a test to observe the velocity of Brownian motion    "  Category:Stochastic processes  Category:Martingale theory  Category:Variants of random walks     Durrett 1996, Sect. 7.1 ↩  ↩  ↩  Forum, [ http://wilmott.com/messageview.cfm?catid=4&threadid; ;=39502 "Variance of integrated Wiener process"], 2009. ↩  Revuz, D., & Yor, M. (1999). Continuous martingales and Brownian motion (Vol. 293). Springer. ↩  Doob, J. L. (1953). Stochastic processes (Vol. 101). Wiley: New York. ↩  ↩     