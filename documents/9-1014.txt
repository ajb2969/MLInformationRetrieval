   Macdonald polynomials      Macdonald polynomials   In mathematics, Macdonald polynomials  P λ ( x ; t , q ) are a family of orthogonal polynomials in several variables, introduced by . Macdonald originally associated his polynomials with weights λ of finite root systems and used just one variable t , but later realized that it is more natural to associate them with affine root systems rather than finite root systems, in which case the variable t can be replaced by several different variables t =( t 1 ,..., t k ), one for each of the k orbits of roots in the affine root system. The Macdonald polynomials are polynomials in n variables x =( x 1 ,..., x n ), where n is the rank of the affine root system. They generalize many other families of orthogonal polynomials, such as Jack polynomials and Hall–Littlewood polynomials and Askey–Wilson polynomials , which in turn include most of the named 1-variable orthogonal polynomials as special cases. Koornwinder polynomials are Macdonald polynomials of certain non-reduced root systems. They have deep relationships with affine Hecke algebras and Hilbert schemes , which were used to prove several conjectures made by Macdonald about them.  Definition  First fix some notation:   R is a finite root system in a real vector space V .  R + is a choice of positive roots , to which corresponds a positive Weyl chamber .  W is the Weyl group of R .  Q is the root lattice of R (the lattice spanned by the roots).  P is the weight lattice of R (containing Q ).  An ordering on the weights     μ  ≤  λ      μ  λ    \mu\leq\lambda   if and only if    λ  -  μ      λ  μ    \lambda-\mu   is a nonnegative linear combination of simple roots .  P + is the set of dominant weights: the elements of P in the positive Weyl chamber.  ρ is the Weyl vector : half the sum of the positive roots; this is a special element of P + in the interior of the positive Weyl chamber.  F is a field of characteristic 0, usually the rational numbers.  A = F ( P ) is the group algebra of P , with a basis of elements written e λ for λ ∈ P .  If f = e λ , then f means e −λ , and this is extended by linearity to the whole group algebra.  m μ = Σ λ ∈ W μ e λ is an orbit sum; these elements form a basis for the subalgebra A W of elements fixed by W .        (  a  ;  q  )   ∞   =    ∏   r  ≥  0     (   1  -   a   q  r     )         subscript   a  q       subscript  product    r  0      1    a   superscript  q  r        (a;q)_{\infty}=\prod_{r\geq 0}(1-aq^{r})   , the infinite q-Pochhammer symbol .       Δ  =    ∏   α  ∈  R       (   e  α   ;  q  )   ∞     (   t   e  α    ;  q  )   ∞      .      normal-Δ    subscript  product    α  R       subscript    superscript  e  α   q      subscript     t   superscript  e  α    q         \Delta=\prod_{\alpha\in R}{(e^{\alpha};q)_{\infty}\over(te^{\alpha};q)_{\infty%
 }}.          ⟨  f  ,  g  ⟩   =    (   constant term of  f   g  ¯   Δ   )   /   |  W  |         f  g       constant term of  f   normal-¯  g   normal-Δ     W      \langle f,g\rangle=(\text{constant term of }f\overline{g}\Delta)/|W|   is the inner product of two elements of A , at least when t is a positive integer power of q .   The Macdonald polynomials  P λ for λ ∈ P + are uniquely defined by the following two conditions:       P  λ   =    ∑   μ  ≤  λ      u   λ  μ     m  μ          subscript  P  λ     subscript     μ  λ       subscript  u    λ  μ     subscript  m  μ       P_{\lambda}=\sum_{\mu\leq\lambda}u_{\lambda\mu}m_{\mu}   where u λμ is a rational function of q and t with u λλ = 1;   P λ and P μ are orthogonal if λ < μ.   In other words the Macdonald polynomials are obtained by orthogonalizing the obvious basis for A W . The existence of polynomials with these properties is easy to show (for any inner product). A key property of the Macdonald polynomials is that they are orthogonal : 〈 P λ , P μ 〉 = 0 whenever λ ≠ μ. This is not a trivial consequence of the definition because P + is not totally ordered, and so has plenty of elements that are incomparable. Thus one must check that the corresponding polynomials are still orthogonal. The orthogonality can be proved by showing that the Macdonald polynomials are eigenvectors for an algebra of commuting self adjoint operators with 1-dimensional eigenspaces, and using the fact that eigenspaces for different eigenvalues must be orthogonal.  In the case of non-simply-laced root systems (B, C, F, G), the parameter t can be chosen to vary with the length of the root, giving a three-parameter family of Macdonald polynomials. One can also extend the definition to the nonreduced root system BC, in which case one obtains a six-parameter family (one t for each orbit of roots, plus q ) known as Koornwinder polynomials . It is sometimes better to regard Macdonald polynomials as depending on a possibly non-reduced affine root system. In this case there is one parameter t associated to each orbit of roots in the affine root system, plus one parameter q . The number of orbits of roots can vary from 1 to 5.  Examples   If q = t the Macdonald polynomials become the Weyl characters of the representations of the compact group of the root system, or the Schur functions in the case of root systems of type A .  If q = 0 the Macdonald polynomials become the (rescaled) zonal spherical functions for a semisimple p -adic group, or the Hall–Littlewood polynomials when the root system has type A .  If t =1 the Macdonald polynomials become the sums over W orbits, which are the monomial symmetric functions when the root system has type A .  If we put t = q α and let q tend to 1 the Macdonald polynomials become Jack polynomials when the root system is of type A , and Heckman–Opdam polynomials for more general root systems.  For the affine root system A 1 , the Macdonald polynomials are the Rogers polynomials .  For the non-reduced rank 1 affine root system of type ( C , C 1 ), the Macdonald polynomials are the Askey–Wilson polynomials , which in turn include as special cases most of the named families of orthogonal polynomials in 1 variable.  For the non-reduced affine root system of type ( C , C n ), the Macdonald polynomials are the   Koornwinder polynomials .  The Macdonald constant term conjecture  If t = q k for some positive integer k , then the norm of the Macdonald polynomials is given by       H  ~   μ     subscript   normal-~  H   μ    \widetilde{H}_{\mu}     Again, these were proved for general reduced root systems by , using double affine Hecke algebras , with the extension to the BC case following shortly thereafter via work of van Diejen, Noumi, and Sahi.  The Macdonald positivity conjecture  In the case of roots systems of type A n −1 the Macdonald polynomials are simply symmetric polynomials in n variables with coefficients that are rational functions of q and t . A certain transformed version    ℚ   (  q  ,  t  )       ℚ   q  t     \mathbb{Q}(q,t)   of the Macdonald polynomials (see Combinatorial formula below) form an orthogonal basis of the space of symmetric functions over    s  λ     subscript  s  λ    s_{\lambda}   , and therefore can be expressed in terms of Schur functions      D  μ   =   C   [   ∂  x   ,   ∂  y   ]    Δ  μ         subscript  D  μ     C     x     y     subscript  normal-Δ  μ      D_{\mu}=C[\partial x,\partial y]\,\Delta_{\mu}   . The coefficients K λμ ( q , t ) of these relations are called Kostka–Macdonald coefficients . Macdonald conjectured that the Kostka–Macdonald coefficients were polynomials in q and t with non-negative integer coefficients. These conjectures are now proved; the hardest and final step was proving the positivity, which was done by Mark Haiman (2001), by proving the n ! conjecture .  n! conjecture  The n ! conjecture of Adriano Garsia and Mark Haiman states that for each partition μ of n the space       Δ  μ   =   det    (    x  i   p  j     y  i   q  j     )     1  ≤   i  ,  j    ,    ≤  n           subscript  normal-Δ  μ      subscript     superscript   subscript  x  i    subscript  p  j     superscript   subscript  y  i    subscript  q  j        1   i  j      absent  n        \Delta_{\mu}=\det(x_{i}^{p_{j}}y_{i}^{q_{j}})_{1\leq i,j,\leq n}     spanned by all higher partial derivatives of       Δ  μ   =      x  1    y  2    +    x  2    y  3    +    x  3    y  1     -    x  2    y  1    -    x  3    y  2    -    x  1    y  3          subscript  normal-Δ  μ          subscript  x  1    subscript  y  2       subscript  x  2    subscript  y  3       subscript  x  3    subscript  y  1        subscript  x  2    subscript  y  1       subscript  x  3    subscript  y  2       subscript  x  1    subscript  y  3       \Delta_{\mu}=x_{1}y_{2}+x_{2}y_{3}+x_{3}y_{1}-x_{2}y_{1}-x_{3}y_{2}-x_{1}y_{3}     has dimension n !, where ( p j , q j ) run through the n elements of the diagram of the partition μ, regarded as a subset of the pairs of non-negative integers. For example, if μ is the partition 3 = 2 + 1 of n = 3 then the pairs ( p j , q j ) are (0, 0), (0, 1), (1, 0), and the space D μ is spanned by       y  2   -   y  3        subscript  y  2    subscript  y  3     y_{2}-y_{3}          y  3   -   y  1        subscript  y  3    subscript  y  1     y_{3}-y_{1}          x  3   -   x  2        subscript  x  3    subscript  x  2     x_{3}-x_{2}          x  1   -   x  3        subscript  x  1    subscript  x  3     x_{1}-x_{3}        1   1   1          H  ~   μ     subscript   normal-~  H   μ    \widetilde{H}_{\mu}   which has dimension 6 = 3!.  Haiman's proof of the Macdonald positivity conjecture and the n ! conjecture involved showing that the isospectral Hilbert scheme of n points in a plane was Cohen–Macaulay (and even Gorenstein ). Earlier results of Haiman and Garsia had already shown that this implied the n ! conjecture, and that the n ! conjecture implied that the Kostka–Macdonald coefficients were graded character multiplicities for the modules D μ . This immediately implies the Macdonald positivity conjecture because character multiplicities have to be non-negative integers.  Ian Grojnowski and Mark Haiman found another proof of the Macdonald positivity conjecture by proving a positivity conjecture for LLT polynomials .  Combinatorial formula for the Macdonald polynomials  In 2005, J. Haglund, M. Haiman and N. Loehr gave the first proof of a combinatorial interpretation of the Macdonald polynomials. While very useful for computation and interesting in its own right, this combinatorial formula does not immediately imply positivity of the Kostka-Macdonald coefficients K λμ ( q , t ), as it gives the decomposition of the Macdonald polynomials into monomial symmetric functions rather than into Schur functions.  The formula, which involves the transformed Macdonald polynomials     P  λ     subscript  P  λ    P_{\lambda}   rather than the usual       H  ~   μ    (  x  ;  q  ,  t  )    =    ∑   σ  :   μ  →   ℤ  +        q   i  n  v   (  σ  )      t   m  a  j   (  σ  )      x  σ            subscript   normal-~  H   μ    x  q  t      subscript    normal-:  σ   normal-→  μ   subscript  ℤ          superscript  q    i  n  v  σ     superscript  t    m  a  j  σ     superscript  x  σ       \widetilde{H}_{\mu}(x;q,t)=\sum_{\sigma:\mu\to\mathbb{Z}_{+}}q^{inv(\sigma)}t^%
 {maj(\sigma)}x^{\sigma}   , is given as       x  1   σ  1     x  2   σ  2    ⋯       superscript   subscript  x  1    subscript  σ  1     superscript   subscript  x  2    subscript  σ  2    normal-⋯    x_{1}^{\sigma_{1}}x_{2}^{\sigma_{2}}\cdots     where σ is a filling of the Young diagram of shape μ, inv and maj are certain combinatorial statistics (functions) defined on the filling σ. This formula expresses the Macdonald polynomials in infinitely many variables. To obtain the polynomials in n variables, simply restrict the formula to fillings that only use the integers 1,2,..., n . The term x σ should be interpreted as      H  ~   μ    (  x  ;  q  ,  t  )        subscript   normal-~  H   μ    x  q  t     \widetilde{H}_{\mu}(x;q,t)   where σ i is the number of boxes in the filling of μ with content i .  (Figure)  This depicts the arm and the leg of a square of a Young diagram. The arm is the number of squares to its right, and the leg is the number of squares above it.   The transformed Macdonald polynomials    P  λ     subscript  P  λ    P_{\lambda}   in the formula above are related to the classical Macdonald polynomials     J  λ    (  x  ;  q  ,  t  )        subscript  J  λ    x  q  t     J_{\lambda}(x;q,t)   via a sequence of transformations. First, the integral form of the Macdonald polynomials, denoted     P  λ    (  x  ;  q  ,  t  )        subscript  P  λ    x  q  t     P_{\lambda}(x;q,t)   , is a re-scaling of      J  λ    (  x  ;  q  ,  t  )    =    ∏   s  ∈   D   (  λ  )         (   1  -    q   a   (  s  )      t   1  +   l   (  s  )        )   ⋅   P  λ     (  x  ;  q  ,  t  )            subscript  J  λ    x  q  t      subscript  product    s    D  λ        normal-⋅    1     superscript  q    a  s     superscript  t    1    l  s        subscript  P  λ     x  q  t       J_{\lambda}(x;q,t)=\prod_{s\in D(\lambda)}(1-q^{a(s)}t^{1+l(s)})\cdot P_{%
 \lambda}(x;q,t)   that clears the denominators of the coefficients:      D   (  λ  )       D  λ    D(\lambda)     where   λ   λ   \lambda   is the collection of squares in the Young diagram of    a   (  s  )       a  s    a(s)   , and    l   (  s  )       l  s    l(s)   and   s   s   s   denote the arm and leg of the square      H  ~   μ    (  x  ;  q  ,  t  )        subscript   normal-~  H   μ    x  q  t     \widetilde{H}_{\mu}(x;q,t)   , as shown in the figure. Note: The figure at right uses French notation for tableau, which is flipped vertically from the English notation used on the Wikipedia page for Young diagrams. French notation is more commonly used in the study of Macdonald polynomials.  The transformed Macdonald polynomials    J  μ     subscript  J  μ    J_{\mu}   can then be defined in terms of the       H  ~   μ    (  x  ;  q  ,  t  )    =    t   -   n   (  μ  )       J  μ    [   X   1  -   t   -  1      ;  q  ,   t   -  1    ]           subscript   normal-~  H   μ    x  q  t       superscript  t      n  μ      subscript  J  μ      X    1   superscript  t    1      q   superscript  t    1        \widetilde{H}_{\mu}(x;q,t)=t^{-n(\mu)}J_{\mu}\left[\frac{X}{1-t^{-1}};q,t^{-1}\right]   's. We have        n   (  μ  )    =    ∑  i     μ  i   ⋅   (   i  -  1   )      .        n  μ     subscript   i    normal-⋅   subscript  μ  i     i  1       n(\mu)=\sum_{i}\mu_{i}\cdot(i-1).   where $n(\mu)=\sum_{i}\mu_i\cdot (i-1).$ The bracket notation above denotes plethystic substitution .  This formula can be used to prove Knop and Sahi's formula for the Jack polynomials . There is also a combinatorial version for the non-symmetric Macdonald polynomials.  References         Mark Haiman Combinatorics, symmetric functions, and Hilbert schemes Current Developments in Mathematics 2002, no. 1 (2002), 39–111.       Haiman, Mark Notes on Macdonald polynomials and the geometry of Hilbert schemes. Symmetric functions 2001: surveys of developments and perspectives, 1–64, NATO Sci. Ser. II Math. Phys. Chem., 74, Kluwer Acad. Publ., Dordrecht, 2002.      Macdonald, I. G. Symmetric functions and Hall polynomials. Second edition. Oxford Mathematical Monographs. Oxford Science Publications. The Clarendon Press, Oxford University Press, New York, 1995. x+475 pp. ISBN 0-19-853489-2  Macdonald, I. G. Symmetric functions and orthogonal polynomials. Dean Jacqueline B. Lewis Memorial Lectures presented at Rutgers University, New Brunswick, NJ. University Lecture Series, 12. American Mathematical Society, Providence, RI, 1998. xvi+53 pp. ISBN 0-8218-0770-6  Macdonald, I. G. Affine Hecke algebras and orthogonal polynomials. Séminaire Bourbaki 797 (1995).     External links   Mike Zabrocki's page about Macdonald polynomials .  Some of Haiman's papers about Macdonald polynomials.   "  Category:Algebraic combinatorics  Category:Algebraic geometry  Category:Orthogonal polynomials   