   Quantum relative entropy      Quantum relative entropy   In quantum information theory , quantum relative entropy is a measure of distinguishability between two quantum states . It is the quantum mechanical analog of relative entropy .  Motivation  For simplicity, it will be assumed that all objects in the article are finite-dimensional.  We first discuss the classical case. Suppose the probabilities of a finite sequence of events is given by the probability distribution P = { p 1 ... p n }, but somehow we mistakenly assumed it to be Q = { q 1 ... q n }. For instance, we can mistake an unfair coin for a fair one. According to this erroneous assumption, our uncertainty about the j -th event, or equivalently, the amount of information provided after observing the j -th event, is       -   log   q  j     .         subscript  q  j      \;-\log q_{j}.     The (assumed) average uncertainty of all possible events is then       -    ∑  j     p  j    log   q  j       .        subscript   j      subscript  p  j      subscript  q  j        \;-\sum_{j}p_{j}\log q_{j}.     On the other hand, the Shannon entropy of the probability distribution p , defined by       -    ∑  j     p  j    log   p  j       ,        subscript   j      subscript  p  j      subscript  p  j        \;-\sum_{j}p_{j}\log p_{j},     is the real amount of uncertainty before observation. Therefore the difference between these two quantities        -    ∑  j     p  j    log   q  j       -   (   -    ∑  j     p  j    log   p  j       )    =     ∑  j     p  j    log   p  j      -    ∑  j     p  j    log   q  j                 subscript   j      subscript  p  j      subscript  q  j           subscript   j      subscript  p  j      subscript  p  j            subscript   j      subscript  p  j      subscript  p  j        subscript   j      subscript  p  j      subscript  q  j         \;-\sum_{j}p_{j}\log q_{j}-\left(-\sum_{j}p_{j}\log p_{j}\right)=\sum_{j}p_{j}%
 \log p_{j}-\sum_{j}p_{j}\log q_{j}     is a measure of the distinguishability of the two probability distributions p and q . This is precisely the classical relative entropy, or Kullback–Leibler divergence :       D  KL    (  P  ∥  Q  )   =   ∑  j    p  j   log     p  j    q  j     .     fragments   subscript  D  KL    fragments  normal-(  P  parallel-to  Q  normal-)     subscript   j    subscript  p  j       subscript  p  j    subscript  q  j    normal-.    D_{\mathrm{KL}}(P\|Q)=\sum_{j}p_{j}\log\frac{p_{j}}{q_{j}}\!.     Note   In the definitions above, the convention that 0·log 0 = 0 is assumed, since lim x → 0  x log x = 0. Intuitively, one would expect that an event of zero probability to contribute nothing towards entropy.  The relative entropy is not a metric . For example, it is not symmetric. The uncertainty discrepancy in mistaking a fair coin to be unfair is not the same as the opposite situation.   Definition  As with many other objects in quantum information theory, quantum relative entropy is defined by extending the classical definition from probability distributions to density matrices . Let ρ be a density matrix. The von Neumann entropy of ρ , which is the quantum mechanical analog of the Shannon entropy, is given by        S   (  ρ  )    =   -   Tr   ρ   log  ρ       .        S  ρ      Tr    ρ    ρ        S(\rho)=-\operatorname{Tr}\rho\log\rho.     For two density matrices ρ and σ , the quantum relative entropy of ρ with respect to σ is defined by      S   (  ρ  ∥  σ  )   =  -  Tr  ρ  log  σ  -  S   (  ρ  )   =  Tr  ρ  log  ρ  -  Tr  ρ  log  σ  =  Tr  ρ   (  log  ρ  -  log  σ  )   .     fragments  S   fragments  normal-(  ρ  parallel-to  σ  normal-)     Tr  ρ   σ   S   fragments  normal-(  ρ  normal-)    Tr  ρ   ρ   Tr  ρ   σ   Tr  ρ   fragments  normal-(   ρ    σ  normal-)   normal-.    S(\rho\|\sigma)=-\operatorname{Tr}\rho\log\sigma-S(\rho)=\operatorname{Tr}\rho%
 \log\rho-\operatorname{Tr}\rho\log\sigma=\operatorname{Tr}\rho(\log\rho-\log%
 \sigma).     We see that, when the states are classically related, i.e. ρσ = σρ , the definition coincides with the classical case.  Non-finite relative entropy  In general, the support of a matrix M is the orthogonal complement of its kernel , i.e. supp ( M ):= ker ( M ) ⊥ . When consider the quantum relative entropy, we assume the convention that − s · log 0 = ∞ for any s > 0. This leads to the definition that      S   (  ρ  ∥  σ  )   =  ∞     fragments  S   fragments  normal-(  ρ  parallel-to  σ  normal-)       S(\rho\|\sigma)=\infty     when        supp   (  ρ  )    ∩   ker   (  σ  )     ≠  0.          supp  ρ     ker  σ    0.    \text{supp}(\rho)\cap\text{ker}(\sigma)\neq 0.     This makes physical sense. Informally, the quantum relative entropy is a measure of our ability to distinguish two quantum states. But orthogonal quantum states can always be distinguished via projective measurements . In the present context, this is reflected by non-finite quantum relative entropy.  In the interpretation given in the previous section, if we erroneously assume the state ρ has support in ker ( σ ), this is an error impossible to recover from.  Klein's inequality  Corresponding classical statement  For the classical Kullback–Leibler divergence, it can be shown that       D  KL    (  P  ∥  Q  )   =   ∑  j    p  j   log    p  j    q  j    ≥  0  ,     fragments   subscript  D  KL    fragments  normal-(  P  parallel-to  Q  normal-)     subscript   j    subscript  p  j       subscript  p  j    subscript  q  j     0  normal-,    D_{\mathrm{KL}}(P\|Q)=\sum_{j}p_{j}\log\frac{p_{j}}{q_{j}}\geq 0,     and the equality holds if and only if P = Q . Colloquially, this means that the uncertainty calculated using erroneous assumptions is always greater than the real amount of uncertainty.  To show the inequality, we rewrite       D  KL    (  P  ∥  Q  )   =   ∑  j    p  j   log    p  j    q  j    =   ∑  j    (  -  log    q  j    p  j    )    (   p  j   )   .     fragments   subscript  D  KL    fragments  normal-(  P  parallel-to  Q  normal-)     subscript   j    subscript  p  j       subscript  p  j    subscript  q  j      subscript   j    fragments  normal-(       subscript  q  j    subscript  p  j    normal-)    fragments  normal-(   subscript  p  j   normal-)   normal-.    D_{\mathrm{KL}}(P\|Q)=\sum_{j}p_{j}\log\frac{p_{j}}{q_{j}}=\sum_{j}(-\log\frac%
 {q_{j}}{p_{j}})(p_{j}).     Notice that log is a concave function . Therefore -log is convex . Applying Jensen's inequality to -log gives       D  KL    (  P  ∥  Q  )   =   ∑  j    (  -  log    q  j    p  j    )    (   p  j   )   ≥  -  log   (   ∑  j     q  j    p  j     p  j   )   =  0.     fragments   subscript  D  KL    fragments  normal-(  P  parallel-to  Q  normal-)     subscript   j    fragments  normal-(       subscript  q  j    subscript  p  j    normal-)    fragments  normal-(   subscript  p  j   normal-)       fragments  normal-(   subscript   j      subscript  q  j    subscript  p  j     subscript  p  j   normal-)    0.    D_{\mathrm{KL}}(P\|Q)=\sum_{j}(-\log\frac{q_{j}}{p_{j}})(p_{j})\geq-\log(\sum_%
 {j}\frac{q_{j}}{p_{j}}p_{j})=0.     Jensen's inequality also states that equality holds if and only if, for all i , q i = (∑ q j ) p i , i.e. p = q .  The result  Klein's inequality states that the quantum relative entropy      S   (  ρ  ∥  σ  )   =  Tr  ρ   (  log  ρ  -  log  σ  )   .     fragments  S   fragments  normal-(  ρ  parallel-to  σ  normal-)    Tr  ρ   fragments  normal-(   ρ    σ  normal-)   normal-.    S(\rho\|\sigma)=\operatorname{Tr}\rho(\log\rho-\log\sigma).     is non-negative in general. It is zero if and only ρ = σ .  Proof  Let ρ and σ have spectral decompositions        ρ  =    ∑  i     p  i    v  i     v  i  *       ,   σ  =    ∑  i     q  i    w  i    w  i  *       .     formulae-sequence    ρ    subscript   i      subscript  p  i    subscript  v  i    superscript   subscript  v  i          σ    subscript   i      subscript  q  i    subscript  w  i    superscript   subscript  w  i          \rho=\sum_{i}p_{i}v_{i}v_{i}^{*}\;,\;\sigma=\sum_{i}q_{i}w_{i}w_{i}^{*}.     So         log  ρ   =    ∑  i     (   log   p  i    )    v  i     v  i  *       ,    log  σ   =    ∑  i     (   log   q  i    )    w  i    w  i  *       .     formulae-sequence      ρ     subscript   i        subscript  p  i     subscript  v  i    superscript   subscript  v  i            σ     subscript   i        subscript  q  i     subscript  w  i    superscript   subscript  w  i          \log\rho=\sum_{i}(\log p_{i})v_{i}v_{i}^{*}\;,\;\log\sigma=\sum_{i}(\log q_{i}%
 )w_{i}w_{i}^{*}.     Direct calculation gives      S   (  ρ  ∥  σ  )      fragments  S   fragments  normal-(  ρ  parallel-to  σ  normal-)     S(\rho\|\sigma)          =     ∑  k     p  k    log   p  k      -    ∑   i  ,  j      (    p  i    log   q  j     )     |    v  i  *    w  j    |   2          absent      subscript   k      subscript  p  k      subscript  p  k        subscript    i  j         subscript  p  i      subscript  q  j      superscript       superscript   subscript  v  i      subscript  w  j     2        =\sum_{k}p_{k}\log p_{k}-\sum_{i,j}(p_{i}\log q_{j})|v_{i}^{*}w_{j}|^{2}          =    ∑  i     p  i    (    log   p  i    -    ∑  j    log    q  j     |    v  i  *    w  j    |   2       )         absent    subscript   i      subscript  p  i        subscript  p  i      subscript   j        subscript  q  j    superscript       superscript   subscript  v  i      subscript  w  j     2           =\sum_{i}p_{i}(\log p_{i}-\sum_{j}\log q_{j}|v_{i}^{*}w_{j}|^{2})           =    ∑  i     p  i    (    log   p  i    -    ∑  j     (   log   q  j    )    P   i  j       )      ,      absent    subscript   i      subscript  p  i        subscript  p  i      subscript   j        subscript  q  j     subscript  P    i  j           \;=\sum_{i}p_{i}(\log p_{i}-\sum_{j}(\log q_{j})P_{ij}),   where P i j = | v i *w j | 2 .  Since the matrix ( P i j ) i j is a doubly stochastic matrix and -log is a convex function, the above expression is       ≥    ∑  i     p  i    (    log   p  i    -   log   (    ∑  j     q  j    P   i  j      )     )         absent    subscript   i      subscript  p  i        subscript  p  i        subscript   j      subscript  q  j    subscript  P    i  j            \geq\sum_{i}p_{i}(\log p_{i}-\log(\sum_{j}q_{j}P_{ij}))           =    ∑  i     p  i    (    log   p  i    -   log   (    ∑  j     q  j    P   i  j      )     )      .      absent    subscript   i      subscript  p  i        subscript  p  i        subscript   j      subscript  q  j    subscript  P    i  j            \;=\sum_{i}p_{i}(\log p_{i}-\log(\sum_{j}q_{j}P_{ij})).     Define r i = ∑ j q j P i j . Then { r i } is a probability distribution. From the non-negativity of classical relative entropy, we have      S   (  ρ  ∥  σ  )   ≥   ∑  i    p  i   log    p  i    r  i    ≥  0.     fragments  S   fragments  normal-(  ρ  parallel-to  σ  normal-)     subscript   i    subscript  p  i       subscript  p  i    subscript  r  i     0.    S(\rho\|\sigma)\geq\sum_{i}p_{i}\log\frac{p_{i}}{r_{i}}\geq 0.     The second part of the claim follows from the fact that, since -log is strictly convex, equality is achieved in        ∑  i     p  i    (    log   p  i    -    ∑  j     (   log   q  j    )    P   i  j       )     ≥    ∑  i     p  i    (    log   p  i    -   log   (    ∑  j     q  j    P   i  j      )     )           subscript   i      subscript  p  i        subscript  p  i      subscript   j        subscript  q  j     subscript  P    i  j           subscript   i      subscript  p  i        subscript  p  i        subscript   j      subscript  q  j    subscript  P    i  j            \sum_{i}p_{i}(\log p_{i}-\sum_{j}(\log q_{j})P_{ij})\geq\sum_{i}p_{i}(\log p_{%
 i}-\log(\sum_{j}q_{j}P_{ij}))     if and only if ( P i j ) is a permutation matrix , which implies ρ = σ , after a suitable labeling of the eigenvectors { v i } and { w i }.  Further see Trace inequalities#Klein's inequality .  An entanglement measure  Let a composite quantum system have state space      H  =   ⊗  k    H  k      fragments  H    subscript  tensor-product  k    subscript  H  k     H=\otimes_{k}H_{k}     and ρ be a density matrix acting on H .  The relative entropy of entanglement of ρ is defined by        D   REE    (  ρ  )   =   min  σ   S   (  ρ  ∥  σ  )      fragments   subscript  D  REE    fragments  normal-(  ρ  normal-)     subscript   σ   S   fragments  normal-(  ρ  parallel-to  σ  normal-)     \;D_{\mathrm{REE}}(\rho)=\min_{\sigma}S(\rho\|\sigma)     where the minimum is taken over the family of separable states . A physical interpretation of the quantity is the optimal distinguishability of the state ρ from separable states.  Clearly, when ρ is not entangled         D   REE    (  ρ  )    =  0         subscript  D  REE   ρ   0    \;D_{\mathrm{REE}}(\rho)=0     by Klein's inequality.  Computing relative entropy of entanglement is NP-complete. 1  Relation to other quantum information quantities  One reason the quantum relative entropy is useful is that several other important quantum information quantities are special cases of it. Often, theorems are stated in terms of the quantum relative entropy, which lead to immediate corollaries concerning the other quantities. Below, we list some of these relations.  Let ρ AB be the joint state of a bipartite system with subsystem A of dimension n A and B of dimension n B . Let ρ A , ρ B be the respective reduced states, and I A , I B the respective identities. The maximally mixed states are I A / n A and I B / n B . Then it is possible to show with direct computation that      S   (   ρ  A   |  |   I  A   /   n  A   )   =  log   (   n  A   )   -  S   (   ρ  A   )   ,     fragments  S   fragments  normal-(   subscript  ρ  A   normal-|  normal-|   subscript  I  A     subscript  n  A   normal-)    log   fragments  normal-(   subscript  n  A   normal-)    S   fragments  normal-(   subscript  ρ  A   normal-)   normal-,    S(\rho_{A}||I_{A}/n_{A})=\mathrm{log}(n_{A})-S(\rho_{A}),\;         S   (   ρ   A  B    |  |   ρ  A   ⊗   ρ  B   )   =  S   (   ρ  A   )   +  S   (   ρ  B   )   -  S   (   ρ   A  B    )   =  I   (  A  :  B  )   ,     fragments  S   fragments  normal-(   subscript  ρ    A  B    normal-|  normal-|   subscript  ρ  A   tensor-product   subscript  ρ  B   normal-)    S   fragments  normal-(   subscript  ρ  A   normal-)    S   fragments  normal-(   subscript  ρ  B   normal-)    S   fragments  normal-(   subscript  ρ    A  B    normal-)    I   fragments  normal-(  A  normal-:  B  normal-)   normal-,    S(\rho_{AB}||\rho_{A}\otimes\rho_{B})=S(\rho_{A})+S(\rho_{B})-S(\rho_{AB})=I(A%
 :B),         S   (   ρ   A  B    |  |   ρ  A   ⊗   I  B   /   n  B   )   =  log   (   n  B   )   +  S   (   ρ  A   )   -  S   (   ρ   A  B    )   =  log   (   n  B   )   -  S   (  B  |  A  )   ,     fragments  S   fragments  normal-(   subscript  ρ    A  B    normal-|  normal-|   subscript  ρ  A   tensor-product   subscript  I  B     subscript  n  B   normal-)    log   fragments  normal-(   subscript  n  B   normal-)    S   fragments  normal-(   subscript  ρ  A   normal-)    S   fragments  normal-(   subscript  ρ    A  B    normal-)    log   fragments  normal-(   subscript  n  B   normal-)    S   fragments  normal-(  B  normal-|  A  normal-)   normal-,    S(\rho_{AB}||\rho_{A}\otimes I_{B}/n_{B})=\mathrm{log}(n_{B})+S(\rho_{A})-S(%
 \rho_{AB})=\mathrm{log}(n_{B})-S(B|A),     where I ( A : B ) is the quantum mutual information and S ( B | A ) is the quantum conditional entropy .  References   Vedral V., 2002, Rev. Mod. Phys. 74, 197 , eprint quant-ph/0102094   "  Category:Quantum mechanical entropy  Category:Quantum information theory     ↩     