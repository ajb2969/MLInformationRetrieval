   Rate function      Rate function   In mathematics ‚Äî specifically, in large deviations theory ‚Äî a rate function is a function used to quantify the probabilities of rare events. It is required to have several properties which assist in the formulation of the large deviation principle . In some sense, the large deviation principle is an analogue of weak convergence of probability measures , but one which takes account of how well the rare events behave.  A rate function is also called a Cram√©r function , after the Swedish probabilist Harald Cram√©r .  Definitions  An extended real-valued function I : X ‚Üí¬†[0,¬†+‚àû] defined on a Hausdorff  topological space  X is said to be a rate function if it is not identically +‚àû and is lower semi-continuous , i.e. all the sub-level sets        {   x  ‚àà  X   |    I   (  x  )    ‚â§  c   }   for  c   ‚â•  0         conditional-set    x  X       I  x   c    for  c   0    \{x\in X|I(x)\leq c\}\mbox{ for }c\geq 0     are closed in X . If, furthermore, they are compact , then I is said to be a good rate function .  A family of probability measures ( Œº Œ¥ ) Œ¥ >0 on X is said to satisfy the large deviation principle with rate function I : X ‚Üí¬†[0,¬†+‚àû) (and rate 1¬†‚ÅÑ Œ¥ ) if, for every closed set F ‚äÜ X and every open set  G ‚äÜ X ,        lim sup   Œ¥  ‚Üì  0     Œ¥   log   Œº  Œ¥     (  F  )     ‚â§    -    inf   x  ‚àà  F     I   (  x  )      ,  (U)         subscript  limit-supremum   normal-‚Üì  Œ¥  0      Œ¥     subscript  Œº  Œ¥    F         subscript  infimum    x  F      I  x     (U)     \limsup_{\delta\downarrow 0}\delta\log\mu_{\delta}(F)\leq-\inf_{x\in F}I(x),%
 \quad\mbox{(U)}          lim inf   Œ¥  ‚Üì  0    Œ¥  log   Œº  Œ¥    (  G  )   ‚â•  -   inf   x  ‚àà  G    I   (  x  )   .  (L)     fragments   subscript  limit-infimum   normal-‚Üì  Œ¥  0    Œ¥    subscript  Œº  Œ¥    fragments  normal-(  G  normal-)      subscript  infimum    x  G    I   fragments  normal-(  x  normal-)   normal-.   (L)    \liminf_{\delta\downarrow 0}\delta\log\mu_{\delta}(G)\geq-\inf_{x\in G}I(x).%
 \quad\mbox{(L)}     If the upper bound (U) holds only for compact (instead of closed) sets F , then ( Œº Œ¥ ) Œ¥ >0 is said to satisfy the weak large deviation principle (with rate 1¬†‚ÅÑ Œ¥ and weak rate function I ).  Remarks  The role of the open and closed sets in the large deviation principle is similar to their role in the weak convergence of probability measures: recall that ( Œº Œ¥ ) Œ¥ >0 is said to converge weakly to Œº if, for every closed set F ‚äÜ X and every open set  G ‚äÜ X ,         lim sup   Œ¥  ‚Üì  0      Œº  Œ¥    (  F  )     ‚â§   Œº   (  F  )     ,        subscript  limit-supremum   normal-‚Üì  Œ¥  0       subscript  Œº  Œ¥   F      Œº  F     \limsup_{\delta\downarrow 0}\mu_{\delta}(F)\leq\mu(F),            lim inf   Œ¥  ‚Üì  0      Œº  Œ¥    (  G  )     ‚â•   Œº   (  G  )     .        subscript  limit-infimum   normal-‚Üì  Œ¥  0       subscript  Œº  Œ¥   G      Œº  G     \liminf_{\delta\downarrow 0}\mu_{\delta}(G)\geq\mu(G).     There is some variation in the nomenclature used in the literature: for example, den Hollander (2000) uses simply "rate function" where this article ‚Äî following Dembo & Zeitouni (1998) ‚Äî uses "good rate function", and "weak rate function". Fortunately, regardless of the nomenclature used for rate functions, examination of whether the upper bound inequality (U) is supposed to hold for closed or compact sets tells one whether the large deviation principle in use is strong or weak.  Properties  Uniqueness  A natural question to ask, given the somewhat abstract setting of the general framework above, is whether the rate function is unique. This turns out to be the case: given a sequence of probability measures ( Œº Œ¥ ) Œ¥ >0 on X satisfying the large deviation principle for two rate functions I and J , it follows that I ( x )¬†= J ( x ) for all x ‚àà X .  Exponential tightness  It is possible to convert a weak large deviation principle into a strong one if the measures converge sufficiently quickly. If the upper bound holds for compact sets F and the sequence of measures ( Œº Œ¥ ) Œ¥ >0 is exponentially tight , then the upper bound also holds for closed sets F . In other words, exponential tightness enables one to convert a weak large deviation principle into a strong one.  Continuity  Na√Øvely, one might try to replace the two inequalities (U) and (L) by the single requirement that, for all Borel sets S ‚äÜ X ,       lim   Œ¥  ‚Üì  0    Œ¥  log   Œº  Œ¥    (  S  )   =  -   inf   x  ‚àà  S    I   (  x  )   .  (E)     fragments   subscript    normal-‚Üì  Œ¥  0    Œ¥    subscript  Œº  Œ¥    fragments  normal-(  S  normal-)      subscript  infimum    x  S    I   fragments  normal-(  x  normal-)   normal-.   (E)    \lim_{\delta\downarrow 0}\delta\log\mu_{\delta}(S)=-\inf_{x\in S}I(x).\quad%
 \mbox{(E)}     Unfortunately, the equality (E) is far too restrictive, since many interesting examples satisfy (U) and (L) but not (E). For example, the measure Œº Œ¥ might be non-atomic for all Œ¥ , so the equality (E) could hold for S =¬†{ x } only if I were identically +‚àû, which is not permitted in the definition. However, the inequalities (U) and (L) do imply the equality (E) for so-called I -continuous sets S ‚äÜ X , those for which        I   (   S  ‚àò   )    =   I   (   S  ¬Ø   )     ,        I   superscript  S       I   normal-¬Ø  S      I\big(\stackrel{\circ}{S}\big)=I\big(\bar{S}\big),     where    S  ‚àò     superscript  S     \stackrel{\circ}{S}   and    S  ¬Ø     normal-¬Ø  S    \bar{S}   denote the interior and closure of S in X respectively. In many examples, many sets/events of interest are I -continuous. For example, if I is a continuous function , then all sets S such that      S  ‚äÜ    S  ‚àò   ¬Ø       S   normal-¬Ø   superscript  S       S\subseteq\bar{\stackrel{\circ}{S}}     are I -continuous; all open sets, for example, satisfy this containment.  Transformation of large deviation principles  Given a large deviation principle on one space, it is often of interest to be able to construct a large deviation principle on another space. There are several results in this area:   the contraction principle tells one how a large deviation principle on one space " pushes forward " to a large deviation principle on another space via a continuous function ;    the Dawson-G√§rtner theorem tells one how a sequence of large deviation principles on a sequence of spaces passes to the projective limit .    the tilted large deviation principle gives a large deviation principle for integrals of exponential functionals .    exponentially equivalent measures have the same large deviation principles.   History and basic development  The notion of a rate function began with the Swedish mathematician Harald Cram√©r 's study of a sequence of i.i.d. random variables ( Z i ) i‚àà‚Ñï at the time of the Great Depression . Namely, among some considerations of scaling, Cram√©r studied the behavior of the distribution of     X  n   =    1  n     ‚àë   i  =  1   n    Z  i          subscript  X  n       1  n     superscript   subscript     i  1    n    subscript  Z  i       X_{n}=\frac{1}{n}\sum_{i=1}^{n}Z_{i}   as n ‚Üí‚àû. 1 He found that the tails of the distribution of X n decay exponentially as e ‚àí nŒª ( x ) where the factor Œª ( x ) in the exponent is the Legendre transform (a.k.a. the convex conjugate ) of the cumulant -generating function       Œ®  Z    (  t  )    =   log   ùîº   e   t  Z       .         subscript  normal-Œ®  Z   t       ùîº   superscript  e    t  Z        \Psi_{Z}(t)=\log\mathbb{E}e^{tZ}.   For this reason this particular function Œª ( x ) is sometimes called the Cram√©r function . The rate function defined above in this article is a broad generalization of this notion of Cram√©r's, defined more abstractly on a probability space , rather than the state space of a random variable.  See also   Extreme value theory   References          "  Category:Asymptotic analysis  Category:Large deviations theory     ‚Ü©     