   Entropic vector      Entropic vector   The entropic vector or entropic function is a concept arising in information theory . Shannon 's information entropy measures and their associated identities and inequalities (both constrained and unconstrained) have received a lot of attention over the past from the time Shannon introduced his concept of Information Entropy. A lot of inequalities and identities have been found and are available in standard Information Theory texts. But recent researchers have laid focus on trying to find all possible identities and inequalities (both constrained and unconstrained) on such entropies and characterize them. Entropic vector lays down the basic framework for such a study.  Definition  Let     X  1   ,   X  2   ,  …  ,   X  n       subscript  X  1    subscript  X  2   normal-…   subscript  X  n     X_{1},X_{2},\dots,X_{n}   be random variables, with    n  ∈  N      n  N    n\in N     A vector h in    R    2  n   -  1      superscript  R     superscript  2  n   1     R^{2^{n}-1}   is an entropic vector of order   n   n   n   if and only if there exists a tuple     X  →   =    X  1   ,   X  2   ,  …  ,   X  n         normal-→  X     subscript  X  1    subscript  X  2   normal-…   subscript  X  n      \overrightarrow{X}=X_{1},X_{2},\ldots,X_{n}   with associated vector    h   X  →      subscript  h   normal-→  X     h_{\overrightarrow{X}}   defined by      h   X  →     (  I  )    =   H   (   X  I   )    =   H   (   X   i  1    ,   X   i  2    ,  …  ,   X   i  k    )             subscript  h   normal-→  X    I     H   subscript  X  I           H    subscript  X   subscript  i  1     subscript  X   subscript  i  2    normal-…   subscript  X   subscript  i  k         h_{\overrightarrow{X}}(I)=H(X_{I})=H(X_{i_{1}},X_{i_{2}},\dots,X_{i_{k}})   where    I  =   {   i  1   ,   i  2   ,  …  ,   i  k   }       I    subscript  i  1    subscript  i  2   normal-…   subscript  i  k      I=\{i_{1},i_{2},\dots,i_{k}\}   y    h  =   h   x  →        h   subscript  h   normal-→  x      h=h_{\overrightarrow{x}}   . The set of all entropic vectors of order   n   n   n   is denoted by    Γ  n  *     superscript   subscript  normal-Γ  n      \Gamma_{n}^{*}     All the properties of entropic functions can be transposed to entropic vectors:      H  :    P  n   →   R  +       normal-:  H   normal-→   subscript  P  n    superscript  R       H:P_{n}\rightarrow R^{+}   is continuous  Given a deterministic random variable   x   x   x   , we have     H   (  x  )    =  0        H  x   0    H(x)=0     Given    α  ∈   R  +       α   superscript  R      \alpha\in R^{+}   , there exists a random variable   x   x   x   such that     H   (  x  )    =  α        H  x   α    H(x)=\alpha     Given   P   P   P   a probability distribution on    [  n  ]     delimited-[]  n    [n]   , we have     H   (  P  )    ≤    log  2   n         H  P     subscript   2   n     H(P)\leq\log_{2}n     Example  Let X , Y be two independent random variables with discrete uniform distribution over the set    {  0  ,  1  }     0  1    \{0,1\}   . Then        H   (  X  )    =   H   (  Y  )    =  1   ,    I   (  X  ;  Y  )    =  0      formulae-sequence        H  X     H  Y        1        I   X  Y    0     H\left(X\right)=H(Y)=1,I\left(X;Y\right)=0     It follows that       H   (  X  ,  Y  )    =     H   (  X  )    +   H   (  Y  )     -   I   (  X  ;  Y  )     =  2          H   X  Y          H  X     H  Y      I   X  Y          2     H(X,Y)=H(X)+H(Y)-I\left(X;Y\right)=2     The entropic vector is thus :      v  =    (  1  ,  1  ,  2  )   T   ∈   Γ  2  *         v   superscript   1  1  2   T         superscript   subscript  normal-Γ  2        v=\left(1,1,2\right)^{T}\in\Gamma_{2}^{*}     The region Γ n *  The Shannon inequality and Γ n  The entropy satisfies the properties      1  )  H  (  )  =  0     fragments  1  normal-)   H  normal-(  normal-)   0    1)\quad H()=0         2  )  α  ⊆  β  :  H  (  α  )  ≤  H  (  β  )     fragments  2  normal-)   α   β  normal-:  H  normal-(  α  normal-)   H  normal-(  β  normal-)    2)\quad\alpha\subseteq\beta:H(\alpha)\leq H(\beta)     The Shannon inequality is      3  )  H  (   X  α   )  +  H  (   X  β   )  ≤  H  (   X   α  ∪  β    )  +  H  (   X   α  ∩  β    )     fragments  3  normal-)   H  normal-(   subscript  X  α   normal-)   H  normal-(   subscript  X  β   normal-)   H  normal-(   subscript  X    α  β    normal-)   H  normal-(   subscript  X    α  β    normal-)    3)\quad H(X_{\alpha})+H(X_{\beta})\leq H(X_{\alpha\cup\beta})+H(X_{\alpha\cap%
 \beta})     The entropy vector that satisfies the linear combination of this region is called    Γ  n     subscript  normal-Γ  n    \Gamma_{n}   .  The region    Γ  n  *     superscript   subscript  normal-Γ  n      \Gamma_{n}^{*}   has been studied recently, the cases for n = 1, 2, 3       L  n   =   Γ  n   =   Γ  n  *   =     Γ  n   ¯   *          subscript  L  n    subscript  normal-Γ  n         superscript   subscript  normal-Γ  n           superscript   normal-¯   subscript  normal-Γ  n         L_{n}=\Gamma_{n}=\Gamma_{n}^{*}=\overline{\Gamma_{n}}^{*}          L  n  o   =   Γ  n  o   =     Γ  n   ¯     *  o    =    ⟨   Shannon  n   ⟩   +          superscript   subscript  L  n   o    superscript   subscript  normal-Γ  n   o         superscript   normal-¯   subscript  normal-Γ  n      absent  o          superscript   delimited-⟨⟩   subscript  Shannon  n         L_{n}^{o}=\Gamma_{n}^{o}=\overline{\Gamma_{n}}^{*o}=\langle\mathrm{Shannon}_{n%
 }\rangle^{+}     if and only if n ∈ {1, 2, 3}  It is difficult harder con the case    n  ≥  4      n  4    n\geq 4   , the number of inequalities given by monotone and submodularity properties increase when we increase n , however the relationship among entropic vectors, polymatroids, are an object of study for the information theory and there are other ways to characterize those relationships mentioned  The most important results for the characterization of    Γ  n  *     superscript   subscript  normal-Γ  n      \Gamma_{n}^{*}   is not precisely about these set, but its topological clousure i.e. the set     Γ  n  *   →     normal-→   superscript   subscript  normal-Γ  n       \overrightarrow{\Gamma_{n}^{*}}   , which says that     Γ  n  *   →     normal-→   superscript   subscript  normal-Γ  n       \overrightarrow{\Gamma_{n}^{*}}   is a convex cone , other interesing characterization is that      Γ  n  *   →   =   Γ  n        normal-→   superscript   subscript  normal-Γ  n       subscript  normal-Γ  n     \overrightarrow{\Gamma_{n}^{*}}=\Gamma_{n}   (    Γ  n     subscript  normal-Γ  n    \Gamma_{n}   is the set of vectors that satisfy Shannon-type inequalities) for    n  ≤  3      n  3    n\leq 3   , in other words the set of entropy vector is completely characterized by Sahnnon's Inequalities, 1 for the case n = 4 fails this property, 2 3 particularly by the Ingleton's inequality . 4       L  n   ⊆     Γ  n   ¯   *   ⊆   Γ  n          subscript  L  n    superscript   normal-¯   subscript  normal-Γ  n            subscript  normal-Γ  n      L_{n}\subseteq\overline{\Gamma_{n}}^{*}\subseteq\Gamma_{n}          Γ  n  o   ⊆     Γ  n   ¯     *  o    ⊆   L  n  o          superscript   subscript  normal-Γ  n   o    superscript   normal-¯   subscript  normal-Γ  n      absent  o          superscript   subscript  L  n   o      \Gamma_{n}^{o}\subseteq\overline{\Gamma_{n}}^{*o}\subseteq L_{n}^{o}          Γ  n  o   =    ⟨   Shannon  n   ⟩   +        superscript   subscript  normal-Γ  n   o    superscript   delimited-⟨⟩   subscript  Shannon  n        \Gamma_{n}^{o}=\langle\mathrm{Shannon}_{n}\rangle^{+}     The Matus theorem  On the year 1998 the Senior Member IEEE Zhen Zhang and Raymond W. Yeung  . 5  show a new non-Shannon's inequality      I   (   X  3   ,   X  4   )   =  I   (  X  4  ,   X  2   )   +  I   (   X  1   :   X  3   ,   X  4   )   +  3  I   (   X  3   :   X  4   |   X  1   )   +  I   (   X  3   :   X  4   |   X  2   )      fragments  I   fragments  normal-(   subscript  X  3   normal-,   subscript  X  4   normal-)    I   fragments  normal-(  X  4  normal-,   subscript  X  2   normal-)    I   fragments  normal-(   subscript  X  1   normal-:   subscript  X  3   normal-,   subscript  X  4   normal-)    3  I   fragments  normal-(   subscript  X  3   normal-:   subscript  X  4   normal-|   subscript  X  1   normal-)    I   fragments  normal-(   subscript  X  3   normal-:   subscript  X  4   normal-|   subscript  X  2   normal-)     I(X_{3},X_{4})=I(X4,X_{2})+I(X_{1}:X_{3},X_{4})+3I(X_{3}:X_{4}|X_{1})+I(X_{3}:%
 X_{4}|X_{2})   On the year 2007 Matus proved  6       Γ  4  *   ¯     normal-¯   superscript   subscript  normal-Γ  4       \overline{\Gamma_{4}^{*}}   is not polihedral.  Entropy and groups  Group-charactizable vectors and quasi-uniform distribution  One way to charactize    Γ  n  *     superscript   subscript  normal-Γ  n      \Gamma_{n}^{*}   is by looking at some special distributions.\\ Definition: A group characterizable vector h is also denoted to be     2  n   →  R     normal-→   superscript  2  n   R    2^{n}\rightarrow R     such that there exists a group   G   G   G   and subgroups     G  1   ,   G  2   ,  …  ,   G  n       subscript  G  1    subscript  G  2   normal-…   subscript  G  n     G_{1},G_{2},\dots,G_{n}   and for    α  ⊂  n      α  n    \alpha\subset n          H   (  α  )    =    |   G  i   |    |  G  |          H  α         G  i      G      H(\alpha)=\frac{|Gi|}{|G|}     if    G  α     subscript  G  α    G_{\alpha}   is not     absent   \quad\quad   and 0 otherwise.    G  =    ∩   i  ∈  α     G  i        G    subscript     i  α     subscript  G  i      G=\cap_{i\in\alpha}G_{i}   .  Definition    γ  n     superscript  γ  n    \gamma^{n}   is the set of all group charactizable vectors is   n   n   n   , and we can describe better the set    Γ  n     superscript  normal-Γ  n    \Gamma^{n}     Theorem     γ  n   ⊂   Γ  n        superscript  γ  n    superscript  normal-Γ  n     \gamma^{n}\subset\Gamma^{n}     Open problem  Given a vector    v  ∈   R    2  n   -  1        v   superscript  R     superscript  2  n   1      v\in R^{2^{n}-1}   , is it possible to say if there exists   n   n   n   random variables such that their joint entropies are given by   v   v   v   ? It turns out that for    n  =   2  ,  3       n   2  3     n=2,3   the problem has been solved. But for    n  ≥  4      n  4    n\geq 4   , it still remains unsolved. Defining the set of all such vectors    v  ∈   R    2  n   -  1        v   superscript  R     superscript  2  n   1      v\in R^{2^{n}-1}   that can be constructed from a set of   n   n   n   random variables as    Γ  n  *     subscript   superscript  normal-Γ    n    {\Gamma}^{*}_{n}   , we see that a complete characterization of this space remains an unsolved mystery.  References     Thomas M. Cover, Joy A. Thomas. Elements of information theory New York: Wiley, 1991. ISBN 0-471-06259-6  Raymond Yeung. A First Course in Information Theory , Chapter 12, Information Inequalities , 2002, Print ISBN 0-306-46791-7   "  Category:Information theory     ↩  ↩  ↩  ↩  ↩  ↩     