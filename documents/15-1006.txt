   Matrix analytic method      Matrix analytic method   In probability theory , the matrix analytic method is a technique to compute the stationary probability distribution of a Markov chain which has a repeating structure (after some point) and a state space which grows unboundedly in no more than one dimension. 1 2 Such models are often described as M/G/1 type Markov chains because they can describe transitions in an M/G/1 queue. 3 4 The method is a more complicated version of the matrix geometric method and is the classical solution method for M/G/1 chains. 5  Method description  An M/G/1-type stochastic matrix is one of the form 6    P = \begin{pmatrix}     B_0 & B_1 & B_2 & B_3 & \cdots \\ A_0 & A_1 & A_2 & A_3 & \cdots \\  &Â A_0Â Â Â Â &Â A_1Â Â Â Â &Â A_2Â Â Â Â &Â \cdotsÂ \\  &Â Â Â Â Â Â Â Â &Â A_0Â Â Â Â &Â A_1Â Â Â Â &Â \cdotsÂ \\  \vdots & \vdots & \vdots & \vdots & \ddots \end{pmatrix}  where B i and A i are k Ã— k matrices. (Note that unmarked matrix entries represent zeroes.) Such a matrix describes the embedded Markov chain in an M/G/1 queue. 7 8 If P is irreducible and positive recurrent then the stationary distribution is given by the solution to the equations 9          P  Ï€   =   Ï€  and       ğ  T   Ï€   =  1      formulae-sequence      P  Ï€    Ï€  and         superscript  ğ  T   Ï€   1     P\pi=\pi\quad\text{ and }\quad\mathbf{e}^{\text{T}}\pi=1        where e represents a vector of suitable dimension with all values equal to 1. Matching the structure of P , Ï€ is partitioned to Ï€ 1 , Ï€ 2 , Ï€ 3 , â€¦. To compute these probabilities the column stochastic matrix G is computed such that 10         G  =    âˆ‘   i  =  0   âˆ     G  i    A  i      .      G    superscript   subscript     i  0         superscript  G  i    subscript  A  i       G=\sum_{i=0}^{\infty}G^{i}A_{i}.        G is called the auxiliary matrix. 11 Matrices are defined 12    \begin{align}     \overline{A}_{i+1} &= \sum_{j=i+1}^\infty G^{j-i-1}A_j \\ \overline{B}_i &= \sum_{j=i}^\infty G^{j-i}B_j \end{align}  then Ï€ 0 is found by solving 13    \begin{align}     \overline{B}_0 \pi_0 &= \pi_0\\  \quadÂ \left(\mathbfÂ e^{\text{T}}Â +Â \mathbfÂ e^{\text{T}}\left(IÂ -Â \sum_{i=1}^\inftyÂ \overline{A}_i\right)^{-1}\sum_{i=1}^\inftyÂ \overline{B}_i\right)Â \pi_0Â &=Â 1  \end{align}  and the Ï€ i are given by Ramaswami's formula , 14 a numerically stable relationship first published by Vaidyanathan Ramaswami in 1988. 15          Ï€  i   =     (   I  -    A  Â¯   1    )    -  1     [      B  Â¯    i  +  1     Ï€  0    +    âˆ‘   j  =  1    i  -  1       A  Â¯     i  +  1   -  j     Ï€  j      ]     ,   i  â‰¥  1.      formulae-sequence     subscript  Ï€  i      superscript    I   subscript   normal-Â¯  A   1      1     delimited-[]       subscript   normal-Â¯  B     i  1     subscript  Ï€  0      superscript   subscript     j  1      i  1       subscript   normal-Â¯  A       i  1   j     subscript  Ï€  j           i  1.     \pi_{i}=(I-\overline{A}_{1})^{-1}\left[\overline{B}_{i+1}\pi_{0}+\sum_{j=1}^{i%
 -1}\overline{A}_{i+1-j}\pi_{j}\right],i\geq 1.        Computation of G  There are two popular iterative methods for computing G , 16 17   functional iterations  cyclic reduction .   Tools   MAMSolver 18   References  "  Category:Probability theory  Category:Single queueing nodes     â†©  â†©  â†©  â†©  â†©   â†©  â†©    â†©     â†©  â†©  â†©  â†©     