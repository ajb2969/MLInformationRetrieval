   Matrix analytic method      Matrix analytic method   In probability theory , the matrix analytic method is a technique to compute the stationary probability distribution of a Markov chain which has a repeating structure (after some point) and a state space which grows unboundedly in no more than one dimension. 1 2 Such models are often described as M/G/1 type Markov chains because they can describe transitions in an M/G/1 queue. 3 4 The method is a more complicated version of the matrix geometric method and is the classical solution method for M/G/1 chains. 5  Method description  An M/G/1-type stochastic matrix is one of the form 6    P = \begin{pmatrix}     B_0 & B_1 & B_2 & B_3 & \cdots \\ A_0 & A_1 & A_2 & A_3 & \cdots \\  & A_0    & A_1    & A_2    & \cdots \\  &        & A_0    & A_1    & \cdots \\  \vdots & \vdots & \vdots & \vdots & \ddots \end{pmatrix}  where B i and A i are k × k matrices. (Note that unmarked matrix entries represent zeroes.) Such a matrix describes the embedded Markov chain in an M/G/1 queue. 7 8 If P is irreducible and positive recurrent then the stationary distribution is given by the solution to the equations 9          P  π   =   π  and       𝐞  T   π   =  1      formulae-sequence      P  π    π  and         superscript  𝐞  T   π   1     P\pi=\pi\quad\text{ and }\quad\mathbf{e}^{\text{T}}\pi=1        where e represents a vector of suitable dimension with all values equal to 1. Matching the structure of P , π is partitioned to π 1 , π 2 , π 3 , …. To compute these probabilities the column stochastic matrix G is computed such that 10         G  =    ∑   i  =  0   ∞     G  i    A  i      .      G    superscript   subscript     i  0         superscript  G  i    subscript  A  i       G=\sum_{i=0}^{\infty}G^{i}A_{i}.        G is called the auxiliary matrix. 11 Matrices are defined 12    \begin{align}     \overline{A}_{i+1} &= \sum_{j=i+1}^\infty G^{j-i-1}A_j \\ \overline{B}_i &= \sum_{j=i}^\infty G^{j-i}B_j \end{align}  then π 0 is found by solving 13    \begin{align}     \overline{B}_0 \pi_0 &= \pi_0\\  \quad \left(\mathbf e^{\text{T}} + \mathbf e^{\text{T}}\left(I - \sum_{i=1}^\infty \overline{A}_i\right)^{-1}\sum_{i=1}^\infty \overline{B}_i\right) \pi_0 &= 1  \end{align}  and the π i are given by Ramaswami's formula , 14 a numerically stable relationship first published by Vaidyanathan Ramaswami in 1988. 15          π  i   =     (   I  -    A  ¯   1    )    -  1     [      B  ¯    i  +  1     π  0    +    ∑   j  =  1    i  -  1       A  ¯     i  +  1   -  j     π  j      ]     ,   i  ≥  1.      formulae-sequence     subscript  π  i      superscript    I   subscript   normal-¯  A   1      1     delimited-[]       subscript   normal-¯  B     i  1     subscript  π  0      superscript   subscript     j  1      i  1       subscript   normal-¯  A       i  1   j     subscript  π  j           i  1.     \pi_{i}=(I-\overline{A}_{1})^{-1}\left[\overline{B}_{i+1}\pi_{0}+\sum_{j=1}^{i%
 -1}\overline{A}_{i+1-j}\pi_{j}\right],i\geq 1.        Computation of G  There are two popular iterative methods for computing G , 16 17   functional iterations  cyclic reduction .   Tools   MAMSolver 18   References  "  Category:Probability theory  Category:Single queueing nodes     ↩  ↩  ↩  ↩  ↩   ↩  ↩    ↩     ↩  ↩  ↩  ↩     