   Additive Markov chain      Additive Markov chain   In probability theory , an additive Markov chain is a Markov chain with an additive  conditional probability function. Here the process is a discrete-time  Markov chain of order m and the transition probability to a state at the next time is a sum of functions, each depending on the next state and one of the m previous states.  Definition  An additive Markov chain of order m is a sequence of random variables  X 1 , X 2 , X 3 , ..., possessing the following property: the probability that a random variable X n has a certain value x n under the condition that the values of all previous variables are fixed depends on the values of m previous variables only ( Markov chain of order m ), and the influence of previous variables on a generated one is additive,       Pr   (    X  n   =   x  n    |    X   n  -  1    =   x   n  -  1     ,    X   n  -  2    =   x   n  -  2     ,  …  ,    X   n  -  m    =   x   n  -  m     )    =    ∑   r  =  1   m    f   (   x  n   ,   x   n  -  r    ,  r  )          Pr     subscript  X  n    subscript  x  n       subscript  X    n  1     subscript  x    n  1        subscript  X    n  2     subscript  x    n  2     normal-…     subscript  X    n  m     subscript  x    n  m        superscript   subscript     r  1    m     f    subscript  x  n    subscript  x    n  r    r       \Pr(X_{n}=x_{n}|X_{n-1}=x_{n-1},X_{n-2}=x_{n-2},\dots,X_{n-m}=x_{n-m})=\sum_{r%
 =1}^{m}f(x_{n},x_{n-r},r)   .  Binary case  A binary additive Markov chain is where the state space of the chain consists on two values only, X n ∈ { x 1 , x 2 }. For example, X n ∈ { 0, 1 }. The conditional probability function of a binary additive Markov chain can be represented as        Pr   (    X  n   =  1   |    X   n  -  1    =   x   n  -  1     ,    X   n  -  2    =   x   n  -  2     ,  …  )    =    X  ¯   +    ∑   r  =  1   m    F   (  r  )    (    x   n  -  r    -   X  ¯    )       ,       Pr     subscript  X  n   1      subscript  X    n  1     subscript  x    n  1        subscript  X    n  2     subscript  x    n  2     normal-…      normal-¯  X     superscript   subscript     r  1    m     F  r     subscript  x    n  r     normal-¯  X         \Pr(X_{n}=1|X_{n-1}=x_{n-1},X_{n-2}=x_{n-2},\dots)=\bar{X}+\sum_{r=1}^{m}F(r)(%
 x_{n-r}-\bar{X}),           Pr   (    X  n   =  0   |    X   n  -  1    =   x   n  -  1     ,    X   n  -  2    =   x   n  -  2     ,  …  )    =   1  -   Pr   (    X  n   =  1   |    X   n  -  1    =   x   n  -  1     ,    X   n  -  2    =   x   n  -  2     ,  …  )      .       Pr     subscript  X  n   0      subscript  X    n  1     subscript  x    n  1        subscript  X    n  2     subscript  x    n  2     normal-…     1   Pr     subscript  X  n   1      subscript  X    n  1     subscript  x    n  1        subscript  X    n  2     subscript  x    n  2     normal-…      \Pr(X_{n}=0|X_{n-1}=x_{n-1},X_{n-2}=x_{n-2},\dots)=1-\Pr(X_{n}=1|X_{n-1}=x_{n-%
 1},X_{n-2}=x_{n-2},\dots).     Here    X  ¯     normal-¯  X    \bar{X}   is the probability to find X n = 1 in the sequence and F ( r ) is referred to as the memory function. The value of    X  ¯     normal-¯  X    \bar{X}   and the function F ( r ) contain all the information about correlation properties of the Markov chain.  Relation between the memory function and the correlation function  In the binary case, the correlation function between the variables    X  n     subscript  X  n    X_{n}   and    X  k     subscript  X  k    X_{k}   of the chain depends on the distance    n  -  k      n  k    n-k   only. It is defined as follows:        K   (  r  )    =   ⟨    (    X  n   -   X  ¯    )    (    X   n  +  r    -   X  ¯    )    ⟩   =    ⟨    X  n    X   n  +  r     ⟩   -    X  ¯   2     ,          K  r    delimited-⟨⟩       subscript  X  n    normal-¯  X       subscript  X    n  r     normal-¯  X              delimited-⟨⟩     subscript  X  n    subscript  X    n  r       superscript   normal-¯  X   2       K(r)=\langle(X_{n}-\bar{X})(X_{n+r}-\bar{X})\rangle=\langle X_{n}X_{n+r}%
 \rangle-{\bar{X}}^{2},     where the symbol    ⟨  ⋯  ⟩     delimited-⟨⟩  normal-⋯    \langle\cdots\rangle   denotes averaging over all n . By definition,         K   (   -  r   )    =   K   (  r  )     ,    K   (  0  )    =    X  ¯    (   1  -   X  ¯    )      .     formulae-sequence      K    r      K  r        K  0      normal-¯  X     1   normal-¯  X        K(-r)=K(r),K(0)=\bar{X}(1-\bar{X}).     There is a relation between the memory function and the correlation function of the binary additive Markov chain: 1         K   (  r  )    =    ∑   s  =  1   m    K   (   r  -  s   )   F   (  s  )      ,   r  =   1  ,  2  ,   …      .     formulae-sequence      K  r     superscript   subscript     s  1    m     K    r  s   F  s       r   1  2  normal-…      K(r)=\sum_{s=1}^{m}K(r-s)F(s),\,\,\,\,r=1,2,\dots\,.     See also   Examples of Markov chains   Notes  References   A.A. Markov. (1906) "Rasprostranenie zakona bol'shih chisel na velichiny, zavisyaschie drug ot druga". Izvestiya Fiziko-matematicheskogo obschestva pri Kazanskom universitete , 2-ya seriya, tom 15, 135–156  A.A. Markov. (1971) "Extension of the limit theorems of probability theory to a sum of variables connected in a chain". reprinted in Appendix B of: R. Howard. Dynamic Probabilistic Systems, volume 1: Markov Chains . John Wiley and Sons    Ramakrishnan, S. (1981) "Finitely Additive Markov Chains", Transactions of the American Mathematical Society , 265 (1), 247-272   "  Category:Stochastic processes  Category:Markov processes     S.S. Melnyk, O.V. Usatenko, and V.A. Yampol’skii. (2006) "Memory functions of the additive Markov chains: applications to complex dynamic systems", Physica A , 361 (2), 405–415 ↩     