   Berry–Esseen theorem      Berry–Esseen theorem  In [[probability theory]], the [[central limit theorem]] states th at, under certain circumstances, the probability distribution of the scaled mean of a random sample  converges to a normal distribution as the sample size increases to infinity. Under stronger assumptions, the Berry–Esseen theorem , or Berry–Esseen inequality , gives a more quantitative result, because it also specifies the rate at which this convergence takes place by giving a bound on the maximal error of approximation between the normal distribution and the true distribution of the scaled sample mean. The approximation is measured by the Kolmogorov–Smirnov distance . In the case of independent samples , the convergence rate is , where   n   n   n   is the sample size, and the constant is estimated in terms of the third absolute normalized moments .  Statement of the theorem  Statements of the theorem vary, as it was independently discovered by two mathematicians , Andrew C. Berry (in 1941) and Carl-Gustav Esseen (1942), who then, along with other authors, refined it repeatedly over subsequent decades.  Identically distributed summands  One version, sacrificing generality somewhat for the sake of clarity, is the following:   There exists a positive constant  C such that if X 1 , X 2 , ..., are i.i.d. random variables with E( X 1 ) = 0, E( X 1 2 ) = σ 2 > 0, and E(| X 1 | 3 ) = ρ Y_n = {X_1 + X_2 + \cdots + X_n \over n}  the sample mean , with F n the cumulative distribution function of        Y  n    n    σ   ,         subscript  Y  n     n    σ    {Y_{n}\sqrt{n}\over{\sigma}},      and Φ the cumulative distribution function of the standard normal distribution , then for all x and n ,     |   F  n    (  x  )   -  Φ   (  x  )   |  ≤    C  ρ      σ  3     n     .   (  1  )      fragments  normal-|   subscript  F  n    fragments  normal-(  x  normal-)    Φ   fragments  normal-(  x  normal-)   normal-|       C  ρ      superscript  σ  3     n     normal-.  italic-   fragments  normal-(  1  normal-)     \left|F_{n}(x)-\Phi(x)\right|\leq{C\rho\over\sigma^{3}\,\sqrt{n}}.\ \ \ \ (1)       That is: given a sequence of independent and identically-distributed random variables , each having mean zero and positive variance , if additionally the third absolute moment is finite, then the cumulative distribution functions of the standardized sample mean and the standard normal distribution differ (vertically, on a graph) by no more than the specified amount. Note that the approximation error for all n (and hence the limiting rate of convergence for indefinite n sufficiently large) is bounded by the order of n −1/2 .  Calculated values of the constant C have decreased markedly over the years, from the original value of 7.59 by , to 0.7882 by , then 0.7655 by , then 0.7056 by , then 0.7005 by , then 0.5894 by , then 0.5129 by , then 0.4785 by . The detailed review can be found in the papers , . The best estimate , C \sup_{x\in\mathbb R}\left|F_n(x) - \Phi(x)\right| \le {0.33554 (\rho+0.415\sigma^3)\over \sigma^3\,\sqrt{n}}, due to , since σ 3 ≤ ρ and 0.33554 · 1.415 3, then the estimate         sup   x  ∈  ℝ     |     F  n    (  x  )    -   Φ   (  x  )     |    ≤    0.3328   (   ρ  +   0.429   σ  3     )       σ  3     n      ,        subscript  supremum    x  ℝ           subscript  F  n   x     normal-Φ  x          0.3328    ρ    0.429   superscript  σ  3         superscript  σ  3     n       \sup_{x\in\mathbb{R}}\left|F_{n}(x)-\Phi(x)\right|\leq{0.3328(\rho+0.429\sigma%
 ^{3})\over\sigma^{3}\,\sqrt{n}},   which is also proved in , gives an even tighter upper estimate.  proved that the constant also satisfies the lower bound      C  ≥     10   +  3    6    2  π      ≈  0.40973  ≈    1    2  π     +  0.01079.         C        10   3     6      2  π           0.40973           1      2  π     0.01079.      C\geq\frac{\sqrt{10}+3}{6\sqrt{2\pi}}\approx 0.40973\approx\frac{1}{\sqrt{2\pi%
 }}+0.01079.     Non-identically distributed summands   Let X 1 , X 2 , ..., be independent random variables with E ( X i ) = 0, E( X i 2 ) = σ i 2 > 0, and E(| X i | 3 ) = ρ i S_n = {X_1 + X_2 + \cdots + X_n \over \sqrt{\sigma_1^2+\sigma_2^2+\cdots+\sigma_n^2} }  be the normalized n -th partial sum. Denote F n the cdf of S n , and Φ the cdf of the standard normal distribution . For the sake of convenience denote        σ  →   =   (   σ  1   ,  …  ,   σ  n   )    ,    ρ  →   =   (   ρ  1   ,  …  ,   ρ  n   )     .     formulae-sequence     normal-→  σ     subscript  σ  1   normal-…   subscript  σ  n        normal-→  ρ     subscript  ρ  1   normal-…   subscript  ρ  n       \vec{\sigma}=(\sigma_{1},\ldots,\sigma_{n}),\ \vec{\rho}=(\rho_{1},\ldots,\rho%
 _{n}).      In 1941, Andrew C. Berry proved that for all n there exists an absolute constant C 1 such that       sup   x  ∈  ℝ     |     F  n    (  x  )    -   Φ   (  x  )     |    ≤     C  1   ⋅   ψ  1    ,   (  2  )          subscript  supremum    x  ℝ           subscript  F  n   x     normal-Φ  x        normal-⋅   subscript  C  1    subscript  ψ  1    2     \sup_{x\in\mathbb{R}}\left|F_{n}(x)-\Phi(x)\right|\leq C_{1}\cdot\psi_{1},\ \ %
 \ \ (2)      where : \psi_1=\psi_1\big(\vec{\sigma},\vec{\rho}\big)=\Big({\textstyle\sum\limits_{i=1}^n\sigma_i^2}\Big)^{-1/2}\cdot\max_{1\le    i\le n}\frac{\rho_i}{\sigma_i^2}.   Independently, in 1942, Carl-Gustav Esseen proved that for all n there exists an absolute constant C 0 such that       sup   x  ∈  ℝ     |     F  n    (  x  )    -   Φ   (  x  )     |    ≤     C  0   ⋅   ψ  0    ,   (  3  )          subscript  supremum    x  ℝ           subscript  F  n   x     normal-Φ  x        normal-⋅   subscript  C  0    subscript  ψ  0    3     \sup_{x\in\mathbb{R}}\left|F_{n}(x)-\Phi(x)\right|\leq C_{0}\cdot\psi_{0},\ \ %
 \ \ (3)      where       ψ  0   =    ψ  0    (   σ  →   ,   ρ  →   )    =     (     ∑   i  =  1   n     σ  i  2    )    -   3  /  2     ⋅    ∑   i  =  1   n    ρ  i      .         subscript  ψ  0      subscript  ψ  0     normal-→  σ    normal-→  ρ           normal-⋅   superscript    superscript   subscript     i  1    n    superscript   subscript  σ  i   2        3  2       superscript   subscript     i  1    n    subscript  ρ  i        \psi_{0}=\psi_{0}\big(\vec{\sigma},\vec{\rho}\big)=\Big({\textstyle\sum\limits%
 _{i=1}^{n}\sigma_{i}^{2}}\Big)^{-3/2}\cdot\sum\limits_{i=1}^{n}\rho_{i}.       It is easy to make sure that ψ 0 ≤ψ 1 . Due to this circumstance inequality (3) is conventionally called the Berry–Esseen inequality, and the quantity ψ 0 is called the Lyapunov fraction of the third order. Moreover, in the case where the summands X 1 ,... X n have identical distributions          ψ  0   =   ψ  1   =    ρ  1     σ  1  3    n      ,         subscript  ψ  0    subscript  ψ  1           subscript  ρ  1      superscript   subscript  σ  1   3     n        \psi_{0}=\psi_{1}=\frac{\rho_{1}}{\sigma_{1}^{3}\sqrt{n}},        and thus the bounds stated by inequalities (1), (2) and (3) coincide.  Regarding C 0 , obviously, the lower bound established by  remains valid:        C  0   ≥     10   +  3    6    2  π      =   0.4097  …    .         subscript  C  0         10   3     6      2  π             0.4097  normal-…      C_{0}\geq\frac{\sqrt{10}+3}{6\sqrt{2\pi}}=0.4097\ldots.     The upper bounds for C 0 were subsequently lowered from the original estimate 7.59 due to  to (we mention the recent results only) 0.9051 due to , 0.7975 due to , 0.7915 due to , 0.6379 and 0.5606 due to  and .  the best estimate is 0.5600 obtained by .  See also   Chernoff's inequality  Edgeworth series  List of inequalities  List of mathematical theorems  Concentration inequality   References    Durrett, Richard (1991). Probability: Theory and Examples . Pacific Grove, CA: Wadsworth & Brooks/Cole. ISBN 0-534-13206-5.    Feller, William (1972). An Introduction to Probability Theory and Its Applications, Volume II (2nd ed.). New York: John Wiley & Sons. ISBN 0-471-25709-5.    Manoukian, Edward B. (1986). Modern Concepts and Theorems of Mathematical Statistics . New York: Springer-Verlag. ISBN 0-387-96186-0.  Serfling, Robert J. (1980). Approximation Theorems of Mathematical Statistics . New York: John Wiley & Sons. ISBN 0-471-02403-1.            External links   Gut, Allan & Holst Lars. Carl-Gustav Esseen , retrieved Mar. 15, 2004.    "  Category:Probability theorems  Category:Probabilistic inequalities  Category:Statistical theorems  Category:Central limit theorem   