   Fisher consistency      Fisher consistency   In statistics , Fisher consistency , named after Ronald Fisher , is a desirable property of an estimator asserting that if the estimator were calculated using the entire population rather than a sample , the true value of the estimated parameter would be obtained. 1  Definition  Suppose we have a statistical sample  X 1 , ..., X n where each X i follows a cumulative distribution  F θ which depends on an unknown parameter  θ . If an estimator of θ based on the sample can be represented as a functional of the empirical distribution function  F̂ n :        θ  ^   =   T   (    F  ^   n   )     ,       normal-^  θ     T   subscript   normal-^  F   n      \hat{\theta}=T(\hat{F}_{n})\,,     the estimator is said to be Fisher consistent if:        T   (   F  θ   )    =   θ    .        T   subscript  F  θ    θ    T(F_{\theta})=\theta\,.    2  As long as the X i are exchangeable , an estimator T defined in terms of the X i can be converted into an estimator T′ that can be defined in terms of F̂ n by averaging T over all permutations of the data. The resulting estimator will have the same expected value as T and its variance will be no larger than that of T .  If the strong law of large numbers can be applied, the empirical distribution functions F̂ n converge pointwise to F θ , allowing us to express Fisher consistency as a limit — the estimator is Fisher consistent if        T   (    lim   n  →  ∞      F  ^   n    )    =  θ   .        T    subscript    normal-→  n      subscript   normal-^  F   n     θ    T\left(\lim_{n\rightarrow\infty}\hat{F}_{n}\right)=\theta.\,     Finite population example  Suppose our sample is obtained from a finite population Z 1 , ..., Z m . We can represent our sample of size n in terms of the proportion of the sample n i / n taking on each value in the population. Writing our estimator of θ as T ( n 1 / n , ..., n m / n ), the population analogue of the estimator is T ( p 1 , ..., p m ), where p i = P ( X = Z i ). Thus we have Fisher consistency if T ( p 1 , ..., p m ) = θ.  Suppose the parameter of interest is the expected value μ and the estimator is the sample mean , which can be written       n   -  1     ∑   i  =  1   n    ∑   j  =  1   m   I   (   X  i   =   Z  j   )    Z  j   ,     fragments   superscript  n    1     superscript   subscript     i  1    n    superscript   subscript     j  1    m   I   fragments  normal-(   subscript  X  i     subscript  Z  j   normal-)    subscript  Z  j   normal-,    n^{-1}\sum_{i=1}^{n}\sum_{j=1}^{m}I(X_{i}=Z_{j})Z_{j},     where I is the indicator function . The population analogue of this expression is         n   -  1      ∑   i  =  1   n     ∑   j  =  1   m     p  j    Z  j       =    n   -  1      ∑   i  =  1   n   μ    =  μ   ,           superscript  n    1      superscript   subscript     i  1    n     superscript   subscript     j  1    m      subscript  p  j    subscript  Z  j          superscript  n    1      superscript   subscript     i  1    n   μ         μ     n^{-1}\sum_{i=1}^{n}\sum_{j=1}^{m}p_{j}Z_{j}=n^{-1}\sum_{i=1}^{n}\mu=\mu,     so we have Fisher consistency.  Role in maximum likelihood estimation  Maximising the likelihood function L gives an estimate that is Fisher consistent for a parameter b if        E   [    d   ln  L     d  b    ]    =   0  at  b   =   b  0    ,          E   delimited-[]      d    L      d  b        0  at  b         subscript  b  0      E\left[\frac{d\ln L}{db}\right]=0\text{ at }b=b_{0},\,     where b 0 represents the true value of b . 3 4  Relationship to asymptotic consistency and unbiasedness  The term consistency in statistics usually refers to an estimator that is asymptotically consistent . Fisher consistency and asymptotic consistency are distinct concepts, although both aim to define a desirable property of an estimator. While many estimators are consistent in both senses, neither definition encompasses the other. For example, suppose we take an estimator T n that is both Fisher consistent and asymptotically consistent, and then form T n + E n , where E n is a deterministic sequence of nonzero numbers converging to zero. This estimator is asymptotically consistent, but not Fisher consistent for any n . Alternatively, take a sequence of Fisher consistent estimators S n , then define T n = S n for n 0, and T n = S n 0 for all n ≥ n 0 . This estimator is Fisher consistent for all n , but not asymptotically consistent. A concrete example of this construction would be estimating the population mean as X 1 regardless of the sample size.  The sample mean is a Fisher consistent and unbiased estimate of the population mean, but not all Fisher consistent estimates are unbiased. Suppose we observe a sample from a uniform distribution on (0,θ) and we wish to estimate θ. The sample maximum is Fisher consistent, but downwardly biased. Conversely, the sample variance is an unbiased estimate of the population variance, but is not Fisher consistent.  Role in decision theory  A loss function is Fisher consistent if the population minimizer of the risk leads to the Bayes optimal decision rule. 5  References  "  Category:Statistical theory  Category:Statistical terminology     ↩  Cox, D.R., Hinkley D.V. (1974) Theoretical Statistics , Chapman and Hall, ISBN 0-412-12420-3. (defined on p287) ↩  ↩  http://economics.about.com/library/glossary/bldef-fisher-consistency.htm ↩  http://www.stat.osu.edu/~yklee/881/consistency.pdf ↩     