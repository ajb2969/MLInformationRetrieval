   Stochastic game      Stochastic game   In game theory , a stochastic game , introduced by Lloyd Shapley in the early 1950s, is a dynamic game with probabilistic transitions played by one or more players. The game is played in a sequence of stages. At the beginning of each stage the game is in some state . The players select actions and each player receives a payoff that depends on the current state and the chosen actions. The game then moves to a new random state whose distribution depends on the previous state and the actions chosen by the players. The procedure is repeated at the new state and play continues for a finite or infinite number of stages. The total payoff to a player is often taken to be the discounted sum of the stage payoffs or the limit inferior of the averages of the stage payoffs.  Stochastic games generalize both Markov decision processes and repeated games .  Two-player games  Stochastic two-player games on directed graphs are widely used for modeling and analysis of discrete systems operating in an unknown (adversarial) environment. Possible configurations of a system and its environment are represented as vertices, and the transitions correspond to actions of the system, its environment, or "nature". A run of the system then corresponds to an infinite path in the graph. Thus, a system and its environment can be seen as two players with antagonistic objectives, where one player (the system) aims at maximizing the probability of "good" runs, while the other player (the environment) aims at the opposite.  In many cases, there exists an equilibrium value of this probability, but optimal strategies for both players may not exist.  We introduce basic concepts and algorithmic questions studied in this area, and we mention some long-standing open problems. Then, we mention selected recent results.  Theory  The ingredients of a stochastic game are: a finite set of players   I   I   I   ; a state space   M   M   M   (either a finite set or a measurable space    (  M  ,  ùíú  )     M  ùíú    (M,{\mathcal{A}})   ); for each player    i  ‚àà  I      i  I    i\in I   , an action set    S  i     superscript  S  i    S^{i}   (either a finite set or a measurable space    (   S  i   ,   ùíÆ  i   )      superscript  S  i    superscript  ùíÆ  i     (S^{i},{\mathcal{S}}^{i})   ); a transition probability   P   P   P   from    M  √ó  S      M  S    M\times S   , where    S  =   √ó   i  ‚àà  I     S  i      fragments  S    subscript     i  I     superscript  S  i     S=\times_{i\in I}S^{i}   is the action profiles, to   M   M   M   , where    P   (  A  ‚à£  m  ,  s  )      fragments  P   fragments  normal-(  A  normal-‚à£  m  normal-,  s  normal-)     P(A\mid m,s)   is the probability that the next state is in   A   A   A   given the current state   m   m   m   and the current action profile   s   s   s   ; and a payoff function   g   g   g   from    M  √ó  S      M  S    M\times S   to    R  I     superscript  R  I    R^{I}   , where the   i   i   i   -th coordinate of   g   g   g   ,    g  i     superscript  g  i    g^{i}   , is the payoff to player   i   i   i   as a function of the state   m   m   m   and the action profile   s   s   s   .  The game starts at some initial state    m  1     subscript  m  1    m_{1}   . At stage   t   t   t   , players first observe    m  t     subscript  m  t    m_{t}   , then simultaneously choose actions     s  t  i   ‚àà   S  i        subscript   superscript  s  i   t    superscript  S  i     s^{i}_{t}\in S^{i}   , then observe the action profile     s  t   =    (   s  t  i   )   i        subscript  s  t    subscript   subscript   superscript  s  i   t   i     s_{t}=(s^{i}_{t})_{i}   , and then nature selects    m   t  +  1      subscript  m    t  1     m_{t+1}   according to the probability    P   (  ‚ãÖ  ‚à£   m  t   ,   s  t   )      fragments  P   fragments  normal-(  normal-‚ãÖ  normal-‚à£   subscript  m  t   normal-,   subscript  s  t   normal-)     P(\cdot\mid m_{t},s_{t})   . A play of the stochastic game,     m  1   ,   s  1   ,  ‚Ä¶  ,   m  t   ,   s  t   ,  ‚Ä¶      subscript  m  1    subscript  s  1   normal-‚Ä¶   subscript  m  t    subscript  s  t   normal-‚Ä¶    m_{1},s_{1},\ldots,m_{t},s_{t},\ldots   , defines a stream of payoffs     g  1   ,   g  2   ,  ‚Ä¶      subscript  g  1    subscript  g  2   normal-‚Ä¶    g_{1},g_{2},\ldots   , where     g  t   =   g   (   m  t   ,   s  t   )         subscript  g  t     g    subscript  m  t    subscript  s  t       g_{t}=g(m_{t},s_{t})   .  The discounted game    Œì  Œª     subscript  normal-Œì  Œª    \Gamma_{\lambda}   with discount factor   Œª   Œª   \lambda   (    0  <  Œª  ‚â§  1        0  Œª       1     0<\lambda\leq 1   ) is the game where the payoff to player   i   i   i   is    Œª    ‚àë   t  =  1   ‚àû      (   1  -  Œª   )    t  -  1     g  t  i         Œª    superscript   subscript     t  1         superscript    1  Œª     t  1     subscript   superscript  g  i   t       \lambda\sum_{t=1}^{\infty}(1-\lambda)^{t-1}g^{i}_{t}   . The   n   n   n   -stage game is the game where the payoff to player   i   i   i   is      g  ¬Ø   n  i   :=    1  n     ‚àë   t  =  1   n    g  t  i        assign   subscript   superscript   normal-¬Ø  g   i   n       1  n     superscript   subscript     t  1    n    subscript   superscript  g  i   t       \bar{g}^{i}_{n}:=\frac{1}{n}\sum_{t=1}^{n}g^{i}_{t}   .  The value     v  n    (   m  1   )        subscript  v  n    subscript  m  1     v_{n}(m_{1})   , respectively     v  Œª    (   m  1   )        subscript  v  Œª    subscript  m  1     v_{\lambda}(m_{1})   , of a two-person zero-sum stochastic game    Œì  n     subscript  normal-Œì  n    \Gamma_{n}   , respectively    Œì  Œª     subscript  normal-Œì  Œª    \Gamma_{\lambda}   , with finitely many states and actions exists, and Truman Bewley and Elon Kohlberg (1976) proved that     v  n    (   m  1   )        subscript  v  n    subscript  m  1     v_{n}(m_{1})   converges to a limit as   n   n   n   goes to infinity and that     v  Œª    (   m  1   )        subscript  v  Œª    subscript  m  1     v_{\lambda}(m_{1})   converges to the same limit as   Œª   Œª   \lambda   goes to   0   0    .  The "undiscounted" game    Œì  ‚àû     subscript  normal-Œì     \Gamma_{\infty}   is the game where the payoff to player   i   i   i   is the "limit" of the averages of the stage payoffs. Some precautions are needed in defining the value of a two-person zero-sum    Œì  ‚àû     subscript  normal-Œì     \Gamma_{\infty}   and in defining equilibrium payoffs of a non-zero-sum    Œì  ‚àû     subscript  normal-Œì     \Gamma_{\infty}   . The uniform value    v  ‚àû     subscript  v     v_{\infty}   of a two-person zero-sum stochastic game    Œì  ‚àû     subscript  normal-Œì     \Gamma_{\infty}   exists if for every    Œµ  >  0      Œµ  0    \varepsilon>0   there is a positive integer   N   N   N   and a strategy pair    œÉ  Œµ     subscript  œÉ  Œµ    \sigma_{\varepsilon}   of player 1 and    œÑ  Œµ     subscript  œÑ  Œµ    \tau_{\varepsilon}   of player 2 such that for every   œÉ   œÉ   \sigma   and   œÑ   œÑ   \tau   and every    n  ‚â•  N      n  N    n\geq N   the expectation of     g  ¬Ø   n  i     subscript   superscript   normal-¬Ø  g   i   n    \bar{g}^{i}_{n}   with respect to the probability on plays defined by    œÉ  Œµ     subscript  œÉ  Œµ    \sigma_{\varepsilon}   and   œÑ   œÑ   \tau   is at least     v  ‚àû   -  Œµ       subscript  v    Œµ    v_{\infty}-\varepsilon   , and the expectation of     g  ¬Ø   n  i     subscript   superscript   normal-¬Ø  g   i   n    \bar{g}^{i}_{n}   with respect to the probability on plays defined by   œÉ   œÉ   \sigma   and    œÑ  Œµ     subscript  œÑ  Œµ    \tau_{\varepsilon}   is at most     v  ‚àû   +  Œµ       subscript  v    Œµ    v_{\infty}+\varepsilon   . Jean-Fran√ßois Mertens and Abraham Neyman (1981) proved that every two-person zero-sum stochastic game with finitely many states and actions has a uniform value.  If there is a finite number of players and the action sets and the set of states are finite, then a stochastic game with a finite number of stages always has a Nash equilibrium . The same is true for a game with infinitely many stages if the total payoff is the discounted sum.  The non-zero-sum stochastic game    Œì  ‚àû     subscript  normal-Œì     \Gamma_{\infty}   has a uniform equilibrium payoff    v  ‚àû     subscript  v     v_{\infty}   if for every    Œµ  >  0      Œµ  0    \varepsilon>0   there is a positive integer   N   N   N   and a strategy profile   œÉ   œÉ   \sigma   such that for every unilateral deviation by a player   i   i   i   , i.e., a strategy profile   œÑ   œÑ   \tau   with     œÉ  j   =   œÑ  j        superscript  œÉ  j    superscript  œÑ  j     \sigma^{j}=\tau^{j}   for all    j  ‚â†  i      j  i    j\neq i   , and every    n  ‚â•  N      n  N    n\geq N   the expectation of     g  ¬Ø   n  i     subscript   superscript   normal-¬Ø  g   i   n    \bar{g}^{i}_{n}   with respect to the probability on plays defined by   œÉ   œÉ   \sigma   is at least     v  ‚àû  i   -  Œµ       subscript   superscript  v  i     Œµ    v^{i}_{\infty}-\varepsilon   , and the expectation of     g  ¬Ø   n  i     subscript   superscript   normal-¬Ø  g   i   n    \bar{g}^{i}_{n}   with respect to the probability on plays defined by   œÑ   œÑ   \tau   is at most     v  ‚àû  i   +  Œµ       subscript   superscript  v  i     Œµ    v^{i}_{\infty}+\varepsilon   . Nicolas Vieille has shown that all two-person stochastic games with finite state and action spaces have a uniform equilibrium payoff.  The non-zero-sum stochastic game    Œì  ‚àû     subscript  normal-Œì     \Gamma_{\infty}   has a limiting-average equilibrium payoff    v  ‚àû     subscript  v     v_{\infty}   if for every    Œµ  >  0      Œµ  0    \varepsilon>0   there is a strategy profile   œÉ   œÉ   \sigma   such that for every unilateral deviation by a player   i   i   i   , the expectation of the limit inferior of the averages of the stage payoffs with respect to the probability on plays defined by   œÉ   œÉ   \sigma   is at least     v  ‚àû  i   -  Œµ       subscript   superscript  v  i     Œµ    v^{i}_{\infty}-\varepsilon   , and the expectation of the limit superior of the averages of the stage payoffs with respect to the probability on plays defined by   œÑ   œÑ   \tau   is at most     v  ‚àû  i   +  Œµ       subscript   superscript  v  i     Œµ    v^{i}_{\infty}+\varepsilon   . Jean-Fran√ßois Mertens and Abraham Neyman (1981) proves that every two-person zero-sum stochastic game with finitely many states and actions has a limiting-average value, and Nicolas Vieille has shown that all two-person stochastic games with finite state and action spaces have a limiting-average equilibrium payoff. In particular, these results imply that these games have a value and an approximate equilibrium payoff, called the liminf-average (respectively, the limsup-average) equilibrium payoff, when the total payoff is the limit inferior (or the limit superior) of the averages of the stage payoffs.  Whether every stochastic game with finitely many players, states, and actions, has a uniform equilibrium payoff, or a limiting-average equilibrium payoff, or even a liminf-average equilibrium payoff, is a challenging open question.  A Markov perfect equilibrium is a refinement of the concept of sub-game perfect Nash equilibrium to stochastic games..  Applications  Stochastic games have applications in economics, evolutionary biology and computer networks. 1 They are generalizations of repeated games which correspond to the special case where there is only one state.  Referring book  The most complete reference is the book of articles edited by Neyman and Sorin. The more elementary book of Filar and Vrieze provides a unified rigorous treatment of the theories of Markov Decision Processes and two-person stochastic games. They coin the term Competitive MDPs to encompass both one- and two-player stochastic games.  External links   Lecture on Stochastic Two-Player Games by Antonin Kucera   Notes  Further reading           (suitable for undergraduates; main results, no proofs)   "  Category:Game theory     Constrained Stochastic Games in Wireless Networks by E.Altman, K.Avratchenkov, N.Bonneau, M.Debbah, R.El-Azouzi, D.S.Menasche ‚Ü©     