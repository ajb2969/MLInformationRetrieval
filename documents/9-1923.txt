   Filtering problem (stochastic processes)      Filtering problem (stochastic processes)  In the theory of stochastic processes , the filtering problem is a mathematical model for a number of filtering problems in signal processing and the like. The general idea is to form some kind of "best estimate" for the true value of some system, given only some (potentially noisy) observations of that system. The problem of optimal non-linear filtering (even for the non-stationary case) was solved by Ruslan L. Stratonovich (1959, 1 1960 2 ), see also Harold J. Kushner 's work 3 and Moshe Zakai 's, who introduced a simplified dynamics for the unnormalized conditional law of the filter 4 known as Zakai equation . The solution, however, is infinite-dimensional in the general case. 5 Certain approximations and special cases are well-understood: for example, the linear filters are optimal for Gaussian random variables, and are known as the Wiener filter and the Kalman-Bucy filter . More generally, as the solution is infinite dimensional, it requires finite dimensional approximations to be implemented in a computer with finite memory. A finite dimensional approximated nonlinear filter may be more based on heuristics, such as the Extended Kalman Filter or the Assumed Density Filters, 6 or more methodologically oriented such as for example the Projection Filters, 7 some sub-families of which are shown to coincide with the Assumed Density Filters. 8  In general, if the separation principle applies, then filtering also arises as part of the solution of an optimal control problem. For example, the Kalman filter is the estimation part of the optimal control solution to the Linear-quadratic-Gaussian control problem.  The mathematical formalism  Consider a probability space (Î©,Â Î£, P ) and suppose that the (random) state Y t in n - dimensional  Euclidean space  R n of a system of interest at time t is a random variable  Y t :Â Î©Â â†’ R n given by the solution to an ItÅ  stochastic differential equation of the form        d   Y  t    =    b   (  t  ,   Y  t   )   d  t   +   Ïƒ   (  t  ,   Y  t   )   d   B  t      ,        normal-d   subscript  Y  t        b   t   subscript  Y  t    normal-d  t     Ïƒ   t   subscript  Y  t    normal-d   subscript  B  t       \mathrm{d}Y_{t}=b(t,Y_{t})\,\mathrm{d}t+\sigma(t,Y_{t})\,\mathrm{d}B_{t},     where B denotes standard p -dimensional Brownian motion , b :Â [0,Â +âˆ)Â Ã— R n â†’ R n is the drift field, and Ïƒ :Â [0,Â +âˆ)Â Ã— R n â†’ R n Ã— p is the diffusion field. It is assumed that observations H t in R m (note that m and n may, in general, be unequal) are taken for each time t according to        H  t   =    c   (  t  ,   Y  t   )    +    Î³   (  t  ,   Y  t   )    â‹…  noise     .       subscript  H  t       c   t   subscript  Y  t      normal-â‹…    Î³   t   subscript  Y  t     noise      H_{t}=c(t,Y_{t})+\gamma(t,Y_{t})\cdot\mbox{noise}.     Adopting the ItÅ interpretation of the stochastic differential and setting        Z  t   =    âˆ«  0  t      H  s    d  s     ,       subscript  Z  t     superscript   subscript   0   t      subscript  H  s   normal-d  s      Z_{t}=\int_{0}^{t}H_{s}\,\mathrm{d}s,     this gives the following stochastic integral representation for the observations Z t :        d   Z  t    =    c   (  t  ,   Y  t   )   d  t   +   Î³   (  t  ,   Y  t   )   d   W  t      ,        normal-d   subscript  Z  t        c   t   subscript  Y  t    normal-d  t     Î³   t   subscript  Y  t    normal-d   subscript  W  t       \mathrm{d}Z_{t}=c(t,Y_{t})\,\mathrm{d}t+\gamma(t,Y_{t})\,\mathrm{d}W_{t},     where W denotes standard r -dimensional Brownian motion , independent of B and the initial condition X 0 , and c :Â [0,Â +âˆ)Â Ã— R n â†’ R n and Î³ :Â [0,Â +âˆ)Â Ã— R n â†’ R n Ã— r satisfy        |   c   (  t  ,  x  )    |   +   |   Î³   (  t  ,  x  )    |    â‰¤   C   (   1  +   |  x  |    )              c   t  x         Î³   t  x        C    1    x       \big|c(t,x)\big|+\big|\gamma(t,x)\big|\leq C\big(1+|x|\big)     for all t and x and some constant C .  The filtering problem is the following: given observations Z s for 0Â â‰¤ s â‰¤ t , what is the best estimate Å¶ t of the true state Y t of the system based on those observations?  By "based on those observations" it is meant that Å¶ t is measurable with respect to the Ïƒ -algebra  G t generated by the observations Z s , 0Â â‰¤ s â‰¤ t . Denote by K = K ( Z , t ) be collection of all R n -valued random variables Y that are square-integrable and G t -measurable:       K  =   K   (  Z  ,  t  )    =    L  2    (  Î©  ,   G  t   ,  ğ  ;   ğ‘  n   )     .        K    K   Z  t            superscript  L  2    normal-Î©   subscript  G  t   ğ   superscript  ğ‘  n        K=K(Z,t)=L^{2}(\Omega,G_{t},\mathbf{P};\mathbf{R}^{n}).     By "best estimate", it is meant that Å¶ t minimizes the mean-square distance between Y t and all candidates in K :      ğ„   [  |   Y  t   -    Y  ^   t    |  2   ]   =   inf   Y  âˆˆ  K    ğ„   [  |   Y  t   -   Y  ^    |  2   ]   .  (M)     fragments  E   fragments  normal-[  normal-|   subscript  Y  t     subscript   normal-^  Y   t    superscript  normal-|  2   normal-]     subscript  infimum    Y  K    E   fragments  normal-[  normal-|   subscript  Y  t     normal-^  Y    superscript  normal-|  2   normal-]   normal-.  italic-  (M)    \mathbf{E}\left[\big|Y_{t}-\hat{Y}_{t}\big|^{2}\right]=\inf_{Y\in K}\mathbf{E}%
 \left[\big|Y_{t}-\hat{Y}\big|^{2}\right].\qquad\mbox{(M)}     Basic result: orthogonal projection  The space K ( Z , t ) of candidates is a Hilbert space , and the general theory of Hilbert spaces implies that the solution Å¶ t of the minimization problem (M) is given by         Y  ^   t   =    P   K   (  Z  ,  t  )      (   X  t   )     ,       subscript   normal-^  Y   t      subscript  P    K   Z  t      subscript  X  t      \hat{Y}_{t}=P_{K(Z,t)}\big(X_{t}\big),     where P K ( Z , t ) denotes the orthogonal projection of L 2 (Î©,Â Î£, P ; R n ) onto the linear subspace  K ( Z , t )Â = L 2 (Î©, G t , P ; R n ). Furthermore, it is a general fact about conditional expectations that if F is any sub- Ïƒ -algebra of Î£ then the orthogonal projection       P  K   :     L  2    (  Î©  ,  Î£  ,  ğ  ;   ğ‘  n   )    â†’    L  2    (  Î©  ,  F  ,  ğ  ;   ğ‘  n   )        normal-:   subscript  P  K    normal-â†’     superscript  L  2    normal-Î©  normal-Î£  ğ   superscript  ğ‘  n        superscript  L  2    normal-Î©  F  ğ   superscript  ğ‘  n        P_{K}:L^{2}(\Omega,\Sigma,\mathbf{P};\mathbf{R}^{n})\to L^{2}(\Omega,F,\mathbf%
 {P};\mathbf{R}^{n})     is exactly the conditional expectation operator E [Â·| F ], i.e.,       P  K    (  X  )   =  ğ„   [  X  |  F  ]   .     fragments   subscript  P  K    fragments  normal-(  X  normal-)    E   fragments  normal-[  X  normal-|  F  normal-]   normal-.    P_{K}(X)=\mathbf{E}\big[X\big|F\big].     Hence,        Y  ^   t   =   P   K   (  Z  ,  t  )      (   X  t   )   =  ğ„   [   X  t   |   G  t   ]   .     fragments   subscript   normal-^  Y   t     subscript  P    K   Z  t      fragments  normal-(   subscript  X  t   normal-)    E   fragments  normal-[   subscript  X  t   normal-|   subscript  G  t   normal-]   normal-.    \hat{Y}_{t}=P_{K(Z,t)}\big(X_{t}\big)=\mathbf{E}\big[X_{t}\big|G_{t}\big].     This elementary result is the basis for the general Fujisaki-Kallianpur-Kunita equation of filtering theory.  References     (See Section 6.1)     "  Category:Control theory  Category:Estimation theory  Category:Signal processing  Category:Stochastic differential equations  Category:Stochastic processes     Stratonovich, R. L. (1959). Optimum nonlinear systems which bring about a separation of a signal with constant parameters from noise . Radiofizika, 2:6, pp. 892-901. â†©  Stratonovich, R.L. (1960). Application of the Markov processes theory to optimal filtering . Radio Engineering and Electronic Physics, 5:11, pp.1-19. â†©  Kushner, Harold. (1967). Nonlinear filtering: The exact dynamical equations satisfied by the conditional mode. Automatic Control, IEEE Transactions on Volume 12, Issue 3, Jun 1967 Page(s): 262 - 267 â†©  Zakai, Moshe (1969), On the optimal filtering of diffusion processes. Zeit. Wahrsch. 11 230â€“243. , , â†©  Mireille Chaleyat-Maurel and Dominique Michel. Des resultats de non existence de filtre de dimension finie. Stochastics, 13(1+2):83-102, 1984. â†©  Maybeck, Peter S., Stochastic models, estimation, and control, Volume 141, Series Mathematics in Science and Engineering, 1979, Academic Press â†©  Damiano Brigo, Bernard Hanzon and FranÃ§ois LeGland, A Differential Geometric approach to nonlinear filtering: the Projection Filter, I.E.E.E. Transactions on Automatic Control Vol. 43, 2 (1998), pp 247--252. â†©  Damiano Brigo , Bernard Hanzon and FranÃ§ois Le Gland , Approximate Nonlinear Filtering by Projection on Exponential Manifolds of Densities, Bernoulli, Vol. 5, N. 3 (1999), pp. 495--534 â†©     