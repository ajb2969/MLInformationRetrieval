   Vector logic      Vector logic   Vector logic 1 2 is an algebraic  model of elementary logic based on matrix algebra . Vector logic assumes that the truth values map on vectors , and that the monadic and dyadic operations are executed by matrix operators.  Overview  Classic binary logic is represented by a small set of mathematical functions depending on one (monadic ) or two (dyadic) variables. In the binary set, the value 1 corresponds to true and the value 0 to false . A two-valued vector logic requires a correspondence between the truth-values true (t) and false (f), and two q -dimensional normalized column vectors composed by real numbers s and n , hence:      t  ↦  s     maps-to  t  s    t\mapsto s   and    f  ↦  n     maps-to  f  n    f\mapsto n     (where    q  ≥  2      q  2    q\geq 2   is an arbitrary natural number, and “normalized” means that the length of the vector is 1; usually s and n are orthogonal vectors). This correspondence generates a space of vector truth-values: V 2 = { s , n }. The basic logical operations defined using this set of vectors lead to matrix operators.  The operations of vector logic are based on the scalar product between q -dimensional column vectors      u  T   v   =   ⟨  u  ,  v  ⟩          superscript  u  T   v    u  v     u^{T}v=\langle u,v\rangle   : the orthonormality between vectors s and n implies that     ⟨  u  ,  v  ⟩   =  1       u  v   1    \langle u,v\rangle=1   if    u  =  v      u  v    u=v   , and     ⟨  u  ,  v  ⟩   =  0       u  v   0    \langle u,v\rangle=0   if    u  ≠  v      u  v    u\neq v   .  Monadic operators  The monadic operators result from the application     M  o  n   :    V  2   →   V  2       normal-:    M  o  n    normal-→   subscript  V  2    subscript  V  2      Mon:V_{2}\to V_{2}   , and the associated matrices have q rows and q columns. The two basic monadic operators for this two-valued vector logic are the identity and the negation :   Identity : A logical identity ID(p)is represented by matrix    I  =    s   s  T    +   n   n  T         I      s   superscript  s  T      n   superscript  n  T       I=ss^{T}+nn^{T}   . This matrix operates as follows: Ip = p , p ∈ V 2 ; due to the orthogonality of s respect to n , we have     I  s   =    s   s  T   s   +   n   n  T   s    =    s   ⟨  s  ,  s  ⟩    +   n   ⟨  n  ,  s  ⟩     =  s          I  s       s   superscript  s  T   s     n   superscript  n  T   s             s   s  s      n   n  s          s     Is=ss^{T}s+nn^{T}s=s\langle s,s\rangle+n\langle n,s\rangle=s   ,   and conversely     I  n   =  n        I  n   n    In=n   .    Negation : A logical negation ¬p is represented by matrix    N  =    n   s  T    +   s   n  T         N      n   superscript  s  T      s   superscript  n  T       N=ns^{T}+sn^{T}   Consequently, Ns = n and Nn = s . The involutory behavior of the logical negation, namely that ¬(¬ p ) equals p , corresponds with the fact that N 2 = I . Is important to note that this vector logic identity matrix is not generally an identity matrix in the sense of matrix algebra.   Dyadic operators  The 16 two-valued dyadic operators correspond to functions of the type     D  y  a  d   :     V  2   ⊗   V  2    →   V  2       normal-:    D  y  a  d    normal-→   tensor-product   subscript  V  2    subscript  V  2     subscript  V  2      Dyad:V_{2}\otimes V_{2}\to V_{2}   ; the dyadic matrices have q rows and q 2 columns. The matrices that execute these dyadic operations are based on the properties of the Kronecker product .  Two properties of this product are essential for the formalism of vector logic:  Using these properties, expressions for dyadic logic functions can be obtained:   Conjunction . The conjunction (p∧q) is executed by a matrix that acts on two vector truth-values    C   (   u  ⊗  v   )       C   tensor-product  u  v     C(u\otimes v)   .This matrix reproduces the features of the classical conjunction truth-table in its formulation:         C  =    s    (   s  ⊗  s   )   T    +   n    (   s  ⊗  n   )   T    +   n    (   n  ⊗  s   )   T    +   n    (   n  ⊗  n   )   T         C      s   superscript   tensor-product  s  s   T      n   superscript   tensor-product  s  n   T      n   superscript   tensor-product  n  s   T      n   superscript   tensor-product  n  n   T       C=s(s\otimes s)^{T}+n(s\otimes n)^{T}+n(n\otimes s)^{T}+n(n\otimes n)^{T}          and verifies             C   (   s  ⊗  s   )    =  s   ,        C   tensor-product  s  s    s    C(s\otimes s)=s,   and             C   (   s  ⊗  n   )    =   C   (   n  ⊗  s   )    =   C   (   n  ⊗  n   )    =  n   .          C   tensor-product  s  n      C   tensor-product  n  s           C   tensor-product  n  n         n     C(s\otimes n)=C(n\otimes s)=C(n\otimes n)=n.         Disjunction . The disjunction (p∨q) is executed by the matrix          D  =    s    (   s  ⊗  s   )   T    +   s    (   s  ⊗  n   )   T    +   s    (   n  ⊗  s   )   T    +   n    (   n  ⊗  n   )   T      ,      D      s   superscript   tensor-product  s  s   T      s   superscript   tensor-product  s  n   T      s   superscript   tensor-product  n  s   T      n   superscript   tensor-product  n  n   T       D=s(s\otimes s)^{T}+s(s\otimes n)^{T}+s(n\otimes s)^{T}+n(n\otimes n)^{T},   resulting in       D   (   s  ⊗  s   )    =   D   (   s  ⊗  n   )    =   D   (   n  ⊗  s   )    =  s          D   tensor-product  s  s      D   tensor-product  s  n           D   tensor-product  n  s         s     D(s\otimes s)=D(s\otimes n)=D(n\otimes s)=s   and        D   (   n  ⊗  n   )    =  n   .        D   tensor-product  n  n    n    D(n\otimes n)=n.         Implication . The implication corresponds in classical logic to the expression p → q ≡ ¬p ∨ q. The vector logic version of this equivalence leads to a matrix that represents this implication in vector logic    L  =   D   (   N  ⊗  I   )        L    D   tensor-product  N  I      L=D(N\otimes I)   . The explicit expression for this implication is:          L  =    s    (   s  ⊗  s   )   T    +   n    (   s  ⊗  n   )   T    +   s    (   n  ⊗  s   )   T    +   n    (   n  ⊗  n   )   T      ,      L      s   superscript   tensor-product  s  s   T      n   superscript   tensor-product  s  n   T      s   superscript   tensor-product  n  s   T      n   superscript   tensor-product  n  n   T       L=s(s\otimes s)^{T}+n(s\otimes n)^{T}+s(n\otimes s)^{T}+n(n\otimes n)^{T},          and the properties of classical implication are satisfied:       L   (   s  ⊗  s   )    =   L   (   n  ⊗  s   )    =   L   (   n  ⊗  n   )    =  s          L   tensor-product  s  s      L   tensor-product  n  s           L   tensor-product  n  n         s     L(s\otimes s)=L(n\otimes s)=L(n\otimes n)=s   and        L   (   s  ⊗  n   )    =  n   .        L   tensor-product  s  n    n    L(s\otimes n)=n.         Equivalence and Exclusive or . In vector logic the equivalence p≡q is represented by the following matrix:         E  =    s    (   s  ⊗  s   )   T    +   n    (   s  ⊗  n   )   T    +   n    (   n  ⊗  s   )   T    +   s    (   n  ⊗  n   )   T         E      s   superscript   tensor-product  s  s   T      n   superscript   tensor-product  s  n   T      n   superscript   tensor-product  n  s   T      s   superscript   tensor-product  n  n   T       E=s(s\otimes s)^{T}+n(s\otimes n)^{T}+n(n\otimes s)^{T}+s(n\otimes n)^{T}   with            E   (   s  ⊗  s   )    =   E   (   n  ⊗  n   )    =  s          E   tensor-product  s  s      E   tensor-product  n  n         s     E(s\otimes s)=E(n\otimes n)=s   and             E   (   s  ⊗  n   )    =   E   (   n  ⊗  s   )    =  n   .          E   tensor-product  s  n      E   tensor-product  n  s         n     E(s\otimes n)=E(n\otimes s)=n.          The Exclusive or is the negation of the equivalence, ¬(p≡q); it corresponds with the matrix    X  =   N  E       X    N  E     X=NE   given by            X  =    n    (   s  ⊗  s   )   T    +   s    (   s  ⊗  n   )   T    +   s    (   n  ⊗  s   )   T    +   n    (   n  ⊗  n   )   T      ,      X      n   superscript   tensor-product  s  s   T      s   superscript   tensor-product  s  n   T      s   superscript   tensor-product  n  s   T      n   superscript   tensor-product  n  n   T       X=n(s\otimes s)^{T}+s(s\otimes n)^{T}+s(n\otimes s)^{T}+n(n\otimes n)^{T},          with     X   (   s  ⊗  s   )    =   X   (   n  ⊗  n   )    =  n          X   tensor-product  s  s      X   tensor-product  n  n         n     X(s\otimes s)=X(n\otimes n)=n   and             X   (   s  ⊗  n   )    =   X   (   n  ⊗  s   )    =  s   .          X   tensor-product  s  n      X   tensor-product  n  s         s     X(s\otimes n)=X(n\otimes s)=s.         NAND and NOR   The matrices S and P correspond to the Sheffer (NAND) and the Peirce (NOR) operations, respectively:        S  =   N  C       S    N  C     S=NC         P  =   N  D       P    N  D     P=ND        De Morgan's law  In the two-valued logic, the conjunction and the disjunction operations satisfy the De Morgan's law : p∧q≡¬(¬p∨¬q), and its dual: p∨q≡¬(¬p∧¬q)). For the two-valued vector logic this Law is also verified:         C   (   u  ⊗  v   )    =   N  D   (     N  u   ⊗  N   v   )          C   tensor-product  u  v      N  D     tensor-product    N  u   N   v      C(u\otimes v)=ND(Nu\otimes Nv)   , where u and v are two logic vectors.     The Kronecker product implies the following factorization:          C   (   u  ⊗  v   )    =   N  D   (   N  ⊗  N   )    (   u  ⊗  v   )     .        C   tensor-product  u  v      N  D   tensor-product  N  N    tensor-product  u  v      C(u\otimes v)=ND(N\otimes N)(u\otimes v).        Then it can be proved that in the two–dimensional vector logic the De Morgan's law is a law involving operators, and not only a law concerning operations: 3        C  =   N  D   (   N  ⊗  N   )        C    N  D   tensor-product  N  N      C=ND(N\otimes N)        Law of contraposition  In the classical propositional calculus, the Law of Contraposition  p → q ≡ ¬ q → ¬ p is proved because the equivalence holds for all the possible combinations of truth-values of p and q . 4 Instead, in vector logic, the law of contraposition emerges from a chain of equalities within the rules of matrix algebra and Kronecker products, as shown in what follows:         L   (   u  ⊗  v   )    =   D   (   N  ⊗  I   )    (   u  ⊗  v   )    =   D   (    N  u   ⊗  v   )    =   D   (     N  u   ⊗  N   N  v   )    =           L   tensor-product  u  v      D   tensor-product  N  I    tensor-product  u  v           D   tensor-product    N  u   v           D     tensor-product    N  u   N   N  v         absent     L(u\otimes v)=D(N\otimes I)(u\otimes v)=D(Nu\otimes v)=D(Nu\otimes NNv)=          D   (     N  N  v   ⊗  N   u   )    =   D   (   N  ⊗  I   )    (     N  v   ⊗  N   u   )    =   L   (     N  v   ⊗  N   u   )            D     tensor-product    N  N  v   N   u      D   tensor-product  N  I      tensor-product    N  v   N   u           L     tensor-product    N  v   N   u       D(NNv\otimes Nu)=D(N\otimes I)(Nv\otimes Nu)=L(Nv\otimes Nu)        This result is based in the fact that D , the disjunction matrix, represents a commutative operation.  Many-valued two-dimensional logic  Many-valued logic was developed by many researchers, particularly by Jan Łukasiewicz and allows extending logical operations to truth-values that include uncertainties. 5 In the case of two-valued vector logic, uncertainties in the truth values can be introduced using vectors with s and n weighted by probabilities.  Let    f  =    ϵ  s   +   δ  n        f      ϵ  s     δ  n      f=\epsilon s+\delta n   , with      ϵ  ,  δ   ∈   [  0  ,  1  ]    ,    ϵ  +  δ   =  1      formulae-sequence     ϵ  δ    0  1        ϵ  δ   1     \epsilon,\delta\in[0,1],\epsilon+\delta=1   be this kind of “probabilistic” vectors. Here, the many-valued character of the logic is introduced a posteriori via the uncertainties introduced in the inputs. 6  Scalar projections of vector outputs  The outputs of this many-valued logic can be projected on scalar functions and generate a particular class of probabilistic logic with similarities with the many-valued logic of Reichenbach. 7 8 9 Given two vectors    u  =    α  s   +   β  n        u      α  s     β  n      u=\alpha s+\beta n   and    v  =     α  ′   s   +    β  ′   n        v       superscript  α  normal-′   s      superscript  β  normal-′   n      v=\alpha^{\prime}s+\beta^{\prime}n   and a dyadic logical matrix   G   G   G   , a scalar probabilistic logic is provided by the projection over vector s :         V  a  l   (  scalars  )    =    s  T   G   (  vectors  )          V  a  l  scalars      superscript  s  T   G  vectors     Val(\mathrm{scalars})=s^{T}G(\mathrm{vectors})        Here are the main results of these projections:         N  O  T   (  α  )    =    s  T   N  u   =   1  -  α           N  O  T  α      superscript  s  T   N  u          1  α      NOT(\alpha)=s^{T}Nu=1-\alpha          O  R   (  α  ,   α  ′   )    =    s  T   D   (   u  ⊗  v   )    =    α  +   α  ′    -   α   α  ′             O  R   α   superscript  α  normal-′        superscript  s  T   D   tensor-product  u  v             α   superscript  α  normal-′      α   superscript  α  normal-′        OR(\alpha,\alpha^{\prime})=s^{T}D(u\otimes v)=\alpha+\alpha^{\prime}-\alpha%
 \alpha^{\prime}          A  N  D   (  α  ,   α  ′   )    =    s  T   C   (   u  ⊗  v   )    =   α   α  ′            A  N  D   α   superscript  α  normal-′        superscript  s  T   C   tensor-product  u  v           α   superscript  α  normal-′       AND(\alpha,\alpha^{\prime})=s^{T}C(u\otimes v)=\alpha\alpha^{\prime}          I  M  P  L   (  α  ,   α  ′   )    =    s  T   L   (   u  ⊗  v   )    =   1  -   α   (   1  -   α  ′    )             I  M  P  L   α   superscript  α  normal-′        superscript  s  T   L   tensor-product  u  v           1    α    1   superscript  α  normal-′         IMPL(\alpha,\alpha^{\prime})=s^{T}L(u\otimes v)=1-\alpha(1-\alpha^{\prime})          X  O  R   (  α  ,   α  ′   )    =    s  T   X   (   u  ⊗  v   )    =    α  +   α  ′    -   2  α   α  ′             X  O  R   α   superscript  α  normal-′        superscript  s  T   X   tensor-product  u  v             α   superscript  α  normal-′      2  α   superscript  α  normal-′        XOR(\alpha,\alpha^{\prime})=s^{T}X(u\otimes v)=\alpha+\alpha^{\prime}-2\alpha%
 \alpha^{\prime}        The associated negations are:         N  O  R   (  α  ,   α  ′   )    =   1  -   O  R   (  α  ,   α  ′   )           N  O  R   α   superscript  α  normal-′       1    O  R   α   superscript  α  normal-′        NOR(\alpha,\alpha^{\prime})=1-OR(\alpha,\alpha^{\prime})          N  A  N  D   (  α  ,   α  ′   )    =   1  -   A  N  D   (  α  ,   α  ′   )           N  A  N  D   α   superscript  α  normal-′       1    A  N  D   α   superscript  α  normal-′        NAND(\alpha,\alpha^{\prime})=1-AND(\alpha,\alpha^{\prime})          E  Q  U  I   (  α  ,   α  ′   )    =   1  -   X  O  R   (  α  ,   α  ′   )           E  Q  U  I   α   superscript  α  normal-′       1    X  O  R   α   superscript  α  normal-′        EQUI(\alpha,\alpha^{\prime})=1-XOR(\alpha,\alpha^{\prime})        If the scalar values belong to the set {0, ½, 1}, this many-valued scalar logic is for many of the operators almost identical to the 3-valued logic of Łukasiewicz. Also, it has been proved that when the monadic or dyadic operators act over probabilistic vectors belonging to this set, the output is also an element of this set. 10  History  The approach has been inspired in neural network models based on the use of high-dimensional matrices and vectors. 11 12 Vector logic is a direct translation into a matrix-vector formalism of the classical Boolean polynomials . 13 This kind of formalism has been applied to develop a fuzzy logic in terms of complex numbers . 14 Other matrix and vector approaches to logical calculus have been developed in the framework of quantum physics , computer science and optics . 15 16 17 Early attempts to use linear algebra to represent logic operations can be referred to Peirce and Copilowish . 18 The Indian biophysicist G.N. Ramachandran developed a formalism using algebraic matrices and vectors to represent many operations of classical Jain Logic known as Syad and Saptbhangi. Indian logic . 19 It requires independent affirmative evidence for each assertion in a proposition, and does not make the assumption for binary complementation.  Boolean polynomials  George Boole established the development of logical operations as polynomials. 20 For the case of monadic operators (such as identity or negation ), the Boolean polynomials look as follows:         f   (  x  )    =    f   (  1  )   x   +   f   (  0  )    (   1  -  x   )           f  x       f  1  x     f  0    1  x       f(x)=f(1)x+f(0)(1-x)        The four different monadic operations result from the different binary values for the coefficients. Identity operation requires f (1) = 1 and f (0) = 0, and negation occurs if f (1) = 0 and f (0) = 1. For the 16 dyadic operators, the Boolean polynomials are of the form:         f   (  x  ,  y  )    =    f   (  1  ,  1  )   x  y   +   f   (  1  ,  0  )   x   (   1  -  y   )    +   f   (  0  ,  1  )    (   1  -  x   )   y   +   f   (  0  ,  0  )    (   1  -  x   )    (   1  -  y   )           f   x  y        f   1  1   x  y     f   1  0   x    1  y      f   0  1     1  x   y     f   0  0     1  x     1  y       f(x,y)=f(1,1)xy+f(1,0)x(1-y)+f(0,1)(1-x)y+f(0,0)(1-x)(1-y)        The dyadic operations can be translated to this polynomial format when the coefficients f take the values indicated in the respective truth tables . For instance: the NAND operation requires that:         f   (  1  ,  1  )    =  0        f   1  1    0    f(1,1)=0   and     f   (  1  ,  0  )    =   f   (  0  ,  1  )    =   f   (  0  ,  0  )    =  1          f   1  0      f   0  1           f   0  0         1     f(1,0)=f(0,1)=f(0,0)=1   .     These Boolean polynomials can be immediately extended to any number of variables, producing a large potential variety of logical operators. In vector logic, the matrix-vector structure of logical operators is an exact translation to the format of liner algebra of these Boolean polynomials, where the x and 1-x correspond to vectors s and n respectively (the same for y and 1-y ). In the example of NAND, f(1,1)=n and f(1,0)=f(0,1)=f(0,0)=s and the matrix version becomes:        S  =    n    (   s  ⊗  s   )   T    +   s   [     (   s  ⊗  n   )   T   +    (   n  ⊗  s   )   T   +    (   n  ⊗  n   )   T    ]         S      n   superscript   tensor-product  s  s   T      s   delimited-[]     superscript   tensor-product  s  n   T    superscript   tensor-product  n  s   T    superscript   tensor-product  n  n   T         S=n(s\otimes s)^{T}+s[(s\otimes n)^{T}+(n\otimes s)^{T}+(n\otimes n)^{T}]        Extensions   Vector logic can be extended to include many truth values since large dimensional vector spaces allow to create many orthogonal truth values and the corresponding logical matrices. 21  Logical modalities can be fully represented in this context, with recursive process inspired in neural models 22 23  Some cognitive problems about logical computations can be analyzed using this formalism, in particular recursive decisions. Any logical expression of classical propositional calculus can be naturally represented by a tree structure . 24 This fact is retained by vector logic, and has been partially used in neural models focused in the investigation of the branched structure of natural languages. 25 26 27 28 beim Graben, P., Gerth, S. (2012) Geometric representations for minimalist grammars. Journal of Logic, Language and Information, 21, 393-432 .   29   The computation via reversible operations as the Fredkin gate can be implemented in vector logic. This implementations provides explicit expressions for matrix operators that produce the input format and the output filtering necessary for obtaining computations 30 31  Elementary cellular automata can be analyzed using the operator structure of vector logic; this analysis leads to a spectral decomposition of the laws governing the its dynamics 32 33   See also   Fuzzy logic  Quantum logic  Boolean algebra  Propositional calculus  George Boole  Jan Łukasiewicz   References  "  Category:Logic  Category:Boolean algebra     Mizraji, E. (1992). Vector logics: the matrix-vector representation of logical calculus. Fuzzy Sets and Systems, 50, 179–185, 1992 ↩  Mizraji, E. (2008) Vector logic: a natural algebraic representation of the fundamental logical gates. Journal of Logic and Computation, 18, 97–121, 2008 ↩  Mizraji, E. (1996) The operators of vector logic. Mathematical Logic Quarterly, 42, 27–39 ↩  Suppes, P. (1957) Introduction to Logic, Van Nostrand Reinhold, New York. ↩  Łukasiewicz, J. (1980) Selected Works. L. Borkowski, ed., pp. 153–178. North-Holland, Amsterdam, 1980 ↩   Rescher, N. (1969) Many-Valued Logic. McGraw–Hill, New York ↩  Blanché, R. (1968) Introduction à la Logique Contemporaine, Armand Colin, Paris ↩  Klir, G.J., Yuan, G. (1995) Fuzzy Sets and Fuzzy Logic. Prentice–Hall, New Jersey ↩   Kohonen, T. (1977) Associative Memory: A System-Theoretical Approach. Springer-Verlag, New York ↩  Mizraji, E. (1989) Context-dependent associations in linear distributed memories . Bulletin of Mathematical Biology, 50, 195–205 ↩  Boole, G. (1854) An Investigation of the Laws of Thought, on which are Founded the Theories of Logic and Probabilities. Macmillan, London, 1854; Dover, New York Reedition, 1958 ↩  Dick, S. (2005) Towards complex fuzzy logic. IEEE Transactions on Fuzzy Systems, 15,405–414, 2005 ↩  Mittelstaedt, P. (1968) Philosophische Probleme der Modernen Physik, Bibliographisches Institut, Mannheim ↩  Stern, A. (1988) Matrix Logic: Theory and Applications. North-Holland, Amsterdam ↩  Westphal, J., Hardy, J. (2005) Logic as a vector system. Journal of Logic and Computation, 15, 751–765 ↩  Copilowish, I.M. (1948) Matrix development of the calculus of relations. Journal of Symbolic Logic, 13, 193–203 ↩  Jain, M.K. (2011) Logic of evidence-based inference propositions, Current Science, 1663–1672, 100 ↩     Mizraji, E. (1994) [ http://projecteuclid.org/DPubS?verb=Display&version; ;=1.0&service;=UI&handle;=euclid.ndjfl/1094061864&page;=record Modalities in vector logic]. Notre Dame Journal of Formal Logic, 35, 272–283 ↩   Mizraji, E., Lin, J. (2002) The dynamics of logical decisions. Physica D, 168–169, 386–396 ↩  beim Graben, P., Potthast, R. (2009). Inverse problems in dynamic cognitive modeling. Chaos, 19, 015103 ↩  beim Graben, P., Pinotsis, D., Saddy, D., Potthast, R. (2008). Language processing with dynamic ﬁelds. Cogn. Neurodyn., 2, 79–88 ↩  beim Graben, P., Gerth, S., Vasishth, S.(2008) Towards dynamical system models of language-related brain potentials. Cogn. Neurodyn., 2, 229–255 ↩  Binazzi, A.(2012) Cognizione logica e modelli mentali. Studi sulla formazione, 1–2012, pag. 69–84 ↩    Mizraji, E. (2006) The parts and the whole: inquiring how the interaction of simple subsystems generates complexity. International Journal of General Systems, 35, pp. 395–415. ↩  Arruti, C., Mizraji, E. (2006) Hidden potentialities. International Journal of General Systems, 35, 461–469. ↩     