   Sobel operator      Sobel operator     The Sobel operator , sometimes called Sobel Filter, is used in image processing and computer vision , particularly within edge detection algorithms, and creates an image which emphasizes edges and transitions. It is named after Irwin Sobel , who presented the idea of an "Isotropic 3x3 Image Gradient Operator" at a talk at the Stanford Artificial Intelligence Laboratory (SAIL) in 1968. It should properly be called the Sobel-Feldman operator since it was co-developed with Gary Feldman, a colleague at SAIL. 1 Technically, it is a discrete differentiation operator , computing an approximation of the gradient of the image intensity function. At each point in the image, the result of the Sobel operator is either the corresponding gradient vector or the norm of this vector. The Sobel operator is based on convolving the image with a small, separable, and integer valued filter in horizontal and vertical direction and is therefore relatively inexpensive in terms of computations. On the other hand, the gradient approximation that it produces is relatively crude, in particular for high frequency variations in the image.  Formulation  The operator uses two 3×3 kernels which are convolved with the original image to calculate approximations of the derivatives - one for horizontal changes, and one for vertical. If we define A as the source image, and G x and G y are two images which at each point contain the horizontal and vertical derivative approximations, the computations are as follows: 2        𝐆  x   =     [      -  1     0     +  1        -  2     0     +  2        -  1     0     +  1      ]   *  𝐀   and      𝐆  y   =    [      -  1      -  2      -  1       0    0    0       +  1      +  2      +  1      ]   *  𝐀       formulae-sequence     subscript  𝐆  x          1   0    1       2   0    2       1   0    1     𝐀   and       subscript  𝐆  y         1     2     1     0  0  0      1     2     1     𝐀      \mathbf{G}_{x}=\begin{bmatrix}-1&0&+1\\
 -2&0&+2\\
 -1&0&+1\end{bmatrix}*\mathbf{A}\quad\mbox{and}\quad\mathbf{G}_{y}=\begin{%
 bmatrix}-1&-2&-1\\
 0&0&0\\
 +1&+2&+1\end{bmatrix}*\mathbf{A}     where   *     *   here denotes the 2-dimensional convolution operation.  Since the Sobel kernels can be decomposed as the products of an averaging and a differentiation kernel, they compute the gradient with smoothing. For example,    𝐆  𝐱     subscript  𝐆  𝐱    \mathbf{G_{x}}   can be written as       [      -  1     0     +  1        -  2     0     +  2        -  1     0     +  1      ]   =    [     1      2      1     ]    [      -  1     0     +  1      ]            1   0    1       2   0    2       1   0    1         1    2    1        1   0    1        \begin{bmatrix}-1&0&+1\\
 -2&0&+2\\
 -1&0&+1\end{bmatrix}=\begin{bmatrix}1\\
 2\\
 1\end{bmatrix}\begin{bmatrix}-1&0&+1\end{bmatrix}     The x -coordinate is defined here as increasing in the "right"-direction, and the y -coordinate is defined as increasing in the "down"-direction. At each point in the image, the resulting gradient approximations can be combined to give the gradient magnitude, using:      𝐆  =     𝐆  x    2   +   𝐆  y    2         𝐆       superscript   subscript  𝐆  x   2    superscript   subscript  𝐆  y   2       \mathbf{G}=\sqrt{{\mathbf{G}_{x}}^{2}+{\mathbf{G}_{y}}^{2}}     Using this information, we can also calculate the gradient's direction:      𝚯  =   atan2   (   𝐆  y   ,   𝐆  x   )        𝚯   atan2   subscript  𝐆  y    subscript  𝐆  x      \mathbf{\Theta}=\operatorname{atan2}\left({\mathbf{G}_{y},\mathbf{G}_{x}}\right)   where, for example, Θ is 0 for a vertical edge which is lighter on the right side.  More formally  Since the intensity function of a digital image is only known at discrete points, derivatives of this function cannot be defined unless we assume that there is an underlying continuous intensity function which has been sampled at the image points. With some additional assumptions, the derivative of the continuous intensity function can be computed as a function on the sampled intensity function, i.e. the digital image. It turns out that the derivatives at any particular point are functions of the intensity values at virtually all image points. However, approximations of these derivative functions can be defined at lesser or larger degrees of accuracy.  The Sobel operator represents a rather inaccurate approximation of the image gradient, but is still of sufficient quality to be of practical use in many applications. More precisely, it uses intensity values only in a 3×3 region around each image point to approximate the corresponding image gradient, and it uses only integer values for the coefficients which weight the image intensities to produce the gradient approximation.  Extension to other dimensions  The Sobel operator consists of two separable operations: 3   Smoothing perpendicular to the derivative direction with a triangle filter      h   (   -  1   )    =  1   ,     h   (  0  )    =  2   ,    h   (  1  )    =  1       formulae-sequence      h    1    1    formulae-sequence      h  0   2       h  1   1      h(-1)=1,h(0)=2,h(1)=1     Simple central difference in the derivative direction       h  ′    (   -  1   )    =  1   ,      h  ′    (  0  )    =  0   ,     h  ′    (  1  )    =   -  1        formulae-sequence       superscript  h  normal-′     1    1    formulae-sequence       superscript  h  normal-′   0   0        superscript  h  normal-′   1     1       h^{\prime}(-1)=1,h^{\prime}(0)=0,h^{\prime}(1)=-1      Sobel filters for image derivatives in different dimensions with     x  ,  y  ,  z  ,  t   ∈   {  0  ,   -  1   ,  1  }        x  y  z  t    0    1   1     x,y,z,t\in\left\{0,-1,1\right\}   :  1D       h  x  ′    (  x  )    =    h  ′    (  x  )     ;         superscript   subscript  h  x   normal-′   x      superscript  h  normal-′   x     h_{x}^{\prime}(x)=h^{\prime}(x);     2D      h  x  ′    (  x  ,  y  )    =    h  ′    (  x  )   h   (  y  )           superscript   subscript  h  x   normal-′    x  y       superscript  h  normal-′   x  h  y     h_{x}^{\prime}(x,y)=h^{\prime}(x)h(y)     3D      h  x  ′    (  x  ,  y  ,  z  )    =    h  ′    (  x  )   h   (  y  )   h   (  z  )           superscript   subscript  h  x   normal-′    x  y  z       superscript  h  normal-′   x  h  y  h  z     h_{x}^{\prime}(x,y,z)=h^{\prime}(x)h(y)h(z)     4D      h  x  ′    (  x  ,  y  ,  z  ,  t  )    =    h  ′    (  x  )   h   (  y  )   h   (  z  )   h   (  t  )           superscript   subscript  h  x   normal-′    x  y  z  t       superscript  h  normal-′   x  h  y  h  z  h  t     h_{x}^{\prime}(x,y,z,t)=h^{\prime}(x)h(y)h(z)h(t)     Thus as an example the 3D Sobel kernel in z-direction:         h  z  ′    (  :  ,  :  ,   -  1   )    =   [      +  1      +  2      +  1        +  2      +  4      +  2        +  1      +  2      +  1      ]        h  z  ′    (  :  ,  :  ,  0  )    =   [     0    0    0      0    0    0      0    0    0     ]       h  z  ′    (  :  ,  :  ,  1  )    =   [      -  1      -  2      -  1        -  2      -  4      -  2        -  1      -  2      -  1      ]        formulae-sequence       superscript   subscript  h  z   normal-′    normal-:  normal-:    1         1     2     1       2     4     2       1     2     1       formulae-sequence       superscript   subscript  h  z   normal-′    normal-:  normal-:  0      0  0  0    0  0  0    0  0  0          superscript   subscript  h  z   normal-′    normal-:  normal-:  1        1     2     1       2     4     2       1     2     1         h_{z}^{\prime}(:,:,-1)=\begin{bmatrix}+1&+2&+1\\
 +2&+4&+2\\
 +1&+2&+1\end{bmatrix}\quad h_{z}^{\prime}(:,:,0)=\begin{bmatrix}0&0&0\\
 0&0&0\\
 0&0&0\end{bmatrix}\quad h_{z}^{\prime}(:,:,1)=\begin{bmatrix}-1&-2&-1\\
 -2&-4&-2\\
 -1&-2&-1\end{bmatrix}     Technical details  As a consequence of its definition, the Sobel operator can be implemented by simple means in both hardware and software: only eight image points around a point are needed to compute the corresponding result and only integer arithmetic is needed to compute the gradient vector approximation. Furthermore, the two discrete filters described above are both separable:       [     1    0     -  1       2    0     -  2       1    0     -  1      ]   =    [     1      2      1     ]    [     1    0     -  1      ]    =      [     1      1     ]   *   [     1      1     ]     [     1     -  1      ]    *   [     1    1     ]            1  0    1     2  0    2     1  0    1         1    2    1      1  0    1                   1    1      1    1       1    1        1  1        \begin{bmatrix}1&0&-1\\
 2&0&-2\\
 1&0&-1\end{bmatrix}=\begin{bmatrix}1\\
 2\\
 1\end{bmatrix}\begin{bmatrix}1&0&-1\end{bmatrix}=\begin{bmatrix}1\\
 1\end{bmatrix}*\begin{bmatrix}1\\
 1\end{bmatrix}\begin{bmatrix}1&-1\end{bmatrix}*\begin{bmatrix}1&1\end{bmatrix}          [     1    2    1      0    0    0       -  1      -  2      -  1      ]   =    [     1      0       -  1      ]    [     1    2    1     ]    =      [     1      1     ]   *   [     1       -  1      ]     [     1    1     ]    *   [     1    1     ]            1  2  1    0  0  0      1     2     1         1    0      1       1  2  1                  1    1      1      1        1  1       1  1        \begin{bmatrix}\ \ 1&\ \ 2&\ \ 1\\
 \ \ 0&\ \ 0&\ \ 0\\
 -1&-2&-1\end{bmatrix}=\begin{bmatrix}\ \ 1\\
 \ \ 0\\
 -1\end{bmatrix}\begin{bmatrix}1&2&1\end{bmatrix}=\begin{bmatrix}1\\
 1\end{bmatrix}*\begin{bmatrix}\ \ 1\\
 -1\end{bmatrix}\begin{bmatrix}1&1\end{bmatrix}*\begin{bmatrix}1&1\end{bmatrix}     and the two derivatives G x and G y can therefore be computed as        𝐆  x   =     [     1      2      1     ]   *   (    [     1    0     -  1      ]   *  𝐀   )    and      𝐆  y   =    [     1      0       -  1      ]   *   (    [     1    2    1     ]   *  𝐀   )        formulae-sequence     subscript  𝐆  x        1    2    1        1  0    1     𝐀    and       subscript  𝐆  y       1    0      1         1  2  1    𝐀       \mathbf{G}_{x}=\begin{bmatrix}1\\
 2\\
 1\end{bmatrix}*\left(\begin{bmatrix}1&0&-1\end{bmatrix}*\mathbf{A}\right)\quad%
 \mbox{and}\quad\mathbf{G}_{y}=\begin{bmatrix}\ \ 1\\
 \ \ 0\\
 -1\end{bmatrix}*\left(\begin{bmatrix}1&2&1\end{bmatrix}*\mathbf{A}\right)     In certain implementations, this separable computation may be advantageous since it implies fewer arithmetic computations for each image point.  Applying convolution K to pixel group P can be represented in pseudocode as:  N(x,y) = Sum of { K(i,j).P(x-i,y-j)}, for i,j running from -1 to 1. N(x,y) represents the new matrix resulted after applying the Convolution K to P. where P is pixel matrix.  Example  The result of the Sobel operator is a 2-dimensional map of the gradient at each point. It can be processed and viewed as though it is itself an image, with the areas of high gradient (the likely edges) visible as white lines. The following images illustrates this, by showing the computation of the Sobel operator on a simple image.     (Figure)  Grayscale test image of brick wall and bike rack   (Figure)  Normalized gradient magnitude from Sobel operator     (Figure)  Normalized x-gradient from Sobel operator   (Figure)  Normalized y-gradient from Sobel operator      Alternative operators  The Sobel operator, while reducing artifacts associated with a pure central differences operator, does not have perfect rotational symmetry. Scharr looked into optimizing this property. 4 5 Filter kernels up to size 5 x 5 have been presented there, but the most frequently used one is:       [      +  3      +  10      +  3       0    0    0       -  3      -  10      -  3      ]    [      +  3     0     -  3        +  10     0     -  10        +  3     0     -  3      ]          3     10     3     0  0  0      3     10     3         3   0    3       10   0    10       3   0    3       \begin{bmatrix}+3&+10&+3\\
 0&0&0\\
 -3&-10&-3\end{bmatrix}\ \ \ \ \ \ \ \ \ \begin{bmatrix}+3&0&-3\\
 +10&0&-10\\
 +3&0&-3\end{bmatrix}     This factors similarly:       [     3    10    3     ]   =    [     1    3     ]   *   [     3    1     ]          3  10  3        1  3      3  1       \begin{bmatrix}3&10&3\end{bmatrix}=\begin{bmatrix}1&3\end{bmatrix}*\begin{%
 bmatrix}3&1\end{bmatrix}     Scharr operators result from an optimization minimizing weighted mean squared angular error in Fourier domain. This optimization is done under the condition that resulting filters are numerically consistent. Therefore they really are derivative kernels rather than merely keeping symmetry constraints.  A similar optimization strategy and resulting filters were also presented by Farid and Simoncelli. 6 7 They also investigate higher-order derivative schemes. In contrast to the work of Scharr, these filters are not enforced to be numerically consistent.  The problem of derivative filter design has been revisited e.g. by Kroon. 8  Derivative filters based on arbitrary cubic splines was presented by Hast. 9 He showed how first and second order derivatives can be computed correctly using cubic or trigonometric splines by a double filtering approach giving filters of length 7.  Orientation-optimal derivative kernels drastically reduce systematic estimation errors in optical flow estimation. Larger schemes with even higher accuracy and optimized filter families for extended optical flow estimation have been presented in subsequent work by Scharr. 10 Second order derivative filter sets have been investigated for transparent motion estimation. 11 It has been observed that the larger the resulting kernels are, the better they approximate Derivative of Gaussian filters.  Example comparisons  Here, four different gradient operators are used to estimate the magnitude of the gradient of the test image.     (Figure)  Grayscale test image of brick wall and bike rack   (Figure)  Gradient magnitude from Sobel operator   (Figure)  Gradient magnitude from Scharr operator     (Figure)  Gradient magnitude from Roberts Cross operator   (Figure)  Gradient magnitude from Prewitt operator      See also   Digital image processing  Computer vision  Edge detection  Feature detection (computer vision)  Feature extraction  Image gradient  Roberts cross  Prewitt operator  Laplace operator   References    External links   Sobel edge detection in Opencv  Sobel Filter , in the SciPy Python Library  Bibliographic citations for Irwin Sobel in DBLP  Sobel and Scharr 5x5 gradients  Sobel edge detection example using computer algorithms   "  Category:Feature detection (computer vision)     Irwin Sobel, 2014, History and Definition of the Sobel Operator ↩  Feature Detectors - Sobel Edge Detector ↩  ↩  Scharr, Hanno, 2000, Dissertation (in German), Optimal Operators in Digital Image Processing . ↩  B. Jähne, H. Scharr, and S. Körkel. Principles of filter design. In Handbook of Computer Vision and Applications. Academic Press, 1999. ↩  H. Farid and E. P. Simoncelli, Optimally Rotation-Equivariant Directional Derivative Kernels , Int'l Conf Computer Analysis of Images and Patterns, pp. 207--214, Sep 1997. ↩  H. Farid and E. P. Simoncelli, Differentiation of discrete multi-dimensional signals , IEEE Trans Image Processing, vol.13(4), pp. 496--508, Apr 2004. ↩  D. Kroon, 2009, Short Paper University Twente, Numerical Optimization of Kernel Based Image Derivatives . ↩  A. Hast., "Simple filter design for first and second order derivatives by a double filtering approach" , Pattern Recognition Letters, Vol. 42, no.1 June, pp. 65--71. 2014. ↩  Scharr, Hanno, ''Optimal Filters for Extended Optical Flow '' In: Jähne, B., Mester, R., Barth, E., Scharr, H. (eds.) IWCM 2004. LNCS, vol. 3417, pp. 14–29. Springer, Heidelberg (2007). ↩  Scharr, Hanno, OPTIMAL SECOND ORDER DERIVATIVE FILTER FAMILIES FOR TRANSPARENT MOTION ESTIMATION 15th European Signal Processing Conference (EUSIPCO 2007), Poznan, Poland, September 3–7, 2007. ↩     