


Hadamard's inequality




Hadamard's inequality

In mathematics, Hadamard's inequality, first published by Jacques Hadamard in 1893,1 is a bound on the determinant of a matrix whose entries are complex numbers in terms of the lengths of its column vectors. In geometrical terms, when restricted to real numbers, it bounds the volume in Euclidean space of n dimensions marked out by n vectors vi for 1 ≤ i ≤ n in terms of the lengths of these vectors ||vi||.
Specifically, Hadamard's inequality states that if N is the matrix having columns2 vi, then


 
  and equality is achieved if and only if the vectors are orthogonal or at least one of the columns is 0.
Alternate forms and corollaries
A corollary is that if the entries of an n by n matrix N are bounded by B, so |Nij|≤B for all i and j, then


 
  In particular, if the entries of N are +1 and −1 only then3


 
  In combinatorics, matrices N for which equality holds, i.e. those with orthogonal columns, are called Hadamard matrices.
A positive-semidefinite matrix P can be written as N*N, where N* denotes the conjugate transpose of N (see Cholesky decomposition). Then


 
  So, the determinant of a positive definite matrix is less than or equal to the product of its diagonal entries. Sometimes this is also known as Hadamard's inequality.4
Proof
The result is trivial if the matrix N is singular, so assume the columns of N are linearly independent. By dividing each column by its length, it can be seen that the result is equivalent to the special case where each column has length 1, in other words if ei are unit vectors and M is the matrix having the ei as columns then


 
  and equality is achieved if and only if the vectors are an orthogonal set, that is when the matrix is unitary. The general result now follows:



For the positive definite case, let P =M*M and let the eigenvalues of P be λ1, λ2, … λn. By assumption, each entry in the diagonal of P is 1, so the trace of P is n. Applying the inequality of arithmetic and geometric means,


 
  so



If there is equality then each of the λi's must all be equal and their sum is n, so they must all be 1. The matrix P is Hermitian, therefore diagonalizable, so it is the identity matrix—in other words the columns of M are an orthonormal set and the columns of N are an orthogonal set.5
Many other proofs can be found in the literature.
References






Further reading



"
Category:Inequalities Category:Determinants



Maz'ya & Shaposhnikova↩
The result is sometimes stated in terms of row vectors. That this is equivalent is seen by applying the transpose.↩
Garling↩

Proof follows, with minor modifications, the second proof given in Maz'ya & Shaposhnikova. See also .↩




