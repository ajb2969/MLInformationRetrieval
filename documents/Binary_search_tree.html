<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="116">Binary search tree</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>Binary search tree</h1>
<style>
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
<style>
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
  </style>
</body></html>
<body>
<hr/>
<figure><b>(Figure)</b>
<figcaption>A binary search tree of size 9 and depth 3, with 8 at the root. The leaves are not drawn.</figcaption>
</figure>

<p>In <a href="computer_science" title="wikilink">computer science</a>, <strong>binary search trees</strong> (<strong>BST</strong>), sometimes called <strong>Ordered</strong> or <strong>sorted binary trees</strong>, are a particular type of <a href="Collection_(abstract_data_type)" title="wikilink">containers</a>: <a href="data_structure" title="wikilink">data structures</a> that store "items" (such as numbers, names and etc.) in <a href="computer_memory" title="wikilink">memory</a>. They allow fast lookup, addition and removal of items, and can be used to implement either <a href="Set_(abstract_data_type)" title="wikilink">dynamic sets</a> of items, or <a href="lookup_table" title="wikilink">lookup tables</a> that allow finding an item by its <em>key</em> (e.g., finding the phone number of a person by name).</p>

<p>Binary search trees keep their keys in sorted order, so that lookup and other operations can use the principle of <a href="binary_search" title="wikilink">binary search</a>: when looking for a key in a tree (or a place to insert a new key), they traverse the tree from root to leaf, making comparisons to keys stored in the nodes of the tree and deciding, based on the comparison, to continue searching in the left or right subtrees. On average, this means that each comparison allows the operations to skip about half of the tree, so that each lookup, insertion or deletion takes <a href="time_complexity" title="wikilink">time proportional to</a> the <a class="uri" href="logarithm" title="wikilink">logarithm</a> of the number of items stored in the tree. This is much better than the <a href="linear_time" title="wikilink">linear time</a> required to find items by key in an (unsorted) array, but slower than the corresponding operations on <a href="hash_table" title="wikilink">hash tables</a>.</p>
<h2 id="definition">Definition</h2>

<p>A binary search tree is a <a href="rooted_tree" title="wikilink">rooted</a> <a href="binary_tree" title="wikilink">binary tree</a>, whose internal nodes each store a key (and optionally, an associated value) and each have two distinguished sub-trees, commonly denoted <em>left</em> and <em>right</em>. The tree additionally satisfies the binary search tree property, which states that the key in each node must be greater than all keys stored in the left sub-tree, and smaller than all keys in right sub-tree.<a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a> (The leaves (final nodes) of the tree contain no key and have no structure to distinguish them from one another. Leaves are commonly represented by a special  or  symbol, a  pointer, etc.)</p>

<p>Generally, the information represented by each node is a record rather than a single data element. However, for sequencing purposes, nodes are compared according to their keys rather than any part of their associated records.</p>

<p>The major advantage of binary search trees over other data structures is that the related <a href="sorting_algorithm" title="wikilink">sorting algorithms</a> and <a href="search_algorithm" title="wikilink">search algorithms</a> such as <a href="in-order_traversal" title="wikilink">in-order traversal</a> can be very efficient; they are also easy to code.</p>

<p>Binary search trees are a fundamental data structure used to construct more abstract data structures such as <a href="set_(computer_science)" title="wikilink">sets</a>, <a href="set_(computer_science)#Multiset" title="wikilink">multisets</a>, and <a href="associative_array" title="wikilink">associative arrays</a>. Some of their disadvantages are as follows:</p>
<ul>
<li>The shape of the binary search tree totally depends on the order of insertions, and it can be degenerated.</li>
<li>When inserting or searching for an element in binary search tree, the key of each visited node has to be compared with the key of the element to be inserted or found, i.e., it takes a long time to search an element in a binary search tree.</li>
<li>The keys in the binary search tree may be long and the run time may increase.</li>
<li>After a long intermixed sequence of random insertion and deletion, the expected height of the tree approaches square root of the number of keys, 

<math display="inline" id="Binary_search_tree:0">
 <semantics>
  <mrow>
   <mi mathvariant="normal">√</mi>
   <mi>n</mi>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <ci>normal-√</ci>
    <ci>n</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   √n
  </annotation>
 </semantics>
</math>

, which grows much faster than 

<math display="inline" id="Binary_search_tree:1">
 <semantics>
  <mrow>
   <mi>l</mi>
   <mi>o</mi>
   <mi>g</mi>
   <mi>n</mi>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <ci>l</ci>
    <ci>o</ci>
    <ci>g</ci>
    <ci>n</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   logn
  </annotation>
 </semantics>
</math>

.</li>
</ul>
<h2 id="operations">Operations</h2>

<p>Binary search trees support three main operations: insertion of keys, deletion of keys, and lookup (checking whether a key is present). Each requires a <em>comparator</em>, a <a class="uri" href="subroutine" title="wikilink">subroutine</a> that computes the total order (linear order) on any two keys. This comparator can be explicitly or implicitly defined, depending on the language in which the binary search tree was implemented. A common comparator is the less-than function, for example, <em>a</em> Find-recursive(key, node): <em>// call initially with node = root</em></p>

<p><code>    </code><strong><code>if</code></strong><code> node = Null </code><strong><code>or</code></strong><code> node.key = key </code><strong><code>then</code></strong><br/>
<code>        </code><strong><code>return</code></strong><code> node</code><br/>
<code>    </code><strong><code>else</code> <code>if</code></strong><code> key </code><code>Find-recursive</code><code>(key, node.left)</code><br/>
<code>    </code><strong><code>else</code></strong><br/>
<code>        </code><strong><code>return</code></strong><code> </code><u><code>Find-recursive</code></u><code>(key, node.right)</code></p>

<p>The same algorithm can be implemented iteratively:</p>

<p><strong><code>function</code></strong><code> </code><u><code>Find</code></u><code>(key, root):</code><br/>
<code>    current-node := root</code><br/>
<code>    </code><strong><code>while</code></strong><code> current-node </code><strong><code>is</code> <code>not</code> <code>Null</code> <code>do</code></strong><br/>
<code>        </code><strong><code>if</code></strong><code> current-node.key = key </code><strong><code>then</code></strong><br/>
<code>            </code><strong><code>return</code></strong><code> current-node</code><br/>
<code>        </code><strong><code>else</code> <code>if</code></strong><code> key </code></p>

<p>void insert(Node*&amp; root, int data) {</p>

<p><code> if (!root) </code><br/>
<code>   root = new Node(data);</code><br/>
<code> else if (data </code><code>data)</code><br/>
<code>   insert(root-&gt;left, data);</code><br/>
<code> else if (data &gt; root-&gt;data)</code><br/>
<code>   insert(root-&gt;right, data);</code></p>

<p>}</p>

<p>The above <em>destructive</em> procedural variant modifies the tree in place. It uses only constant heap space (and the iterative version uses constant stack space as well), but the prior version of the tree is lost. Alternatively, as in the following <a href="Python_(programming_language)" title="wikilink">Python</a> example, we can reconstruct all ancestors of the inserted node; any reference to the original tree root remains valid, making the tree a <a href="persistent_data_structure" title="wikilink">persistent data structure</a>:</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"> <span class="kw">def</span> binary_tree_insert(node, key, value):
     <span class="cf">if</span> node <span class="op">is</span> <span class="va">None</span>:
         <span class="cf">return</span> TreeNode(<span class="va">None</span>, key, value, <span class="va">None</span>)
     <span class="cf">if</span> key <span class="op">==</span> node.key:
         <span class="cf">return</span> TreeNode(node.left, key, value, node.right)
     <span class="cf">if</span> key <span class="op">&lt;</span> node.key:
         <span class="cf">return</span> TreeNode(binary_tree_insert(node.left, key, value), node.key, node.value, node.right)
     <span class="cf">else</span>:
         <span class="cf">return</span> TreeNode(node.left, node.key, node.value, binary_tree_insert(node.right, key, value))</code></pre></div>

<p>The part that is rebuilt uses O(log <em>n</em>) space in the average case and O(<em>n</em>) in the worst case (see <a href="big-O_notation" title="wikilink">big-O notation</a>).</p>

<p>In either version, this operation requires time proportional to the height of the tree in the worst case, which is O(log <em>n</em>) time in the average case over all trees, but O(<em>n</em>) time in the worst case.</p>

<p>Another way to explain insertion is that in order to insert a new node in the tree, its key is first compared with that of the root. If its key is less than the root's, it is then compared with the key of the root's left child. If its key is greater, it is compared with the root's right child. This process continues, until the new node is compared with a leaf node, and then it is added as this node's right or left child, depending on its key.</p>

<p>There are other ways of inserting nodes into a binary tree, but this is the only way of inserting nodes at the leaves and at the same time preserving the BST structure.</p>
<h3 id="deletion">Deletion</h3>

<p>There are three possible cases to consider:</p>
<ul>
<li>Deleting a node with no children: simply remove the node from the tree.</li>
<li>Deleting a node with one child: remove the node and replace it with its child.</li>
<li>Deleting a node with two children: call the node to be deleted <em>N</em>. Do not delete <em>N</em>. Instead, choose either its <a href="tree_traversal" title="wikilink">in-order</a> successor node or its in-order predecessor node, <em>R</em>. Copy the value of <em>R</em> to <em>N</em>, then recursively call delete on <em>R</em> until reaching one of the first two cases. If you choose in-order successor of a node, as right sub tree is not NIL (Our present case is node has 2 children), then its in-order successor is node with least value in its right sub tree, which will have at a maximum of 1 sub tree, so deleting it would fall in one of first 2 cases.</li>
</ul>

<p>Broadly speaking, nodes with children are harder to delete. As with all binary trees, a node's in-order successor is its right subtree's left-most child, and a node's in-order predecessor is the left subtree's right-most child. In either case, this node will have zero or one children. Delete it according to one of the two simpler cases above. </p>

<p>Consistently using the in-order successor or the in-order predecessor for every instance of the two-child case can lead to an <a href="self-balancing_binary_search_tree" title="wikilink">unbalanced</a> tree, so some implementations select one or the other at different times.</p>

<p>Runtime analysis: Although this operation does not always traverse the tree down to a leaf, this is always a possibility; thus in the worst case it requires time proportional to the height of the tree. It does not require more even when the node has two children, since it still follows a single path and does not visit any node twice.</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="kw">def</span> find_min(<span class="va">self</span>):   <span class="co"># Gets minimum node in a subtree</span>
    current_node <span class="op">=</span> <span class="va">self</span>
    <span class="cf">while</span> current_node.left_child:
        current_node <span class="op">=</span> current_node.left_child
    <span class="cf">return</span> current_node

<span class="kw">def</span> replace_node_in_parent(<span class="va">self</span>, new_value<span class="op">=</span><span class="va">None</span>):
    <span class="cf">if</span> <span class="va">self</span>.parent:
        <span class="cf">if</span> <span class="va">self</span> <span class="op">==</span> <span class="va">self</span>.parent.left_child:
            <span class="va">self</span>.parent.left_child <span class="op">=</span> new_value
        <span class="cf">else</span>:
            <span class="va">self</span>.parent.right_child <span class="op">=</span> new_value
    <span class="cf">if</span> new_value:
        new_value.parent <span class="op">=</span> <span class="va">self</span>.parent

<span class="kw">def</span> binary_tree_delete(<span class="va">self</span>, key):
    <span class="cf">if</span> key <span class="op">&lt;</span> <span class="va">self</span>.key:
        <span class="va">self</span>.left_child.binary_tree_delete(key)
    <span class="cf">elif</span> key <span class="op">&gt;</span> <span class="va">self</span>.key:
        <span class="va">self</span>.right_child.binary_tree_delete(key)
    <span class="cf">else</span>: <span class="co"># delete the key here</span>
        <span class="cf">if</span> <span class="va">self</span>.left_child <span class="op">and</span> <span class="va">self</span>.right_child: <span class="co"># if both children are present</span>
            successor <span class="op">=</span> <span class="va">self</span>.right_child.find_min()
            <span class="va">self</span>.key <span class="op">=</span> successor.key
            successor.binary_tree_delete(successor.key)
        <span class="cf">elif</span> <span class="va">self</span>.left_child:   <span class="co"># if the node has only a *left* child</span>
            <span class="va">self</span>.replace_node_in_parent(<span class="va">self</span>.left_child)
        <span class="cf">elif</span> <span class="va">self</span>.right_child:  <span class="co"># if the node has only a *right* child</span>
            <span class="va">self</span>.replace_node_in_parent(<span class="va">self</span>.right_child)
        <span class="cf">else</span>: <span class="co"># this node has no children</span>
            <span class="va">self</span>.replace_node_in_parent(<span class="va">None</span>)</code></pre></div>
<h3 id="traversal">Traversal</h3>

<p>Once the binary search tree has been created, its elements can be retrieved <a href="in-order_traversal" title="wikilink">in-order</a> by <a href="recursion" title="wikilink">recursively</a> traversing the left subtree of the root node, accessing the node itself, then recursively traversing the right subtree of the node, continuing this pattern with each node in the tree as it's recursively accessed. As with all binary trees, one may conduct a <a href="pre-order_traversal" title="wikilink">pre-order traversal</a> or a <a href="post-order_traversal" title="wikilink">post-order traversal</a>, but neither are likely to be useful for binary search trees. An in-order traversal of a binary search tree will always result in a sorted list of node items (numbers, strings or other comparable items).</p>

<p>The code for in-order traversal in Python is given below. It will call <strong>callback</strong> for every node in the tree.</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="kw">def</span> traverse_binary_tree(node, callback):
    <span class="cf">if</span> node <span class="op">is</span> <span class="va">None</span>:
        <span class="cf">return</span>
    traverse_binary_tree(node.leftChild, callback)
    callback(node.value)
    traverse_binary_tree(node.rightChild, callback)</code></pre></div>

<p>Traversal requires <a href="big_O_notation#Related_asymptotic_notations" title="wikilink">O(<em>n</em>)</a> time, since it must visit every node. This algorithm is also O(<em>n</em>), so it is <a href="asymptotically_optimal" title="wikilink">asymptotically optimal</a>.</p>
<h3 id="sort">Sort</h3>

<p>A binary search tree can be used to implement a simple <a href="sorting_algorithm" title="wikilink">sorting algorithm</a>. Similar to <a class="uri" href="heapsort" title="wikilink">heapsort</a>, we insert all the values we wish to sort into a new ordered data structure—in this case a binary search tree—and then traverse it in order.</p>

<p>The worst-case time of <code>build_binary_tree</code> is 

<math display="inline" id="Binary_search_tree:2">
 <semantics>
  <mrow>
   <mi>O</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <msup>
     <mi>n</mi>
     <mn>2</mn>
    </msup>
    <mo stretchy="false">)</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <ci>O</ci>
    <apply>
     <csymbol cd="ambiguous">superscript</csymbol>
     <ci>n</ci>
     <cn type="integer">2</cn>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   O(n^{2})
  </annotation>
 </semantics>
</math>

—if you feed it a sorted list of values, it chains them into a <a href="linked_list" title="wikilink">linked list</a> with no left subtrees. For example, <code>build_binary_tree([1, 2, 3, 4, 5])</code> yields the tree <code>(1 (2 (3 (4 (5)))))</code>.</p>

<p>There are several schemes for overcoming this flaw with simple binary trees; the most common is the <a href="self-balancing_binary_search_tree" title="wikilink">self-balancing binary search tree</a>. If this same procedure is done using such a tree, the overall worst-case time is O(<em>n</em>log <em>n</em>), which is <a href="asymptotically_optimal" title="wikilink">asymptotically optimal</a> for a <a href="comparison_sort" title="wikilink">comparison sort</a>. In practice, the poor <a href="CPU_cache" title="wikilink">cache</a> performance and added overhead in time and space for a tree-based sort (particularly for node <a href="dynamic_memory_allocation" title="wikilink">allocation</a>) make it inferior to other asymptotically optimal sorts such as <a class="uri" href="heapsort" title="wikilink">heapsort</a> for static list sorting. On the other hand, it is one of the most efficient methods of <em>incremental sorting</em>, adding items to a list over time while keeping the list sorted at all times.</p>
<h3 id="verification">Verification</h3>

<p>Sometimes we already have a binary tree, and we need to determine whether it is a BST. This problem has a simple recursive solution.</p>

<p>The BST property—every node on the right subtree has to be larger than the current node and every node on the left subtree has to be smaller than (or equal to - should not be the case as only unique values should be in the tree - this also poses the question as to if such nodes should be left or right of this parent) the current node—is the key to figuring out whether a tree is a BST or not. The <a href="greedy_algorithm" title="wikilink">greedy algorithm</a> – simply traverse the tree, at every node check whether the node contains a value larger than the value at the left child and smaller than the value on the right child – does not work for all cases. Consider the following tree:</p>

<p><code>     20</code><br/>
<code>    /  \</code><br/>
<code>  10    30</code><br/>
<code>       /  \</code><br/>
<code>      5    40</code></p>

<p>In the tree above, each node meets the condition that the node contains a value larger than its left child and smaller than its right child hold, and yet it is not a BST: the value 5 is on the right subtree of the node containing 20, a violation of the BST property.</p>

<p>Instead of making a decision based solely on the values of a node and its children, we also need information flowing down from the parent as well. In the case of the tree above, if we could remember about the node containing the value 20, we would see that the node with value 5 is violating the BST property contract.</p>

<p>So the condition we need to check at each node is:</p>
<ul>
<li>if the node is the left child of its parent, then it must be smaller than (or equal to) the parent and it must pass down the value from its parent to its right subtree to make sure none of the nodes in that subtree is greater than the parent</li>
<li>if the node is the right child of its parent, then it must be larger than the parent and it must pass down the value from its parent to its left subtree to make sure none of the nodes in that subtree is lesser than the parent.</li>
</ul>

<p>A recursive solution in C++ can explain this further:</p>
<div class="sourceCode"><pre class="sourceCode c"><code class="sourceCode c"><span class="kw">struct</span> TreeNode {
    <span class="dt">int</span> data;
    TreeNode *left;
    TreeNode *right;
};

bool isBST(TreeNode *node, <span class="dt">int</span> minData, <span class="dt">int</span> maxData) {
    <span class="kw">if</span>(node == NULL) <span class="kw">return</span> true;
    <span class="kw">if</span>(node-&gt;data &lt; minData || node-&gt;data &gt; maxData) <span class="kw">return</span> false;
    
    <span class="kw">return</span> isBST(node-&gt;left, minData, node-&gt;data) &amp;&amp; isBST(node-&gt;right, node-&gt;data, maxData);
}</code></pre></div>

<p>The initial call to this function can be something like this:</p>
<div class="sourceCode"><pre class="sourceCode c"><code class="sourceCode c"><span class="kw">if</span>(isBST(root, INT_MIN, INT_MAX)) {
    puts(<span class="st">"This is a BST."</span>);
} <span class="kw">else</span> {
    puts(<span class="st">"This is NOT a BST!"</span>);
}</code></pre></div>

<p>Essentially we keep creating a valid range (starting from [MIN_VALUE, MAX_VALUE]) and keep shrinking it down for each node as we go down recursively.</p>
<h3 id="priority-queue-operations">Priority queue operations</h3>

<p>Binary search trees can serve as <a href="priority_queue" title="wikilink">priority queues</a>: structures that allow insertion of arbitrary key as well as lookup and deletion of the minimum (or maximum) key. Insertion works as previously explained. <em>Find-min</em> walks the tree, following left pointers as far as it can without hitting a leaf:</p>

<p><em><code>//</code> <code>Precondition:</code> <code>T</code> <code>is</code> <code>not</code> <code>a</code> <code>leaf</code></em><br/>
<strong><code>function</code></strong><code> find-min(T):</code><br/>
<code>    </code><strong><code>while</code></strong><code> hasLeft(T):</code><br/>
<code>        T ← left(T)</code><br/>
<code>    </code><strong><code>return</code></strong><code> key(T)</code></p>

<p><em>Find-max</em> is analogous: follow right pointers as far as possible. <em>Delete-min</em> (<em>max</em>) can simply look up the minimum (maximum), then delete it. This way, insertion and deletion both take logarithmic time, just as they do in a <a href="binary_heap" title="wikilink">binary heap</a>, but unlike a binary heap and most other priority queue implementations, a single tree can support all of <em>find-min</em>, <em>find-max</em>, <em>delete-min</em> and <em>delete-max</em> at the same time, making binary search trees suitable as <a href="double-ended_priority_queue" title="wikilink">double-ended priority queues</a>.<a class="footnoteRef" href="#fn2" id="fnref2"><sup>2</sup></a></p>
<h2 id="types">Types</h2>

<p>There are many types of binary search trees. <a href="AVL_tree" title="wikilink">AVL trees</a> and <a href="red-black_tree" title="wikilink">red-black trees</a> are both forms of <a href="self-balancing_binary_search_tree" title="wikilink">self-balancing binary search trees</a>. A <a href="splay_tree" title="wikilink">splay tree</a> is a binary search tree that automatically moves frequently accessed elements nearer to the root. In a <a class="uri" href="treap" title="wikilink">treap</a> (<em>tree <a href="heap_(data_structure)" title="wikilink">heap</a></em>), each node also holds a (randomly chosen) priority and the parent node has higher priority than its children. <a href="Tango_tree" title="wikilink">Tango trees</a> are trees optimized for fast searches.</p>

<p>Two other titles describing binary search trees are that of a <em>complete</em> and <em>degenerate</em> tree.</p>

<p>A complete binary tree is a binary tree, which is completely filled, with the possible exception of the bottom level, which is filled from left to right. In complete binary tree, all nodes are far left as possible. It is a tree with n levels, where for each level d d. This means all possible nodes exist at these levels. An additional requirement for a complete binary tree is that for the nth level, while every node does not have to exist, the nodes that do exist must fill from left to right.</p>

<p>A degenerate tree is a tree where for each parent node, there is only one associated child node. It is unbalanced and, in the worst case, performance degrades to that of a linked list. If your added node function does not handle re-balancing, then you can easily construct a degenerate tree by feeding it with data that is already sorted. What this means is that in a performance measurement, the tree will essentially behave like a linked list data structure.</p>
<h3 id="performance-comparisons">Performance comparisons</h3>

<p>D. A. Heger (2004)<a class="footnoteRef" href="#fn3" id="fnref3"><sup>3</sup></a> presented a performance comparison of binary search trees. <a class="uri" href="Treap" title="wikilink">Treap</a> was found to have the best average performance, while <a href="red-black_tree" title="wikilink">red-black tree</a> was found to have the smallest amount of performance variations.</p>
<h3 id="optimal-binary-search-trees">Optimal binary search trees</h3>

<p> If we do not plan on modifying a search tree, and we know exactly how often each item will be accessed, we can construct<a class="footnoteRef" href="#fn4" id="fnref4"><sup>4</sup></a> an <em>optimal binary search tree</em>, which is a search tree where the average cost of looking up an item (the <em>expected search cost</em>) is minimized.</p>

<p>Even if we only have estimates of the search costs, such a system can considerably speed up lookups on average. For example, if you have a BST of English words used in a <a href="spell_checker" title="wikilink">spell checker</a>, you might balance the tree based on word frequency in <a href="text_corpus" title="wikilink">text corpora</a>, placing words like <em>the</em> near the root and words like <em>agerasia</em> near the leaves. Such a tree might be compared with <a href="Huffman_tree" title="wikilink">Huffman trees</a>, which similarly seek to place frequently used items near the root in order to produce a dense information encoding; however, Huffman trees store data elements only in leaves, and these elements need not be ordered.</p>

<p>If we do not know the sequence in which the elements in the tree will be accessed in advance, we can use <a href="splay_tree" title="wikilink">splay trees</a> which are asymptotically as good as any static search tree we can construct for any particular sequence of lookup operations.</p>

<p><em>Alphabetic trees</em> are Huffman trees with the additional constraint on order, or, equivalently, search trees with the modification that all elements are stored in the leaves. Faster algorithms exist for <em>optimal alphabetic binary trees</em> (OABTs).</p>
<h2 id="see-also">See also</h2>
<ul>
<li><a href="Search_tree" title="wikilink">Search tree</a></li>
<li><a href="Binary_search_algorithm" title="wikilink">Binary search algorithm</a></li>
<li><a href="Randomized_binary_search_tree" title="wikilink">Randomized binary search tree</a></li>
<li><a href="Tango_tree" title="wikilink">Tango trees</a></li>
<li><a href="Self-balancing_binary_search_tree" title="wikilink">Self-balancing binary search tree</a></li>
<li><a href="Geometry_of_binary_search_trees" title="wikilink">Geometry of binary search trees</a></li>
<li><a href="Red-black_tree" title="wikilink">Red-black tree</a></li>
<li><a href="AVL_trees" title="wikilink">AVL trees</a></li>
<li><a href="Day–Stout–Warren_algorithm" title="wikilink">Day–Stout–Warren algorithm</a></li>
</ul>
<h2 id="references">References</h2>
<h2 id="further-reading">Further reading</h2>
<ul>
<li></li>
<li></li>
<li></li>
<li></li>
<li></li>
<li></li>
</ul>
<h2 id="external-links">External links</h2>
<ul>
<li><a href="http://en.literateprograms.org/Category:Binary_search_tree">Literate implementations of binary search trees in various languages</a> on LiteratePrograms</li>
<li><a href="http://btv.melezinek.cz">Binary Tree Visualizer</a> (JavaScript animation of various BT-based data structures)</li>
<li></li>
<li>

<p>C++ implementation.</p></li>
<li><a href="http://code.activestate.com/recipes/286239/">Binary Search Tree Example in Python</a></li>
<li>

<p>Gives an example binary tree implementation.</p></li>
</ul>

<p>"</p>

<p><a href="Category:Articles_with_example_C++_code" title="wikilink">Category:Articles with example C++ code</a> <a href="Category:Articles_with_example_Python_code" title="wikilink">Category:Articles with example Python code</a> <a href="Category:Binary_trees" title="wikilink">Category:Binary trees</a> <a href="Category:Data_types" title="wikilink">Category:Data types</a> <a href="Category:Search_trees" title="wikilink">Category:Search trees</a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1"><a href="#fnref1">↩</a></li>
<li id="fn2"><a href="#fnref2">↩</a></li>
<li id="fn3"><a href="#fnref3">↩</a></li>
<li id="fn4"><a href="#fnref4">↩</a></li>
</ol>
</section>
</body>

