


Tobit model




Tobit model

The Tobit model is a statistical model proposed by James Tobin (1958)1 to describe the relationship between a non-negative dependent variable 
 
 
 
  and an independent variable (or vector) 
 
 
 
 . The term Tobit was derived from Tobin's name by truncating and adding -it by analogy with the probit model.2
The model supposes that there is a latent (i.e. unobservable) variable

 
 . This variable linearly depends on 
 
 
 
 
  via a parameter (vector) 
 
 
 
  which determines the relationship between the independent variable (or vector) 
 
 
 
  and the latent variable

 
  (just as in a linear model). In addition, there is a normally distributed error term

 
  to capture random influences on this relationship. The observable variable 
 
 
 
 
  is defined to be equal to the latent variable whenever the latent variable is above zero and zero otherwise.



where 
 
 
 
  is a latent variable:



Consistency
If the relationship parameter 
 
 
 
  is estimated by regressing the observed 
 
 
 
  on 
 
 
 
 , the resulting ordinary least squares regression estimator is inconsistent. It will yield a downwards-biased estimate of the slope coefficient and an upward-biased estimate of the intercept. Takeshi Amemiya (1973) has proven that the maximum likelihood estimator suggested by Tobin for this model is consistent.
Interpretation
The 
 
 
 
  coefficient should not be interpreted as the effect of 
 
 
 
  on 
 
 
 
 , as one would with a linear regression model; this is a common error. Instead, it should be interpreted as the combination of (1) the change in 
 
 
 
  of those above the limit, weighted by the probability of being above the limit; and (2) the change in the probability of being above the limit, weighted by the expected value of 
 
 
 
  if above.3
Variations of the Tobit model
Variations of the Tobit model can be produced by changing where and when censoring occurs.  classifies these variations into five categories (Tobit type I - Tobit type V), where Tobit type I stands for the first model described above. Schnedler (2005) provides a general formula to obtain consistent likelihood estimators for these and other variations of the Tobit model.
Type I
The Tobit model is a special case of a censored regression model, because the latent variable 
 
 
 
  cannot always be observed while the independent variable 
 
 
 
  is observable. A common variation of the Tobit model is censoring at a value 
 
 
 
  different from zero:



Another example is censoring of values above 
 
 
 
 .


 
  is censored from above and below at the same time.



Heckman (1987) falls into the Type II Tobit. In Type I Tobit, the latent variable absorb both the process of participation and 'outcome' of interest. Type II Tobit allows the process of participation/selection and the process of 'outcome' to be independent, conditional on x.
Type III
Type III introduces a second observed dependent variable.





 
  The Heckman model falls into this type.
Type IV
Type IV introduces a third observed dependent variable and a third latent variable.









Type V
Similar to Type II, in Type V we only observe the sign of 
 
 
 
 .






The likelihood function
Below are the likelihood and log likelihood functions for a type I Tobit. This is a Tobit that is censored from below at 
 
 
 
  when the latent variable 
 
 
 
 . In writing out the likelihood function, we first define an indicator function 
 
 
 
 
  where:



Next, we mean 
 
 
 
  to be the standard normal cumulative distribution function and 
 
 
 
  to be the standard normal probability density function. For a data set with N observations the likelihood function for a type I Tobit is
$$\mathcal{L}(\beta, \sigma) =  \prod _{j=1}^N \left(\frac{1}{\sigma}\phi \left(\frac{y_j-X_j\beta  }{\sigma
    }\right)\right)^{I\left(y_j\right)} \left(1-\Phi
    \left(\frac{X_j\beta-y_L}{\sigma}\right)\right)^{1-I\left(y_j\right)}$$
and the log likelihood is given by
$$\log \mathcal{L}(\beta, \sigma) = \sum^n_{j = 1} I(y_j) \log \left( \frac{1}{\sigma} \phi\left( \frac{y_j - X_j\beta}{\sigma} \right) \right) + (1 - I(y_j)) \log\left( 1- \Phi\left( \frac{X_j \beta - y_L}{\sigma} \right) \right)$$
See also

Generalized Tobit
Limited dependent variable
Rectifier (neural networks)
Truncated regression model

References
Further reading







"
Category:Regression analysis Category:Econometrics Category:Single-equation methods (econometrics)



↩
International Encyclopedia of the Social Sciences (2008)↩
↩




