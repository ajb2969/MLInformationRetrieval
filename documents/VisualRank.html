<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="482">VisualRank</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>VisualRank</h1>
<hr/>

<p><strong>VisualRank</strong> is a system for <a href="image_retrieval" title="wikilink">finding</a> and ranking images by analysing and comparing their content, rather than searching image names, Web links or other text. <a class="uri" href="Google" title="wikilink">Google</a> scientists made their VisualRank work public in a paper describing applying <a class="uri" href="PageRank" title="wikilink">PageRank</a> to Google image search at the International World Wide Web Conference in <a class="uri" href="Beijing" title="wikilink">Beijing</a> in 2008. <a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a></p>
<blockquote>

<p>We cast the image-ranking problem into the task of identifying "authority" nodes on an inferred visual similarity graph and propose VisualRank to analyze the visual link structures among images. The images found to be "authorities" are chosen as those that answer the image-queries well.</p>
</blockquote>
<h2 id="methods">Methods</h2>

<p>Both <a href="computer_vision" title="wikilink">computer vision</a> techniques and <a href="locality-sensitive_hashing" title="wikilink">locality-sensitive hashing</a> (LSH) are used in the VisualRank <a class="uri" href="algorithm" title="wikilink">algorithm</a>. Consider an image search initiated by a text query. An existing search technique based on image metadata and surrounding text is used to retrieve the initial result candidates (<a class="uri" href="PageRank" title="wikilink">PageRank</a>), which along with other images in the index are clustered in a <a href="Graph_(data_structure)" title="wikilink">graph</a> according to their similarity (which is precomputed). <a class="uri" href="Centrality" title="wikilink">Centrality</a> is then measured on the clustering, which will return the most canonical image(s) with respect to the query. The idea here is that agreement between users of the web about the image and its related concepts will result in those images being deemed more similar. VisualRank is defined iteratively by 

<math display="inline" id="VisualRank:0">
 <semantics>
  <mrow>
   <mrow>
    <mi>V</mi>
    <mi>R</mi>
   </mrow>
   <mo>=</mo>
   <mrow>
    <mrow>
     <msup>
      <mi>S</mi>
      <mo>*</mo>
     </msup>
     <mo>×</mo>
     <mi>V</mi>
    </mrow>
    <mi>R</mi>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <times></times>
     <ci>V</ci>
     <ci>R</ci>
    </apply>
    <apply>
     <times></times>
     <apply>
      <times></times>
      <apply>
       <csymbol cd="ambiguous">superscript</csymbol>
       <ci>S</ci>
       <times></times>
      </apply>
      <ci>V</ci>
     </apply>
     <ci>R</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   VR=S^{*}\times VR
  </annotation>
 </semantics>
</math>

, where 

<math display="inline" id="VisualRank:1">
 <semantics>
  <msup>
   <mi>S</mi>
   <mo>*</mo>
  </msup>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">superscript</csymbol>
    <ci>S</ci>
    <times></times>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   S^{*}
  </annotation>
 </semantics>
</math>

 is the image similarity matrix. As matrices are used, <a href="eigenvector_centrality" title="wikilink">eigenvector centrality</a> will be the measure applied, with repeated multiplication of 

<math display="inline" id="VisualRank:2">
 <semantics>
  <mrow>
   <mi>V</mi>
   <mi>R</mi>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <ci>V</ci>
    <ci>R</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   VR
  </annotation>
 </semantics>
</math>

 and 

<math display="inline" id="VisualRank:3">
 <semantics>
  <msup>
   <mi>S</mi>
   <mo>*</mo>
  </msup>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">superscript</csymbol>
    <ci>S</ci>
    <times></times>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   S^{*}
  </annotation>
 </semantics>
</math>

 producing the <a class="uri" href="eigenvector" title="wikilink">eigenvector</a> we're looking for. Clearly, the image similarity measure is crucial to the performance of VisualRank since it determines the underlying graph structure.</p>

<p>The main VisualRank system begins with local feature vectors being extracted from images using <a href="scale-invariant_feature_transform" title="wikilink">scale-invariant feature transform</a> (SIFT). Local feature descriptors are used instead of color histograms as they allow similarity to be considered between images with potential rotation, scale, and perspective transformations. Locality-sensitive hashing is then applied to these feature vectors using the <a href="locality-sensitive_hashing#methods" title="wikilink">p-stable distribution scheme</a>. In addition to this, LSH amplification using AND/OR constructions are applied. As part of the applied scheme, a <a href="Gaussian_distribution" title="wikilink">Gaussian distribution</a> is used under the <a href="L2_norm#Euclidean_norm" title="wikilink">

<math display="inline" id="VisualRank:4">
 <semantics>
  <msub>
   <mi>l</mi>
   <mn>2</mn>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>l</ci>
    <cn type="integer">2</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   l_{2}
  </annotation>
 </semantics>
</math>

 norm</a>.</p>
<h2 id="references">References</h2>
<h2 id="external-links">External links</h2>
<ul>
<li>[<a class="uri" href="http://www.nytimes.com/2008/04/28/technology/28google.html?adxnnl=1&amp;ref">http://www.nytimes.com/2008/04/28/technology/28google.html?adxnnl=1&amp;ref;</a>;=business&amp;adxnnlx;=1210140241-DOwaJr/5AjMPCYJDerw++Q New York Times article]</li>
<li>[<a class="uri" href="http://tech.slashdot.org/article.pl?sid=08/04/28/1852254&amp;from">http://tech.slashdot.org/article.pl?sid=08/04/28/1852254&amp;from;</a>;=rss Slashdot article]</li>
</ul>

<p>"</p>

<p><a href="Category:Internet_search" title="wikilink">Category:Internet search</a> <a href="Category:Image_processing" title="wikilink">Category:Image processing</a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1">.<a href="#fnref1">↩</a></li>
</ol>
</section>
</body>
</html>
