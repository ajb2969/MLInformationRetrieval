   Multicriteria classification      Multicriteria classification   In multiple criteria decision aiding (MCDA), multicriteria classification (or sorting) involves problems where a finite set of alternative actions should be assigned into a predefined set of preferentially ordered categories (classes). 1 For example, credit analysts classify loan applications into risk categories (e.g., acceptable/unacceptable applicants), customers rate products and classify them into attractiveness groups, candidates for a job position are evaluated and their applications are approved or rejected, technical systems are prioritized for inspection on the basis of their failure risk, etc.  Problem statement  In a multicriteria classification problem (MCP) a set      X  =   {   ùê±  1   ,   ùê±  2   ,  ‚Ä¶  ,   ùê±  m   }       X    subscript  ùê±  1    subscript  ùê±  2   normal-‚Ä¶   subscript  ùê±  m      X=\{\mathbf{x}_{1},\mathbf{x}_{2},...,\mathbf{x}_{m}\}     of m alternative actions is available. Each alternative is evaluated over a set of n criteria. The scope of the analysis is to assign each alternative into a given set of categories (classes) C ={ c 1 , c 2 , ..., c k }.  The categories are defined in an ordinal way. Assuming (without loss of generality) an ascending order, this means that category c 1 consists of the best alternatives whereas c 2 includes the worst (least preferred) ones. The alternatives in each category cannot be assumed be equivalent in terms of their overall evaluation (the categories are not equivalence classes ).  Furthermore, the categories are defined independently of the set of alternatives under consideration. In that regard, MCPs are based on an absolute evaluation scheme. For instance, a predefined specific set of categories is often used to classify industrial accidents (e.g., major, minor, etc.). These categories are not related to a specific event under consideration. Of course, in many cases the definition of the categories is adjusted over time to take into consideration the changes in the decision environment.  Relationship to pattern recognition  In comparison to statistical classification and pattern recognition in a machine learning sense, two main distinguishing features of MCPs can be identified: 2 3   In MCPs the categories are defined in an ordinal way. This ordinal definition of the categories implicitly defines a preference structure. In contrast, machine learning is usually involved with nominal classification problems, where classes of observations are defined in a nominal way (i.e., collection of cases described by some common patterns), without any preferential implications.  In MCPs, the alternatives are evaluated over a set of criteria. A criterion is an attribute that incorporates preferential information. Thus, the decision model should have some form of monotonic relationship with respect to the criteria. This kind of information is explicitly introduced (a priory) in multicriteria methods for MCPs.   Methods  The most popular modeling approach for MCPs are based on value function models, outranking relations, and decision rules:   In a value function model, the classification rules can be expressed as follows: Alternative i is assigned to group c r if and only if        Œ≤  *   =    arg    min   Œ≤  ‚àà  B    L     [   D   (  X  )    ,    D    ‚Ä≤     (  X  ,   f  Œ≤   )    ]         superscript  Œ≤          subscript     Œ≤  B    L       D  X      superscript  D   normal-‚Ä≤     X   subscript  f  Œ≤         \beta^{*}=\arg\min_{\beta\in B}L[D(X),D^{^{\prime}}(X,f_{\beta})]   based on the solution of an optimization problem of the following general form:        ‚àë  i     (    s  i  +   +   s  i  -    )       subscript   i      superscript   subscript  s  i      superscript   subscript  s  i        \displaystyle\sum_{i}{(s_{i}^{+}+s_{i}^{-})}   where X is the set of reference alternatives, D ( X ) is the classification of the reference alternatives by the decision-maker, D ' ( X , f Œ≤ ) are the recommendations of the model for the reference alternatives, L is a function that measures the differences between the decision-maker's evaluations and the model's outputs, and B is the set of feasible values for the model's parameters.  For example, the following linear program can be formulated in the context of a weighted average model V ( x i )= w 1 x i 1 +...+ w n x in with w j being the (non-negative) trade-off constant for criterion j ( w 1 +...+ w n =1) and x ij being the data for alternative i on criterion j :  $$\begin{align}
 & \text{minimize} && \sum_{i}{(s_i^+ + s_i^-)}\\
 & \text{subject to:} && w_1x_{i1}+...+w_nx_{in}-t_r+s_i^+\ge\delta& \text{for all reference alternatives in class } c_r (r=1,...,k-1)\\
 & && w_1x_{i1}+...+w_nx_{in}-t_{r-1}-s_i^-\leq-\delta& \text{for all reference alternatives in class } c_r (r=2,\ldots,k)\\
 & && w_1+...+w_n=1\\
 & && w_j,s_i^+,s_i^-,t_r\ge 0\\
 \end{align}$$ This linear programming formulation can be generalized in context of additive value functions. 4 5 Similar optimization problems (linear and nonlinear) can be formulated for outranking models, 6 7 8 whereas decision rule models are build through rule induction algorithms.  External links   Site dedicated to the sorting problematic of MCDA   References  "  Category:Decision theory  Category:Operations research     ‚Ü©  ‚Ü©  ‚Ü©  ‚Ü©  ‚Ü©  ‚Ü©  ‚Ü©  ‚Ü©     