   Elementary effects method      Elementary effects method   The elementary effects (EE) method is the most used screening method in sensitivity analysis . It is applied to identify non-influential inputs for a computationally costly mathematical model or for a model with a large number of inputs, where the costs of estimating other sensitivity analysis measures such as the variance-based measures is not affordable. Like all screening, the EE method provides qualitative sensitivity analysis measures, i.e. measures which allow the identification of non-influential inputs or which allow to rank the input factors in order of importance, but do not quantify exactly the relative importance of the inputs.  Methodology  To exemplify the EE method, let us assume to consider a mathematical model with   k   k   k   input factors. Let   Y   Y   Y   be the output of interest (a scalar for simplicity):       Y  =   f   (   X  1   ,   X  2   ,   ‚Ä¶   X  k    )     .      Y    f    subscript  X  1    subscript  X  2     normal-‚Ä¶   subscript  X  k        Y=f(X_{1},X_{2},...X_{k}).     The original EE method of Morris 1 provides two sensitivity measures for each input factor:   the measure   Œº   Œº   \mu   , assessing the overall importance of an input factor on the model output;  the measure   œÉ   œÉ   \sigma   , describing non-linear effects and interactions.   These two measures are obtained through a design based on the construction of a series of trajectories in the space of the inputs, where inputs are randomly moved One-At-a-Time (OAT). In this design, each model input is assumed to vary across   p   p   p   selected levels in the space of the input factors. The region of experimentation   Œ©   normal-Œ©   \Omega   is thus a   k   k   k   -dimensional   p   p   p   -level grid.  Each trajectory is composed of    (   k  +  1   )      k  1    (k+1)   points since input factors move one by one of a step   Œî   normal-Œî   \Delta   in    {  0  ,   1  /   (   p  -  1   )    ,   2  /   (   p  -  1   )    ,  ‚Ä¶  ,  1  }     0    1    p  1      2    p  1    normal-‚Ä¶  1    \{0,1/(p-1),2/(p-1),...,1\}   while all the others remain fixed.  Along each trajectory the so-called elementary effect for each input factor is defined as:        d  i    (  X  )    =     Y   (   X  1   ,  ‚Ä¶  ,   X   i  -  1    ,    X  i   +  Œî   ,   X   i  +  1    ,  ‚Ä¶  ,   X  k   )    -   Y   (  ùêó  )     Œî          subscript  d  i   X         Y    subscript  X  1   normal-‚Ä¶   subscript  X    i  1       subscript  X  i   normal-Œî    subscript  X    i  1    normal-‚Ä¶   subscript  X  k       Y  ùêó    normal-Œî     d_{i}(X)=\frac{Y(X_{1},\ldots,X_{i-1},X_{i}+\Delta,X_{i+1},\ldots,X_{k})-Y(%
 \mathbf{X})}{\Delta}   ,  where    ùêó  =   (   X  1   ,   X  2   ,   ‚Ä¶   X  k    )       ùêó    subscript  X  1    subscript  X  2     normal-‚Ä¶   subscript  X  k       \mathbf{X}=(X_{1},X_{2},...X_{k})   is any selected value in   Œ©   normal-Œ©   \Omega   such that the transformed point is still in   Œ©   normal-Œ©   \Omega   for each index     i  =   1  ,  ‚Ä¶  ,  k    .      i   1  normal-‚Ä¶  k     i=1,\ldots,k.      r   r   r   elementary effects are estimated for each input      d  i    (   X   (  1  )    )    ,    d  i    (   X   (  2  )    )    ,  ‚Ä¶  ,    d  i    (   X   (  r  )    )          subscript  d  i    superscript  X  1       subscript  d  i    superscript  X  2    normal-‚Ä¶     subscript  d  i    superscript  X  r      d_{i}\left(X^{(1)}\right),d_{i}\left(X^{(2)}\right),\ldots,d_{i}\left(X^{(r)}\right)   by randomly sampling   r   r   r   points     X   (  1  )    ,   X   (  2  )    ,  ‚Ä¶  ,   X   (  r  )        superscript  X  1    superscript  X  2   normal-‚Ä¶   superscript  X  r     X^{(1)},X^{(2)},\ldots,X^{(r)}   . Usually   r   r   r   ~ 4-10, depending on the number of input factors, on the computational cost of the model and on the choice of the number of levels   p   p   p   , since a high number of levels to be explored needs to be balanced by a high number of trajectories, in order to obtain an exploratory sample. It is demonstrated that a convenient choice for the parameters   p   p   p   and   Œî   normal-Œî   \Delta   is   p   p   p   even and   Œî   normal-Œî   \Delta   equal to    p  /   [   2   (   p  -  1   )    ]       p   delimited-[]    2    p  1       p/[2(p-1)]   , as this ensures equal probability of sampling in the input space.  In case input factors are not uniformly distributed, the best practice is to sample in the space of the quantiles and to obtain the inputs values using inverse cumulative distribution functions. Note that in this case   Œî   normal-Œî   \Delta   equals the step taken by the inputs in the space of the quantiles.  The two measures   Œº   Œº   \mu   and   œÉ   œÉ   \sigma   are defined as the mean and the standard deviation of the distribution of the elementary effects of each input:      Œº  i   =    1  r     ‚àë   j  =  1   r     d  i    (   X   (  j  )    )           subscript  Œº  i       1  r     superscript   subscript     j  1    r      subscript  d  i    superscript  X  j        \mu_{i}=\frac{1}{r}\sum_{j=1}^{r}d_{i}\left(X^{(j)}\right)   ,       œÉ  i   =     1   (   r  -  1   )      ‚àë   j  =  1   r     (     d  i    (   X   (  j  )    )    -   Œº  i    )   2           subscript  œÉ  i         1    r  1      superscript   subscript     j  1    r    superscript       subscript  d  i    superscript  X  j     subscript  Œº  i    2        \sigma_{i}=\sqrt{\frac{1}{(r-1)}\sum_{j=1}^{r}\left(d_{i}\left(X^{(j)}\right)-%
 \mu_{i}\right)^{2}}   .  These two measures need to be read together (e.g. on a two-dimensional graph) in order to rank input factors in order of importance and identify those inputs which do not influence the output variability. Low values of both   Œº   Œº   \mu   and   œÉ   œÉ   \sigma   correspond to a non-influent input.  An improvement of this method was developed by Campolongo et al. 2 who proposed a revised measure    Œº  *     superscript  Œº     \mu^{*}   , which on its own is sufficient to provide a reliable ranking of the input factors. The revised measure is the mean of the distribution of the absolute values of the elementary effects of the input factors:      Œº  i  *   =    1  r     ‚àë   j  =  1   r    |    d  i    (   X   (  j  )    )    |          superscript   subscript  Œº  i         1  r     superscript   subscript     j  1    r        subscript  d  i    superscript  X  j         \mu_{i}^{*}=\frac{1}{r}\sum_{j=1}^{r}\left|d_{i}\left(X^{(j)}\right)\right|   . The use of    Œº  *     superscript  Œº     \mu^{*}   solves the problem of the effects of opposite signs which occurs when the model is non-monotonic and which can cancel each other out, thus resulting in a low value for   Œº   Œº   \mu   .  An efficient technical scheme to construct the trajectories used in the EE method is presented in the original paper by Morris while an improvement strategy aimed at better exploring the input space is proposed by Campolongo et al..  References  "  Category:Scientific modeling  Category:Sensitivity analysis     Morris, M. D. (1991). Factorial sampling plans for preliminary computational experiments. Technometrics , 33 , 161‚Äì174. ‚Ü©  Campolongo, F., J. Cariboni, and A. Saltelli (2007). An effective screening design for sensitivity analysis of large models. Environmental Modelling and Software , 22 , 1509‚Äì1518. ‚Ü©     