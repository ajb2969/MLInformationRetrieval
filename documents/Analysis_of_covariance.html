<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="661">Analysis of covariance</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>Analysis of covariance</h1>
<hr/>

<p><a class="uri" href="Covariance" title="wikilink">Covariance</a> is a measure of linear association between two variables, (i.e. how much a change in one variable is linearly associated with a change in another variable).<a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a> <strong>Analysis of covariance (ANCOVA)</strong> is a <a href="general_linear_model" title="wikilink">general linear model</a> which blends <a class="uri" href="ANOVA" title="wikilink">ANOVA</a> and <a href="regression_analysis" title="wikilink">regression</a>. ANCOVA evaluates whether population means of a <a href="dependent_variable" title="wikilink">dependent variable</a> (DV) are equal across levels of a categorical <a href="independent_variable" title="wikilink">independent variable</a> (IV) often called a treatment, while statistically controlling for the effects of other continuous variables that are not of primary interest, known as <a href="covariate" title="wikilink">covariates</a> (CV) or nuisance variables. Mathematically, ANCOVA decomposes the variance in the DV into variance explained by the CV(s), variance explained by the categorical IV, and residual variance. Intuitively, ANCOVA can be thought of as 'adjusting' the DV by the group means of the CV(s).<a class="footnoteRef" href="#fn2" id="fnref2"><sup>2</sup></a></p>

<p>The ANCOVA procedure is described as follows, assuming that a linear relationship between the response (DV) and covariate (CV) exists:</p>

<p>

<math display="inline" id="Analysis_of_covariance:0">
 <semantics>
  <mrow>
   <msub>
    <mi>y</mi>
    <mrow>
     <mi>i</mi>
     <mi>j</mi>
    </mrow>
   </msub>
   <mo>=</mo>
   <mrow>
    <mi>μ</mi>
    <mo>+</mo>
    <msub>
     <mi>τ</mi>
     <mi>i</mi>
    </msub>
    <mo>+</mo>
    <mrow>
     <merror class="ltx_ERROR undefined undefined">
      <mtext>\Beta</mtext>
     </merror>
     <mrow>
      <mo stretchy="false">(</mo>
      <mrow>
       <msub>
        <mi>x</mi>
        <mrow>
         <mi>i</mi>
         <mi>j</mi>
        </mrow>
       </msub>
       <mo>-</mo>
       <mover accent="true">
        <msub>
         <mi>x</mi>
         <mi>i</mi>
        </msub>
        <mo>¯</mo>
       </mover>
      </mrow>
      <mo stretchy="false">)</mo>
     </mrow>
    </mrow>
    <mo>+</mo>
    <msub>
     <mi>ϵ</mi>
     <mrow>
      <mi>i</mi>
      <mi>j</mi>
     </mrow>
    </msub>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>y</ci>
     <apply>
      <times></times>
      <ci>i</ci>
      <ci>j</ci>
     </apply>
    </apply>
    <apply>
     <plus></plus>
     <ci>μ</ci>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>τ</ci>
      <ci>i</ci>
     </apply>
     <apply>
      <times></times>
      <mtext>\Beta</mtext>
      <apply>
       <minus></minus>
       <apply>
        <csymbol cd="ambiguous">subscript</csymbol>
        <ci>x</ci>
        <apply>
         <times></times>
         <ci>i</ci>
         <ci>j</ci>
        </apply>
       </apply>
       <apply>
        <ci>normal-¯</ci>
        <apply>
         <csymbol cd="ambiguous">subscript</csymbol>
         <ci>x</ci>
         <ci>i</ci>
        </apply>
       </apply>
      </apply>
     </apply>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>ϵ</ci>
      <apply>
       <times></times>
       <ci>i</ci>
       <ci>j</ci>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   y_{ij}=\mu+\tau_{i}+\Beta(x_{ij}-\overline{x_{i}})+\epsilon_{ij}
  </annotation>
 </semantics>
</math>


</p>

<p>where 

<math display="inline" id="Analysis_of_covariance:1">
 <semantics>
  <msub>
   <mi>y</mi>
   <mrow>
    <mi>i</mi>
    <mi>j</mi>
   </mrow>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>y</ci>
    <apply>
     <times></times>
     <ci>i</ci>
     <ci>j</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   y_{ij}
  </annotation>
 </semantics>
</math>

 is the jth observation under the ith categorical group, 

<math display="inline" id="Analysis_of_covariance:2">
 <semantics>
  <mi>μ</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>μ</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \mu
  </annotation>
 </semantics>
</math>

 is the grand mean, 

<math display="inline" id="Analysis_of_covariance:3">
 <semantics>
  <msub>
   <mi>τ</mi>
   <mi>i</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>τ</ci>
    <ci>i</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \tau_{i}
  </annotation>
 </semantics>
</math>

 is the effect of the ith level of the IV, 

<math display="inline" id="Analysis_of_covariance:4">
 <semantics>
  <msub>
   <mi>x</mi>
   <mrow>
    <mi>i</mi>
    <mi>j</mi>
   </mrow>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>x</ci>
    <apply>
     <times></times>
     <ci>i</ci>
     <ci>j</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   x_{ij}
  </annotation>
 </semantics>
</math>

 is the jth observation of the covariate under the ith group, 

<math display="inline" id="Analysis_of_covariance:5">
 <semantics>
  <mover accent="true">
   <msub>
    <mi>x</mi>
    <mi>i</mi>
   </msub>
   <mo>¯</mo>
  </mover>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <ci>normal-¯</ci>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>x</ci>
     <ci>i</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \overline{x_{i}}
  </annotation>
 </semantics>
</math>


 is the ith group mean, and 

<math display="inline" id="Analysis_of_covariance:6">
 <semantics>
  <msub>
   <mi>ϵ</mi>
   <mrow>
    <mi>i</mi>
    <mi>j</mi>
   </mrow>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>ϵ</ci>
    <apply>
     <times></times>
     <ci>i</ci>
     <ci>j</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \epsilon_{ij}
  </annotation>
 </semantics>
</math>

 is the associated unobserved error term. Under this specification, we assume that the categorical treatment effects sum to zero 

<math display="inline" id="Analysis_of_covariance:7">
 <semantics>
  <mrow>
   <mrow>
    <mo>(</mo>
    <mrow>
     <mrow>
      <msubsup>
       <mo largeop="true" symmetric="true">∑</mo>
       <mi>i</mi>
       <mi>a</mi>
      </msubsup>
      <msub>
       <mi>τ</mi>
       <mi>i</mi>
      </msub>
     </mrow>
     <mo>=</mo>
     <mn>0</mn>
    </mrow>
    <mo>)</mo>
   </mrow>
   <mo>.</mo>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <sum></sum>
       <ci>i</ci>
      </apply>
      <ci>a</ci>
     </apply>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>τ</ci>
      <ci>i</ci>
     </apply>
    </apply>
    <cn type="integer">0</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \left(\sum_{i}^{a}\tau_{i}=0\right).
  </annotation>
 </semantics>
</math>

 The standard assumptions of the linear regression model are also assumed to hold, as discussed below.<a class="footnoteRef" href="#fn3" id="fnref3"><sup>3</sup></a></p>
<h2 id="uses-of-ancova">Uses of ANCOVA</h2>
<h3 id="increase-power">Increase Power</h3>

<p>ANCOVA can be used to increase <a href="statistical_power" title="wikilink">statistical power</a><a class="footnoteRef" href="#fn4" id="fnref4"><sup>4</sup></a> (the ability to find a <a href="Statistical_significance" title="wikilink">significant difference</a> between groups when one exists) by reducing the within-group error <a class="uri" href="variance" title="wikilink">variance</a>. In order to understand this, it is necessary to understand the test used to evaluate differences between groups, the <a class="uri" href="F-test" title="wikilink">F-test</a>. The <em>F</em>-test is computed by dividing the explained variance between groups (e.g., gender difference) by the unexplained variance within the groups. Thus,</p>

<p><code>                </code><big><em><code>F</code></em></big><code> = </code>

<math display="inline" id="Analysis_of_covariance:8">
 <semantics>
  <mfrac>
   <mi>𝑀𝑆𝑏𝑒𝑡𝑤𝑒𝑒𝑛</mi>
   <mi>𝑀𝑆𝑤𝑖𝑡ℎ𝑖𝑛</mi>
  </mfrac>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <divide></divide>
    <ci>𝑀𝑆𝑏𝑒𝑡𝑤𝑒𝑒𝑛</ci>
    <ci>𝑀𝑆𝑤𝑖𝑡ℎ𝑖𝑛</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \frac{\mathit{MSbetween}}{\mathit{MSwithin}}
  </annotation>
 </semantics>
</math>

</p>

<p>If this value is larger than a critical value, we conclude that there is a significant difference between groups. Unexplained variance includes error variance (e.g., individual differences), as well as the influence of other factors. Therefore, the influence of CVs is grouped in the denominator. When we control for the effect of CVs on the DV, we remove it from the denominator making <em>F</em> larger, thereby increasing your power to find a significant effect if one exists at all.</p>
<figure><b>(Figure)</b>
<figcaption>Partitioning variance</figcaption>
</figure>
<h3 id="adjusting-preexisting-differences">Adjusting Preexisting Differences</h3>

<p>Another use of ANCOVA is to adjust for preexisting differences in nonequivalent (intact) groups. This controversial application aims at correcting for initial group differences (prior to group assignment) that exists on DV among several intact groups. In this situation, participants cannot be made equal through random assignment, so CVs are used to adjust scores and make participants more similar than without the CV. However, even with the use of covariates, there are no statistical techniques that can equate unequal groups. Furthermore, the CV may be so intimately related to the IV that removing the variance on the DV associated with the CV would remove considerable variance on the DV, rendering the results meaningless.<a class="footnoteRef" href="#fn5" id="fnref5"><sup>5</sup></a></p>
<h2 id="assumptions-of-ancova">Assumptions of ANCOVA</h2>

<p>There are several key assumptions that underlie the use of ANCOVA and affect interpretation of the results.<a class="footnoteRef" href="#fn6" id="fnref6"><sup>6</sup></a> The standard <a href="regression_analysis" title="wikilink">linear regression</a> assumptions hold, further we assume that the slope of the covariate is equal across all treatment groups (homogeneity of regression slopes).</p>
<h3 id="assumption-1-linearity-of-regression">''Assumption 1: Linearity of Regression ''</h3>

<p>The regression relationship between the dependent variable and concomitant variables must be linear.</p>
<h3 id="assumption-2-homogeneity-of-error-variances"><em>Assumption 2: Homogeneity of Error Variances</em></h3>

<p>The error is a random variable with conditional zero mean and equal variances for different treatment classes and observations.</p>
<h3 id="assumption-3-independence-error-terms"><em>Assumption 3: Independence Error Terms</em></h3>

<p>The errors are uncorrelated. That is that the error covariance matrix is diagonal.</p>
<h3 id="assumption-4-normality-of-error-terms"><em>Assumption 4: Normality of Error terms</em></h3>

<p>The <a href="Errors_and_residuals_in_statistics" title="wikilink">residuals (error terms)</a> should be normally distributed 

<math display="inline" id="Analysis_of_covariance:9">
 <semantics>
  <msub>
   <mi>ϵ</mi>
   <mrow>
    <mi>i</mi>
    <mi>j</mi>
   </mrow>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>ϵ</ci>
    <apply>
     <times></times>
     <ci>i</ci>
     <ci>j</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \epsilon_{ij}
  </annotation>
 </semantics>
</math>

 ~ 

<math display="inline" id="Analysis_of_covariance:10">
 <semantics>
  <mrow>
   <mi>N</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <mn>0</mn>
    <mo>,</mo>
    <msup>
     <mi>σ</mi>
     <mn>2</mn>
    </msup>
    <mo stretchy="false">)</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <ci>N</ci>
    <interval closure="open">
     <cn type="integer">0</cn>
     <apply>
      <csymbol cd="ambiguous">superscript</csymbol>
      <ci>σ</ci>
      <cn type="integer">2</cn>
     </apply>
    </interval>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   N(0,\sigma^{2})
  </annotation>
 </semantics>
</math>


.</p>
<h3 id="assumption-5-homogeneity-of-regression-slopes"><em>Assumption 5: Homogeneity of Regression Slopes</em></h3>

<p>The slopes of the different regression lines should be equivalent, i.e., regression lines should be parallel among groups.</p>

<p>The fifth issue, concerning the homogeneity of different treatment regression slopes is particularly important in evaluating the appropriateness of ANCOVA model. Also note that we only need the error terms to be normally distributed. In fact both the independent variable and the concomitant variables will not be normally distributed in most cases.</p>
<h2 id="conducting-an-ancova">Conducting an ANCOVA</h2>
<h3 id="test-multicollinearity"><em>Test <a class="uri" href="Multicollinearity" title="wikilink">Multicollinearity</a></em></h3>

<p>If a CV is highly related to another CV (at a correlation of .5 or more), then it will not adjust the DV over and above the other CV. One or the other should be removed since they are statistically redundant.</p>
<h3 id="test-the-homogeneity-of-variance-assumption"><em>Test the Homogeneity of Variance Assumption</em></h3>

<p>Tested by <a href="Levene's_test" title="wikilink">Levene's test</a> of equality of error variances. This is most important after adjustments have been made, but if you have it before adjustment you are likely to have it afterwards.</p>
<h3 id="test-the-homogeneity-of-regression-slopes-assumption"><em>Test the Homogeneity of Regression Slopes Assumption</em></h3>

<p>To see if the CV significantly interacts with the IV, run an ANCOVA model including both the IV and the CVxIV interaction term. If the CVxIV interaction is significant, ANCOVA should not be performed. Instead, Green &amp; Salkind<a class="footnoteRef" href="#fn7" id="fnref7"><sup>7</sup></a> suggest assessing group differences on the DV at particular levels of the CV. Also consider using a <a href="Moderation_(statistics)" title="wikilink">moderated regression analysis</a>, treating the CV and its interaction as another IV. Alternatively, one could use <a href="Mediation_(statistics)" title="wikilink">mediation analyses</a> to determine if the CV accounts for the IV’s effect on the DV.</p>
<h3 id="run-ancova-analysis"><em>Run ANCOVA Analysis</em></h3>

<p>If the CVxIV interaction is not significant, rerun the ANCOVA without the CVxIV interaction term. In this analysis, you need to use the adjusted means and adjusted MSerror. The adjusted means (also referred to as least squares means, LS means, estimated marginal means, or EMM) refer to the group means after controlling for the influence of the CV on the DV.</p>
<h3 id="follow-up-analyses"><em>Follow-up Analyses</em></h3>

<p>If there was a significant <a href="main_effect" title="wikilink">main effect</a>, it means that there is a significant difference between the levels of one IV, ignoring all other factors.<a class="footnoteRef" href="#fn8" id="fnref8"><sup>8</sup></a> To find exactly which levels are significantly different from one another, one can use the same follow-up tests as for the ANOVA. If there are two or more IVs, there may be a <a href="Interaction_(statistics)" title="wikilink">significant interaction</a>, which means that the effect of one IV on the DV changes depending on the level of another factor. One can investigate the simple main effects using the same methods as in a <a href="Factor_analysis" title="wikilink">factorial ANOVA</a>.</p>
<h2 id="power-considerations">Power considerations</h2>

<p>While the inclusion of a covariate into an ANOVA generally increases <a href="statistical_power" title="wikilink">statistical power</a> by accounting for some of the variance in the dependent variable and thus increasing the ratio of variance explained by the independent variables, adding a covariate into ANOVA also reduces the <a href="Degrees_of_freedom_(statistics)" title="wikilink">degrees of freedom</a>. Accordingly, adding a covariate which accounts for very little variance in the dependent variable might actually reduce power.</p>
<h2 id="see-also">See also</h2>
<ul>
<li><a class="uri" href="MANCOVA" title="wikilink">MANCOVA</a> (Multivariate analysis of covariance)</li>
<li><a href="Covariance_mapping" title="wikilink">Covariance mapping</a></li>
</ul>
<h2 id="references">References</h2>
<references>
</references>
<h2 id="external-links">External links</h2>
<ul>
<li><a href="http://www.southampton.ac.uk/~cpd/anovas/datasets/index.htm">Examples of all ANOVA and ANCOVA models with up to three treatment factors, including randomized block, split plot, repeated measures, and Latin squares, and their analysis in R</a></li>
<li><a href="http://faculty.vassar.edu/lowry/ch17pt1.html">One-Way Analysis of Covariance for Independent Samples</a></li>
<li>[<a class="uri" href="http://journals.cambridge.org/action/displayAbstract?fromPage=online&amp;aid">http://journals.cambridge.org/action/displayAbstract?fromPage=online&amp;aid;</a>;=1296348 Use of covariates in randomized controlled trials by G.J.P. Van Breukelen and K.R.A. Van Dijk (2007)]</li>
</ul>

<p>"</p>

<p><a href="Category:Analysis_of_variance" title="wikilink">Category:Analysis of variance</a> <a href="Category:Covariance_and_correlation" title="wikilink">Category:Covariance and correlation</a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1">Howell, D. C. (2009) <em>Statistical methods for psychology</em> (7th ed.). Belmont: Cengage Wadsworth.<a href="#fnref1">↩</a></li>
<li id="fn2">Keppel, G. (1991). <em>Design and analysis: A researcher's handbook</em> (3rd ed.). Englewood Cliffs: Prentice-Hall, Inc.<a href="#fnref2">↩</a></li>
<li id="fn3">Montgomery, Douglas C. "Design and analysis of experiments" (8th Ed.). John Wiley &amp; Sons, 2012.<a href="#fnref3">↩</a></li>
<li id="fn4">Tabachnick, B. G., &amp; Fidell, L. S. (2007). <em>Using Multivariate Statistics</em> (5th ed.). Boston: Pearson Education, Inc.<a href="#fnref4">↩</a></li>
<li id="fn5">Miller, G. A., &amp; Chapman, J. P. (2001). Misunderstanding Analysis of Covariance. <em>Journal of Abnormal Psychology, 110 (1),</em> 40-48.<a href="#fnref5">↩</a></li>
<li id="fn6"></li>
<li id="fn7">Green, S. B., &amp; Salkind, N. J. (2011). <em>Using SPSS for Windows and Macintosh: Analyzing and Understanding Data</em> (6th ed.). Upper Saddle River, NJ: Prentice Hall.<a href="#fnref7">↩</a></li>
<li id="fn8"></li>
</ol>
</section>
</body>
</html>
