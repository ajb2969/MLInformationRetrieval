   Matrix determinant lemma      Matrix determinant lemma   In mathematics , in particular linear algebra , the matrix determinant lemma 1 2 computes the determinant of the sum of an invertible  matrix  A and the dyadic product , u v T , of a column vector  u and a row vector v T .  Statement  Suppose A is an invertible  square matrix and u , v are column vectors . Then the matrix determinant lemma states that        det   (   ğ€  +   ğ®ğ¯  T    )    =    (   1  +    ğ¯  T    ğ€   -  1    ğ®    )    det   (  ğ€  )      .          ğ€   superscript  ğ®ğ¯  normal-T         1     superscript  ğ¯  normal-T    superscript  ğ€    1    ğ®      ğ€      \det(\mathbf{A}+\mathbf{uv}^{\mathrm{T}})=(1+\mathbf{v}^{\mathrm{T}}\mathbf{A}%
 ^{-1}\mathbf{u})\,\det(\mathbf{A})\,.     Here, uv T is the outer product of two vectors u and v .  The theorem can also be stated in terms of the adjugate matrix of A :        det   (   ğ€  +   ğ®ğ¯  T    )    =    det   (  ğ€  )    +    ğ¯  T   adj   (  ğ€  )    ğ®      ,          ğ€   superscript  ğ®ğ¯  normal-T         ğ€      superscript  ğ¯  normal-T   adj  ğ€  ğ®      \det(\mathbf{A}+\mathbf{uv}^{\mathrm{T}})=\det(\mathbf{A})+\mathbf{v}^{\mathrm%
 {T}}\mathrm{adj}(\mathbf{A})\mathbf{u}\,,   in which case it applies whether or not the square matrix A is invertible.  Proof  First the proof of the special case A = I follows from the equality: 3         (     ğˆ    0       ğ¯  T     1     )    (      ğˆ  +   ğ®ğ¯  T      ğ®      0    1     )    (     ğˆ    0       -   ğ¯  T      1     )    =   (     ğˆ    ğ®      0     1  +    ğ¯  T   ğ®       )    .          ğˆ  0     superscript  ğ¯  normal-T   1        ğˆ   superscript  ğ®ğ¯  normal-T    ğ®    0  1      ğˆ  0       superscript  ğ¯  normal-T    1       ğˆ  ğ®    0    1     superscript  ğ¯  normal-T   ğ®        \begin{pmatrix}\mathbf{I}&0\\
 \mathbf{v}^{\mathrm{T}}&1\end{pmatrix}\begin{pmatrix}\mathbf{I}+\mathbf{uv}^{%
 \mathrm{T}}&\mathbf{u}\\
 0&1\end{pmatrix}\begin{pmatrix}\mathbf{I}&0\\
 -\mathbf{v}^{\mathrm{T}}&1\end{pmatrix}=\begin{pmatrix}\mathbf{I}&\mathbf{u}\\
 0&1+\mathbf{v}^{\mathrm{T}}\mathbf{u}\end{pmatrix}.     The determinant of the left hand side is the product of the determinants of the three matrices. Since the first and third matrix are triangle matrices with unit diagonal, their determinants are just 1. The determinant of the middle matrix is our desired value. The determinant of the right hand side is simply (1 + v T u ). So we have the result:        det   (   ğˆ  +   ğ®ğ¯  T    )    =   (   1  +    ğ¯  T   ğ®    )    .          ğˆ   superscript  ğ®ğ¯  normal-T       1     superscript  ğ¯  normal-T   ğ®      \det(\mathbf{I}+\mathbf{uv}^{\mathrm{T}})=(1+\mathbf{v}^{\mathrm{T}}\mathbf{u}).     Then the general case can be found as:      det   (   ğ€  +   ğ®ğ¯  T    )         ğ€   superscript  ğ®ğ¯  normal-T      \displaystyle\det(\mathbf{A}+\mathbf{uv}^{\mathrm{T}})     Application  If the determinant and inverse of A are already known, the formula provides a numerically cheap way to compute the determinant of A corrected by the matrix uv T . The computation is relatively cheap because the determinant of A + uv T does not have to be computed from scratch (which in general is expensive). Using unit vectors for u and/or v , individual columns, rows or elements 4 of A may be manipulated and a correspondingly updated determinant computed relatively cheaply in this way.  When the matrix determinant lemma is used in conjunction with the Sherman-Morrison formula , both the inverse and determinant may be conveniently updated together.  Generalization  Suppose A is an invertible  n -by- n matrix and U , V are n -by- m matrices. Then        det   (   ğ€  +   ğ”ğ•  T    )    =    det   (    ğˆ  ğ¦   +    ğ•  T    ğ€   -  1    ğ”    )     det   (  ğ€  )      .       det    ğ€   superscript  ğ”ğ•  normal-T        det     subscript  ğˆ  ğ¦      superscript  ğ•  normal-T    superscript  ğ€    1    ğ”      det  ğ€      \operatorname{det}(\mathbf{A}+\mathbf{UV}^{\mathrm{T}})=\operatorname{det}(%
 \mathbf{I_{m}}+\mathbf{V}^{\mathrm{T}}\mathbf{A}^{-1}\mathbf{U})\operatorname{%
 det}(\mathbf{A}).     In the special case    ğ€  =   ğˆ  ğ§       ğ€   subscript  ğˆ  ğ§     \mathbf{A}=\mathbf{I_{n}}   this is Sylvester's theorem for determinants .  Given additionally an invertible m -by- m matrix W , the relationship can also be expressed as        det   (   ğ€  +   ğ”ğ–ğ•  T    )    =   det    (    ğ–   -  1    +    ğ•  T    ğ€   -  1    ğ”    )    det    (  ğ–  )    det   (  ğ€  )         .       det    ğ€   superscript  ğ”ğ–ğ•  normal-T            superscript  ğ–    1       superscript  ğ•  normal-T    superscript  ğ€    1    ğ”        ğ–    ğ€         \operatorname{det}(\mathbf{A}+\mathbf{UWV}^{\mathrm{T}})=\det(\mathbf{W}^{-1}+%
 \mathbf{V}^{\mathrm{T}}\mathbf{A}^{-1}\mathbf{U})\det(\mathbf{W})\det(\mathbf{%
 A}).     See also   The Sherman-Morrison formula , which shows how to update the inverse, A âˆ’1 , to obtain ( A + uv T ) âˆ’1 .  The Woodbury formula , which shows how to update the inverse, A âˆ’1 , to obtain ( A + UCV T ) âˆ’1 .  The binomial inverse theorem for ( A + UCV T ) âˆ’1 .   References    "  Category:Linear algebra  Category:Matrix theory  Category:Lemmas     â†©  â†©  â†©  â†©     