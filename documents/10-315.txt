   Orthogonal Procrustes problem      Orthogonal Procrustes problem   The orthogonal Procrustes problem  1 is a matrix approximation problem in linear algebra . In its classical form, one is given two matrices    A   A   A   and   B   B   B   and asked to find an orthogonal matrix    R   R   R   which most closely maps   A   A   A   to   B   B   B   . 2 Specifically,        R  =     arg   min  Ω      ∥    A  Ω   -  B   ∥   F      subject   to        Ω  T   Ω   =  I    ,     formulae-sequence    R        subscript   normal-Ω     subscript   norm      A  normal-Ω   B    F      subject  to          superscript  normal-Ω  T   normal-Ω   I     R=\arg\min_{\Omega}\|A\Omega-B\|_{F}\quad\mathrm{subject\ to}\quad\Omega^{T}%
 \Omega=I,     where    ∥  ⋅   ∥  F      fragments  parallel-to  normal-⋅   subscript  parallel-to  F     \|\cdot\|_{F}   denotes the Frobenius norm .  The name Procrustes refers to a bandit from Greek mythology who made his victims fit his bed by either stretching their limbs or cutting them off.  Solution  This problem was originally solved by Peter Schonemann in a 1964 thesis. The individual solution was later published. 3 A proof is also given in 4  This problem is equivalent to finding the nearest orthogonal matrix to a given matrix    M  =    A  T   B       M     superscript  A  T   B     M=A^{T}B   . To find this orthogonal matrix   R   R   R   , one uses the singular value decomposition      M  =   U  Σ   V  T        M    U  normal-Σ   superscript  V  T      M=U\Sigma V^{T}\,\!   to write       R  =   U   V  T     .      R    U   superscript  V  T      R=UV^{T}.\,\!     Proof  One proof depends on basic properties of the standard matrix inner product that induces the Frobenius norm:     R   R   \displaystyle R     Generalized/constrained Procrustes problems  There are a number of related problems to the classical orthogonal Procrustes problem. One might generalize it by seeking the closest matrix in which the columns are orthogonal , but not necessarily orthonormal . 5  Alternately, one might constrain it by only allowing rotation matrices (i.e. orthogonal matrices with determinant 1, also known as special orthogonal matrices ). In this case, one can write (using the above decomposition    M  =   U  Σ   V  T        M    U  normal-Σ   superscript  V  T      M=U\Sigma V^{T}   )       R  =   U   Σ  ′    V  T     ,      R    U   superscript  normal-Σ  normal-′    superscript  V  T      R=U\Sigma^{\prime}V^{T},\,\!     where    Σ  ′     superscript  normal-Σ  normal-′    \Sigma^{\prime}\,\!   is a modified   Σ   normal-Σ   \Sigma\,\!   , with the smallest singular value replaced by    sign   (   det   (   U   V  T    )    )      sign      U   superscript  V  T       \operatorname{sign}(\det(UV^{T}))   (+1 or -1), and the other singular values replaced by 1, so that the determinant of R is guaranteed to be positive. 6 For more information, see the Kabsch algorithm .  See also   Procrustes analysis  Procrustes transformation   References    "  Category:Linear algebra  Category:Matrix theory  Category:Singular value decomposition     ↩  ↩  ↩  ↩  ↩  ↩     