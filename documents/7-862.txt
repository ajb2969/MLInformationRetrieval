   Variance decomposition of forecast errors      Variance decomposition of forecast errors   In econometrics and other applications of multivariate time series analysis , a variance decomposition or forecast error variance decomposition (FEVD) is used to aid in the interpretation of a vector autoregression (VAR) model once it has been fitted. 1 The variance decomposition indicates the amount of information each variable contributes to the other variables in the autoregression. It determines how much of the forecast error variance of each of the variables can be explained by exogenous shocks to the other variables.  Calculating the forecast error variance  For the VAR (p) of form       y  t   =   ŒΩ  +    A  1    y   t  -  1     +  ‚Ä¶  +    A  p    y   t  -  p     +   u  t         subscript  y  t     ŒΩ     subscript  A  1    subscript  y    t  1     normal-‚Ä¶     subscript  A  p    subscript  y    t  p      subscript  u  t      y_{t}=\nu+A_{1}y_{t-1}+\dots+A_{p}y_{t-p}+u_{t}   .  This can be changed to a VAR(1) structure by writing it in companion form (see general matrix notation of a VAR(p) )       Y  t   =   V  +   A   Y   t  -  1     +   U  t         subscript  Y  t     V    A   subscript  Y    t  1      subscript  U  t      Y_{t}=V+AY_{t-1}+U_{t}   where         A=\begin{bmatrix} A_1 & A_2 & \dots & A_{p-1} & A_p \\ \mathbf{I}_k & 0 & \dots & 0 & 0 \\ 0 & \mathbf{I}_k & & 0 & 0 \\ \vdots & & \ddots & \vdots & \vdots \\ 0 & 0 & \dots & \mathbf{I}_k & 0 \\ \end{bmatrix}  ,    Y  =   [      y  1       ‚ãÆ       y  p      ]       Y     subscript  y  1     normal-‚ãÆ     subscript  y  p       Y=\begin{bmatrix}y_{1}\\
 \vdots\\
 y_{p}\end{bmatrix}   ,    V  =   [     ŒΩ      0      ‚ãÆ      0     ]       V    ŒΩ    0    normal-‚ãÆ    0      V=\begin{bmatrix}\nu\\
 0\\
 \vdots\\
 0\end{bmatrix}   and     U  t   =   [      u  t       0      ‚ãÆ      0     ]        subscript  U  t      subscript  u  t     0    normal-‚ãÆ    0      U_{t}=\begin{bmatrix}u_{t}\\
 0\\
 \vdots\\
 0\end{bmatrix}     where    y  t     subscript  y  t    y_{t}   ,   ŒΩ   ŒΩ   \nu   and   u   u   u   are   k   k   k   dimensional column vectors,   A   A   A   is    k  p      k  p    kp   by    k  p      k  p    kp   dimensional matrix and   Y   Y   Y   ,   V   V   V   and   U   U   U   are    k  p      k  p    kp   dimensional column vectors.  The mean squared error of the h-step forecast of variable j is        ùêåùêíùêÑ   [    y   j  ,  t     (  h  )    ]    =    ‚àë   i  =  0    h  -  1      ‚àë   k  =  1   K     (    e  j  ‚Ä≤    Œò  i    e  k    )   2     =    (    ‚àë   i  =  0    h  -  1      Œò  i    Œò  i  ‚Ä≤     )    j  j    =    (    ‚àë   i  =  0    h  -  1      Œ¶  i    Œ£  u    Œ¶  i  ‚Ä≤     )    j  j     ,          ùêåùêíùêÑ   delimited-[]     subscript  y   j  t    h       superscript   subscript     i  0      h  1      superscript   subscript     k  1    K    superscript     superscript   subscript  e  j   normal-‚Ä≤    subscript  normal-Œò  i    subscript  e  k    2           subscript    superscript   subscript     i  0      h  1       subscript  normal-Œò  i    superscript   subscript  normal-Œò  i   normal-‚Ä≤       j  j          subscript    superscript   subscript     i  0      h  1       subscript  normal-Œ¶  i    subscript  normal-Œ£  u    superscript   subscript  normal-Œ¶  i   normal-‚Ä≤       j  j       \mathbf{MSE}[y_{j,t}(h)]=\sum_{i=0}^{h-1}\sum_{k=1}^{K}(e_{j}^{\prime}\Theta_{%
 i}e_{k})^{2}=\bigg(\sum_{i=0}^{h-1}\Theta_{i}\Theta_{i}^{\prime}\bigg)_{jj}=%
 \bigg(\sum_{i=0}^{h-1}\Phi_{i}\Sigma_{u}\Phi_{i}^{\prime}\bigg)_{jj},   and where  :*    e  j     subscript  e  j    e_{j}   is the j th column of    I  K     subscript  I  K    I_{K}   and the subscript    j  j      j  j    jj   refers to that element of the matrix  :*      Œò  i   =    Œ¶  i   P    ,       subscript  normal-Œò  i      subscript  normal-Œ¶  i   P     \Theta_{i}=\Phi_{i}P,   where   P   P   P   is a lower triangular matrix obtained by a Cholesky decomposition of    Œ£  u     subscript  normal-Œ£  u    \Sigma_{u}   such that     Œ£  u   =   P   P  ‚Ä≤         subscript  normal-Œ£  u     P   superscript  P  normal-‚Ä≤      \Sigma_{u}=PP^{\prime}   , where    Œ£  u     subscript  normal-Œ£  u    \Sigma_{u}   is the covariance matrix of the errors    u  t     subscript  u  t    u_{t}     :*      Œ¶  i   =   J   A  i    J  ‚Ä≤     ,       subscript  normal-Œ¶  i     J   superscript  A  i    superscript  J  normal-‚Ä≤      \Phi_{i}=JA^{i}J^{\prime},   where     J  =   [      ùêà  k     0    ‚Ä¶    0     ]    ,      J     subscript  ùêà  k   0  normal-‚Ä¶  0      J=\begin{bmatrix}\mathbf{I}_{k}&0&\dots&0\end{bmatrix},   so that   J   J   J   is a   k   k   k   by    k  p      k  p    kp   dimensional matrix.  The amount of forecast error variance of variable   j   j   j   accounted for by exogenous shocks to variable   k   k   k   is given by     œâ    j  k   ,  h    ,     subscript  œâ     j  k   h     \omega_{jk,h},           œâ    j  k   ,  h    =    ‚àë   i  =  0    h  -  1        (    e  j  ‚Ä≤    Œò  i    e  k    )   2   /  M   S  E   [    y   j  ,  t     (  h  )    ]      .       subscript  œâ     j  k   h      superscript   subscript     i  0      h  1         superscript     superscript   subscript  e  j   normal-‚Ä≤    subscript  normal-Œò  i    subscript  e  k    2   M   S  E   delimited-[]     subscript  y   j  t    h        \omega_{jk,h}=\sum_{i=0}^{h-1}(e_{j}^{\prime}\Theta_{i}e_{k})^{2}/MSE[y_{j,t}(%
 h)].     Notes  "  Category:Econometrics  Category:Multivariate time series analysis     L√ºtkepohl, H. (2007) New Introduction to Multiple Time Series Analysis , Springer. p.¬†63. ‚Ü©     