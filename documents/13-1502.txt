   Divergence (statistics)      Divergence (statistics)   In statistics and information geometry , divergence or a contrast function is a function which establishes the "distance" of one probability distribution to the other on a statistical manifold . The divergence is a weaker notion than that of the distance , in particular the divergence need not be symmetric (that is, in general the divergence from p to q is not equal to the divergence from q to p ), and need not satisfy the triangle inequality .  Definition  Suppose S is a space of all probability distributions with common support. Then a divergence on S is a function  satisfying 1   D ( p || q ) ≥ 0 for all p , q ∈ S ,  D ( p || q ) = 0 if and only if p = q ,   The dual divergence  D* is defined as       D  *    (  p  ∥  q  )   =  D   (  q  ∥  p  )   .     fragments   superscript  D     fragments  normal-(  p  parallel-to  q  normal-)    D   fragments  normal-(  q  parallel-to  p  normal-)   normal-.    D^{*}(p\parallel q)=D(q\parallel p).     Geometrical properties  Many properties of divergences can be derived if we restrict S to be a statistical manifold , meaning that it can be parametrized with a finite-dimensional coordinate system θ , so that for a distribution  we can write .  For a pair of points  with coordinates θ p and θ q , denote the partial derivatives of D ( p || q ) as      D   (    (   ∂  i   )   p   ∥  q  )      fragments  D   fragments  normal-(   subscript   fragments  normal-(   subscript   i   normal-)   p   parallel-to  q  normal-)     \displaystyle D((\partial_{i})_{p}\parallel q)   Now we restrict these functions to a diagonal , and denote 2      D   [   ∂  i   ∥  ⋅  ]      fragments  D   fragments  normal-[   subscript   i   parallel-to  normal-⋅  normal-]     \displaystyle D[\partial_{i}\parallel\cdot]     By definition, the function D ( p || q ) is minimized at , and therefore      D   [   ∂  i   ∥  ⋅  ]   =  D   [  ⋅  ∥   ∂  i   ]   =  0  ,     fragments  D   fragments  normal-[   subscript   i   parallel-to  normal-⋅  normal-]    D   fragments  normal-[  normal-⋅  parallel-to   subscript   i   normal-]    0  normal-,    \displaystyle D[\partial_{i}\parallel\cdot]=D[\cdot\parallel\partial_{i}]=0,   where matrix g ( D ) is positive semi-definite and defines a unique Riemannian metric on the manifold S .  Divergence D (· || ·) also defines a unique torsion -free affine connection ∇ ( D ) with coefficients       Γ    i  j   ,  k    (  D  )    =  -  D   [   ∂  i    ∂  j   ∥   ∂  k   ]   ,     fragments   superscript   subscript  normal-Γ     i  j   k    D     D   fragments  normal-[   subscript   i    subscript   j   parallel-to   subscript   k   normal-]   normal-,    \Gamma_{ij,k}^{(D)}=-D[\partial_{i}\partial_{j}\parallel\partial_{k}],   and the dual to this connection ∇* is generated by the dual divergence D *.  Thus, a divergence D (· || ·) generates on a statistical manifold a unique dualistic structure ( g ( D ) , ∇ ( D ) , ∇ ( D *) ). The converse is also true: every torsion-free dualistic structure on a statistical manifold is induced from some globally defined divergence function (which however need not be unique). 3  For example, when D is an f-divergence for some function ƒ(·), then it generates the metric  and the connection , where g is the canonical Fisher information metric , ∇ ( α ) is the α-connection , , and .  Examples  The largest and most frequently used class of divergences form the so-called f-divergences , however other types of divergence functions are also encountered in the literature.  f-divergences  This family of divergences are generated through functions f ( u ), convex on  and such that . Then an f -divergence is defined as       D  f    (  p  ∥  q  )   =  ∫  p   (  x  )   f   (    q   (  x  )     p   (  x  )     )   d  x     fragments   subscript  D  f    fragments  normal-(  p  parallel-to  q  normal-)     p   fragments  normal-(  x  normal-)   f   fragments  normal-(      q  x     p  x    normal-)   d  x    D_{f}(p\parallel q)=\int p(x)f\bigg(\frac{q(x)}{p(x)}\bigg)dx         Kullback–Leibler divergence :        D  KL    (  p  ∥  q  )   =  ∫  p   (  x  )   ln   (    p   (  x  )     q   (  x  )     )   d  x     fragments   subscript  D  KL    fragments  normal-(  p  parallel-to  q  normal-)     p   fragments  normal-(  x  normal-)     fragments  normal-(      p  x     q  x    normal-)   d  x    D_{\mathrm{KL}}(p\parallel q)=\int p(x)\ln\left(\frac{p(x)}{q(x)}\right)dx        squared Hellinger distance :         H  2    (  p  ,  q  )    =   2   ∫     (     p   (  x  )     -     q   (  x  )       )   2   d  x            superscript  H  2    p  q      2       superscript        p  x        q  x     2   d  x       H^{2}(p,\,q)=2\int\Big(\sqrt{p(x)}-\sqrt{q(x)}\,\Big)^{2}dx        Jeffreys divergence:        D  J    (  p  ∥  q  )   =  ∫   (  p   (  x  )   -  q   (  x  )   )    (  ln  p   (  x  )   -  ln  q   (  x  )   )   d  x     fragments   subscript  D  J    fragments  normal-(  p  parallel-to  q  normal-)      fragments  normal-(  p   fragments  normal-(  x  normal-)    q   fragments  normal-(  x  normal-)   normal-)    fragments  normal-(   p   fragments  normal-(  x  normal-)     q   fragments  normal-(  x  normal-)   normal-)   d  x    D_{J}(p\parallel q)=\int(p(x)-q(x))\big(\ln p(x)-\ln q(x)\big)dx        Chernoff's α-divergence :        D   (  α  )     (  p  ∥  q  )   =   4   1  -   α  2      (  1  -  ∫  p    (  x  )     1  -  α   2    q    (  x  )     1  +  α   2    d  x  )      fragments   superscript  D  α    fragments  normal-(  p  parallel-to  q  normal-)      4    1   superscript  α  2      fragments  normal-(  1    p   superscript   fragments  normal-(  x  normal-)       1  α   2    q   superscript   fragments  normal-(  x  normal-)       1  α   2    d  x  normal-)     D^{(\alpha)}(p\parallel q)=\frac{4}{1-\alpha^{2}}\bigg(1-\int p(x)^{\frac{1-%
 \alpha}{2}}q(x)^{\frac{1+\alpha}{2}}dx\bigg)        exponential divergence:        D  e    (  p  ∥  q  )   =  ∫  p   (  x  )     (  ln  p   (  x  )   -  ln  q   (  x  )   )   2   d  x     fragments   subscript  D  e    fragments  normal-(  p  parallel-to  q  normal-)     p   fragments  normal-(  x  normal-)    superscript   fragments  normal-(   p   fragments  normal-(  x  normal-)     q   fragments  normal-(  x  normal-)   normal-)   2   d  x    D_{e}(p\parallel q)=\int p(x)\big(\ln p(x)-\ln q(x)\big)^{2}dx        Kagan's divergence:        D   χ  2     (  p  ∥  q  )   =   1  2   ∫     (    p   (  x  )    -   q   (  x  )     )   2    p   (  x  )     d  x     fragments   subscript  D   superscript  χ  2     fragments  normal-(  p  parallel-to  q  normal-)      1  2       superscript      p  x     q  x    2     p  x    d  x    D_{\chi^{2}}(p\parallel q)=\frac{1}{2}\int\frac{(p(x)-q(x))^{2}}{p(x)}dx        ( α , β )-product divergence:        D   α  ,  β     (  p  ∥  q  )   =   2    (   1  -  α   )    (   1  -  β   )     ∫   (  1  -    (    q   (  x  )     p   (  x  )     )      1  -  α   2     )    (  1  -    (    q   (  x  )     p   (  x  )     )      1  -  β   2     )   p   (  x  )   d  x     fragments   subscript  D   α  β     fragments  normal-(  p  parallel-to  q  normal-)      2      1  α     1  β       fragments  normal-(  1    superscript   fragments  normal-(      q  x     p  x    normal-)       1  α   2    normal-)    fragments  normal-(  1    superscript   fragments  normal-(      q  x     p  x    normal-)       1  β   2    normal-)   p   fragments  normal-(  x  normal-)   d  x    D_{\alpha,\beta}(p\parallel q)=\frac{2}{(1-\alpha)(1-\beta)}\int\Big(1-\Big(%
 \tfrac{q(x)}{p(x)}\Big)^{\!\!\frac{1-\alpha}{2}}\Big)\Big(1-\Big(\tfrac{q(x)}{%
 p(x)}\Big)^{\!\!\frac{1-\beta}{2}}\Big)p(x)dx        M-divergences  S-divergences  See also   Statistical distance   References        "  Category:Statistical distance measures  Category:F-divergences     ↩  ↩  ↩     