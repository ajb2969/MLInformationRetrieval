   Best linear unbiased prediction      Best linear unbiased prediction   In statistics , best linear unbiased prediction ( BLUP ) is used in linear mixed models for the estimation of random effects . BLUP was derived by Charles Roy Henderson in 1950 but the term "best linear unbiased predictor" (or "prediction") seems not to have been used until 1962. 1 "Best linear unbiased predictions" (BLUPs) of random effects are similar to best linear unbiased estimates (BLUEs) (see Gauss–Markov theorem ) of fixed effects. The distinction arises because it is conventional to talk about estimating fixed effects but predicting random effects, but the two terms are otherwise equivalent. (This is a bit strange since the random effects have already been "realized" − they already exist. The use of the term "prediction" may be because in the field of animal breeding in which Henderson worked, the random effects were usually genetic merit, which could be used to predict the quality of offspring (Robinson 2 page 28)). However, the equations for the "fixed" effects and for the random effects are different.  In practice, it is often the case that the parameters associated with the random effect(s) term(s) are unknown; these parameters are the variances of the random effects and residuals. Typically the parameters are estimated and plugged into the predictor, leading to the Empirical Best Linear Unbiased Predictor (EBLUP). Notice that by simply plugging in the estimated parameter into the predictor, additional variability is unaccounted for, leading to overly optimistic prediction variances for the EBLUP.  Best linear unbiased predictions are similar to empirical Bayes estimates of random effects in linear mixed models, except that in the latter case, where weights depend on unknown values of components of variance, these unknown variances are replaced by sample-based estimates.  Example  Suppose that the model for observations { Y j ; j = 1, ..., n } is written as        Y  j   =   μ  +    x  j  T   β   +   ξ  j   +   ε  j     ,       subscript  Y  j     μ     superscript   subscript  x  j   T   β    subscript  ξ  j    subscript  ε  j      Y_{j}=\mu+x_{j}^{T}\beta+\xi_{j}+\varepsilon_{j},\,     where ξ j and ε j represent the random effect and observation error for observation j , and suppose they are uncorrelated and have known variances σ ξ 2 and σ ε 2 , respectively. Further, x j is a vector of independent variables for the j th observation and β is a vector of regression parameters. The BLUP problem of providing an estimate of the observation-error-free value for the k th observation,         Y  k   ~   =   μ  +    x  k  T   β   +   ξ  k     ,       normal-~   subscript  Y  k      μ     superscript   subscript  x  k   T   β    subscript  ξ  k      \tilde{Y_{k}}=\mu+x_{k}^{T}\beta+\xi_{k},     can be formulated as requiring that the coefficients of a linear predictor, defined as         Y  k   ^   =    ∑   j  =  1   n     c   j  ,  k     Y  j      ,       normal-^   subscript  Y  k      superscript   subscript     j  1    n      subscript  c   j  k     subscript  Y  j       \widehat{Y_{k}}=\sum_{j=1}^{n}c_{j,k}Y_{j},     should be chosen so as to minimise the variance of the prediction error,       V  =   Var   (     Y  k   ~   -    Y  k   ^    )     ,      V   Var     normal-~   subscript  Y  k     normal-^   subscript  Y  k        V=\operatorname{Var}(\tilde{Y_{k}}-\widehat{Y_{k}}),     subject to the condition that the predictor is unbiased,       E   (     Y  k   ~   -    Y  k   ^    )    =  0.       normal-E     normal-~   subscript  Y  k     normal-^   subscript  Y  k      0.    \operatorname{E}(\tilde{Y_{k}}-\widehat{Y_{k}})=0.     BLUP vs BLUE  In contrast to the case of best linear unbiased estimation , the "quantity to be estimated",     Y  k   ~     normal-~   subscript  Y  k     \tilde{Y_{k}}   , not only has a contribution from a random element but one of the observed quantities, specifically    Y  k     subscript  Y  k    Y_{k}   which contributes to     Y  k   ^     normal-^   subscript  Y  k     \widehat{Y_{k}}   , also has a contribution from this same random element.  In contrast to BLUE, BLUP takes into account known or estimated variances. 3  See also   Minimum mean square error   Tutorials   Estimating BLUPs and Heritability Using R  Genomic Relationships and GBLUP  Ridge Regression, rrBLUP for Genome-Wide Selection   Notes    References    Xu-Qing Liu, Jian-Ying Rong, Xiu-Ying Liu (2008), "Best linear unbiased prediction for linear combinations in general mixed linear models", Journal of Multivariate Analysis , 99 (8),1503–1517. .   "  Category:Statistical methods  Category:Estimation theory     ↩   ↩     