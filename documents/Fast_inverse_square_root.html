<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title offset="1856">Fast inverse square root</title>
   <script type="text/javascript"
      src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js">
    </script>
</head>
<body>
<h1>Fast inverse square root</h1>
<style>
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
<style>
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
  </style>
</head>
<body>
<hr/>
<figure><b>(Figure)</b>
<figcaption>Lighting and reflection calculations (shown here in the <a href="first-person_shooter" title="wikilink">first-person shooter</a> <em><a class="uri" href="OpenArena" title="wikilink">OpenArena</a></em>) use the fast inverse square root code to compute <a href="Angle_of_incidence" title="wikilink">angles of incidence</a> and reflection.</figcaption>
</figure>
<p><strong>Fast inverse square root</strong> (sometimes referred to as <strong>Fast InvSqrt()</strong> or by the <a class="uri" href="hexadecimal" title="wikilink">hexadecimal</a> constant <strong>0x5f3759df</strong>) is a method of calculating x<sup>−½</sup>, the <a href="Multiplicative_inverse" title="wikilink">reciprocal</a> (or multiplicative inverse) of a <a href="square_root" title="wikilink">square root</a> for a 32-bit <a href="floating_point" title="wikilink">floating point</a> number in <a href="Single_precision_floating-point_format#IEEE_754_single_precision_binary_floating-point_format:_binary32" title="wikilink">IEEE 754 floating point format</a>. The algorithm was probably developed at <a href="Silicon_Graphics" title="wikilink">Silicon Graphics</a> in the early 1990s, and an implementation appeared in 1999 in the <em><a href="Quake_III_Arena" title="wikilink">Quake III Arena</a></em> source code, but the method did not appear on public forums such as <a class="uri" href="Usenet" title="wikilink">Usenet</a> until 2002 or 2003. <a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a> (There is a discussion on Chinese developer forum CSDN back in 2000 <a class="footnoteRef" href="#fn2" id="fnref2"><sup>2</sup></a>) At the time, the primary advantage of the algorithm came from avoiding <a href="computationally_expensive" title="wikilink">computationally expensive</a> floating point operations in favor of integer operations. Inverse square roots are used to compute <a href="angles_of_incidence" title="wikilink">angles of incidence</a> and <a href="Reflection_(computer_graphics)" title="wikilink">reflection</a> for <a class="uri" href="lighting" title="wikilink">lighting</a> and <a class="uri" href="shading" title="wikilink">shading</a> in <a href="computer_graphics" title="wikilink">computer graphics</a>.</p>
<p>The algorithm accepts a 32-bit floating point number as the input and stores a halved value for later use. Then, treating the bits representing the floating point number as a 32-bit integer, a <a href="logical_shift" title="wikilink">logical shift</a> right of one bit is performed and the result subtracted from the magic number <a href="Hexadecimal#Representing_hexadecimal" title="wikilink">0x</a>5f3759df. This is the first approximation of the inverse square root of the input. Treating the bits again as floating point it runs one iteration of <a href="Newton's_method" title="wikilink">Newton's method</a> to return a more precise approximation. This computes an approximation of the inverse square root of a floating point number approximately four times faster than <a href="floating_point_arithmetic" title="wikilink">floating point division</a>.</p>
<p>The algorithm was originally attributed to <a href="John_D._Carmack" title="wikilink">John Carmack</a>, but an investigation showed that the code had deeper roots in both the hardware and software side of computer graphics. Adjustments and alterations passed through both Silicon Graphics and <a href="3dfx_Interactive" title="wikilink">3dfx Interactive</a>, with Gary Tarolli's implementation for the <a href="SGI_Indigo" title="wikilink">SGI Indigo</a> as the earliest known use. It is not known how the constant was originally derived, though investigation has shed some light on possible methods.</p>
<h2 id="motivation">Motivation</h2>
<p> The inverse square root of a floating point number is used in calculating a <a href="Unit_vector" title="wikilink">normalized vector</a>. Since a <a href="3D_graphics" title="wikilink">3D graphics</a> program uses these normalized vectors to determine lighting and <a href="Lambert's_cosine_law" title="wikilink">reflection</a>, millions of these calculations must be done per second. Before the creation of specialized hardware to handle <a href="Transform,_clipping,_and_lighting" title="wikilink">transform and lighting</a>, software computations could be slow. Specifically, when the code was developed in the early 1990s, most floating point processing power lagged behind the speed of integer processing.<a class="footnoteRef" href="#fn3" id="fnref3"><sup>3</sup></a></p>
<p>To normalize a vector, the length of the vector is determined by calculating its <a href="Euclidean_norm" title="wikilink">Euclidean norm</a>: the square root of the sum of squares of the <a href="vector_components" title="wikilink">vector components</a>. When each component of the vector is divided by that length, the new vector will be a <a href="unit_vector" title="wikilink">unit vector</a> pointing in the same direction.</p>
<p><span class="LaTeX">$$\|\boldsymbol{v}\| = \sqrt{v_1^2+v_2^2+v_3^2}$$</span> is the Euclidean norm of the vector, analogous to the calculation of the <a href="Euclidean_distance" title="wikilink">Euclidean distance</a> between two points in <a href="Euclidean_space" title="wikilink">Euclidean space</a>.</p>
<p><span class="LaTeX">$$\boldsymbol{\hat{v}} = \boldsymbol{v} / \|\boldsymbol{v}\|$$</span> is the normalized (unit) vector. Using <span class="LaTeX">$\|\boldsymbol{v}\|^2$</span> to represent <span class="LaTeX">$v_1^2+v_2^2+v_3^2$</span>,</p>
<p><span class="LaTeX">$$\boldsymbol{\hat{v}} = \boldsymbol{v} / \sqrt{\|\boldsymbol{v}\|^2}$$</span>, which relates the unit vector to the inverse square root of the distance components.</p>
<p><em>Quake III Arena</em> used the fast inverse square root algorithm to speed graphics processing unit computation, but the algorithm has since been implemented in some dedicated hardware <a href="vertex_shader" title="wikilink">vertex shaders</a> using <a href="field-programmable_gate_array" title="wikilink">field-programmable gate arrays</a> (FPGA).</p>
<h2 id="overview-of-the-code">Overview of the code</h2>
<p>The following code is the fast inverse square root implementation from <em><a href="Quake_III_Arena" title="wikilink">Quake III Arena</a></em>, stripped of <a href="C_preprocessor" title="wikilink">C preprocessor</a> directives, but including the exact original comment text:<a class="footnoteRef" href="#fn4" id="fnref4"><sup>4</sup></a></p>
<div class="sourceCode"><pre class="sourceCode c"><code class="sourceCode c"><span class="dt">float</span> Q_rsqrt( <span class="dt">float</span> number )
{
    <span class="dt">long</span> i;
    <span class="dt">float</span> x2, y;
    <span class="dt">const</span> <span class="dt">float</span> threehalfs = <span class="fl">1.</span>5F;

    x2 = number * <span class="fl">0.</span>5F;
    y  = number;
    i  = * ( <span class="dt">long</span> * ) &y;                       <span class="co">// evil floating point bit level hacking</span>
    i  = <span class="bn">0x5f3759df</span> - ( i >> <span class="dv">1</span> );               <span class="co">// what the fuck? </span>
    y  = * ( <span class="dt">float</span> * ) &i;
    y  = y * ( threehalfs - ( x2 * y * y ) );   <span class="co">// 1st iteration</span>
<span class="co">//  y  = y * ( threehalfs - ( x2 * y * y ) );   // 2nd iteration, this can be removed</span>

    <span class="kw">return</span> y;
}</code></pre></div>
<p>In order to determine the inverse square root, an approximation for <span class="LaTeX">$x^{-1/2}$</span> would be determined by the software, then some numerical method would revise that approximation until it came within an acceptable error range of the actual result. <a href="Methods_of_computing_square_roots" title="wikilink">Common software methods</a> in the early 1990s drew a first approximation from a <a href="lookup_table" title="wikilink">lookup table</a>. This bit of code proved faster than table lookups and approximately four times faster than regular floating point division. Some loss of precision occurred, but was offset by the significant gains in performance. The algorithm was designed with the <a href="IEEE_754-1985" title="wikilink">IEEE 754-1985</a> 32-bit floating point specification in mind, but investigation from Chris Lomont and later Charles McEniry showed that it could be implemented in other floating point specifications.</p>
<p>The advantages in speed offered by the fast inverse square root <a href="Kludge#In_computer_science" title="wikilink">kludge</a> came from treating the longword<a class="footnoteRef" href="#fn5" id="fnref5"><sup>5</sup></a> containing the floating point number as an integer then subtracting it from a specific constant, <strong>0x5f3759df</strong>. The purpose of the constant is not immediately clear to someone viewing the code, so, like other such constants found in code, it is often called a <a href="Magic_number_(programming)#Unnamed_numerical_constants" title="wikilink">magic number</a>.<a class="footnoteRef" href="#fn6" id="fnref6"><sup>6</sup></a> This integer subtraction and bit shift results in a longword which when treated as a floating point number is a rough approximation for the inverse square root of the input number. One iteration of Newton's method is performed to gain some precision, and the code is finished. The algorithm generates reasonably accurate results using a unique first approximation for <a href="Newton's_method" title="wikilink">Newton's method</a>; however, it is much slower and less accurate than using the <a href="Streaming_SIMD_Extensions" title="wikilink">SSE</a> instruction <code>rsqrtss</code> on x86 processors also released in 1999.<a class="footnoteRef" href="#fn7" id="fnref7"><sup>7</sup></a></p>
<h3 id="a-worked-example">A worked example</h3>
<p>As an example, consider the number <span class="LaTeX">$x = 0.15625$</span>, for which we want to calculate <span class="LaTeX">$1/  ≈ 2.52982$</span>. The first steps of the algorithm are illustrated below:</p>
<p><code>00111110001000000000000000000000  Bit pattern of both x and i</code><br/>
<code>00011111000100000000000000000000  Shift right one position: (i >> 1)</code><br/>
<code>01011111001101110101100111011111  The magic number 0x5f3759df</code><br/>
<code>01000000001001110101100111011111  The result of 0x5f3759df - (i >> 1)</code></p>
<p>Reinterpreting this last bit pattern as a floating point number gives the approximation <span class="LaTeX">$y = 2.61486$</span>, which has an error of about 3.4%. After the single iteration of Newton's method, the final result is <span class="LaTeX">$y = 2.52549$</span>, in error by only 0.17%.</p>
<h2 id="working-of-the-algorithm">Working of the algorithm</h2>
<p>The algorithm computes <span class="LaTeX">$1/ $</span> by performing the following steps:</p>
<ol>
<li>Alias the argument <span class="LaTeX">$x$</span> to an integer, as a way to compute an approximation of <mtpl></mtpl></li>
<li>use this approximation to compute an approximation of <mtpl></mtpl></li>
<li>alias back to a float, as a way to compute an approximation of the base-2 exponential</li>
<li>refine the approximation using a single iteration of the Newton's method.</li>
</ol>
<h3 id="floating-point-representation">Floating point representation</h3>
<p>Since this algorithm relies heavily on the bit-level representation of single-precision floating point numbers, a short overview of this representation is provided here. In order to encode a non-zero real number <span class="LaTeX">$x$</span> as a single precision float, the first step is to write <span class="LaTeX">$x$</span> as a <a href="Normalized_number" title="wikilink">normalized</a> binary number:</p>
<p><span class="LaTeX">$$\begin{align}
x &= \pm 1.b_1b_2b_3\ldots \times 2^{e_x}\\
  &= \pm 2^{e_x} (1 + m_x)
\end{align}$$</span></p>
<p>where the exponent <mtpl></mtpl> is an integer, <mtpl></mtpl>, and <mtpl></mtpl> is the binary representation of the “significand” <mtpl></mtpl>. It should be noted that, since the single bit before the point in the significand is always 1, it need not be stored. From this form, three unsigned integers are computed:</p>
<ul>
<li><mtpl></mtpl>, the “sign bit”, is 0 if <span class="LaTeX">$x > 0$</span>, and 1 if <span class="LaTeX">$x  (1 bit)</span></li>
<li><mtpl> <em>e<sub>x</sub></em> + <em>B</em>}}</mtpl> is the “biased exponent”, where <span class="LaTeX">$B = 127$</span> is the “<a href="exponent_bias" title="wikilink">exponent bias</a>”<a class="footnoteRef" href="#fn8" id="fnref8"><sup>8</sup></a> (8 bits)</li>
<li><mtpl> <em>m<sub>x</sub></em> × <em>L</em>}}</mtpl>, where <mtpl> 2<sup>23</sup>}}</mtpl><a class="footnoteRef" href="#fn9" id="fnref9"><sup>9</sup></a> (23 bits)</li>
</ul>
<p>These fields are then packed, left to right, into a 32 bit container.</p>
<p>As an example, consider again the number <mtpl> 0.15625 {{=}} 0.00101<sub>2</sub>}}</mtpl>. Normalizing <span class="LaTeX">$x$</span> yields:</p>
<p><span class="LaTeX">$$x = +2^{-3}(1 + 0.25)$$</span></p>
<p>and thus, the three unsigned integer fields are:</p>
<ul>
<li><span class="LaTeX">$S = 0$</span></li>
<li><mtpl> −3 + 127 {{=}} 124 {{=}} 01111100<sub>2</sub>}}</mtpl></li>
<li><mtpl> 0.25 × 2<sup>23</sup> {{=}} 2097152 {{=}} 01000000000000000000000<sub>2</sub>}}</mtpl></li>
</ul>
<p>these fields are packed as shown in the figure below:</p>
<figure><b>(Figure)</b>
<figcaption>Float w significand 2.svg</figcaption>
</figure>
<h3 id="aliasing-to-an-integer-as-an-approximate-logarithm">Aliasing to an integer as an approximate logarithm</h3>
<p>If one had to calculate <span class="LaTeX">$1/ $</span> without a computer or a calculator, a <a href="table_of_logarithms" title="wikilink">table of logarithms</a> would be useful, together with the identity <mtpl> −½ log<sub>b</sub>(<em>x</em>)}}</mtpl>, which is valid for every base <span class="LaTeX">$b$</span>. The fast inverse square root is based on this identity, and on the fact that aliasing a float32 to an integer gives a rough approximation of its logarithm. Here is how:</p>
<p>If <span class="LaTeX">$x$</span> is a positive normal number:</p>
<p><span class="LaTeX">$$x = 2^{e_x} (1 + m_x)$$</span></p>
<p>then we have</p>
<p><span class="LaTeX">$$\log_2(x) = e_x + \log_2(1 + m_x)$$</span></p>
<p>but since <mtpl></mtpl>, the logarithm on the right hand side can be approximated by</p>
<p><span class="LaTeX">$$\log_2(1 + m_x) \approx m_x + \sigma$$</span></p>
<p>where <span class="LaTeX">$σ$</span> is a free parameter used to tune the approximation. For example, <span class="LaTeX">$σ = 0$</span> yields exact results at both ends of the interval, while <span class="LaTeX">$σ ≈ 0.0430357$</span> yields the <a href="Approximation_theory#Optimal_polynomials" title="wikilink">optimal approximation</a> (the best in the sense of the <a href="uniform_norm" title="wikilink">uniform norm</a> of the error).</p>
<figure><b>(Figure)</b>
<figcaption>The integer aliased to a floating point number (in blue), compared to a scaled and shifted logarithm (in gray).</figcaption>
</figure>
<p>Thus we have the approximation</p>
<p><span class="LaTeX">$$\log_2(x) \approx e_x + m_x + \sigma.$$</span></p>
<p>On the other hand, interpreting the bit-pattern of <span class="LaTeX">$x$</span> as an integer yields<a class="footnoteRef" href="#fn10" id="fnref10"><sup>10</sup></a></p>
<p><span class="LaTeX">$$\begin{align}
I_x &= E_x L + M_x\\
    &= L (e_x + B + m_x)\\
    &\approx L \log_2(x) + L (B - \sigma).
\end{align}$$</span></p>
<p>It then appears that <mtpl></mtpl> is a scaled and shifted piecewise-linear approximation of <mtpl></mtpl>, as illustrated in the figure on the right. In other words, <mtpl></mtpl> is approximated by</p>
<p><span class="LaTeX">$$\log_2(x) \approx \frac{I_x}{L} - (B - \sigma).$$</span></p>
<h3 id="first-approximation-of-the-result">First approximation of the result</h3>
<p>The calculation of <span class="LaTeX">$y = 1/ $</span> is based on the identity</p>
<p><span class="LaTeX">$$\log_2(y) = - \frac{1}{2}\log_2(x)$$</span></p>
<p>Using the approximation of the logarithm above, applied to both <span class="LaTeX">$x$</span> and <span class="LaTeX">$y$</span>, the above equation gives:</p>
<p><span class="LaTeX">$$I_y \approx \frac{3}{2} L (B - \sigma) - \frac{1}{2} I_x$$</span></p>
<p>which is written in the code as</p>
<div class="sourceCode"><pre class="sourceCode c"><code class="sourceCode c">i  = <span class="bn">0x5f3759df</span> - ( i >> <span class="dv">1</span> );</code></pre></div>
<p>The first term above is the magic number</p>
<p><span class="LaTeX">$$\frac{3}{2} L (B - \sigma) = \text{0x5f3759df}$$</span></p>
<p>from which it can be inferred <span class="LaTeX">$σ ≈ 0.0450466$</span>. The second term, <mtpl></mtpl>, is calculated by shifting the bits of <mtpl></mtpl> one position to the right.<a class="footnoteRef" href="#fn11" id="fnref11"><sup>11</sup></a></p>
<h3 id="newtons-method">Newton's method</h3>
<p>After performing those integer operations, the algorithm once again treats the longword as a floating point number (<code>y = *(float*)&i;</code>) and performs a floating point multiplication operation (<code>y = y*(1.5f - xhalf*y*y);</code>). The floating point operation represents a single iteration of Newton's method of finding roots for a given equation. For this example,</p>
<p><span class="LaTeX">$$y=\frac{1}{\sqrt{x}}$$</span> is the inverse square root, or, as a function of <em>y</em>,</p>
<p><span class="LaTeX">$$f(y)=\frac{1}{y^2}-x=0$$</span>.</p>
<dl>
<dd>As <span class="LaTeX">$y_{n+1} = y_{n} - \frac{f(y_n)}{f'(y_n)}$</span> represents a general expression of Newton's method with <span class="LaTeX">$\, y_n$</span> as the first approximation,
</dd>
</dl>
<p><span class="LaTeX">$$y_{n+1} = \frac{y_{n}(3-xy_n^2)}{2}$$</span> is the particularized expression where <span class="LaTeX">$f(y)=\frac{1}{y^2}-x$</span> and <span class="LaTeX">$f'(y)=\frac{-2}{y^3}$</span>.</p>
<dl>
<dd>Hence <code>y = y*(1.5f - xhalf*y*y);</code> is the same as <span class="LaTeX">$\, y_{n+1} = y_{n}(1.5-\frac{xy_n^2}{2}) = \frac{y_{n}(3-xy_n^2)}{2}$</span>
</dd>
</dl>
<p>The first approximation is generated above through the integer operations and input into the last two lines of the function. Repeated iterations of the algorithm, using the output of the function (<span class="LaTeX">$y_{n+1}$</span>) as the input of the next iteration, cause the algorithm to <a href="Rate_of_convergence" title="wikilink">converge</a> on the root with increasing precision. For the purposes of the <a href="id_Tech_3" title="wikilink"><em>Quake III</em> engine</a>, only one iteration was used. A second iteration remained in the code but was <a href="Comment_out" title="wikilink">commented out</a>.</p>
<h3 id="accuracy">Accuracy</h3>
<p> As noted above, the approximation is surprisingly accurate. The graph on the right plots the error of the function (that is, the error of the approximation after it has been improved by running one iteration of Newton's method), for inputs starting at 0.01, where the standard library gives 10.0 as a result, while InvSqrt() gives 9.982522, making the difference 0.017479, or 0.175%. The absolute error only drops from then on, while the relative error stays within the same bounds across all orders of magnitude.</p>
<h2 id="history-and-investigation">History and investigation</h2>
<p> The source code for <em>Quake III</em> was not released until <a href="QuakeCon#2005" title="wikilink">QuakeCon 2005</a>, but copies of the fast inverse square root code appeared on <a class="uri" href="Usenet" title="wikilink">Usenet</a> and other forums as early as 2002 or 2003.<a class="footnoteRef" href="#fn12" id="fnref12"><sup>12</sup></a> Initial speculation pointed to John Carmack as the probable author of the code, but he demurred and suggested it was written by Terje Mathisen, an accomplished assembly programmer who had previously helped id Software with <em>Quake</em> optimization. Mathisen had written an implementation of a similar bit of code in the late 1990s, but the original authors proved to be much further back in the history of 3D computer graphics with Gary Tarolli's implementation for the <a href="SGI_Indigo" title="wikilink">SGI Indigo</a> as a possible earliest known use. Rys Sommefeldt concluded that the original algorithm was devised by Greg Walsh at <a href="Ardent_Computer" title="wikilink">Ardent Computer</a> in consultation with <a href="Cleve_Moler" title="wikilink">Cleve Moler</a>, the creator of <a class="uri" href="MATLAB" title="wikilink">MATLAB</a>.<a class="footnoteRef" href="#fn13" id="fnref13"><sup>13</sup></a> <a href="Cleve_Moler" title="wikilink">Cleve Moler</a> learned about this trick from code written by <a href="William_Kahan" title="wikilink">William Kahan</a> and K.C. Ng at Berkeley around 1986 (see the comment section at the end of fdlibm code for sqrt<a class="footnoteRef" href="#fn14" id="fnref14"><sup>14</sup></a>).<a class="footnoteRef" href="#fn15" id="fnref15"><sup>15</sup></a> <a href="Jim_Blinn" title="wikilink">Jim Blinn</a> also demonstrated a simple approximation of the inverse square root in a 1997 column for <em><a href="List_of_Institute_of_Electrical_and_Electronics_Engineers_publications" title="wikilink">IEEE Computer Graphics and Applications</a></em>.</p>
<p>It is not known precisely how the exact value for the magic number was determined. Chris Lomont developed a function to minimize <a href="approximation_error" title="wikilink">approximation error</a> by choosing the magic number <em>R</em> over a range. He first computed the optimal constant for the linear approximation step as <strong>0x5f37642f</strong>, close to <strong>0x5f3759df</strong>, but this new constant gave slightly less accuracy after one iteration of Newton's method. Lomont then searched for a constant optimal even after one and two Newton iterations and found <strong>0x5f375a86</strong>, which is more accurate than the original at every iteration stage. He concluded by asking whether the exact value of the original constant was chosen through derivation or <a href="trial_and_error" title="wikilink">trial and error</a>. Lomont pointed out that the magic number for 64 bit IEEE754 size type double is <strong>0x5fe6ec85e7de30da</strong>, but it was later shown by Matthew Robertson to be exactly <strong>0x5fe6eb50c7b537a9</strong>.<a class="footnoteRef" href="#fn16" id="fnref16"><sup>16</sup></a> Charles McEniry performed a similar but more sophisticated optimization over likely values for R. His initial <a href="Brute-force_search" title="wikilink">brute force</a> search resulted in the same constant that Lomont determined. When he attempted to find the constant through <a href="Bisection_method" title="wikilink">weighted bisection</a>, the specific value of <em>R</em> used in the function occurred, leading McEniry to believe that the constant may have originally been derived through "bisecting to a given tolerance".</p>
<h2 id="see-also">See also</h2>
<ul>
<li><a href="Methods_of_computing_square_roots#Approximations_that_depend_on_the_floating_point_representation" title="wikilink">Methods of computing square roots: Approximations that depend on the floating point representation</a></li>
</ul>
<h2 id="notes">Notes</h2>
<references group="note/">
<h2 id="references">References</h2>
<h3 id="documents">Documents</h3>
<ul>
<li></li>
<li></li>
<li></li>
<li></li>
<li></li>
</ul>
<ul>
<li></li>
<li></li>
<li></li>
<li></li>
</ul>
<ul>
<li></li>
</ul>
<h2 id="external-links">External links</h2>
<ul>
<li><a href="http://shelfflag.com/rsqrt.pdf">A Brief History of InvSqrt</a> by Matthew Robertson</li>
<li><a href="http://blog.quenta.org/2012/09/0x5f3759df.html">0x5f3759df</a>, further investigations into accuracy and generalizability of the algorithm by Christian Plesner Hansen</li>
<li><a href="http://www.beyond3d.com/content/articles/8/">Origin of Quake3's Fast InvSqrt()</a></li>
<li><a href="https://github.com/id-Software/Quake-III-Arena">Quake III Arena source code</a></li>
<li></li>
</ul>
<p>"</p>
</references>
<p><a href="Category:Quake_(series)" title="wikilink">Category:Quake (series)</a> <a href="Category:Source_code" title="wikilink">Category:Source code</a> <a href="Category:Root-finding_algorithms" title="wikilink">Category:Root-finding algorithms</a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1"></li>
<li id="fn2"></li>
<li id="fn3"></li>
<li id="fn4"></li>
<li id="fn5">Use of the type <code>long</code> reduces the portability of this code on modern systems. For the code to execute properly, <code>sizeof(long)</code> must be 4 bytes, otherwise negative outputs may result. Under many modern 64-bit systems, <code>sizeof(long)</code> is 8 bytes.<a href="#fnref5">↩</a></li>
<li id="fn6"></li>
<li id="fn7"></li>
<li id="fn8"><mtpl></mtpl> should be in the range <span class="LaTeX">$1, 254 4$</span> for <span class="LaTeX">$x$</span> to be representable as a <a href="Normal_number_(computing)" title="wikilink">normal number</a>.<a href="#fnref8">↩</a></li>
<li id="fn9">The only real numbers that can be represented <em>exactly</em> as floating point are those for which <mtpl></mtpl> is an integer. Other numbers can only be represented approximately by rounding them to the nearest exactly representable number.<a href="#fnref9">↩</a></li>
<li id="fn10"><mtpl> 0}}</mtpl> since <span class="LaTeX">$x > 0$</span>.<a href="#fnref10">↩</a></li>
<li id="fn11">Hennessey & Patterson 1998, p. 305.<a href="#fnref11">↩</a></li>
<li id="fn12"></li>
<li id="fn13"></li>
<li id="fn14"></li>
<li id="fn15"></li>
<li id="fn16"></li>
</ol>
</section>
</body>
</html>
