   Majorization      Majorization    In mathematics , majorization is a preorder on vectors of real numbers . For a vector    𝐚  ∈   ℝ  d       𝐚   superscript  ℝ  d     \mathbf{a}\in\mathbb{R}^{d}   , we denote by     𝐚  ↓   ∈   ℝ  d        superscript  𝐚  normal-↓    superscript  ℝ  d     \mathbf{a}^{\downarrow}\in\mathbb{R}^{d}   the vector with the same components, but sorted in descending order. Given     𝐚  ,  𝐛   ∈   ℝ  d        𝐚  𝐛    superscript  ℝ  d     \mathbf{a},\mathbf{b}\in\mathbb{R}^{d}   , we say that   𝐚   𝐚   \mathbf{a}    weakly majorizes (or dominates)   𝐛   𝐛   \mathbf{b}    from below written as    𝐚   ≻  w   𝐛      subscript  succeeds  w   𝐚  𝐛    \mathbf{a}\succ_{w}\mathbf{b}    iff          ∑   i  =  1   k    a  i  ↓    ≥    ∑   i  =  1   k    b  i  ↓       for  k   =   1  ,  …  ,  d     ,     formulae-sequence      superscript   subscript     i  1    k    superscript   subscript  a  i   normal-↓      superscript   subscript     i  1    k    superscript   subscript  b  i   normal-↓         for  k    1  normal-…  d      \sum_{i=1}^{k}a_{i}^{\downarrow}\geq\sum_{i=1}^{k}b_{i}^{\downarrow}\quad\text%
 {for }k=1,\dots,d,     where    a  i  ↓     subscript   superscript  a  normal-↓   i    a^{\downarrow}_{i}   and    b  i  ↓     subscript   superscript  b  normal-↓   i    b^{\downarrow}_{i}   are the elements of   𝐚   𝐚   \mathbf{a}   and   𝐛   𝐛   \mathbf{b}   , respectively, sorted in decreasing order. Equivalently, we say that   𝐛   𝐛   \mathbf{b}   is weakly majorized (or dominated) by   𝐚   𝐚   \mathbf{a}    from below , denoted as    𝐛   ≺  w   𝐚      subscript  precedes  w   𝐛  𝐚    \mathbf{b}\prec_{w}\mathbf{a}   .  Similarly, we say that   𝐚   𝐚   \mathbf{a}    weakly majorizes    𝐛   𝐛   \mathbf{b}    from above written as    𝐚   ≻  w   𝐛      superscript  succeeds  w   𝐚  𝐛    \mathbf{a}\succ^{w}\mathbf{b}    iff          ∑   i  =  k   d    a  i  ↓    ≤    ∑   i  =  k   d    b  i  ↓       for  k   =   1  ,  …  ,  d     ,     formulae-sequence      superscript   subscript     i  k    d    superscript   subscript  a  i   normal-↓      superscript   subscript     i  k    d    superscript   subscript  b  i   normal-↓         for  k    1  normal-…  d      \sum_{i=k}^{d}a_{i}^{\downarrow}\leq\sum_{i=k}^{d}b_{i}^{\downarrow}\quad\text%
 {for }k=1,\dots,d,     Equivalently, we say that   𝐛   𝐛   \mathbf{b}   is weakly majorized by   𝐚   𝐚   \mathbf{a}    from above , denoted as    𝐛   ≺  w   𝐚      superscript  precedes  w   𝐛  𝐚    \mathbf{b}\prec^{w}\mathbf{a}   .  If    𝐚   ≻  w   𝐛      subscript  succeeds  w   𝐚  𝐛    \mathbf{a}\succ_{w}\mathbf{b}   and in addition      ∑   i  =  1   d    a  i    =    ∑   i  =  1   d    b  i          superscript   subscript     i  1    d    subscript  a  i      superscript   subscript     i  1    d    subscript  b  i      \sum_{i=1}^{d}a_{i}=\sum_{i=1}^{d}b_{i}   we say that   𝐚   𝐚   \mathbf{a}    majorizes (or dominates)   𝐛   𝐛   \mathbf{b}   written as    𝐚  ≻  𝐛     succeeds  𝐚  𝐛    \mathbf{a}\succ\mathbf{b}   . Equivalently, we say that   𝐛   𝐛   \mathbf{b}   is majorized (or dominated) by   𝐚   𝐚   \mathbf{a}   , denoted as    𝐛  ≺  𝐚     precedes  𝐛  𝐚    \mathbf{b}\prec\mathbf{a}   .  It is easy to see that    𝐚  ≻  𝐛     succeeds  𝐚  𝐛    \mathbf{a}\succ\mathbf{b}   if and only if    𝐚   ≻  w   𝐛      subscript  succeeds  w   𝐚  𝐛    \mathbf{a}\succ_{w}\mathbf{b}   and    𝐚   ≻  w   𝐛      superscript  succeeds  w   𝐚  𝐛    \mathbf{a}\succ^{w}\mathbf{b}   .  Note that the majorization order do not depend on the order of the components of the vectors   𝐚   𝐚   \mathbf{a}   or   𝐛   𝐛   \mathbf{b}   . Majorization is not a partial order , since    𝐚  ≻  𝐛     succeeds  𝐚  𝐛    \mathbf{a}\succ\mathbf{b}   and    𝐛  ≻  𝐚     succeeds  𝐛  𝐚    \mathbf{b}\succ\mathbf{a}   do not imply    𝐚  =  𝐛      𝐚  𝐛    \mathbf{a}=\mathbf{b}   , it only implies that the components of each vector are equal, but not necessarily in the same order.  Regrettably, to confuse the matter, some literature sources use the reverse notation, e.g.,   ≻   succeeds   \succ   is replaced with   ≺   precedes   \prec   , most notably, in Horn and Johnson, Matrix analysis (Cambridge Univ. Press, 1985), Definition 4.3.24, while the same authors switch to the traditional notation, introduced here, later in their Topics in Matrix Analysis (1994).  A function    f  :    ℝ  d   →  ℝ      normal-:  f   normal-→   superscript  ℝ  d   ℝ     f:\mathbb{R}^{d}\to\mathbb{R}   is said to be Schur convex when    𝐚  ≻  𝐛     succeeds  𝐚  𝐛    \mathbf{a}\succ\mathbf{b}   implies     f   (  𝐚  )    ≥   f   (  𝐛  )          f  𝐚     f  𝐛     f(\mathbf{a})\geq f(\mathbf{b})   . Similarly,    f   (  𝐚  )       f  𝐚    f(\mathbf{a})   is Schur concave when    𝐚  ≻  𝐛     succeeds  𝐚  𝐛    \mathbf{a}\succ\mathbf{b}   implies      f   (  𝐚  )    ≤   f   (  𝐛  )     .        f  𝐚     f  𝐛     f(\mathbf{a})\leq f(\mathbf{b}).     The majorization partial order on finite sets, described here, can be generalized to the Lorenz ordering , a partial order on distribution functions .  Examples  The order of the entries does not affect the majorization, e.g., the statement     (  1  ,  2  )   ≺   (  0  ,  3  )      precedes   1  2    0  3     (1,2)\prec(0,3)   is simply equivalent to     (  2  ,  1  )   ≺   (  3  ,  0  )      precedes   2  1    3  0     (2,1)\prec(3,0)   .  (Strong) majorization     (  1  ,  2  ,  3  )   ≺   (  0  ,  3  ,  3  )   ≺   (  0  ,  0  ,  6  )        precedes   1  2  3    0  3  3     precedes     0  0  6      (1,2,3)\prec(0,3,3)\prec(0,0,6)   . For vectors with n components        (   1  n   ,  …  ,   1  n   )   ≺   (   1   n  -  1    ,  …  ,   1   n  -  1    ,  0  )   ≺  ⋯  ≺   (   1  2   ,   1  2   ,  0  ,  …  ,  0  )   ≺   (  1  ,  0  ,  …  ,  0  )    .       precedes     1  n   normal-…    1  n       1    n  1    normal-…    1    n  1    0     precedes    normal-⋯    precedes       1  2     1  2   0  normal-…  0     precedes     1  0  normal-…  0      \left(\frac{1}{n},\ldots,\frac{1}{n}\right)\prec\left(\frac{1}{n-1},\ldots,%
 \frac{1}{n-1},0\right)\prec\cdots\prec\left(\frac{1}{2},\frac{1}{2},0,\ldots,0%
 \right)\prec\left(1,0,\ldots,0\right).     (Weak) majorization     (  1  ,  2  ,  3  )    ≺  w    (  1  ,  3  ,  3  )    ≺  w    (  1  ,  3  ,  4  )         subscript  precedes  w    1  2  3    1  3  3      subscript  precedes  w      1  3  4      (1,2,3)\prec_{w}(1,3,3)\prec_{w}(1,3,4)   . For vectors with n components:        (   1  n   ,  …  ,   1  n   )    ≺  w    (   1   n  -  1    ,  …  ,   1   n  -  1    ,  1  )    .      subscript  precedes  w      1  n   normal-…    1  n       1    n  1    normal-…    1    n  1    1     \left(\frac{1}{n},\ldots,\frac{1}{n}\right)\prec_{w}\left(\frac{1}{n-1},\ldots%
 ,\frac{1}{n-1},1\right).     Geometry of Majorization  For      𝐱  ,  𝐲   ∈   ℝ  n    ,       𝐱  𝐲    superscript  ℝ  n     \mathbf{x},\mathbf{y}\in\mathbb{R}^{n},   we have    𝐱  ≺  𝐲     precedes  𝐱  𝐲    \mathbf{x}\prec\mathbf{y}   if and only if   𝐱   𝐱   \mathbf{x}   is in the convex hull of all vectors obtained by permuting the coordinates of   𝐲   𝐲   \mathbf{y}   .  Figure 1 displays the convex hull in 2D for the vector    𝐲  =   (  3  ,  1  )       𝐲   3  1     \mathbf{y}=(3,\,1)   . Notice that the center of the convex hull, which is an interval in this case, is the vector    𝐱  =   (  2  ,  2  )       𝐱   2  2     \mathbf{x}=(2,\,2)   . This is the "smallest" vector satisfying    𝐱  ≺  𝐲     precedes  𝐱  𝐲    \mathbf{x}\prec\mathbf{y}   for this given vector   𝐲   𝐲   \mathbf{y}   .  Figure 2 shows the convex hull in 3D. The center of the convex hull, which is a 2D polygon in this case, is the "smallest" vector   𝐱   𝐱   \mathbf{x}   satisfying    𝐱  ≺  𝐲     precedes  𝐱  𝐲    \mathbf{x}\prec\mathbf{y}   for this given vector   𝐲   𝐲   \mathbf{y}   .  Equivalent conditions  Each of the following statements is true if and only if    𝐚  ≻  𝐛     succeeds  𝐚  𝐛    \mathbf{a}\succ\mathbf{b}   :       𝐛  =   D  𝐚       𝐛    D  𝐚     \mathbf{b}=D\mathbf{a}   for some doubly stochastic matrix    D   D   D   (see Arnold, 1 Theorem 2.1). This is equivalent to saying b can be represented as a weighted average of the permutations of   a   a   a   .  From   𝐚   𝐚   \mathbf{a}   we can produce   𝐛   𝐛   \mathbf{b}   by a finite sequence of "Robin Hood operations" where we replace two elements    a  i     subscript  a  i    a_{i}   and     a  j   <   a  i        subscript  a  j    subscript  a  i     a_{j}   with     a  i   -  ε       subscript  a  i   ε    a_{i}-\varepsilon   and     a  j   +  ε       subscript  a  j   ε    a_{j}+\varepsilon   , respectively, for some    ε  ∈   (  0  ,    a  i   -   a  j    )       ε   0     subscript  a  i    subscript  a  j       \varepsilon\in(0,a_{i}-a_{j})   (see Arnold, 2 p. 11).  For every convex function    h  :   ℝ  →  ℝ      normal-:  h   normal-→  ℝ  ℝ     h:\mathbb{R}\to\mathbb{R}   ,      ∑   i  =  1   d    h   (   a  i   )     ≥    ∑   i  =  1   d    h   (   b  i   )           superscript   subscript     i  1    d     h   subscript  a  i       superscript   subscript     i  1    d     h   subscript  b  i       \sum_{i=1}^{d}h(a_{i})\geq\sum_{i=1}^{d}h(b_{i})   (see Arnold, 3 Theorem 2.9).        ∀  t   ∈  ℝ      ∑   j  =  1   d    |    a  j   -  t   |    ≥    ∑   j  =  1   d    |    b  j   -  t   |        formulae-sequence     for-all  t   ℝ       superscript   subscript     j  1    d        subscript  a  j   t       superscript   subscript     j  1    d        subscript  b  j   t        \forall t\in\mathbb{R}\quad\sum_{j=1}^{d}|a_{j}-t|\geq\sum_{j=1}^{d}|b_{j}-t|   . (see Nielsen and Chuang Exercise 12.17, 4 )   In linear algebra   Suppose that for two real vectors      v  ,   v  ′    ∈   ℝ  d        v   superscript  v  normal-′     superscript  ℝ  d     v,v^{\prime}\in\mathbb{R}^{d}   ,   v   v   v   majorizes    v  ′     superscript  v  normal-′    v^{\prime}   . Then it can be shown that there exists a set of probabilities (p_1,p_2,\ldots,p_d),   \sum_{i=1}^d p_i=1 and a set of permutations     (   P  1   ,   P  2   ,  …  ,   P  d   )      subscript  P  1    subscript  P  2   normal-…   subscript  P  d     (P_{1},P_{2},\ldots,P_{d})   such that     v  ′   =    ∑   i  =  1   d     p  i    P  i   v         superscript  v  normal-′     superscript   subscript     i  1    d      subscript  p  i    subscript  P  i   v      v^{\prime}=\sum_{i=1}^{d}p_{i}P_{i}v   . Alternatively it can be shown that there exists a doubly stochastic matrix    D   D   D   such that     v  D   =   v  ′         v  D    superscript  v  normal-′     vD=v^{\prime}      We say that a hermitian operator ,   H   H   H   , majorizes another,    H  ′     superscript  H  normal-′    H^{\prime}   , if the set of eigenvalues of   H   H   H   majorizes that of    H  ′     superscript  H  normal-′    H^{\prime}   .   In recursion theory  Given     f  ,  g   :   ℕ  →  ℕ      normal-:   f  g    normal-→  ℕ  ℕ     f,g:\mathbb{N}\to\mathbb{N}\,\!   , then   f   f   f\,\!   is said to majorize    g   g   g\,\!   if, for all   x   x   x\,\!   ,     f   (  x  )    ≥   g   (  x  )          f  x     g  x     f(x)\geq g(x)\,\!   . If there is some   n   n   n\,\!   so that     f   (  x  )    ≥   g   (  x  )          f  x     g  x     f(x)\geq g(x)\,\!   for all    x  >  n      x  n    x>n\,\!   , then   f   f   f\,\!   is said to dominate (or eventually dominate )   g   g   g\,\!   . Alternatively, the preceding terms are often defined requiring the strict inequality     f   (  x  )    >   g   (  x  )          f  x     g  x     f(x)>g(x)\,\!   instead of     f   (  x  )    ≥   g   (  x  )          f  x     g  x     f(x)\geq g(x)\,\!   in the foregoing definitions.  Generalizations  Various generalizations of majorization are discussed in chapters 14 and 15 of the reference work Inequalities: Theory of Majorization and Its Applications . Albert W. Marshall, Ingram Olkin , Barry Arnold. Second edition. Springer Series in Statistics. Springer, New York, 2011. ISBN 978-0-387-40087-7  See also   Muirhead's inequality  Schur-convex function  Schur–Horn theorem relating diagonal entries of a matrix to its eigenvalues.  For positive integer numbers , weak majorization is called Dominance order .   Notes    References   J. Karamata. Sur une inegalite relative aux fonctions convexes. Publ. Math. Univ. Belgrade 1, 145–158, 1932.  G. H. Hardy, J. E. Littlewood and G. Pólya, Inequalities, 2nd edition, 1952, Cambridge University Press, London.  Inequalities: Theory of Majorization and Its Applications Albert W. Marshall, Ingram Olkin , Barry Arnold, Second edition. Springer Series in Statistics. Springer, New York, 2011. ISBN 978-0-387-40087-7  Inequalities: Theory of Majorization and Its Applications (1980) Albert W. Marshall, Ingram Olkin , Academic Press, ISBN 978-0-12-473750-1  A tribute to Marshall and Olkin's book "Inequalities: Theory of Majorization and its Applications"  Quantum Computation and Quantum Information , (2000) Michael A. Nielsen and Isaac L. Chuang, Cambridge University Press, ISBN 978-0-521-63503-5  Matrix Analysis (1996) Rajendra Bhatia, Springer, ISBN 978-0-387-94846-1  Topics in Matrix Analysis (1994) Roger A. Horn and Charles R. Johnson, Cambridge University Press, ISBN 978-0-521-46713-1  Majorization and Matrix Monotone Functions in Wireless Communications (2007) Eduard Jorswieck and Holger Boche, Now Publishers, ISBN 978-1-60198-040-3  The Cauchy Schwarz Master Class (2004) J. Michael Steele, Cambridge University Press, ISBN 978-0-521-54677-5   External links   Majorization in MathWorld  Majorization in PlanetMath   Software   OCTAVE / MATLAB  code to check majorization   "  Category:Order theory  Category:Linear algebra     Barry C. Arnold. "Majorization and the Lorenz Order: A Brief Introduction". Springer-Verlag Lecture Notes in Statistics, vol. 43, 1987. ↩    Nielsen and Chuang. "Quantum Computation and Quantum Information". Cambridge University Press, 2000 ↩     