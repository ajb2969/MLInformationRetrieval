<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="1565">Post hoc analysis</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>Post hoc analysis</h1>
<hr/>

<p>In the <a href="Design_of_experiments" title="wikilink">design and analysis of experiments</a>, <strong>post hoc analysis</strong> (from <a href="Latin_language" title="wikilink">Latin</a> <em><a href="post_hoc_(disambiguation)" title="wikilink">post hoc</a></em>, "after this") consists of looking at the data—after the experiment has concluded—for patterns that were not specified <a href="a_priori_(epistemology)" title="wikilink"><em>a priori</em></a>. It is sometimes called by critics <em><a href="data_dredging" title="wikilink">data dredging</a></em> to evoke the sense that the more one looks the more likely something will be found. More subtly, each time a pattern in the data is considered, a <a href="Statistical_hypothesis_testing" title="wikilink">statistical test</a> is effectively performed. This greatly inflates the total number of statistical tests and necessitates the use of <a href="multiple_testing" title="wikilink">multiple testing</a> procedures to compensate. However, this is difficult to do precisely and in fact most results of post hoc analyses are reported as they are with unadjusted <a href="P-value" title="wikilink"><em>p</em>-values</a>. These <em>p</em>-values must be interpreted in light of the fact that they are a small and selected subset of a potentially large group of <em>p</em>-values. Results of post hoc analyses should be explicitly labeled as such in reports and publications to avoid misleading readers.</p>

<p>In practice, post hoc analyses are usually concerned with finding patterns and/or relationships between <a href="Sample_(statistics)" title="wikilink">subgroups</a> of <a href="Statistical_population" title="wikilink">sampled populations</a> that would otherwise remain undetected and undiscovered were a scientific community to rely strictly upon <em><a href="a_priori_probability" title="wikilink">a priori</a></em> statistical methods. Post hoc tests — also known as <em><a href="A_priori_and_a_posteriori" title="wikilink">a posteriori</a></em> tests — greatly expand the range and capability of methods that can be applied in <em><a href="exploratory_research" title="wikilink">exploratory research</a></em>. Post hoc examination strengthens <a href="Inductive_reasoning" title="wikilink">induction</a> by limiting the probability that significant effects will seem to have been discovered between subgroups of a population when none actually exist. As it is, many scientific papers are published without adequate, preventative post hoc control of the <a href="Type_I_and_type_II_errors" title="wikilink">type I error rate</a>.<a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a></p>

<p>Post hoc analysis is an important procedure without which multivariate hypothesis testing would greatly suffer, rendering the chances of discovering false positives unacceptably high. Ultimately, post hoc testing creates better informed scientists who can therefore formulate better, more efficient <em><a href="A_priori_and_a_posteriori" title="wikilink">a priori</a></em> hypotheses and research designs.</p>
<h2 id="relationship-with-the-multiple-comparisons-problem">Relationship with the multiple comparisons problem</h2>

<p>In its most literal and narrow sense, post hoc analysis simply refers to unplanned data analysis performed after the data is collected in order to reach further conclusions. In this sense, even a test that does not provide <a href="Type_I_and_type_II_errors" title="wikilink">Type I Error Rate</a> <a class="footnoteRef" href="#fn2" id="fnref2"><sup>2</sup></a> protection, using multiple comparisons methods, is considered as post hoc analysis. A good example is performing initially unplanned multiple t-tests at level 

<math display="inline" id="Post_hoc_analysis:0">
 <semantics>
  <mi>α</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>α</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \alpha\,\!
  </annotation>
 </semantics>
</math>

, following an 

<math display="inline" id="Post_hoc_analysis:1">
 <semantics>
  <mi>α</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>α</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \alpha\,\!
  </annotation>
 </semantics>
</math>

 level anova test. Such post hoc analysis does not include multiple testing procedures, which are sometimes difficult to perform precisely. Unfortunately, analyses such as the above are still commonly conducted and their results reported with unadjusted p-values. Results of post hoc analyses which do not address the multiple comparisons problem should be explicitly labeled as such to avoid misleading readers.</p>

<p>In the wider and more useful sense, post hoc analysis tests enable protection from the multiple comparisons problem, whether the inferences made are selective or simultaneous. The type of inference is related directly to the hypotheses <a href="Familywise_error_rate" title="wikilink">family</a> of interest. Simultaneous inference indicates that all inferences, in the family of all hypotheses, are jointly corrected up to a specified type I error rate. In practice, post hoc analyses are usually concerned with finding patterns and/or relationships between <a href="Sample_(statistics)" title="wikilink">subgroups</a> of <a href="Statistical_population" title="wikilink">sampled populations</a> that would otherwise remain undetected and undiscovered were a scientific community to rely strictly upon <em><a href="a_priori_probability" title="wikilink">a priori</a></em> statistical methods . Therefore, simultaneous inference may be too conservative for certain large scale problems that are currently being addressed by science. For such problems, a <strong>selective inference</strong> approach might be more suitable, since it assumes that sub-groups of hypotheses from the large scale group can be viewed as a family. Selective post hoc examination strengthens <a href="Inductive_reasoning" title="wikilink">induction</a> by limiting the probability that significant differences will seem to have been discovered between sub-groups of a population when none actually exist. Accordingly, p-values of such sub-groups must be interpreted in light of the fact that they are a small and selected subset of a potentially large group of p-values.</p>
<h2 id="list-of-post-hoc-tests">List of <em>post hoc</em> tests</h2>

<p>The following are referred to as "post hoc tests". However, on some occasions a researcher may have initially planned on using them, thus referring to them as "post-hoc tests" is not entirely accurate. For instance, The <a href="Student–Newman–Keuls_test" title="wikilink">Student–Newman–Keuls</a> and <a href="Tukey's_range_test" title="wikilink">Tukey's</a> methods are often referred to as <em>post hoc</em>. However, it is not uncommon to plan on testing all pairwise comparisons before seeing the data. Therefore, in such cases, these tests are better categorized as <em>a priori</em>.</p>
<h3 id="fishers-least-significant-difference-lsd">Fisher's least significant difference (LSD)<a class="footnoteRef" href="#fn3" id="fnref3"><sup>3</sup></a></h3>

<p>This technique was developed by <a href="Ronald_Fisher" title="wikilink">Ronald Fisher</a> in 1935 and is used most commonly after a hypothesis in an analysis of variance (<a class="uri" href="ANOVA" title="wikilink">ANOVA</a>) test is rejected. A significant ANOVA test only reveals that not all the means compared in the test are equal. Fisher's LSD is basically a set of individual t-tests, differentiated only in the calculation of the standard deviation. In each t-test, a pooled standard deviation is computed from only the two groups being compared, while the Fisher's LSD test computes the pooled standard deviation from all groups - thus increasing power. Fisher's LSD does not correct for multiple comparisons.</p>
<h3 id="the-bonferroni-procedure">The Bonferroni procedure</h3>
<ul>
<li>Denote by 

<math display="inline" id="Post_hoc_analysis:2">
 <semantics>
  <msub>
   <mi>p</mi>
   <mi>i</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>p</ci>
    <ci>i</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   p_{i}
  </annotation>
 </semantics>
</math>

 the p-value for testing 

<math display="inline" id="Post_hoc_analysis:3">
 <semantics>
  <msub>
   <mi>H</mi>
   <mi>i</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>H</ci>
    <ci>i</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   H_{i}
  </annotation>
 </semantics>
</math>

</li>
<li>reject 

<math display="inline" id="Post_hoc_analysis:4">
 <semantics>
  <msub>
   <mi>H</mi>
   <mi>i</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>H</ci>
    <ci>i</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   H_{i}
  </annotation>
 </semantics>
</math>

 if 

<math display="inline" id="Post_hoc_analysis:5">
 <semantics>
  <mrow>
   <msub>
    <mi>p</mi>
    <mi>i</mi>
   </msub>
   <mo>≤</mo>
   <mfrac>
    <mi>α</mi>
    <mi>m</mi>
   </mfrac>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <leq></leq>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>p</ci>
     <ci>i</ci>
    </apply>
    <apply>
     <divide></divide>
     <ci>α</ci>
     <ci>m</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   p_{i}\leq\frac{\alpha}{m}
  </annotation>
 </semantics>
</math>

</li>
<li>

<math display="inline" id="Post_hoc_analysis:6">
 <semantics>
  <mi>m</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>m</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   m
  </annotation>
 </semantics>
</math>

 being the number of hypotheses</li>
</ul>

<p>Although mainly used with planned contrasts, it can be used as a post hoc test for comparisons between data groups of interest in the experiment after the fact. It is flexible and very simple to compute, but naive in its idea of retaining of <a href="familywise_error_rate" title="wikilink">familywise error rate</a> by division by 

<math display="inline" id="Post_hoc_analysis:7">
 <semantics>
  <mi>m</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>m</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   m
  </annotation>
 </semantics>
</math>

. This method results in a large reduction in the power of the test. That is, because the cut-off value is reduced, it becomes substantially more difficult for any result to be concluded as being statistically significant, irrespective of whether it is true or not.</p>
<h3 id="holmbonferroni-method">Holm–Bonferroni method</h3>
<ul>
<li>Start by ordering the p-values 

<math display="inline" id="Post_hoc_analysis:8">
 <semantics>
  <mrow>
   <msub>
    <mi>P</mi>
    <mrow>
     <mo stretchy="false">(</mo>
     <mn>1</mn>
     <mo stretchy="false">)</mo>
    </mrow>
   </msub>
   <mi mathvariant="normal">…</mi>
   <msub>
    <mi>P</mi>
    <mrow>
     <mo stretchy="false">(</mo>
     <mi>m</mi>
     <mo stretchy="false">)</mo>
    </mrow>
   </msub>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>P</ci>
     <cn type="integer">1</cn>
    </apply>
    <ci>normal-…</ci>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>P</ci>
     <ci>m</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   P_{(1)}\ldots P_{(m)}
  </annotation>
 </semantics>
</math>

 and let the associated hypotheses be 

<math display="inline" id="Post_hoc_analysis:9">
 <semantics>
  <mrow>
   <msub>
    <mi>H</mi>
    <mrow>
     <mo stretchy="false">(</mo>
     <mn>1</mn>
     <mo stretchy="false">)</mo>
    </mrow>
   </msub>
   <mi mathvariant="normal">…</mi>
   <msub>
    <mi>H</mi>
    <mrow>
     <mo stretchy="false">(</mo>
     <mi>m</mi>
     <mo stretchy="false">)</mo>
    </mrow>
   </msub>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>H</ci>
     <cn type="integer">1</cn>
    </apply>
    <ci>normal-…</ci>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>H</ci>
     <ci>m</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   H_{(1)}\ldots H_{(m)}
  </annotation>
 </semantics>
</math>

</li>
</ul>
<ul>
<li>Let 

<math display="inline" id="Post_hoc_analysis:10">
 <semantics>
  <mi>R</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>R</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   R
  </annotation>
 </semantics>
</math>

 be the smallest 

<math display="inline" id="Post_hoc_analysis:11">
 <semantics>
  <mi>k</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>k</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   k
  </annotation>
 </semantics>
</math>

 such that 

<math display="inline" id="Post_hoc_analysis:12">
 <semantics>
  <mrow>
   <msub>
    <mi>P</mi>
    <mrow>
     <mo stretchy="false">(</mo>
     <mi>k</mi>
     <mo stretchy="false">)</mo>
    </mrow>
   </msub>
   <mo>></mo>
   <mfrac>
    <mi>α</mi>
    <mrow>
     <mrow>
      <mi>m</mi>
      <mo>+</mo>
      <mn>1</mn>
     </mrow>
     <mo>-</mo>
     <mi>k</mi>
    </mrow>
   </mfrac>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <gt></gt>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>P</ci>
     <ci>k</ci>
    </apply>
    <apply>
     <divide></divide>
     <ci>α</ci>
     <apply>
      <minus></minus>
      <apply>
       <plus></plus>
       <ci>m</ci>
       <cn type="integer">1</cn>
      </apply>
      <ci>k</ci>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   P_{(k)}>\frac{\alpha}{m+1-k}
  </annotation>
 </semantics>
</math>

</li>
</ul>
<ul>
<li>Reject the null hypotheses 

<math display="inline" id="Post_hoc_analysis:13">
 <semantics>
  <mrow>
   <msub>
    <mi>H</mi>
    <mrow>
     <mo stretchy="false">(</mo>
     <mn>1</mn>
     <mo stretchy="false">)</mo>
    </mrow>
   </msub>
   <mi mathvariant="normal">…</mi>
   <msub>
    <mi>H</mi>
    <mrow>
     <mo stretchy="false">(</mo>
     <mrow>
      <mi>R</mi>
      <mo>-</mo>
      <mn>1</mn>
     </mrow>
     <mo stretchy="false">)</mo>
    </mrow>
   </msub>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>H</ci>
     <cn type="integer">1</cn>
    </apply>
    <ci>normal-…</ci>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>H</ci>
     <apply>
      <minus></minus>
      <ci>R</ci>
      <cn type="integer">1</cn>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   H_{(1)}\ldots H_{(R-1)}
  </annotation>
 </semantics>
</math>

. If 

<math display="inline" id="Post_hoc_analysis:14">
 <semantics>
  <mrow>
   <mi>R</mi>
   <mo>=</mo>
   <mn>1</mn>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <ci>R</ci>
    <cn type="integer">1</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   R=1
  </annotation>
 </semantics>
</math>

 then none of the hypotheses are rejected.</li>
</ul>
<ul>
<li>This procedure is uniformly better than Bonferroni's.</li>
</ul>
<ul>
<li>It is worth noticing here that the reason why this procedure controls the family-wise error rate for all the m hypotheses at level α in the strong sense is because it is essentially a <a href="closed_testing_procedure" title="wikilink">closed testing procedure</a>. As such, each intersection is tested using the simple Bonferroni test.</li>
</ul>

<p>The Bonferroni-Holm method introduces a correction to Bonferroni's method that allows more rejections, and is therefore less conservative and more powerful than the Bonferroni method.</p>
<h3 id="newmankeuls-method">Newman–Keuls method</h3>

<p>A stepwise <a href="multiple_comparisons" title="wikilink">multiple comparisons</a> procedure used to identify <a href="Sample_(statistics)" title="wikilink">sample</a> <a href="Arithmetic_mean" title="wikilink">means</a> that are <a href="Statistical_significance" title="wikilink">significantly</a> different from each other. It is used often as a post hoc test whenever a significant difference between three or more sample means has been revealed by an <a href="analysis_of_variance" title="wikilink">analysis of variance (ANOVA)</a></p>
<h3 id="duncans-new-multiple-range-test-mrt">Duncan's new multiple range test (MRT)</h3>

<p>Duncan developed this test as a modification of the <a href="Newman–Keuls_method" title="wikilink">Newman–Keuls method</a> that would have greater power. Duncan's MRT is especially protective against <a href="Type_I_and_type_II_errors" title="wikilink">false negative (Type II) error</a> at the expense of having a greater risk of making <a href="Type_I_and_type_II_errors" title="wikilink">false positive (Type I) errors</a>.</p>
<h3 id="rodgers-method">Rodger's method</h3>

<p>Rodger's method is a procedure for examining research data <a href="post_hoc_(disambiguation)" title="wikilink">post hoc</a> following an 'omnibus' analysis, that is after carrying out an <a href="analysis_of_variance" title="wikilink">analysis of variance (ANOVA)</a>. Rodger's method utilizes a decision-based error rate, arguing that it is not the probability (

<math display="inline" id="Post_hoc_analysis:15">
 <semantics>
  <mi>α</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>α</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \alpha
  </annotation>
 </semantics>
</math>

) of rejecting 

<math display="inline" id="Post_hoc_analysis:16">
 <semantics>
  <msub>
   <mi>H</mi>
   <mn>0</mn>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>H</ci>
    <cn type="integer">0</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   H_{0}
  </annotation>
 </semantics>
</math>

 in error that should be controlled, rather it is the average rate of rejecting true null contrasts that should be controlled. Meaning we should control the expected rate (

<math display="inline" id="Post_hoc_analysis:17">
 <semantics>
  <mrow>
   <mo>E</mo>
   <mi>α</mi>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <ci>normal-E</ci>
    <ci>α</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \operatorname{E}\alpha
  </annotation>
 </semantics>
</math>

) of true null contrast rejection.</p>
<h3 id="scheffés-method">Scheffé's method</h3>

<p>Scheffé's method applies to the set of estimates of all possible contrasts among the factor level means, not just the pairwise differences. Having an advantage of flexibility, it can be used to test any number of post hoc simple and/or complex comparisons that appear interesting. However, the drawback of this flexibility is a low <a href="type_I_error_rate" title="wikilink">type I error rate</a>, and a low power.</p>
<h3 id="tukeys-procedure">Tukey's procedure</h3>
<ul>
<li>Tukey's procedure is only applicable for <a href="pairwise_comparison" title="wikilink">pairwise comparisons</a>.</li>
<li>It assumes independence of the observations being tested, as well as equal variation across observations (<a class="uri" href="homoscedasticity" title="wikilink">homoscedasticity</a>).</li>
<li>The procedure calculates for each pair the <a href="studentized_range" title="wikilink">studentized range</a> statistic

<math display="block" id="Post_hoc_analysis:18">
 <semantics>
  <mfrac>
   <mrow>
    <msub>
     <mi>Y</mi>
     <mi>A</mi>
    </msub>
    <mo>-</mo>
    <msub>
     <mi>Y</mi>
     <mi>B</mi>
    </msub>
   </mrow>
   <mrow>
    <mi>S</mi>
    <mi>E</mi>
   </mrow>
  </mfrac>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <divide></divide>
    <apply>
     <minus></minus>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>Y</ci>
      <ci>A</ci>
     </apply>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>Y</ci>
      <ci>B</ci>
     </apply>
    </apply>
    <apply>
     <times></times>
     <ci>S</ci>
     <ci>E</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \frac{Y_{A}-Y_{B}}{SE}
  </annotation>
 </semantics>
</math>

 where 

<math display="inline" id="Post_hoc_analysis:19">
 <semantics>
  <msub>
   <mi>Y</mi>
   <mi>A</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>Y</ci>
    <ci>A</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   Y_{A}
  </annotation>
 </semantics>
</math>

 is the larger of the two means being compared, 

<math display="inline" id="Post_hoc_analysis:20">
 <semantics>
  <msub>
   <mi>Y</mi>
   <mi>B</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>Y</ci>
    <ci>B</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   Y_{B}
  </annotation>
 </semantics>
</math>

 is the smaller, and 

<math display="inline" id="Post_hoc_analysis:21">
 <semantics>
  <mrow>
   <mi>S</mi>
   <mi>E</mi>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <ci>S</ci>
    <ci>E</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   SE
  </annotation>
 </semantics>
</math>

 is the standard error of the data in question.</li>
<li>Tukey's test is essentially a <a href="Student's_t-test" title="wikilink">Student's t-test</a>, except that it corrects for <strong>family-wise error-rate</strong>.</li>
</ul>

<p>A correction with a similar framework is Fisher’s LSD (least significant difference).</p>
<h3 id="dunnetts-correction">Dunnett's correction</h3>

<p><a href="Charles_Dunnett" title="wikilink">Charles Dunnett</a> (1955, 1966; not to be confused with Dunn) described an alternative alpha error adjustment when <em>k</em> groups are compared to the same control group. Now known as <a href="Dunnett's_test" title="wikilink">Dunnett's test</a>, this method is less conservative than the Bonferroni adjustment.</p>
<h3 id="benjaminihochberg-bh-procedure">Benjamini–Hochberg (BH) procedure</h3>

<p>BH-procedure is a step-up procedure iterating over 

<math display="inline" id="Post_hoc_analysis:22">
 <semantics>
  <mrow>
   <msub>
    <mi>H</mi>
    <mn>1</mn>
   </msub>
   <mo>,</mo>
   <mi mathvariant="normal">…</mi>
   <mo>,</mo>
   <msub>
    <mi>H</mi>
    <mi>m</mi>
   </msub>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <list>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>H</ci>
     <cn type="integer">1</cn>
    </apply>
    <ci>normal-…</ci>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>H</ci>
     <ci>m</ci>
    </apply>
   </list>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   H_{1},\ldots,H_{m}
  </annotation>
 </semantics>
</math>

 null hypotheses tested and 

<math display="inline" id="Post_hoc_analysis:23">
 <semantics>
  <mrow>
   <msub>
    <mi>P</mi>
    <mrow>
     <mo stretchy="false">(</mo>
     <mn>1</mn>
     <mo stretchy="false">)</mo>
    </mrow>
   </msub>
   <mo>,</mo>
   <mi mathvariant="normal">…</mi>
   <mo>,</mo>
   <msub>
    <mi>P</mi>
    <mrow>
     <mo stretchy="false">(</mo>
     <mi>m</mi>
     <mo stretchy="false">)</mo>
    </mrow>
   </msub>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <list>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>P</ci>
     <cn type="integer">1</cn>
    </apply>
    <ci>normal-…</ci>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>P</ci>
     <ci>m</ci>
    </apply>
   </list>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   P_{(1)},\ldots,P_{(m)}
  </annotation>
 </semantics>
</math>

, their ordered p-values in an increasing order. The method then proceeds to identify the rejected null hypotheses from the above set, whilst controlling the false discovery rate (at level 

<math display="inline" id="Post_hoc_analysis:24">
 <semantics>
  <mi>α</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>α</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   \alpha
  </annotation>
 </semantics>
</math>

) under the premise that the total 

<math display="inline" id="Post_hoc_analysis:25">
 <semantics>
  <mi>m</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>m</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   m
  </annotation>
 </semantics>
</math>

 hypotheses are <a href="Statistical_independence" title="wikilink">independent</a>.</p>
<h2 id="see-also">See also</h2>
<ul>
<li><a class="uri" href="ANOVA" title="wikilink">ANOVA</a></li>
<li><a href="Multiple_comparisons" title="wikilink">Multiple comparisons</a></li>
<li>The significance level α (alpha) in <a href="statistical_hypothesis_testing" title="wikilink">statistical hypothesis testing</a></li>
<li><a href="Subgroup_analysis" title="wikilink">Subgroup analysis</a></li>
<li><a href="Testing_hypotheses_suggested_by_the_data" title="wikilink">Testing hypotheses suggested by the data</a></li>
</ul>
<h2 id="references">References</h2>
<references>
</references>
<h2 id="bibliography">Bibliography</h2>
<ul>
<li>James E. Carlson and Others (1975) [<a class="uri" href="http://www.eric.ed.gov/ERICWebPortal/custom/portlets/recordDetails/detailmini.jsp?_nfpb=true&amp;_&amp;ERICExtSearch;_SearchValue_0=ED109185&amp;ERICExtSearch;_SearchType_0=no&amp;accno">http://www.eric.ed.gov/ERICWebPortal/custom/portlets/recordDetails/detailmini.jsp?_nfpb=true&amp;_&amp;ERICExtSearch;_SearchValue_0=ED109185&amp;ERICExtSearch;_SearchType_0=no&amp;accno;</a>;=ED109185 "The Distribution of the Test Statistic Used in the Newman–Keuls Multiple Comparison Technique"], Annual Meeting of the American Educational Research Association (Washington, D. C., March 30–April 3, 1975)</li>
<li></li>
</ul>

<p>"</p>

<p><a href="Category:Data_analysis" title="wikilink">Category:Data analysis</a> <a href="Category:Multiple_comparisons" title="wikilink">Category:Multiple comparisons</a> <a href="Category:Clinical_research" title="wikilink">Category:Clinical research</a> <a href="Category:Medical_statistics" title="wikilink">Category:Medical statistics</a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1"><a href="#fnref1">↩</a></li>
<li id="fn2"></li>
<li id="fn3"><a href="#fnref3">↩</a></li>
</ol>
</section>
</body>
</html>
