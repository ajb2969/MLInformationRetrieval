   Sequent calculus      Sequent calculus   Sequent calculus is, in essence, a style of formal logical argumentation where every line of a proof is a conditional tautology (called a sequent by Gerhard Gentzen ) instead of an unconditional tautology. Each conditional tautology is inferred from other conditional tautologies on earlier lines in a formal argument according to rules and procedures of inference , giving a better approximation to the style of natural deduction used by mathematicians than David Hilbert's earlier style of formal logic where every line was an unconditional tautology. (This is the essence of the idea, but there are several over-simplifications here. For example, there may be non-logical axioms upon which all propositions are implicitly dependent. Then sequents signify conditional theorems in a first-order language rather than conditional tautologies.)  Sequent calculus is one of several extant styles of proof calculus for expressing line-by-line logical arguments.   Hilbert style . Every line is an unconditional tautology (or theorem).  Gentzen style. Every line is a conditional tautology (or theorem) with zero or more conditions on the left.  Natural deduction . Every (conditional) line has exactly one asserted proposition on the right.  Sequent calculus. Every (conditional) line has zero or more asserted propositions on the right.    In other words, natural deduction and sequent calculus systems are particular distinct kinds of Gentzen-style systems. Hilbert-style systems typically have a very small number of inference rules, relying more on sets of axioms. Gentzen-style systems typically have very few axioms, if any, relying more on sets of rules.  Gentzen-style systems have significant practical and theoretical advantages compared to Hilbert-style systems. For example, both natural deduction and sequent calculus systems facilitate the elimination and introduction of universal and existential quantifiers so that unquantified logical expressions can be manipulated according to the much simpler rules of propositional calculus . In a typical argument, quantifiers are eliminated, then propositional calculus is applied to unquantified expressions (which typically contain free variables), and then the quantifiers are reintroduced. This very much parallels the way in which mathematical proofs are carried out in practice by mathematicians. Predicate calculus proofs are generally much easier to discover with this approach, and are often shorter. Natural deduction systems are more suited to practical theorem-proving. Sequent calculus systems are more suited to theoretical analysis.  Introduction  In proof theory and mathematical logic , sequent calculus is a family of formal systems sharing a certain style of inference and certain formal properties. The first sequent calculi, systems LK and LJ , were introduced in 1934/1935 by Gerhard Gentzen 1 as a tool for studying natural deduction in first-order logic (in classical and intuitionistic versions, respectively). Gentzen's so-called "Main Theorem" ( Hauptsatz ) about LK and LJ was the cut-elimination theorem , 2 3 a result with far-reaching meta-theoretic consequences, including consistency . Gentzen further demonstrated the power and flexibility of this technique a few years later, applying a cut-elimination argument to give a (transfinite) proof of the consistency of Peano arithmetic , in surprising response to Gödel's incompleteness theorems . Since this early work, sequent calculi, also called Gentzen systems , 4 5 6 7 and the general concepts relating to them, have been widely applied in the fields of proof theory, mathematical logic, and automated deduction .  Hilbert-style deduction systems  One way to classify different styles of deduction systems is to look at the form of judgments in the system, i.e. , which things may appear as the conclusion of a (sub)proof. The simplest judgment form is used in Hilbert-style deduction systems , where a judgment has the form      B    B   B\,   where   B   B   B   is any formula of first-order-logic (or whatever logic the deduction system applies to, e.g. , propositional calculus or a higher-order logic or a modal logic ). The theorems are those formulae that appear as the concluding judgment in a valid proof. A Hilbert-style system needs no distinction between formulae and judgments; we make one here solely for comparison with the cases that follow.  The price paid for the simple syntax of a Hilbert-style system is that complete formal proofs tend to get extremely long. Concrete arguments about proofs in such a system almost always appeal to the deduction theorem . This leads to the idea of including the deduction theorem as a formal rule in the system, which happens in natural deduction .  Natural deduction systems  In natural deduction, judgments have the shape        A  1   ,   A  2   ,  …  ,   A  n    ⊢  B     proves    subscript  A  1    subscript  A  2   normal-…   subscript  A  n    B    A_{1},A_{2},\ldots,A_{n}\vdash B   where the    A  i     subscript  A  i    A_{i}   's and   B   B   B   are again formulae and    n  ≥  0      n  0    n\geq 0   . Permutations of the    A  i     subscript  A  i    A_{i}   's are immaterial. In other words, a judgment consists of a list (possibly empty) of formulae on the left-hand side of a turnstile symbol "   ⊢   proves   \vdash   ", with a single formula on the right-hand side. 8 9 10 The theorems are those formulae   B   B   B   such that     ⊢  B     proves  absent  B    \vdash B   (with an empty left-hand side) is the conclusion of a valid proof. (In some presentations of natural deduction, the    A  i     subscript  A  i    A_{i}   s and the turnstile are not written down explicitly; instead a two-dimensional notation from which they can be inferred is used.)  The standard semantics of a judgment in natural deduction is that it asserts that whenever 11     A  1     subscript  A  1    A_{1}   ,    A  2     subscript  A  2    A_{2}   , etc., are all true,   B   B   B   will also be true. The judgments        A  1   ,  …  ,   A  n    ⊢  B     proves    subscript  A  1   normal-…   subscript  A  n    B    A_{1},\ldots,A_{n}\vdash B   and       ⊢    (    A  1   ∧  ⋯  ∧   A  n    )   →  B      proves  absent   normal-→     subscript  A  1   normal-⋯   subscript  A  n    B     \vdash(A_{1}\land\cdots\land A_{n})\rightarrow B   are equivalent in the strong sense that a proof of either one may be extended to a proof of the other.  Sequent calculus systems  Finally, sequent calculus generalizes the form of a natural deduction judgment to         A  1   ,  …  ,   A  n    ⊢    B  1   ,  …  ,   B  k     ,     proves    subscript  A  1   normal-…   subscript  A  n      subscript  B  1   normal-…   subscript  B  k      A_{1},\ldots,A_{n}\vdash B_{1},\ldots,B_{k},   a syntactic object called a sequent. The formulas on left-hand side of the turnstile are called the antecedent , and the formulas on right-hand side are called the succedent or consequent ; together they are called cedents or sequents . 12 Again,    A  i     subscript  A  i    A_{i}   and    B  i     subscript  B  i    B_{i}   are formulae, and   n   n   n   and   k   k   k   are nonnegative integers, that is, the left-hand-side or the right-hand-side (or neither or both) may be empty. As in natural deduction, theorems are those   B   B   B   where     ⊢  B     proves  absent  B    \vdash B   is the conclusion of a valid proof. The empty sequent, having both cedents empty, is defined to be false. 13  The standard semantics of a sequent is an assertion that whenever every     A  i     subscript  A  i    A_{i}   is true, at least one     B  i     subscript  B  i    B_{i}   will also be true. 14 One way to express this is that a comma to the left of the turnstile should be thought of as an "and", and a comma to the right of the turnstile should be thought of as an (inclusive) "or". The sequents        A  1   ,  …  ,   A  n    ⊢    B  1   ,  …  ,   B  k       proves    subscript  A  1   normal-…   subscript  A  n      subscript  B  1   normal-…   subscript  B  k      A_{1},\ldots,A_{n}\vdash B_{1},\ldots,B_{k}   and       ⊢    (    A  1   ∧  ⋯  ∧   A  n    )   →   (    B  1   ∨  ⋯  ∨   B  k    )       proves  absent   normal-→     subscript  A  1   normal-⋯   subscript  A  n       subscript  B  1   normal-⋯   subscript  B  k       \vdash(A_{1}\land\cdots\land A_{n})\rightarrow(B_{1}\lor\cdots\lor B_{k})   are equivalent in the strong sense that a proof of either one may be extended to a proof of the other.  At first sight, this extension of the judgment form may appear to be a strange complication — it is not motivated by an obvious shortcoming of natural deduction, and it is initially confusing that the comma seems to mean entirely different things on the two sides of the turnstile. However, in a classical context the semantics of the sequent can also (by propositional tautology) be expressed either as       ⊢    ¬   A  1    ∨   ¬   A  2    ∨  ⋯  ∨   ¬   A  n    ∨   B  1   ∨   B  2   ∨  ⋯  ∨   B  k       proves  absent        subscript  A  1        subscript  A  2    normal-⋯      subscript  A  n     subscript  B  1    subscript  B  2   normal-⋯   subscript  B  k      \vdash\neg A_{1}\lor\neg A_{2}\lor\cdots\lor\neg A_{n}\lor B_{1}\lor B_{2}\lor%
 \cdots\lor B_{k}   (at least one of the As is false, or one of the Bs is true) or as       ⊢   ¬   (    A  1   ∧   A  2   ∧  ⋯  ∧   A  n   ∧   ¬   B  1    ∧   ¬   B  2    ∧  ⋯  ∧   ¬   B  k     )       proves  absent       subscript  A  1    subscript  A  2   normal-⋯   subscript  A  n       subscript  B  1        subscript  B  2    normal-⋯      subscript  B  k        \vdash\neg(A_{1}\land A_{2}\land\cdots\land A_{n}\land\neg B_{1}\land\neg B_{2%
 }\land\cdots\land\neg B_{k})   (it cannot be the case that all of the As are true and all of the Bs are false). In these formulations, the only difference between formulae on either side of the turnstile is that one side is negated. Thus, swapping left for right in a sequent corresponds to negating all of the constituent formulae. This means that a symmetry such as De Morgan's laws , which manifests itself as logical negation on the semantic level, translates directly into a left-right symmetry of sequents — and indeed, the inference rules in sequent calculus for dealing with conjunction (∧) are mirror images of those dealing with disjunction (∨).  Many logicians feel that this symmetric presentation offers a deeper insight in the structure of the logic than other styles of proof system, where the classical duality of negation is not as apparent in the rules.  Distinction between natural deduction and sequent calculus  Gentzen asserted a sharp distinction between his single-output natural deduction systems (NK and NJ) and his multiple-output sequent calculus systems (LK and LJ). He wrote that the intuitionistic natural deduction system NJ was somewhat ugly. 15 He said that the special role of the excluded middle in the classical natural deduction system NK is removed in the classical sequent calculus system LK. 16 He said that the sequent calculus LJ gave more symmetry than natural deduction NJ in the case of intuitionistic logic, as also in the case of classical logic (LK versus NK). 17 Then he said that in addition to these reasons, the sequent calculus with multiple succedent formulas is intended particularly for his principal theorem ("Hauptsatz"). 18  Origin of word "sequent"  The word "sequent" is taken from the word "Sequenz" in Gentzen's 1934 paper. 19 Kleene makes the following comment on the translation into English: "Gentzen says 'Sequenz', which we translate as 'sequent', because we have already used 'sequence' for any succession of objects, where the German is 'Folge'." 20  The system LK  This section introduces the rules of the sequent calculus LK (which just stands for “ k lassische Prädikaten l ogik”), as introduced by Gentzen in 1934. A (formal) proof in this calculus is a sequence of sequents, where each of the sequents is derivable from sequents appearing earlier in the sequence by using one of the rules below.  Inference rules  The following notation will be used:      ⊢   proves   \vdash   known as the turnstile , separates the assumptions on the left from the propositions on the right     A   A   A   and   B   B   B   denote formulae of first-order predicate logic (one may also restrict this to propositional logic),      Γ  ,  Δ  ,  Σ     normal-Γ  normal-Δ  normal-Σ    \Gamma,\Delta,\Sigma   , and   Π   normal-Π   \Pi   are finite (possibly empty) sequences of formulae (in fact, the order of formulae do not matter; see subsection Structural Rules ), called contexts,  when on the left of the   ⊢   proves   \vdash   , the sequence of formulas is considered conjunctively (all assumed to hold at the same time),  while on the right of the   ⊢   proves   \vdash   , the sequence of formulas is considered disjunctively (at least one of the formulas must hold for any assignment of variables),      t   t   t   denotes an arbitrary term,     x   x   x   and   y   y   y   denote variables.  a variable is said to occur free within a formula if it occurs outside the scope of quantifiers   ∀   for-all   \forall   or   ∃     \exists   .      A   [   t  /  x   ]       A   delimited-[]    t  x      A[t/x]   denotes the formula that is obtained by substituting the term   t   t   t   for every free occurrence of the variable   x   x   x   in formula   A   A   A   with the restriction that the term   t   t   t   must be free for the variable   x   x   x   in   A   A   A   (i.e., no occurrence of any variable in   t   t   t   becomes bound in    A   [   t  /  x   ]       A   delimited-[]    t  x      A[t/x]   ).      W  L      W  L    WL   and    W  R      W  R    WR   stand for Weakening Left/Right ,    C  L      C  L    CL   and    C  R      C  R    CR   for Contraction , and    P  L      P  L    PL   and    P  R      P  R    PR   for Permutation .       Axiom:   Cut:             A  ⊢  A      (  I  )       continued-fraction  absent   proves  A  A    I    \cfrac{\qquad}{A\vdash A}\quad(I)             Γ  ⊢   Δ  ,  A  A  ,  Σ   ⊢  Π     Γ  ,  Σ   ⊢   Δ  ,  Π       (  𝐶𝑢𝑡  )       continued-fraction     proves  normal-Γ   normal-Δ  A  A  normal-Σ     proves    normal-Π     proves   normal-Γ  normal-Σ    normal-Δ  normal-Π     𝐶𝑢𝑡    \cfrac{\Gamma\vdash\Delta,A\qquad A,\Sigma\vdash\Pi}{\Gamma,\Sigma\vdash\Delta%
 ,\Pi}\quad(\mathit{Cut})        Left logical rules:   Right logical rules:             Γ  ,  A   ⊢  Δ     Γ  ,   A  and  B    ⊢  Δ      (   and   L  1    )       continued-fraction   proves   normal-Γ  A   normal-Δ    proves   normal-Γ    A  italic- and  B    normal-Δ      italic- and   subscript  L  1      \cfrac{\Gamma,A\vdash\Delta}{\Gamma,A\and B\vdash\Delta}\quad({\and}L_{1})             Γ  ⊢   A  ,  Δ     Γ  ⊢    A  B   ,  Δ       (   R  1   )       continued-fraction   proves  normal-Γ   A  normal-Δ     proves  normal-Γ     A  B   normal-Δ      subscript  R  1     \cfrac{\Gamma\vdash A,\Delta}{\Gamma\vdash AB,\Delta}\quad({}R_{1})                Γ  ,  B   ⊢  Δ     Γ  ,   A  and  B    ⊢  Δ      (   and   L  2    )       continued-fraction   proves   normal-Γ  B   normal-Δ    proves   normal-Γ    A  italic- and  B    normal-Δ      italic- and   subscript  L  2      \cfrac{\Gamma,B\vdash\Delta}{\Gamma,A\and B\vdash\Delta}\quad({\and}L_{2})             Γ  ⊢   B  ,  Δ     Γ  ⊢    A  B   ,  Δ       (   R  2   )       continued-fraction   proves  normal-Γ   B  normal-Δ     proves  normal-Γ     A  B   normal-Δ      subscript  R  2     \cfrac{\Gamma\vdash B,\Delta}{\Gamma\vdash AB,\Delta}\quad({}R_{2})                Γ  ,  A   ⊢   Δ  Σ  ,  B   ⊢  Π     Γ  ,  Σ  ,   A  B    ⊢   Δ  ,  Π       (  L  )       continued-fraction     proves   normal-Γ  A    normal-Δ  normal-Σ  B     proves    normal-Π     proves   normal-Γ  normal-Σ    A  B     normal-Δ  normal-Π     L    \cfrac{\Gamma,A\vdash\Delta\qquad\Sigma,B\vdash\Pi}{\Gamma,\Sigma,AB\vdash%
 \Delta,\Pi}\quad({}L)             Γ  ⊢   A  ,  Δ  Σ   ⊢   B  ,  Π      Γ  ,  Σ   ⊢    A  and  B   ,  Δ  ,  Π       (   and  R   )       continued-fraction     proves  normal-Γ   A  normal-Δ  normal-Σ     proves     B  normal-Π      proves   normal-Γ  normal-Σ      A  italic- and  B   normal-Δ  normal-Π       italic- and  R     \cfrac{\Gamma\vdash A,\Delta\qquad\Sigma\vdash B,\Pi}{\Gamma,\Sigma\vdash A%
 \and B,\Delta,\Pi}\quad({\and}R)               Γ  ⊢   A  ,  Δ  Σ  ,  B   ⊢  Π      Γ  ,  Σ  ,  A   →  B   ⊢   Δ  ,  Π         (    →  L   )      annotated   continued-fraction     proves  normal-Γ   A  normal-Δ  normal-Σ  B     proves    normal-Π     proves   normal-→   normal-Γ  normal-Σ  A   B    normal-Δ  normal-Π      normal-→  absent  L     \cfrac{\Gamma\vdash A,\Delta\qquad\Sigma,B\vdash\Pi}{\Gamma,\Sigma,A%
 \rightarrow B\vdash\Delta,\Pi}\quad({\rightarrow}L)              Γ  ,  A   ⊢   B  ,  Δ     Γ  ⊢   A  →   B  ,  Δ          (    →  R   )      annotated   continued-fraction   proves   normal-Γ  A    B  normal-Δ     proves  normal-Γ   normal-→  A   B  normal-Δ       normal-→  absent  R     \cfrac{\Gamma,A\vdash B,\Delta}{\Gamma\vdash A\rightarrow B,\Delta}\quad({%
 \rightarrow}R)               Γ  ⊢   A  ,  Δ      Γ  ,   ¬  A    ⊢  Δ      (   ¬  L   )       continued-fraction   proves  normal-Γ   A  normal-Δ     proves   normal-Γ     A    normal-Δ       L     \cfrac{\Gamma\vdash A,\Delta}{\Gamma,\lnot A\vdash\Delta}\quad({\lnot}L)              Γ  ,  A   ⊢  Δ    Γ  ⊢    ¬  A   ,  Δ       (   ¬  R   )       continued-fraction   proves   normal-Γ  A   normal-Δ    proves  normal-Γ      A   normal-Δ        R     \cfrac{\Gamma,A\vdash\Delta}{\Gamma\vdash\lnot A,\Delta}\quad({\lnot}R)                Γ  ,   A   [   t  /  x   ]     ⊢  Δ     Γ  ,   ∀   x  A     ⊢  Δ      (   ∀  L   )       continued-fraction   proves   normal-Γ    A   delimited-[]    t  x      normal-Δ    proves   normal-Γ   for-all    x  A     normal-Δ     for-all  L     \cfrac{\Gamma,A[t/x]\vdash\Delta}{\Gamma,\forall xA\vdash\Delta}\quad({\forall%
 }L)             Γ  ⊢    A   [   y  /  x   ]    ,  Δ     Γ  ⊢    ∀   x  A    ,  Δ       (   ∀  R   )       continued-fraction   proves  normal-Γ     A   delimited-[]    y  x     normal-Δ     proves  normal-Γ    for-all    x  A    normal-Δ      for-all  R     \cfrac{\Gamma\vdash A[y/x],\Delta}{\Gamma\vdash\forall xA,\Delta}\quad({%
 \forall}R)                Γ  ,   A   [   y  /  x   ]     ⊢  Δ     Γ  ,   ∃   x  A     ⊢  Δ      (   ∃  L   )       continued-fraction   proves   normal-Γ    A   delimited-[]    y  x      normal-Δ    proves   normal-Γ      x  A     normal-Δ      L     \cfrac{\Gamma,A[y/x]\vdash\Delta}{\Gamma,\exists xA\vdash\Delta}\quad({\exists%
 }L)             Γ  ⊢    A   [   t  /  x   ]    ,  Δ     Γ  ⊢    ∃   x  A    ,  Δ       (   ∃  R   )       continued-fraction   proves  normal-Γ     A   delimited-[]    t  x     normal-Δ     proves  normal-Γ       x  A    normal-Δ       R     \cfrac{\Gamma\vdash A[t/x],\Delta}{\Gamma\vdash\exists xA,\Delta}\quad({%
 \exists}R)        Left structural rules:   Right structural rules:            Γ  ⊢  Δ     Γ  ,  A   ⊢  Δ      (  𝑊𝐿  )       continued-fraction   proves  normal-Γ  normal-Δ    proves   normal-Γ  A   normal-Δ    𝑊𝐿    \cfrac{\Gamma\vdash\Delta}{\Gamma,A\vdash\Delta}\quad(\mathit{WL})             Γ  ⊢  Δ    Γ  ⊢   A  ,  Δ       (  𝑊𝑅  )       continued-fraction   proves  normal-Γ  normal-Δ    proves  normal-Γ   A  normal-Δ     𝑊𝑅    \cfrac{\Gamma\vdash\Delta}{\Gamma\vdash A,\Delta}\quad(\mathit{WR})                Γ  ,  A  ,  A   ⊢  Δ     Γ  ,  A   ⊢  Δ      (  𝐶𝐿  )       continued-fraction   proves   normal-Γ  A  A   normal-Δ    proves   normal-Γ  A   normal-Δ    𝐶𝐿    \cfrac{\Gamma,A,A\vdash\Delta}{\Gamma,A\vdash\Delta}\quad(\mathit{CL})             Γ  ⊢   A  ,  A  ,  Δ     Γ  ⊢   A  ,  Δ       (  𝐶𝑅  )       continued-fraction   proves  normal-Γ   A  A  normal-Δ     proves  normal-Γ   A  normal-Δ     𝐶𝑅    \cfrac{\Gamma\vdash A,A,\Delta}{\Gamma\vdash A,\Delta}\quad(\mathit{CR})                 Γ  1   ,  A  ,  B  ,   Γ  2    ⊢  Δ      Γ  1   ,  B  ,  A  ,   Γ  2    ⊢  Δ      (  𝑃𝐿  )       continued-fraction   proves    subscript  normal-Γ  1   A  B   subscript  normal-Γ  2    normal-Δ    proves    subscript  normal-Γ  1   B  A   subscript  normal-Γ  2    normal-Δ    𝑃𝐿    \cfrac{\Gamma_{1},A,B,\Gamma_{2}\vdash\Delta}{\Gamma_{1},B,A,\Gamma_{2}\vdash%
 \Delta}\quad(\mathit{PL})             Γ  ⊢    Δ  1   ,  A  ,  B  ,   Δ  2      Γ  ⊢    Δ  1   ,  B  ,  A  ,   Δ  2        (  𝑃𝑅  )       continued-fraction   proves  normal-Γ    subscript  normal-Δ  1   A  B   subscript  normal-Δ  2      proves  normal-Γ    subscript  normal-Δ  1   B  A   subscript  normal-Δ  2      𝑃𝑅    \cfrac{\Gamma\vdash\Delta_{1},A,B,\Delta_{2}}{\Gamma\vdash\Delta_{1},B,A,%
 \Delta_{2}}\quad(\mathit{PR})        Restrictions: In the rules    (   ∀  R   )     for-all  R    ({\forall}R)   and    (   ∃  L   )      L    ({\exists}L)   , the variable   y   y   y   must not occur free within   Γ   normal-Γ   \Gamma   and   Δ   normal-Δ   \Delta   . Alternatively, the variable   y   y   y   must not appear anywhere in the respective lower sequents.  An intuitive explanation  The above rules can be divided into two major groups: logical and structural ones. Each of the logical rules introduces a new logical formula either on the left or on the right of the turnstile    ⊢   proves   \vdash   . In contrast, the structural rules operate on the structure of the sequents, ignoring the exact shape of the formulae. The two exceptions to this general scheme are the axiom of identity (I) and the rule of (Cut).  Although stated in a formal way, the above rules allow for a very intuitive reading in terms of classical logic. Consider, for example, the rule    (   and   L  1    )      italic- and   subscript  L  1     ({\and}L_{1})   . It says that, whenever one can prove that   Δ   normal-Δ   \Delta   can be concluded from some sequence of formulae that contain   A   A   A   , then one can also conclude   Δ   normal-Δ   \Delta   from the (stronger) assumption, that    A  and  B      A  italic- and  B    A\and B   holds. Likewise, the rule    (   ¬  R   )       R    ({\neg}R)   states that, if   Γ   normal-Γ   \Gamma   and A suffice to conclude   Δ   normal-Δ   \Delta   , then from Γ alone one can either still conclude   Δ   normal-Δ   \Delta   or A must be false, i.e.    ¬  A       A    {\neg}A   holds. All the rules can be interpreted in this way.  For an intuition about the quantifier rules, consider the rule    (   ∀  R   )     for-all  R    ({\forall}R)   . Of course concluding that    ∀   x  A      for-all    x  A     \forall{x}A   holds just from the fact that    A   [   y  /  x   ]       A   delimited-[]    y  x      A[y/x]   is true is not in general possible. If, however, the variable y is not mentioned elsewhere (i.e. it can still be chosen freely, without influencing the other formulae), then one may assume, that    A   [   y  /  x   ]       A   delimited-[]    y  x      A[y/x]   holds for any value of y. The other rules should then be pretty straightforward.  Instead of viewing the rules as descriptions for legal derivations in predicate logic, one may also consider them as instructions for the construction of a proof for a given statement. In this case the rules can be read bottom-up; for example,    (   and  R   )      italic- and  R    ({\and}R)   says that, to prove that    A  and  B      A  italic- and  B    A\and B   follows from the assumptions   Γ   normal-Γ   \Gamma   and   Σ   normal-Σ   \Sigma   , it suffices to prove that A can be concluded from   Γ   normal-Γ   \Gamma   and B can be concluded from   Σ   normal-Σ   \Sigma   , respectively. Note that, given some antecedent, it is not clear how this is to be split into   Γ   normal-Γ   \Gamma   and   Σ   normal-Σ   \Sigma   . However, there are only finitely many possibilities to be checked since the antecedent by assumption is finite. This also illustrates how proof theory can be viewed as operating on proofs in a combinatorial fashion: given proofs for both A and B, one can construct a proof for A∧B.  When looking for some proof, most of the rules offer more or less direct recipes of how to do this. The rule of cut is different: It states that, when a formula A can be concluded and this formula may also serve as a premise for concluding other statements, then the formula A can be "cut out" and the respective derivations are joined. When constructing a proof bottom-up, this creates the problem of guessing A (since it does not appear at all below). The cut-elimination theorem is thus crucial to the applications of sequent calculus in automated deduction : it states that all uses of the cut rule can be eliminated from a proof, implying that any provable sequent can be given a cut-free proof.  The second rule that is somewhat special is the axiom of identity (I). The intuitive reading of this is obvious: every formula proves itself. Like the cut rule, the axiom of identity is somewhat redundant: the completeness of atomic initial sequents states that the rule can be restricted to atomic formulas without any loss of provability.  Observe that all rules have mirror companions, except the ones for implication. This reflects the fact that the usual language of first-order logic does not include the "is not implied by" connective   ↚   ↚   \not\leftarrow   that would be the De Morgan dual of implication. Adding such a connective with its natural rules would make the calculus completely left-right symmetric.  Example derivations  Here is the derivation of "     ⊢   A  ¬  A      proves  absent    A   A     \vdash A\lnot A   ", known as the Law of excluded middle ( tertium non datur in Latin).                (  I  )    I   (I)        align=center style='border-top:1px solid black;'    A  ⊢  A     proves  A  A    A\vdash A                  (   ¬  R   )       R    (\lnot R)        align=center style='border-top:1px solid black;'     ⊢    ¬  A   ,  A      proves  absent      A   A     \vdash\lnot A,A                  (   R  2   )     subscript  R  2    (R_{2})        align=center style='border-top:1px solid black;'     ⊢    A  ¬  A   ,  A      proves  absent     A   A   A     \vdash A\lnot A,A                  (   P  R   )      P  R    (PR)        align=center style='border-top:1px solid black;'     ⊢   A  ,   A  ¬  A       proves  absent   A    A   A      \vdash A,A\lnot A                  (   R  1   )     subscript  R  1    (R_{1})        align=center style='border-top:1px solid black;'     ⊢    A  ¬  A   ,   A  ¬  A       proves  absent     A   A     A   A      \vdash A\lnot A,A\lnot A                  (   C  R   )      C  R    (CR)        align=center style='border-top:1px solid black;'     ⊢   A  ¬  A      proves  absent    A   A     \vdash A\lnot A                   Next is the proof of a simple fact involving quantifiers. Note that the converse is not true, and its falsity can be seen when attempting to derive it bottom-up, because an existing free variable cannot be used in substitution in the rules    (   ∀  R   )     for-all  R    (\forall R)   and    (   ∃  L   )      L    (\exists L)   .                (  I  )    I   (I)        align=center style='border-top:1px solid black;'     p   (  x  ,  y  )    ⊢   p   (  x  ,  y  )       proves    p   x  y      p   x  y      p(x,y)\vdash p(x,y)                  (   ∀  L   )     for-all  L    (\forall L)        align=center style='border-top:1px solid black;'     ∀   x   (   p   (  x  ,  y  )    )     ⊢   p   (  x  ,  y  )       proves   for-all    x    p   x  y        p   x  y      \forall x\left(p(x,y)\right)\vdash p(x,y)                  (   ∃  R   )      R    (\exists R)        align=center style='border-top:1px solid black;'     ∀   x   (   p   (  x  ,  y  )    )     ⊢   ∃   y   (   p   (  x  ,  y  )    )        proves   for-all    x    p   x  y          y    p   x  y        \forall x\left(p(x,y)\right)\vdash\exists y\left(p(x,y)\right)                  (   ∃  L   )      L    (\exists L)        align=center style='border-top:1px solid black;'     ∃   y   (   ∀   x   (   p   (  x  ,  y  )    )     )     ⊢   ∃   y   (   p   (  x  ,  y  )    )        proves      y   for-all    x    p   x  y            y    p   x  y        \exists y\left(\forall x\left(p(x,y)\right)\right)\vdash\exists y\left(p(x,y)\right)                  (   ∀  R   )     for-all  R    (\forall R)        align=center style='border-top:1px solid black;'     ∃   y   (   ∀   x   (   p   (  x  ,  y  )    )     )     ⊢   ∀   x   (   ∃   y   (   p   (  x  ,  y  )    )     )        proves      y   for-all    x    p   x  y         for-all    x      y    p   x  y          \exists y\left(\forall x\left(p(x,y)\right)\right)\vdash\forall x\left(\exists
 y%
 \left(p(x,y)\right)\right)                   For something more interesting we shall prove    (   (  A  →   (  B  C  )   )   →   (   (   (  B  →  ¬  A  )   and  ¬  C  )   →  ¬  A  )   )     fragments  normal-(   fragments  normal-(  A  normal-→   fragments  normal-(  B  C  normal-)   normal-)   normal-→   fragments  normal-(   fragments  normal-(   fragments  normal-(  B  normal-→   A  normal-)   and   C  normal-)   normal-→   A  normal-)   normal-)    \left(\left(A\rightarrow\left(BC\right)\right)\rightarrow\left(\left(\left(B%
 \rightarrow\lnot A\right)\and\lnot C\right)\rightarrow\lnot A\right)\right)   . It is straightforward to find the derivation, which exemplifies the usefulness of LK in automated proving.                      (  I  )    I   (I)        align=center style='border-top:1px solid black;'    A  ⊢  A     proves  A  A    A\vdash A                  (   ¬  R   )       R    (\lnot R)        align=center style='border-top:1px solid black;'     ⊢    ¬  A   ,  A      proves  absent      A   A     \vdash\lnot A,A                  (   P  R   )      P  R    (PR)        align=center style='border-top:1px solid black;'     ⊢   A  ,   ¬  A       proves  absent   A     A      \vdash A,\lnot A                                       |          (  I  )    I   (I)        align=center style='border-top:1px solid black;'    B  ⊢  B     proves  B  B    B\vdash B                           |          (  I  )    I   (I)        align=center style='border-top:1px solid black;'    C  ⊢  C     proves  C  C    C\vdash C                          rowspan=2    (  L  )    L   (L)        align=center style='border-top:1px solid black;'     B  C   ⊢   B  ,  C      proves    B  C    B  C     BC\vdash B,C                  (   P  R   )      P  R    (PR)        align=center style='border-top:1px solid black;'     B  C   ⊢   C  ,  B      proves    B  C    C  B     BC\vdash C,B                  (   ¬  L   )       L    (\lnot L)        align=center style='border-top:1px solid black;'      B  C   ,   ¬  C    ⊢  B     proves     B  C      C    B    BC,\lnot C\vdash B                                    (  I  )    I   (I)        align=center style='border-top:1px solid black;'     ¬  A   ⊢   ¬  A      proves     A      A     \lnot A\vdash\lnot A                          rowspan=2    (    →  L   )     normal-→  absent  L    (\rightarrow L)        align=center style='border-top:1px solid black;'     (  B  C  )   ,  ¬  C  ,   (  B  →  ¬  A  )   ⊢  ¬  A     fragments   fragments  normal-(  B  C  normal-)   normal-,   C  normal-,   fragments  normal-(  B  normal-→   A  normal-)   proves   A    \left(BC\right),\lnot C,\left(B\rightarrow\lnot A\right)\vdash\lnot A                  (   and   L  1    )      italic- and   subscript  L  1     (\and L_{1})        align=center style='border-top:1px solid black;'     (  B  C  )   ,  ¬  C  ,   (   (  B  →  ¬  A  )   and  ¬  C  )   ⊢  ¬  A     fragments   fragments  normal-(  B  C  normal-)   normal-,   C  normal-,   fragments  normal-(   fragments  normal-(  B  normal-→   A  normal-)   and   C  normal-)   proves   A    \left(BC\right),\lnot C,\left(\left(B\rightarrow\lnot A\right)\and\lnot C%
 \right)\vdash\lnot A                  (   P  L   )      P  L    (PL)        align=center style='border-top:1px solid black;'     (  B  C  )   ,   (   (  B  →  ¬  A  )   and  ¬  C  )   ,  ¬  C  ⊢  ¬  A     fragments   fragments  normal-(  B  C  normal-)   normal-,   fragments  normal-(   fragments  normal-(  B  normal-→   A  normal-)   and   C  normal-)   normal-,   C  proves   A    \left(BC\right),\left(\left(B\rightarrow\lnot A\right)\and\lnot C\right),\lnot
 C%
 \vdash\lnot A                  (   and   L  2    )      italic- and   subscript  L  2     (\and L_{2})        align=center style='border-top:1px solid black;'     (  B  C  )   ,   (   (  B  →  ¬  A  )   and  ¬  C  )   ,   (   (  B  →  ¬  A  )   and  ¬  C  )   ⊢  ¬  A     fragments   fragments  normal-(  B  C  normal-)   normal-,   fragments  normal-(   fragments  normal-(  B  normal-→   A  normal-)   and   C  normal-)   normal-,   fragments  normal-(   fragments  normal-(  B  normal-→   A  normal-)   and   C  normal-)   proves   A    \left(BC\right),\left(\left(B\rightarrow\lnot A\right)\and\lnot C\right),\left%
 (\left(B\rightarrow\lnot A\right)\and\lnot C\right)\vdash\lnot A                  (   C  L   )      C  L    (CL)        align=center style='border-top:1px solid black;'     (  B  C  )   ,   (   (  B  →  ¬  A  )   and  ¬  C  )   ⊢  ¬  A     fragments   fragments  normal-(  B  C  normal-)   normal-,   fragments  normal-(   fragments  normal-(  B  normal-→   A  normal-)   and   C  normal-)   proves   A    \left(BC\right),\left(\left(B\rightarrow\lnot A\right)\and\lnot C\right)\vdash\lnot
 A                  (   P  L   )      P  L    (PL)        align=center style='border-top:1px solid black;'     (   (  B  →  ¬  A  )   and  ¬  C  )   ,   (  B  C  )   ⊢  ¬  A     fragments   fragments  normal-(   fragments  normal-(  B  normal-→   A  normal-)   and   C  normal-)   normal-,   fragments  normal-(  B  C  normal-)   proves   A    \left(\left(B\rightarrow\lnot A\right)\and\lnot C\right),\left(BC\right)\vdash\lnot
 A                          rowspan=2    (    →  L   )     normal-→  absent  L    (\rightarrow L)        align=center style='border-top:1px solid black;'     (   (  B  →  ¬  A  )   and  ¬  C  )   ,   (  A  →   (  B  C  )   )   ⊢  ¬  A  ,  ¬  A     fragments   fragments  normal-(   fragments  normal-(  B  normal-→   A  normal-)   and   C  normal-)   normal-,   fragments  normal-(  A  normal-→   fragments  normal-(  B  C  normal-)   normal-)   proves   A  normal-,   A    \left(\left(B\rightarrow\lnot A\right)\and\lnot C\right),\left(A\rightarrow%
 \left(BC\right)\right)\vdash\lnot A,\lnot A                  (   C  R   )      C  R    (CR)        align=center style='border-top:1px solid black;'     (   (  B  →  ¬  A  )   and  ¬  C  )   ,   (  A  →   (  B  C  )   )   ⊢  ¬  A     fragments   fragments  normal-(   fragments  normal-(  B  normal-→   A  normal-)   and   C  normal-)   normal-,   fragments  normal-(  A  normal-→   fragments  normal-(  B  C  normal-)   normal-)   proves   A    \left(\left(B\rightarrow\lnot A\right)\and\lnot C\right),\left(A\rightarrow%
 \left(BC\right)\right)\vdash\lnot A                  (   P  L   )      P  L    (PL)        align=center style='border-top:1px solid black;'     (  A  →   (  B  C  )   )   ,   (   (  B  →  ¬  A  )   and  ¬  C  )   ⊢  ¬  A     fragments   fragments  normal-(  A  normal-→   fragments  normal-(  B  C  normal-)   normal-)   normal-,   fragments  normal-(   fragments  normal-(  B  normal-→   A  normal-)   and   C  normal-)   proves   A    \left(A\rightarrow\left(BC\right)\right),\left(\left(B\rightarrow\lnot A\right%
 )\and\lnot C\right)\vdash\lnot A                  (    →  R   )     normal-→  absent  R    (\rightarrow R)        align=center style='border-top:1px solid black;'     (  A  →   (  B  C  )   )   ⊢   (   (   (  B  →  ¬  A  )   and  ¬  C  )   →  ¬  A  )      fragments   fragments  normal-(  A  normal-→   fragments  normal-(  B  C  normal-)   normal-)   proves   fragments  normal-(   fragments  normal-(   fragments  normal-(  B  normal-→   A  normal-)   and   C  normal-)   normal-→   A  normal-)     \left(A\rightarrow\left(BC\right)\right)\vdash\left(\left(\left(B\rightarrow%
 \lnot A\right)\and\lnot C\right)\rightarrow\lnot A\right)                  (    →  R   )     normal-→  absent  R    (\rightarrow R)        align=center style='border-top:1px solid black;'    ⊢   (   (  A  →   (  B  C  )   )   →   (   (   (  B  →  ¬  A  )   and  ¬  C  )   →  ¬  A  )   )      fragments  proves   fragments  normal-(   fragments  normal-(  A  normal-→   fragments  normal-(  B  C  normal-)   normal-)   normal-→   fragments  normal-(   fragments  normal-(   fragments  normal-(  B  normal-→   A  normal-)   and   C  normal-)   normal-→   A  normal-)   normal-)     \vdash\left(\left(A\rightarrow\left(BC\right)\right)\rightarrow\left(\left(%
 \left(B\rightarrow\lnot A\right)\and\lnot C\right)\rightarrow\lnot A\right)\right)                   These derivations also emphasize the strictly formal structure of the sequent calculus. For example, the logical rules as defined above always act on a formula immediately adjacent to the turnstile, such that the permutation rules are necessary. Note, however, that this is in part an artifact of the presentation, in the original style of Gentzen. A common simplification involves the use of multisets of formulas in the interpretation of the sequent, rather than sequences, eliminating the need for an explicit permutation rule. This corresponds to shifting commutativity of assumptions and derivations outside the sequent calculus, whereas LK embeds it within the system itself.  Structural rules  The structural rules deserve some additional discussion.  Weakening (W) allows the addition of arbitrary elements to a sequence. Intuitively, this is allowed in the antecedent because we can always restrict the scope of our proof (if all cars have wheels, then it's safe to say that all black cars have wheels); and in the succedent because we can always allow for alternative conclusions (if all cars have wheels, then it's safe to say that all cars have either wheels or wings).  Contraction (C) and Permutation (P) assure that neither the order (P) nor the multiplicity of occurrences (C) of elements of the sequences matters. Thus, one could instead of sequences also consider sets .  The extra effort of using sequences, however, is justified since part or all of the structural rules may be omitted. Doing so, one obtains the so-called substructural logics .  Properties of the system LK  This system of rules can be shown to be both sound and complete with respect to first-order logic, i.e. a statement    A    A   A\,   follows semantically from a set of premises    Γ    normal-Γ   \Gamma\,       (   Γ  ⊨  A   )     normal-⊨  normal-Γ  A    (\Gamma\vDash A)    iff the sequent    Γ  ⊢  A     proves  normal-Γ  A    \Gamma\vdash A   can be derived by the above rules. 21  In the sequent calculus, the rule of cut is admissible . This result is also referred to as Gentzen's Hauptsatz ("Main Theorem"). 22 23  Variants  The above rules can be modified in various ways:  Minor structural alternatives  There is some freedom of choice regarding the technical details of how sequents and structural rules are formalized. As long as every derivation in LK can be effectively transformed to a derivation using the new rules and vice versa, the modified rules may still be called LK.  First of all, as mentioned above, the sequents can be viewed to consist of sets or multisets . In this case, the rules for permuting and (when using sets) contracting formulae are obsolete.  The rule of weakening will become admissible, when the axiom (I) is changed, such that any sequent of the form     Γ  ,  A   ⊢   A  ,  Δ      proves   normal-Γ  A    A  normal-Δ     \Gamma,A\vdash A,\Delta   can be concluded. This means that   A   A   A   proves   A   A   A   in any context. Any weakening that appears in a derivation can then be performed right at the start. This may be a convenient change when constructing proofs bottom-up.  Independent of these one may also change the way in which contexts are split within the rules: In the cases     (   and  R   )   ,   (  L  )        italic- and  R   L    ({\and}R),({}L)   , and    (    →  L   )     normal-→  absent  L    ({\rightarrow}L)   the left context is somehow split into   Γ   normal-Γ   \Gamma   and   Σ   normal-Σ   \Sigma   when going upwards. Since contraction allows for the duplication of these, one may assume that the full context is used in both branches of the derivation. By doing this, one assures that no important premises are lost in the wrong branch. Using weakening, the irrelevant parts of the context can be eliminated later.  Absurdity  One can introduce   ⊥   bottom   \bot   , the absurdity constant representing false , with the axiom:        ⊥  ⊢      continued-fraction  absent   fragments  bottom  proves      \cfrac{}{\bot\vdash\quad}     Or if, as described above, weakening is to be an admissible rule, then with the axiom:        Γ  ,  ⊥  ⊢  Δ      continued-fraction  absent   fragments  Γ  normal-,  bottom  proves  Δ     \cfrac{}{\Gamma,\bot\vdash\Delta}     With   ⊥   bottom   \bot   , negation can be subsumed as a special case of implication, via the definition     ¬  A   ⇔   A  →  ⊥      iff     A    normal-→  A  bottom     \neg A\iff A\to\bot   .  Substructural logics  Alternatively, one may restrict or forbid the use of some of the structural rules. This yields a variety of substructural logic systems. They are generally weaker than LK ( i.e. , they have fewer theorems), and thus not complete with respect to the standard semantics of first-order logic. However, they have other interesting properties that have led to applications in theoretical computer science and artificial intelligence .  Intuitionistic sequent calculus: System LJ  Surprisingly, some small changes in the rules of LK suffice to turn it into a proof system for intuitionistic logic . 24 To this end, one has to restrict to sequents with exactly one formula on the right-hand side, and modify the rules to maintain this invariant. For example,    (  L  )    L   ({}L)   is reformulated as follows (where C is an arbitrary formula):         Γ  ,  A   ⊢   C  Σ  ,  B   ⊢  C     Γ  ,  Σ  ,   A  B    ⊢  C     (  L  )       continued-fraction     proves   normal-Γ  A    C  normal-Σ  B     proves    C     proves   normal-Γ  normal-Σ    A  B    C    L    \cfrac{\Gamma,A\vdash C\qquad\Sigma,B\vdash C}{\Gamma,\Sigma,AB\vdash C}\quad(%
 {}L)     The resulting system is called LJ. It is sound and complete with respect to intuitionistic logic and admits a similar cut-elimination proof. This can be used in proving disjunction and existence properties .  In fact, the only two rules in LK that need to be restricted to single-formula consequents are    (    →  R   )     normal-→  absent  R    ({\to}R)   and    (   ¬  R   )       R    (\neg R)    25 (and the latter can be seen as a special case of the former, via   ⊥   bottom   \bot   as described above). When multi-formula consequents are interpreted as disjunctions, all of the other inference rules of LK are actually derivable in LJ, while the offending rule is        Γ  ,  A   ⊢   B  C     Γ  ⊢   (  A  →  B  )   C      continued-fraction   proves   normal-Γ  A     B  C     fragments  Γ  proves   fragments  normal-(  A  normal-→  B  normal-)   C     \cfrac{\Gamma,A\vdash BC}{\Gamma\vdash(A\to B)C}     This amounts to the propositional formula     (  A  →   (  B  C  )   )   →   (   (  A  →  B  )   C  )      fragments   fragments  normal-(  A  normal-→   fragments  normal-(  B  C  normal-)   normal-)   normal-→   fragments  normal-(   fragments  normal-(  A  normal-→  B  normal-)   C  normal-)     (A\to(BC))\to((A\to B)C)   , a classical tautology that is not constructively valid.  See also   Resolution (logic)   Notes  References               External links    A Brief Diversion: Sequent Calculus  Interactive tutorial of the Sequent Calculus   "  Category:Proof theory  Category:Logical calculi  Category:Automated theorem proving     , . ↩  , gives a 5-page proof of the elimination theorem. See also pages 188, 250. ↩  , gives a very brief proof of the cut-elimination theorem. ↩  , calls Gentzen systems LC systems. Curry's emphasis is more on theory than on practical logic proofs. ↩  . This book is much more concerned with the theoretical, metamathematical implications of Gentzen-style sequent calculus than applications to practical logic proofs. ↩  , defines Gentzen systems and proves various theorems within these systems, including Gödel's completeness theorem and Gentzen's theorem. ↩  , gives a brief theoretical presentation of Gentzen systems. He uses the tableau proof layout style. ↩  , compares natural deduction systems, denoted LA, and Gentzen systems, denoted LC. Curry's emphasis is more theoretical than practical. ↩  , is an introductory presentation of practical natural deduction of this kind. This became the basis of System L . ↩  is an elementary introduction to practical natural deduction based on the convenient abbreviated proof layout style System L based on . ↩  Here, "whenever" is used as an informal abbreviation "for every assignment of values to the free variables in the judgment" ↩  ↩  ↩  For explanations of the disjunctive semantics for the right side of sequents, see , , , ,  and . ↩  . "Der Kalkül NJ hat manche formale Unschönheiten." ↩  . "In dem klassischen Kalkül NK nahm der Satz vom ausgeschlossenen Dritten eine Sonderstellung unter den Schlußweisen ein [...], indem er sich der Einführungs- und Beseitigungssystematik nicht einfügte. Bei dem im folgenden anzugebenden logistischen klassichen Kalkül LK wird diese Sonderstellung aufgehoben." ↩  . "Die damit erreichte Symmetrie erweist sich als für die klassische Logik angemessener." ↩  . "Hiermit haben wir einige Gesichtspunkte zur Begründung der Aufstellung der folgenden Kalküle angegeben. Im wesentlichen ist ihre Form jedoch durch die Rücksicht auf den nachher zu beweisenden 'Hauptsatz' bestimmt und kann daher vorläufig nicht näher begründet werden." ↩   . ↩  , wrote in 1967 that "it was a major logical discovery by Gentzen 1934–5 that, when there is any (purely logical) proof of a proposition, there is a direct proof. The implications of this discovery are in theoretical logical investigations, rather than in building collections of proved formulas." ↩    , wrote: "Der Unterschied zwischen intuitionistischer und klassischer Logik ist bei den Kalkülen LJ und LK äußerlich ganz anderer Art als bei NJ und NK . Dort bestand er in Weglassung bzw. Hinzunahme des Satzes vom ausgeschlossenen Dritten, während er hier durch die Sukzedensbedingung ausgedrückt wird." English translation: "The difference between intuitionistic and classical logic is in the case of the calculi LJ and LK of an extremely, totally different kind to the case of NJ and NK . In the latter case, it consisted of the removal or addition respectively of the excluded middle rule, whereas in the former case, it is expressed through the succedent conditions." ↩  Structural Proof Theory (CUP, 2001), Sara Negri and Jan van Plato ↩     