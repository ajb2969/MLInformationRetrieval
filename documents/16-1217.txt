   SUPS      SUPS   In computational neuroscience , SUPS (for S ynaptic U pdates P er S econd) or formerly CUPS ( C onnections U pdates P er S econd) is a measure of a neuronal network performance, useful in fields of neuroscience , cognitive science , artificial intelligence , and computer science .  Computing  For a processor or computer designed to simulate a neural network SUPS is measured as the product of simulated neurons   N   N   N   and average connectivity   c   c   c   (synapses) per neuron per second:       S  U  P  S   =   c  ×  N         S  U  P  S     c  N     SUPS=c\times N     Depending on the type of simulation it is usual equal to the total number of synapses simulated.  In an "asynchronous" dynamic simulation if a neuron spikes at   υ   υ   \upsilon   Hz, the average rate of synaptic updates provoked by the activity of that neuron is    υ  c  N      υ  c  N    \upsilon cN   . In a synchronous simulation with step    Δ  t      normal-Δ  t    \Delta t   the number of synaptic updates per second would be     c  N    Δ  t         c  N     normal-Δ  t     \frac{cN}{\Delta t}   . As    Δ  t      normal-Δ  t    \Delta t   has to be chosen much smaller than the average interval between two successive afferent spikes, which implies     Δ  t   <   1   υ  N          normal-Δ  t     1    υ  N      \Delta t<\frac{1}{\upsilon N}   , giving an average of synaptic updates equal to    υ  c   N  2       υ  c   superscript  N  2     \upsilon cN^{2}   . Therefore, spike-driven synaptic dynamics leads to a linear scaling of computational complexity O (N) per neuron, compared with the O(N 2 ) in the "synchronous" case. 1  Records  Developed in the 1980s Adaptive Solutions' CNAPS-1064 Digital Parallel Processor chip is a full neural network (NNW) . It was designed as a coprocessor to a host and has 64 sub-processors arranged in a 1D array and operating in a SIMD mode. Each sub-processor can emulate one or more neurons and multiple chips can be grouped together. At 25 MHz it is capable of 1.28 GMAC . 2  After the presentation of the RN-100 (12 MHz) single neuron chip at Seattle 1991 Ricoh developed the multi-neuron chip RN-200. It had 16 neurons and 16 synapses per neuron. The chip has on-chip learning ability using a proprietary backdrop algorithm. It comes in a 257-pin PGA encapsulation and develops 3.0 W (max). It was capable of 3 GCPS (1 GCPS at 32 MHz). 3  In 1991-97, Siemens developed the MA-16 chip, SYNAPSE-1 and SYNAPSE-3 Neurocomputer. The MA-16 is a fast matrix-matrix multiplier that can be combined to form systolic arrays. It can process 4 patterns of 16 elements each (16-bit), with 16 neuron values (16-bit) at a rate of 800 MMAC or 400 MCPS at 50 MHz. The SYNAPSE3-PC PCI card contains 2 MA-16 with a peak performance of 2560 MOPS (1.28 GMAC); 7160 MOPS (3.58 GMAC) when using three boards. 4  In 2013, the K computer was used to simulate a neural network of 1.73 billion neurons with a total of 10.4 trillion synapses (1% of the human brain). The simulation ran for 40 minutes to simulate 1 s of brain activity at a normal activity level (4.4 on average). The simulation required 1 Petabyte of storage. 5  See also   FLOP  SPECint  SPECfp  Multiply–accumulate operation  Orders of magnitude (computing)    SyNAPSE   References  External links  "  Category:Computer benchmarks  Category:Units of frequency  Category:Artificial intelligence  Category:Computational neuroscience  Category:Neurotechnology     ↩  Real-Time Computing: Implications for General Microprocessors Chip Weems, Steve Dropsho ↩  ↩  Neural Network Hardware Clark S. Lindsey , Bruce Denby , Thomas Lindblad, 1998 ↩  Fujitsu supercomputer simulates 1 second of brain activity Tim Hornyak, CNET, August 5, 2013 ↩     