   Characteristic polynomial      Characteristic polynomial   In linear algebra , the characteristic polynomial of a square matrix is a polynomial , which is invariant under matrix similarity and has the eigenvalues as roots . It has the determinant and the trace of the matrix as coefficients. The characteristic polynomial of an endomorphism of vector spaces of finite dimension is the characteristic polynomial of the matrix of the endomorphism over any base; it does not depend on the choice of a basis. The characteristic equation is the equation obtained by equating to zero the characteristic polynomial.  The characteristic polynomial of a graph is the characteristic polynomial of its adjacency matrix . It is a graph invariant , though it is not complete: the smallest pair of non-isomorphic graphs with the same characteristic polynomial have five nodes. 1  Motivation  Given a square matrix A , we want to find a polynomial whose zeros are the eigenvalues of A . For a diagonal matrix  A , the characteristic polynomial is easy to define: if the diagonal entries are a 1 , a 2 , a 3 ,Â etc. then the characteristic polynomial will be:        (   t  -   a  1    )    (   t  -   a  2    )    (   t  -   a  3    )   â‹¯   .        t   subscript  a  1      t   subscript  a  2      t   subscript  a  3    normal-â‹¯    (t-a_{1})(t-a_{2})(t-a_{3})\cdots.\,     This works because the diagonal entries are also the eigenvalues of this matrix.  For a general matrix A , one can proceed as follows. A scalar Î» is an eigenvalue of A if and only if there is an eigenvector  v â‰  0 such that        A  ð¯   =   Î»  ð¯    ,        A  ð¯     Î»  ð¯     A\mathbf{v}=\lambda\mathbf{v},\,   or        (    Î»  I   -  A   )   ð¯   =   0             Î»  I   A   ð¯   0    (\lambda I-A)\mathbf{v}=0\,     (where I is the identity matrix ). Since v is non-zero, this means that the matrix Î»  I âˆ’ A'' is singular (non-invertible), which in turn means that its determinant is 0. Thus the roots of the function det( Î»  I âˆ’ A'') are the eigenvalues of A , and it is clear that this determinant is a polynomial in Î» .  Formal definition  We consider an n Ã— n matrix A . The characteristic polynomial of A , denoted by p A ( t ), is the polynomial defined by        p  A    (  t  )    =   det   (    t  ð‘°   -  A   )           subscript  p  A   t         t  ð‘°   A      p_{A}(t)=\det\left(t\boldsymbol{I}-A\right)   where I denotes the n -by- n  identity matrix .  Some authors define the characteristic polynomial to be det( A - t  I ). That polynomial differs from the one defined here by a sign (âˆ’1) n , so it makes no difference for properties like having as roots the eigenvalues of A ; however the current definition always gives a monic polynomial , whereas the alternative definition always has constant term det( A ).  Examples  Suppose we want to compute the characteristic polynomial of the matrix       A  =   (     2    1       -  1     0     )    .      A    2  1      1   0      A=\begin{pmatrix}2&1\\
 -1&0\end{pmatrix}.   We now compute the determinant of        t  I   -  A   =   (      t  -  2      -  1       1      t  -  0   ;      )           t  I   A       t  2     1     1    t  0       tI-A=\begin{pmatrix}t-2&-1\\
 1&t-0\end{pmatrix}   which is        (   t  -  2   )   t   -   1   (   -  1   )     =     t  2   -   2  t    +  1    ,            t  2   t     1    1          superscript  t  2     2  t    1     (t-2)t-1(-1)=t^{2}-2t+1\,\!,   the characteristic polynomial of A .  Another example uses hyperbolic functions of a hyperbolic angle Ï†. For the matrix take       A  =   (      cosh   (  Ï•  )       sinh   (  Ï•  )         sinh   (  Ï•  )       cosh   (  Ï•  )       )    .      A      Ï•     Ï•       Ï•     Ï•       A=\begin{pmatrix}\cosh(\phi)&\sinh(\phi)\\
 \sinh(\phi)&\cosh(\phi)\end{pmatrix}.   Its characteristic polynomial is        det   (    t  I   -  A   )    =     (   t  -   cosh   (  Ï•  )     )   2   -    sinh  2    (  Ï•  )     =     t  2   -   2   t    cosh   (  Ï•  )      +  1   =    (   t  -   e  Ï•    )    (   t  -   e   -  Ï•     )     .              t  I   A       superscript    t    Ï•    2     superscript   2   Ï•              superscript  t  2     2  t    Ï•     1            t   superscript  e  Ï•      t   superscript  e    Ï•         \det(tI-A)=(t-\cosh(\phi))^{2}-\sinh^{2}(\phi)=t^{2}-2t\ \cosh(\phi)+1=(t-e^{%
 \phi})(t-e^{-\phi}).     Properties  The polynomial p A ( t ) is monic (its leading coefficient is 1) and its degree is n . The most important fact about the characteristic polynomial was already mentioned in the motivational paragraph: the eigenvalues of A are precisely the roots of p A ( t ) (this also holds for the minimal polynomial of A , but its degree may be less than n ). The coefficients of the characteristic polynomial are all polynomial expressions in the entries of the matrix. In particular its constant coefficient p A (0)Â  is det(âˆ’ A ) = (âˆ’1) n det( A ), the coefficient of is one, and the coefficient of is tr(âˆ’ A ) = âˆ’tr( A ), where    t  r   (  A  )       t  r  A    tr(A)   is the matrix trace of A . (The signs given here correspond to the formal definition given in the previous section; 2 for the alternative definition these would instead be det( A ) and (âˆ’1) n âˆ’Â 1 tr( A ) respectively. 3 )  For a 2Ã—2 matrix A , the characteristic polynomial is thus given by         t  2   -    tr   (  A  )    t    +   det   (  A  )     .         superscript  t  2     tr  A   t      A     t^{2}-\operatorname{tr}(A)t+\det(A).     Using the language of exterior algebra , one may compactly express the characteristic polynomial of an n Ã— n matrix A as        p  A    (  t  )    =    âˆ‘   k  =  0   n     t   n  -  k      (   -  1   )   k    tr   (    Î›  k   A   )             subscript  p  A   t     superscript   subscript     k  0    n      superscript  t    n  k     superscript    1   k    tr     superscript  normal-Î›  k   A        p_{A}(t)=\sum_{k=0}^{n}t^{n-k}(-1)^{k}\operatorname{tr}(\Lambda^{k}A)   where tr(Î› k A) is the trace of the k th exterior power of A , which has dimension    (      n      k      )     binomial  n  k    {\textstyle\left({{n}\atop{k}}\right)}   . This trace may be computed as the sum of all principal minors of A of size k ; when the characteristic is 0 it may alternatively be computed as a single determinant, that of the    k  Ã—  k      k  normal-Ã—  k    kÃ—k   matrix,        1   k  !      |      tr  A      k  -  1     0    â‹¯          tr   A  2       tr  A      k  -  2     â‹¯         â‹®    â‹®       â‹±    â‹®       tr   A   k  -  1        tr   A   k  -  2          â‹¯    1       tr   A  k       tr   A   k  -  1          â‹¯     tr  A      |     .        1    k         tr  A     k  1   0  normal-â‹¯  absent     tr   superscript  A  2     tr  A     k  2   normal-â‹¯  absent    normal-â‹®  normal-â‹®  absent  normal-â‹±  normal-â‹®     tr   superscript  A    k  1      tr   superscript  A    k  2     absent  normal-â‹¯  1     tr   superscript  A  k     tr   superscript  A    k  1     absent  normal-â‹¯   tr  A        \frac{1}{k!}\begin{vmatrix}\operatorname{tr}A&k-1&0&\cdots&\\
 \operatorname{tr}A^{2}&\operatorname{tr}A&k-2&\cdots&\\
 \vdots&\vdots&&\ddots&\vdots\\
 \operatorname{tr}A^{k-1}&\operatorname{tr}A^{k-2}&&\cdots&1\\
 \operatorname{tr}A^{k}&\operatorname{tr}A^{k-1}&&\cdots&\operatorname{tr}A\end%
 {vmatrix}~{}.     The Cayleyâ€“Hamilton theorem states that replacing t by A in the characteristic polynomial (interpreting the resulting powers as matrix powers, and the constant term c as c times the identity matrix) yields the zero matrix. Informally speaking, every matrix satisfies its own characteristic equation. This statement is equivalent to saying that the minimal polynomial of A divides the characteristic polynomial of A .  Two similar matrices have the same characteristic polynomial. The converse however is not true in general: two matrices with the same characteristic polynomial need not be similar.  The matrix A and its transpose have the same characteristic polynomial. A is similar to a triangular matrix  if and only if its characteristic polynomial can be completely factored into linear factors over K (the same is true with the minimal polynomial instead of the characteristic polynomial). In this case A is similar to a matrix in Jordan normal form .  Characteristic polynomial of a product of two matrices  If A and B are two square nÃ—n matrices then characteristic polynomials of AB and BA coincide:         p   A  B     (  t  )    =    p   B  A     (  t  )     .         subscript  p    A  B    t      subscript  p    B  A    t     p_{AB}(t)=p_{BA}(t).\,     When A is non-singular this result follows from the fact that AB and BA are similar :        B  A   =    A   -  1     (   A  B   )   A    .        B  A      superscript  A    1      A  B   A     BA=A^{-1}(AB)A.     For the case where both A and B are singular, one may remark that the desired identity is an equality between polynomials in t and the coefficients of the matrices. Thus, to prove this equality, it suffices to prove that it is verified on a non-empty open subset (for the usual topology , or, more generally, for the Zariski topology ) of the space of all the coefficients. As the non-singular matrices form such an open subset of the space of all matrices, this proves the result.  More generally, if A is a matrix of order mÃ—n and B is a matrix of order nÃ—m , then AB is mÃ—m and BA is nÃ—n matrix, and one has         p   B  A     (  t  )    =    t   n  -  m     p   A  B     (  t  )     .         subscript  p    B  A    t      superscript  t    n  m     subscript  p    A  B    t     p_{BA}(t)=t^{n-m}p_{AB}(t).\,     To prove this, one may suppose n > m , by exchanging, if needed, A and B . Then, by bordering A on the bottom by n â€“ m rows of zeros, and B on the right, by, n â€“ m columns of zeros, one gets two nÃ—n matrices ''A' ''and ''B' '' such that ''B'A' ''= BA , and ''A'B' '' is equal to AB bordered by n â€“ m rows and columns of zeros. The result follows from the case of square matrices, by comparing the characteristic polynomials of ''A'B' '' and AB .  Secular function and secular equation  Secular function  The term secular function has been used for what is now called characteristic polynomial (in some literature the term secular function is still used). The term comes from the fact that the characteristic polynomial was used to calculate secular perturbations (on a time scale of a century, i.e. slow compared to annual motion) of planetary orbits, according to Lagrange 's theory of oscillations.  Secular equation  Secular equation may have several meanings.   In linear algebra it is sometimes used in place of characteristic equation.    In astronomy it is the algebraic or numerical expression of the magnitude of the inequalities in a planet's motion that remain after the inequalities of a short period have been allowed for. 4    In molecular orbital calculations relating to the energy of the electron and its wave function it is also used instead of the characteristic equation.   See also   Characteristic equation  Minimal polynomial  Invariants of tensors  Companion matrix   References   T.S. Blyth & E.F. Robertson (1998) Basic Linear Algebra , p 149, Springer ISBN 3-540-76122-5 .  John B. Fraleigh & Raymond A. Beauregard (1990) Linear Algebra 2nd edition, p 246, Addison-Wesley ISBN 0-201-11949-8 .  Werner Greub (1974) Linear Algebra 4th edition, pp 120â€“5, Springer, ISBN 0-387-90110-8 .  Paul C. Shields (1980) Elementary Linear Algebra 3rd edition, p 274, Worth Publishers ISBN 0-87901-121-1 .  Gilbert Strang (1988) Linear Algebra and Its Applications 3rd edition, p 246, Brooks/Cole ISBN 0-15-551005-3 .   External links   R. Skip Garibaldi. The characteristic polynomial and determinant are not ad hoc constructions. http://arxiv.org/abs/math/0203276   "  Category:Polynomials  Category:Linear algebra  Category:Tensors     â†©  Proposition 28 in these lecture notes â†©  Theorem 4 in these lecture notes â†©  â†©     