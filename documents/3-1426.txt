   Tridiagonal matrix      Tridiagonal matrix   In linear algebra , a tridiagonal matrix is a matrix that has nonzero elements only on the main diagonal , the first diagonal below this, and the first diagonal above the main diagonal.  For example, the following matrix is tridiagonal:       (     1    4    0    0      3    4    1    0      0    2    3    4      0    0    1    3     )   .      1  4  0  0    3  4  1  0    0  2  3  4    0  0  1  3     \begin{pmatrix}1&4&0&0\\
 3&4&1&0\\
 0&2&3&4\\
 0&0&1&3\\
 \end{pmatrix}.     The determinant of a tridiagonal matrix is given by the continuant of its elements. 1  An orthogonal transformation of a symmetric (or Hermitian) matrix to tridiagonal form can be done with the Lanczos algorithm .  Properties  A tridiagonal matrix is a matrix that is both upper and lower Hessenberg matrix . 2 In particular, a tridiagonal matrix is a direct sum of p 1-by-1 and q 2-by-2 matrices such that p + q/2 = n -- the dimension of the tridiagonal. Although a general tridiagonal matrix is not necessarily symmetric or Hermitian , many of those that arise when solving linear algebra problems have one of these properties. Furthermore, if a real tridiagonal matrix A satisfies a k , k +1  a k +1, k > 0 for all k , so that the signs of its entries are symmetric, then it is similar to a Hermitian matrix, by a diagonal change of basis matrix. Hence, its eigenvalues are real. If we replace the strict inequality by a k , k +1  a k +1, k ≥ 0, then by continuity, the eigenvalues are still guaranteed to be real, but the matrix need no longer be similar to a Hermitian matrix. 3  The set of all n × n tridiagonal matrices forms a 3n-2  dimensional  vector space .  Many linear algebra algorithms require significantly less computational effort when applied to diagonal matrices, and this improvement often carries over to tridiagonal matrices as well.  Determinant  The determinant of a tridiagonal matrix A of order n can be computed from a three-term recurrence relation . 4 Write f 1 = | a 1 | = a 1 and    f_n = \begin{vmatrix}     a_1 & b_1 \\ c_1 & a_2 & b_2 \\ & c_2 & \ddots & \ddots \\ & & \ddots & \ddots & b_{n-1} \\ & & & c_{n-1} & a_n \end{vmatrix}. The sequence ( f i ) is called the continuant and satisfies the recurrence relation         f  n   =     a  n    f   n  -  1     -    c   n  -  1     b   n  -  1     f   n  -  2           subscript  f  n        subscript  a  n    subscript  f    n  1        subscript  c    n  1     subscript  b    n  1     subscript  f    n  2        f_{n}=a_{n}f_{n-1}-c_{n-1}b_{n-1}f_{n-2}        with initial values f 0 = 1 and f -1 = 0. The cost of computing the determinant of a tridiagonal matrix using this formula is linear in n , while the cost is cubic for a general matrix.  Inversion  The inverse of a non-singular tridiagonal matrix T    T = \begin{pmatrix}     a_1 & b_1 \\ c_1 & a_2 & b_2 \\ & c_2 & \ddots & \ddots \\ & & \ddots & \ddots & b_{n-1} \\ & & & c_{n-1} & a_n \end{pmatrix} is given by    (T^{-1})_{ij} = \begin{cases}     (-1)^{i+j}b_i \cdots b_{j-1} \theta_{i-1} \phi_{j+1}/\theta_n & \text{ if } i \leq j\\ (-1)^{i+j}c_j \cdots c_{i-1} \theta_{j-1} \phi_{i+1}/\theta_n & \text{ if } i > j\\ \end{cases} where the θ i satisfy the recurrence relation          θ  i   =     a  i    θ   i  -  1     -    b   i  -  1     c   i  -  1     θ   i  -  2         for  i   =   2  ,  3  ,  …  ,  n       formulae-sequence     subscript  θ  i        subscript  a  i    subscript  θ    i  1        subscript  b    i  1     subscript  c    i  1     subscript  θ    i  2           for  i    2  3  normal-…  n      \theta_{i}=a_{i}\theta_{i-1}-b_{i-1}c_{i-1}\theta_{i-2}\quad\text{ for }i=2,3,%
 \ldots,n        with initial conditions θ 0 = 1, θ 1 = a 1 and the ϕ i satisfy          ϕ  i   =     a  i    ϕ   i  +  1     -    b  i    c  i    ϕ   i  +  2         for  i   =    n  -  1   ,  …  ,  1       formulae-sequence     subscript  ϕ  i        subscript  a  i    subscript  ϕ    i  1        subscript  b  i    subscript  c  i    subscript  ϕ    i  2           for  i      n  1   normal-…  1      \phi_{i}=a_{i}\phi_{i+1}-b_{i}c_{i}\phi_{i+2}\quad\text{ for }i=n-1,\ldots,1        with initial conditions ϕ n +1 = 1 and ϕ n = a n . 5 6  Closed form solutions can be computed for special cases such as symmetric matrices with all off-diagonal elements equal 7 or Toeplitz matrices 8 and for the general case as well. 9 10  In general, the inverse of a tridiagonal matrix is a semiseparable matrix and vice versa. 11  Solution of linear system  A system of equations A  x = b for    b  ∈    \reals   n       b   superscript  \reals  n     \scriptstyle b\in\reals^{n}   can be solved by an efficient form of Gaussian elimination when A is tridiagonal called tridiagonal matrix algorithm , requiring O(n) operations. 12  Eigenvalues  When a tridiagonal matrix is also Toeplitz , there is a simple closed-form solution for its eigenvalues, namely    a  +   2     b  c      cos   (    k  π   /   (   n  +  1   )    )         a    2      b  c          k  π     n  1        a+2\sqrt{bc}\,\cos(k\pi/{(n+1)})   , for     k  =   1  ,  …  ,  n    .      k   1  normal-…  n     k=1,...,n.    13 14  Computer programming  A transformation that reduces a general matrix to Hessenberg form will reduce a Hermitian matrix to tridiagonal form. So, many eigenvalue algorithms , when applied to a Hermitian matrix, reduce the input Hermitian matrix to tridiagonal form as a first step.  A tridiagonal matrix can also be stored more efficiently than a general matrix by using a special storage scheme . For instance, the LAPACK  Fortran package stores an unsymmetric tridiagonal matrix of order n in three one-dimensional arrays, one of length n containing the diagonal elements, and two of length n − 1 containing the subdiagonal and superdiagonal elements.  See also   Pentadiagonal matrix   Notes    External links   Tridiagonal and Bidiagonal Matrices in the LAPACK manual.  Module for Tri-Diagonal Linear Systems   High performance algorithms for reduction to condensed (Hessenberg, tridiagonal, bidiagonal) form  Tridiagonal linear system solver in C++   "  Category:Sparse matrices     ↩  ↩  Horn & Johnson, page 174 ↩  ↩  ↩  ↩  ↩  ↩  ↩  ↩  ↩  ↩  ↩  This can also be written as    a  -   2     b  c      cos   (    k  π   /   (   n  +  1   )    )         a    2      b  c          k  π     n  1        a-2\sqrt{bc}\,\cos(k\pi/{(n+1)})   because     cos   (  x  )    =   -   cos   (   π  -  x   )           x         π  x       \cos(x)=-\cos(\pi-x)   , as is done in: ↩     