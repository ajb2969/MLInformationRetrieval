   Subgradient method      Subgradient method   Subgradient methods are iterative methods for solving convex minimization problems. Originally developed by Naum Z. Shor and others in the 1960s and 1970s, subgradient methods are convergent when applied even to a non-differentiable objective function. When the objective function is differentiable, subgradient methods for unconstrained problems use the same search direction as the method of steepest descent .  Subgradient methods are slower than Newton's method when applied to minimize twice continuously differentiable convex functions. However, Newton's method fails to converge on problems that have non-differentiable kinks.  In recent years, some interior-point methods have been suggested for convex minimization problems, but subgradient projection methods and related bundle methods of descent remain competitive. For convex minimization problems with very large number of dimensions, subgradient-projection methods are suitable, because they require little storage.  Subgradient projection methods are often applied to large-scale problems with decomposition techniques. Such decomposition methods often allow a simple distributed method for a problem.  Classical subgradient rules  Let    f  :    ‚Ñù  n   ‚Üí  ‚Ñù      normal-:  f   normal-‚Üí   superscript  ‚Ñù  n   ‚Ñù     f:\mathbb{R}^{n}\to\mathbb{R}   be a convex function with domain    ‚Ñù  n     superscript  ‚Ñù  n    \mathbb{R}^{n}   . A classical subgradient method iterates       x   (   k  +  1   )    =    x   (  k  )    -    Œ±  k    g   (  k  )           superscript  x    k  1       superscript  x  k      subscript  Œ±  k    superscript  g  k       x^{(k+1)}=x^{(k)}-\alpha_{k}g^{(k)}   where    g   (  k  )      superscript  g  k    g^{(k)}   denotes a subgradient of   f   f   f   at    x   (  k  )      superscript  x  k    x^{(k)}   . If   f   f   f   is differentiable, then its only subgradient is the gradient vector    ‚àá  f     normal-‚àá  f    \nabla f   itself. It may happen that    -   g   (  k  )         superscript  g  k     -g^{(k)}   is not a descent direction for   f   f   f   at    x   (  k  )      superscript  x  k    x^{(k)}   . We therefore maintain a list    f  best     subscript  f  best    f_{\rm{best}}   that keeps track of the lowest objective function value found so far, i.e.        f  best   (  k  )    =   min   {   f  best   (   k  -  1   )    ,   f   (   x   (  k  )    )    }     .       superscript   subscript  f  best   k      superscript   subscript  f  best     k  1      f   superscript  x  k       f_{\rm{best}}^{(k)}=\min\{f_{\rm{best}}^{(k-1)},f(x^{(k)})\}.   which is resultant convex optimized.  Step size rules  Many different types of step-size rules are used by subgradient methods. This article notes five classical step-size rules for which convergence proofs are known:   Constant step size,      Œ±  k   =  Œ±   .       subscript  Œ±  k   Œ±    \alpha_{k}=\alpha.     Constant step length,     Œ±  k   =   Œ≥  /    ‚à•   g   (  k  )    ‚à•   2         subscript  Œ±  k     Œ≥   subscript   norm   superscript  g  k    2      \alpha_{k}=\gamma/\lVert g^{(k)}\rVert_{2}   , which gives       ‚à•    x   (   k  +  1   )    -   x   (  k  )     ‚à•   2   =  Œ≥   .       subscript   norm     superscript  x    k  1     superscript  x  k     2   Œ≥    \lVert x^{(k+1)}-x^{(k)}\rVert_{2}=\gamma.     Square summable but not summable step size, i.e. any step sizes satisfying          Œ±  k   ‚â•  0   ,      ‚àë   k  =  1   ‚àû    Œ±  k  2    <  ‚àû   ,     ‚àë   k  =  1   ‚àû    Œ±  k    =  ‚àû     .     formulae-sequence     subscript  Œ±  k   0    formulae-sequence      superscript   subscript     k  1       superscript   subscript  Œ±  k   2          superscript   subscript     k  1       subscript  Œ±  k         \alpha_{k}\geq 0,\qquad\sum_{k=1}^{\infty}\alpha_{k}^{2}<\infty,\qquad\sum_{k=%
 1}^{\infty}\alpha_{k}=\infty.      Nonsummable diminishing, i.e. any step sizes satisfying          Œ±  k   ‚â•  0   ,      lim   k  ‚Üí  ‚àû     Œ±  k    =  0   ,     ‚àë   k  =  1   ‚àû    Œ±  k    =  ‚àû     .     formulae-sequence     subscript  Œ±  k   0    formulae-sequence      subscript    normal-‚Üí  k      subscript  Œ±  k    0       superscript   subscript     k  1       subscript  Œ±  k         \alpha_{k}\geq 0,\qquad\lim_{k\to\infty}\alpha_{k}=0,\qquad\sum_{k=1}^{\infty}%
 \alpha_{k}=\infty.      Nonsummable diminishing step lengths, i.e.     Œ±  k   =    Œ≥  k   /    ‚à•   g   (  k  )    ‚à•   2         subscript  Œ±  k      subscript  Œ≥  k    subscript   norm   superscript  g  k    2      \alpha_{k}=\gamma_{k}/\lVert g^{(k)}\rVert_{2}   , where          Œ≥  k   ‚â•  0   ,      lim   k  ‚Üí  ‚àû     Œ≥  k    =  0   ,     ‚àë   k  =  1   ‚àû    Œ≥  k    =  ‚àû     .     formulae-sequence     subscript  Œ≥  k   0    formulae-sequence      subscript    normal-‚Üí  k      subscript  Œ≥  k    0       superscript   subscript     k  1       subscript  Œ≥  k         \gamma_{k}\geq 0,\qquad\lim_{k\to\infty}\gamma_{k}=0,\qquad\sum_{k=1}^{\infty}%
 \gamma_{k}=\infty.   For all five rules, the step-sizes are determined "off-line", before the method is iterated; the step-sizes do not depend on preceding iterations. This "off-line" property of subgradient methods differs from the "on-line" step-size rules used for descent methods for differentiable functions: Many methods for minimizing differentiable functions satisfy Wolfe's sufficient conditions for convergence, where step-sizes typically depend on the current point and the current search-direction. An extensive discussion of stepsize rules for subgradient methods, including incremental versions, is given in the books by Bertsekas 1 and by Bertsekas, Nedic, and Ozdaglar. 2  Convergence results  For constant step-length and scaled subgradients having Euclidean norm equal to one, the subgradient method converges to an arbitrarily close approximation to the minimum value, that is         lim   k  ‚Üí  ‚àû     f  best   (  k  )     -   f  *    <  œµ          subscript    normal-‚Üí  k      superscript   subscript  f  best   k     superscript  f     œµ    \lim_{k\to\infty}f_{\rm{best}}^{(k)}-f^{*}<\epsilon   by a result of Shor . 3 These classical subgradient methods have poor performance and are no longer recommended for general use. 4 5 However, they are still used widely in specialized applications because they are simple and they can be easily adapted to take advantage of the special structure of the problem at hand.  Subgradient-projection & bundle methods  During the 1970s, Claude Lemar√©chal and Phil. Wolfe proposed "bundle methods" of descent for problems of convex minimization. 6 The meaning of the term "bundle methods" has changed significantly since that time. Modern versions and full convergence analysis were provided by Kiwiel. 7 Contemporary bundle-methods often use " level control" rules for choosing step-sizes, developing techniques from the "subgradient-projection" method of Boris T. Polyak (1969). However, there are problems on which bundle methods offer little advantage over subgradient-projection methods. 8 9  Constrained optimization  Projected subgradient  One extension of the subgradient method is the projected subgradient method , which solves the constrained optimization problem   minimize    f   (  x  )       f  x    f(x)   subject to      x  ‚àà  ùíû      x  ùíû    x\in\mathcal{C}      where   ùíû   ùíû   \mathcal{C}   is a convex set. The projected subgradient method uses the iteration       x   (   k  +  1   )    =   P   (    x   (  k  )    -    Œ±  k    g   (  k  )      )         superscript  x    k  1      P     superscript  x  k      subscript  Œ±  k    superscript  g  k        x^{(k+1)}=P\left(x^{(k)}-\alpha_{k}g^{(k)}\right)     where   P   P   P   is projection on   ùíû   ùíû   \mathcal{C}   and    g   (  k  )      superscript  g  k    g^{(k)}   is any subgradient of   f   f   f   at     x   (  k  )    .     superscript  x  k    x^{(k)}.     General constraints  The subgradient method can be extended to solve the inequality constrained problem   minimize     f  0    (  x  )        subscript  f  0   x    f_{0}(x)   subject to         f  i    (  x  )    ‚â§  0   ,   i  =   1  ,  ‚Ä¶  ,  m       formulae-sequence       subscript  f  i   x   0     i   1  normal-‚Ä¶  m      f_{i}(x)\leq 0,\quad i=1,\dots,m      where    f  i     subscript  f  i    f_{i}   are convex. The algorithm takes the same form as the unconstrained case       x   (   k  +  1   )    =    x   (  k  )    -    Œ±  k    g   (  k  )           superscript  x    k  1       superscript  x  k      subscript  Œ±  k    superscript  g  k       x^{(k+1)}=x^{(k)}-\alpha_{k}g^{(k)}     where     Œ±  k   >  0       subscript  Œ±  k   0    \alpha_{k}>0   is a step size, and    g   (  k  )      superscript  g  k    g^{(k)}   is a subgradient of the objective or one of the constraint functions at    x  .    x   x.   Take       g   (  k  )    =   {       ‚àÇ   f  0     (  x  )        if   f  i    (  x  )    ‚â§    0    ‚àÄ  i    =   1  ‚Ä¶  m          ‚àÇ   f  j     (  x  )        for some  j  such that   f  j    (  x  )    >  0            superscript  g  k    cases       subscript  f  0    x         if   subscript  f  i   x     0   for-all  i           1  normal-‚Ä¶  m          subscript  f  j    x       for some  j  such that   subscript  f  j   x   0      g^{(k)}=\begin{cases}\partial f_{0}(x)&\text{ if }f_{i}(x)\leq 0\;\forall i=1%
 \dots m\\
 \partial f_{j}(x)&\text{ for some }j\text{ such that }f_{j}(x)>0\end{cases}     where    ‚àÇ  f      f    \partial f   denotes the subdifferential of   f   f   f   . If the current point is feasible, the algorithm uses an objective subgradient; if the current point is infeasible, the algorithm chooses a subgradient of any violated constraint.  References    Further reading           External links   EE364A and EE364B , Stanford's convex optimization course sequence.   "  Category:Mathematical optimization  Category:Convex optimization     ‚Ü©  ‚Ü©  The approximate convergence of the constant step-size (scaled) subgradient method is stated as Exercise 6.3.14(a) in Bertsekas (page 636):  On page 636, Bertsekas attributes this result to Shor: ‚Ü©    ‚Ü©  ‚Ü©  ‚Ü©  ‚Ü©     