   Gradient theorem      Gradient theorem   The gradient theorem , also known as the fundamental theorem of calculus for line integrals , says that a line integral through a gradient field can be evaluated by evaluating the original scalar field at the endpoints of the curve.  Let    φ  :   U  ⊆   ℝ  n   →  ℝ      normal-:  φ      U   superscript  ℝ  n     normal-→    ℝ      \varphi:U\subseteq\mathbb{R}^{n}\to\mathbb{R}   . Then         φ   (  𝐪  )    -   φ   (  𝐩  )     =    ∫   γ   [  𝐩  ,  𝐪  ]         ∇  φ    (  𝐫  )    ⋅  d   𝐫     .          φ  𝐪     φ  𝐩      subscript     γ   𝐩  𝐪        normal-⋅     normal-∇  φ   𝐫   d   𝐫      \varphi\left(\mathbf{q}\right)-\varphi\left(\mathbf{p}\right)=\int_{\gamma[%
 \mathbf{p},\,\mathbf{q}]}\nabla\varphi(\mathbf{r})\cdot d\mathbf{r}.     It is a generalization of the fundamental theorem of calculus to any curve in a plane or space (generally n -dimensional) rather than just the real line.  The gradient theorem implies that line integrals through gradient fields are path independent . In physics this theorem is one of the ways of defining a "conservative" force . By placing φ as potential, ∇φ is a conservative field . Work done by conservative forces does not depend on the path followed by the object, but only the end points, as the above equation shows.  The gradient theorem also has an interesting converse: any path-independent vector field can be expressed as the gradient of a scalar field . Just like the gradient theorem itself, this converse has many striking consequences and applications in both pure and applied mathematics.  Proof  If φ is a differentiable function from some open subset  U (of R n ) to R , and if r is a differentiable function from some closed interval [ a,b ] to U , then by the multivariate chain rule , the composite function φ ∘ r is differentiable on ( a , b ) and        d   d  t     (   φ  ∘  𝐫   )    (  t  )    =      ∇  φ    (   𝐫   (  t  )    )    ⋅   𝐫  ′     (  t  )            d    d  t      φ  𝐫   t      normal-⋅     normal-∇  φ     𝐫  t     superscript  𝐫  normal-′    t     \frac{d}{dt}(\varphi\circ\mathbf{r})(t)=\nabla\varphi(\mathbf{r}(t))\cdot%
 \mathbf{r}^{\prime}(t)     for all t in ( a , b ). Here the ⋅ denotes the usual inner product .  Now suppose the domain U of φ contains the differentiable curve γ with endpoints p and q , ( oriented in the direction from p to q ). If r  parametrizes γ for t in [ a , b ], then the above shows that 1        ∫  γ        ∇  φ    (  𝐮  )    ⋅  d   𝐮       subscript   γ      normal-⋅     normal-∇  φ   𝐮   d   𝐮     \displaystyle\int_{\gamma}\nabla\varphi(\mathbf{u})\cdot d\mathbf{u}     where the definition of the line integral is used in the first equality, and the fundamental theorem of calculus is used in the third equality.  Examples  Example 1  Suppose γ ⊂ R 2 is the circular arc oriented counterclockwise from (5, 0) to (−4, 3). Using the definition of a line integral ,         ∫  γ     y  d  x    +   x  d  y         subscript   γ     y  d  x      x  d  y     \displaystyle\int_{\gamma}ydx+xdy     Notice all of the painstaking computations involved in directly calculating the integral. Instead, since the function f ( x , y ) = xy is differentiable on all of R 2 , we can simply use the gradient theorem to say         ∫  γ    y  d  x    +   x  d  y    =    ∫  γ     ∇   (   x  y   )    ⋅   (   d  x   ,   d  y   )     =     x  y   |    (  5  ,  0  )    (   -  4   ,  3  )    =    -   4  ⋅  3    -   5  ⋅  0    =   -  12             subscript   γ     y  d  x      x  d  y      subscript   γ    normal-⋅   normal-∇    x  y       d  x     d  y            evaluated-at    x  y    5  0      4   3              normal-⋅  4  3     normal-⋅  5  0           12      \int_{\gamma}ydx+xdy=\int_{\gamma}\nabla(xy)\cdot(dx,dy)=xy|_{(5,0)}^{(-4,3)}=%
 -4\cdot 3-5\cdot 0=-12   .  Notice that either way gives the same answer, but using the latter method, most of the work is already done in the proof of the gradient theorem.  Example 2  For a more abstract example, suppose γ ⊂ R n has endpoints p , q , with orientation from p to q . For u in R n , let | u | denote the Euclidean norm of u . If α ≥ 1 is a real number, then        ∫  γ         |  𝐱  |    α  -  1    𝐱   ⋅  d   𝐱       subscript   γ      normal-⋅     superscript    𝐱     α  1    𝐱   d   𝐱     \displaystyle\int_{\gamma}|\mathbf{x}|^{\alpha-1}\mathbf{x}\cdot d\mathbf{x}     Here the final equality follows by the gradient theorem, since the function f ( x ) = | x | α + 1 is differentiable on R n if α ≥ 1.  If α α−1 x will fail to be defined there. However, the case α = −1 is somewhat different; in this case, the integrand becomes | x | −2 x = ∇(log| x |), so that the final equality becomes log| q |−log| p |.  Note that if n=1, then this example is simply a slight variant of the familiar Power rule from single-variable calculus.  Example 3  Suppose there are n  point charges arranged in three-dimensional space, and the i -th point charge has charge  Q i and is located at position p i in R 3 . We would like to calculate the work done on a particle of charge q as it travels from a point a to a point b in R 3 . Using Coulomb's law , we can easily determine that the force on the particle at position r will be       𝐅   (  𝐫  )    =   k  q    ∑   i  =  1   n      Q  i    (   𝐫  -   𝐩  i    )      |   𝐫  -   𝐩  i    |   3            𝐅  𝐫     k  q    superscript   subscript     i  1    n        subscript  Q  i     𝐫   subscript  𝐩  i      superscript      𝐫   subscript  𝐩  i     3        \mathbf{F}(\mathbf{r})=kq\sum_{i=1}^{n}\frac{Q_{i}(\mathbf{r}-\mathbf{p}_{i})}%
 {|\mathbf{r}-\mathbf{p}_{i}|^{3}}     Here | u | denotes the Euclidean norm of the vector u in R 3 , and k = 1/(4πε 0 ), where ε 0 is the Vacuum permittivity .  Let γ ⊂ R 3 − { p 1 , ..., p n } be an arbitrary differentiable curve from a to b . Then the work done on the particle is      W  =    ∫  γ      𝐅   (  𝐫  )    ⋅  d   𝐫    =    ∫  γ      (   k  q    ∑   i  =  1   n      Q  i    (   𝐫  -   𝐩  i    )      |   𝐫  -   𝐩  i    |   3      )   ⋅  d   𝐫    =   k  q    ∑   i  =  1   n    (    Q  i     ∫  γ       (   𝐫  -   𝐩  i    )     |   𝐫  -   𝐩  i    |   3    ⋅  d   𝐫     )           W    subscript   γ      normal-⋅    𝐅  𝐫   d   𝐫           subscript   γ      normal-⋅    k  q    superscript   subscript     i  1    n        subscript  Q  i     𝐫   subscript  𝐩  i      superscript      𝐫   subscript  𝐩  i     3      d   𝐫           k  q    superscript   subscript     i  1    n      subscript  Q  i     subscript   γ      normal-⋅      𝐫   subscript  𝐩  i     superscript      𝐫   subscript  𝐩  i     3    d   𝐫          W=\int_{\gamma}\mathbf{F}(\mathbf{r})\cdot d\mathbf{r}=\int_{\gamma}\bigg(kq%
 \sum_{i=1}^{n}\frac{Q_{i}(\mathbf{r}-\mathbf{p}_{i})}{|\mathbf{r}-\mathbf{p}_{%
 i}|^{3}}\bigg)\cdot d\mathbf{r}=kq\sum_{i=1}^{n}\bigg(Q_{i}\int_{\gamma}\frac{%
 (\mathbf{r}-\mathbf{p}_{i})}{|\mathbf{r}-\mathbf{p}_{i}|^{3}}\cdot d\mathbf{r}\bigg)     Now for each i , direct computation shows that         (   𝐫  -   𝐩  i    )     |   𝐫  -   𝐩  i    |   3    =   -   ∇   (   1   |   𝐫  -   𝐩  i    |    )      .          𝐫   subscript  𝐩  i     superscript      𝐫   subscript  𝐩  i     3       normal-∇    1      𝐫   subscript  𝐩  i          \frac{(\mathbf{r}-\mathbf{p}_{i})}{|\mathbf{r}-\mathbf{p}_{i}|^{3}}=-\nabla%
 \left(\frac{1}{|\mathbf{r}-\mathbf{p}_{i}|}\right).     Thus, continuing from above and using the gradient theorem,      W  =   -   k  q    ∑   i  =  1   n    (    Q  i     ∫  γ      ∇   (   1   |   𝐫  -   𝐩  i    |    )    ⋅  d   𝐫     )      =   k  q    ∑   i  =  1   n     Q  i    (    1   |   𝐚  -   𝐩  i    |    -   1   |   𝐛  -   𝐩  i    |     )            W      k  q    superscript   subscript     i  1    n      subscript  Q  i     subscript   γ      normal-⋅   normal-∇    1      𝐫   subscript  𝐩  i       d   𝐫               k  q    superscript   subscript     i  1    n      subscript  Q  i       1      𝐚   subscript  𝐩  i        1      𝐛   subscript  𝐩  i             W=-kq\sum_{i=1}^{n}\bigg(Q_{i}\int_{\gamma}\nabla\left(\frac{1}{|\mathbf{r}-%
 \mathbf{p}_{i}|}\right)\cdot d\mathbf{r}\bigg)=kq\sum_{i=1}^{n}Q_{i}\left(%
 \frac{1}{|\mathbf{a}-\mathbf{p}_{i}|}-\frac{1}{|\mathbf{b}-\mathbf{p}_{i}|}\right)     We are finished. Of course, we could have easily completed this calculation using the powerful language of electrostatic potential or electrostatic potential energy (with the familiar formulas W = −Δ U = − q Δ V ). However, we have not yet defined potential or potential energy, because the converse of the gradient theorem is required to prove that these are well-defined, differentiable functions and that these formulas hold ( see below ). Thus, we have solved this problem using only Coulomb's Law, the definition of work, and the gradient theorem.  Converse of the gradient theorem  The gradient theorem states that if the vector field F is the gradient of some scalar-valued function (i.e, if F is conservative ), then F is a path-independent vector field (i.e, the integral of F over some piecewise-differentiable curve is dependent only on end points). This theorem has a powerful converse; namely, if F is a path-independent vector field, then F is the gradient of some scalar-valued function. 2 It is straightforward to show that a vector field is path-independent if and only if the integral of the vector field over every closed loop in its domain is zero. Thus the converse can alternatively be stated as follows: If the integral of F over every closed loop in the domain of F is zero, then F is the gradient of some scalar-valued function.      Proof of the converse       Suppose U is an open , path-connected subset of R n , and F : U → R n is a continuous and path-independent vector field. Fix some element a of U , and define f : U → R by       f   (  𝐱  )    :=    ∫   γ   [  𝐚  ,  𝐱  ]        𝐅   (  𝐮  )    ⋅  d   𝐮       assign    f  𝐱     subscript     γ   𝐚  𝐱        normal-⋅    𝐅  𝐮   d   𝐮      f(\mathbf{x}):=\int_{\gamma[\mathbf{a},\mathbf{x}]}\mathbf{F}(\mathbf{u})\cdot
 d%
 \mathbf{u}   Here γ[ a , x ] is any (differentiable) curve in U originating at a and terminating at x . We know that f is well-defined because F is path-independent. Let v be any nonzero vector in R n . By the definition of the directional derivative ,         ∂  f    ∂  𝐯      (  𝐱  )           f     𝐯    𝐱    \displaystyle\frac{\partial f}{\partial\mathbf{v}}(\mathbf{x})   To calculate the integral within the final limit, we must parametrize γ[ x , x + t v ]. Since F is path-independent, U is open, and t is approaching zero, we may assume that this path is a straight line, and parametrize it as u ( s ) = x + s v for 0  \lim_{t \to 0} \frac{1}{t} \int_0^t \mathbf{F}(\mathbf{u}(s)) \cdot \mathbf{u}'(s) ds = \frac{d}{dt} \int_0^t \mathbf{F}(\mathbf{x} + s\mathbf{v}) \cdot \mathbf{v} ds \bigg|_{t=0} = \mathbf{F}(\mathbf{x}) \cdot \mathbf{v}  Thus we have a formula for ∂ v f , where v is arbitrary.. Let x = ( x 1 , x 2 , ..., x n ) and let e i denote the i - th  standard basis vector , so that        ∇  f    (  𝐱  )    =   (     ∂  f    (  𝐱  )     ∂   x  1     ,     ∂  f    (  𝐱  )     ∂   x  2     ,  …  ,     ∂  f    (  𝐱  )     ∂   x  n     )   =   (    𝐅   (  𝐱  )    ⋅   𝐞  1    ,    𝐅   (  𝐱  )    ⋅   𝐞  2    ,  …  ,    𝐅   (  𝐱  )    ⋅   𝐞  n    )   =   𝐅   (  𝐱  )             normal-∇  f   𝐱          f   𝐱      subscript  x  1           f   𝐱      subscript  x  2     normal-…        f   𝐱      subscript  x  n             normal-⋅    𝐅  𝐱    subscript  𝐞  1     normal-⋅    𝐅  𝐱    subscript  𝐞  2    normal-…   normal-⋅    𝐅  𝐱    subscript  𝐞  n            𝐅  𝐱      \nabla f(\mathbf{x})=\bigg(\frac{\partial f(\mathbf{x})}{\partial x_{1}},\frac%
 {\partial f(\mathbf{x})}{\partial x_{2}},...,\frac{\partial f(\mathbf{x})}{%
 \partial x_{n}}\bigg)=(\mathbf{F}(\mathbf{x})\cdot\mathbf{e}_{1},\mathbf{F}(%
 \mathbf{x})\cdot\mathbf{e}_{2},...,\mathbf{F}(\mathbf{x})\cdot\mathbf{e}_{n})=%
 \mathbf{F}(\mathbf{x})   Thus we have found a scalar-valued function f whose gradient is the path-independent vector field F , as desired. 3     Example of the converse principle  To illustrate the power of this converse principle, we cite an example that has significant physical consequences. In classical electromagnetism , the electric force is a path-independent force ; i.e. the work done on a particle that has returned to its original position within an electric field is zero (assuming that no changing magnetic fields are present).  Therefore the above theorem implies that the electric force field  F e : S → R 3 is conservative (here S is some open , path-connected subset of R 3 that contains a charge distribution). Following the ideas of the above proof, we can set some reference point a in S , and define a function U e : S → R by        U  e    (  𝐫  )    :=   -    ∫   γ   [  𝐚  ,  𝐫  ]         𝐅  e    (  𝐮  )    ⋅  d   𝐮        assign     subscript  U  e   𝐫       subscript     γ   𝐚  𝐫        normal-⋅     subscript  𝐅  e   𝐮   d   𝐮       U_{e}(\mathbf{r}):=-\int_{\gamma[\mathbf{a},\mathbf{r}]}\mathbf{F}_{e}(\mathbf%
 {u})\cdot d\mathbf{u}     Using the above proof, we know U e is well-defined and differentiable, and F e = −∇ U e (from this formula we can use the gradient theorem to easily derive the well-known formula for calculating work done by conservative forces: W = −Δ U ). This function U e is often referred to as the electrostatic potential energy of the system of charges in S (with reference to the zero-of-potential a ). In many cases, the domain S is assumed to be unbounded and the reference point a is taken to be "infinity," which can be made rigorous using limiting techniques. This function U e is an indispensable tool used in the analysis of many physical systems.  Generalizations  Many of the critical theorems of vector calculus generalize elegantly to statements about the integration of differential forms on manifolds . In the language of differential forms and exterior derivatives , the gradient theorem states that        ∫   ∂  γ    ϕ   =    ∫  γ    d  ϕ          subscript     γ    ϕ     subscript   γ     d  ϕ      \int_{\partial\gamma}\phi=\int_{\gamma}d\phi     for any 0-form φ defined on some differentiable curve γ ⊂ R n (here the integral of φ over the boundary of the γ is understood to be the evaluation of φ at the endpoints of γ).  Notice the striking similarity between this statement and the generalized version of Stokes' theorem , which says that the integral of any compactly supported differential form ω over the boundary of some orientable manifold Ω is equal to the integral of its exterior derivative dω over the whole of Ω, i.e.        ∫   ∂  Ω    ω   =    ∫  Ω    d  ω          subscript     normal-Ω    ω     subscript   normal-Ω     d  ω      \int_{\partial\Omega}\omega=\int_{\Omega}d\omega     This powerful statement is a generalization of the gradient theorem from 1-forms defined on one-dimensional manifolds to differential forms defined on manifolds of arbitrary dimension.  The converse statement of the gradient theorem also has a powerful generalization in terms of differential forms on manifolds. In particular, suppose ω is a form defined on a contractible domain , and the integral of ω over any closed manifold is zero. Then there exists a form ψ such that ω = d ψ. Thus, on a contractible domain, every closed form is exact . This result is summarized by the Poincaré lemma .  See also   State function  Scalar potential  Jordan curve theorem  Differential of a function  Classical mechanics   References    "  Category:Theorems in calculus  Category:Articles containing proofs     Williamson, Richard and Trotter, Hale. (2004). Multivariable Mathematics, Fourth Edition, p. 374. Pearson Education, Inc. ↩  Williamson, Richard and Trotter, Hale. (2004). Multivariable Mathematics, Fourth Edition, p. 410. Pearson Education, Inc. ↩      