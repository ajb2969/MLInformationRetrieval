<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="1904">Contourlet</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>Contourlet</h1>
<hr/>

<p><strong>Contourlets</strong> form a multiresolution directional tight <a href="Frame_of_a_vector_space" title="wikilink">frame</a> designed to efficiently approximate images made of smooth regions separated by smooth boundaries. The Contourlet transform has a fast implementation based on a Laplacian Pyramid decomposition followed by directional filterbanks applied on each bandpass subband.</p>
<h2 id="contourlet-transform">Contourlet Transform</h2>
<h3 id="introduction-and-motivation">Introduction and Motivation</h3>

<p>In the field of Geometrical Image Transforms, there are many 1-D transforms designed for detecting or capturing the geometry of image information, such as the <a href="Fourier_Transform" title="wikilink">Fourier</a> and <a href="wavelet_transform" title="wikilink">wavelet transform</a>. However, the ability of 1-D transform processing of the intrinsic geometrical structures, such as smoothness of curves, is limited in one direction, then more powerful representations are required in higher dimensions. The Contourlet transform which was proposed by Do and Vetterli in 2002, is a new two-dimensional transform method for image representations.The Contourlet transform has properties of multiresolution, localization, directionality, critical sampling and anisotropy. Its basic functions are multiscale and multidimensional. The contours of original images, which are the dominant features in natural images, can be captured effectively with a few coefficients by using Contourlet transform.</p>

<p>The Contourlet transform is inspired by the human visual system and <a class="uri" href="Curvelet" title="wikilink">Curvelet</a> transform which can capture the smoothness of the contour of images with different elongated shapes and in variety of directions.<a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a> However, it is difficult to sampling on a rectangular grid for Curvelet transform since Curvelet transform was developed in continuous domain and directions other than horizontal and vertical are very different on rectangular grid. Therefore, the Contourlet transform was proposed initially as a directional multiresolution transform in the discrete domain.</p>
<h3 id="definition">Definition</h3>

<p> The Contourlet transform uses a double filter bank structure to get the smooth contours of images. In this double filter bank, the <a href="Laplacian_pyramid" title="wikilink">Laplacian pyramid</a> (LP) is first used to capture the point discontinuities, and then a <a href="filter_bank" title="wikilink">directional filter bank</a> (DFB) is used to form those point discontinuities into linear structures.<a class="footnoteRef" href="#fn2" id="fnref2"><sup>2</sup></a></p>

<p>The Laplacian pyramid (LP) decomposition only produce one bandpass image in a <a href="multidimensional_signal_processing" title="wikilink">multidimensional signal processing</a>, that can avoid frequency scrambling. And directional filter bank (DFB) is only fit for high frequency since it will leak the low frequency of signals in its directional subbands. This is the reason to combine DFB with LP, which is multiscale decomposition and remove the low frequency. Therefore, image signals pass through LP subbands to get bandpass signals and pass those signals through DFB to capture the directional information of image. This double filter bank structure of combination of LP and DFB is also called as pyramid directional filter bank (PDFB), and this transform is approximate the original image by using basic contour, so it is also called discrete contourlet transform.<a class="footnoteRef" href="#fn3" id="fnref3"><sup>3</sup></a></p>
<h3 id="the-properties-of-discrete-contourlet-transform">The properties of discrete contourlet transform <a class="footnoteRef" href="#fn4" id="fnref4"><sup>4</sup></a></h3>

<p>1). If perfect-reconstruction filters are used for both the LP decomposition and DFB, then the discrete contourlet transform can reconstruct the original image perfectly, which means it provides a frame operator.<br/>
2). If orthogonal filters are used for both the LP decomposition and DFB, then the discrete contourlet transform provides a tight frame which bounds equal to 1.<br/>
3). The upper bound for the redundancy ratio of the discrete contourlet transform is 

<math display="inline" id="Contourlet:0">
<semantics>
<mrow>
<mn>4</mn>
<mo>/</mo>
<mn>3</mn>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<divide></divide>
<cn type="integer">4</cn>
<cn type="integer">3</cn>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   4/3
  </annotation>
</semantics>
</math>

.<br/>
4). If the 

<math display="inline" id="Contourlet:1">
<semantics>
<mi>j</mi>
<annotation-xml encoding="MathML-Content">
<ci>j</ci>
</annotation-xml>
<annotation encoding="application/x-tex">
   j
  </annotation>
</semantics>
</math>

 pyramidal level of LP applies to 

<math display="inline" id="Contourlet:2">
<semantics>
<msub>
<mi>l</mi>
<mi>j</mi>
</msub>
<annotation-xml encoding="MathML-Content">
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>l</ci>
<ci>j</ci>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   l_{j}
  </annotation>
</semantics>
</math>

 level DFB, the basis images of the contourlet transform have the size of 

<math display="inline" id="Contourlet:3">
<semantics>
<mrow>
<mi>w</mi>
<mi>i</mi>
<mi>d</mi>
<mi>t</mi>
<mi>h</mi>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<times></times>
<ci>w</ci>
<ci>i</ci>
<ci>d</ci>
<ci>t</ci>
<ci>h</ci>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   width
  </annotation>
</semantics>
</math>

 ≈ 

<math display="inline" id="Contourlet:4">
<semantics>
<msup>
<mn>2</mn>
<mi>j</mi>
</msup>
<annotation-xml encoding="MathML-Content">
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<cn type="integer">2</cn>
<ci>j</ci>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   2^{j}
  </annotation>
</semantics>
</math>

 and 

<math display="inline" id="Contourlet:5">
<semantics>
<mrow>
<mi>l</mi>
<mi>e</mi>
<mi>n</mi>
<mi>g</mi>
<mi>t</mi>
<mi>h</mi>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<times></times>
<ci>l</ci>
<ci>e</ci>
<ci>n</ci>
<ci>g</ci>
<ci>t</ci>
<ci>h</ci>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   length
  </annotation>
</semantics>
</math>

 ≈ 

<math display="inline" id="Contourlet:6">
<semantics>
<msup>
<mn>2</mn>
<mrow>
<mrow>
<mi>j</mi>
<mo>+</mo>
<msub>
<mi>l</mi>
<mi>j</mi>
</msub>
</mrow>
<mo>-</mo>
<mn>2</mn>
</mrow>
</msup>
<annotation-xml encoding="MathML-Content">
<apply>
<csymbol cd="ambiguous">superscript</csymbol>
<cn type="integer">2</cn>
<apply>
<minus></minus>
<apply>
<plus></plus>
<ci>j</ci>
<apply>
<csymbol cd="ambiguous">subscript</csymbol>
<ci>l</ci>
<ci>j</ci>
</apply>
</apply>
<cn type="integer">2</cn>
</apply>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   2^{j+l_{j}-2}
  </annotation>
</semantics>
</math>

.<br/>
5). When FIR is used, the computational complexity of the discrete contourlet transform is 

<math display="inline" id="Contourlet:7">
<semantics>
<mrow>
<mi>O</mi>
<mrow>
<mo stretchy="false">(</mo>
<mi>N</mi>
<mo stretchy="false">)</mo>
</mrow>
</mrow>
<annotation-xml encoding="MathML-Content">
<apply>
<times></times>
<ci>O</ci>
<ci>N</ci>
</apply>
</annotation-xml>
<annotation encoding="application/x-tex">
   O(N)
  </annotation>
</semantics>
</math>

 for N-pixel images.</p>
<h2 id="nonsubsampled-contourlet-transform">Nonsubsampled Contourlet Transform</h2>
<h3 id="motivation-and-applications">Motivation and Applications</h3>

<p>The contourlet transform has a number of useful features and qualities, but it also has its flaws. One of the more notable variations of the contourlet transform was developed and proposed by da Cunha, Zhou and Do in 2006. The nonsubsampled contourlet transform (NSCT) was developed mainly because the contourlet transform is not shift invariant.<a class="footnoteRef" href="#fn5" id="fnref5"><sup>5</sup></a> The reason for this lies in the up-sampling and down-sampling present in both the Laplacian Pyramid and the directional filter banks. The method used in this variation was inspired by the nonsubsampled wavelet transform or the stationary wavelet transform which were computed with the à trous algorithm.<a class="footnoteRef" href="#fn6" id="fnref6"><sup>6</sup></a></p>

<p>Though the contourlet and this variant are relatively new, they have been used in many different applications including synthetic aperture radar despeckling,<a class="footnoteRef" href="#fn7" id="fnref7"><sup>7</sup></a> image enhancement<a class="footnoteRef" href="#fn8" id="fnref8"><sup>8</sup></a> and texture classification.<a class="footnoteRef" href="#fn9" id="fnref9"><sup>9</sup></a></p>
<h3 id="basic-concept">Basic Concept</h3>

<p> To retain the directional and multiscale properties of the transform, the Laplacian Pyramid was replaced with a nonsubsampled pyramid structure to retain the multiscale property, and a nonsubsampled directional filter bank for directionality. The first major notable difference is that upsampling and downsampling are removed from both processes. Instead the filters in both the Laplacian Pyramid and the directional filter banks are upsampled. Though this mitigates the shift invariance issue a new issue is now present with aliasing and the directional filter bank. When processing the coarser levels of the pyramid there is potential for aliasing and loss in resolution. This issue is avoided though by upsampling the directional filter bank filters as was done with the filters from the pyramidal filter bank.<a class="footnoteRef" href="#fn10" id="fnref10"><sup>10</sup></a></p>

<p>The next issue that lies with this transform is the design of the filters for both filter banks. According to the authors there were some properties that they desired with this transform such as: perfect reconstruction, a sharp frequency response, easy implementation and linear-phase filters.<a class="footnoteRef" href="#fn11" id="fnref11"><sup>11</sup></a> These features were implemented by first removing the tight frame requirement and then using a mapping to design the filters and then implementing a ladder type structure. These changes lead to a transform that is not only efficient but performs well in comparison to other similar and in some cases more advanced transforms when denoising and enhancing images.</p>
<h2 id="variations-of-the-contourlet-transform">Variations of the Contourlet Transform</h2>
<h3 id="wavelet-based-contourlet-transform">Wavelet-Based Contourlet Transform</h3>

<p> Although the wavelet transform is not optimal in capturing the 2-D singularities of images, it can take the place of LP decomposition in the double filter bank structure to make the contourlet transform a non-redundant image transform.<a class="footnoteRef" href="#fn12" id="fnref12"><sup>12</sup></a> The wavelet-based contourlet transform is similar to the original contourlet transform, and it also consists of two filter bank stages. In the first stage, the wavelet transform is used to do the sub-band decomposition instead of the Laplacian pyramid (LP) in the contourlet transform. And the second stage of the wavelet-based contourlet transform is still a directional filter bank (DFB) to provide the link of singular points. One of the advantages to the wavelet-based contourlet transform is that the wavelet-based contourlet packets are similar to the wavelet packets which allows quad-tree decomposition of both low-pass and high-pass channels and then apply the DFB on each sub-band.</p>
<h3 id="the-hidden-markov-tree-hmt-model-for-the-contourlet-transform">The hidden Markov tree (HMT) model for the contourlet transform</h3>

<p>Based on the study of statistics of contourlet coefficients of natural images, the HMT model for the contourlet transform is proposed. The statistics show that the contourlet coefficients are highly non-Gaussian, high interaction dependent on all their eight neighbors and high inter-direction dependent on their cousins. Therefore, the HMT model, that captures the highly non-Gaussian property, is used to get the dependence on neighborhood through the links between the hidden states of the coefficients.<a class="footnoteRef" href="#fn13" id="fnref13"><sup>13</sup></a> This HMT model of contourlet transform coefficients has better results than original contourlet transform and other HMT modeled transforms in denoising and texture retrieval, since it restores edges better visually.</p>
<h3 id="contourlet-transform-with-sharp-frequency-localization">Contourlet Transform with Sharp Frequency Localization</h3>

<p>An alternative or variation of the contourlet transform was proposed by Lu and Do in 2006. This new proposed method was intended as a remedy to fix non-localized basis images in frequency.<a class="footnoteRef" href="#fn14" id="fnref14"><sup>14</sup></a> The issue with the original contourlet transform was that when the contourlet transform was used with imperfect filter bank filters aliasing occurs and the frequency domain resolution is affected. There are two contributing factors to the aliasing, the first is the periodicity of 2-D frequency spectra and the second is an inherent flaw in the critical sampling of the directional filter banks.<a class="footnoteRef" href="#fn15" id="fnref15"><sup>15</sup></a> This new method mitigates these issues by changing the method of multiscale decomposition. As mentioned before, the original contourlet used the Laplacian Pyramid for multiscale decomposition. This new method as proposed by Lu and Do uses a multiscale pyramid that can be adjusted by applying low pass or high pass filters for the different levels.<a class="footnoteRef" href="#fn16" id="fnref16"><sup>16</sup></a> This method fixes multiple issues, it reduces the amount of cross terms and localizes the basis images in frequency, removes aliasing and has proven in some instances more effective in denoising images. Though it fixes all of those issues, this method requires more filters than the original contourlet transform and still has both the up-sampling and down-sampling operations meaning it is not shift-invariant.</p>
<h3 id="image-enhancement-based-on-nonsubsampled-contourlet-transform">Image Enhancement Based on Nonsubsampled Contourlet Transform</h3>

<p>In prior studies the contourlet transform has proven effective in the denoising of images but in this method the researchers developed a method of image enhancement. When enhancing images preservation and the enhancement of important data is of paramount importance. The contourlet transform meets this criteria somewhat with its ability to denoise and detect edges.<a class="footnoteRef" href="#fn17" id="fnref17"><sup>17</sup></a> This transform first passes the image through the multiscale decomposition by way of the nonsubsampled laplacian pyramid. After that, the noise variance for each sub-band is calculated and relative to local statistics of the image it is classified as either noise, a weak edge or strong edge. The strong edges are retained, the weak edges are enhanced and the noise is discarded. This method of image enhancement significantly outperformed the nonsubsampled wavelet transform (NSWT) both qualitatively and quantitatively.<a class="footnoteRef" href="#fn18" id="fnref18"><sup>18</sup></a> Though this method outperformed the NSWT there still lies the issue of the complexity of designing adequate filter banks and fine tuning the filters for specific applications of which further study will be required.<a class="footnoteRef" href="#fn19" id="fnref19"><sup>19</sup></a></p>
<h2 id="applications">Applications</h2>

<p><a href="Noise_reduction#In_images" title="wikilink">Image Denoising</a><br/>
<a href="Image_editing#Enhancing_images" title="wikilink">Image Enhancement</a><br/>
<a href="Image_restoration" title="wikilink">Image Restoration</a><br/>
<a href="Speckle_noise#Speckle_Noise_Reduction" title="wikilink">Image Despeckling</a></p>
<h2 id="see-also">See also</h2>
<ul>
<li><a class="uri" href="Wavelet" title="wikilink">Wavelet</a></li>
<li><a href="Multiresolution_analysis" title="wikilink">Multiresolution analysis</a></li>
<li><a href="Scale_space" title="wikilink">Scale space</a></li>
<li><a href="Bandelet_(computer_science)" title="wikilink">Bandelets</a></li>
<li><a href="Curvelet" title="wikilink">Curvelets</a></li>
<li><a href="Multiscale_decomposition" title="wikilink">Multiscale decomposition</a></li>
<li><a href="Directional_decomposition" title="wikilink">Directional decomposition</a></li>
<li><a href="Pyramid_Directional_Filter_Banks" title="wikilink">Pyramid Directional Filter Banks</a></li>
<li><a href="Basis_Functions" title="wikilink">Basis Functions</a></li>
</ul>
<h2 id="references">References</h2>
<h2 id="external-links">External links</h2>
<ul>
<li>The <a href="http://www.ifp.uiuc.edu/~minhdo/software/contourlet_toolbox.zip">Contourlet Toolbox</a> (in <a class="uri" href="Matlab" title="wikilink">Matlab</a>)</li>
</ul>

<p>"</p>

<p><a class="uri" href="Category:Wavelets" title="wikilink">Category:Wavelets</a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1"></li>
<li id="fn2"></li>
<li id="fn3"></li>
<li id="fn4"></li>
<li id="fn5"></li>
<li id="fn6"></li>
<li id="fn7"></li>
<li id="fn8"></li>
<li id="fn9"></li>
<li id="fn10"></li>
<li id="fn11"></li>
<li id="fn12"></li>
<li id="fn13"></li>
<li id="fn14"></li>
<li id="fn15"></li>
<li id="fn16"></li>
<li id="fn17"></li>
<li id="fn18"></li>
<li id="fn19"></li>
</ol>
</section>
</body>
</html>
