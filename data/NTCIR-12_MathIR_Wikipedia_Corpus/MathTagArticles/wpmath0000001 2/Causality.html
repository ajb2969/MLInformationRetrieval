<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="1138">Causality</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>Causality</h1>
<hr/>
<figure><b>(Figure)</b>
<figcaption><em>The Illustrated Sutra of Cause and Effect</em>. 8th century, Japan</figcaption>
</figure>

<p><strong>Causality</strong> (also referred to as <strong>causation</strong><a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a>) is the relation between an <a href="event_(philosophy)" title="wikilink">event</a> (the <em>cause</em>) and a second event (the <em><a href="Result" title="wikilink">effect</a></em>), where the first event is understood to be responsible for the second.</p>

<p>In common usage, causality is also the relation between a set of factors (causes) and a phenomenon (the <em><a href="Result" title="wikilink">effect</a></em>). Anything that affects an effect is a factor of that effect. A direct factor is a factor that affects an effect directly, that is, without any intervening factors. (Intervening factors are sometimes called "intermediate factors".) The connection between a cause(s) and an effect in this way can also be referred to as a <em>causal nexus</em>.<a class="footnoteRef" href="#fn2" id="fnref2"><sup>2</sup></a></p>

<p>Causes and effects are typically related to changes, events, or processes; such causes are Aristotle's moving causes. The word 'cause' is also used to mean 'explanation' or 'answer to a why question', including Aristotle's material, final, and formal causes; then the 'cause' is the explanans while the 'effect' is the <a class="uri" href="explanandum" title="wikilink">explanandum</a>. In this case, there are various recognizable kinds of 'cause'; candidates include <a href="object_(philosophy)" title="wikilink">objects</a>, <a href="Process_(science)" title="wikilink">processes</a>, <a href="property_(philosophy)" title="wikilink">properties</a>, variables, <a href="fact" title="wikilink">facts</a>, and <a href="State_of_affairs_(philosophy)" title="wikilink">states of affairs</a>; failure to recognize that different kinds of 'cause' are being considered can lead to debate.</p>

<p>The <a href="Philosophy" title="wikilink">philosophical</a> treatment on the subject of causality extends over millennia. In the Western philosophical tradition, discussion stretches back at least to <a class="uri" href="Aristotle" title="wikilink">Aristotle</a>, and the topic remains a staple in <a href="contemporary_philosophy" title="wikilink">contemporary philosophy</a>.</p>
<h2 id="history">History</h2>
<h3 id="western-philosophy">Western philosophy</h3>
<h4 id="aristotelian">Aristotelian</h4>

<p>Aristotle identified four kinds of answer or explanatory mode to various "Why?" questions. He thought that, for any given topic, all four kinds of explanatory mode were important, each in its own right. As a result of traditional specialized philosophical peculiarities of language, with translations between ancient Greek, Latin, and English, the word 'cause' is nowadays in specialized philosophical writings used to label Aristotle's four kinds.<a class="footnoteRef" href="#fn3" id="fnref3"><sup>3</sup></a><a class="footnoteRef" href="#fn4" id="fnref4"><sup>4</sup></a> In ordinary language, there are various meanings of the word cause, the commonest referring to efficient cause, the topic of the present article.</p>
<ul>
<li><a href="Material_cause" title="wikilink">Material cause</a>, the material whence a thing has come or that which persists while it changes, as for example, one's mother or the bronze of a statue (see also <a href="substance_theory" title="wikilink">substance theory</a>).<a class="footnoteRef" href="#fn5" id="fnref5"><sup>5</sup></a></li>
<li><a href="Formal_cause" title="wikilink">Formal cause</a>, whereby a thing's dynamic <em>form</em> or static <em>shape</em> determines the thing's properties and function, as a human differs from a statue of a human or as a statue differs from a lump of bronze.<a class="footnoteRef" href="#fn6" id="fnref6"><sup>6</sup></a></li>
<li><a href="Efficient_cause" title="wikilink">Efficient cause</a>, which imparts the first relevant <em>movement</em>, as a human lifts a rock or raises a statue.</li>
<li><a href="Final_cause" title="wikilink">Final cause</a>, the criterion of completion, or the <a href="Telos_(philosophy)" title="wikilink">end</a>; it may refer to an action or to an inanimate process. Examples: Socrates takes a walk after dinner for the sake of his health; earth falls to the lowest level because that is its nature.</li>
</ul>

<p>Of Aristotle's four kinds or explanatory modes, only one, the 'efficient cause' is a cause as defined in the leading paragraph of this present article. The other three explanatory modes might be rendered material composition, structure and dynamics, and, again, criterion of completion. The word that Aristotle used was 

<math display="inline" id="Causality:0">
 <semantics>
  <mrow>
   <mi>α</mi>
   <mi>ἰ</mi>
   <mi>τ</mi>
   <mi>ί</mi>
   <mi>α</mi>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <times></times>
    <ci>α</ci>
    <ci>ἰ</ci>
    <ci>τ</ci>
    <ci>ί</ci>
    <ci>α</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   αἰτία
  </annotation>
 </semantics>
</math>

. For the present purpose, that Greek word would be better translated as "explanation" than as "cause" as those words are most often used in current English. Another translation of Aristotle is that he meant "the four Becauses" as four kinds of answer to "why" questions.<a class="footnoteRef" href="#fn7" id="fnref7"><sup>7</sup></a></p>

<p>In some works of Aristotle, the four causes are listed as (1) the essential cause, (2) the logical ground, (3) the moving cause, and (4) the final cause. In this listing, a statement of essential cause is a demonstration that an indicated object conforms to a definition of the word that refers to it. A statement of logical ground is an argument as to why an object statement is true. These are further examples of the idea that a "cause" in general in the context of Aristotle's usage is an "explanation".<a class="footnoteRef" href="#fn8" id="fnref8"><sup>8</sup></a></p>

<p>The word "efficient" used here can also be translated from Aristotle as "moving" or "initiating".<a class="footnoteRef" href="#fn9" id="fnref9"><sup>9</sup></a></p>

<p>Efficient causation was connected with <a href="Aristotelian_physics" title="wikilink">Aristotelian physics</a>, which recognized the <a href="four_classical_elements" title="wikilink">four elements</a> (earth, air, fire, water), and added the <a href="Aether_(classical_element)" title="wikilink">fifth element</a> (aether). Water and earth by their intrinsic property <em>gravitas</em> or heaviness intrinsically fall toward, whereas air and fire by their intrinsic property <em>levitas</em> or lightness intrinsically rise away from, Earth's center—the motionless center of the universe—in a straight line while accelerating during the substance's approach to its natural place.</p>

<p>As air remained on Earth, however, and did not escape Earth while eventually achieving infinite speed—an absurdity—Aristotle inferred that the universe is finite in size and contains an invisible substance that held planet Earth and its atmosphere, the <a href="sublunary_sphere" title="wikilink">sublunary sphere</a>, centered in the universe. And since celestial bodies exhibit perpetual, unaccelerated motion orbiting planet Earth in unchanging relations, Aristotle inferred that the fifth element, <em>aither</em>, that fills space and composes celestial bodies intrinsically moves in perpetual circles, the only constant motion between two points. (An object traveling a straight line from point <em>A</em> to <em>B</em> and back must stop at either point before returning to the other.)</p>

<p>Left to itself, a thing exhibits <em>natural motion</em>, but can—according to <a href="Aristotelian_metaphysics" title="wikilink">Aristotelian metaphysics</a>—exhibit <em>enforced motion</em> imparted by an efficient cause. The form of plants endows plants with the processes nutrition and reproduction, the form of animals adds locomotion, and the form of humankind adds reason atop these. A rock normally exhibits <em>natural motion</em>—explained by the rock's material cause of being composed of the element earth—but a living thing can lift the rock, an <em>enforced motion</em> diverting the rock from its natural place and natural motion. As a further kind of explanation, Aristotle identified the final cause, specifying a purpose or criterion of completion in light of which something should be understood.</p>

<p>Aristotle himself explained,</p>

<p>Aristotle further discerned two modes of causation: proper (prior) causation and accidental (chance) causation. All causes, proper and accidental, can be spoken as potential or as actual, particular or generic. The same language refers to the effects of causes, so that generic effects are assigned to generic causes, particular effects to particular causes, and actual effects to operating causes.</p>

<p>Averting <a href="infinite_regress" title="wikilink">infinite regress</a>, Aristotle inferred the first mover—an <a href="unmoved_mover" title="wikilink">unmoved mover</a>. The first mover's motion, too, must have been caused, but, being an unmoved mover, must have moved only toward a particular goal or desire.</p>
<h4 id="middle-ages">Middle Ages</h4>

<p>In line with Aristotelian cosmology, <a href="Thomas_Aquinas" title="wikilink">Thomas Aquinas</a> posed a hierarchy prioritizing Aristotle's four causes: "final &gt; efficient &gt; material &gt; formal".<a class="footnoteRef" href="#fn10" id="fnref10"><sup>10</sup></a> Aquinas sought to identify the first efficient cause—now simply <em><a href="first_cause" title="wikilink">first cause</a></em>—as everyone would agree, said Aquinas, to call it <em>God</em>. Later in the Middle Ages, many scholars conceded that the first cause was God, but explained that many earthly events occur within God's design or plan, and thereby scholars sought freedom to investigate the numerous <em><a href="secondary_cause" title="wikilink">secondary causes</a></em>.</p>
<h4 id="after-the-middle-ages">After the Middle Ages</h4>

<p>For Aristotelian philosophy before Aquinas, the word cause had a broad meaning. It meant 'answer to a why question' or 'explanation', and Aristotelian scholars recognized four kinds of such answers. With the end of the <a href="Middle_Ages" title="wikilink">Middle Ages</a>, in many philosophical usages, the meaning of the word 'cause' narrowed. It often lost that broad meaning, and was restricted to just one of the four kinds. For authors such as <a href="Niccolò_Machiavelli" title="wikilink">Niccolò Machiavelli</a>, in the field of political thinking, and <a href="Francis_Bacon" title="wikilink">Francis Bacon</a>, concerning <a class="uri" href="science" title="wikilink">science</a> more generally, Aristotle's moving cause was the focus of their interest. A widely used modern definition of causality in this newly narrowed sense was assumed by <a href="David_Hume" title="wikilink">David Hume</a>.<a class="footnoteRef" href="#fn11" id="fnref11"><sup>11</sup></a> He undertook an epistemological and metaphysical investigation of the notion of moving cause. He denied that we can ever perceive cause and effect, except by developing a habit or custom of mind where we come to associate two types of object or event, always contiguous and occurring one after the other.<a class="footnoteRef" href="#fn12" id="fnref12"><sup>12</sup></a> In Part III, section XV of his book <em><a href="A_Treatise_of_Human_Nature" title="wikilink">A Treatise of Human Nature</a></em>, Hume expanded this to a list of eight ways of judging whether two things might be cause and effect. The first three:</p>
<dl>
<dd>1. "The cause and effect must be contiguous in space and time."
</dd>
<dd>2. "The cause must be prior to the effect."
</dd>
<dd>3. "There must be a constant union betwixt the cause and effect. 'Tis chiefly this quality, that constitutes the relation."
</dd>
</dl>

<p>And then additionally there are three connected criteria which come from our experience and which are "the source of most of our philosophical reasonings":</p>
<dl>
<dd>4. "The same cause always produces the same effect, and the same effect never arises but from the same cause. This principle we derive from experience, and is the source of most of our philosophical reasonings."
</dd>
<dd>5. Hanging upon the above, Hume says that "where several different objects produce the same effect, it must be by means of some quality, which we discover to be common amongst them."
</dd>
<dd>6. And "founded on the same reason": "The difference in the effects of two resembling objects must proceed from that particular, in which they differ."
</dd>
</dl>

<p>And then two more:</p>
<dl>
<dd>7. "When any object increases or diminishes with the increase or diminution of its cause, 'tis to be regarded as a compounded effect, deriv'd from the union of the several different effects, which arise from the several different parts of the cause."
</dd>
<dd>8. An "object, which exists for any time in its full perfection without any effect, is not the sole cause of that effect, but requires to be assisted by some other principle, which may forward its influence and operation."
</dd>
</dl>

<p>In 1949, physicist <a href="Max_Born" title="wikilink">Max Born</a> distinguished determination from causality. For him, determination meant that actual events are so linked by laws of nature that certainly reliable predictions and retrodictions can be made from sufficient present data about them. For him, there are two kinds of causation, which we may here call nomic or generic causation, and singular causation. Nomic causality means that cause and effect are linked by more or less certain or probabilistic general laws covering many possible or potential instances; we may recognize this as a probabilized version of criterion 3. of Hume mentioned just above. Singular causation means that unique particular chains of actual events are essentially and physically linked by antecedence and contiguity, which we may here recognize as criteria 1. and 2. of Hume mentioned just above.<a class="footnoteRef" href="#fn13" id="fnref13"><sup>13</sup></a></p>
<h4 id="th-century-the-second-law-of-thermodynamics">19th century: The Second Law of Thermodynamics</h4>

<p>In <a class="uri" href="thermodynamics" title="wikilink">thermodynamics</a>, a branch of <a class="uri" href="physics" title="wikilink">physics</a>, the <a href="Second_Law_of_Thermodynamics" title="wikilink">Second Law of Thermodynamics</a>, discovered in the 19th century, helps define an <a href="arrow_of_time" title="wikilink">arrow of time</a>. This provides an opportunity to physically describe how causes differ from effects: The sum of effects can never have lower <a class="uri" href="entropy" title="wikilink">entropy</a> than the sum of causes – provided equilibrium conditions.</p>

<p>This is more thoroughly described below.</p>
<h4 id="causality-determinism-and-existentialism">Causality, determinism, and existentialism</h4>

<p>The <a href="determinism" title="wikilink">deterministic</a> world-view is one in which the <a class="uri" href="universe" title="wikilink">universe</a> is no more than a <a href="chain_of_events" title="wikilink">chain of events</a> following one after another according to the law of cause and effect. To hold this <a href="World_view" title="wikilink">worldview</a>, as an <a href="incompatibilism" title="wikilink">incompatibilist</a>, there is no such thing as "<a href="free_will" title="wikilink">free will</a>". However, <a href="compatibilism" title="wikilink">compatibilists</a> argue that determinism is compatible with, or even necessary for, free will. <a href="Existensialism" title="wikilink">Existentialists</a> argue that while no intrinsic meaning has been designed in a deterministic universe, we each can provide a meaning for ourselves.<a class="footnoteRef" href="#fn14" id="fnref14"><sup>14</sup></a></p>
<h3 id="hindu-philosophy">Hindu philosophy</h3>

<p><a href="Vedic_period" title="wikilink">Vedic period</a> (ca.1750–500 BCE) literature has karma's Eastern origins.<a class="footnoteRef" href="#fn15" id="fnref15"><sup>15</sup></a> Karma is the belief held by <a href="Sanathana_Dharma" title="wikilink">Sanathana Dharma</a> and major religions that a person's actions cause certain effects in the current life and/or in future <a href="reincarnation" title="wikilink">life</a>, positively or negatively. The various philosophical schools (<a class="uri" href="darsanas" title="wikilink">darsanas</a>) provide different accounts of the subject. The doctrine of <strong>satkaryavada</strong> affirms that the effect inheres in the cause in some way. The effect is thus either a real or apparent modification of the cause. The doctrine of <strong>asatkaryavada</strong> affirms that the effect does not inhere in the cause, but is a new arising. See <a class="uri" href="Nyaya" title="wikilink">Nyaya</a> for some details of the theory of causation in the Nyaya school. In <a href="Brahma_Samhita" title="wikilink">Brahma Samhita</a>, Brahma describes Krishna as the prime cause of all causes.<a class="footnoteRef" href="#fn16" id="fnref16"><sup>16</sup></a></p>

<p><a href="http://www.bhagavad-gita.org/Gita/verse-18-13.html">Bhagavad-gītā 18.14</a> identifies five causes for any action (knowing which it can be perfected): the body, the individual soul, the senses, the efforts and the supersoul.</p>
<h3 id="buddhist-philosophy">Buddhist philosophy</h3>

<p>According to the theory of action and result (karmaphala), our karmic actions are the principal cause of our happiness or suffering. From the Buddhist point of view, a positive or wholesome action is one that will lead to greater happiness for ourselves and others, and a negative or unwholesome action is one that will lead to greater suffering for ourselves or others.</p>

<p>The general or universal definition of pratityasamutpada (or "dependent origination" or "dependent arising" or "interdependent co-arising") is that everything arises in dependence upon multiple causes and conditions; nothing exists as a singular, independent entity. A traditional example in Buddhist texts is of three sticks standing upright and leaning against each other and supporting each other. If one stick is taken away, the other two will fall to the ground.</p>
<h2 id="logic">Logic</h2>
<h3 id="necessary-and-sufficient-causes">Necessary and sufficient causes</h3>
<dl>
<dd><em>A similar concept occurs in logic, for this see <a href="Necessary_and_sufficient_conditions" title="wikilink">Necessary and sufficient conditions</a></em>
</dd>
</dl>

<p>Causes are often distinguished into two types: Necessary and sufficient.<a class="footnoteRef" href="#fn17" id="fnref17"><sup>17</sup></a> A third type of causation, which requires neither necessity nor sufficiency in and of itself, but which contributes to the effect, is called a "contributory cause."</p>

<p><strong>Necessary causes:</strong></p>

<p>If <em>x</em> is a necessary cause of <em>y</em>, then the presence of <em>y</em> necessarily implies the presence of <em>x</em>. The presence of <em>x</em>, however, does not imply that <em>y</em> will occur.</p>

<p><strong>Sufficient causes:</strong></p>

<p>If <em>x</em> is a sufficient cause of <em>y</em>, then the presence of <em>x</em> necessarily implies the presence of <em>y</em>. However, another cause <em>z</em> may alternatively cause <em>y</em>. Thus the presence of <em>y</em> does not imply the presence of <em>x</em>.</p>

<p><strong>Contributory causes:</strong></p>

<p>A cause may be classified as a "contributory cause", if the presumed cause precedes the effect, and altering the cause alters the effect, regardless of whether either the cause or the effect appears only in the presence of the other.<a class="footnoteRef" href="#fn18" id="fnref18"><sup>18</sup></a></p>

<p><a href="J._L._Mackie" title="wikilink">J. L. Mackie</a> argues that usual talk of "cause", in fact refers to <strong>INUS</strong> conditions (insufficient but non-redundant parts of a condition which is itself unnecessary but sufficient for the occurrence of the effect).<a class="footnoteRef" href="#fn19" id="fnref19"><sup>19</sup></a> An example is a short circuit as a cause for a house burning down. Consider the collection of events: the short circuit, the proximity of flammable material, and the absence of firefighters. Together these are unnecessary but sufficient to the house's burning down (since many other collections of events certainly could have led to the house burning down, for example shooting the house with a flamethrower in the presence of oxygen and so forth). Within this collection, the short circuit is an insufficient (since the short circuit by itself would not have caused the fire) but non-redundant (because the fire would not have happened without it, everything else being equal) part of a condition which is itself unnecessary but sufficient for the occurrence of the effect. So, the short circuit is an INUS condition for the occurrence of the house burning down.</p>
<h3 id="causality-contrasted-with-conditionals">Causality contrasted with conditionals</h3>

<p><a href="Indicative_conditional" title="wikilink">Conditional</a> statements are <em>not</em> statements of causality. An important distinction is that statements of causality require the antecedent to precede or coincide with the consequent in time, whereas conditional statements do not require this temporal order. Confusion commonly arises since many different statements in English may be presented using "If ..., then ..." form (and, arguably, because this form is far more commonly used to make a statement of causality). The two types of statements are distinct, however.</p>

<p>For example, all of the following statements are true when interpreting "If ..., then ..." as the material conditional:</p>
<ol>
<li><em>If Barack Obama is president of the United States in 2011, then Germany is in Europe.</em></li>
<li><em>If George Washington is president of the United States in 2011, then <arbitrary statement="">.</arbitrary></em></li>
</ol>

<p>The first is true since both the <a href="Antecedent_(logic)" title="wikilink">antecedent</a> and the <a class="uri" href="consequent" title="wikilink">consequent</a> are true. The second is true in <a href="sentential_logic" title="wikilink">sentential logic</a> and indeterminate in natural language, regardless of the consequent statement that follows, because the antecedent is false.</p>

<p>The ordinary <a href="indicative_conditional" title="wikilink">indicative conditional</a> has somewhat more structure than the material conditional. For instance, although the first is the closest, neither of the preceding two statements seems true as an ordinary indicative reading. But the sentence</p>
<ul>
<li><em>If Shakespeare of Stratford-on-Avon did not write Macbeth, then someone else did.</em></li>
</ul>

<p>intuitively seems to be true, even though there is no straightforward causal relation in this hypothetical situation between Shakespeare's not writing Macbeth and someone else's actually writing it.</p>

<p>Another sort of conditional, the <a href="counterfactual_conditional" title="wikilink">counterfactual conditional</a>, has a stronger connection with causality, yet even counterfactual statements are not all examples of causality. Consider the following two statements:</p>
<ol>
<li><em>If A were a triangle, then A would have three sides.</em></li>
<li><em>If switch S were thrown, then bulb B would light.</em></li>
</ol>

<p>In the first case, it would not be correct to say that A's being a triangle <em>caused</em> it to have three sides, since the relationship between triangularity and three-sidedness is that of definition. The property of having three sides actually determines A's state as a triangle. Nonetheless, even when interpreted counterfactually, the first statement is true.</p>

<p>A full grasp of the concept of conditionals is important to understanding the literature on causality. A crucial stumbling block is that conditionals in everyday English are usually loosely used to describe a general situation. For example, "If I drop my coffee, then my shoe gets wet" relates an infinite number of possible events. It is shorthand for "For any fact that would count as 'dropping my coffee', some fact that counts as 'my shoe gets wet' will be true". This general statement will be strictly false if there is any circumstance where I drop my coffee and my shoe doesn't get wet. However, an "If..., then..." statement in logic typically relates two <em>specific</em> events or facts—a specific coffee-dropping did or did not occur, and a specific shoe-wetting did or did not follow. Thus, with explicit events in mind, if I drop my coffee and wet my shoe, then it is true that "If I dropped my coffee, then I wet my shoe", regardless of the fact that yesterday I dropped a coffee in the trash for the opposite effect—the conditional relates to <em>specific facts</em>. More counterintuitively, if I didn't drop my coffee at all, then it is also true that "If I drop my coffee then I wet my shoe", or "Dropping my coffee implies I wet my shoe", regardless of whether I wet my shoe or not by any means. This usage would not be <a class="uri" href="counterintuitive" title="wikilink">counterintuitive</a> if it were not for the everyday usage. Briefly, "If X then Y" is equivalent to the first-order logic statement "A implies B" or "not A-and-not-B", where A and B are predicates, but the more familiar usage of an "if A then B" statement would need to be written symbolically using a higher order logic using quantifiers ("for all" and "there exists").</p>
<h3 id="questionable-cause">Questionable cause</h3>

<p>Fallacies of questionable cause, also known as causal fallacies, <em>non-causa pro causa</em> (Latin for "non-cause for cause"), or false cause, are <a href="informal_fallacy" title="wikilink">informal fallacies</a> where a cause is incorrectly identified.</p>
<h2 id="theories">Theories</h2>
<h3 id="counterfactual-theories">Counterfactual theories</h3>

<p>Subjunctive conditionals are familiar from ordinary language. They are of the form, if A <em>were</em> the case, then B <em>would</em> be the case, or if A <em>had been</em> the case, then B <em>would have been</em> the case. Counterfactual conditionals are specifically subjunctive conditionals whose antecedents are in fact false, hence the name. However the term used technically may apply to conditionals with true antecedents as well.</p>

<p>Psychological research shows that people's thoughts about the causal relationships between events influences their judgments of the plausibility of counterfactual alternatives, and conversely, their <a href="counterfactual_thinking" title="wikilink">counterfactual thinking</a> about how a situation could have turned out differently changes their judgements of the causal role of events and agents. Nonetheless, their identification of the cause of an event, and their counterfactual thought about how the event could have turned out differently do not always coincide.<a class="footnoteRef" href="#fn20" id="fnref20"><sup>20</sup></a> People distinguish between various sorts of causes, e.g., strong and weak causes.<a class="footnoteRef" href="#fn21" id="fnref21"><sup>21</sup></a> Research in the <a href="psychology_of_reasoning" title="wikilink">psychology of reasoning</a> shows that people make different sorts of inferences from different sorts of causes.</p>

<p>In the philosophical literature, the suggestion that causation is to be defined in terms of a counterfactual relation is made by the 18th Century Scottish philosopher <a href="David_Hume" title="wikilink">David Hume</a>. Hume remarks that we may define the relation of cause and effect such that ``where, if the first object had not been, the second never had existed." <a class="footnoteRef" href="#fn22" id="fnref22"><sup>22</sup></a></p>

<p>More full-fledged analysis of causation in terms of counterfactual conditionals only came in the 20th Century after development of the possible world semantics for the evaluation of counterfactual conditionals. In his 1973 paper "Causation," <a href="David_Lewis_(philosopher)" title="wikilink">David Lewis</a> proposed that the following definition of the notion of <em>causal dependence</em>:<a class="footnoteRef" href="#fn23" id="fnref23"><sup>23</sup></a></p>
<dl>
<dd><dl>
<dd>An event E <em>causally depends</em> on C if, and only if, (i) if C had occurred, then E would have occurred, and (ii) if C had not occurred, then E would not have occurred.
</dd>
</dl>
</dd>
</dl>

<p>Causation is then defined as a chain of causal dependence. That is, C causes E if and only if there exists a sequence of events C, D<sub>1</sub>, D<sub>2</sub>, ... D<sub>k</sub>, E such that each event in the sequence depends on the previous.</p>

<p>Note that the analysis does not purport to explain how we make causal judgements or how we reason about causation, but rather to give a metaphysical account of what it is for there to be a causal relation between some pair of events. If correct, the analysis has the power to explain certain features of causation. Knowing that causation is a matter of counterfactual dependence, we may reflect on the nature of counterfactual dependence to account for the nature of causation. For example, in his paper "Counterfactual Dependence and Time's Arrow," Lewis sought to account for the time-directedness of counterfactual dependence in terms of the semantics of the counterfactual conditional.<a class="footnoteRef" href="#fn24" id="fnref24"><sup>24</sup></a> If correct, this theory can serve to explain a fundamental part of our experience, which is that we can only causally affect the future but not the past.</p>
<h3 id="probabilistic-causation">Probabilistic causation</h3>

<p>Interpreting causation as a <a href="Determinism" title="wikilink">deterministic</a> relation means that if <em>A</em> causes <em>B</em>, then <em>A</em> must <em>always</em> be followed by <em>B</em>. In this sense, war does not cause deaths, nor does <a href="Tobacco_smoking" title="wikilink">smoking</a> cause <a class="uri" href="cancer" title="wikilink">cancer</a>. As a result, many turn to a notion of probabilistic causation. Informally, <em>A</em> probabilistically causes <em>B</em> if <em>A</em>'s occurrence increases the probability of <em>B</em>. This is sometimes interpreted to reflect imperfect knowledge of a deterministic system but other times interpreted to mean that the causal system under study is inherently probabilistic, such as quantum mechanics.</p>
<h3 id="causal-calculus">Causal calculus</h3>

<p>When experimental interventions are infeasible or illegal, the derivation of cause effect relationship from observational studies must rest on some qualitative theoretical assumptions, for example, that symptoms do not cause diseases, usually expressed in the form of missing arrows in <a href="causal_graphs" title="wikilink">causal graphs</a> such as <a href="Bayesian_network" title="wikilink">Bayesian networks</a> or <a href="path_analysis_(statistics)" title="wikilink">path diagrams</a>. The theory underlying these derivations relies on the distinction between <em>conditional probabilities</em>, as in 

<math display="inline" id="Causality:1">
 <semantics>
  <mrow>
   <mi>P</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <mi>c</mi>
    <mi>a</mi>
    <mi>n</mi>
    <mi>c</mi>
    <mi>e</mi>
    <mi>r</mi>
    <mo stretchy="false">|</mo>
    <mi>s</mi>
    <mi>m</mi>
    <mi>o</mi>
    <mi>k</mi>
    <mi>i</mi>
    <mi>n</mi>
    <mi>g</mi>
    <mo stretchy="false">)</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <cerror>
    <csymbol cd="ambiguous">fragments</csymbol>
    <csymbol cd="unknown">P</csymbol>
    <cerror>
     <csymbol cd="ambiguous">fragments</csymbol>
     <ci>normal-(</ci>
     <csymbol cd="unknown">c</csymbol>
     <csymbol cd="unknown">a</csymbol>
     <csymbol cd="unknown">n</csymbol>
     <csymbol cd="unknown">c</csymbol>
     <csymbol cd="unknown">e</csymbol>
     <csymbol cd="unknown">r</csymbol>
     <ci>normal-|</ci>
     <csymbol cd="unknown">s</csymbol>
     <csymbol cd="unknown">m</csymbol>
     <csymbol cd="unknown">o</csymbol>
     <csymbol cd="unknown">k</csymbol>
     <csymbol cd="unknown">i</csymbol>
     <csymbol cd="unknown">n</csymbol>
     <csymbol cd="unknown">g</csymbol>
     <ci>normal-)</ci>
    </cerror>
   </cerror>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   P(cancer|smoking)
  </annotation>
 </semantics>
</math>

, and <em>interventional probabilities</em>, as in 

<math display="inline" id="Causality:2">
 <semantics>
  <mrow>
   <mi>P</mi>
   <mrow>
    <mo stretchy="false">(</mo>
    <mi>c</mi>
    <mi>a</mi>
    <mi>n</mi>
    <mi>c</mi>
    <mi>e</mi>
    <mi>r</mi>
    <mo stretchy="false">|</mo>
    <mi>d</mi>
    <mi>o</mi>
    <mrow>
     <mo stretchy="false">(</mo>
     <mi>s</mi>
     <mi>m</mi>
     <mi>o</mi>
     <mi>k</mi>
     <mi>i</mi>
     <mi>n</mi>
     <mi>g</mi>
     <mo stretchy="false">)</mo>
    </mrow>
    <mo stretchy="false">)</mo>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <cerror>
    <csymbol cd="ambiguous">fragments</csymbol>
    <csymbol cd="unknown">P</csymbol>
    <cerror>
     <csymbol cd="ambiguous">fragments</csymbol>
     <ci>normal-(</ci>
     <csymbol cd="unknown">c</csymbol>
     <csymbol cd="unknown">a</csymbol>
     <csymbol cd="unknown">n</csymbol>
     <csymbol cd="unknown">c</csymbol>
     <csymbol cd="unknown">e</csymbol>
     <csymbol cd="unknown">r</csymbol>
     <ci>normal-|</ci>
     <csymbol cd="unknown">d</csymbol>
     <csymbol cd="unknown">o</csymbol>
     <cerror>
      <csymbol cd="ambiguous">fragments</csymbol>
      <ci>normal-(</ci>
      <csymbol cd="unknown">s</csymbol>
      <csymbol cd="unknown">m</csymbol>
      <csymbol cd="unknown">o</csymbol>
      <csymbol cd="unknown">k</csymbol>
      <csymbol cd="unknown">i</csymbol>
      <csymbol cd="unknown">n</csymbol>
      <csymbol cd="unknown">g</csymbol>
      <ci>normal-)</ci>
     </cerror>
     <ci>normal-)</ci>
    </cerror>
   </cerror>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   P(cancer|do(smoking))
  </annotation>
 </semantics>
</math>

. The former reads: "the probability of finding cancer in a person known to smoke, having started, unforced by the experimenter, to do so at an unspecified time in the past", while the latter reads: "the probability of finding cancer in a person forced by the experimenter to smoke at a specified time in the past". The former is a statistical notion that can be estimated by observation with negligible intervention by the experimenter, while the latter is a causal notion which is estimated in an experiment with an important controlled randomized intervention. It is specifically characteristic of <a href="quantum_mechanics" title="wikilink">quantal phenomena</a> that observations defined by incompatible variables always involve important intervention by the experimenter, as described quantitatively by the Heisenberg <a href="uncertainty_principle" title="wikilink">uncertainty principle</a>. In classical <a class="uri" href="thermodynamics" title="wikilink">thermodynamics</a>, <a href="thermodynamic_process" title="wikilink">processes</a> are initiated by interventions called <a href="thermodynamic_operation" title="wikilink">thermodynamic operations</a>. In other branches of science, for example <a class="uri" href="astronomy" title="wikilink">astronomy</a>, the experimenter can often observe with negligible intervention.</p>

<p>The theory of "causal calculus"<a class="footnoteRef" href="#fn25" id="fnref25"><sup>25</sup></a> permits one to infer interventional probabilities from conditional probabilities in causal <a href="Bayesian_network" title="wikilink">Bayesian networks</a> with unmeasured variables. One very practical result of this theory is the characterization of <a href="confounding_variables" title="wikilink">confounding variables</a>, namely, a sufficient set of variables that, if adjusted for, would yield the correct causal effect between variables of interest. It can be shown that a sufficient set for estimating the causal effect of 

<math display="inline" id="Causality:3">
 <semantics>
  <mi>X</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>X</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   X
  </annotation>
 </semantics>
</math>

 on 

<math display="inline" id="Causality:4">
 <semantics>
  <mi>Y</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>Y</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   Y
  </annotation>
 </semantics>
</math>

 is any set of non-descendants of 

<math display="inline" id="Causality:5">
 <semantics>
  <mi>X</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>X</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   X
  </annotation>
 </semantics>
</math>

 that 

<math display="inline" id="Causality:6">
 <semantics>
  <mi>d</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>d</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   d
  </annotation>
 </semantics>
</math>

-separate 

<math display="inline" id="Causality:7">
 <semantics>
  <mi>X</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>X</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   X
  </annotation>
 </semantics>
</math>

 from 

<math display="inline" id="Causality:8">
 <semantics>
  <mi>Y</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>Y</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   Y
  </annotation>
 </semantics>
</math>

 after removing all arrows emanating from 

<math display="inline" id="Causality:9">
 <semantics>
  <mi>X</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>X</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   X
  </annotation>
 </semantics>
</math>

. This criterion, called "backdoor", provides a mathematical definition of "confounding" and helps researchers identify accessible sets of variables worthy of measurement.</p>
<h3 id="structure-learning">Structure learning</h3>

<p>While derivations in causal calculus rely on the structure of the causal graph, parts of the causal structure can, under certain assumptions, be learned from statistical data. The basic idea goes back to <a href="Sewall_Wright" title="wikilink">Sewall Wright</a>'s 1921 work<a class="footnoteRef" href="#fn26" id="fnref26"><sup>26</sup></a> on <a href="Path_analysis_(statistics)" title="wikilink">path analysis</a>. A "recovery" algorithm was developed by Rebane and Pearl (1987)<a class="footnoteRef" href="#fn27" id="fnref27"><sup>27</sup></a> which rests on Wright's distinction between the three possible types of causal substructures allowed in a <a href="directed_acyclic_graph" title="wikilink">directed acyclic graph</a> (DAG):</p>
<ol>
<li>

<math display="inline" id="Causality:10">
 <semantics>
  <mrow>
   <mi>X</mi>
   <mo>→</mo>
   <mi>Y</mi>
   <mo>→</mo>
   <mi>Z</mi>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <and></and>
    <apply>
     <ci>normal-→</ci>
     <ci>X</ci>
     <ci>Y</ci>
    </apply>
    <apply>
     <ci>normal-→</ci>
     <share href="#.cmml">
     </share>
     <ci>Z</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   X\rightarrow Y\rightarrow Z
  </annotation>
 </semantics>
</math>

</li>
<li>

<math display="inline" id="Causality:11">
 <semantics>
  <mrow>
   <mi>X</mi>
   <mo>←</mo>
   <mi>Y</mi>
   <mo>→</mo>
   <mi>Z</mi>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <and></and>
    <apply>
     <ci>normal-←</ci>
     <ci>X</ci>
     <ci>Y</ci>
    </apply>
    <apply>
     <ci>normal-→</ci>
     <share href="#.cmml">
     </share>
     <ci>Z</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   X\leftarrow Y\rightarrow Z
  </annotation>
 </semantics>
</math>

</li>
<li>

<math display="inline" id="Causality:12">
 <semantics>
  <mrow>
   <mi>X</mi>
   <mo>→</mo>
   <mi>Y</mi>
   <mo>←</mo>
   <mi>Z</mi>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <and></and>
    <apply>
     <ci>normal-→</ci>
     <ci>X</ci>
     <ci>Y</ci>
    </apply>
    <apply>
     <ci>normal-←</ci>
     <share href="#.cmml">
     </share>
     <ci>Z</ci>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   X\rightarrow Y\leftarrow Z
  </annotation>
 </semantics>
</math>

</li>
</ol>

<p>Type 1 and type 2 represent the same statistical dependencies (i.e., 

<math display="inline" id="Causality:13">
 <semantics>
  <mi>X</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>X</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   X
  </annotation>
 </semantics>
</math>

 and 

<math display="inline" id="Causality:14">
 <semantics>
  <mi>Z</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>Z</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   Z
  </annotation>
 </semantics>
</math>

 are independent given 

<math display="inline" id="Causality:15">
 <semantics>
  <mi>Y</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>Y</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   Y
  </annotation>
 </semantics>
</math>

) and are, therefore, indistinguishable within purely <a href="cross-sectional_data" title="wikilink">cross-sectional data</a>. Type 3, however, can be uniquely identified, since 

<math display="inline" id="Causality:16">
 <semantics>
  <mi>X</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>X</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   X
  </annotation>
 </semantics>
</math>

 and 

<math display="inline" id="Causality:17">
 <semantics>
  <mi>Z</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>Z</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   Z
  </annotation>
 </semantics>
</math>

 are marginally independent and all other pairs are dependent. Thus, while the <em>skeletons</em> (the graphs stripped of arrows) of these three triplets are identical, the directionality of the arrows is partially identifiable. The same distinction applies when 

<math display="inline" id="Causality:18">
 <semantics>
  <mi>X</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>X</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   X
  </annotation>
 </semantics>
</math>

 and 

<math display="inline" id="Causality:19">
 <semantics>
  <mi>Z</mi>
  <annotation-xml encoding="MathML-Content">
   <ci>Z</ci>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   Z
  </annotation>
 </semantics>
</math>

 have common ancestors, except that one must first condition on those ancestors. Algorithms have been developed to systematically determine the skeleton of the underlying graph and, then, orient all arrows whose directionality is dictated by the conditional independencies observed.<a class="footnoteRef" href="#fn28" id="fnref28"><sup>28</sup></a><a class="footnoteRef" href="#fn29" id="fnref29"><sup>29</sup></a><a class="footnoteRef" href="#fn30" id="fnref30"><sup>30</sup></a><a class="footnoteRef" href="#fn31" id="fnref31"><sup>31</sup></a></p>

<p>Alternative methods of structure learning search through the <em>many</em> possible causal structures among the variables, and remove ones which are strongly incompatible with the observed <a href="correlation" title="wikilink">correlations</a>. In general this leaves a set of possible causal relations, which should then be tested by analyzing time series data or, preferably, designing appropriately controlled <a href="experiment" title="wikilink">experiments</a>. In contrast with Bayesian Networks, <a href="path_analysis_(statistics)" title="wikilink">path analysis</a> (and its generalization, <a href="structural_equation_model" title="wikilink">structural equation modeling</a>), serve better to estimate a known causal effect or to test a causal model than to generate causal hypotheses.</p>

<p>For nonexperimental data, causal direction can often be inferred if information about time is available. This is because (according to many, though not all, theories) causes must precede their effects temporally. This can be determined by statistical <a href="time_series" title="wikilink">time series</a> models, for instance, or with a statistical test based on the idea of <a href="Granger_causality" title="wikilink">Granger causality</a>, or by direct experimental manipulation. The use of temporal data can permit statistical tests of a pre-existing theory of causal direction. For instance, our degree of confidence in the direction and nature of causality is much greater when supported by <a href="cross-correlation" title="wikilink">cross-correlations</a>, <a class="uri" href="ARIMA" title="wikilink">ARIMA</a> models, or <a href="Cross-spectrum" title="wikilink">cross-spectral analysis</a> using vector time series data than by <a href="cross-sectional_data" title="wikilink">cross-sectional data</a>.</p>
<h3 id="derivation-theories">Derivation theories</h3>

<p>The Nobel Prize holder <a href="Herbert_A._Simon" title="wikilink">Herbert A. Simon</a> and Philosopher <a href="Nicholas_Rescher" title="wikilink">Nicholas Rescher</a><a class="footnoteRef" href="#fn32" id="fnref32"><sup>32</sup></a> claim that the asymmetry of the causal relation is unrelated to the asymmetry of any mode of implication that contraposes. Rather, a causal relation is not a relation between values of variables, but a function of one variable (the cause) on to another (the effect). So, given a system of equations, and a set of variables appearing in these equations, we can introduce an asymmetric relation among individual equations and variables that corresponds perfectly to our commonsense notion of a causal ordering. The system of equations must have certain properties, most importantly, if some values are chosen arbitrarily, the remaining values will be determined uniquely through a path of serial discovery that is perfectly causal. They postulate the inherent serialization of such a system of equations may correctly capture causation in all empirical fields, including physics and economics.</p>
<h3 id="manipulation-theories">Manipulation theories</h3>

<p>Some theorists have equated causality with manipulability.<a class="footnoteRef" href="#fn33" id="fnref33"><sup>33</sup></a><a class="footnoteRef" href="#fn34" id="fnref34"><sup>34</sup></a><a class="footnoteRef" href="#fn35" id="fnref35"><sup>35</sup></a><a class="footnoteRef" href="#fn36" id="fnref36"><sup>36</sup></a> Under these theories, <em>x</em> causes <em>y</em> only in the case that one can change <em>x</em> in order to change <em>y</em>. This coincides with commonsense notions of causations, since often we ask causal questions in order to change some feature of the world. For instance, we are interested in knowing the causes of crime so that we might find ways of reducing it.</p>

<p>These theories have been criticized on two primary grounds. First, theorists complain that these accounts are <a href="Begging_the_question" title="wikilink">circular</a>. Attempting to reduce causal claims to manipulation requires that manipulation is more basic than causal interaction. But describing manipulations in non-causal terms has provided a substantial difficulty.</p>

<p>The second criticism centers around concerns of <a class="uri" href="anthropocentrism" title="wikilink">anthropocentrism</a>. It seems to many people that causality is some existing relationship in the world that we can harness for our desires. If causality is identified with our manipulation, then this intuition is lost. In this sense, it makes humans overly central to interactions in the world.</p>

<p>Some attempts to defend manipulability theories are recent accounts that don't claim to reduce causality to manipulation. These accounts use manipulation as a sign or feature in causation without claiming that manipulation is more fundamental than causation.<a class="footnoteRef" href="#fn37" id="fnref37"><sup>37</sup></a><a class="footnoteRef" href="#fn38" id="fnref38"><sup>38</sup></a></p>
<h3 id="process-theories">Process theories</h3>

<p>Some theorists are interested in distinguishing between causal processes and non-causal processes (Russell 1948; Salmon 1984).<a class="footnoteRef" href="#fn39" id="fnref39"><sup>39</sup></a><a class="footnoteRef" href="#fn40" id="fnref40"><sup>40</sup></a> These theorists often want to distinguish between a process and a <a class="uri" href="pseudo-process" title="wikilink">pseudo-process</a>. As an example, a ball moving through the air (a process) is contrasted with the motion of a shadow (a pseudo-process). The former is causal in nature while the latter is not.</p>

<p>Salmon (1984)<a class="footnoteRef" href="#fn41" id="fnref41"><sup>41</sup></a> claims that causal processes can be identified by their ability to transmit an alteration over space and time. An alteration of the ball (a mark by a pen, perhaps) is carried with it as the ball goes through the air. On the other hand, an alteration of the shadow (insofar as it is possible) will not be transmitted by the shadow as it moves along.</p>

<p>These theorists claim that the important concept for understanding causality is not causal relationships or causal interactions, but rather identifying causal processes. The former notions can then be defined in terms of causal processes.</p>
<figure><b>(Figure)</b>
<figcaption><a href="Why-Because_analysis" title="wikilink">Why-Because</a> Graph of the capsizing of the <a href="Herald_of_Free_Enterprise" title="wikilink">Herald of Free Enterprise</a> (click to see in detail).</figcaption>
</figure>
<h3 id="systemic-causality">Systemic causality</h3>

<p><a href="George_Lakoff" title="wikilink">George Lakoff</a> writes, in relation to the cause of <a href="Hurricane_Sandy" title="wikilink">Hurricane Sandy</a>,<a class="footnoteRef" href="#fn42" id="fnref42"><sup>42</sup></a></p>
<h2 id="fields">Fields</h2>
<h3 id="science">Science</h3>

<p>For the scientific investigation of efficient causality, the cause and effect are each best conceived of as temporally transient processes.</p>

<p>Within the conceptual frame of the so-called <a href="scientific_method" title="wikilink">scientific method</a>, an investigator sets up several distinct and contrasting temporally transient material processes that have the structure of <a href="experiment" title="wikilink">experiments</a>, and records candidate material responses, normally with the end of determining causality in the physical world. For instance, one may want to <a class="uri" href="know" title="wikilink">know</a> whether a high intake of <a href="carrot" title="wikilink">carrots</a> causes humans to develop the <a href="bubonic_plague" title="wikilink">bubonic plague</a>. The quantity of carrot intake is a process that is varied from occasion to occasion. The occurrence or non-occurrence of subsequent bubonic plague is recorded. To establish causality, the experiment must fulfill certain criteria, only one example of which is mentioned here. (There are other criteria not mentioned here.) For example, instances of the hypothesized cause must be set up to occur at a time when the hypothesized effect is relatively unlikely in the absence of the hypothesized cause; such unlikelihood is to be established by empirical evidence. A mere observation of a <a href="correlation_does_not_imply_causation" title="wikilink">correlation</a> is not nearly adequate to establish causality. In nearly all cases, establishment of causality relies on repetition of experiments and probabilistic reasoning. Hardly ever is causality established more firmly than as more or less probable. It is often most convenient for establishment of causality if the contrasting material states of affairs are fully comparable, and differ, through only one variable factor, perhaps measured by a real number. Otherwise, experiments are usually difficult or impossible to interpret.</p>

<p>In some sciences, it is very difficult or nearly impossible to set up material states of affairs that closely test hypotheses of causality. Such sciences can in some sense be regarded as "softer".</p>
<h4 id="physics">Physics</h4>

<p>It is useful to be careful in the use of the word cause in physics. Properly speaking, the hypothesized cause and the hypothesized effect are each temporally transient processes. For example, force is a useful concept for the explanation of acceleration, but force is not by itself a cause. More is needed. For example, a temporally transient process might be characterized by a definite change of force at a definite time. Such a process can be regarded as a cause. Causality is not inherently implied in <a href="equations_of_motion" title="wikilink">equations of motion</a>, but postulated as an additional <a href="constraint_(classical_mechanics)" title="wikilink">constraint</a> that needs to be satisfied (i.e. a cause always precedes its effect). This constraint has mathematical implications<a class="footnoteRef" href="#fn43" id="fnref43"><sup>43</sup></a> such as the <a href="Kramers-Kronig_relations" title="wikilink">Kramers-Kronig relations</a>.</p>

<p>Causality is one the most fundamental and essential notions of physics. Causal efficacy cannot propagate faster than light. Otherwise, reference coordinate systems could be constructed (using the <a href="Lorentz_transform" title="wikilink">Lorentz transform</a> of <a href="special_relativity" title="wikilink">special relativity</a>) in which an observer would see an effect precede its cause (i.e. the postulate of causality would be violated).</p>

<p>Causal notions appear in the context of the flow of mass-energy. For example, it is commonplace to argue that causal efficacy can be propagated by waves (such as electromagnetic waves) only if they propagate no faster than light. Wave packets have <a href="group_velocity" title="wikilink">group velocity</a> and <a href="phase_velocity" title="wikilink">phase velocity</a>. For waves that propagate causal efficacy, both of these must travel no faster than light. Thus light waves often propagate causal efficacy but <a href="matter_wave" title="wikilink">de Broglie waves</a> often have phase velocity faster than light and consequently cannot be propagating causal efficacy.</p>

<p>Causal notions are important in general relativity to the extent that the existence of an arrow of time demands that the universe's semi-Riemannian manifold be orientable, so that "future" and "past" are globally definable quantities.</p>

<p>Much has been written about the question, but there is not yet any generally accepted formal theory of causation tied to the second law of thermodynamics.</p>
<h4 id="engineering">Engineering</h4>

<p>A <a href="causal_system" title="wikilink">causal system</a> is a <a class="uri" href="system" title="wikilink">system</a> with output and internal states that depends only on the current and previous input values. A system that has <em>some</em> dependence on input values from the future (in addition to possible past or current input values) is termed an <strong>acausal</strong> system, and a system that depends <em>solely</em> on future input values is an <a href="anticausal_system" title="wikilink">anticausal system</a>. Acausal filters, for example, can only exist as postprocessing filters, because these filters can extract future values from a memory buffer or a file.</p>
<h4 id="biology-medicine-and-epidemiology">Biology, medicine and epidemiology</h4>

<p><a href="Austin_Bradford_Hill" title="wikilink">Austin Bradford Hill</a> built upon the work of <a href="David_Hume" title="wikilink">Hume</a> and <a href="Karl_Popper" title="wikilink">Popper</a> and suggested in his paper "The Environment and Disease: Association or Causation?" that aspects of an association such as strength, consistency, specificity and temporality be considered in attempting to distinguish causal from noncausal associations in the epidemiological situation. (See <a href="Bradford-Hill_criteria" title="wikilink">Bradford-Hill criteria</a>.) He did not note however, that temporality is the only necessary criterion among those aspects. Directed acyclic graphs (DAGs) are increasingly used in epidemiology to help enlighten causal thinking.<a class="footnoteRef" href="#fn44" id="fnref44"><sup>44</sup></a></p>
<h4 id="psychology">Psychology</h4>

<p>Psychologists take an empirical approach to causality, investigating how people and non-human animals detect or infer causation from sensory information, prior experience and <a href="innatism" title="wikilink">innate knowledge</a>.</p>
<dl>
<dt>Attribution</dt>
</dl>

<p><a href="Attribution_theory" title="wikilink">Attribution theory</a> is the <a class="uri" href="theory" title="wikilink">theory</a> concerning how people explain individual occurrences of causation. <a href="Attribution_(psychology)" title="wikilink">Attribution</a> can be external (assigning causality to an outside agent or force – claiming that some outside thing motivated the event) or internal (assigning causality to factors within the person – taking personal <a href="Moral_responsibility" title="wikilink">responsibility</a> or <a class="uri" href="accountability" title="wikilink">accountability</a> for one's actions and claiming that the person was directly responsible for the event). Taking causation one step further, the type of attribution a person provides influences their future behavior.</p>

<p>The intention behind the cause or the effect can be covered by the subject of <a href="action_(philosophy)" title="wikilink">action</a>. See also <a class="uri" href="accident" title="wikilink">accident</a>; <a class="uri" href="blame" title="wikilink">blame</a>; <a href="intent_(law)" title="wikilink">intent</a>; and responsibility.</p>
<dl>
<dt>Causal powers</dt>
</dl>

<p>Whereas <a href="David_Hume#Causation" title="wikilink">David Hume</a> argued that causes are inferred from non-causal observations, <a href="Immanuel_Kant" title="wikilink">Immanuel Kant</a> claimed that people have innate assumptions about causes. Within psychology, <a href="Patricia_Cheng" title="wikilink">Patricia Cheng</a> (1997)<a class="footnoteRef" href="#fn45" id="fnref45"><sup>45</sup></a> attempted to reconcile the Humean and Kantian views. According to her power PC theory, people filter observations of events through a basic belief that causes have the power to generate (or prevent) their effects, thereby inferring specific cause-effect relations.</p>
<dl>
<dt>Causation and salience</dt>
</dl>

<p>Our view of causation depends on what we consider to be the relevant events. Another way to view the statement, "Lightning causes thunder" is to see both lightning and thunder as two perceptions of the same event, viz., an electric discharge that we perceive first visually and then aurally.</p>
<dl>
<dt>Naming and causality</dt>
</dl>

<p>David Sobel and Alison Gopnik from the Psychology Department of UC Berkeley designed a device known as <em>the blicket detector</em> which would turn on when an object was placed on it. Their research suggests that "even young children will easily and swiftly learn about a new causal power of an object and spontaneously use that information in classifying and naming the object."<a class="footnoteRef" href="#fn46" id="fnref46"><sup>46</sup></a></p>
<dl>
<dt>Perception of launching events</dt>
</dl>

<p>Some researchers such as Anjan Chatterjee at the University of Pennsylvania and Jonathan Fugelsang at the University of Waterloo are using neuroscience techniques to investigate the neural and psychological underpinnings of causal launching events in which one object causes another object to move. Both temporal and spatial factors can be manipulated.<a class="footnoteRef" href="#fn47" id="fnref47"><sup>47</sup></a></p>

<p>See <a href="Causal_Reasoning_(Psychology)" title="wikilink">Causal Reasoning (Psychology)</a> for more information.</p>
<h4 id="statistics-and-economics">Statistics and economics</h4>

<p><a class="uri" href="Statistics" title="wikilink">Statistics</a> and <a class="uri" href="economics" title="wikilink">economics</a> usually employ pre-existing data or experimental data to infer causality by regression methods. The body of statistical techniques involves substantial use of <a href="regression_analysis" title="wikilink">regression analysis</a>. Typically a linear relationship such as</p>

<p>

<math display="block" id="Causality:20">
 <semantics>
  <mrow>
   <msub>
    <mi>y</mi>
    <mi>i</mi>
   </msub>
   <mo>=</mo>
   <mrow>
    <msub>
     <mi>a</mi>
     <mn>0</mn>
    </msub>
    <mo>+</mo>
    <mrow>
     <msub>
      <mi>a</mi>
      <mn>1</mn>
     </msub>
     <msub>
      <mi>x</mi>
      <mrow>
       <mn>1</mn>
       <mo>,</mo>
       <mi>i</mi>
      </mrow>
     </msub>
    </mrow>
    <mo>+</mo>
    <mrow>
     <msub>
      <mi>a</mi>
      <mn>2</mn>
     </msub>
     <msub>
      <mi>x</mi>
      <mrow>
       <mn>2</mn>
       <mo>,</mo>
       <mi>i</mi>
      </mrow>
     </msub>
    </mrow>
    <mo>+</mo>
    <mi mathvariant="normal">…</mi>
    <mo>+</mo>
    <mrow>
     <msub>
      <mi>a</mi>
      <mi>k</mi>
     </msub>
     <msub>
      <mi>x</mi>
      <mrow>
       <mi>k</mi>
       <mo>,</mo>
       <mi>i</mi>
      </mrow>
     </msub>
    </mrow>
    <mo>+</mo>
    <msub>
     <mi>e</mi>
     <mi>i</mi>
    </msub>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>y</ci>
     <ci>i</ci>
    </apply>
    <apply>
     <plus></plus>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>a</ci>
      <cn type="integer">0</cn>
     </apply>
     <apply>
      <times></times>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>a</ci>
       <cn type="integer">1</cn>
      </apply>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>x</ci>
       <list>
        <cn type="integer">1</cn>
        <ci>i</ci>
       </list>
      </apply>
     </apply>
     <apply>
      <times></times>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>a</ci>
       <cn type="integer">2</cn>
      </apply>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>x</ci>
       <list>
        <cn type="integer">2</cn>
        <ci>i</ci>
       </list>
      </apply>
     </apply>
     <ci>normal-…</ci>
     <apply>
      <times></times>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>a</ci>
       <ci>k</ci>
      </apply>
      <apply>
       <csymbol cd="ambiguous">subscript</csymbol>
       <ci>x</ci>
       <list>
        <ci>k</ci>
        <ci>i</ci>
       </list>
      </apply>
     </apply>
     <apply>
      <csymbol cd="ambiguous">subscript</csymbol>
      <ci>e</ci>
      <ci>i</ci>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   y_{i}=a_{0}+a_{1}x_{1,i}+a_{2}x_{2,i}+...+a_{k}x_{k,i}+e_{i}
  </annotation>
 </semantics>
</math>

</p>

<p>is postulated, in which 

<math display="inline" id="Causality:21">
 <semantics>
  <msub>
   <mi>y</mi>
   <mi>i</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>y</ci>
    <ci>i</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   y_{i}
  </annotation>
 </semantics>
</math>

 is the <em>i</em>th observation of the dependent variable (hypothesized to be the caused variable), 

<math display="inline" id="Causality:22">
 <semantics>
  <msub>
   <mi>x</mi>
   <mrow>
    <mi>j</mi>
    <mo>,</mo>
    <mi>i</mi>
   </mrow>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>x</ci>
    <list>
     <ci>j</ci>
     <ci>i</ci>
    </list>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   x_{j,i}
  </annotation>
 </semantics>
</math>

 for <em>j</em>=1,...,<em>k</em> is the <em>i</em>th observation on the <em>j</em>th independent variable (hypothesized to be a causative variable), and 

<math display="inline" id="Causality:23">
 <semantics>
  <msub>
   <mi>e</mi>
   <mi>i</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>e</ci>
    <ci>i</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   e_{i}
  </annotation>
 </semantics>
</math>

 is the error term for the <em>i</em>th observation (containing the combined effects of all other causative variables, which must be uncorrelated with the included independent variables). If there is reason to believe that none of the 

<math display="inline" id="Causality:24">
 <semantics>
  <msub>
   <mi>x</mi>
   <mi>j</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>x</ci>
    <ci>j</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   x_{j}
  </annotation>
 </semantics>
</math>

s is caused by <em>y</em>, then estimates of the coefficients 

<math display="inline" id="Causality:25">
 <semantics>
  <msub>
   <mi>a</mi>
   <mi>j</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>a</ci>
    <ci>j</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   a_{j}
  </annotation>
 </semantics>
</math>

 are obtained. If the null hypothesis that 

<math display="inline" id="Causality:26">
 <semantics>
  <mrow>
   <msub>
    <mi>a</mi>
    <mi>j</mi>
   </msub>
   <mo>=</mo>
   <mn>0</mn>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>a</ci>
     <ci>j</ci>
    </apply>
    <cn type="integer">0</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   a_{j}=0
  </annotation>
 </semantics>
</math>

 is rejected, then the alternative hypothesis that 

<math display="inline" id="Causality:27">
 <semantics>
  <mrow>
   <msub>
    <mi>a</mi>
    <mi>j</mi>
   </msub>
   <mo>≠</mo>
   <mn>0</mn>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <neq></neq>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>a</ci>
     <ci>j</ci>
    </apply>
    <cn type="integer">0</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   a_{j}\neq 0
  </annotation>
 </semantics>
</math>

 and equivalently that 

<math display="inline" id="Causality:28">
 <semantics>
  <msub>
   <mi>x</mi>
   <mi>j</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>x</ci>
    <ci>j</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   x_{j}
  </annotation>
 </semantics>
</math>

 causes <em>y</em> cannot be rejected. On the other hand, if the null hypothesis that 

<math display="inline" id="Causality:29">
 <semantics>
  <mrow>
   <msub>
    <mi>a</mi>
    <mi>j</mi>
   </msub>
   <mo>=</mo>
   <mn>0</mn>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>a</ci>
     <ci>j</ci>
    </apply>
    <cn type="integer">0</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   a_{j}=0
  </annotation>
 </semantics>
</math>

 cannot be rejected, then equivalently the hypothesis of no causal effect of 

<math display="inline" id="Causality:30">
 <semantics>
  <msub>
   <mi>x</mi>
   <mi>j</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>x</ci>
    <ci>j</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   x_{j}
  </annotation>
 </semantics>
</math>

 on <em>y</em> cannot be rejected. Here the notion of causality is one of contributory causality as discussed <a href="Causality#Necessary_and_sufficient_causes" title="wikilink">above</a>: If the true value 

<math display="inline" id="Causality:31">
 <semantics>
  <mrow>
   <msub>
    <mi>a</mi>
    <mi>j</mi>
   </msub>
   <mo>≠</mo>
   <mn>0</mn>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <neq></neq>
    <apply>
     <csymbol cd="ambiguous">subscript</csymbol>
     <ci>a</ci>
     <ci>j</ci>
    </apply>
    <cn type="integer">0</cn>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   a_{j}\neq 0
  </annotation>
 </semantics>
</math>

, then a change in 

<math display="inline" id="Causality:32">
 <semantics>
  <msub>
   <mi>x</mi>
   <mi>j</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>x</ci>
    <ci>j</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   x_{j}
  </annotation>
 </semantics>
</math>

 will result in a change in <em>y</em> <em>unless</em> some other causative variable(s), either included in the regression or implicit in the error term, change in such a way as to exactly offset its effect; thus a change in 

<math display="inline" id="Causality:33">
 <semantics>
  <msub>
   <mi>x</mi>
   <mi>j</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>x</ci>
    <ci>j</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   x_{j}
  </annotation>
 </semantics>
</math>

 is <em>not sufficient</em> to change <em>y</em>. Likewise, a change in 

<math display="inline" id="Causality:34">
 <semantics>
  <msub>
   <mi>x</mi>
   <mi>j</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>x</ci>
    <ci>j</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   x_{j}
  </annotation>
 </semantics>
</math>

 is <em>not necessary</em> to change <em>y</em>, because a change in <em>y</em> could be caused by something implicit in the error term (or by some other causative explanatory variable included in the model).</p>

<p>The above way of testing for causality requires belief that there is no reverse causation, in which <em>y</em> would cause 

<math display="inline" id="Causality:35">
 <semantics>
  <msub>
   <mi>x</mi>
   <mi>j</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>x</ci>
    <ci>j</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   x_{j}
  </annotation>
 </semantics>
</math>

. This belief can be established in one of several ways. First, the variable 

<math display="inline" id="Causality:36">
 <semantics>
  <msub>
   <mi>x</mi>
   <mi>j</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>x</ci>
    <ci>j</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   x_{j}
  </annotation>
 </semantics>
</math>

 may be a non-economic variable: for example, if rainfall amount 

<math display="inline" id="Causality:37">
 <semantics>
  <msub>
   <mi>x</mi>
   <mi>j</mi>
  </msub>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <csymbol cd="ambiguous">subscript</csymbol>
    <ci>x</ci>
    <ci>j</ci>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   x_{j}
  </annotation>
 </semantics>
</math>

 is hypothesized to affect the futures price <em>y</em> of some agricultural commodity, it is impossible that in fact the futures price affects rainfall amount (provided that cloud seeding is never attempted). Second, the <a href="instrumental_variables" title="wikilink">instrumental variables</a> technique may be employed to remove any reverse causation by introducing a role for other variables (instruments) that are known to be unaffected by the dependent variable. Third, the principle that effects cannot precede causes can be invoked, by including on the right side of the regression only variables that precede in time the dependent variable; this principle is invoked, for example, in testing for <a href="Granger_causality" title="wikilink">Granger causality</a> and in its multivariate analog, <a href="vector_autoregression" title="wikilink">vector autoregression</a>, both of which control for lagged values of the dependent variable while testing for causal effects of lagged independent variables.</p>

<p>Regression analysis controls for other relevant variables by including them as regressors (explanatory variables). This helps to avoid false inferences of causality due to the presence of a third, underlying, variable that influences both the potentially causative variable and the potentially caused variable: its effect on the potentially caused variable is captured by directly including it in the regression, so that effect will not be picked up as an indirect effect through the potentially causative variable of interest.</p>
<h3 id="management">Management</h3>

<p> For quality control in manufacturing in the 1960s, <a href="Kaoru_Ishikawa" title="wikilink">Kaoru Ishikawa</a> developed a cause and effect diagram, known as an <a href="Ishikawa_diagram" title="wikilink">Ishikawa diagram</a> or fishbone diagram. The diagram categorizes causes, such as into the six main categories shown here. These categories are then sub-divided. Ishikawa's method identifies "causes" in brainstorming sessions conducted among various groups involved in the manufacturing process. These groups can then be labeled as categories in the diagrams. The use of these diagrams has now spread beyond quality control, and they are used in other areas of management and in design and engineering. Ishikawa diagrams have been criticized for failing to make the distinction between necessary conditions and sufficient conditions. It seems that Ishikawa was not even aware of this distinction.<a class="footnoteRef" href="#fn48" id="fnref48"><sup>48</sup></a></p>
<h3 id="humanities">Humanities</h3>
<h4 id="history-1">History</h4>

<p>In the discussion of history, events are sometimes considered as if in some way being agents that can then bring about other historical events. Thus, the combination of poor harvests, the hardships of the peasants, high taxes, lack of representation of the people, and kingly ineptitude are among the <em>causes</em> of the <a href="French_Revolution" title="wikilink">French Revolution</a>. This is a somewhat <a href="Plato" title="wikilink">Platonic</a> and <a href="Georg_Wilhelm_Friedrich_Hegel" title="wikilink">Hegelian</a> view that <a href="Concretization" title="wikilink">reifies</a> causes as <a href="Ontology" title="wikilink">ontological entities</a>. In Aristotelian terminology, this use approximates to the case of the <em>efficient</em> cause.</p>

<p>Some philosophers of history such as Arthur Danto have claimed that "explanations in history and elsewhere" describe "not simply an event – something that happens – but a change".<a class="footnoteRef" href="#fn49" id="fnref49"><sup>49</sup></a> Like many practicing historians, they treat causes as intersecting actions and sets of actions which bring about "larger changes", in Danto’s words: to decide "what are the elements which persist through a change" is "rather simple" when treating an individual’s "shift in attitude", but "it is considerably more complex and metaphysically challenging when we are interested in such a change as, say, the break-up of feudalism or the emergence of nationalism".<a class="footnoteRef" href="#fn50" id="fnref50"><sup>50</sup></a></p>

<p>Much of the historical debate about causes has focused on the relationship between communicative and other actions, between singular and repeated ones, and between actions, structures of action or group and institutional contexts and wider sets of conditions.<a class="footnoteRef" href="#fn51" id="fnref51"><sup>51</sup></a> John Gaddis has distinguished between exceptional and general causes (following Marc Bloch) and between "routine" and "distinctive links" in causal relationships: "in accounting for what happened at Hiroshima on August 6, 1945, we attach greater importance to the fact that President Truman ordered the dropping of an atomic bomb than to the decision of the Army Air Force to carry out his orders."<a class="footnoteRef" href="#fn52" id="fnref52"><sup>52</sup></a> He has also pointed to the difference between immediate, intermediate and distant causes.<a class="footnoteRef" href="#fn53" id="fnref53"><sup>53</sup></a> For his part, Christopher Lloyd puts forward four "general concepts of causation" used in history: the "metaphysical idealist concept, which asserts that the phenomena of the universe are products of or emanations from an omnipotent being or such final cause"; "the empiricist (or Humean) regularity concept, which is based on the idea of causation being a matter of constant conjunctions of events"; "the functional/teleological/consequential concept", which is "goal-directed, so that goals are causes"; and the "realist, structurist and dispositional approach, which sees relational structures and internal dispositions as the causes of phenomena".<a class="footnoteRef" href="#fn54" id="fnref54"><sup>54</sup></a></p>
<h4 id="law">Law</h4>

<p>According to <a class="uri" href="law" title="wikilink">law</a> and <a class="uri" href="jurisprudence" title="wikilink">jurisprudence</a>, <strong>legal cause</strong> must be demonstrated to hold a <a class="uri" href="defendant" title="wikilink">defendant</a> liable for a <a class="uri" href="crime" title="wikilink">crime</a> or a <a class="uri" href="tort" title="wikilink">tort</a> (i.e. a civil wrong such as negligence or trespass). It must be proven that causality, or a "sufficient causal link" relates the defendant's actions to the criminal event or damage in question. Causation is also an essential legal element that must be proven to qualify for remedy measures under international trade law.<a class="footnoteRef" href="#fn55" id="fnref55"><sup>55</sup></a></p>
<h3 id="theology">Theology</h3>

<p>Note the concept of omnicausality in <a href="Abrahamic_religions" title="wikilink">Abrahamic</a> theology, which is the belief that God has set in motion all events at the dawn of time; he is the determiner and the cause of all things. It is therefore an attempt to rectify the apparent <a href="incompatibilism" title="wikilink">incompatibility</a> between determinism and the existence of an <a href="omnipotence" title="wikilink">omnipotent god</a>.<a class="footnoteRef" href="#fn56" id="fnref56"><sup>56</sup></a></p>
<h2 id="see-also">See also</h2>
<dl>
<dt>General</dt>
</dl>
<ul>
<li><a href="Causal_research" title="wikilink">Causal research</a></li>
<li><a href="Cosmological_argument" title="wikilink">Cosmological argument</a></li>
<li><a href="Domino_effect" title="wikilink">Domino effect</a></li>
<li><a class="uri" href="Effectuation" title="wikilink">Effectuation</a></li>
<li><a href="Sequence_of_events" title="wikilink">Sequence of events</a></li>
</ul>
<dl>
<dt>Mathematics</dt>
</dl>
<ul>
<li><a href="Causal_filter" title="wikilink">Causal filter</a></li>
<li><a href="Causal_system" title="wikilink">Causal system</a></li>
<li><a href="Causality_conditions" title="wikilink">Causality conditions</a></li>
<li><a href="Chaos_theory" title="wikilink">Chaos theory</a></li>
</ul>
<dl>
<dt>Physics</dt>
</dl>
<ul>
<li><a href="Anthropic_principle" title="wikilink">Anthropic principle</a></li>
<li><a href="Arrow_of_time" title="wikilink">Arrow of time</a></li>
<li><a href="Butterfly_effect" title="wikilink">Butterfly effect</a></li>
<li><a href="Chain_reaction" title="wikilink">Chain reaction</a></li>
<li><a class="uri" href="Feedback" title="wikilink">Feedback</a></li>
<li><a href="Grandfather_paradox" title="wikilink">Grandfather paradox</a></li>
<li><a href="Quantum_Zeno_effect" title="wikilink">Quantum Zeno effect</a></li>
<li><a class="uri" href="Retrocausality" title="wikilink">Retrocausality</a></li>
<li><a href="Schrödinger's_cat" title="wikilink">Schrödinger's cat</a></li>
<li><a href="Wheeler–Feynman_absorber_theory" title="wikilink">Wheeler–Feynman absorber theory</a></li>
</ul>
<dl>
<dt>Philosophy</dt>
</dl>
<ul>
<li><a class="uri" href="Aetiology" title="wikilink">Aetiology</a></li>
<li><a class="uri" href="Arche" title="wikilink">Arche</a> (ἀρχή)</li>
<li><a href="Chance_(philosophy)" title="wikilink">Chance (philosophy)</a></li>
<li><a href="Chicken_or_the_egg" title="wikilink">Chicken or the egg</a></li>
<li><a href="Condition_of_possibility" title="wikilink">Condition of possibility</a></li>
<li><a class="uri" href="Determinism" title="wikilink">Determinism</a></li>
<li><a href="Mill's_Methods" title="wikilink">Mill's Methods</a></li>
<li><a href="Newcomb's_paradox" title="wikilink">Newcomb's paradox</a></li>
<li><a href="Non_sequitur_(logic)" title="wikilink">Non sequitur (logic)</a></li>
<li><a href="Ontological_paradox" title="wikilink">Ontological paradox</a></li>
<li><a href="Post_hoc_ergo_propter_hoc" title="wikilink">Post hoc ergo propter hoc</a></li>
<li><a href="Predestination_paradox" title="wikilink">Predestination paradox</a></li>
<li><a href="Principle_of_sufficient_reason#Proposed_proofs_of_universal_validity" title="wikilink">Proposed proofs of universal validity</a> (principle of causality)</li>
<li><a href="Proximate_and_ultimate_causation" title="wikilink">Proximate and ultimate causation</a></li>
<li><a href="Subject–object_problem" title="wikilink">Subject–object problem</a></li>
<li><a class="uri" href="Supervenience" title="wikilink">Supervenience</a></li>
</ul>
<dl>
<dt>Philosophy of mind</dt>
</dl>
<ul>
<li><a class="uri" href="Synchronicity" title="wikilink">Synchronicity</a></li>
</ul>
<dl>
<dt>Statistics</dt>
</dl>
<ul>
<li><a href="Causal_loop_diagram" title="wikilink">Causal loop diagram</a></li>
<li><a href="Causal_Markov_condition" title="wikilink">Causal Markov condition</a></li>
<li><a href="Correlation_does_not_imply_causation" title="wikilink">Correlation does not imply causation</a></li>
<li><a href="Experimental_design" title="wikilink">Experimental design</a></li>
<li><a href="Granger_causality" title="wikilink">Granger causality</a></li>
<li><a href="Linear_regression" title="wikilink">Linear regression</a></li>
<li><a class="uri" href="Randomness" title="wikilink">Randomness</a></li>
<li><a href="Rubin_causal_model" title="wikilink">Rubin causal model</a></li>
<li><a href="Validity_(statistics)" title="wikilink">Validity (statistics)</a></li>
</ul>
<dl>
<dt>Psychology and medicine</dt>
</dl>
<ul>
<li><a href="Adverse_effect_(medicine)" title="wikilink">Adverse effect</a></li>
<li><a href="Clinical_trial" title="wikilink">Clinical trial</a></li>
<li><a href="Force_dynamics" title="wikilink">Force dynamics</a></li>
<li><a class="uri" href="Iatrogenesis" title="wikilink">Iatrogenesis</a></li>
<li><a class="uri" href="Nocebo" title="wikilink">Nocebo</a></li>
<li><a class="uri" href="Placebo" title="wikilink">Placebo</a></li>
<li><a href="Scientific_control" title="wikilink">Scientific control</a></li>
<li><a class="uri" href="Suggestibility" title="wikilink">Suggestibility</a></li>
<li><a class="uri" href="Suggestion" title="wikilink">Suggestion</a></li>
</ul>
<dl>
<dt>Pathology and epidemiology</dt>
</dl>
<ul>
<li><a href="Causal_inference" title="wikilink">Causal inference</a></li>
<li><a class="uri" href="Epidemiology" title="wikilink">Epidemiology</a></li>
<li><a class="uri" href="Etiology" title="wikilink">Etiology</a></li>
<li><a href="Molecular_pathology" title="wikilink">Molecular pathology</a></li>
<li><a href="Molecular_pathological_epidemiology" title="wikilink">Molecular pathological epidemiology</a></li>
<li><a class="uri" href="Pathogenesis" title="wikilink">Pathogenesis</a></li>
<li><a class="uri" href="Pathology" title="wikilink">Pathology</a></li>
</ul>
<dl>
<dt>Sociology and economics</dt>
</dl>
<ul>
<li><a href="Instrumental_variable" title="wikilink">Instrumental variable</a></li>
<li><a href="Root_cause_analysis" title="wikilink">Root cause analysis</a></li>
<li><a href="Self-fulfilling_prophecy" title="wikilink">Self-fulfilling prophecy</a></li>
<li><a href="Unintended_consequence" title="wikilink">Unintended consequence</a></li>
<li><a href="Virtuous_circle_and_vicious_circle" title="wikilink">Virtuous circle and vicious circle</a></li>
</ul>
<h2 id="references">References</h2>
<h2 id="further-reading">Further reading</h2>
<ul>
<li><a href="Azamat_Abdoullaev" title="wikilink">Azamat Abdoullaev</a> (2000). <em>The Ultimate of Reality: Reversible Causality</em>, in Proceedings of the 20th World Congress of Philosophy, Boston: Philosophy Documentation Centre, internet site, Paideia Project On-Line: <a class="uri" href="http://www.bu.edu/wcp/MainMeta.htm">http://www.bu.edu/wcp/MainMeta.htm</a></li>
<li><a href="Arthur_Danto" title="wikilink">Arthur Danto</a> (1965). <em>Analytical Philosophy of History</em>. Cambridge University Press.</li>
<li>Idem, 'Complex Events', <em>Philosophy and Phenomenological Research</em>, 30 (1969), 66-77.</li>
<li>Idem, 'On Explanations in History', <em>Philosophy of Science</em>, 23 (1956), 15-30.</li>
<li>Dorschel, Andreas, 'The Crypto-Metaphysic of 'Ultimate Causes'. Remarks on an alleged Exposé' (transl. <a href="Edward_Craig_(translator)" title="wikilink">Edward Craig</a>), in: <em>Ratio</em>, N.S. I (1988), nr. 2, pp. 97–112.</li>
<li>Green, Celia (2003). <em>The Lost Cause: Causation and the Mind-Body Problem</em>. Oxford: Oxford Forum. ISBN 0-9536772-1-4 Includes three chapters on causality at the microlevel in physics.</li>
<li>Hewitson, Mark (2014). <em>History and Causality</em>. Palgrave Macmillan. ISBN 978-1-137-37239-0.</li>
<li>Little, Daniel (1998). <em>Microfoundations, Method and Causation: On the Philosophy of the Social Sciences</em>. New York: Transaction.</li>
<li>Lloyd, Christopher (1993). <em>The Structures of History</em>. Oxford: Blackwell.</li>
<li>Idem (1986). <em>Explanation in Social History</em>. Oxford: Blackwell.</li>
<li><a href="Maurice_Mandelbaum" title="wikilink">Maurice Mandelbaum</a> (1977). <em>The Anatomy of Historical Knowledge</em>. Baltimore: Johns Hopkins Press.</li>
<li><a href="Judea_Pearl" title="wikilink">Judea Pearl</a> (2000). <em>Causality: Models of Reasoning and Inference</em> <a href="http://bayes.cs.ucla.edu/BOOK-2K/">1</a> <a href="Cambridge_University_Press" title="wikilink">Cambridge University Press</a> ISBN 978-0-521-77362-1</li>
<li>Rosenberg, M. (1968). <em>The Logic of Survey Analysis</em>. New York: Basic Books, Inc.</li>
</ul>
<ul>
<li>Spirtes, Peter, Clark Glymour and Richard Scheines <em>Causation, Prediction, and Search</em>, <a href="MIT_Press" title="wikilink">MIT Press</a>, ISBN 0-262-19440-6</li>
<li><a href="University_of_California" title="wikilink">University of California</a> journal articles, including Judea Pearl's articles between 1984 and 1998 <a href="http://fmdb.cs.ucla.edu/tech_reports/searchresponse.lasso#Anchor-Judea%20Pearl">2</a>.</li>
<li></li>
</ul>
<h2 id="external-links">External links</h2>
<ul>
<li>Mete Avcı <a href="http://metheus.eu">Metheus</a>, 2013, <a href="http://metheus.eu/yazi/nedensellik">Nedenselliğin bir eleştirisi</a></li>
<li></li>
<li></li>
<li><a href="http://bayes.cs.ucla.edu/LECTURE/lecture_sec1.htm">"The Art and Science of Cause and Effect"</a>: a slide show and tutorial lecture by Judea Pearl</li>
<li><a href="http://www.utm.edu/research/iep/d/davidson.htm#H3">Donald Davidson: Causal Explanation of Action</a> The Internet Encyclopedia of Philosophy</li>
<li><a href="http://leadsto.fzi.de">leadsto:</a> a public available collection comprising more than 5000 causalities</li>
<li><a href="http://ftp.cs.ucla.edu/pub/stat_ser/r350.pdf">Causal inference in statistics: An overview</a>, by Judea Pearl (September 2009)</li>
</ul>
<dl>
<dt>Stanford Encyclopedia of Philosophy</dt>
</dl>
<ul>
<li><a href="http://plato.stanford.edu/entries/causation-backwards/">Backwards Causation</a></li>
<li><a href="http://plato.stanford.edu/entries/causation-process/">Causal Processes</a></li>
<li><a href="http://plato.stanford.edu/entries/causation-mani/">Causation and Manipulability</a></li>
<li><a href="http://plato.stanford.edu/entries/causation-law/">Causation in the Law</a></li>
<li><a href="http://plato.stanford.edu/entries/causation-counterfactual/">Counterfactual Theories of Causation</a></li>
<li><a href="http://plato.stanford.edu/entries/causation-medieval/">Medieval Theories of Causation</a></li>
<li><a href="http://plato.stanford.edu/entries/causation-probabilistic/">Probabilistic Causation</a></li>
<li><a href="http://plato.stanford.edu/entries/causation-metaphysics/">The Metaphysics of Causation</a></li>
</ul>
<dl>
<dt>General</dt>
</dl>
<ul>
<li><a href="http://etext.lib.virginia.edu/cgi-local/DHI/dhi.cgi?id=dv1-37"><em>Dictionary of the History of Ideas</em>:</a> Causation</li>
<li><a href="http://etext.lib.virginia.edu/cgi-local/DHI/dhi.cgi?id=dv1-38"><em>Dictionary of the History of Ideas</em>:</a> Causation in History</li>
<li><a href="http://etext.lib.virginia.edu/cgi-local/DHI/dhi.cgi?id=dv1-40"><em>Dictionary of the History of Ideas</em>:</a> Causation in Law</li>
<li><a href="http://www.epidemiology.ch/history/betaversion.htm">People's Epidemiology Library</a></li>
</ul>

<p><a class="uri" href="ru:Причинность" title="wikilink">ru:Причинность</a>"</p>

<p><a href="Category:Causality" title="wikilink"> </a> <a href="Category:Causal_inference" title="wikilink"> </a> <a class="uri" href="Category:Conditionals" title="wikilink">Category:Conditionals</a> <a href="Category:Philosophy_of_science" title="wikilink">Category:Philosophy of science</a> <a href="Category:Concepts_in_physics" title="wikilink">Category:Concepts in physics</a> <a href="Category:Concepts_in_epistemology" title="wikilink">Category:Concepts in epistemology</a> <a href="Category:Concepts_in_metaphysics" title="wikilink">Category:Concepts in metaphysics</a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1">'The action of causing; the relation of cause and effect' <a class="uri" href="OED" title="wikilink">OED</a><a href="#fnref1">↩</a></li>
<li id="fn2"><a class="uri" href="http://psychologydictionary.org/causal-nexus/">http://psychologydictionary.org/causal-nexus/</a><a href="#fnref2">↩</a></li>
<li id="fn3">Graham, D.W. (1987). <a href="http://ukcatalogue.oup.com/product/9780198243151.do#.UhqWXr5-8dE"><em>Aristotles's Two Systems</em></a>, Oxford University Press, Oxford UK, ISBN 0-19-824970-5<a href="#fnref3">↩</a></li>
<li id="fn4"><a class="uri" href="http://www.wisdomsupreme.com/dictionary/aristotles-four-causes.php">http://www.wisdomsupreme.com/dictionary/aristotles-four-causes.php</a><a href="#fnref4">↩</a></li>
<li id="fn5"><a href="#fnref5">↩</a></li>
<li id="fn6"><a href="#fnref6">↩</a></li>
<li id="fn7"></li>
<li id="fn8"></li>
<li id="fn9"></li>
<li id="fn10"><a href="#fnref10">↩</a></li>
<li id="fn11"></li>
<li id="fn12"><a href="#fnref12">↩</a></li>
<li id="fn13"><a href="Max_Born" title="wikilink">Born, M.</a> (1949). <a href="https://archive.org/details/naturalphilosoph032159mbp"><em>Natural Philosophy of Cause and Chance</em></a>, Oxford University Press, London, p. 9.<a href="#fnref13">↩</a></li>
<li id="fn14"><a href="#fnref14">↩</a></li>
<li id="fn15"><a href="#fnref15">↩</a></li>
<li id="fn16"><a href="#fnref16">↩</a></li>
<li id="fn17">Epp, Susanna S.: "Discrete Mathematics with Applications, Third Edition", pp 25-26. Brooks/Cole—Thomson Learning, 2004. ISBN 0-534-35945-0<a href="#fnref17">↩</a></li>
<li id="fn18"><a href="#fnref18">↩</a></li>
<li id="fn19">Mackie, John L. The Cement of the Universe: A study in Causation. Clarendon Press, Oxford, England, 1988.<a href="#fnref19">↩</a></li>
<li id="fn20">Byrne, R.M.J. (2005). <em>The Rational Imagination: How People Create Counterfactual Alternatives to Reality.</em> Cambridge, Massachusetts: MIT Press.<a href="#fnref20">↩</a></li>
<li id="fn21">Miller, G. &amp; Johnson-Laird, P.N. (1976). Language and Perception. Cambridge: Cambridge University Press.<a href="#fnref21">↩</a></li>
<li id="fn22"><a href="#fnref22">↩</a></li>
<li id="fn23"><a href="#fnref23">↩</a></li>
<li id="fn24"><a href="#fnref24">↩</a></li>
<li id="fn25">Pearl, Judea (2000). <em>Causality: Models, Reasoning, and Inference</em>, Cambridge University Press.<a href="#fnref25">↩</a></li>
<li id="fn26">Wright, S., "Correlation and Causation", <em>Journal of Agricultural Research, vol. 20</em>, #7, pp. 557–585.<a href="#fnref26">↩</a></li>
<li id="fn27">Rebane, G. and Pearl, J., "The Recovery of Causal Poly-trees from Statistical Data", <em>Proceedings, 3rd Workshop on Uncertainty in AI</em>, (Seattle) pp. 222-228,1987<a href="#fnref27">↩</a></li>
<li id="fn28"></li>
<li id="fn29">Spirites, P. and Glymour, C., "An algorithm for fast recovery of sparse causal graphs", <em>Social Science Computer Review</em>, Vol. 9, pp. 62-72, 1991.<a href="#fnref29">↩</a></li>
<li id="fn30">Spirtes, P. and Glymour, C. and Scheines, R., <em>Causation, Prediction, and Search</em>, New York: Springer-Verlag, 1993<a href="#fnref30">↩</a></li>
<li id="fn31">Verma, T. and Pearl, J., "Equivalence and Synthesis of Causal Models", <em>Proceedings of the Sixth Conference on Uncertainty in Artificial Intelligence</em>, (July, Cambridge, Massachusetts), pp. 220-227, 1990. Reprinted in P. Bonissone, M. Henrion, L.N. Kanal and J.F.\ Lemmer (Eds.), <em>Uncertainty in Artificial Intelligence 6</em>, Amsterdam: Elsevier Science Publishers, B.V., pp. 225-268, 1991<a href="#fnref31">↩</a></li>
<li id="fn32">Simon, Herbert, and Rescher, Nicholas (1966) "Cause and Counterfactual." Philosophy of Science 33: 323–40.<a href="#fnref32">↩</a></li>
<li id="fn33">Collingwood, R.(1940) <em>An Essay on Metaphysics.</em> Clarendon Press.<a href="#fnref33">↩</a></li>
<li id="fn34">Gasking, D. (1955) "Causation and Recipes" <em>Mind</em> (64): 479-487.<a href="#fnref34">↩</a></li>
<li id="fn35">Menzies, P. and H. Price (1993) "Causation as a Secondary Quality" <em>British Journal for the Philosophy of Science</em> (44): 187-203.<a href="#fnref35">↩</a></li>
<li id="fn36">von Wright, G.(1971) <em>Explanation and Understanding.</em> <a href="Cornell_University_Press" title="wikilink">Cornell University Press</a>.<a href="#fnref36">↩</a></li>
<li id="fn37"></li>
<li id="fn38">Woodward, James (2003) <em>Making Things Happen: A Theory of Causal Explanation</em>. <a href="Oxford_University_Press" title="wikilink">Oxford University Press</a>, ISBN 0-19-515527-0<a href="#fnref38">↩</a></li>
<li id="fn39">Salmon, W. (1984) <em>Scientific Explanation and the Causal Structure of the World</em>. Princeton University Press.<a href="#fnref39">↩</a></li>
<li id="fn40">Russell, B. (1948) <em>Human Knowledge</em>. Simon and Schuster.<a href="#fnref40">↩</a></li>
<li id="fn41"></li>
<li id="fn42"><a class="uri" href="http://blogs.berkeley.edu/2012/11/05/global-warming-systemically-caused-hurricane-sandy/">http://blogs.berkeley.edu/2012/11/05/global-warming-systemically-caused-hurricane-sandy/</a><a href="#fnref42">↩</a></li>
<li id="fn43"><a href="#fnref43">↩</a></li>
<li id="fn44"><a href="#fnref44">↩</a></li>
<li id="fn45">Cheng, P.W. (1997). "From Covariation to Causation: A Causal Power Theory." <em>Psychological Review</em> 104: 367-405.<a href="#fnref45">↩</a></li>
<li id="fn46"><a href="#fnref46">↩</a></li>
<li id="fn47"><a href="#fnref47">↩</a></li>
<li id="fn48">Gregory, Frank Hutson (1992) <a href="s:Cause,_Effect,_Efficiency_&amp;_Soft_Systems_Models" title="wikilink">Cause, Effect, Efficiency &amp; Soft Systems Models</a>, Warwick Business School Research Paper No. 42 (ISSN 0265-5976), later published in <em>Journal of the Operational Research Society</em>, vol. 44 (4), pp 333-344.<a href="#fnref48">↩</a></li>
<li id="fn49">Danto, Arthur (1965) <em>Analytical Philosophy of History</em>, 233.<a href="#fnref49">↩</a></li>
<li id="fn50">Danto, Arthur (1965) <em>Analytical Philosophy of History</em>, 249.<a href="#fnref50">↩</a></li>
<li id="fn51">Hewitson, Mark (2014) <em>History and Causality</em>, 86-116.<a href="#fnref51">↩</a></li>
<li id="fn52">Gaddis, John L. (2002), <em>The Landscape of History: How Historians Map the Past</em>, 64.<a href="#fnref52">↩</a></li>
<li id="fn53">Gaddis, John L. (2002), <em>The Landscape of History: How Historians Map the Past</em>, 95.<a href="#fnref53">↩</a></li>
<li id="fn54">Lloyd, Christopher (1993) <em>Structures of History</em>, 159.<a href="#fnref54">↩</a></li>
<li id="fn55"><a href="#fnref55">↩</a></li>
<li id="fn56">See for example <a href="#fnref56">↩</a></li>
</ol>
</section>
</body>
</html>
