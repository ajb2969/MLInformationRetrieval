<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="590">Logic programming</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>Logic programming</h1>
<hr/>

<p><strong>Logic programming</strong> is a <a href="programming_paradigm" title="wikilink">programming paradigm</a> based on <a href="formal_logic" title="wikilink">formal logic</a>. A program written in a logic <a href="programming_language" title="wikilink">programming language</a> is a set of sentences in logical form, expressing facts and rules about some problem domain. Major <a href="logic_programming_language" title="wikilink">logic programming language</a> families include <a class="uri" href="Prolog" title="wikilink">Prolog</a>, <a href="Answer_set_programming" title="wikilink">Answer set programming</a> (ASP) and <a class="uri" href="Datalog" title="wikilink">Datalog</a>. In all of these languages, rules are written in the form of <em>clauses</em>:</p>
<dl>
<dd><code>H :- B<sub>1</sub>, …, B<sub>n</sub>.</code>
</dd>
</dl>

<p>and are read declaratively as logical implications:</p>
<dl>
<dd><code>H if B<sub>1</sub> and … and B<sub>n</sub>.</code>
</dd>
</dl>

<p><code>H</code> is called the <em>head</em> of the rule and <code>B<sub>1</sub></code>, …, <code>B<sub>n</sub></code> is called the <em>body</em>. Facts are rules that have no body, and are written in the simplified form:</p>
<dl>
<dd><code>H.</code>
</dd>
</dl>

<p>In the simplest case in which <code>H</code>, <code>B<sub>1</sub></code>, …, <code>B<sub>n</sub></code> are all atomic formulae, these clauses are called definite clauses or <a href="Horn_clause" title="wikilink">Horn clauses</a>. However, there exist many extensions of this simple case, the most important one being the case in which conditions in the body of a clause can also be negations of atomic formulae. Logic programming languages that include this extension have the knowledge representation capabilities of a <a href="non-monotonic_logic" title="wikilink">non-monotonic logic</a>.</p>

<p>In ASP and Datalog, logic programs have only a <a href="Declarative_programming" title="wikilink">declarative</a> reading, and their execution is performed by means of a proof procedure or model generator whose behaviour is not meant to be under the control of the programmer. However, in the Prolog family of languages, logic programs also have a <a href="Procedural_programming" title="wikilink">procedural</a> interpretation as goal-reduction procedures:</p>
<dl>
<dd>to solve <code>H</code>, solve <code>B<sub>1</sub></code>, and ... and solve <code>B<sub>n</sub></code>.
</dd>
</dl>

<p>Consider, for example, the following clause:</p>
<dl>
<dd><code>fallible(X) :- human(X).</code>
</dd>
</dl>

<p>based on an example used by <a href="Terry_Winograd" title="wikilink">Terry Winograd</a> <a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a> to illustrate the programming language <a href="Planner_(programming_language)" title="wikilink">Planner</a>. As a clause in a logic program, it can be used both as a procedure to test whether <code>X</code> is <code>fallible</code> by testing whether <code>X</code> is <code>human</code>, and as a procedure to find an <code>X</code> that is <code>fallible</code> by finding an <code>X</code> that is <code>human</code>. Even facts have a procedural interpretation. For example, the clause:</p>
<dl>
<dd><code>human(socrates).</code>
</dd>
</dl>

<p>can be used both as a procedure to show that <code>socrates</code> is <code>human</code>, and as a procedure to find an <code>X</code> that is <code>human</code> by "assigning" <code>socrates</code> to <code>X</code>.</p>

<p>The declarative reading of logic programs can be used by a programmer to verify their correctness. Moreover, logic-based <a href="program_transformation" title="wikilink">program transformation</a> techniques can also be used to transform logic programs into logically equivalent programs that are more efficient. In the Prolog family of logic programming languages, the programmer can also use the known problem-solving behaviour of the execution mechanism to improve the efficiency of programs.</p>
<h2 id="history">History</h2>

<p>The use of mathematical logic to represent and execute computer programs is also a feature of the <a href="lambda_calculus" title="wikilink">lambda calculus</a>, developed by <a href="Alonzo_Church" title="wikilink">Alonzo Church</a> in the 1930s. However, the first proposal to use the <a href="Clausal_normal_form" title="wikilink">clausal</a> form of logic for representing computer programs was made by Cordell Green.<a class="footnoteRef" href="#fn2" id="fnref2"><sup>2</sup></a> This used an axiomatization of a subset of <a class="uri" href="LISP" title="wikilink">LISP</a>, together with a representation of an input-output relation, to compute the relation by simulating the execution of the program in LISP. Foster and Elcock's <a class="uri" href="Absys" title="wikilink">Absys</a>, on the other hand, employed a combination of equations and lambda calculus in an assertional programming language which places no constraints on the order in which operations are performed.<a class="footnoteRef" href="#fn3" id="fnref3"><sup>3</sup></a></p>

<p>Logic programming in its present form can be traced back to debates in the late 1960s and early 1970s about declarative versus procedural representations of knowledge in Artificial Intelligence. Advocates of declarative representations were notably working at <a href="Stanford_University" title="wikilink">Stanford</a>, associated with <a href="John_McCarthy_(computer_scientist)" title="wikilink">John McCarthy</a>, <a href="Bertram_Raphael" title="wikilink">Bertram Raphael</a> and <a href="Cordell_Green" title="wikilink">Cordell Green</a>, and in <a href="University_of_Edinburgh" title="wikilink">Edinburgh</a>, with <a href="John_Alan_Robinson" title="wikilink">John Alan Robinson</a> (an academic visitor from <a href="Syracuse_University" title="wikilink">Syracuse University</a>), <a href="Patrick_J._Hayes" title="wikilink">Pat Hayes</a>, and <a href="Robert_Kowalski" title="wikilink">Robert Kowalski</a>. Advocates of procedural representations were mainly centered at <a class="uri" href="MIT" title="wikilink">MIT</a>, under the leadership of <a href="Marvin_Minsky" title="wikilink">Marvin Minsky</a> and <a href="Seymour_Papert" title="wikilink">Seymour Papert</a>.</p>

<p>Although it was based on the proof methods of logic, <a href="Planner_(programming_language)" title="wikilink">Planner</a>, developed at MIT, was the first language to emerge within this proceduralist paradigm.<a class="footnoteRef" href="#fn4" id="fnref4"><sup>4</sup></a> Planner featured pattern-directed invocation of procedural plans from goals (i.e. goal-reduction or <a href="backward_chaining" title="wikilink">backward chaining</a>) and from assertions (i.e. <a href="forward_chaining" title="wikilink">forward chaining</a>). The most influential implementation of Planner was the subset of Planner, called Micro-Planner, implemented by <a href="Gerald_Jay_Sussman" title="wikilink">Gerry Sussman</a>, <a href="Eugene_Charniak" title="wikilink">Eugene Charniak</a> and <a href="Terry_Winograd" title="wikilink">Terry Winograd</a>. It was used to implement Winograd's natural-language understanding program <a class="uri" href="SHRDLU" title="wikilink">SHRDLU</a>, which was a landmark at that time.<a class="footnoteRef" href="#fn5" id="fnref5"><sup>5</sup></a> To cope with the very limited memory systems at the time, Planner used a backtracking control structure so that only one possible computation path had to be stored at a time. Planner gave rise to the programming languages QA-4, Popler, Conniver, QLISP, and the concurrent language Ether.</p>

<p>Hayes and Kowalski in Edinburgh tried to reconcile the logic-based declarative approach to knowledge representation with Planner's procedural approach. Hayes (1973) developed an equational language, Golux, in which different procedures could be obtained by altering the behavior of the theorem prover.<a class="footnoteRef" href="#fn6" id="fnref6"><sup>6</sup></a> Kowalski, on the other hand, developed <a href="SLD_resolution" title="wikilink">SLD resolution</a>,<a class="footnoteRef" href="#fn7" id="fnref7"><sup>7</sup></a> a variant of SL-resolution,<a class="footnoteRef" href="#fn8" id="fnref8"><sup>8</sup></a> and showed how it treats implications as goal-reduction procedures. Kowalski collaborated with <a href="Alain_Colmerauer" title="wikilink">Colmerauer</a> in Marseille, who developed these ideas in the design and implementation of the programming language <a class="uri" href="Prolog" title="wikilink">Prolog</a>.</p>

<p>The <a href="Association_for_Logic_Programming" title="wikilink">Association for Logic Programming</a> was founded to promote Logic Programming in 1986.</p>

<p>Prolog gave rise to the programming languages <a href="Algebraic_Logic_Functional_programming_language" title="wikilink">ALF</a>, <a class="uri" href="Fril" title="wikilink">Fril</a>, <a href="Gödel_(programming_language)" title="wikilink">Gödel</a>, <a href="Mercury_programming_language" title="wikilink">Mercury</a>, <a href="Oz_(programming_language)" title="wikilink">Oz</a>, <a href="Ciao_(programming_language)" title="wikilink">Ciao</a>, <a href="Visual_Prolog" title="wikilink">Visual Prolog</a>, <a class="uri" href="XSB" title="wikilink">XSB</a>, and <a class="uri" href="λProlog" title="wikilink">λProlog</a>, as well as a variety of <a href="Concurrent_logic_programming" title="wikilink"> concurrent logic programming languages</a>,<a class="footnoteRef" href="#fn9" id="fnref9"><sup>9</sup></a> <a href="constraint_logic_programming" title="wikilink">constraint logic programming</a> languages and <a class="uri" href="datalog" title="wikilink">datalog</a>.</p>
<h2 id="concepts">Concepts</h2>
<h3 id="logic-and-control">Logic and control</h3>
<dl>
<dd>
</dd>
</dl>

<p>Logic programming can be viewed as controlled deduction. An important concept in logic programming is the separation of programs into their logic component and their control component. With pure logic programming languages, the logic component alone determines the solutions produced. The control component can be varied to provide alternative ways of executing a logic program. This notion is captured by the slogan</p>
<dl>
<dd>Algorithm = Logic + Control
</dd>
</dl>

<p>where "Logic" represents a logic program and "Control" represents different theorem-proving strategies.<a class="footnoteRef" href="#fn10" id="fnref10"><sup>10</sup></a></p>
<h3 id="problem-solving">Problem solving</h3>

<p>In the simplified, propositional case in which a logic program and a top-level atomic goal contain no variables, backward reasoning determines an <a href="and-or_tree" title="wikilink">and-or tree</a>, which constitutes the search space for solving the goal. The top-level goal is the root of the tree. Given any node in the tree and any clause whose head matches the node, there exists a set of child nodes corresponding to the sub-goals in the body of the clause. These child nodes are grouped together by an "and". The alternative sets of children corresponding to alternative ways of solving the node are grouped together by an "or".</p>

<p>Any search strategy can be used to search this space. Prolog uses a sequential, last-in-first-out, backtracking strategy, in which only one alternative and one sub-goal is considered at a time. Other search strategies, such as parallel search, intelligent backtracking, or best-first search to find an optimal solution, are also possible.</p>

<p>In the more general case, where sub-goals share variables, other strategies can be used, such as choosing the subgoal that is most highly instantiated or that is sufficiently instantiated so that only one procedure applies. Such strategies are used, for example, in <a href="concurrent_logic_programming" title="wikilink">concurrent logic programming</a>.</p>
<h3 id="negation-as-failure">Negation as failure</h3>

<p>For most practical applications, as well as for applications that require non-monotonic reasoning in artificial intelligence, Horn clause logic programs need to be extended to normal logic programs, with negative conditions. A <em>clause</em> in a normal logic program has the form:</p>
<dl>
<dd><code>H :- A<sub>1</sub>, …, A<sub>n</sub>, not B<sub>1</sub>, …, not B<sub>n</sub>. </code>
</dd>
</dl>

<p>and is read declaratively as a logical implication:</p>
<dl>
<dd><code>H if A<sub>1</sub> and … and A<sub>n</sub> and not B<sub>1</sub> and … and not B<sub>n</sub>.</code>
</dd>
</dl>

<p>where <code>H</code> and all the <code>A<sub>i</sub></code> and <code>B<sub>i</sub></code> are atomic formulas. The negation in the negative literals <code> not B<sub>i</sub></code> is commonly referred to as "<a href="negation_as_failure" title="wikilink">negation as failure</a>", because in most implementations, a negative condition <code> not B<sub>i</sub></code> is shown to hold by showing that the positive condition <code> B<sub>i</sub></code> fails to hold. For example:</p>
<dl>
<dd><code>canfly(X) :- bird(X), not abnormal(X).</code>
</dd>
<dd><code>abnormal(X) :-  wounded(X).</code>
</dd>
<dd><code> bird(john).</code>
</dd>
<dd><code> bird(mary).</code>
</dd>
<dd><code> wounded(john).</code>
</dd>
</dl>

<p>Given the goal of finding something that can fly:</p>
<dl>
<dd><code>:- canfly(X).</code>
</dd>
</dl>

<p>there are two candidate solutions, which solve the first subgoal <code>bird(X)</code>, namely <code>X = john</code> and <code>X = mary</code>. The second subgoal <code>not abnormal(john)</code> of the first candidate solution fails, because <code>wounded(john)</code> succeeds and therefore <code>abnormal(john)</code> succeeds. However, The second subgoal <code>not abnormal(mary)</code> of the second candidate solution succeeds, because <code>wounded(mary)</code> fails and therefore <code>abnormal(mary)</code> fails. Therefore <code>X = mary</code> is the only solution of the goal.</p>

<p>Micro-Planner had a construct, called "thnot", which when applied to an expression returns the value true if (and only if) the evaluation of the expression fails. An equivalent operator is normally built-in in modern <a class="uri" href="Prolog" title="wikilink">Prolog</a>'s implementations. It is normally written as <code>not(''Goal'')</code> or <code>\+ ''Goal''</code>, where <code>''Goal''</code> is some goal (proposition) to be proved by the program. This operator differs from negation in first-order logic: a negation such as <code>\+ X == 1</code> fails when the variable <code>X</code> has been bound to the atom <code>1</code>, but it succeeds in all other cases, including when <code>X</code> is unbound. This makes Prolog's reasoning <a href="non-monotonic_logic" title="wikilink">non-monotonic</a>: <code>X = 1, \+ X == 1</code> always fails, while <code>\+ X == 1, X = 1</code> can succeed, binding <code>X</code> to <code>1</code>, depending on whether <code>X</code> was initially bound (note that standard Prolog executes goals in left-to-right order).</p>

<p>The logical status of negation as failure was unresolved until Keith Clark [1978] showed that, under certain natural conditions, it is a correct (and sometimes complete) implementation of classical negation with respect to the completion of the program. Completion amounts roughly to regarding the set of all the program clauses with the same predicate on the left hand side, say</p>
<dl>
<dd><code>H :-  Body<sub>1</sub>.</code>
</dd>
<dd><code>      …</code>
</dd>
<dd><code>H :-  Body<sub>k</sub>.</code>
</dd>
</dl>

<p>as a definition of the predicate</p>
<dl>
<dd><code>H iff (Body<sub>1</sub> or … or Body<sub>k</sub>)</code>
</dd>
</dl>

<p>where "iff" means "if and only if". Writing the completion also requires explicit use of the equality predicate and the inclusion of a set of appropriate axioms for equality. However, the implementation of negation by failure needs only the if-halves of the definitions without the axioms of equality.</p>

<p>For example the completion of the program above is:</p>
<dl>
<dd><code>canfly(X) iff bird(X), not abnormal(X).</code>
</dd>
<dd><code>abnormal(X) iff  wounded(X).</code>
</dd>
<dd><code> bird(X) iff X = john or X = mary.</code>
</dd>
<dd><code> X = X.</code>
</dd>
<dd><code> not john = mary.</code>
</dd>
<dd><code> not mary = john.</code>
</dd>
</dl>

<p>The notion of completion is closely related to McCarthy's <a href="Circumscription_(logic)" title="wikilink">circumscription</a> semantics for default reasoning, and to the <a href="closed_world_assumption" title="wikilink">closed world assumption</a>.</p>

<p>As an alternative to the completion semantics, negation as failure can also be interpreted epistemically, as in the <a href="stable_model_semantics" title="wikilink">stable model semantics</a> of <a href="answer_set_programming" title="wikilink">answer set programming</a>. In this interpretation not(B<sub>i</sub>) means literally that B<sub>i</sub> is not known or not believed. The epistemic interpretation has the advantage that it can be combined very simply with classical negation, as in "extended logic programming", to formalise such phrases as "the contrary can not be shown", where "contrary" is classical negation and "can not be shown" is the epistemic interpretation of negation as failure.</p>
<h3 id="knowledge-representation">Knowledge representation</h3>

<p>The fact that Horn clauses can be given a procedural interpretation and, vice versa, that goal-reduction procedures can be understood as Horn clauses + backward reasoning means that logic programs combine declarative and procedural representations of <a href="Knowledge_representation" title="wikilink">knowledge</a>. The inclusion of <a href="negation_as_failure" title="wikilink">negation as failure</a> means that logic programming is a kind of <a href="non-monotonic_logic" title="wikilink">non-monotonic logic</a>.</p>

<p>Despite its simplicity compared with classical logic, this combination of Horn clauses and negation as failure has proved to be surprisingly expressive. For example, it has been shown to correspond, with some further extensions, quite naturally to the semi-formal language of legislation. It is also a natural language for expressing common-sense laws of cause and effect, as in the <a href="situation_calculus" title="wikilink">situation calculus</a> and <a href="event_calculus" title="wikilink">event calculus</a>.</p>
<h2 id="variants-and-extensions">Variants and extensions</h2>
<h3 id="prolog">Prolog</h3>

<p>The programming language <a class="uri" href="Prolog" title="wikilink">Prolog</a> was developed in 1972 by <a href="Alain_Colmerauer" title="wikilink">Alain Colmerauer</a>. It emerged from a collaboration between Colmerauer in <a class="uri" href="Marseille" title="wikilink">Marseille</a> and <a href="Robert_Kowalski" title="wikilink">Robert Kowalski</a> in Edinburgh. Colmerauer was working on <a href="natural_language_understanding" title="wikilink">natural language understanding</a>, using logic to represent semantics and using resolution for question-answering. During the summer of 1971, Colmerauer and Kowalski discovered that the clausal form of logic could be used to represent formal grammars and that resolution theorem provers could be used for parsing. They observed that some theorem provers, like hyper-resolution, behave as bottom-up parsers and others, like <a href="SLD_resolution" title="wikilink">SL-resolution</a> (1971), behave as top-down parsers.</p>

<p>It was in the following summer of 1972, that Kowalski, again working with Colmerauer, developed the procedural interpretation of implications. This dual declarative/procedural interpretation later became formalised in the Prolog notation</p>
<dl>
<dd><code>H :- B<sub>1</sub>, …, B<sub>n</sub>.</code>
</dd>
</dl>

<p>which can be read (and used) both declaratively and procedurally. It also became clear that such clauses could be restricted to definite clauses or <a href="Horn_clause" title="wikilink">Horn clauses</a>, where <code>H</code>, <code>B<sub>1</sub></code>, …, <code>B<sub>n</sub></code> are all atomic predicate logic formulae, and that SL-resolution could be restricted (and generalised) to LUSH or <a href="SLD_resolution" title="wikilink">SLD-resolution</a>. Kowalski's procedural interpretation and LUSH were described in a 1973 memo, published in 1974.<a class="footnoteRef" href="#fn11" id="fnref11"><sup>11</sup></a></p>

<p>Colmerauer, with Philippe Roussel, used this dual interpretation of clauses as the basis of Prolog, which was implemented in the summer and autumn of 1972. The first Prolog program, also written in 1972 and implemented in Marseille, was a French question-answering system. The use of Prolog as a practical programming language was given great momentum by the development of a compiler by David Warren in Edinburgh in 1977. Experiments demonstrated that Edinburgh Prolog could compete with the processing speed of other symbolic programming languages such as <a href="Lisp_(programming_language)" title="wikilink">Lisp</a>. Edinburgh Prolog became the <em>de facto</em> standard and strongly influenced the definition of <a href="International_Organization_for_Standardization" title="wikilink">ISO</a> standard Prolog.</p>
<h3 id="abductive-logic-programming">Abductive logic programming</h3>

<p><a href="Abductive_logic_programming" title="wikilink">Abductive logic programming</a> is an extension of normal Logic Programming that allows some predicates, declared as abducible predicates, to be "open" or undefined. A clause in an abductive logic program has the form:</p>
<dl>
<dd><code>H :-  B<sub>1</sub>, …, B<sub>n</sub>, A<sub>1</sub>, …, A<sub>n</sub>.</code>
</dd>
</dl>

<p>where <code>H</code> is an atomic formula that is not abducible, all the <code>B<sub>i</sub></code> are literals whose predicates are not abducible, and the <code>A<sub>i</sub></code> are atomic formulas whose predicates are abducible. The abducible predicates can be constrained by integrity constraints, which can have the form:</p>
<dl>
<dd><code>false :-  B<sub>1</sub>, …, B<sub>n</sub>.</code>
</dd>
</dl>

<p>where the <code>B<sub>i</sub></code> are arbitrary literals (defined or abducible, and atomic or negated). For example:</p>
<dl>
<dd><code>canfly(X) :- bird(X), normal(X).</code>
</dd>
<dd><code>false :-  normal(X), wounded(X).</code>
</dd>
<dd><code> bird(john).</code>
</dd>
<dd><code> bird(mary).</code>
</dd>
<dd><code> wounded(john).</code>
</dd>
</dl>

<p>where the predicate <code>normal</code> is abducible.</p>

<p>Problem solving is achieved by deriving hypotheses expressed in terms of the abducible predicates as solutions of problems to be solved. These problems can be either observations that need to be explained (as in classical <a href="abductive_reasoning" title="wikilink">abductive reasoning</a>) or goals to be solved (as in normal logic programming). For example, the hypothesis <code>normal(mary)</code> explains the observation <code>canfly(mary)</code>. Moreover, the same hypothesis entails the only solution <code>X = mary</code> of the goal of finding something that can fly:</p>
<dl>
<dd><code>:- canfly(X).</code>
</dd>
</dl>

<p>Abductive logic programming has been used for fault diagnosis, planning, natural language processing and machine learning. It has also been used to interpret Negation as Failure as a form of abductive reasoning.</p>
<h3 id="metalogic-programming">Metalogic programming</h3>

<p>Because mathematical logic has a long tradition of distinguishing between <a href="object_language" title="wikilink">object language</a> and metalanguage, logic programming also allows <a href="metalevel_programming" title="wikilink">metalevel programming</a>. The simplest metalogic program is the so-called "<a href="Vanilla_(computing)" title="wikilink">vanilla</a>" meta-interpreter:</p>

<p><code>   solve(true).</code><br/>
<code>   solve((A,B)):- solve(A),solve(B).</code><br/>
<code>   solve(A):- clause(A,B),solve(B).</code></p>

<p>where true represents an empty conjunction, and clause(A,B) means there is an object-level clause of the form A :- B.</p>

<p>Metalogic programming allows object-level and metalevel representations to be combined, as in natural language. It can also be used to implement any logic that is specified by means of <a href="inference_rule" title="wikilink">inference rules</a>.</p>
<h3 id="constraint-logic-programming">Constraint logic programming</h3>

<p><a href="Constraint_logic_programming" title="wikilink">Constraint logic programming</a> combines Horn clause logic programming with <a href="constraint_solving" title="wikilink">constraint solving</a>. It extends Horn clauses by allowing some predicates, declared as constraint predicates, to occur as literals in the body of clauses. A constraint logic program is a set of clauses of the form:</p>
<dl>
<dd><code>H :- C<sub>1</sub>, …, C<sub>n</sub> <math>\Diamond </math> B<sub>1</sub>, …, B<sub>n</sub>.</code>
</dd>
</dl>

<p>where <code>H</code> and all the <code>B<sub>i</sub></code> are atomic formulas, and the <code>C<sub>i</sub></code> are constraints. Declaratively, such clauses are read as ordinary logical implications:</p>
<dl>
<dd><code>H if C<sub>1</sub> and … and C<sub>n</sub> and B<sub>1</sub> and … and B<sub>n</sub>.</code>
</dd>
</dl>

<p>However, whereas the predicates in the heads of clauses are defined by the constraint logic program, the predicates in the constraints are predefined by some domain-specific model-theoretic structure or theory.</p>

<p>Procedurally, subgoals whose predicates are defined by the program are solved by goal-reduction, as in ordinary logic programming, but constraints are checked for satisfiability by a domain-specific constraint-solver, which implements the semantics of the constraint predicates. An initial problem is solved by reducing it to a satisfiable conjunction of constraints.</p>

<p>The following constraint logic program represents a toy temporal database of <code>john's</code> history as a teacher:</p>
<dl>
<dd><code>teaches(john, hardware, T) :- 1990 ≤ T, T &lt; 1999.</code>
</dd>
<dd><code>teaches(john, software, T) :- 1999 ≤ T, T &lt; 2005.</code>
</dd>
<dd><code>teaches(john, logic, T) :- 2005 ≤ T, T ≤ 2012.</code>
</dd>
<dd><code>rank(john, instructor, T) :- 1990 ≤ T, T &lt; 2010.</code>
</dd>
<dd><code>rank(john, professor, T) :- 2010 ≤ T, T &lt; 2014.</code>
</dd>
</dl>

<p>Here <code>≤</code> and <tt> are constraint predicates, with their usual intended semantics. The following goal clause queries the database to find out when <code>john</code> both taught <code>logic</code> and was a <code>professor</code>:</tt></p>
<dl>
<dd><code>:- teaches(john, logic, T), rank(john, professor, T).</code>
</dd>
</dl>

<p>The solution is <code>2010 ≤ T, T ≤ 2012</code>.</p>

<p>Constraint logic programming has been used to solve problems in such fields as <a href="civil_engineering" title="wikilink">civil engineering</a>, <a href="mechanical_engineering" title="wikilink">mechanical engineering</a>, <a href="digital_circuit" title="wikilink">digital circuit</a> verification, <a href="automated_timetabling" title="wikilink">automated timetabling</a>, <a href="air_traffic_control" title="wikilink">air traffic control</a>, and finance. It is closely related to <a href="abductive_logic_programming" title="wikilink">abductive logic programming</a>.</p>
<h3 id="concurrent-logic-programming">Concurrent logic programming</h3>

<p>Concurrent logic programming integrates concepts of logic programming with <a href="concurrent_programming" title="wikilink">concurrent programming</a>. Its development was given a big impetus in the 1980s by its choice for the systems programming language of the <a href="Fifth_generation_computer" title="wikilink">Japanese Fifth Generation Project (FGCS)</a>.<a class="footnoteRef" href="#fn12" id="fnref12"><sup>12</sup></a></p>

<p>A concurrent logic program is a set of guarded <a href="Horn_clauses" title="wikilink">Horn clauses</a> of the form:</p>
<dl>
<dd><dl>
<dd><code>H :- G<sub>1</sub>, …, G<sub>n</sub> | B<sub>1</sub>, …, B<sub>n</sub>.</code>
</dd>
</dl>
</dd>
</dl>

<p>The conjunction <code>G<sub>1</sub>, … , G<sub>n</sub></code> is called the <a href="Guard_(computing)" title="wikilink">guard</a> of the clause, and <code>  | </code> is the commitment operator. Declaratively, guarded Horn clauses are read as ordinary logical implications:</p>
<dl>
<dd><dl>
<dd><code>H if G<sub>1</sub> and … and G<sub>n</sub> and B<sub>1</sub> and … and B<sub>n</sub>.</code>
</dd>
</dl>
</dd>
</dl>

<p>However, procedurally, when there are several clauses whose heads <code> H </code> match a given goal, then all of the clauses are executed in parallel, checking whether their guards <code>G<sub>1</sub>, … , G<sub>n</sub></code> hold. If the guards of more than one clause hold, then a committed choice is made to one of the clauses, and execution proceedes with the subgoals <code> B<sub>1</sub>, …, B<sub>n</sub></code> of the chosen clause. These subgoals can also be executed in parallel. Thus concurrent logic programming implements a form of "don't care nondeterminism", rather than "don't know nondeterminism".</p>

<p>For example, the following concurrent logic program defines a predicate <code> shuffle(Left, Right, Merge) </code>, which can be used to shuffle two lists <code>Left</code> and <code>Right</code>, combining them into a single list <code>Merge</code> that preserves the ordering of the two lists <code>Left</code> and <code>Right</code>:</p>
<dl>
<dd><code>shuffle([], [], []).</code>
</dd>
<dd><code>shuffle(Left, Right, Merge) :- Left = [First | Rest] | Merge = [First | ShortMerge], shuffle(Rest, Right, ShortMerge).</code>
</dd>
<dd><code>shuffle(Left, Right, Merge) :- Right = [First | Rest] | Merge = [First | ShortMerge], shuffle(Left, Rest, ShortMerge).</code>
</dd>
</dl>

<p>Here, <code>[]</code> represents the empty list, and <code>[Head | Tail]</code> represents a list with first element <code>Head</code> followed by list <code>Tail</code>, as in Prolog. (Notice that the first occurrence of <code>  | </code> in the second and third clauses is the list constructor, whereas the second occurrence of <code>  | </code> is the commitment operator.) The program can be used, for example, to shuffle the lists <code>[ace, queen, king]</code> and <code>[1, 4, 2]</code> by invoking the goal clause:</p>
<dl>
<dd><code>shuffle([ace, queen, king], [1, 4, 2], Merge).</code>
</dd>
</dl>

<p>The program will non-deterministically generate a single solution, for example <code> Merge = [ace, queen, 1, king, 4, 2]</code>.</p>

<p>Arguably, concurrent logic programming is based on message passing and consequently is subject to the same indeterminacy as other concurrent message-passing systems, such as <a href="Actor_model" title="wikilink">Actors</a> (see <a href="Indeterminacy_in_concurrent_computation" title="wikilink">Indeterminacy in concurrent computation</a>). Carl Hewitt  has argued that, concurrent logic programming is not based on logic in his sense that computational steps cannot be logically deduced [Hewitt and Agha, 1988]. However, in concurrent logic programming, any result of a terminating computation is a logical consequence of the program, and any partial result of a partial computation is a logical consequence of the program and the residual goal (process network). Consequently, the indeterminacy of computations implies that not all logical consequences of the program can be deduced.</p>
<h3 id="concurrent-constraint-logic-programming">Concurrent constraint logic programming</h3>

<p><a href="Concurrent_constraint_logic_programming" title="wikilink">Concurrent constraint logic programming</a> combines concurrent logic programming and <a href="constraint_logic_programming" title="wikilink">constraint logic programming</a>, using constraints to control concurrency. A clause can contain a guard, which is a set of constraints that may block the applicability of the clause. When the guards of several clauses are satisfied, concurrent constraint logic programming makes a committed choice to the use of only one.</p>
<h3 id="inductive-logic-programming">Inductive logic programming</h3>

<p>Inductive logic programming is concerned with generalizing positive and negative examples in the context of background knowledge: <a href="machine_learning" title="wikilink">machine learning</a> of logic programs. Recent work in this area, combining logic programming, learning and probability, has given rise to the new field of <a href="statistical_relational_learning" title="wikilink">statistical relational learning</a> and <a href="probabilistic_inductive_logic_programming" title="wikilink">probabilistic inductive logic programming</a>.</p>
<h3 id="higher-order-logic-programming">Higher-order logic programming</h3>

<p>Several researchers have extended logic programming with <a href="higher-order_programming" title="wikilink">higher-order programming</a> features derived from <a href="higher-order_logic" title="wikilink">higher-order logic</a>, such as predicate variables. Such languages include the Prolog extensions <a class="uri" href="HiLog" title="wikilink">HiLog</a> and <a class="uri" href="λProlog" title="wikilink">λProlog</a>.</p>
<h3 id="linear-logic-programming">Linear logic programming</h3>

<p>Basing logic programming within <a href="linear_logic" title="wikilink">linear logic</a> has resulted in the design of logic programming languages that are considerably more expressive than those based on classical logic. Horn clause programs can only represent state change by the change in arguments to predicates. In linear logic programming, one can use the ambient linear logic to support state change. Some early designs of logic programming languages based on linear logic include LO [Andreoli &amp; Pareschi, 1991], Lolli,<a class="footnoteRef" href="#fn13" id="fnref13"><sup>13</sup></a> ACL,<a class="footnoteRef" href="#fn14" id="fnref14"><sup>14</sup></a> and Forum [Miller, 1996]. Forum provides a goal-directed interpretation of all of linear logic.</p>
<h3 id="object-oriented-logic-programming">Object-oriented logic programming</h3>

<p><a class="uri" href="F-logic" title="wikilink">F-logic</a> extends logic programming with objects and the frame syntax. A number of systems are based on F-logic, including <a class="uri" href="Flora-2" title="wikilink">Flora-2</a>, <a href="http://dbis.informatik.uni-freiburg.de/index.php?project=Florid">FLORID</a>, and a highly scalable commercial system <a href="http://www.semafora-systems.com/en/products/ontobroker/">Ontobroker</a>.</p>
<h3 id="transaction-logic-programming">Transaction logic programming</h3>

<p><a href="Transaction_logic" title="wikilink">Transaction logic</a> is an extension of logic programming with a logical theory of state-modifying updates. It has both a model-theoretic semantics and a procedural one. An implementation of a subset of Transaction logic is available in the <a class="uri" href="Flora-2" title="wikilink">Flora-2</a> system. Other prototypes are also <a href="Transaction_logic" title="wikilink">available</a>.</p>
<h2 id="see-also">See also</h2>
<ul>
<li><a href="Boolean_satisfiability_problem" title="wikilink">Boolean satisfiability problem</a></li>
<li><a href="Constraint_logic_programming" title="wikilink">Constraint logic programming</a></li>
<li><a class="uri" href="Datalog" title="wikilink">Datalog</a></li>
<li><a href="Functional_programming" title="wikilink">Functional programming</a></li>
<li><a href="Inductive_logic_programming" title="wikilink">Inductive logic programming</a></li>
<li><a href="Fuzzy_logic" title="wikilink">Fuzzy logic</a></li>
<li><a href="Logic_in_computer_science" title="wikilink">Logic in computer science</a> (includes <a href="Formal_methods" title="wikilink">Formal methods</a>)</li>
<li><a href=":Category:Logic_programming_languages" title="wikilink">Logic programming languages</a></li>
<li><a href="Programming_paradigm" title="wikilink">Programming paradigm</a></li>
<li><a class="uri" href="R++" title="wikilink">R++</a></li>
<li><a href="Reasoning_system" title="wikilink">Reasoning system</a></li>
<li><a href="Relational_programming" title="wikilink">Relational programming</a></li>
<li><a class="uri" href="Satisfiability" title="wikilink">Satisfiability</a></li>
</ul>
<h2 id="references">References</h2>
<h3 id="general-introductions">General introductions</h3>
<ul>
<li></li>
<li>Robert Kowalski. <a href="http://www.doc.ic.ac.uk/~rak/papers/the%20early%20years.pdf"><strong>The Early Years of Logic Programming</strong></a> </li>
<li></li>
</ul>
<h3 id="other-sources">Other sources</h3>
<ul>
<li>John McCarthy. <strong>Programs with <a href="common_sense" title="wikilink">common sense</a></strong> Symposium on Mechanization of Thought Processes. National Physical Laboratory. Teddington, England. 1958.</li>
<li>D. Miller, G. Nadathur, F. Pfenning, A. Scedrov. <strong>Uniform proofs as a foundation for logic programming</strong>, Annals of Pure and Applied Logic, vol. 51, pp 125–157, 1991.</li>
<li>Ehud Shapiro (Editor). <strong>Concurrent Prolog</strong> MIT Press. 1987.</li>
<li>James Slagle. <strong>Experiments with a Deductive Question-Answering Program</strong> CACM. December 1965.</li>
</ul>
<h2 id="further-reading">Further reading</h2>
<ul>
<li>Carl Hewitt. <strong>Procedural Embedding of Knowledge In Planner</strong> IJCAI 1971.</li>
<li>Carl Hewitt. <strong><a href="http://aaaipress.org/Papers/Symposia/Spring/2006/SS-06-08/SS06-08-003.pdf">The repeated demise of logic programming and why it will be reincarnated</a></strong> What Went Wrong and Why: Lessons from AI Research and Applications. Technical Report SS-06-08. AAAI Press. March 2006.</li>
<li>Evgeny Dantsin, Thomas , Georg Gottlob, Andrei Voronkov: Complexity and expressive power of logic programming. ACM Comput. Surv. 33(3): 374-425 (2001)</li>
<li>Ulf Nilsson and Jan Maluszynski, <a href="http://www.ida.liu.se/~ulfni/lpp/">Logic, Programming and Prolog</a></li>
</ul>
<h2 id="external-links">External links</h2>
<ul>
<li><a href="http://vl.fmnet.info/logic-prog/"><em>Logic Programming</em> Virtual Library entry</a></li>
<li><a href="http://liinwww.ira.uka.de/bibliography/LogicProgramming/">Bibliographies on Logic Programming</a></li>
<li><a href="http://www.logicprogramming.org/">Association for Logic Programming (ALP)</a></li>
<li><a href="http://www.cs.kuleuven.be/~dtai/projects/ALP/TPLP/">Theory and Practice of Logic Programming</a> journal</li>
<li><a href="http://www.mpprogramming.com/Cpp/">Logic programming in C++ with Castor</a></li>
<li><a href="http://www.mozart-oz.org/documentation/tutorial/node12.html">Logic programming in</a> <a href="Oz_programming_language" title="wikilink">Oz</a></li>
<li><a href="http://www.pdc.dk/">Prolog Development Center</a></li>
<li><a href="http://docs.racket-lang.org/racklog/">Racklog: Logic Programming in Racket</a></li>
</ul>

<p>"</p>

<p><a href="Category:1972_introductions" title="wikilink">Category:1972 introductions</a> <a href="Category:Logic_programming" title="wikilink"> </a> <a href="Category:Programming_paradigms" title="wikilink">Category:Programming paradigms</a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1"><a href="#fnref1">↩</a></li>
<li id="fn2">Cordell Green. <strong>Application of Theorem Proving to Problem Solving</strong> IJCAI 1969.<a href="#fnref2">↩</a></li>
<li id="fn3">J.M. Foster and E.W. Elcock. ABSYS 1: An Incremental Compiler for Assertions: an Introduction, Machine Intelligence 4, Edinburgh U Press, 1969, pp. 423–429<a href="#fnref3">↩</a></li>
<li id="fn4">Carl Hewitt. <strong>Planner: A Language for Proving Theorems in Robots</strong> IJCAI 1969.<a href="#fnref4">↩</a></li>
<li id="fn5"></li>
<li id="fn6">Pat Hayes. Computation and Deduction. In Proceedings of the 2nd MFCS Symposium. Czechoslovak Academy of Sciences, 1973, pp. 105–118.<a href="#fnref6">↩</a></li>
<li id="fn7">Robert Kowalski <a href="http://www.doc.ic.ac.uk/~rak/papers/IFIP%2074.pdf"><strong>Predicate Logic as a Programming Language</strong></a> Memo 70, Department of Artificial Intelligence, Edinburgh University. 1973. Also in Proceedings IFIP Congress, Stockholm, North Holland Publishing Co., 1974, pp. 569–574.<a href="#fnref7">↩</a></li>
<li id="fn8">Robert Kowalski and Donald and Kuehner <a href="http://www.doc.ic.ac.uk/~rak/papers/sl.pdf"><strong>Linear Resolution with Selection Function</strong></a> Artificial Intelligence, Vol. 2, 1971, pp. 227–60.<a href="#fnref8">↩</a></li>
<li id="fn9"> Also appeared in <a href="#fnref9">↩</a></li>
<li id="fn10"><a href="#fnref10">↩</a></li>
<li id="fn11"></li>
<li id="fn12">Shunichi Uchida and Kazuhiro Fuchi <strong>Proceedings of the FGCS Project Evaluation Workshop</strong> Institute for New Generation Computer Technology (ICOT). 1992.<a href="#fnref12">↩</a></li>
<li id="fn13">Joshua Hodas and Dale Miller. <strong>Logic Programming in a Fragment of Intuitionistic Linear Logic</strong>, Information and Computation, 1994, 110(2), 327-365.<a href="#fnref13">↩</a></li>
<li id="fn14">Naoki Kobayashi and <a href="Akinori_Yonezawa" title="wikilink">Akinori Yonezawa</a>. <strong>Asynchronous communication model based on linear logic</strong>, Formal Aspects of Computing, 1994, 279-294.<a href="#fnref14">↩</a></li>
</ol>
</section>
</body>
</html>
