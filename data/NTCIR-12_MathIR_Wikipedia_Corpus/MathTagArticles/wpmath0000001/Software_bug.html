<html lang="en">
<head>
<meta charset="utf-8"/>
<title offset="1137">Software bug</title>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript">
</script>
</head>
<body>
<h1>Software bug</h1>
<hr/>

<p>A <strong>software bug</strong> is an error, flaw, <a class="uri" href="failure" title="wikilink">failure</a>, or <a href="fault_(technology)" title="wikilink">fault</a> in a computer program or <a href="software_system" title="wikilink">system</a> that causes it to produce an incorrect or unexpected result, or to behave in unintended ways. Most bugs arise from mistakes and errors made by people in either a program's <a href="source_code" title="wikilink">source code</a> or its <a href="software_architecture" title="wikilink">design</a>, or in frameworks and operating systems used by such programs, and a few are caused by <a href="compiler" title="wikilink">compilers</a> producing incorrect code. A program that contains a large number of bugs, and/or bugs that seriously interfere with its functionality, is said to be <em>buggy</em>. Reports detailing bugs in a program are commonly known as bug reports, defect reports, fault reports, problem reports, trouble reports, change requests, and so forth.</p>

<p>Bugs trigger errors that can in turn have a wide variety of <a href="ripple_effect" title="wikilink">ripple effects</a>, with varying levels of inconvenience to the user of the program. Some bugs have only a subtle effect on the program's functionality, and may thus lie undetected for a long time. More serious bugs may cause the program to <a href="crash_(computing)" title="wikilink">crash</a> or <a href="freeze_(computing)" title="wikilink">freeze</a>. Others qualify as <a href="security_bugs" title="wikilink">security bugs</a> and might for example enable a <a href="Black_hat_hacking" title="wikilink">malicious user</a> to bypass <a href="access_controls" title="wikilink">access controls</a> in order to <a href="Privilege_escalation" title="wikilink">obtain unauthorized privileges</a>.</p>

<p>The results of bugs may be extremely serious. Bugs in the code controlling the <a class="uri" href="Therac-25" title="wikilink">Therac-25</a> <a href="radiation_therapy" title="wikilink">radiation therapy</a> machine were directly responsible for some patient deaths in the 1980s. In 1996, the <a href="European_Space_Agency" title="wikilink">European Space Agency</a>'s US$1 billion <a href="Cluster_(spacecraft)#Launch_failure" title="wikilink">prototype</a> <a href="Ariane_5" title="wikilink">Ariane 5</a> rocket had to be destroyed less than a minute after launch, due to a bug in the on-board guidance computer program. In June 1994, a Royal Air Force <a href="CH-47_Chinook" title="wikilink">Chinook</a> helicopter <a href="1994_Scotland_RAF_Chinook_crash" title="wikilink">crashed</a> into the <a href="Mull_of_Kintyre" title="wikilink">Mull of Kintyre</a>, killing 29. This was initially dismissed as pilot error, but an investigation by <em><a href="Computer_Weekly" title="wikilink">Computer Weekly</a></em> uncovered sufficient evidence to convince a <a href="House_of_Lords" title="wikilink">House of Lords</a> inquiry that it may have been caused by a software bug in the aircraft's <a href="FADEC" title="wikilink">engine control computer</a>.<a class="footnoteRef" href="#fn1" id="fnref1"><sup>1</sup></a></p>

<p>In 2002, a study commissioned by the US <a href="Department_of_Commerce" title="wikilink">Department of Commerce</a>' <a href="National_Institute_of_Standards_and_Technology" title="wikilink">National Institute of Standards and Technology</a> concluded that "software bugs, or errors, are so prevalent and so detrimental that they cost the US economy an estimated $59 billion annually, or about 0.6 percent of the gross domestic product".<a class="footnoteRef" href="#fn2" id="fnref2"><sup>2</sup></a></p>
<h2 id="etymology">Etymology</h2>

<p>Use of the term "bug" to describe inexplicable defects has been a part of engineering jargon for many decades and predates computers and computer software; it may have originally been used in hardware engineering to describe mechanical malfunctions. For instance, <a href="Thomas_Edison" title="wikilink">Thomas Edison</a> wrote the following words in a letter to an associate in 1878:</p>

<p><mtpl></mtpl></p>

<p>The Middle English word <em>bugge</em> is the basis for the terms "bugbear" and "bugaboo", terms used for a monster.<a class="footnoteRef" href="#fn3" id="fnref3"><sup>3</sup></a> <a href="Baffle_Ball" title="wikilink">Baffle Ball</a>, the first mechanical <a class="uri" href="pinball" title="wikilink">pinball</a> game, was advertised as being "free of bugs" in 1931.<a class="footnoteRef" href="#fn4" id="fnref4"><sup>4</sup></a> Problems with military gear during <a href="World_War_II" title="wikilink">World War II</a> were referred to as <em>bug</em>s (or <a href="glitch" title="wikilink">glitches</a>).<a class="footnoteRef" href="#fn5" id="fnref5"><sup>5</sup></a></p>

<p> The term "bug" was used in an account by computer pioneer <a href="Grace_Hopper" title="wikilink">Grace Hopper</a>, who publicized the cause of a malfunction in an early electromechanical computer.<a class="footnoteRef" href="#fn6" id="fnref6"><sup>6</sup></a> A typical version of the story is given by this quote:<a class="footnoteRef" href="#fn7" id="fnref7"><sup>7</sup></a> </p>

<p>Hopper was not actually the one who found the insect, as she readily acknowledged. The date in the log book was September 9, 1947,<a class="footnoteRef" href="#fn8" id="fnref8"><sup>8</sup></a><a class="footnoteRef" href="#fn9" id="fnref9"><sup>9</sup></a> although sometimes erroneously reported as 1945.<a class="footnoteRef" href="#fn10" id="fnref10"><sup>10</sup></a> The operators who did find it, including William "Bill" Burke, later of the <a href="Naval_Surface_Warfare_Center_Dahlgren_Division" title="wikilink">Naval Weapons Laboratory</a>, <a href="Dahlgren,_Virginia" title="wikilink">Dahlgren, Virginia</a>,<a class="footnoteRef" href="#fn11" id="fnref11"><sup>11</sup></a> were familiar with the engineering term and, amused, kept the insect with the notation "First actual case of bug being found." Hopper loved to recount the story.<a class="footnoteRef" href="#fn12" id="fnref12"><sup>12</sup></a> This log book, complete with attached moth, is part of the collection of the Smithsonian <a href="National_Museum_of_American_History" title="wikilink">National Museum of American History</a>, though it is not currently on display.<a class="footnoteRef" href="#fn13" id="fnref13"><sup>13</sup></a></p>

<p>The related term "<a class="uri" href="debug" title="wikilink">debug</a>" also appears to predate its usage in computing: the <a href="Oxford_English_Dictionary" title="wikilink">Oxford English Dictionary</a>'s etymology of the word contains an attestation from 1945, in the context of aircraft engines.<a class="footnoteRef" href="#fn14" id="fnref14"><sup>14</sup></a></p>
<h2 id="prevalence">Prevalence</h2>

<p>In software development projects, a "mistake" or "fault" can be introduced at any stage during development. Bugs are a consequence of the nature of <a href="human_factor" title="wikilink">human factors</a> in the programming task. They arise from oversights or mutual misunderstandings made by a software team during specification, design, coding, data entry and documentation. For example, in creating a relatively simple program to sort a list of words into alphabetical order, one's design might fail to consider what should happen when a word contains a <a class="uri" href="hyphen" title="wikilink">hyphen</a>. Perhaps, when converting the abstract design into the chosen programming language, one might inadvertently create an <a href="off-by-one_error" title="wikilink">off-by-one error</a> and fail to sort the last word in the list. Finally, when typing the resulting program into the computer, one might accidentally type a "" was intended, perhaps resulting in the words being sorted into reverse alphabetical order.</p>

<p>Another category of bug is called a <em><a href="race_condition" title="wikilink">race condition</a></em> that can occur when programs have multiple components executing at the same time, either on the same system or across multiple systems interacting across a network. If the components interact in a different order than the developers intended, it may break the logical flow of the program. These bugs can be difficult to detect or anticipate, since they may not occur during every execution of a program.</p>

<p>More complex bugs can arise from unintended interactions between different parts of a computer program. This frequently occurs because computer programs can be complex — millions of lines long in some cases — often having been programmed by many people over a great length of time, so that programmers are unable to mentally track every possible way in which parts can interact.</p>
<h2 id="mistake-metamorphism">Mistake metamorphism</h2>

<p>There is ongoing debate over the use of the term "bug" to describe software errors.<a class="footnoteRef" href="#fn15" id="fnref15"><sup>15</sup></a> One argument is that the word "bug" is divorced from a sense that a human being caused the problem, and instead implies that the defect arose on its own, leading to a push to abandon the term "bug" in favor of terms such as "defect", with limited success.</p>

<p>In software engineering, <em>mistake metamorphism</em> (from Greek <em>meta</em> = "change", <em>morph</em> = "form") refers to the evolution of a defect in the final stage of software deployment.  Transformation of a "mistake" committed by an analyst in the early stages of the software development lifecycle, which leads to a "defect" in the final stage of the cycle has been called 'mistake metamorphism'.<a class="footnoteRef" href="#fn16" id="fnref16"><sup>16</sup></a></p>

<p>Different stages of a "mistake" in the entire cycle may be described by using the following terms:<a class="footnoteRef" href="#fn17" id="fnref17"><sup>17</sup></a></p>
<ul>
<li>Mistake</li>
<li>Anomaly</li>
<li>Fault</li>
<li>Failure</li>
<li>Error</li>
<li>Exception</li>
<li>Crash</li>
<li>Bug</li>
<li>Defect</li>
<li>Incident</li>
<li>Side Effect</li>
</ul>
<h2 id="prevention">Prevention</h2>

<p>The software industry has put much effort into finding methods for preventing programmers from inadvertently introducing bugs while writing software.<a class="footnoteRef" href="#fn18" id="fnref18"><sup>18</sup></a><a class="footnoteRef" href="#fn19" id="fnref19"><sup>19</sup></a> These include:</p>
<dl>
<dt>Programming style: While <a class="uri" href="typos" title="wikilink">typos</a> in the program code are often caught by the compiler, a bug usually appears when the programmer makes a <a href="logic_error" title="wikilink">logic error</a>. Various innovations in <a href="programming_style" title="wikilink">programming style</a> and <a href="defensive_programming" title="wikilink">defensive programming</a> are designed to make these bugs less likely, or easier to spot. In some programming languages, so-called typos, especially of symbols or logical/<a href="Operator_(mathematics)" title="wikilink">mathematical operators</a>, actually represent logic errors, since the mistyped constructs are accepted by the compiler with a meaning other than that which the programmer intended.</dt>
</dl>
<dl>
<dt>Programming techniques: Bugs often create inconsistencies in the internal data of a running program. Programs can be written to <a href="Assertion_(programming)" title="wikilink">check</a> the consistency of their own internal data while running. If an inconsistency is encountered, the program can immediately halt, so that the bug can be located and fixed. Alternatively, the program can simply inform the user, attempt to correct the inconsistency, and continue running.</dt>
</dl>
<dl>
<dt>Development methodologies: There are several schemes for managing programmer activity, so that fewer bugs are produced. Many of these fall under the discipline of <a href="software_engineering" title="wikilink">software engineering</a> (which addresses software design issues as well). For example, formal <a href="program_specification" title="wikilink">program specifications</a> are used to state the exact behavior of programs, so that design bugs can be eliminated. Unfortunately, formal specifications are impractical or impossible for anything but the shortest programs, because of problems of <a href="combinatorial_explosion" title="wikilink">combinatorial explosion</a> and <a href="Nondeterministic_algorithm" title="wikilink">indeterminacy</a>.</dt>
<dd>In modern times, popular approaches include <a href="Automated_testing" title="wikilink">automated</a> <a href="unit_testing" title="wikilink">unit testing</a> and automated <a href="acceptance_testing" title="wikilink">acceptance testing</a> (sometimes going to the extreme of <a href="test-driven_development" title="wikilink">test-driven development</a>), and <a href="agile_software_development" title="wikilink">agile software development</a> (which is often <a href="Scrum_(software_development)" title="wikilink">combined with</a>, or even in some cases <a href="extreme_programming" title="wikilink">mandates</a>, automated testing). All of these approaches are supposed to catch bugs and poorly-specified <a class="uri" href="requirements" title="wikilink">requirements</a> soon after they are introduced, which should make them easier and cheaper to fix, and to catch at least some of them before they enter into production use.
</dd>
</dl>
<dl>
<dt>Programming language support: <a href="Programming_language" title="wikilink">Programming languages</a> often include features which help programmers prevent bugs, such as static <a href="type_system" title="wikilink">type systems</a>, restricted <a href="namespace" title="wikilink">namespaces</a> and <a href="modular_programming" title="wikilink">modular programming</a>, among others. For example, when a programmer writes (pseudocode) <code>LET REAL_VALUE PI = "THREE AND A BIT"</code>, although this may be syntactically correct, the code fails a <a href="Type_checking" title="wikilink">type check</a>. Depending on the language and implementation, this may be caught by the <a class="uri" href="compiler" title="wikilink">compiler</a> or at <a href="Run_time_(program_lifecycle_phase)" title="wikilink">run-time</a>. In addition, many recently invented languages have deliberately excluded features which can easily lead to bugs, at the expense of making code slower than it need be: the general principle being that, because of <a href="Moore's_law" title="wikilink">Moore's law</a>, computers get faster and software engineers get slower; it is <em>almost always</em> better to write simpler, slower code than "clever", inscrutable code, especially considering that <a href="maintenance_cost" title="wikilink">maintenance cost</a> is substantial. For example, the <a href="Java_(programming_language)" title="wikilink">Java programming language</a> does not support <a href="pointer_(computer_programming)" title="wikilink">pointer</a> arithmetic; implementations of some languages such as <a href="Pascal_(programming_language)" title="wikilink">Pascal</a> and <a href="scripting_language" title="wikilink">scripting languages</a> often have runtime <a href="bounds_checking" title="wikilink">bounds checking</a> of arrays, at least in a debugging build.</dt>
</dl>
<dl>
<dt>Code analysis: Tools for <a href="Static_code_analysis" title="wikilink">code analysis</a> help developers by inspecting the program text beyond the compiler's capabilities to spot potential problems. Although in general the problem of finding all programming errors given a specification is not solvable (see <a href="halting_problem" title="wikilink">halting problem</a>), these tools exploit the fact that human programmers tend to make the same kinds of mistakes when writing software.</dt>
</dl>
<dl>
<dt><a class="uri" href="Instrumentation" title="wikilink">Instrumentation</a>: Tools to monitor the performance of the software as it is running, either specifically to find problems such as <a href="Bottleneck_(engineering)" title="wikilink">bottlenecks</a> or to give assurance as to correct working, may be embedded in the code explicitly (perhaps as simple as a statement saying <code>PRINT "I AM HERE"</code>), or provided as tools. It is often a surprise to find where most of the time is taken by a piece of code, and this removal of assumptions might cause the code to be rewritten.</dt>
</dl>
<h2 id="debugging">Debugging</h2>

<p> </p>

<p>Finding and fixing bugs, or "debugging", has always been a major part of <a href="computer_programming" title="wikilink">computer programming</a>. <a href="Maurice_Wilkes" title="wikilink">Maurice Wilkes</a>, an early computing pioneer, described his realization in the late 1940s that much of the rest of his life would be spent finding mistakes in his own programs.<a class="footnoteRef" href="#fn20" id="fnref20"><sup>20</sup></a> As computer programs grow more complex, bugs become more common and difficult to fix. Often programmers spend more time and effort finding and fixing bugs than writing new code. <a href="Software_tester" title="wikilink">Software testers</a> are professionals whose primary task is to find bugs, or write code to support testing. On some projects, more resources can be spent on testing than in developing the program.</p>

<p>Usually, the most difficult part of debugging is finding the bug in the <a href="source_code" title="wikilink">source code</a>. Once it is found, correcting it is usually relatively easy. Programs known as <a href="debugger" title="wikilink">debuggers</a> exist to help programmers locate bugs by executing code line by line, watching variable values, and other features to observe program behavior. Without a debugger, code can be added so that messages or values can be written to a console (for example with <em>printf</em> in the <a href="C_programming_language" title="wikilink">C programming language</a>) or to a window or log file to trace program execution or show values.</p>

<p>However, even with the aid of a debugger, locating bugs is something of an art. It is not uncommon for a bug in one section of a program to cause failures in a completely different section, thus making it especially difficult to track (for example, an error in a graphics <a href="Rendering_(computer_graphics)" title="wikilink">rendering</a> routine causing a file <a href="Input/output" title="wikilink">I/O</a> routine to fail), in an apparently unrelated part of the system.</p>

<p>Sometimes, a bug is not an isolated flaw, but represents an error of thinking or planning on the part of the programmer. Such <em><a href="logic_error" title="wikilink">logic errors</a></em> require a section of the program to be overhauled or rewritten. As a part of <a href="Code_review" title="wikilink">Code review</a>, stepping through the code modelling the execution process in one's head or on paper can often find these errors without ever needing to reproduce the bug as such, if it can be shown there is some faulty logic in its implementation.</p>

<p>But more typically, the first step in locating a bug is to reproduce it reliably. Once the bug is reproduced, the programmer can use a debugger or some other tool to monitor the execution of the program in the faulty region, and find the point at which the program went astray.</p>

<p>It is not always easy to reproduce bugs. Some are triggered by inputs to the program which may be difficult for the programmer to re-create. One cause of the <a class="uri" href="Therac-25" title="wikilink">Therac-25</a> radiation machine deaths was a bug (specifically, a <a href="race_condition" title="wikilink">race condition</a>) that occurred only when the machine operator very rapidly entered a treatment plan; it took days of practice to become able to do this, so the bug did not manifest in testing or when the manufacturer attempted to duplicate it. Other bugs may disappear when the program is run with a debugger; these are <a href="heisenbug" title="wikilink">heisenbugs</a> (humorously named after the <a href="uncertainty_principle" title="wikilink">Heisenberg uncertainty principle</a>).</p>

<p>Debugging is still a tedious task requiring considerable effort. Since the 1990s, particularly following the <a href="Ariane_5_Flight_501" title="wikilink">Ariane 5 Flight 501</a> disaster, there has been a renewed interest in the development of effective automated aids to debugging. For instance, methods of <a href="static_code_analysis" title="wikilink">static code analysis</a> by <a href="abstract_interpretation" title="wikilink">abstract interpretation</a> have already made significant achievements, while still remaining much of a work in progress.</p>

<p>As with any creative act, sometimes a flash of inspiration will show a solution, but this is rare and, by definition, cannot be relied on.</p>

<p>There are also classes of bugs that have nothing to do with the code itself. If, for example, one relies on faulty documentation or hardware, the code may be written perfectly properly to what the documentation says, but the bug truly lies in the documentation or hardware, not the code. However, it is common to change the code instead of the other parts of the system, as the cost and time to change it is generally less. <a href="Embedded_system" title="wikilink">Embedded systems</a> frequently have <a href="workaround" title="wikilink">workarounds</a> for hardware bugs, since to make a new version of a <a href="Read-only_memory" title="wikilink">ROM</a> is much cheaper than remanufacturing the hardware, especially if they are <a href="commodity_items" title="wikilink">commodity items</a>.</p>
<h2 id="bug-management">Bug management</h2>

<p>Bug management encompasses more than bug tracking, and there exists no industry-wide standard. Proposed changes to software – bugs as well as enhancement requests and even entire releases – are commonly tracked and managed using <a href="bug_tracking_system" title="wikilink">bug tracking systems</a> or <a href="issue_tracking_system" title="wikilink">issue tracking systems</a>. The items added may be called defects, tickets, issues, or, following the <a href="agile_development" title="wikilink">agile development</a> paradigm, stories and epics. The systems allow or even require some type of categorization of each issue. Categories may be objective, subjective or a combination, such as <a href="version_number" title="wikilink">version number</a>, area of the software, severity and priority, as well as what type of issue it is, such as a feature request or a bug.</p>
<h3 id="severity-of-a-bug">Severity of a Bug</h3>

<p>Given a bug is impairing an user scenario, one can easily see the impact the bug has. This impact can be tangible as tangible as of data loss, immediate losses in terms of money, or can be indirect - loss of goodwill or man hours, and eventual business. This impact is said to be the severity of a bug : "the impact a bug causes when encountered by users". Thus, severity, as a <a href="Software_metric" title="wikilink">Software metric</a> does have a very precise meaning. Unfortunately, Severity levels are not standardised in industry and are decided by each software producer, if they are even used. This is because impacts differ across the industry. A crash in a video game has a totally different impact than a crash in the browser, or real time monitoring system. Irrespective of that, crashes would be generally categorised high severity in the respective fields. For example, bug severity levels might be "crash or hang", "no workaround" (meaning there is no way the customer can accomplish a given task), "has workaround" (meaning there is a way for the user to recover and accomplish the task), "UI" or "visual defect" (for example, a missing image or displaced button or form element), or "documentation error". Some software publishers use more qualified severities such as "critical", "high", "low," "blocker," or "trivial".<a class="footnoteRef" href="#fn21" id="fnref21"><sup>21</sup></a> The severity of a bug may be a separate category to its priority for fixing, and the two may be quantified and managed separately.</p>
<h3 id="priority-of-a-bug">Priority of a Bug</h3>

<p>Given a bug, how fast it needs to get fixed is defined by the <a href="Software_metric" title="wikilink">Software metric</a> Priority. How the priority for fixing is used is decided internally by each software producer. Priorities are sometimes numerical and sometimes words, such "critical," "high," "low" or "deferred"; note that these can be similar or even identical to severity ratings when looking at different software producers. For example, a software company may decide that priority 1 bugs are always to be fixed for the next release, whereas "5" could mean its fix is put off – sometimes indefinitely.</p>
<h3 id="connection-between-priority-and-severity">Connection between Priority and Severity</h3>

<p>If a flaw is found in an application which causes it to crash, yet the crash is so rare and takes, say, ten extremely unusual or unlikely steps to produce it, management may set its priority as "low" or even "will not fix." Thus it is easily seen that Priority is a function of probability of a bug to occur, and Severity (impact) of the bug. In specificity, Priority is an strictly increasing function of both probability of the bug occurrence and severity. Given probability p = 1, the severity defines the priority. When p = 0, the bug, in all probability needs not to be fixed at all, however we can have a priority strictly proportional to the severity. In the same way, when Severity S=0 for a bug, we can have a priority strictly proportional to the probability.</p>

<p>One can axiomatise the Priority function as any function having above characteristics, for example this very simplified function works 

<math display="block" id="Software_bug:0">
 <semantics>
  <mrow>
   <mrow>
    <mi>P</mi>
    <mrow>
     <mo stretchy="false">(</mo>
     <mi>p</mi>
     <mo>,</mo>
     <mi>s</mi>
     <mo stretchy="false">)</mo>
    </mrow>
   </mrow>
   <mo>=</mo>
   <mrow>
    <mi>B</mi>
    <mo>-</mo>
    <mrow>
     <mo stretchy="false">⌈</mo>
     <mrow>
      <mi>k</mi>
      <mi>p</mi>
      <mi>S</mi>
     </mrow>
     <mo stretchy="false">⌉</mo>
    </mrow>
   </mrow>
  </mrow>
  <annotation-xml encoding="MathML-Content">
   <apply>
    <eq></eq>
    <apply>
     <times></times>
     <ci>P</ci>
     <interval closure="open">
      <ci>p</ci>
      <ci>s</ci>
     </interval>
    </apply>
    <apply>
     <minus></minus>
     <ci>B</ci>
     <apply>
      <ceiling></ceiling>
      <apply>
       <times></times>
       <ci>k</ci>
       <ci>p</ci>
       <ci>S</ci>
      </apply>
     </apply>
    </apply>
   </apply>
  </annotation-xml>
  <annotation encoding="application/x-tex">
   P(p,s)=B-\lceil kpS\rceil
  </annotation>
 </semantics>
</math>

 where p is the probability while S is the severity, with k a scaling constant, and to invert the value B is the base. The <a href="Floor_and_ceiling_functions" title="wikilink">ceiling function</a> is used to get the domain of priority to only integers. It also assigns priority-B to <a href="almost_never" title="wikilink">almost never</a> occurring bugs. Industry standard practice is to use an inverted scale, so that highest priority are low numbers, example priority 0, priority 1, while lowest priority are bigger numbers, i.e. priority 3, priority 4... etc.</p>
<h3 id="software-releases">Software Releases</h3>

<p>It is common practice for software to be released with known bugs that are considered "non-critical" as defined by the software producer(s). While software products may, by definition, contain any number of unknown bugs, measurements during testing can provide an estimate of the number of likely bugs remaining; this becomes more reliable the longer a product is tested and developed. Most big software projects maintain two lists of "known bugs"— those known to the software team, and those to be told to users. The second list informs users about bugs that are not fixed in the current release, or not fixed at all, and a <a class="uri" href="workaround" title="wikilink">workaround</a> may be offered.</p>

<p>A software publisher may opt not to fix a particular bug for a number of reasons, including:</p>
<ul>
<li>A deadline must be met and priorities are such that all but those above a certain severity are fixed for the current software release.</li>
<li>The bug is already fixed in an upcoming release, and it is not serious enough to warrant an immediate update or <a href="Patch_(computing)" title="wikilink">patch</a></li>
<li>The changes to the code required to fix the bug are too costly, will take too long for the current release, or affect too many other areas of the software.</li>
<li>Users may be relying on the undocumented, buggy behavior; it may introduce a <a href="wiktionary:breaking_change" title="wikilink">breaking change</a>.</li>
<li>The problem is in an area which will be obsolete with an upcoming release; fixing it is unnecessary.</li>
<li>It's "not a bug". A misunderstanding has arisen between expected and perceived behavior, when such misunderstanding is not due to confusion arising from design flaws, or faulty documentation.</li>
</ul>

<p>The amount and type of damage a software bug can cause naturally affects decision-making, processes and policy regarding software quality. In applications such as <a href="Human_spaceflight" title="wikilink">manned space travel</a> or <a href="automotive_safety" title="wikilink">automotive safety</a>, since software flaws have the potential to cause human injury or even death, such software will have far more scrutiny and quality control than, for example, an online shopping website. In applications such as banking, where software flaws have the potential to cause serious financial damage to a bank or its customers, quality control is also more important than, say, a photo editing application. NASA's <a href="Software_Assurance_Technology_Center" title="wikilink">SATC</a> managed to reduce the number of errors to fewer than 0.1 per 1000 lines of code (<a href="Source_lines_of_code" title="wikilink">SLOC</a>) but this was not felt to be feasible for projects in the business world.</p>

<p>A school of thought popularized by <a href="Eric_S._Raymond" title="wikilink">Eric S. Raymond</a> as <a href="Linus's_Law" title="wikilink">Linus's Law</a> says that popular <a href="open-source_software" title="wikilink">open-source software</a> has more chance of having few or no bugs than other software, because "given enough eyeballs, all bugs are shallow".<a class="footnoteRef" href="#fn22" id="fnref22"><sup>22</sup></a> This assertion has been disputed, however: computer security specialist <a href="Elias_Levy" title="wikilink">Elias Levy</a> wrote that "it is easy to hide vulnerabilities in complex, little understood and undocumented source code," because, "even if people are reviewing the code, that doesn't mean they're qualified to do so."<a class="footnoteRef" href="#fn23" id="fnref23"><sup>23</sup></a></p>
<h2 id="security-vulnerabilities">Security vulnerabilities</h2>

<p><a href="Malware" title="wikilink">Malicious software</a> may attempt to exploit known vulnerabilities in a system–which may or may not be bugs. Viruses are not bugs in themselves–they are typically programs that are doing precisely what they were designed to do. However, viruses are occasionally referred to as such in the popular press. In addition, it is often a security bug in a computer program that allows viruses to work in the first place.</p>
<h2 id="common-types-of-computer-bugs">Common types of computer bugs</h2>
<ul>
<li>Conceptual error (code is syntactically correct, but the programmer or designer intended it to do something else).</li>
</ul>
<h3 id="arithmetic-bugs">Arithmetic bugs</h3>
<ul>
<li><a href="Division_by_zero#In_computer_arithmetic" title="wikilink">Division by zero</a>.</li>
<li><a href="Arithmetic_overflow" title="wikilink">Arithmetic overflow</a> or <a href="Arithmetic_underflow" title="wikilink">underflow</a>.</li>
<li>Loss of <a href="arithmetic_precision" title="wikilink">arithmetic precision</a> due to <a class="uri" href="rounding" title="wikilink">rounding</a> or <a href="numerical_stability" title="wikilink">numerically unstable</a> algorithms.</li>
</ul>
<h3 id="logic-bugs">Logic bugs</h3>
<ul>
<li><a href="Infinite_loop" title="wikilink">Infinite loops</a> and infinite <a href="Recursion_(computer_science)" title="wikilink">recursion</a>.</li>
<li><a href="Off-by-one_error" title="wikilink">Off-by-one error</a>, counting one too many or too few when looping.</li>
</ul>
<h3 id="syntax-bugs">Syntax bugs</h3>
<ul>
<li>Use of the wrong operator, such as performing assignment instead of <a href="==#Equality" title="wikilink">equality test</a>. For example, in some languages x=5 will set the value of x to 5 while x==5 will check whether x is currently 5 or some other number. In simple cases often the compiler can generate a warning. In many languages, the language syntax is deliberately designed to guard against this error.</li>
</ul>
<h3 id="resource-bugs">Resource bugs</h3>
<ul>
<li><a href="Null_pointer" title="wikilink">Null pointer</a> dereference.</li>
<li>Using an <a href="uninitialized_variable" title="wikilink">uninitialized variable</a>.</li>
<li>Using an otherwise valid instruction on the wrong <a href="data_type" title="wikilink">data type</a> (see <a href="packed_decimal" title="wikilink">packed decimal</a>/<a href="binary_coded_decimal" title="wikilink">binary coded decimal</a>).</li>
<li><a href="Access_violation" title="wikilink">Access violations</a>.</li>
<li>Resource leaks, where a finite system resource (such as <a href="memory_leak" title="wikilink">memory</a> or <a href="handle_leak" title="wikilink">file handles</a>) become exhausted by repeated allocation without release.</li>
<li><a href="Buffer_overflow" title="wikilink">Buffer overflow</a>, in which a program tries to store data past the end of allocated storage. This may or may not lead to an access violation or <a href="storage_violation" title="wikilink">storage violation</a>. These bugs can form a <a href="Software_bug#Security_vulnerabilities" title="wikilink">security vulnerability</a>.</li>
<li>Excessive recursion which — though logically valid — causes <a href="stack_overflow" title="wikilink">stack overflow</a>.</li>
<li>Use-after-free error, where a <a href="Pointer_(computer_programming)" title="wikilink">pointer</a> is used after the system has freed the memory it references.</li>
<li>Double free error.</li>
</ul>
<h3 id="multi-threading-programming-bugs">Multi-threading programming bugs</h3>
<ul>
<li><a class="uri" href="Deadlock" title="wikilink">Deadlock</a>, where task A can't continue until task B finishes, but at the same time, task B can't continue until task A finishes.</li>
<li><a href="Race_condition" title="wikilink">Race condition</a>, where the computer does not perform tasks in the order the programmer intended.</li>
<li>Concurrency errors in <a href="critical_section" title="wikilink">critical sections</a>, <a href="mutual_exclusion" title="wikilink">mutual exclusions</a> and other features of <a href="Concurrent_programming#Coordinating_access_to_resources" title="wikilink">concurrent processing</a>. <a class="uri" href="Time-of-check-to-time-of-use" title="wikilink">Time-of-check-to-time-of-use</a> (TOCTOU) is a form of unprotected critical section.</li>
</ul>
<h3 id="interfacing-bugs">Interfacing bugs</h3>
<ul>
<li>Incorrect API usage.</li>
<li>Incorrect protocol implementation.</li>
<li>Incorrect hardware handling.</li>
<li>Incorrect assumptions of a particular platform.</li>
<li>Incompatible systems. Often a proposed "new <a class="uri" href="API" title="wikilink">API</a>" or new <a href="communications_protocol" title="wikilink">communications protocol</a> may seem to work when both computers use the old version or both computers use the new version, but upgrading only the receiver exposes <a href="backward_compatibility" title="wikilink">backward compatibility</a> problems; in other cases upgrading only the transmitter exposes <a href="forward_compatibility" title="wikilink">forward compatibility</a> problems. Often it is not feasible to upgrade every computer simultaneously—in particular, in the telecommunication industry<ref></ref></li>
</ul>

<p>K. Kimbler. <a href="https://books.google.com/books?id=q7BSGKJrWxsC">"Feature Interactions in Telecommunications and Software Systems V"</a> p. 8.  or the internet.<a class="footnoteRef" href="#fn24" id="fnref24"><sup>24</sup></a><a class="footnoteRef" href="#fn25" id="fnref25"><sup>25</sup></a><a class="footnoteRef" href="#fn26" id="fnref26"><sup>26</sup></a> Even when it is feasible to update every computer simultaneously, sometimes people accidentally forget to update every computer—the <a href="Knight_Capital_Group#2012_stock_trading_disruption" title="wikilink">Knight Capital Group#2012 stock trading disruption</a> involved one such incompatibility between the old API and a new API.</p>
<h3 id="performance-bugs">Performance bugs</h3>
<ul>
<li>Too high <a href="Analysis_of_algorithms" title="wikilink">computational complexity</a> of algorithm.</li>
<li>Random disk or memory access.</li>
</ul>
<h3 id="teamworking-bugs">Teamworking bugs</h3>
<ul>
<li>Unpropagated updates; e.g. programmer changes "myAdd" but forgets to change "mySubtract", which uses the same algorithm. These errors are mitigated by the <a href="Don't_repeat_yourself" title="wikilink">Don't Repeat Yourself</a> philosophy.</li>
<li>Comments out of date or incorrect: many programmers assume the comments accurately describe the code.</li>
<li>Differences between documentation and the actual product.</li>
</ul>
<h2 id="well-known-bugs">Well-known bugs</h2>

<p>A number of software bugs have become well-known, usually due to their severity: examples include various space and military aircraft crashes. Possibly the most famous bug is the <a href="Year_2000_problem" title="wikilink">Year 2000 problem</a>, also known as the Y2K bug, in which it was feared that worldwide economic collapse would happen at the start of the year 2000 as a result of computers thinking it was 1900. (In the end, no major problems occurred.)</p>
<h2 id="in-popular-culture">In popular culture</h2>
<ul>
<li>In <a href="Robert_A._Heinlein" title="wikilink">Robert A. Heinlein</a>'s 1966 novel <em><a href="The_Moon_Is_a_Harsh_Mistress" title="wikilink">The Moon Is a Harsh Mistress</a></em>, computer technician Manuel Davis blames a real bug for a (non-existent) failure of supercomputer Mike, presenting a dead fly as evidence.</li>
<li>In the 1968 novel <em><a href="2001:_A_Space_Odyssey_(novel)" title="wikilink">2001: A Space Odyssey</a></em> (and the <a href="2001:_A_Space_Odyssey_(film)" title="wikilink">corresponding 1968 film</a>), a spaceship's onboard computer, <a href="HAL_9000" title="wikilink">HAL 9000</a>, attempts to kill all its crew members. In the followup 1982 novel, <em><a href="2010:_Odyssey_Two" title="wikilink">2010: Odyssey Two</a></em>, and the accompanying 1984 film, <em><a href="2010_(film)" title="wikilink">2010</a></em>, it is revealed that this action was caused by the computer having been programmed with two conflicting objectives: to fully disclose all its information, and to keep the true purpose of the flight secret from the crew; this conflict caused HAL to become paranoid and eventually homicidal. In addition HAL's orders were to continue the mission even if the crew and cold-slept specialists were unable to do so. Thus HAL's solution was within the parameters of the orders since by attempting to shut it off the crew were jeopardizing the mission (it was not sure that they would turn it back on as well as no HAL Series computer was ever shut off after activation).</li>
<li>The 2004 novel <em>The Bug</em>, by <a href="Ellen_Ullman" title="wikilink">Ellen Ullman</a>, is about a programmer's attempt to find an elusive bug in a database application.</li>
<li>The 2008 Canadian film <em><a href="Control_Alt_Delete_(film)" title="wikilink">Control Alt Delete</a></em> is about a computer programmer at the end of 1999 struggling to fix bugs at his company related to the year 2000 problem.</li>
</ul>
<h2 id="see-also">See also</h2>
<ul>
<li><a class="uri" href="Anti-pattern" title="wikilink">Anti-pattern</a></li>
<li><a href="Software_rot" title="wikilink">Bit rot</a></li>
<li><a href="Bug_bounty_program" title="wikilink">Bug bounty program</a></li>
<li><a href="Bug_tracking_system" title="wikilink">Bug tracking system</a></li>
<li><a href="Glitch_removal" title="wikilink">Glitch removal</a></li>
<li><a href="ISO/IEC_9126" title="wikilink">ISO/IEC 9126</a>, which classifies a bug as either a <em>defect</em> or a <em>nonconformity</em></li>
<li><a href="One-line_fix" title="wikilink">One-line fix</a></li>
<li><a href="Orthogonal_Defect_Classification" title="wikilink">Orthogonal Defect Classification</a></li>
<li><a href="Racetrack_problem" title="wikilink">Racetrack problem</a></li>
<li><a href="RISKS_Digest" title="wikilink">RISKS Digest</a></li>
<li><a href="Software_defect_indicator" title="wikilink">Software defect indicator</a></li>
<li><a href="Software_regression" title="wikilink">Software regression</a></li>
<li><a href="Unusual_software_bug" title="wikilink">Unusual software bugs</a> (schroedinbug, heisenbug, Bohr bug, and mandelbug)</li>
</ul>
<h2 id="notes">Notes</h2>
<h2 id="further-reading">Further reading</h2>
<ul>
<li>Allen, Mitch, May/Jun 2002 "Bug Tracking Basics: A beginner’s guide to reporting and tracking defects" <em>The Software Testing &amp; Quality Engineering Magazine</em>. Vol. 4, Issue 3, pp. 20–24.</li>
</ul>
<h2 id="external-links">External links</h2>
<ul>
<li><a href="http://www.history.navy.mil/photos/images/h96000/h96566kc.htm">Picture of the "first computer bug"</a> The error of this term is elaborated above. (Naval Historical Center)</li>
<li><a href="http://www.waterholes.com/~dennette/1996/hopper/bug.htm">The First Computer Bug!</a> An email from 1981 about Adm. Hopper's bug</li>
</ul>

<p>"</p>

<p><a href="Category:Software_bugs" title="wikilink"> </a></p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1"><a href="#fnref1">↩</a></li>
<li id="fn2"><a href="#fnref2">↩</a></li>
<li id="fn3"><a href="#fnref3">↩</a></li>
<li id="fn4"><a href="#fnref4">↩</a></li>
<li id="fn5"><a href="#fnref5">↩</a></li>
<li id="fn6"><a href="#fnref6">↩</a></li>
<li id="fn7"><a href="#fnref7">↩</a></li>
<li id="fn8">"<a href="http://catb.org/jargon/html/B/bug.html">Bug</a>", <em>The Jargon File</em>, ver. 4.4.7. Retrieved June 3, 2010.<a href="#fnref8">↩</a></li>
<li id="fn9">"<a href="http://americanhistory.si.edu/collections/search/object/nmah_334663">Log Book With Computer Bug</a>", National Museum of American History, Smithsonian Institution.<a href="#fnref9">↩</a></li>
<li id="fn10">"<a href="http://www.history.navy.mil/photos/images/h96000/h96566kc.htm">The First "Computer Bug</a>", Naval Historical Center. But note the <a href="Harvard_Mark_II" title="wikilink">Harvard Mark II</a> computer was not complete until the summer of 1947.<a href="#fnref10">↩</a></li>
<li id="fn11">IEEE Annals of the History of Computing, Vol 22 Issue 1, 2000<a href="#fnref11">↩</a></li>
<li id="fn12"><a href="#fnref12">↩</a></li>
<li id="fn13"></li>
<li id="fn14">Journal of the Royal Aeronautical Society. 49, 183/2, 1945 "It ranged ... through the stage of type test and flight test and ‘debugging’ ..."<a href="#fnref14">↩</a></li>
<li id="fn15"><a href="#fnref15">↩</a></li>
<li id="fn16"> <a href="#fnref16">↩</a></li>
<li id="fn17"></li>
<li id="fn18"><a href="#fnref18">↩</a></li>
<li id="fn19"><a href="#fnref19">↩</a></li>
<li id="fn20"><a href="q:Maurice_Wilkes" title="wikilink">Maurice Wilkes Quotes</a><a href="#fnref20">↩</a></li>
<li id="fn21"><a href="#fnref21">↩</a></li>
<li id="fn22"><a href="http://www.catb.org/~esr/writings/cathedral-bazaar/cathedral-bazaar/ar01s04.html">"Release Early, Release Often"</a>, <a href="Eric_S._Raymond" title="wikilink">Eric S. Raymond</a>, <em><a href="The_Cathedral_and_the_Bazaar" title="wikilink">The Cathedral and the Bazaar</a></em><a href="#fnref22">↩</a></li>
<li id="fn23"><a href="http://www.securityfocus.com/news/19">"Wide Open Source"</a>, <a href="Elias_Levy" title="wikilink">Elias Levy</a>, <em>SecurityFocus</em>, April 17, 2000<a href="#fnref23">↩</a></li>
<li id="fn24">Mahbubur Rahman Syed. <a href="https://books.google.com/books?id=e3rAmuQSUXkC">"Multimedia Networking: Technology, Management and Applications: Technology, Management and Applications"</a>. p. 398.<a href="#fnref24">↩</a></li>
<li id="fn25">Chwan-Hwa (John) Wu, J. David Irwin. <a href="https://books.google.com/books?id=bInNBQAAQBAJ">"Introduction to Computer Networks and Cybersecurity"</a>. p. 500.<a href="#fnref25">↩</a></li>
<li id="fn26">RFC 1263: "TCP Extensions Considered Harmful" quote: "the time to distribute the new version of the protocol to all hosts can be quite long (forever in fact). ... If there is the slightest incompatibly between old and new versions, chaos can result."<a href="#fnref26">↩</a></li>
</ol>
</section>
</body>
</html>
